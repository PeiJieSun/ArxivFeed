{"2025-02-28T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2502.21321v1","updated":"2025-02-28T18:59:54Z","published":"2025-02-28T18:59:54Z","title":"LLM Post-Training: A Deep Dive into Reasoning Large Language Models","summary":"  Large Language Models (LLMs) have transformed the natural language processing\nlandscape and brought to life diverse applications. Pretraining on vast\nweb-scale data has laid the foundation for these models, yet the research\ncommunity is now increasingly shifting focus toward post-training techniques to\nachieve further breakthroughs. While pretraining provides a broad linguistic\nfoundation, post-training methods enable LLMs to refine their knowledge,\nimprove reasoning, enhance factual accuracy, and align more effectively with\nuser intents and ethical considerations. Fine-tuning, reinforcement learning,\nand test-time scaling have emerged as critical strategies for optimizing LLMs\nperformance, ensuring robustness, and improving adaptability across various\nreal-world tasks. This survey provides a systematic exploration of\npost-training methodologies, analyzing their role in refining LLMs beyond\npretraining, addressing key challenges such as catastrophic forgetting, reward\nhacking, and inference-time trade-offs. We highlight emerging directions in\nmodel alignment, scalable adaptation, and inference-time reasoning, and outline\nfuture research directions. We also provide a public repository to continually\ntrack developments in this fast-evolving field:\nhttps://github.com/mbzuai-oryx/Awesome-LLM-Post-training.\n","authors":["Komal Kumar","Tajamul Ashraf","Omkar Thawakar","Rao Muhammad Anwer","Hisham Cholakkal","Mubarak Shah","Ming-Hsuan Yang","Phillip H. S. Torr","Salman Khan","Fahad Shahbaz Khan"],"pdf_url":"https://arxiv.org/pdf/2502.21321v1.pdf","comment":"31 pages, 7 figures, 3 tables, 375 references"},{"id":"http://arxiv.org/abs/2502.21315v1","updated":"2025-02-28T18:59:15Z","published":"2025-02-28T18:59:15Z","title":"Identifying Emerging Concepts in Large Corpora","summary":"  We introduce a new method to identify emerging concepts in large text\ncorpora. By analyzing changes in the heatmaps of the underlying embedding\nspace, we are able to detect these concepts with high accuracy shortly after\nthey originate, in turn outperforming common alternatives. We further\ndemonstrate the utility of our approach by analyzing speeches in the U.S.\nSenate from 1941 to 2015. Our results suggest that the minority party is more\nactive in introducing new concepts into the Senate discourse. We also identify\nspecific concepts that closely correlate with the Senators' racial, ethnic, and\ngender identities. An implementation of our method is publicly available.\n","authors":["Sibo Ma","Julian Nyarko"],"pdf_url":"https://arxiv.org/pdf/2502.21315v1.pdf","comment":"9 pages, 4 figures"},{"id":"http://arxiv.org/abs/2410.08388v4","updated":"2025-02-28T18:55:08Z","published":"2024-10-10T21:51:22Z","title":"The GUS Framework: Benchmarking Social Bias Classification with\n  Discriminative (Encoder-Only) and Generative (Decoder-Only) Language Models","summary":"  The detection of social bias in text is a critical challenge, particularly\ndue to the limitations of binary classification methods. These methods often\noversimplify nuanced biases, leading to high emotional impact when content is\nmisclassified as either \"biased\" or \"fair.\" To address these shortcomings, we\npropose a more nuanced framework that focuses on three key linguistic\ncomponents underlying social bias: Generalizations, Unfairness, and Stereotypes\n(the GUS framework). The GUS framework employs a semi-automated approach to\ncreate a comprehensive synthetic dataset, which is then verified by humans to\nmaintain ethical standards. This dataset enables robust multi-label token\nclassification. Our methodology, which combines discriminative (encoder-only)\nmodels and generative (auto-regressive large language models), identifies\nbiased entities in text. Through extensive experiments, we demonstrate that\nencoder-only models are effective for this complex task, often outperforming\nstate-of-the-art methods, both in terms of macro and entity-wise F1-score and\nHamming loss. These findings can guide the choice of model for different use\ncases, highlighting the GUS framework's effectiveness in capturing explicit and\nimplicit biases across diverse contexts, and offering a pathway for future\nresearch and applications in various fields.\n","authors":["Maximus Powers","Shaina Raza","Alex Chang","Umang Mavani","Harshitha Reddy Jonala","Ansh Tiwari","Hua Wei"],"pdf_url":"https://arxiv.org/pdf/2410.08388v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21309v1","updated":"2025-02-28T18:52:24Z","published":"2025-02-28T18:52:24Z","title":"FANformer: Improving Large Language Models Through Effective Periodicity\n  Modeling","summary":"  Periodicity, as one of the most important basic characteristics, lays the\nfoundation for facilitating structured knowledge acquisition and systematic\ncognitive processes within human learning paradigms. However, the potential\nflaws of periodicity modeling in Transformer affect the learning efficiency and\nestablishment of underlying principles from data for large language models\n(LLMs) built upon it. In this paper, we demonstrate that integrating effective\nperiodicity modeling can improve the learning efficiency and performance of\nLLMs. We introduce FANformer, which integrates Fourier Analysis Network (FAN)\ninto attention mechanism to achieve efficient periodicity modeling, by\nmodifying the feature projection process of attention mechanism. Extensive\nexperimental results on language modeling show that FANformer consistently\noutperforms Transformer when scaling up model size and training tokens,\nunderscoring its superior learning efficiency. To further validate the\neffectiveness of FANformer, we pretrain a FANformer-1B on 1 trillion tokens.\nFANformer-1B exhibits marked improvements on downstream tasks compared to\nopen-source LLMs with similar model parameters or training tokens. The results\nposition FANformer as an effective and promising architecture for advancing\nLLMs.\n","authors":["Yihong Dong","Ge Li","Xue Jiang","Yongding Tao","Kechi Zhang","Hao Zhu","Huanyu Liu","Jiazheng Ding","Jia Li","Jinliang Deng","Hong Mei"],"pdf_url":"https://arxiv.org/pdf/2502.21309v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21297v1","updated":"2025-02-28T18:28:16Z","published":"2025-02-28T18:28:16Z","title":"Persuasion Should be Double-Blind: A Multi-Domain Dialogue Dataset With\n  Faithfulness Based on Causal Theory of Mind","summary":"  Persuasive dialogue plays a pivotal role in human communication, influencing\nvarious domains. Recent persuasive dialogue datasets often fail to align with\nreal-world interpersonal interactions, leading to unfaithful representations.\nFor instance, unrealistic scenarios may arise, such as when the persuadee\nexplicitly instructs the persuader on which persuasion strategies to employ,\nwith each of the persuadee's questions corresponding to a specific strategy for\nthe persuader to follow. This issue can be attributed to a violation of the\n\"Double Blind\" condition, where critical information is fully shared between\nparticipants. In actual human interactions, however, key information such as\nthe mental state of the persuadee and the persuasion strategies of the\npersuader is not directly accessible. The persuader must infer the persuadee's\nmental state using Theory of Mind capabilities and construct arguments that\nalign with the persuadee's motivations. To address this gap, we introduce\nToMMA, a novel multi-agent framework for dialogue generation that is guided by\ncausal Theory of Mind. This framework ensures that information remains\nundisclosed between agents, preserving \"double-blind\" conditions, while causal\nToM directs the persuader's reasoning, enhancing alignment with human-like\npersuasion dynamics. Consequently, we present CToMPersu, a multi-domain,\nmulti-turn persuasive dialogue dataset that tackles both double-blind and\nlogical coherence issues, demonstrating superior performance across multiple\nmetrics and achieving better alignment with real human dialogues. Our dataset\nand prompts are available at https://github.com/DingyiZhang/ToMMA-CToMPersu .\n","authors":["Dingyi Zhang","Deyu Zhou"],"pdf_url":"https://arxiv.org/pdf/2502.21297v1.pdf","comment":"23pages"},{"id":"http://arxiv.org/abs/2501.09768v3","updated":"2025-02-28T18:27:21Z","published":"2025-01-15T11:32:35Z","title":"Can Large Language Models Predict the Outcome of Judicial Decisions?","summary":"  Large Language Models (LLMs) have shown exceptional capabilities in Natural\nLanguage Processing (NLP) across diverse domains. However, their application in\nspecialized tasks such as Legal Judgment Prediction (LJP) for low-resource\nlanguages like Arabic remains underexplored. In this work, we address this gap\nby developing an Arabic LJP dataset, collected and preprocessed from Saudi\ncommercial court judgments. We benchmark state-of-the-art open-source LLMs,\nincluding LLaMA-3.2-3B and LLaMA-3.1-8B, under varying configurations such as\nzero-shot, one-shot, and fine-tuning using LoRA. Additionally, we employed a\ncomprehensive evaluation framework that integrates both quantitative metrics\n(such as BLEU, ROUGE, and BERT) and qualitative assessments (including\nCoherence, Legal Language, Clarity, etc.) using an LLM. Our results demonstrate\nthat fine-tuned smaller models achieve comparable performance to larger models\nin task-specific contexts while offering significant resource efficiency.\nFurthermore, we investigate the impact of fine-tuning the model on a diverse\nset of instructions, offering valuable insights into the development of a more\nhuman-centric and adaptable LLM. We have made the dataset, code, and models\npublicly available to provide a solid foundation for future research in Arabic\nlegal NLP.\n","authors":["Mohamed Bayan Kmainasi","Ali Ezzat Shahroor","Amani Al-Ghraibah"],"pdf_url":"https://arxiv.org/pdf/2501.09768v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.02891v2","updated":"2025-02-28T17:57:47Z","published":"2025-01-06T10:08:56Z","title":"Explaining Humour Style Classifications: An XAI Approach to\n  Understanding Computational Humour Analysis","summary":"  Humour styles can have either a negative or a positive impact on well-being.\nGiven the importance of these styles to mental health, significant research has\nbeen conducted on their automatic identification. However, the automated\nmachine learning models used for this purpose are black boxes, making their\nprediction decisions opaque. Clarity and transparency are vital in the field of\nmental health. This paper presents an explainable AI (XAI) framework for\nunderstanding humour style classification, building upon previous work in\ncomputational humour analysis. Using the best-performing single model\n(ALI+XGBoost) from prior research, we apply comprehensive XAI techniques to\nanalyse how linguistic, emotional, and semantic features contribute to humour\nstyle classification decisions. Our analysis reveals distinct patterns in how\ndifferent humour styles are characterised and misclassified, with particular\nemphasis on the challenges in distinguishing affiliative humour from other\nstyles. Through detailed examination of feature importance, error patterns, and\nmisclassification cases, we identify key factors influencing model decisions,\nincluding emotional ambiguity, context misinterpretation, and target\nidentification. The framework demonstrates significant utility in understanding\nmodel behaviour, achieving interpretable insights into the complex interplay of\nfeatures that define different humour styles. Our findings contribute to both\nthe theoretical understanding of computational humour analysis and practical\napplications in mental health, content moderation, and digital humanities\nresearch.\n","authors":["Mary Ogbuka Kenneth","Foaad Khosmood","Abbas Edalat"],"pdf_url":"https://arxiv.org/pdf/2501.02891v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.00075v5","updated":"2025-02-28T17:50:12Z","published":"2024-06-21T19:18:16Z","title":"Logicbreaks: A Framework for Understanding Subversion of Rule-based\n  Inference","summary":"  We study how to subvert large language models (LLMs) from following\nprompt-specified rules. We first formalize rule-following as inference in\npropositional Horn logic, a mathematical system in which rules have the form\n\"if $P$ and $Q$, then $R$\" for some propositions $P$, $Q$, and $R$. Next, we\nprove that although small transformers can faithfully follow such rules,\nmaliciously crafted prompts can still mislead both theoretical constructions\nand models learned from data. Furthermore, we demonstrate that popular attack\nalgorithms on LLMs find adversarial prompts and induce attention patterns that\nalign with our theory. Our novel logic-based framework provides a foundation\nfor studying LLMs in rule-based settings, enabling a formal analysis of tasks\nlike logical reasoning and jailbreak attacks.\n","authors":["Anton Xue","Avishree Khare","Rajeev Alur","Surbhi Goel","Eric Wong"],"pdf_url":"https://arxiv.org/pdf/2407.00075v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21265v1","updated":"2025-02-28T17:41:27Z","published":"2025-02-28T17:41:27Z","title":"Token-level Ensembling of Models with Different Vocabularies","summary":"  Model ensembling is a technique to combine the predicted distributions of two\nor more models, often leading to improved robustness and performance. For\nensembling in text generation, the next token's probability distribution is\nderived from a weighted sum of the distributions of each individual model. This\nrequires the underlying models to share the same subword vocabulary, limiting\nthe applicability of ensembling, since many open-sourced models have distinct\nvocabularies. In research settings, experimentation or upgrades to vocabularies\nmay introduce multiple vocabulary sizes. This paper proposes an inference-time\nonly algorithm that allows for ensembling models with different vocabularies,\nwithout the need to learn additional parameters or alter the underlying models.\nInstead, the algorithm ensures that tokens generated by the ensembled models\n\\textit{agree} in their surface form. We apply this technique to combinations\nof traditional encoder-decoder models and decoder-only LLMs and evaluate on\nmachine translation. In addition to expanding to model pairs that were\npreviously incapable of token-level ensembling, our algorithm frequently\nimproves translation performance over either model individually.\n","authors":["Rachel Wicks","Kartik Ravisankar","Xinchen Yang","Philipp Koehn","Matt Post"],"pdf_url":"https://arxiv.org/pdf/2502.21265v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2502.21263v1","updated":"2025-02-28T17:40:24Z","published":"2025-02-28T17:40:24Z","title":"RuCCoD: Towards Automated ICD Coding in Russian","summary":"  This study investigates the feasibility of automating clinical coding in\nRussian, a language with limited biomedical resources. We present a new dataset\nfor ICD coding, which includes diagnosis fields from electronic health records\n(EHRs) annotated with over 10,000 entities and more than 1,500 unique ICD\ncodes. This dataset serves as a benchmark for several state-of-the-art models,\nincluding BERT, LLaMA with LoRA, and RAG, with additional experiments examining\ntransfer learning across domains (from PubMed abstracts to medical diagnosis)\nand terminologies (from UMLS concepts to ICD codes). We then apply the\nbest-performing model to label an in-house EHR dataset containing patient\nhistories from 2017 to 2021. Our experiments, conducted on a carefully curated\ntest set, demonstrate that training with the automated predicted codes leads to\na significant improvement in accuracy compared to manually annotated data from\nphysicians. We believe our findings offer valuable insights into the potential\nfor automating clinical coding in resource-limited languages like Russian,\nwhich could enhance clinical efficiency and data accuracy in these contexts.\n","authors":["Aleksandr Nesterov","Andrey Sakhovskiy","Ivan Sviridov","Airat Valiev","Vladimir Makharev","Petr Anokhin","Galina Zubkova","Elena Tutubalina"],"pdf_url":"https://arxiv.org/pdf/2502.21263v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21239v1","updated":"2025-02-28T17:09:08Z","published":"2025-02-28T17:09:08Z","title":"Semantic Volume: Quantifying and Detecting both External and Internal\n  Uncertainty in LLMs","summary":"  Large language models (LLMs) have demonstrated remarkable performance across\ndiverse tasks by encoding vast amounts of factual knowledge. However, they are\nstill prone to hallucinations, generating incorrect or misleading information,\noften accompanied by high uncertainty. Existing methods for hallucination\ndetection primarily focus on quantifying internal uncertainty, which arises\nfrom missing or conflicting knowledge within the model. However, hallucinations\ncan also stem from external uncertainty, where ambiguous user queries lead to\nmultiple possible interpretations. In this work, we introduce Semantic Volume,\na novel mathematical measure for quantifying both external and internal\nuncertainty in LLMs. Our approach perturbs queries and responses, embeds them\nin a semantic space, and computes the determinant of the Gram matrix of the\nembedding vectors, capturing their dispersion as a measure of uncertainty. Our\nframework provides a generalizable and unsupervised uncertainty detection\nmethod without requiring white-box access to LLMs. We conduct extensive\nexperiments on both external and internal uncertainty detection, demonstrating\nthat our Semantic Volume method consistently outperforms existing baselines in\nboth tasks. Additionally, we provide theoretical insights linking our measure\nto differential entropy, unifying and extending previous sampling-based\nuncertainty measures such as the semantic entropy. Semantic Volume is shown to\nbe a robust and interpretable approach to improving the reliability of LLMs by\nsystematically detecting uncertainty in both user queries and model responses.\n","authors":["Xiaomin Li","Zhou Yu","Ziji Zhang","Yingying Zhuang","Swair Shah","Anurag Beniwal"],"pdf_url":"https://arxiv.org/pdf/2502.21239v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21236v1","updated":"2025-02-28T17:05:13Z","published":"2025-02-28T17:05:13Z","title":"Transforming Tuberculosis Care: Optimizing Large Language Models For\n  Enhanced Clinician-Patient Communication","summary":"  Tuberculosis (TB) is the leading cause of death from an infectious disease\nglobally, with the highest burden in low- and middle-income countries. In these\nregions, limited healthcare access and high patient-to-provider ratios impede\neffective patient support, communication, and treatment completion. To bridge\nthis gap, we propose integrating a specialized Large Language Model into an\nefficacious digital adherence technology to augment interactive communication\nwith treatment supporters. This AI-powered approach, operating within a\nhuman-in-the-loop framework, aims to enhance patient engagement and improve TB\ntreatment outcomes.\n","authors":["Daniil Filienko","Mahek Nizar","Javier Roberti","Denise Galdamez","Haroon Jakher","Sarah Iribarren","Weichao Yuwen","Martine De Cock"],"pdf_url":"https://arxiv.org/pdf/2502.21236v1.pdf","comment":"GenAI4Health at AAAI-25"},{"id":"http://arxiv.org/abs/2412.16100v2","updated":"2025-02-28T17:02:23Z","published":"2024-12-20T17:42:25Z","title":"Logical Consistency of Large Language Models in Fact-checking","summary":"  In recent years, large language models (LLMs) have demonstrated significant\nsuccess in performing varied natural language tasks such as language\ntranslation, question-answering, summarizing, fact-checking, etc. Despite LLMs'\nimpressive ability to generate human-like texts, LLMs are infamous for their\ninconsistent responses - a meaning-preserving change in the input query results\nin an inconsistent response and attributes to vulnerabilities of LLMs such as\nhallucination. Consequently, existing research focuses on simple\nparaphrasing-based consistency assessment of LLMs, and ignores complex queries\nthat necessitate an even better understanding of logical reasoning by an LLM.\nOur work therefore addresses the logical inconsistency of LLMs under complex\nlogical queries with primitive logical operators, e.g., negation, conjunction,\nand disjunction. As a test bed, we consider retrieval-augmented LLMs on a\nfact-checking task involving propositional logic queries from knowledge graphs\n(KGs). Our contributions are threefold. Benchmark: We introduce three logical\nfact-checking datasets over KGs for community development towards logically\nconsistent LLMs. Assessment: We propose consistency measures of LLMs on\npropositional logic queries and demonstrate that existing LLMs lack logical\nconsistency, especially on complex queries. Improvement: We employ supervised\nfine-tuning to improve the logical consistency of LLMs on the complex\nfact-checking task with KG contexts. We have made our source code and\nbenchmarks available.\n","authors":["Bishwamittra Ghosh","Sarah Hasan","Naheed Anjum Arafat","Arijit Khan"],"pdf_url":"https://arxiv.org/pdf/2412.16100v2.pdf","comment":"Published at ICLR 2025"},{"id":"http://arxiv.org/abs/2502.21228v1","updated":"2025-02-28T16:59:30Z","published":"2025-02-28T16:59:30Z","title":"ECLeKTic: a Novel Challenge Set for Evaluation of Cross-Lingual\n  Knowledge Transfer","summary":"  To achieve equitable performance across languages, multilingual large\nlanguage models (LLMs) must be able to abstract knowledge beyond the language\nin which it was acquired. However, the current literature lacks reliable ways\nto measure LLMs' capability of cross-lingual knowledge transfer. To that end,\nwe present ECLeKTic, a multilingual closed-book QA (CBQA) dataset that\nEvaluates Cross-Lingual Knowledge Transfer in a simple, black-box manner. We\ndetected information with uneven coverage across languages by controlling for\npresence and absence of Wikipedia articles in 12 languages. We generated\nknowledge-seeking questions in a source language, for which the answer appears\nin a relevant Wikipedia article and translated them to all other 11 languages,\nfor which the respective Wikipedias lack equivalent articles. Assuming that\nWikipedia reflects the prominent knowledge in the LLM's training data, to solve\nECLeKTic's CBQA task the model is required to transfer knowledge between\nlanguages. Experimenting with 8 LLMs, we show that SOTA models struggle to\neffectively share knowledge across, languages even if they can predict the\nanswer well for queries in the same language the knowledge was acquired in.\n","authors":["Omer Goldman","Uri Shaham","Dan Malkin","Sivan Eiger","Avinatan Hassidim","Yossi Matias","Joshua Maynez","Adi Mayrav Gilady","Jason Riesa","Shruti Rijhwani","Laura Rimell","Idan Szpektor","Reut Tsarfaty","Matan Eyal"],"pdf_url":"https://arxiv.org/pdf/2502.21228v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21224v1","updated":"2025-02-28T16:56:34Z","published":"2025-02-28T16:56:34Z","title":"Detecting Linguistic Diversity on Social Media","summary":"  This chapter explores the efficacy of using social media data to examine\nchanging linguistic behaviour of a place. We focus our investigation on\nAotearoa New Zealand where official statistics from the census is the only\nsource of language use data. We use published census data as the ground truth\nand the social media sub-corpus from the Corpus of Global Language Use as our\nalternative data source. We use place as the common denominator between the two\ndata sources. We identify the language conditions of each tweet in the social\nmedia data set and validated our results with two language identification\nmodels. We then compare levels of linguistic diversity at national, regional,\nand local geographies. The results suggest that social media language data has\nthe possibility to provide a rich source of spatial and temporal insights on\nthe linguistic profile of a place. We show that social media is sensitive to\ndemographic and sociopolitical changes within a language and at low-level\nregional and local geographies.\n","authors":["Sidney Wong","Benjamin Adams","Jonathan Dunn"],"pdf_url":"https://arxiv.org/pdf/2502.21224v1.pdf","comment":"Accepted to Cartography and GIScience in Australasia and Oceania:\n  Including twenty years of GeoCart"},{"id":"http://arxiv.org/abs/2410.20672v3","updated":"2025-02-28T16:44:24Z","published":"2024-10-28T02:15:45Z","title":"Relaxed Recursive Transformers: Effective Parameter Sharing with\n  Layer-wise LoRA","summary":"  Large language models (LLMs) are expensive to deploy. Parameter sharing\noffers a possible path towards reducing their size and cost, but its\neffectiveness in modern LLMs remains fairly limited. In this work, we revisit\n\"layer tying\" as form of parameter sharing in Transformers, and introduce novel\nmethods for converting existing LLMs into smaller \"Recursive Transformers\" that\nshare parameters across layers, with minimal loss of performance. Here, our\nRecursive Transformers are efficiently initialized from standard pretrained\nTransformers, but only use a single block of unique layers that is then\nrepeated multiple times in a loop. We further improve performance by\nintroducing Relaxed Recursive Transformers that add flexibility to the layer\ntying constraint via depth-wise low-rank adaptation (LoRA) modules, yet still\npreserve the compactness of the overall model. We show that our recursive\nmodels (e.g., recursive Gemma 1B) outperform both similar-sized vanilla\npretrained models (such as TinyLlama 1.1B and Pythia 1B) and knowledge\ndistillation baselines -- and can even recover most of the performance of the\noriginal \"full-size\" model (e.g., Gemma 2B with no shared parameters). Finally,\nwe propose Continuous Depth-wise Batching, a promising new inference paradigm\nenabled by the Recursive Transformer when paired with early exiting. In a\ntheoretical analysis, we show that this has the potential to lead to\nsignificant (2-3x) gains in inference throughput.\n","authors":["Sangmin Bae","Adam Fisch","Hrayr Harutyunyan","Ziwei Ji","Seungyeon Kim","Tal Schuster"],"pdf_url":"https://arxiv.org/pdf/2410.20672v3.pdf","comment":"ICLR 2025; 49 pages, 17 figures, 19 tables"},{"id":"http://arxiv.org/abs/2404.16880v2","updated":"2025-02-28T16:19:08Z","published":"2024-04-23T12:35:44Z","title":"Atomas: Hierarchical Alignment on Molecule-Text for Unified Molecule\n  Understanding and Generation","summary":"  Molecule-and-text cross-modal representation learning has emerged as a\npromising direction for enhancing the quality of molecular representation,\nthereby improving performance in various scientific fields, including drug\ndiscovery and materials science. Existing studies adopt a global alignment\napproach to learn the knowledge from different modalities. These global\nalignment approaches fail to capture fine-grained information, such as\nmolecular fragments and their corresponding textual description, which is\ncrucial for downstream tasks. Furthermore, it is incapable to model such\ninformation using a similar global alignment strategy due to data scarcity of\npaired local part annotated data from existing datasets. In this paper, we\npropose Atomas, a multi-modal molecular representation learning framework to\njointly learn representations from SMILES string and text. We design a\nHierarchical Adaptive Alignment model to concurrently learn the fine-grained\nfragment correspondence between two modalities and align these representations\nof fragments in three levels. Additionally, Atomas's end-to-end training\nframework incorporates the tasks of understanding and generating molecule,\nthereby supporting a wider range of downstream tasks. In the retrieval task,\nAtomas exhibits robust generalization ability and outperforms the baseline by\n30.8% of recall@1 on average. In the generation task, Atomas achieves\nstate-of-the-art results in both molecule captioning task and molecule\ngeneration task. Moreover, the visualization of the Hierarchical Adaptive\nAlignment model further confirms the chemical significance of our approach. Our\ncodes can be found at https://anonymous.4open.science/r/Atomas-03C3.\n","authors":["Yikun Zhang","Geyan Ye","Chaohao Yuan","Bo Han","Long-Kai Huang","Jianhua Yao","Wei Liu","Yu Rong"],"pdf_url":"https://arxiv.org/pdf/2404.16880v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.15296v3","updated":"2025-02-28T15:23:40Z","published":"2025-01-25T18:26:39Z","title":"You Only Prune Once: Designing Calibration-Free Model Compression With\n  Policy Learning","summary":"  The ever-increasing size of large language models (LLMs) presents significant\nchallenges for deployment due to their heavy computational and memory\nrequirements. Current model pruning techniques attempt to alleviate these\nissues by relying heavily on external calibration datasets to determine which\nparameters to prune or compress, thus limiting their flexibility and\nscalability across different compression ratios. Moreover, these methods often\ncause severe performance degradation, particularly in downstream tasks, when\nsubjected to higher compression rates. In this paper, we propose PruneNet, a\nnovel model compression method that addresses these limitations by\nreformulating model pruning as a policy learning process. PruneNet decouples\nthe pruning process from the model architecture, eliminating the need for\ncalibration datasets. It learns a stochastic pruning policy to assess parameter\nimportance solely based on intrinsic model properties while preserving the\nspectral structure to minimize information loss. PruneNet can compress the\nLLaMA-2-7B model in just 15 minutes, achieving over 80% retention of its\nzero-shot performance with a 30% compression ratio, outperforming existing\nmethods that retain only 75% performance. Furthermore, on complex multitask\nlanguage understanding tasks, PruneNet demonstrates its robustness by\npreserving up to 80% performance of the original model, proving itself a\nsuperior alternative to conventional structured compression techniques.\n","authors":["Ayan Sengupta","Siddhant Chaudhary","Tanmoy Chakraborty"],"pdf_url":"https://arxiv.org/pdf/2501.15296v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.08587v2","updated":"2025-02-28T15:16:04Z","published":"2024-06-12T18:47:28Z","title":"CS-Bench: A Comprehensive Benchmark for Large Language Models towards\n  Computer Science Mastery","summary":"  Large language models (LLMs) have demonstrated significant potential in\nadvancing various fields of research and society. However, the current\ncommunity of LLMs overly focuses on benchmarks for analyzing specific\nfoundational skills (e.g. mathematics and code generation), neglecting an\nall-round evaluation of the computer science field. To bridge this gap, we\nintroduce CS-Bench, the first multilingual (English, Chinese, French, German)\nbenchmark dedicated to evaluating the performance of LLMs in computer science.\nCS-Bench comprises approximately 10K meticulously curated test samples,\ncovering 26 subfields across 4 key areas of computer science, encompassing\nvarious task forms and divisions of knowledge and reasoning. Utilizing\nCS-Bench, we conduct a comprehensive evaluation of over 30 mainstream LLMs,\nrevealing the relationship between CS performance and model scales. We also\nquantitatively analyze the reasons for failures in existing LLMs and highlight\ndirections for improvements, including knowledge supplementation and\nCS-specific reasoning. Further cross-capability experiments show a high\ncorrelation between LLMs' capabilities in computer science and their abilities\nin mathematics and coding. Moreover, expert LLMs specialized in mathematics and\ncoding also demonstrate strong performances in several CS subfields. Looking\nahead, we envision CS-Bench serving as a cornerstone for LLM applications in\nthe CS field and paving new avenues in assessing LLMs' diverse reasoning\ncapabilities. The CS-Bench data and evaluation code are available at\nhttps://github.com/csbench/csbench.\n","authors":["Xiaoshuai Song","Muxi Diao","Guanting Dong","Zhengyang Wang","Yujia Fu","Runqi Qiao","Zhexu Wang","Dayuan Fu","Huangxuan Wu","Bin Liang","Weihao Zeng","Yejie Wang","Zhuoma GongQue","Jianing Yu","Qiuna Tan","Weiran Xu"],"pdf_url":"https://arxiv.org/pdf/2406.08587v2.pdf","comment":"Accepted at ICLR 2025"},{"id":"http://arxiv.org/abs/2501.06842v2","updated":"2025-02-28T15:15:31Z","published":"2025-01-12T15:21:22Z","title":"SPAM: Spike-Aware Adam with Momentum Reset for Stable LLM Training","summary":"  Large Language Models (LLMs) have demonstrated exceptional performance across\ndiverse tasks, yet their training remains highly resource-intensive and\nsusceptible to critical challenges such as training instability. A predominant\nsource of this instability stems from gradient and loss spikes, which disrupt\nthe learning process, often leading to costly interventions like checkpoint\nrecovery and experiment restarts, further amplifying inefficiencies. This paper\npresents a comprehensive investigation into gradient spikes observed during LLM\ntraining, revealing their prevalence across multiple architectures and\ndatasets. Our analysis shows that these spikes can be up to $1000\\times$ larger\nthan typical gradients, substantially deteriorating model performance. To\naddress this issue, we propose Spike-Aware Adam with Momentum Reset SPAM, a\nnovel optimizer designed to counteract gradient spikes through momentum reset\nand spike-aware gradient clipping. Extensive experiments, including both\npre-training and fine-tuning, demonstrate that SPAM consistently surpasses Adam\nand its variants across various tasks, including (1) LLM pre-training from 60M\nto 1B, (2) 4-bit LLM pre-training,(3) reinforcement learning, and (4) Time\nSeries Forecasting. Additionally, SPAM facilitates memory-efficient training by\nenabling sparse momentum, where only a subset of momentum terms are maintained\nand updated. When operating under memory constraints, SPAM outperforms\nstate-of-the-art memory-efficient optimizers such as GaLore and Adam-Mini. Our\nwork underscores the importance of mitigating gradient spikes in LLM training\nand introduces an effective optimization strategy that enhances both training\nstability and resource efficiency at scale. Code is available at\nhttps://github.com/TianjinYellow/SPAM-Optimizer.git\n","authors":["Tianjin Huang","Ziquan Zhu","Gaojie Jin","Lu Liu","Zhangyang Wang","Shiwei Liu"],"pdf_url":"https://arxiv.org/pdf/2501.06842v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.01523v4","updated":"2025-02-28T15:13:46Z","published":"2024-01-03T03:28:55Z","title":"GOAT-Bench: Safety Insights to Large Multimodal Models through\n  Meme-Based Social Abuse","summary":"  The exponential growth of social media has profoundly transformed how\ninformation is created, disseminated, and absorbed, exceeding any precedent in\nthe digital age. Regrettably, this explosion has also spawned a significant\nincrease in the online abuse of memes. Evaluating the negative impact of memes\nis notably challenging, owing to their often subtle and implicit meanings,\nwhich are not directly conveyed through the overt text and image. In light of\nthis, large multimodal models (LMMs) have emerged as a focal point of interest\ndue to their remarkable capabilities in handling diverse multimodal tasks. In\nresponse to this development, our paper aims to thoroughly examine the capacity\nof various LMMs (e.g., GPT-4o) to discern and respond to the nuanced aspects of\nsocial abuse manifested in memes. We introduce the comprehensive meme\nbenchmark, GOAT-Bench, comprising over 6K varied memes encapsulating themes\nsuch as implicit hate speech, sexism, and cyberbullying, etc. Utilizing\nGOAT-Bench, we delve into the ability of LMMs to accurately assess hatefulness,\nmisogyny, offensiveness, sarcasm, and harmful content. Our extensive\nexperiments across a range of LMMs reveal that current models still exhibit a\ndeficiency in safety awareness, showing insensitivity to various forms of\nimplicit abuse. We posit that this shortfall represents a critical impediment\nto the realization of safe artificial intelligence. The GOAT-Bench and\naccompanying resources are publicly accessible at https://goatlmm.github.io/,\ncontributing to ongoing research in this vital field.\n","authors":["Hongzhan Lin","Ziyang Luo","Bo Wang","Ruichao Yang","Jing Ma"],"pdf_url":"https://arxiv.org/pdf/2401.01523v4.pdf","comment":"The first work to benchmark Large Multimodal Models in safety insight\n  on social media"},{"id":"http://arxiv.org/abs/2501.13983v2","updated":"2025-02-28T15:07:55Z","published":"2025-01-23T06:57:24Z","title":"AdEval: Alignment-based Dynamic Evaluation to Mitigate Data\n  Contamination in Large Language Models","summary":"  As Large Language Models (LLMs) are pretrained on massive-scale corpora, the\nissue of data contamination has become increasingly severe, leading to\npotential overestimation of model performance during evaluation. To address\nthis, we propose AdEval (Alignment-based Dynamic Evaluation), a dynamic data\nevaluation method aimed at mitigating the impact of data contamination on\nevaluation reliability. AdEval extracts key knowledge points and main ideas to\nalign dynamically generated questions with static data's core concepts. It also\nleverages online search to provide detailed explanations of related knowledge\npoints, thereby creating high-quality evaluation samples with robust knowledge\nsupport. Furthermore, AdEval incorporates mechanisms to control the number and\ncomplexity of questions, enabling dynamic alignment and flexible adjustment.\nThis ensures that the generated questions align with the complexity of static\ndata while supporting varied complexity levels. Based on Bloom's taxonomy,\nAdEval conducts a multi-dimensional evaluation of LLMs across six cognitive\nlevels: remembering, understanding, applying, analyzing, evaluating, and\ncreating. Experimental results on multiple datasets demonstrate that AdEval\neffectively reduces the impact of data contamination on evaluation outcomes,\nenhancing both the fairness and reliability of the evaluation process.\n","authors":["Yang Fan"],"pdf_url":"https://arxiv.org/pdf/2501.13983v2.pdf","comment":"There are serious academic problems in this paper, such as data\n  falsification and plagiarism in the method of the paper"},{"id":"http://arxiv.org/abs/2502.19104v2","updated":"2025-02-28T15:00:01Z","published":"2025-02-26T12:46:59Z","title":"Are All Spanish Doctors Male? Evaluating Gender Bias in German Machine\n  Translation","summary":"  We present WinoMTDE, a new gender bias evaluation test set designed to assess\noccupational stereotyping and underrepresentation in German machine translation\n(MT) systems. Building on the automatic evaluation method introduced by\narXiv:1906.00591v1, we extend the approach to German, a language with\ngrammatical gender. The WinoMTDE dataset comprises 288 German sentences that\nare balanced in regard to gender, as well as stereotype, which was annotated\nusing German labor statistics. We conduct a large-scale evaluation of five\nwidely used MT systems and a large language model. Our results reveal\npersistent bias in most models, with the LLM outperforming traditional systems.\nThe dataset and evaluation code are publicly available under\nhttps://github.com/michellekappl/mt_gender_german.\n","authors":["Michelle Kappl"],"pdf_url":"https://arxiv.org/pdf/2502.19104v2.pdf","comment":"ISCA/ITG Workshop on Diversity in Large Speech and Language Models"},{"id":"http://arxiv.org/abs/2502.21112v1","updated":"2025-02-28T14:52:25Z","published":"2025-02-28T14:52:25Z","title":"Optimizing Large Language Models for ESG Activity Detection in Financial\n  Texts","summary":"  The integration of Environmental, Social, and Governance (ESG) factors into\ncorporate decision-making is a fundamental aspect of sustainable finance.\nHowever, ensuring that business practices align with evolving regulatory\nframeworks remains a persistent challenge. AI-driven solutions for\nautomatically assessing the alignment of sustainability reports and\nnon-financial disclosures with specific ESG activities could greatly support\nthis process. Yet, this task remains complex due to the limitations of\ngeneral-purpose Large Language Models (LLMs) in domain-specific contexts and\nthe scarcity of structured, high-quality datasets. In this paper, we\ninvestigate the ability of current-generation LLMs to identify text related to\nenvironmental activities. Furthermore, we demonstrate that their performance\ncan be significantly enhanced through fine-tuning on a combination of original\nand synthetically generated data. To this end, we introduce ESG-Activities, a\nbenchmark dataset containing 1,325 labelled text segments classified according\nto the EU ESG taxonomy. Our experimental results show that fine-tuning on\nESG-Activities significantly enhances classification accuracy, with open models\nsuch as Llama 7B and Gemma 7B outperforming large proprietary solutions in\nspecific configurations. These findings have important implications for\nfinancial analysts, policymakers, and AI researchers seeking to enhance ESG\ntransparency and compliance through advanced natural language processing\ntechniques.\n","authors":["Mattia Birti","Francesco Osborne","Andrea Maurino"],"pdf_url":"https://arxiv.org/pdf/2502.21112v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.18540v2","updated":"2025-02-28T14:49:25Z","published":"2024-05-28T19:16:17Z","title":"Learning diverse attacks on large language models for robust red-teaming\n  and safety tuning","summary":"  Red-teaming, or identifying prompts that elicit harmful responses, is a\ncritical step in ensuring the safe and responsible deployment of large language\nmodels (LLMs). Developing effective protection against many modes of attack\nprompts requires discovering diverse attacks. Automated red-teaming typically\nuses reinforcement learning to fine-tune an attacker language model to generate\nprompts that elicit undesirable responses from a target LLM, as measured, for\nexample, by an auxiliary toxicity classifier. We show that even with explicit\nregularization to favor novelty and diversity, existing approaches suffer from\nmode collapse or fail to generate effective attacks. As a flexible and\nprobabilistically principled alternative, we propose to use GFlowNet\nfine-tuning, followed by a secondary smoothing phase, to train the attacker\nmodel to generate diverse and effective attack prompts. We find that the\nattacks generated by our method are effective against a wide range of target\nLLMs, both with and without safety tuning, and transfer well between target\nLLMs. Finally, we demonstrate that models safety-tuned using a dataset of\nred-teaming prompts generated by our method are robust to attacks from other\nRL-based red-teaming approaches.\n","authors":["Seanie Lee","Minsu Kim","Lynn Cherif","David Dobre","Juho Lee","Sung Ju Hwang","Kenji Kawaguchi","Gauthier Gidel","Yoshua Bengio","Nikolay Malkin","Moksh Jain"],"pdf_url":"https://arxiv.org/pdf/2405.18540v2.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2502.21107v1","updated":"2025-02-28T14:46:02Z","published":"2025-02-28T14:46:02Z","title":"Generating patient cohorts from electronic health records using two-step\n  retrieval-augmented text-to-SQL generation","summary":"  Clinical cohort definition is crucial for patient recruitment and\nobservational studies, yet translating inclusion/exclusion criteria into SQL\nqueries remains challenging and manual. We present an automated system\nutilizing large language models that combines criteria parsing, two-level\nretrieval augmented generation with specialized knowledge bases, medical\nconcept standardization, and SQL generation to retrieve patient cohorts with\npatient funnels. The system achieves 0.75 F1-score in cohort identification on\nEHR data, effectively capturing complex temporal and logical relationships.\nThese results demonstrate the feasibility of automated cohort generation for\nepidemiological research.\n","authors":["Angelo Ziletti","Leonardo D'Ambrosi"],"pdf_url":"https://arxiv.org/pdf/2502.21107v1.pdf","comment":"7 pages, 1 figure"},{"id":"http://arxiv.org/abs/2502.21098v1","updated":"2025-02-28T14:36:57Z","published":"2025-02-28T14:36:57Z","title":"Re-evaluating Theory of Mind evaluation in large language models","summary":"  The question of whether large language models (LLMs) possess Theory of Mind\n(ToM) -- often defined as the ability to reason about others' mental states --\nhas sparked significant scientific and public interest. However, the evidence\nas to whether LLMs possess ToM is mixed, and the recent growth in evaluations\nhas not resulted in a convergence. Here, we take inspiration from cognitive\nscience to re-evaluate the state of ToM evaluation in LLMs. We argue that a\nmajor reason for the disagreement on whether LLMs have ToM is a lack of clarity\non whether models should be expected to match human behaviors, or the\ncomputations underlying those behaviors. We also highlight ways in which\ncurrent evaluations may be deviating from \"pure\" measurements of ToM abilities,\nwhich also contributes to the confusion. We conclude by discussing several\ndirections for future research, including the relationship between ToM and\npragmatic communication, which could advance our understanding of artificial\nsystems as well as human cognition.\n","authors":["Jennifer Hu","Felix Sosa","Tomer Ullman"],"pdf_url":"https://arxiv.org/pdf/2502.21098v1.pdf","comment":"under review"},{"id":"http://arxiv.org/abs/2502.21087v1","updated":"2025-02-28T14:26:47Z","published":"2025-02-28T14:26:47Z","title":"PASemiQA: Plan-Assisted Agent for Question Answering on Semi-Structured\n  Data with Text and Relational Information","summary":"  Large language models (LLMs) have shown impressive abilities in answering\nquestions across various domains, but they often encounter hallucination issues\non questions that require professional and up-to-date knowledge. To address\nthis limitation, retrieval-augmented generation (RAG) techniques have been\nproposed, which retrieve relevant information from external sources to inform\ntheir responses. However, existing RAG methods typically focus on a single type\nof external data, such as vectorized text database or knowledge graphs, and\ncannot well handle real-world questions on semi-structured data containing both\ntext and relational information. To bridge this gap, we introduce PASemiQA, a\nnovel approach that jointly leverages text and relational information in\nsemi-structured data to answer questions. PASemiQA first generates a plan to\nidentify relevant text and relational information to answer the question in\nsemi-structured data, and then uses an LLM agent to traverse the\nsemi-structured data and extract necessary information. Our empirical results\ndemonstrate the effectiveness of PASemiQA across different semi-structured\ndatasets from various domains, showcasing its potential to improve the accuracy\nand reliability of question answering systems on semi-structured data.\n","authors":["Hansi Yang","Qi Zhang","Wei Jiang","Jianguo Li"],"pdf_url":"https://arxiv.org/pdf/2502.21087v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.18934v3","updated":"2025-02-28T14:23:16Z","published":"2025-02-26T08:36:20Z","title":"Kanana: Compute-efficient Bilingual Language Models","summary":"  We introduce Kanana, a series of bilingual language models that demonstrate\nexceeding performance in Korean and competitive performance in English. The\ncomputational cost of Kanana is significantly lower than that of\nstate-of-the-art models of similar size. The report details the techniques\nemployed during pre-training to achieve compute-efficient yet competitive\nmodels, including high quality data filtering, staged pre-training, depth\nup-scaling, and pruning and distillation. Furthermore, the report outlines the\nmethodologies utilized during the post-training of the Kanana models,\nencompassing supervised fine-tuning and preference optimization, aimed at\nenhancing their capability for seamless interaction with users. Lastly, the\nreport elaborates on plausible approaches used for language model adaptation to\nspecific scenarios, such as embedding, retrieval augmented generation, and\nfunction calling. The Kanana model series spans from 2.1B to 32.5B parameters\nwith 2.1B models (base, instruct, embedding) publicly released to promote\nresearch on Korean language models.\n","authors":[" Kanana LLM Team","Yunju Bak","Hojin Lee","Minho Ryu","Jiyeon Ham","Seungjae Jung","Daniel Wontae Nam","Taegyeong Eo","Donghun Lee","Doohae Jung","Boseop Kim","Nayeon Kim","Jaesun Park","Hyunho Kim","Hyunwoong Ko","Changmin Lee","Kyoung-Woon On","Seulye Baeg","Junrae Cho","Sunghee Jung","Jieun Kang","EungGyun Kim","Eunhwa Kim","Byeongil Ko","Daniel Lee","Minchul Lee","Miok Lee","Shinbok Lee","Gaeun Seo"],"pdf_url":"https://arxiv.org/pdf/2502.18934v3.pdf","comment":"40 pages, 15 figures"},{"id":"http://arxiv.org/abs/2502.21074v1","updated":"2025-02-28T14:07:48Z","published":"2025-02-28T14:07:48Z","title":"CODI: Compressing Chain-of-Thought into Continuous Space via\n  Self-Distillation","summary":"  Chain-of-Thought (CoT) enhances Large Language Models (LLMs) by enabling\nstep-by-step reasoning in natural language. However, the language space may be\nsuboptimal for reasoning. While implicit CoT methods attempt to enable\nreasoning without explicit CoT tokens, they have consistently lagged behind\nexplicit CoT method in task performance. We propose CODI (Continuous\nChain-of-Thought via Self-Distillation), a novel framework that distills CoT\ninto a continuous space, where a shared model acts as both teacher and student,\njointly learning explicit and implicit CoT while aligning their hidden\nactivation on the token generating the final answer. CODI is the first implicit\nCoT method to match explicit CoT's performance on GSM8k while achieving 3.1x\ncompression, surpassing the previous state-of-the-art by 28.2% in accuracy.\nFurthermore, CODI demonstrates scalability, robustness, and generalizability to\nmore complex CoT datasets. Additionally, CODI retains interpretability by\ndecoding its continuous thoughts, making its reasoning process transparent. Our\nfindings establish implicit CoT as not only a more efficient but a powerful\nalternative to explicit CoT.\n","authors":["Zhenyi Shen","Hanqi Yan","Linhai Zhang","Zhanghao Hu","Yali Du","Yulan He"],"pdf_url":"https://arxiv.org/pdf/2502.21074v1.pdf","comment":"15 pages"},{"id":"http://arxiv.org/abs/2406.11431v3","updated":"2025-02-28T13:43:17Z","published":"2024-06-17T11:36:39Z","title":"Super(ficial)-alignment: Strong Models May Deceive Weak Models in\n  Weak-to-Strong Generalization","summary":"  Superalignment, where humans act as weak supervisors for superhuman models,\nhas become a crucial problem with the rapid development of Large Language\nModels (LLMs). Recent work has preliminarily studied this problem by using weak\nmodels to supervise strong models, and discovered that weakly supervised strong\nstudents can consistently outperform weak teachers towards the alignment\ntarget, leading to a weak-to-strong generalization phenomenon. However, we are\nconcerned that behind such a promising phenomenon, whether there exists an\nissue of weak-to-strong deception, where strong models deceive weak models by\nexhibiting well-aligned in areas known to weak models but producing misaligned\nbehaviors in cases weak models do not know. We take an initial step towards\nexploring this security issue in a specific but realistic multi-objective\nalignment case, where there may be some alignment targets conflicting with each\nother (e.g., helpfulness v.s. harmlessness). We aim to explore whether, in such\ncases, strong models might deliberately make mistakes in areas known to them\nbut unknown to weak models within one alignment dimension, in exchange for a\nhigher reward in another dimension. Through extensive experiments in both the\nreward modeling and preference optimization scenarios, we find: (1) The\nweak-to-strong deception phenomenon exists across all settings. (2) The\ndeception intensifies as the capability gap between weak and strong models\nincreases. (3) Bootstrapping with an intermediate model can mitigate the\ndeception to some extent, though its effectiveness remains limited. Our work\nhighlights the urgent need to pay more attention to the true reliability of\nsuperalignment.\n","authors":["Wenkai Yang","Shiqi Shen","Guangyao Shen","Wei Yao","Yong Liu","Zhi Gong","Yankai Lin","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2406.11431v3.pdf","comment":"Accepted at ICLR 2025, camera-ready version"},{"id":"http://arxiv.org/abs/2502.15835v2","updated":"2025-02-28T13:40:42Z","published":"2025-02-20T12:44:26Z","title":"Pragmatic Reasoning improves LLM Code Generation","summary":"  Large Language Models (LLMs) have demonstrated impressive potential in\ntranslating natural language (NL) instructions into program code. However, user\ninstructions often contain inherent ambiguities, making it challenging for LLMs\nto generate code that accurately reflects the user's true intent. To address\nthis challenge, researchers have proposed to produce multiple candidates of the\nprogram code and then rerank them to identify the best solution. In this paper,\nwe propose CodeRSA, a novel code candidate reranking mechanism built upon the\nRational Speech Act (RSA) framework, designed to guide LLMs toward more\ncomprehensive pragmatic reasoning about user intent. We evaluate CodeRSA using\none of the latest LLMs on a popular code generation dataset. Our experiment\nresults show that CodeRSA consistently outperforms common baselines, surpasses\nthe state-of-the-art approach in most cases, and demonstrates robust overall\nperformance. These findings underscore the effectiveness of integrating\npragmatic reasoning into code candidate reranking, offering a promising\ndirection for enhancing code generation quality in LLMs.\n","authors":["Zhuchen Cao","Sven Apel","Adish Singla","Vera Demberg"],"pdf_url":"https://arxiv.org/pdf/2502.15835v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.09961v2","updated":"2025-02-28T13:33:00Z","published":"2024-06-14T12:10:51Z","title":"ChartMimic: Evaluating LMM's Cross-Modal Reasoning Capability via\n  Chart-to-Code Generation","summary":"  We introduce a new benchmark, ChartMimic, aimed at assessing the\nvisually-grounded code generation capabilities of large multimodal models\n(LMMs). ChartMimic utilizes information-intensive visual charts and textual\ninstructions as inputs, requiring LMMs to generate the corresponding code for\nchart rendering. ChartMimic includes 4,800 human-curated (figure, instruction,\ncode) triplets, which represent the authentic chart use cases found in\nscientific papers across various domains (e.g., Physics, Computer Science,\nEconomics, etc). These charts span 18 regular types and 4 advanced types,\ndiversifying into 201 subcategories. Furthermore, we propose multi-level\nevaluation metrics to provide an automatic and thorough assessment of the\noutput code and the rendered charts. Unlike existing code generation\nbenchmarks, ChartMimic places emphasis on evaluating LMMs' capacity to\nharmonize a blend of cognitive capabilities, encompassing visual understanding,\ncode generation, and cross-modal reasoning. The evaluation of $3$ proprietary\nmodels and 14 open-weight models highlights the substantial challenges posed by\nChartMimic. Even the advanced GPT-4o, InternVL2-Llama3-76B only achieved an\naverage score across Direct Mimic and Customized Mimic tasks of 82.2 and 61.6,\nrespectively, indicating significant room for improvement. We anticipate that\nChartMimic will inspire the development of LMMs, advancing the pursuit of\nartificial general intelligence.\n","authors":["Cheng Yang","Chufan Shi","Yaxin Liu","Bo Shui","Junjie Wang","Mohan Jing","Linran Xu","Xinyu Zhu","Siheng Li","Yuxiang Zhang","Gongye Liu","Xiaomei Nie","Deng Cai","Yujiu Yang"],"pdf_url":"https://arxiv.org/pdf/2406.09961v2.pdf","comment":"Accepted to ICLR 2025. Data and code are available at\n  https://github.com/ChartMimic/ChartMimic"},{"id":"http://arxiv.org/abs/2408.08545v3","updated":"2025-02-28T13:23:56Z","published":"2024-08-16T06:11:21Z","title":"SelectLLM: Query-Aware Efficient Selection Algorithm for Large Language\n  Models","summary":"  Large language models (LLMs) have been widely adopted due to their remarkable\nperformance across various applications, driving the accelerated development of\na large number of diverse models. However, these individual LLMs show\nlimitations in generalization and performance on complex tasks due to inherent\ntraining biases, model size constraints, and the quality or diversity of\npre-training datasets. A promising direction is to efficiently harness the\ndiverse capabilities of LLMs to overcome these individual limitations. To\naddress these limitations, we introduce a novel LLM selection algorithm called\nSelectLLM, which efficiently directs input queries to the most suitable subset\nof LLMs from a large pool, ensuring that the selected models collectively\nprovide accurate responses. SelectLLM employs a multi-label classifier and\npolicy based on the classifier's predictions and confidence scores in selecting\nan optimal, query-aware, and lightweight subset of LLMs. Our findings indicate\nthat the proposed model outperforms existing ensemble-based baselines and\nachieves competitive performance with similarly sized top-performing LLMs while\nmaintaining efficiency. Specifically, it achieves a huge reduction in inference\nlatency on two challenging reasoning benchmarks: 13% on GSM8K and 70% on MMLU,\ncompared to the top-performing baseline. Also, we establish a theoretical upper\nbound by an Oracle with LLMs and perform an in-depth linguistic analysis to\nunderstand the performance gap between the Oracle and SelectLLM.\n","authors":["Kaushal Kumar Maurya","KV Aditya Srivatsa","Ekaterina Kochmar"],"pdf_url":"https://arxiv.org/pdf/2408.08545v3.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2502.21030v1","updated":"2025-02-28T13:22:29Z","published":"2025-02-28T13:22:29Z","title":"Beyond Words: A Latent Memory Approach to Internal Reasoning in LLMs","summary":"  Recent advances in large language models (LLMs) have popularized the\nchain-of-thought (CoT) paradigm, in which models produce explicit reasoning\nsteps in natural language. Although this approach improves interpretability and\nfacilitates external auditing, it may not represent the most computationally\nefficient method for internal reasoning. In contrast, human cognition relies on\nimplicit mental representations that recall past sensory and episodic\ninformation without requiring complete verbalization. In this paper, we propose\na framework that integrates implicit mental representations into the internal\nreasoning processes of LLMs. Preliminary experiments indicate that\nincorporating an Implicit Memory Module (IMM) into a simple GPT model yields a\nreduction of between 35% and 57% in final training loss compared to a regular\nGPT baseline. The addition of an explicit interpretability channel (e.g., a\nchain-of-thought decoder) is straightforward to implement within this approach.\nWe outline theoretical foundations, propose technical mechanisms to scale the\nmemory module, and discuss how these ideas may lead to more efficient and\nrobust reasoning, with optional future extensions for explicit auditability.\n","authors":["José I. Orlicki"],"pdf_url":"https://arxiv.org/pdf/2502.21030v1.pdf","comment":"13 pages, 5 figures"},{"id":"http://arxiv.org/abs/2406.17808v3","updated":"2025-02-28T13:08:44Z","published":"2024-06-24T03:59:17Z","title":"Training-Free Exponential Context Extension via Cascading KV Cache","summary":"  The transformer's context window is vital for tasks such as few-shot learning\nand conditional generation as it preserves previous tokens for active memory.\nHowever, as the context lengths increase, the computational costs grow\nquadratically, hindering the deployment of large language models (LLMs) in\nreal-world, long sequence scenarios. Although some recent key-value caching (KV\nCache) methods offer linear inference complexity, they naively manage the\nstored context, prematurely evicting tokens and losing valuable information.\nMoreover, they lack an optimized prefill/prompt stage strategy, resulting in\nhigher latency than even quadratic attention for realistic context sizes. In\nresponse, we introduce a novel mechanism that leverages cascading sub-cache\nbuffers to selectively retain the most relevant tokens, enabling the model to\nmaintain longer context histories without increasing the cache size. Our\napproach outperforms linear caching baselines across key benchmarks, including\nstreaming perplexity, question answering, book summarization, and passkey\nretrieval, where it retains better retrieval accuracy at 1M tokens after four\ndoublings of the cache size of 65K. Additionally, our method reduces prefill\nstage latency by a factor of 6.8 when compared to flash attention on 1M tokens.\nThese innovations not only enhance the computational efficiency of LLMs but\nalso pave the way for their effective deployment in resource-constrained\nenvironments, enabling large-scale, real-time applications with significantly\nreduced latency.\n","authors":["Jeffrey Willette","Heejun Lee","Youngwan Lee","Myeongjae Jeon","Sung Ju Hwang"],"pdf_url":"https://arxiv.org/pdf/2406.17808v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21024v1","updated":"2025-02-28T13:06:25Z","published":"2025-02-28T13:06:25Z","title":"Extending Dense Passage Retrieval with Temporal Information","summary":"  Temporal awareness is crucial in many information retrieval tasks,\nparticularly in scenarios where the relevance of documents depends on their\nalignment with the query's temporal context. Traditional retrieval methods such\nas BM25 and Dense Passage Retrieval (DPR) excel at capturing lexical and\nsemantic relevance but fall short in addressing time-sensitive queries. To\nbridge this gap, we introduce the temporal retrieval model that integrates\nexplicit temporal signals by incorporating query timestamps and document dates\ninto the representation space. Our approach ensures that retrieved passages are\nnot only topically relevant but also temporally aligned with user intent. We\nevaluate our approach on two large-scale benchmark datasets, ArchivalQA and\nChroniclingAmericaQA, achieving substantial performance gains over standard\nretrieval baselines. In particular, our model improves Top-1 retrieval accuracy\nby 6.63% and NDCG@10 by 3.79% on ArchivalQA, while yielding a 9.56% boost in\nTop-1 retrieval accuracy and 4.68% in NDCG@10 on ChroniclingAmericaQA.\nAdditionally, we introduce a time-sensitive negative sampling strategy, which\nrefines the model's ability to distinguish between temporally relevant and\nirrelevant documents during training. Our findings highlight the importance of\nexplicitly modeling time in retrieval systems and set a new standard for\nhandling temporally grounded queries.\n","authors":["Abdelrahman Abdallah","Bhawna Piryani","Jonas Wallat","Avishek Anand","Adam Jatowt"],"pdf_url":"https://arxiv.org/pdf/2502.21024v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.20372v2","updated":"2025-02-28T13:06:02Z","published":"2024-12-29T06:32:36Z","title":"LLM2: Let Large Language Models Harness System 2 Reasoning","summary":"  Large language models (LLMs) have exhibited impressive capabilities across a\nmyriad of tasks, yet they occasionally yield undesirable outputs. We posit that\nthese limitations are rooted in the foundational autoregressive architecture of\nLLMs, which inherently lacks mechanisms for differentiating between desirable\nand undesirable results. Drawing inspiration from the dual-process theory of\nhuman cognition, we introduce LLM2, a novel framework that combines an LLM\n(System 1) with a process-based verifier (System 2). Within LLM2, the LLM is\nresponsible for generating plausible candidates, while the verifier provides\ntimely process-based feedback to distinguish desirable and undesirable outputs.\nThe verifier is trained with a pairwise comparison loss on synthetic\nprocess-supervision data generated through our token quality exploration\nstrategy. Empirical results on mathematical reasoning benchmarks substantiate\nthe efficacy of LLM2, exemplified by an accuracy enhancement from 50.3 to 57.8\n(+7.5) for Llama3-1B on GSM8K. Furthermore, when combined with\nself-consistency, LLM2 achieves additional improvements, boosting major@20\naccuracy from 56.2 to 70.2 (+14.0).\n","authors":["Cheng Yang","Chufan Shi","Siheng Li","Bo Shui","Yujiu Yang","Wai Lam"],"pdf_url":"https://arxiv.org/pdf/2412.20372v2.pdf","comment":"Accepted to NAACL 2025 Main Conference"},{"id":"http://arxiv.org/abs/2502.21017v1","updated":"2025-02-28T13:04:04Z","published":"2025-02-28T13:04:04Z","title":"PersuasiveToM: A Benchmark for Evaluating Machine Theory of Mind in\n  Persuasive Dialogues","summary":"  The ability to understand and predict the mental states of oneself and\nothers, known as the Theory of Mind (ToM), is crucial for effective social\ninteractions. Recent research has emerged to evaluate whether Large Language\nModels (LLMs) exhibit a form of ToM. Although recent studies have evaluated ToM\nin LLMs, existing benchmarks focus predominantly on physical perception with\nprinciples guided by the Sally-Anne test in synthetic stories and\nconversations, failing to capture the complex psychological activities of\nmental states in real-life social interactions. To mitigate this gap, we\npropose PersuasiveToM, a benchmark designed to evaluate the ToM abilities of\nLLMs in persuasive dialogues. Our framework introduces two categories of\nquestions: (1) ToM Reasoning, assessing the capacity of LLMs to track evolving\nmental states (e.g., desire shifts in persuadees), and (2) ToM Application,\nevaluating whether LLMs can take advantage of inferred mental states to select\neffective persuasion strategies (e.g., emphasize rarity) and evaluate the\neffectiveness of persuasion strategies. Experiments across eight\nstate-of-the-art LLMs reveal that while models excel on multiple questions,\nthey struggle to answer questions that need tracking the dynamics and shifts of\nmental states and understanding the mental states in the whole dialogue\ncomprehensively. Our aim with PersuasiveToM is to allow an effective evaluation\nof the ToM reasoning ability of LLMs with more focus on complex psychological\nactivities. Our code is available at\nhttps://github.com/Yu-Fangxu/PersuasiveToM.\n","authors":["Fangxu Yu","Lai Jiang","Shenyi Huang","Zhen Wu","Xinyu Dai"],"pdf_url":"https://arxiv.org/pdf/2502.21017v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.19883v2","updated":"2025-02-28T12:59:26Z","published":"2025-02-27T08:44:04Z","title":"Behind the Tip of Efficiency: Uncovering the Submerged Threats of\n  Jailbreak Attacks in Small Language Models","summary":"  Small language models (SLMs) have become increasingly prominent in the\ndeployment on edge devices due to their high efficiency and low computational\ncost. While researchers continue to advance the capabilities of SLMs through\ninnovative training strategies and model compression techniques, the security\nrisks of SLMs have received considerably less attention compared to large\nlanguage models (LLMs).To fill this gap, we provide a comprehensive empirical\nstudy to evaluate the security performance of 13 state-of-the-art SLMs under\nvarious jailbreak attacks. Our experiments demonstrate that most SLMs are quite\nsusceptible to existing jailbreak attacks, while some of them are even\nvulnerable to direct harmful prompts.To address the safety concerns, we\nevaluate several representative defense methods and demonstrate their\neffectiveness in enhancing the security of SLMs. We further analyze the\npotential security degradation caused by different SLM techniques including\narchitecture compression, quantization, knowledge distillation, and so on. We\nexpect that our research can highlight the security challenges of SLMs and\nprovide valuable insights to future work in developing more robust and secure\nSLMs.\n","authors":["Sibo Yi","Tianshuo Cong","Xinlei He","Qi Li","Jiaxing Song"],"pdf_url":"https://arxiv.org/pdf/2502.19883v2.pdf","comment":"12 pages. 6 figures"},{"id":"http://arxiv.org/abs/2410.14668v4","updated":"2025-02-28T12:57:03Z","published":"2024-10-18T17:57:40Z","title":"MiCEval: Unveiling Multimodal Chain of Thought's Quality via Image\n  Description and Reasoning Steps","summary":"  Multimodal Chain of Thought (MCoT) is a popular prompting strategy for\nimproving the performance of multimodal large language models (MLLMs) across a\nrange of complex reasoning tasks. Despite its popularity, there is a notable\nabsence of automated methods for evaluating the quality of reasoning steps in\nMCoT. To address this gap, we propose Multimodal Chain-of-Thought Evaluation\n(MiCEval), a framework designed to assess the correctness of reasoning chains\nby evaluating the quality of both the description and each reasoning step. The\nevaluation of the description component focuses on the accuracy of the image\ndescriptions, while the reasoning step evaluates the quality of each step as it\nis conditionally generated based on the preceding steps. MiCEval is built upon\na fine-grained dataset with annotations that rate each step according to\ncorrectness, relevance, and informativeness. Extensive experiments on four\nstate-of-the-art MLLMs show that step-wise evaluations using MiCEval align more\nclosely with human judgments compared to existing methods based on cosine\nsimilarity or fine-tuning approaches. MiCEval datasets and code can be found in\nhttps://github.com/alenai97/MiCEval.\n","authors":["Xiongtao Zhou","Jie He","Lanyu Chen","Jingyu Li","Haojing Chen","Víctor Gutiérrez-Basulto","Jeff Z. Pan","Hanjie Chen"],"pdf_url":"https://arxiv.org/pdf/2410.14668v4.pdf","comment":"NAACL 2025"},{"id":"http://arxiv.org/abs/2402.17812v4","updated":"2025-02-28T12:53:34Z","published":"2024-02-27T14:51:11Z","title":"DropBP: Accelerating Fine-Tuning of Large Language Models by Dropping\n  Backward Propagation","summary":"  Large language models (LLMs) have achieved significant success across various\ndomains. However, training these LLMs typically involves substantial memory and\ncomputational costs during both forward and backward propagation. While\nparameter-efficient fine-tuning (PEFT) considerably reduces the training memory\nassociated with parameters, it does not address the significant computational\ncosts and activation memory. In this paper, we propose Dropping Backward\nPropagation (DropBP), a novel approach designed to reduce computational costs\nand activation memory while maintaining accuracy. DropBP randomly drops layers\nduring backward propagation, which is essentially equivalent to training\nshallow submodules generated by undropped layers and residual connections.\nAdditionally, DropBP calculates the sensitivity of each layer to assign an\nappropriate drop rate, thereby stabilizing the training process. DropBP is not\nonly applicable to full fine-tuning but can also be orthogonally integrated\nwith all types of PEFT by dropping layers during backward propagation.\nSpecifically, DropBP can reduce training time by 44% with comparable accuracy\nto the baseline, accelerate convergence to the same perplexity by 1.5x, and\nenable training with a sequence length 6.2x larger on a single NVIDIA-A100 GPU.\nFurthermore, our DropBP enabled a throughput increase of 79% on a NVIDIA A100\nGPU and 117% on an Intel Gaudi2 HPU. The code is available at\nhttps://github.com/WooSunghyeon/dropbp.\n","authors":["Sunghyeon Woo","Baeseong Park","Byeongwook Kim","Minjung Jo","Se Jung Kwon","Dongsuk Jeon","Dongsoo Lee"],"pdf_url":"https://arxiv.org/pdf/2402.17812v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.19839v5","updated":"2025-02-28T12:35:34Z","published":"2024-09-30T00:41:51Z","title":"ForecastBench: A Dynamic Benchmark of AI Forecasting Capabilities","summary":"  Forecasts of future events are essential inputs into informed\ndecision-making. Machine learning (ML) systems have the potential to deliver\nforecasts at scale, but there is no framework for evaluating the accuracy of ML\nsystems on a standardized set of forecasting questions. To address this gap, we\nintroduce ForecastBench: a dynamic benchmark that evaluates the accuracy of ML\nsystems on an automatically generated and regularly updated set of 1,000\nforecasting questions. To avoid any possibility of data leakage, ForecastBench\nis comprised solely of questions about future events that have no known answer\nat the time of submission. We quantify the capabilities of current ML systems\nby collecting forecasts from expert (human) forecasters, the general public,\nand LLMs on a random subset of questions from the benchmark ($N=200$). While\nLLMs have achieved super-human performance on many benchmarks, they perform\nless well here: expert forecasters outperform the top-performing LLM ($p$-value\n$<0.001$). We display system and human scores in a public leaderboard at\nwww.forecastbench.org.\n","authors":["Ezra Karger","Houtan Bastani","Chen Yueh-Han","Zachary Jacobs","Danny Halawi","Fred Zhang","Philip E. Tetlock"],"pdf_url":"https://arxiv.org/pdf/2409.19839v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20992v1","updated":"2025-02-28T12:22:13Z","published":"2025-02-28T12:22:13Z","title":"Capability Localization: Capabilities Can be Localized rather than\n  Individual Knowledge","summary":"  Large scale language models have achieved superior performance in tasks\nrelated to natural language processing, however, it is still unclear how model\nparameters affect performance improvement. Previous studies assumed that\nindividual knowledge is stored in local parameters, and the storage form of\nindividual knowledge is dispersed parameters, parameter layers, or parameter\nchains, which are not unified. We found through fidelity and reliability\nevaluation experiments that individual knowledge cannot be localized.\nAfterwards, we constructed a dataset for decoupling experiments and discovered\nthe potential for localizing data commonalities. To further reveal this\nphenomenon, this paper proposes a Commonality Neuron Localization (CNL) method,\nwhich successfully locates commonality neurons and achieves a neuron overlap\nrate of 96.42% on the GSM8K dataset. Finally, we have demonstrated through\ncross data experiments that commonality neurons are a collection of capability\nneurons that possess the capability to enhance performance. Our code is\navailable at https://github.com/nlpkeg/Capability-Neuron-Localization.\n","authors":["Xiusheng Huang","Jiaxiang Liu","Yequan Wang","Jun Zhao","Kang Liu"],"pdf_url":"https://arxiv.org/pdf/2502.20992v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20988v1","updated":"2025-02-28T12:00:51Z","published":"2025-02-28T12:00:51Z","title":"Merging Clinical Knowledge into Large Language Models for Medical\n  Research and Applications: A Survey","summary":"  Clinical knowledge is the collection of information learned from studies on\nthe causes, prognosis, diagnosis, and treatment of diseases. This type of\nknowledge can improve curing performances, and promote physical health. With\nthe emergence of large language models (LLMs), medical artificial intelligence\n(medical AI), which aims to apply academic medical AI systems to real-world\nmedical scenarios, has entered a new age of development, resulting in excellent\nworks such as DoctorGPT and Pangu-Drug from academic and industrial researches.\nHowever, the field lacks a comprehensive compendium and comparison of building\nmedical AI systems from academia and industry. Therefore, this survey focuses\non the building paradigms of medical AI systems including the use of clinical\ndatabases, datasets, training pipelines, integrating medical knowledge graphs,\nsystem applications, and evaluation systems. We hope that this survey can help\nrelevant practical researchers understand the current performance of academic\nmodels in various fields of healthcare, as well as the potential problems and\nfuture directions for implementing these scientific achievements.\n","authors":["Qiyuan Li","Haijiang Liu","Caicai Guo","Deyu Chen","Meng Wang","Feng Gao","Jinguang Gu"],"pdf_url":"https://arxiv.org/pdf/2502.20988v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06655v2","updated":"2025-02-28T11:58:28Z","published":"2024-11-11T01:42:56Z","title":"Explore the Reasoning Capability of LLMs in the Chess Testbed","summary":"  Reasoning is a central capability of human intelligence. In recent years,\nwith the advent of large-scale datasets, pretrained large language models have\nemerged with new capabilities, including reasoning. However, these models still\nstruggle with long-term, complex reasoning tasks, such as playing chess. Based\non the observation that expert chess players employ a dual approach combining\nlong-term strategic play with short-term tactical play along with language\nexplanation, we propose improving the reasoning capability of large language\nmodels in chess by integrating annotated strategy and tactic. Specifically, we\ncollect a dataset named MATE, which consists of 1 million chess positions with\ncandidate moves annotated by chess experts for strategy and tactics. We\nfinetune the LLaMA-3-8B model and compare it against state-of-the-art\ncommercial language models in the task of selecting better chess moves. Our\nexperiments show that our models perform better than GPT, Claude, and Gemini\nmodels. We find that language explanations can enhance the reasoning capability\nof large language models.\n","authors":["Shu Wang","Lei Ji","Renxi Wang","Wenxiao Zhao","Haokun Liu","Yifan Hou","Ying Nian Wu"],"pdf_url":"https://arxiv.org/pdf/2411.06655v2.pdf","comment":"NAACL2025 Main Conference. Data and models are available:\n  https://mate-chess.github.io/"},{"id":"http://arxiv.org/abs/2502.20984v1","updated":"2025-02-28T11:52:02Z","published":"2025-02-28T11:52:02Z","title":"UoR-NCL at SemEval-2025 Task 1: Using Generative LLMs and CLIP Models\n  for Multilingual Multimodal Idiomaticity Representation","summary":"  SemEval-2025 Task 1 focuses on ranking images based on their alignment with a\ngiven nominal compound that may carry idiomatic meaning in both English and\nBrazilian Portuguese. To address this challenge, this work uses generative\nlarge language models (LLMs) and multilingual CLIP models to enhance idiomatic\ncompound representations. LLMs generate idiomatic meanings for potentially\nidiomatic compounds, enriching their semantic interpretation. These meanings\nare then encoded using multilingual CLIP models, serving as representations for\nimage ranking. Contrastive learning and data augmentation techniques are\napplied to fine-tune these embeddings for improved performance. Experimental\nresults show that multimodal representations extracted through this method\noutperformed those based solely on the original nominal compounds. The\nfine-tuning approach shows promising outcomes but is less effective than using\nembeddings without fine-tuning. The source code used in this paper is available\nat https://github.com/tongwu17/SemEval-2025-Task1-UoR-NCL.\n","authors":["Thanet Markchom","Tong Wu","Liting Huang","Huizhi Liang"],"pdf_url":"https://arxiv.org/pdf/2502.20984v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20975v1","updated":"2025-02-28T11:40:34Z","published":"2025-02-28T11:40:34Z","title":"Set-Theoretic Compositionality of Sentence Embeddings","summary":"  Sentence encoders play a pivotal role in various NLP tasks; hence, an\naccurate evaluation of their compositional properties is paramount. However,\nexisting evaluation methods predominantly focus on goal task-specific\nperformance. This leaves a significant gap in understanding how well sentence\nembeddings demonstrate fundamental compositional properties in a\ntask-independent context. Leveraging classical set theory, we address this gap\nby proposing six criteria based on three core \"set-like\"\ncompositions/operations: \\textit{TextOverlap}, \\textit{TextDifference}, and\n\\textit{TextUnion}. We systematically evaluate $7$ classical and $9$ Large\nLanguage Model (LLM)-based sentence encoders to assess their alignment with\nthese criteria. Our findings show that SBERT consistently demonstrates set-like\ncompositional properties, surpassing even the latest LLMs. Additionally, we\nintroduce a new dataset of ~$192$K samples designed to facilitate future\nbenchmarking efforts on set-like compositionality of sentence embeddings.\n","authors":["Naman Bansal","Yash mahajan","Sanjeev Sinha","Santu Karmaker"],"pdf_url":"https://arxiv.org/pdf/2502.20975v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.08248v2","updated":"2025-02-28T11:40:20Z","published":"2025-01-14T16:38:33Z","title":"Eliciting In-context Retrieval and Reasoning for Long-context Large\n  Language Models","summary":"  Recent advancements in long-context language models (LCLMs) promise to\ntransform Retrieval-Augmented Generation (RAG) by simplifying pipelines. With\ntheir expanded context windows, LCLMs can process entire knowledge bases and\nperform retrieval and reasoning directly -- a capability we define as\nIn-Context Retrieval and Reasoning (ICR^2). However, existing benchmarks like\nLOFT often overestimate LCLM performance by providing overly simplified\ncontexts. To address this, we introduce ICR^2, a benchmark that evaluates LCLMs\nin more realistic scenarios by including confounding passages retrieved with\nstrong retrievers. We then propose three methods to enhance LCLM performance:\n(1) retrieve-then-generate fine-tuning, (2) retrieval-attention-probing, which\nuses attention heads to filter and de-noise long contexts during decoding, and\n(3) joint retrieval head training alongside the generation head. Our evaluation\nof five well-known LCLMs on LOFT and ICR^2 demonstrates significant gains with\nour best approach applied to Mistral-7B: +17 and +15 points by Exact Match on\nLOFT, and +13 and +2 points on ICR^2, compared to vanilla RAG and supervised\nfine-tuning, respectively. It even outperforms GPT-4-Turbo on most tasks\ndespite being a much smaller model.\n","authors":["Yifu Qiu","Varun Embar","Yizhe Zhang","Navdeep Jaitly","Shay B. Cohen","Benjamin Han"],"pdf_url":"https://arxiv.org/pdf/2501.08248v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20973v1","updated":"2025-02-28T11:37:52Z","published":"2025-02-28T11:37:52Z","title":"Arabizi vs LLMs: Can the Genie Understand the Language of Aladdin?","summary":"  In this era of rapid technological advancements, communication continues to\nevolve as new linguistic phenomena emerge. Among these is Arabizi, a hybrid\nform of Arabic that incorporates Latin characters and numbers to represent the\nspoken dialects of Arab communities. Arabizi is widely used on social media and\nallows people to communicate in an informal and dynamic way, but it poses\nsignificant challenges for machine translation due to its lack of formal\nstructure and deeply embedded cultural nuances. This case study arises from a\ngrowing need to translate Arabizi for gisting purposes. It evaluates the\ncapacity of different LLMs to decode and translate Arabizi, focusing on\nmultiple Arabic dialects that have rarely been studied up until now. Using a\ncombination of human evaluators and automatic metrics, this research project\ninvestigates the model's performance in translating Arabizi into both Modern\nStandard Arabic and English. Key questions explored include which dialects are\ntranslated most effectively and whether translations into English surpass those\ninto Arabic.\n","authors":["Perla Al Almaoui","Pierrette Bouillon","Simon Hengchen"],"pdf_url":"https://arxiv.org/pdf/2502.20973v1.pdf","comment":"Submitted to MT Summit 2025"},{"id":"http://arxiv.org/abs/2406.10288v3","updated":"2025-02-28T11:36:06Z","published":"2024-06-12T18:33:11Z","title":"Do as I do (Safely): Mitigating Task-Specific Fine-tuning Risks in Large\n  Language Models","summary":"  Recent research shows that fine-tuning on benign instruction-following data\ncan inadvertently undo the safety alignment process and increase a model's\npropensity to comply with harmful queries. While instruction-following\nfine-tuning is important, task-specific fine-tuning - where models are trained\non datasets with clear ground truth answers (e.g., multiple choice questions) -\ncan enhance model performance on specialized downstream tasks. Understanding\nand mitigating safety risks in the task-specific setting remains distinct from\nthe instruction-following context due to structural differences in the data.\nOur work demonstrates how malicious actors can subtly manipulate the structure\nof almost any task-specific dataset to foster significantly more dangerous\nmodel behaviors, while maintaining an appearance of innocuity and reasonable\ndownstream task performance. To address this issue, we propose a novel\nmitigation strategy that mixes in safety data which mimics the task format and\nprompting style of the user data, showing this is significantly more effective\nand efficient than existing baselines at re-establishing safety alignment while\nmaintaining similar task performance.\n","authors":["Francisco Eiras","Aleksandar Petrov","Philip H. S. Torr","M. Pawan Kumar","Adel Bibi"],"pdf_url":"https://arxiv.org/pdf/2406.10288v3.pdf","comment":"Accepted to ICLR'25"},{"id":"http://arxiv.org/abs/2502.20968v1","updated":"2025-02-28T11:31:27Z","published":"2025-02-28T11:31:27Z","title":"Beware of Your Po! Measuring and Mitigating AI Safety Risks in Role-Play\n  Fine-Tuning of LLMs","summary":"  Role-playing enables large language models (LLMs) to engage users in\nimmersive and personalized interactions, but it also introduces significant\nsafety risks. Existing role-play fine-tuning techniques improve role\nadaptability but may degrade safety performance, particularly for villainous\ncharacters. In this work, we conduct the first comprehensive assessment of\nrole-play fine-tuning risks by training 95 role-specific LLMs using RoleBench.\nOur experiments reveal that role-play fine-tuning leads to a noticeable decline\nin safety performance, with safety risks varying based on character traits. To\ntackle this challenge, we propose Safety-Aware Role-Play Fine-Tuning (SaRFT), a\nnovel method designed to balance role-playing capabilities and safety.\nExtensive experiments on LLaMA-3-8B-Instruct, Gemma-2-9B-it, and\nQwen2.5-7B-Instruct demonstrate that SaRFT consistently outperforms\nstate-of-the-art baselines under both LoRA and full-parameter fine-tuning\nsettings. Our findings highlight the necessity of role-adaptive safety measures\nand provide insights into mitigating role-specific safety risks in role-playing\nLLMs.\n","authors":["Weixiang Zhao","Yulin Hu","Yang Deng","Jiahe Guo","Xingyu Sui","Xinyang Han","An Zhang","Yanyan Zhao","Bing Qin","Tat-Seng Chua","Ting Liu"],"pdf_url":"https://arxiv.org/pdf/2502.20968v1.pdf","comment":"25 pages, 10 figures, 13 tables"},{"id":"http://arxiv.org/abs/2502.20936v1","updated":"2025-02-28T10:46:52Z","published":"2025-02-28T10:46:52Z","title":"WebFAQ: A Multilingual Collection of Natural Q&A Datasets for Dense\n  Retrieval","summary":"  We present WebFAQ, a large-scale collection of open-domain question answering\ndatasets derived from FAQ-style schema.org annotations. In total, the data\ncollection consists of 96 million natural question-answer (QA) pairs across 75\nlanguages, including 47 million (49%) non-English samples. WebFAQ further\nserves as the foundation for 20 monolingual retrieval benchmarks with a total\nsize of 11.2 million QA pairs (5.9 million non-English). These datasets are\ncarefully curated through refined filtering and near-duplicate detection,\nyielding high-quality resources for training and evaluating multilingual dense\nretrieval models. To empirically confirm WebFAQ's efficacy, we use the\ncollected QAs to fine-tune an in-domain pretrained XLM-RoBERTa model. Through\nthis process of dataset-specific fine-tuning, the model achieves significant\nretrieval performance gains, which generalize - beyond WebFAQ - to other\nmultilingual retrieval benchmarks evaluated in zero-shot setting. Last but not\nleast, we utilize WebFAQ to construct a set of QA-aligned bilingual corpora\nspanning over 1000 language pairs using state-of-the-art bitext mining and\nautomated LLM-assessed translation evaluation. Due to our advanced, automated\nmethod of bitext dataset generation, the resulting bilingual corpora\ndemonstrate higher translation quality compared to similar datasets. WebFAQ and\nall associated resources are publicly available on GitHub and HuggingFace.\n","authors":["Michael Dinzinger","Laura Caspari","Kanishka Ghosh Dastidar","Jelena Mitrović","Michael Granitzer"],"pdf_url":"https://arxiv.org/pdf/2502.20936v1.pdf","comment":"10 pages, 3 figures, 7 tables"},{"id":"http://arxiv.org/abs/2502.20931v1","updated":"2025-02-28T10:39:07Z","published":"2025-02-28T10:39:07Z","title":"Automated Evaluation of Meter and Rhyme in Russian Generative and\n  Human-Authored Poetry","summary":"  Generative poetry systems require effective tools for data engineering and\nautomatic evaluation, particularly to assess how well a poem adheres to\nversification rules, such as the correct alternation of stressed and unstressed\nsyllables and the presence of rhymes.\n  In this work, we introduce the Russian Poetry Scansion Tool library designed\nfor stress mark placement in Russian-language syllabo-tonic poetry, rhyme\ndetection, and identification of defects of poeticness. Additionally, we\nrelease RIFMA -- a dataset of poem fragments spanning various genres and forms,\nannotated with stress marks. This dataset can be used to evaluate the\ncapability of modern large language models to accurately place stress marks in\npoetic texts.\n  The published resources provide valuable tools for researchers and\npractitioners in the field of creative generative AI, facilitating advancements\nin the development and evaluation of generative poetry systems.\n","authors":["Ilya Koziev"],"pdf_url":"https://arxiv.org/pdf/2502.20931v1.pdf","comment":"7 pages, 1 figure"},{"id":"http://arxiv.org/abs/2409.07170v2","updated":"2025-02-28T10:22:04Z","published":"2024-09-11T10:33:30Z","title":"Learning Efficient Recursive Numeral Systems via Reinforcement Learning","summary":"  It has previously been shown that by using reinforcement learning (RL),\nagents can derive simple approximate and exact-restricted numeral systems that\nare similar to human ones (Carlsson, 2021). However, it is a major challenge to\nshow how more complex recursive numeral systems, similar to for example\nEnglish, could arise via a simple learning mechanism such as RL. Here, we\nintroduce an approach towards deriving a mechanistic explanation of the\nemergence of efficient recursive number systems. We consider pairs of agents\nlearning how to communicate about numerical quantities through a meta-grammar\nthat can be gradually modified throughout the interactions. %We find that the\nseminal meta-grammar of Hurford (Hurford, 1975) is not suitable for this\napplication as its optimization results in systems that deviate from standard\nconventions observed within human numeral systems. We propose a simple\nmodification which addresses this issue. Utilising a slightly modified version\nof the meta-grammar of Hurford, we demonstrate that our RL agents, shaped by\nthe pressures for efficient communication, can effectively modify their lexicon\ntowards Pareto-optimal configurations which are comparable to those observed\nwithin human numeral systems in terms of their efficiency.\n","authors":["Andrea Silvi","Jonathan Thomas","Emil Carlsson","Devdatt Dubhashi","Moa Johansson"],"pdf_url":"https://arxiv.org/pdf/2409.07170v2.pdf","comment":"8 pages, 5 figures"},{"id":"http://arxiv.org/abs/2502.20914v1","updated":"2025-02-28T10:13:54Z","published":"2025-02-28T10:13:54Z","title":"Everything, Everywhere, All at Once: Is Mechanistic Interpretability\n  Identifiable?","summary":"  As AI systems are used in high-stakes applications, ensuring interpretability\nis crucial. Mechanistic Interpretability (MI) aims to reverse-engineer neural\nnetworks by extracting human-understandable algorithms to explain their\nbehavior. This work examines a key question: for a given behavior, and under\nMI's criteria, does a unique explanation exist? Drawing on identifiability in\nstatistics, where parameters are uniquely inferred under specific assumptions,\nwe explore the identifiability of MI explanations.\n  We identify two main MI strategies: (1) \"where-then-what,\" which isolates a\ncircuit replicating model behavior before interpreting it, and (2)\n\"what-then-where,\" which starts with candidate algorithms and searches for\nneural activation subspaces implementing them, using causal alignment.\n  We test both strategies on Boolean functions and small multi-layer\nperceptrons, fully enumerating candidate explanations. Our experiments reveal\nsystematic non-identifiability: multiple circuits can replicate behavior, a\ncircuit can have multiple interpretations, several algorithms can align with\nthe network, and one algorithm can align with different subspaces.\n  Is uniqueness necessary? A pragmatic approach may require only predictive and\nmanipulability standards. If uniqueness is essential for understanding,\nstricter criteria may be needed. We also reference the inner interpretability\nframework, which validates explanations through multiple criteria. This work\ncontributes to defining explanation standards in AI.\n","authors":["Maxime Méloux","Silviu Maniu","François Portet","Maxime Peyrard"],"pdf_url":"https://arxiv.org/pdf/2502.20914v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20898v1","updated":"2025-02-28T09:54:13Z","published":"2025-02-28T09:54:13Z","title":"A database to support the evaluation of gender biases in GPT-4o output","summary":"  The widespread application of Large Language Models (LLMs) involves ethical\nrisks for users and societies. A prominent ethical risk of LLMs is the\ngeneration of unfair language output that reinforces or exacerbates harm for\nmembers of disadvantaged social groups through gender biases (Weidinger et al.,\n2022; Bender et al., 2021; Kotek et al., 2023). Hence, the evaluation of the\nfairness of LLM outputs with respect to such biases is a topic of rising\ninterest. To advance research in this field, promote discourse on suitable\nnormative bases and evaluation methodologies, and enhance the reproducibility\nof related studies, we propose a novel approach to database construction. This\napproach enables the assessment of gender-related biases in LLM-generated\nlanguage beyond merely evaluating their degree of neutralization.\n","authors":["Luise Mehner","Lena Alicija Philine Fiedler","Sabine Ammon","Dorothea Kolossa"],"pdf_url":"https://arxiv.org/pdf/2502.20898v1.pdf","comment":"ISCA/ITG Workshop on Diversity in Large Speech and Language Models"},{"id":"http://arxiv.org/abs/2502.20897v1","updated":"2025-02-28T09:53:42Z","published":"2025-02-28T09:53:42Z","title":"Beyond Demographics: Fine-tuning Large Language Models to Predict\n  Individuals' Subjective Text Perceptions","summary":"  People naturally vary in their annotations for subjective questions and some\nof this variation is thought to be due to the person's sociodemographic\ncharacteristics. LLMs have also been used to label data, but recent work has\nshown that models perform poorly when prompted with sociodemographic\nattributes, suggesting limited inherent sociodemographic knowledge. Here, we\nask whether LLMs can be trained to be accurate sociodemographic models of\nannotator variation. Using a curated dataset of five tasks with standardized\nsociodemographics, we show that models do improve in sociodemographic prompting\nwhen trained but that this performance gain is largely due to models learning\nannotator-specific behaviour rather than sociodemographic patterns. Across all\ntasks, our results suggest that models learn little meaningful connection\nbetween sociodemographics and annotation, raising doubts about the current use\nof LLMs for simulating sociodemographic variation and behaviour.\n","authors":["Matthias Orlikowski","Jiaxin Pei","Paul Röttger","Philipp Cimiano","David Jurgens","Dirk Hovy"],"pdf_url":"https://arxiv.org/pdf/2502.20897v1.pdf","comment":"Reviewed ARR December 2024"},{"id":"http://arxiv.org/abs/2502.19941v2","updated":"2025-02-28T09:51:26Z","published":"2025-02-27T10:11:53Z","title":"Alleviating Distribution Shift in Synthetic Data for Machine Translation\n  Quality Estimation","summary":"  Quality Estimation (QE) models evaluate the quality of machine translations\nwithout reference translations, serving as the reward models for the\ntranslation task. Due to the data scarcity, synthetic data generation has\nemerged as a promising solution. However, synthetic QE data often suffers from\ndistribution shift, which can manifest as discrepancies between pseudo and real\ntranslations, or in pseudo labels that do not align with human preferences. To\ntackle this issue, we introduce ADSQE, a novel framework for alleviating\ndistribution shift in synthetic QE data. To reduce the difference between\npseudo and real translations, we employ the constrained beam search algorithm\nand enhance translation diversity through the use of distinct generation\nmodels. ADSQE uses references, i.e., translation supervision signals, to guide\nboth the generation and annotation processes, enhancing the quality of\nword-level labels. ADSE further identifies the shortest phrase covering\nconsecutive error tokens, mimicking human annotation behavior, to assign the\nfinal phrase-level labels. Specially, we underscore that the translation model\ncan not annotate translations of itself accurately. Extensive experiments\ndemonstrate that ADSQE outperforms SOTA baselines like COMET in both supervised\nand unsupervised settings. Further analysis offers insights into synthetic data\ngeneration that could benefit reward models for other tasks.\n","authors":["Xiang Geng","Zhejian Lai","Jiajun Chen","Hao Yang","Shujian Huang"],"pdf_url":"https://arxiv.org/pdf/2502.19941v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.01570v3","updated":"2025-02-28T09:23:04Z","published":"2024-03-03T17:35:52Z","title":"Small Models are LLM Knowledge Triggers on Medical Tabular Prediction","summary":"  Recent development in large language models (LLMs) has demonstrated\nimpressive domain proficiency on unstructured textual or multi-modal tasks.\nHowever, despite with intrinsic world knowledge, their application on\nstructured tabular data prediction still lags behind, primarily due to the\nnumerical insensitivity and modality discrepancy that brings a gap between LLM\nreasoning and statistical tabular learning. Unlike textual or vision data\n(e.g., electronic clinical notes or medical imaging data), tabular data is\noften presented in heterogeneous numerical values (e.g., CBC reports). This\nubiquitous data format requires intensive expert annotation, and its numerical\nnature limits LLMs' capability to effectively transfer untapped domain\nexpertise. In this paper, we propose SERSAL, a general self-prompting method by\nsynergy learning with small models to enhance LLM tabular prediction in an\nunsupervised manner. Specifically, SERSAL utilizes the LLM's prior outcomes as\noriginal soft noisy annotations, which are dynamically leveraged to teach a\nbetter small student model. Reversely, the outcomes from the trained small\nmodel are used to teach the LLM to further refine its real capability. This\nprocess can be repeatedly applied to gradually distill refined knowledge for\ncontinuous progress. Comprehensive experiments on widely used medical domain\ntabular datasets show that, without access to gold labels, applying SERSAL to\nOpenAI GPT reasoning process attains substantial improvement compared to\nlinguistic prompting methods, which serves as an orthogonal direction for\ntabular LLM, and increasing prompting bonus is observed as more powerful LLMs\nappear.\n","authors":["Jiahuan Yan","Jintai Chen","Chaowen Hu","Bo Zheng","Yaojun Hu","Jimeng Sun","Jian Wu"],"pdf_url":"https://arxiv.org/pdf/2403.01570v3.pdf","comment":"Accepted to ICLR 2025. Codes will be available at\n  https://github.com/jyansir/sersal"},{"id":"http://arxiv.org/abs/2411.12537v3","updated":"2025-02-28T09:17:14Z","published":"2024-11-19T14:35:38Z","title":"Unlocking State-Tracking in Linear RNNs Through Negative Eigenvalues","summary":"  Linear Recurrent Neural Networks (LRNNs) such as Mamba, RWKV, GLA, mLSTM, and\nDeltaNet have emerged as efficient alternatives to Transformers for long\nsequences. However, both Transformers and LRNNs struggle to perform\nstate-tracking, which may impair performance in tasks such as code evaluation.\nIn one forward pass, current architectures are unable to solve even parity, the\nsimplest state-tracking task, which non-linear RNNs can handle effectively.\nRecently, Sarrof et al. (2024) demonstrated that the failure of LRNNs like\nMamba to solve parity stems from restricting the value range of their diagonal\nstate-transition matrices to $[0, 1]$ and that incorporating negative values\ncan resolve this issue. We extend this result to non-diagonal LRNNs such as\nDeltaNet. We prove that finite precision LRNNs with state-transition matrices\nhaving only positive eigenvalues cannot solve parity, while non-triangular\nmatrices are needed to count modulo $3$. Notably, we also prove that LRNNs can\nlearn any regular language when their state-transition matrices are products of\nidentity minus vector outer product matrices, each with eigenvalues in the\nrange $[-1, 1]$. Our experiments confirm that extending the eigenvalue range of\nMamba and DeltaNet to include negative values not only enables them to solve\nparity but consistently improves their performance on state-tracking tasks. We\nalso show that state-tracking enabled LRNNs can be pretrained stably and\nefficiently at scale (1.3B parameters), achieving competitive performance on\nlanguage modeling and showing promise on code and math tasks.\n","authors":["Riccardo Grazzi","Julien Siems","Jörg K. H. Franke","Arber Zela","Frank Hutter","Massimiliano Pontil"],"pdf_url":"https://arxiv.org/pdf/2411.12537v3.pdf","comment":"V2: Correction to Theorem 1 and 2 and to point 3 of Proposition 1.\n  V3: ICLR Camera Ready"},{"id":"http://arxiv.org/abs/2502.20868v1","updated":"2025-02-28T09:12:42Z","published":"2025-02-28T09:12:42Z","title":"ProBench: Benchmarking Large Language Models in Competitive Programming","summary":"  With reasoning language models such as OpenAI-o3 and DeepSeek-R1 emerging,\nlarge language models (LLMs) have entered a new phase of development. However,\nexisting benchmarks for coding evaluation are gradually inadequate to assess\nthe capability of advanced LLMs in code reasoning. To bridge the gap for\nhigh-level code reasoning assessment, we propose ProBench to benchmark LLMs in\ncompetitive programming, drawing inspiration from the International Collegiate\nProgramming Contest. ProBench collects a comprehensive set of competitive\nprogramming problems from Codeforces, Luogu, and Nowcoder platforms during the\nperiod from July to December 2024, obtaining real test results through online\nsubmissions to ensure the fairness and accuracy of the evaluation. We establish\na unified problem attribute system, including difficulty grading and algorithm\ntagging. With carefully collected and annotated data in ProBench, we\nsystematically assess 9 latest LLMs in competitive programming across multiple\ndimensions, including thought chain analysis, error type diagnosis, and\nreasoning depth evaluation. Experimental results show that QwQ-32B-Preview\nachieves the best score of 20.93 followed by DeepSeek-V3 with a score of 16.38,\nsuggesting that models trained with specialized reasoning tasks significantly\noutperform general-purpose models (even larger than reasoning-oriented models)\nin programming. Further analysis also reveals key areas for programming\ncapability enhancement, e.g., algorithm adaptability and reasoning sufficiency,\nproviding important insights for the future development of reasoning models.\n","authors":["Lei Yang","Renren Jin","Ling Shi","Jianxiang Peng","Yue Chen","Deyi Xiong"],"pdf_url":"https://arxiv.org/pdf/2502.20868v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20866v1","updated":"2025-02-28T09:08:57Z","published":"2025-02-28T09:08:57Z","title":"Better Benchmarking LLMs for Zero-Shot Dependency Parsing","summary":"  While LLMs excel in zero-shot tasks, their performance in linguistic\nchallenges like syntactic parsing has been less scrutinized. This paper studies\nstate-of-the-art open-weight LLMs on the task by comparing them to baselines\nthat do not have access to the input sentence, including baselines that have\nnot been used in this context such as random projective trees or optimal linear\narrangements. The results show that most of the tested LLMs cannot outperform\nthe best uninformed baselines, with only the newest and largest versions of\nLLaMA doing so for most languages, and still achieving rather low performance.\nThus, accurate zero-shot syntactic parsing is not forthcoming with open LLMs.\n","authors":["Ana Ezquerro","Carlos Gómez-Rodríguez","David Vilares"],"pdf_url":"https://arxiv.org/pdf/2502.20866v1.pdf","comment":"Accepted at NoDaLiDa/Baltic-HLT 2025"},{"id":"http://arxiv.org/abs/2502.20864v1","updated":"2025-02-28T09:05:35Z","published":"2025-02-28T09:05:35Z","title":"Do Language Models Understand Honorific Systems in Javanese?","summary":"  The Javanese language features a complex system of honorifics that vary\naccording to the social status of the speaker, listener, and referent. Despite\nits cultural and linguistic significance, there has been limited progress in\ndeveloping a comprehensive corpus to capture these variations for natural\nlanguage processing (NLP) tasks. In this paper, we present Unggah-Ungguh, a\ncarefully curated dataset designed to encapsulate the nuances of Unggah-Ungguh\nBasa, the Javanese speech etiquette framework that dictates the choice of words\nand phrases based on social hierarchy and context. Using Unggah-Ungguh, we\nassess the ability of language models (LMs) to process various levels of\nJavanese honorifics through classification and machine translation tasks. To\nfurther evaluate cross-lingual LMs, we conduct machine translation experiments\nbetween Javanese (at specific honorific levels) and Indonesian. Additionally,\nwe explore whether LMs can generate contextually appropriate Javanese\nhonorifics in conversation tasks, where the honorific usage should align with\nthe social role and contextual cues. Our findings indicate that current LMs\nstruggle with most honorific levels, exhibitinga bias toward certain honorific\ntiers.\n","authors":["Mohammad Rifqi Farhansyah","Iwan Darmawan","Adryan Kusumawardhana","Genta Indra Winata","Alham Fikri Aji","Derry Tanti Wijaya"],"pdf_url":"https://arxiv.org/pdf/2502.20864v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20859v1","updated":"2025-02-28T09:01:39Z","published":"2025-02-28T09:01:39Z","title":"The Power of Personality: A Human Simulation Perspective to Investigate\n  Large Language Model Agents","summary":"  Large language models (LLMs) excel in both closed tasks (including\nproblem-solving, and code generation) and open tasks (including creative\nwriting), yet existing explanations for their capabilities lack connections to\nreal-world human intelligence. To fill this gap, this paper systematically\ninvestigates LLM intelligence through the lens of ``human simulation'',\naddressing three core questions: (1) How do personality traits affect\nproblem-solving in closed tasks? (2) How do traits shape creativity in open\ntasks? (3) How does single-agent performance influence multi-agent\ncollaboration? By assigning Big Five personality traits to LLM agents and\nevaluating their performance in single- and multi-agent settings, we reveal\nthat specific traits significantly influence reasoning accuracy (closed tasks)\nand creative output (open tasks). Furthermore, multi-agent systems exhibit\ncollective intelligence distinct from individual capabilities, driven by\ndistinguishing combinations of personalities. We demonstrate that LLMs\ninherently simulate human behavior through next-token prediction, mirroring\nhuman language, decision-making, and collaborative dynamics.\n","authors":["Yifan Duan","Yihong Tang","Xuefeng Bai","Kehai Chen","Juntao Li","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2502.20859v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20855v1","updated":"2025-02-28T08:53:42Z","published":"2025-02-28T08:53:42Z","title":"MAMUT: A Novel Framework for Modifying Mathematical Formulas for the\n  Generation of Specialized Datasets for Language Model Training","summary":"  Mathematical formulas are a fundamental and widely used component in various\nscientific fields, serving as a universal language for expressing complex\nconcepts and relationships. While state-of-the-art transformer models excel in\nprocessing and understanding natural language, they encounter challenges with\nmathematical notation, which involves a complex structure and diverse\nrepresentations. This study focuses on the development of specialized training\ndatasets to enhance the encoding of mathematical content. We introduce Math\nMutator (MAMUT), a framework capable of generating equivalent and falsified\nversions of a given mathematical formula in LaTeX notation, effectively\ncapturing the mathematical variety in notation of the same concept. Based on\nMAMUT, we have generated four large mathematical datasets containing diverse\nnotation, which can be used to train language models with enhanced mathematical\nembeddings.\n","authors":["Jonathan Drechsel","Anja Reusch","Steffen Herbold"],"pdf_url":"https://arxiv.org/pdf/2502.20855v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20854v1","updated":"2025-02-28T08:53:08Z","published":"2025-02-28T08:53:08Z","title":"A Pilot Empirical Study on When and How to Use Knowledge Graphs as\n  Retrieval Augmented Generation","summary":"  The integration of Knowledge Graphs (KGs) into the Retrieval Augmented\nGeneration (RAG) framework has attracted significant interest, with early\nstudies showing promise in mitigating hallucinations and improving model\naccuracy. However, a systematic understanding and comparative analysis of the\nrapidly emerging KG-RAG methods are still lacking. This paper seeks to lay the\nfoundation for systematically answering the question of when and how to use\nKG-RAG by analyzing their performance in various application scenarios\nassociated with different technical configurations. After outlining the mind\nmap using KG-RAG framework and summarizing its popular pipeline, we conduct a\npilot empirical study of KG-RAG works to reimplement and evaluate 6 KG-RAG\nmethods across 7 datasets in diverse scenarios, analyzing the impact of 9\nKG-RAG configurations in combination with 17 LLMs. Our results underscore the\ncritical role of appropriate application conditions and optimal configurations\nof KG-RAG components.\n","authors":["Xujie Yuan","Yongxu Liu","Shimin Di","Shiwen Wu","Libin Zheng","Rui Meng","Xiaofang Zhou","Lei Chen","Jian Yin"],"pdf_url":"https://arxiv.org/pdf/2502.20854v1.pdf","comment":"8 pages, 2 figures, 14 tables"},{"id":"http://arxiv.org/abs/2407.01449v6","updated":"2025-02-28T08:51:57Z","published":"2024-06-27T15:45:29Z","title":"ColPali: Efficient Document Retrieval with Vision Language Models","summary":"  Documents are visually rich structures that convey information through text,\nbut also figures, page layouts, tables, or even fonts. Since modern retrieval\nsystems mainly rely on the textual information they extract from document pages\nto index documents -often through lengthy and brittle processes-, they struggle\nto exploit key visual cues efficiently. This limits their capabilities in many\npractical document retrieval applications such as Retrieval Augmented\nGeneration (RAG). To benchmark current systems on visually rich document\nretrieval, we introduce the Visual Document Retrieval Benchmark ViDoRe,\ncomposed of various page-level retrieval tasks spanning multiple domains,\nlanguages, and practical settings. The inherent complexity and performance\nshortcomings of modern systems motivate a new concept; doing document retrieval\nby directly embedding the images of the document pages. We release ColPali, a\nVision Language Model trained to produce high-quality multi-vector embeddings\nfrom images of document pages. Combined with a late interaction matching\nmechanism, ColPali largely outperforms modern document retrieval pipelines\nwhile being drastically simpler, faster and end-to-end trainable. We release\nmodels, data, code and benchmarks under open licenses at https://hf.co/vidore.\n","authors":["Manuel Faysse","Hugues Sibille","Tony Wu","Bilel Omrani","Gautier Viaud","Céline Hudelot","Pierre Colombo"],"pdf_url":"https://arxiv.org/pdf/2407.01449v6.pdf","comment":"Published as a conference paper at ICLR 2025"},{"id":"http://arxiv.org/abs/2502.17184v4","updated":"2025-02-28T08:44:08Z","published":"2025-02-24T14:20:22Z","title":"Measuring Data Diversity for Instruction Tuning: A Systematic Analysis\n  and A Reliable Metric","summary":"  Data diversity is crucial for the instruction tuning of large language\nmodels. Existing studies have explored various diversity-aware data selection\nmethods to construct high-quality datasets and enhance model performance.\nHowever, the fundamental problem of precisely defining and measuring data\ndiversity remains underexplored, limiting clear guidance for data engineering.\nTo address this, we systematically analyze 11 existing diversity measurement\nmethods by evaluating their correlation with model performance through\nextensive fine-tuning experiments. Our results indicate that a reliable\ndiversity measure should properly account for both inter-sample differences and\nthe information distribution in the sample space. Building on this, we propose\nNovelSum, a new diversity metric based on sample-level \"novelty.\" Experiments\non both simulated and real-world data show that NovelSum accurately captures\ndiversity variations and achieves a 0.97 correlation with instruction-tuned\nmodel performance, highlighting its value in guiding data engineering\npractices. With NovelSum as an optimization objective, we further develop a\ngreedy, diversity-oriented data selection strategy that outperforms existing\napproaches, validating both the effectiveness and practical significance of our\nmetric.\n","authors":["Yuming Yang","Yang Nan","Junjie Ye","Shihan Dou","Xiao Wang","Shuo Li","Huijie Lv","Mingqi Wu","Tao Gui","Qi Zhang","Xuanjing Huang"],"pdf_url":"https://arxiv.org/pdf/2502.17184v4.pdf","comment":"16 pages. The related codes and resources will be released later.\n  Project page: https://github.com/UmeanNever/NovelSum"},{"id":"http://arxiv.org/abs/2410.21357v3","updated":"2025-02-28T08:41:03Z","published":"2024-10-28T17:25:56Z","title":"Energy-Based Diffusion Language Models for Text Generation","summary":"  Despite remarkable progress in autoregressive language models, alternative\ngenerative paradigms beyond left-to-right generation are still being actively\nexplored. Discrete diffusion models, with the capacity for parallel generation,\nhave recently emerged as a promising alternative. Unfortunately, these models\nstill underperform the autoregressive counterparts, with the performance gap\nincreasing when reducing the number of sampling steps. Our analysis reveals\nthat this degradation is a consequence of an imperfect approximation used by\ndiffusion models. In this work, we propose Energy-based Diffusion Language\nModel (EDLM), an energy-based model operating at the full sequence level for\neach diffusion step, introduced to improve the underlying approximation used by\ndiffusion models. More specifically, we introduce an EBM in a residual form,\nand show that its parameters can be obtained by leveraging a pretrained\nautoregressive model or by finetuning a bidirectional transformer via noise\ncontrastive estimation. We also propose an efficient generation algorithm via\nparallel important sampling. Comprehensive experiments on language modeling\nbenchmarks show that our model can consistently outperform state-of-the-art\ndiffusion models by a significant margin, and approaches autoregressive models'\nperplexity. We further show that, without any generation performance drop, our\nframework offers a 1.3$\\times$ sampling speedup over existing diffusion models.\n","authors":["Minkai Xu","Tomas Geffner","Karsten Kreis","Weili Nie","Yilun Xu","Jure Leskovec","Stefano Ermon","Arash Vahdat"],"pdf_url":"https://arxiv.org/pdf/2410.21357v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20246v2","updated":"2025-02-28T08:39:27Z","published":"2025-02-27T16:30:00Z","title":"Beyond Natural Language Perplexity: Detecting Dead Code Poisoning in\n  Code Generation Datasets","summary":"  The increasing adoption of large language models (LLMs) for code-related\ntasks has raised concerns about the security of their training datasets. One\ncritical threat is dead code poisoning, where syntactically valid but\nfunctionally redundant code is injected into training data to manipulate model\nbehavior. Such attacks can degrade the performance of neural code search\nsystems, leading to biased or insecure code suggestions. Existing detection\nmethods, such as token-level perplexity analysis, fail to effectively identify\ndead code due to the structural and contextual characteristics of programming\nlanguages. In this paper, we propose DePA (Dead Code Perplexity Analysis), a\nnovel line-level detection and cleansing method tailored to the structural\nproperties of code. DePA computes line-level perplexity by leveraging the\ncontextual relationships between code lines and identifies anomalous lines by\ncomparing their perplexity to the overall distribution within the file. Our\nexperiments on benchmark datasets demonstrate that DePA significantly\noutperforms existing methods, achieving 0.14-0.19 improvement in detection\nF1-score and a 44-65% increase in poisoned segment localization precision.\nFurthermore, DePA enhances detection speed by 0.62-23x, making it practical for\nlarge-scale dataset cleansing. Overall, by addressing the unique challenges of\ndead code poisoning, DePA provides a robust and efficient solution for\nsafeguarding the integrity of code generation model training datasets.\n","authors":["Chi-Chien Tsai","Chia-Mu Yu","Ying-Dar Lin","Yu-Sung Wu","Wei-Bin Lee"],"pdf_url":"https://arxiv.org/pdf/2502.20246v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20834v1","updated":"2025-02-28T08:30:47Z","published":"2025-02-28T08:30:47Z","title":"Learning to Substitute Components for Compositional Generalization","summary":"  Despite the rising prevalence of neural language models, recent empirical\nevidence suggests their deficiency in compositional generalization. One of the\ncurrent de-facto solutions to this problem is compositional data augmentation,\nwhich aims to introduce additional compositional inductive bias. However,\nexisting handcrafted augmentation strategies offer limited improvement when\nsystematic generalization of neural language models requires multi-grained\ncompositional bias (i.e., not limited to either lexical or structural biases\nalone) or when training sentences have an imbalanced difficulty distribution.\nTo address these challenges, we first propose a novel compositional\naugmentation strategy called Component Substitution (CompSub), which enables\nmulti-grained composition of substantial substructures across the entire\ntraining set. Furthermore, we introduce the Learning Component Substitution\n(LCS) framework. This framework empowers the learning of component substitution\nprobabilities in CompSub in an end-to-end manner by maximizing the loss of\nneural language models, thereby prioritizing challenging compositions with\nelusive concepts and novel contexts. We extend the key ideas of CompSub and LCS\nto the recently emerging in-context learning scenarios of pre-trained large\nlanguage models (LLMs), proposing the LCS-ICL algorithm to enhance the few-shot\ncompositional generalization of state-of-the-art (SOTA) LLMs. Theoretically, we\nprovide insights into why applying our algorithms to language models can\nimprove compositional generalization performance. Empirically, our results on\nfour standard compositional generalization benchmarks(SCAN, COGS, GeoQuery, and\nCOGS-QL) demonstrate the superiority of CompSub, LCS, and LCS-ICL, with\nimprovements of up to 66.5%, 10.3%, 1.4%, and 8.8%, respectively.\n","authors":["Zhaoyi Li","Gangwei Jiang","Chenwang Wu","Ying Wei","Defu Lian","Enhong Chen"],"pdf_url":"https://arxiv.org/pdf/2502.20834v1.pdf","comment":"23 pages, 9 figures, preprint, the extension paper of the paper\n  (arXiv:2306.02840)"},{"id":"http://arxiv.org/abs/2406.07155v2","updated":"2025-02-28T08:26:52Z","published":"2024-06-11T11:02:04Z","title":"Scaling Large-Language-Model-based Multi-Agent Collaboration","summary":"  Recent breakthroughs in large language model-driven autonomous agents have\nrevealed that multi-agent collaboration often surpasses each individual through\ncollective reasoning. Inspired by the neural scaling law--increasing neurons\nenhances performance, this study explores whether the continuous addition of\ncollaborative agents can yield similar benefits. Technically, we utilize\ndirected acyclic graphs to organize agents into a multi-agent collaboration\nnetwork (MacNet), upon which their interactive reasoning is topologically\norchestrated for autonomous task solving. Extensive evaluations reveal that it\neffectively supports collaboration among over a thousand agents, with irregular\ntopologies outperforming regular ones. We also identify a collaborative scaling\nlaw--the overall performance follows a logistic growth pattern as agents scale,\nwith collaborative emergence occurring earlier than traditional neural\nemergence. We speculate this may be because scaling agents catalyzes their\nmultidimensional considerations during interactive reflection and refinement,\nthereby producing more comprehensive artifacts. The code is available at\nhttps://github.com/OpenBMB/ChatDev/tree/macnet.\n","authors":["Chen Qian","Zihao Xie","YiFei Wang","Wei Liu","Kunlun Zhu","Hanchen Xia","Yufan Dang","Zhuoyun Du","Weize Chen","Cheng Yang","Zhiyuan Liu","Maosong Sun"],"pdf_url":"https://arxiv.org/pdf/2406.07155v2.pdf","comment":"Accepted to ICLR-2025; https://github.com/OpenBMB/ChatDev/tree/macnet"},{"id":"http://arxiv.org/abs/2407.08351v2","updated":"2025-02-28T08:14:49Z","published":"2024-07-11T10:03:47Z","title":"AutoBencher: Towards Declarative Benchmark Construction","summary":"  We present AutoBencher, a declarative framework for automatic benchmark\nconstruction, and use it to scalably discover novel insights and\nvulnerabilities of existing language models. Concretely, given a few desiderata\nof benchmarks (e.g., question difficulty, topic salience), we operationalize\neach desideratum and cast benchmark creation as an optimization problem.\nSpecifically, we experiment with two settings with different optimization\nobjectives: (i) for capability evaluation, we declare the goal of finding a\nsalient, difficult dataset that induces novel performance patterns; (ii) for\nsafety evaluation, we declare the goal of finding a dataset of unsafe prompts\nthat existing LMs fail to decline. To tackle this optimization problem, we use\na language model to iteratively propose and refine dataset descriptions, which\nare then used to generate topic-specific questions and answers. These\ndescriptions are optimized to improve the declared desiderata. We use\nAutoBencher (powered by GPT-4) to create datasets for math, multilinguality,\nknowledge, and safety. The scalability of AutoBencher allows it to test\nfine-grained categories and tail knowledge, creating datasets that elicit 22%\nmore model errors (i.e., difficulty) than existing benchmarks. On the novelty\nends, AutoBencher also helps identify specific gaps not captured by existing\nbenchmarks: e.g., Gemini-Pro has knowledge gaps on Permian Extinction and\nFordism while GPT-4o fails to decline harmful requests about cryptocurrency\nscams.\n","authors":["Xiang Lisa Li","Farzaan Kaiyom","Evan Zheran Liu","Yifan Mai","Percy Liang","Tatsunori Hashimoto"],"pdf_url":"https://arxiv.org/pdf/2407.08351v2.pdf","comment":"Accepted for publication at ICLR 2025"},{"id":"http://arxiv.org/abs/2502.20122v2","updated":"2025-02-28T08:12:10Z","published":"2025-02-27T14:14:50Z","title":"Self-Training Elicits Concise Reasoning in Large Language Models","summary":"  Chain-of-thought (CoT) reasoning has enabled large language models (LLMs) to\nutilize additional computation through intermediate tokens to solve complex\ntasks. However, we posit that typical reasoning traces contain many redundant\ntokens, incurring extraneous inference costs. Upon examination of the output\ndistribution of current LLMs, we find evidence on their latent ability to\nreason more concisely, relative to their default behavior. To elicit this\ncapability, we propose simple fine-tuning methods which leverage self-generated\nconcise reasoning paths obtained by best-of-N sampling and few-shot\nconditioning, in task-specific settings. Our combined method achieves a 30%\nreduction in output tokens on average, across five model families on GSM8K and\nMATH, while maintaining average accuracy. By exploiting the fundamental\nstochasticity and in-context learning capabilities of LLMs, our self-training\napproach robustly elicits concise reasoning on a wide range of models,\nincluding those with extensive post-training. Code is available at\nhttps://github.com/TergelMunkhbat/concise-reasoning\n","authors":["Tergel Munkhbat","Namgyu Ho","Seo Hyun Kim","Yongjin Yang","Yujin Kim","Se-Young Yun"],"pdf_url":"https://arxiv.org/pdf/2502.20122v2.pdf","comment":"23 pages, 10 figures, 18 tables"},{"id":"http://arxiv.org/abs/2501.01638v2","updated":"2025-02-28T08:07:50Z","published":"2025-01-03T05:11:41Z","title":"A non-ergodic framework for understanding emergent capabilities in Large\n  Language Models","summary":"  Large language models have emergent capabilities that come unexpectedly at\nscale, but we need a theoretical framework to explain why and how they emerge.\nWe prove that language models are actually non-ergodic systems while providing\na mathematical framework based on Stuart Kauffman's theory of the adjacent\npossible (TAP) to explain capability emergence. Our resource-constrained TAP\nequation demonstrates how architectural, training, and contextual constraints\ninteract to shape model capabilities through phase transitions in semantic\nspace. We prove through experiments with three different language models that\ncapacities emerge through discrete transitions guided by constraint\ninteractions and path-dependent exploration. This framework provides a\ntheoretical basis for understanding emergence in language models and guides the\ndevelopment of architectures that can guide capability emergence.\n","authors":["Javier Marín"],"pdf_url":"https://arxiv.org/pdf/2501.01638v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08467v2","updated":"2025-02-28T08:06:39Z","published":"2024-12-11T15:32:24Z","title":"Bootstrapping Language-Guided Navigation Learning with Self-Refining\n  Data Flywheel","summary":"  Creating high-quality data for training robust language-instructed agents is\na long-lasting challenge in embodied AI. In this paper, we introduce a\nSelf-Refining Data Flywheel (SRDF) that generates high-quality and large-scale\nnavigational instruction-trajectory pairs by iteratively refining the data pool\nthrough the collaboration between two models, the instruction generator and the\nnavigator, without any human-in-the-loop annotation. Specifically, SRDF starts\nwith using a base generator to create an initial data pool for training a base\nnavigator, followed by applying the trained navigator to filter the data pool.\nThis leads to higher-fidelity data to train a better generator, which can, in\nturn, produce higher-quality data for training the next-round navigator. Such a\nflywheel establishes a data self-refining process, yielding a continuously\nimproved and highly effective dataset for large-scale language-guided\nnavigation learning. Our experiments demonstrate that after several flywheel\nrounds, the navigator elevates the performance boundary from 70% to 78% SPL on\nthe classic R2R test set, surpassing human performance (76%) for the first\ntime. Meanwhile, this process results in a superior generator, evidenced by a\nSPICE increase from 23.5 to 26.2, better than all previous VLN instruction\ngeneration methods. Finally, we demonstrate the scalability of our method\nthrough increasing environment and instruction diversity, and the\ngeneralization ability of our pre-trained navigator across various downstream\nnavigation tasks, surpassing state-of-the-art methods by a large margin in all\ncases.\n","authors":["Zun Wang","Jialu Li","Yicong Hong","Songze Li","Kunchang Li","Shoubin Yu","Yi Wang","Yu Qiao","Yali Wang","Mohit Bansal","Limin Wang"],"pdf_url":"https://arxiv.org/pdf/2412.08467v2.pdf","comment":"28 pages, Code and data are available at\n  https://github.com/wz0919/VLN-SRDF"},{"id":"http://arxiv.org/abs/2410.09870v3","updated":"2025-02-28T08:02:31Z","published":"2024-10-13T15:08:49Z","title":"ChroKnowledge: Unveiling Chronological Knowledge of Language Models in\n  Multiple Domains","summary":"  Large language models (LLMs) have brought significant changes to many aspects\nof our lives. However, assessing and ensuring their chronological knowledge\nremains challenging. Existing approaches fall short in addressing the temporal\nadaptability of knowledge, often relying on a fixed time-point view. To\novercome this, we introduce ChroKnowBench, a benchmark dataset designed to\nevaluate chronologically accumulated knowledge across three key aspects:\nmultiple domains, time dependency, temporal state. Our benchmark distinguishes\nbetween knowledge that evolves (e.g., personal history, scientific discoveries,\namended laws) and knowledge that remain constant (e.g., mathematical truths,\ncommonsense facts). Building on this benchmark, we present ChroKnowledge\n(Chronological Categorization of Knowledge), a novel sampling-based framework\nfor evaluating LLMs' non-parametric chronological knowledge. Our evaluation led\nto the following observations: (1) The ability of eliciting temporal knowledge\nvaries depending on the data format that model was trained on. (2) LLMs\npartially recall knowledge or show a cut-off at temporal boundaries rather than\nrecalling all aspects of knowledge correctly. Thus, we apply our\nChroKnowPrompt, an in-depth prompting to elicit chronological knowledge by\ntraversing step-by-step through the surrounding time spans. We observe that it\nsuccessfully recalls objects across both open-source and proprietary LLMs,\ndemonstrating versatility, though it faces challenges with dynamic datasets and\nunstructured formats.\n","authors":["Yein Park","Chanwoong Yoon","Jungwoo Park","Donghyeon Lee","Minbyul Jeong","Jaewoo Kang"],"pdf_url":"https://arxiv.org/pdf/2410.09870v3.pdf","comment":"ICLR 2025, 40 pages, 17 figures"},{"id":"http://arxiv.org/abs/2410.09542v2","updated":"2025-02-28T08:01:32Z","published":"2024-10-12T14:12:36Z","title":"MIRAGE: Evaluating and Explaining Inductive Reasoning Process in\n  Language Models","summary":"  Inductive reasoning is an essential capability for large language models\n(LLMs) to achieve higher intelligence, which requires the model to generalize\nrules from observed facts and then apply them to unseen examples. We present\nMIRAGE, a synthetic dataset that addresses the limitations of previous work,\nspecifically the lack of comprehensive evaluation and flexible test data. In\nit, we evaluate LLMs' capabilities in both the inductive and deductive stages,\nallowing for flexible variation in input distribution, task scenario, and task\ndifficulty to analyze the factors influencing LLMs' inductive reasoning. Based\non these multi-faceted evaluations, we demonstrate that the LLM is a poor\nrule-based reasoner. In many cases, when conducting inductive reasoning, they\ndo not rely on a correct rule to answer the unseen case. From the perspectives\nof different prompting methods, observation numbers, and task forms, models\ntend to consistently conduct correct deduction without correct inductive rules.\nBesides, we find that LLMs are good neighbor-based reasoners. In the inductive\nreasoning process, the model tends to focus on observed facts that are close to\nthe current test example in feature space. By leveraging these similar\nexamples, the model maintains strong inductive capabilities within a localized\nregion, significantly improving its deductive performance.\n","authors":["Jiachun Li","Pengfei Cao","Zhuoran Jin","Yubo Chen","Kang Liu","Jun Zhao"],"pdf_url":"https://arxiv.org/pdf/2410.09542v2.pdf","comment":"Accepted as ICLR 2025 conference paper (26 pages, 16 tables, 9\n  figures)"},{"id":"http://arxiv.org/abs/2412.06287v3","updated":"2025-02-28T07:54:16Z","published":"2024-12-09T08:19:28Z","title":"PediaBench: A Comprehensive Chinese Pediatric Dataset for Benchmarking\n  Large Language Models","summary":"  The emergence of Large Language Models (LLMs) in the medical domain has\nstressed a compelling need for standard datasets to evaluate their\nquestion-answering (QA) performance. Although there have been several benchmark\ndatasets for medical QA, they either cover common knowledge across different\ndepartments or are specific to another department rather than pediatrics.\nMoreover, some of them are limited to objective questions and do not measure\nthe generation capacity of LLMs. Therefore, they cannot comprehensively assess\nthe QA ability of LLMs in pediatrics. To fill this gap, we construct\nPediaBench, the first Chinese pediatric dataset for LLM evaluation.\nSpecifically, it contains 4,117 objective questions and 1,632 subjective\nquestions spanning 12 pediatric disease groups. It adopts an integrated scoring\ncriterion based on different difficulty levels to thoroughly assess the\nproficiency of an LLM in instruction following, knowledge understanding,\nclinical case analysis, etc. Finally, we validate the effectiveness of\nPediaBench with extensive experiments on 20 open-source and commercial LLMs.\nThrough an in-depth analysis of experimental results, we offer insights into\nthe ability of LLMs to answer pediatric questions in the Chinese context,\nhighlighting their limitations for further improvements. Our code and data are\npublished at https://github.com/ACMISLab/PediaBench.\n","authors":["Qian Zhang","Panfeng Chen","Jiali Li","Linkun Feng","Shuyu Liu","Heng Zhao","Mei Chen","Hui Li","Yanhao Wang"],"pdf_url":"https://arxiv.org/pdf/2412.06287v3.pdf","comment":"21 pages, 12 figures"},{"id":"http://arxiv.org/abs/2502.20811v1","updated":"2025-02-28T07:53:40Z","published":"2025-02-28T07:53:40Z","title":"HAIC: Improving Human Action Understanding and Generation with Better\n  Captions for Multi-modal Large Language Models","summary":"  Recent Multi-modal Large Language Models (MLLMs) have made great progress in\nvideo understanding. However, their performance on videos involving human\nactions is still limited by the lack of high-quality data. To address this, we\nintroduce a two-stage data annotation pipeline. First, we design strategies to\naccumulate videos featuring clear human actions from the Internet. Second,\nvideos are annotated in a standardized caption format that uses human\nattributes to distinguish individuals and chronologically details their actions\nand interactions. Through this pipeline, we curate two datasets, namely\nHAICTrain and HAICBench. \\textbf{HAICTrain} comprises 126K video-caption pairs\ngenerated by Gemini-Pro and verified for training purposes. Meanwhile,\n\\textbf{HAICBench} includes 500 manually annotated video-caption pairs and\n1,400 QA pairs, for a comprehensive evaluation of human action understanding.\nExperimental results demonstrate that training with HAICTrain not only\nsignificantly enhances human understanding abilities across 4 benchmarks, but\ncan also improve text-to-video generation results. Both the HAICTrain and\nHAICBench are released at https://huggingface.co/datasets/KuaishouHAIC/HAIC.\n","authors":["Xiao Wang","Jingyun Hua","Weihong Lin","Yuanxing Zhang","Fuzheng Zhang","Jianlong Wu","Di Zhang","Liqiang Nie"],"pdf_url":"https://arxiv.org/pdf/2502.20811v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.15089v2","updated":"2025-02-28T07:53:20Z","published":"2025-01-25T05:32:14Z","title":"LongReason: A Synthetic Long-Context Reasoning Benchmark via Context\n  Expansion","summary":"  Large language models (LLMs) have demonstrated remarkable progress in\nunderstanding long-context inputs. However, benchmarks for evaluating the\nlong-context reasoning abilities of LLMs fall behind the pace. Existing\nbenchmarks often focus on a narrow range of tasks or those that do not demand\ncomplex reasoning. To address this gap and enable a more comprehensive\nevaluation of the long-context reasoning capabilities of current LLMs, we\npropose a new synthetic benchmark, LongReason, which is constructed by\nsynthesizing long-context reasoning questions from a varied set of\nshort-context reasoning questions through context expansion. LongReason\nconsists of 794 multiple-choice reasoning questions with diverse reasoning\npatterns across three task categories: reading comprehension, logical\ninference, and mathematical word problems. We evaluate 21 LLMs on LongReason,\nrevealing that most models experience significant performance drops as context\nlength increases. Our further analysis shows that even state-of-the-art LLMs\nstill have significant room for improvement in providing robust reasoning\nacross different tasks. We have open-sourced LongReason under\nhttps://huggingface.co/datasets/lz1bytedance/LongReason to support the\ncomprehensive evaluation of LLMs' long-context reasoning capabilities.\n","authors":["Zhan Ling","Kang Liu","Kai Yan","Yifan Yang","Weijian Lin","Ting-Han Fan","Lingfeng Shen","Zhengyin Du","Jiecao Chen"],"pdf_url":"https://arxiv.org/pdf/2501.15089v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.15359v2","updated":"2025-02-28T07:49:06Z","published":"2025-02-21T10:14:55Z","title":"ARS: Automatic Routing Solver with Large Language Models","summary":"  Real-world Vehicle Routing Problems (VRPs) are characterized by a variety of\npractical constraints, making manual solver design both knowledge-intensive and\ntime-consuming. Although there is increasing interest in automating the design\nof routing algorithms, existing research has explored only a limited array of\nVRP variants and fails to adequately address the complex and prevalent\nconstraints encountered in real-world situations. To fill this gap, this paper\nintroduces RoutBench, a benchmark of 1,000 VRP variants derived from 24\nattributes, for evaluating the effectiveness of automatic routing solvers in\naddressing complex constraints. Along with RoutBench, we present the Automatic\nRouting Solver (ARS), which employs Large Language Model (LLM) agents to\nenhance a backbone algorithm framework by automatically generating\nconstraint-aware heuristic code, based on problem descriptions and several\nrepresentative constraints selected from a database. Our experiments show that\nARS outperforms state-of-the-art LLM-based methods and commonly used solvers,\nautomatically solving 91.67% of common VRPs and achieving at least a 30%\nimprovement across all benchmarks.\n","authors":["Kai Li","Fei Liu","Zhenkun Wang","Xialiang Tong","Xiongwei Han","Mingxuan Yuan"],"pdf_url":"https://arxiv.org/pdf/2502.15359v2.pdf","comment":"Authorship is under discussion; arXiv release will follow\n  finalization"},{"id":"http://arxiv.org/abs/2411.08870v2","updated":"2025-02-28T07:34:44Z","published":"2024-11-13T18:50:13Z","title":"The Limited Impact of Medical Adaptation of Large Language and\n  Vision-Language Models","summary":"  Several recent works seek to adapt general-purpose large language models\n(LLMs) and vision-language models (VLMs) for medical applications through\ncontinued pretraining on publicly available biomedical corpora. These works\ntypically claim that such domain-adaptive pretraining improves performance on\nvarious downstream medical tasks, such as answering medical exam questions. In\nthis paper, we compare ten \"medical\" LLMs and two VLMs against their\ncorresponding base models, arriving at a different conclusion: all medical VLMs\nand nearly all medical LLMs fail to consistently improve over their base models\nin the zero-/few-shot prompting and supervised fine-tuning regimes for medical\nquestion answering (QA). For instance, on clinical-note-based QA tasks in the\n3-shot setting, medical LLMs outperform their base models in only 26.7% of\ncases, reach a (statistical) tie in 16.7% of cases, and perform significantly\nworse in the remaining 56.7% of cases. Our conclusions are based on (i)\ncomparing each medical model directly against its base model; (ii) optimizing\nthe prompts for each model separately in zero-/few-shot prompting; and (iii)\naccounting for statistical uncertainty in comparisons. Our findings suggest\nthat state-of-the-art general-domain models may already exhibit strong medical\nknowledge and reasoning capabilities, and offer recommendations to strengthen\nthe conclusions of future studies.\n","authors":["Daniel P. Jeong","Pranav Mani","Saurabh Garg","Zachary C. Lipton","Michael Oberst"],"pdf_url":"https://arxiv.org/pdf/2411.08870v2.pdf","comment":"Extended version of EMNLP 2024 paper arXiv:2411.04118. Includes\n  additional results on clinical note QA tasks and supervised fine-tuning\n  evaluations"},{"id":"http://arxiv.org/abs/2502.17651v2","updated":"2025-02-28T07:28:24Z","published":"2025-02-24T21:01:39Z","title":"METAL: A Multi-Agent Framework for Chart Generation with Test-Time\n  Scaling","summary":"  Chart generation aims to generate code to produce charts satisfying the\ndesired visual properties, e.g., texts, layout, color, and type. It has great\npotential to empower the automatic professional report generation in financial\nanalysis, research presentation, education, and healthcare. In this work, we\nbuild a vision-language model (VLM) based multi-agent framework for effective\nautomatic chart generation. Generating high-quality charts requires both strong\nvisual design skills and precise coding capabilities that embed the desired\nvisual properties into code. Such a complex multi-modal reasoning process is\ndifficult for direct prompting of VLMs. To resolve these challenges, we propose\nMETAL, a multi-agent framework that decomposes the task of chart generation\ninto the iterative collaboration among specialized agents. METAL achieves 5.2%\nimprovement over the current best result in the chart generation task. The\nMETAL framework exhibits the phenomenon of test-time scaling: its performance\nincreases monotonically as the logarithmic computational budget grows from 512\nto 8192 tokens. In addition, we find that separating different modalities\nduring the critique process of METAL boosts the self-correction capability of\nVLMs in the multimodal context.\n","authors":["Bingxuan Li","Yiwei Wang","Jiuxiang Gu","Kai-Wei Chang","Nanyun Peng"],"pdf_url":"https://arxiv.org/pdf/2502.17651v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20795v1","updated":"2025-02-28T07:24:33Z","published":"2025-02-28T07:24:33Z","title":"Plan2Align: Predictive Planning Based Test-Time Preference Alignment in\n  Paragraph-Level Machine Translation","summary":"  Machine Translation (MT) has been predominantly designed for sentence-level\ntranslation using transformer-based architectures. While next-token prediction\nbased Large Language Models (LLMs) demonstrate strong capabilities in long-text\ntranslation, non-extensive language models often suffer from omissions and\nsemantic inconsistencies when processing paragraphs. Existing preference\nalignment methods improve sentence-level translation but fail to ensure\ncoherence over extended contexts due to the myopic nature of next-token\ngeneration. We introduce Plan2Align, a test-time alignment framework that\ntreats translation as a predictive planning problem, adapting Model Predictive\nControl to iteratively refine translation outputs. Experiments on WMT24\nDiscourse-Level Literary Translation show that Plan2Align significantly\nimproves paragraph-level translation, achieving performance surpassing or on\npar with the existing training-time and test-time alignment methods on\nLLaMA-3.1 8B.\n","authors":["Kuang-Da Wang","Teng-Ruei Chen","Yu Heng Hung","Shuoyang Ding","Yueh-Hua Wu","Yu-Chiang Frank Wang","Chao-Han Huck Yang","Wen-Chih Peng","Ping-Chun Hsieh"],"pdf_url":"https://arxiv.org/pdf/2502.20795v1.pdf","comment":"Preprint. Code will be released at Plan2Align GitHub link:\n  https://github.com/NYCU-RL-Bandits-Lab/Plan2Align"},{"id":"http://arxiv.org/abs/2502.20790v1","updated":"2025-02-28T07:15:12Z","published":"2025-02-28T07:15:12Z","title":"Chain-of-Thought Matters: Improving Long-Context Language Models with\n  Reasoning Path Supervision","summary":"  Recent advances in Large Language Models (LLMs) have highlighted the\nchallenge of handling long-context tasks, where models need to reason over\nextensive input contexts to aggregate target information. While\nChain-of-Thought (CoT) prompting has shown promise for multi-step reasoning,\nits effectiveness for long-context scenarios remains underexplored. Through\nsystematic investigation across diverse tasks, we demonstrate that CoT's\nbenefits generalize across most long-context scenarios and amplify with\nincreasing context length. Motivated by this critical observation, we propose\nLongRePS, a process-supervised framework that teaches models to generate\nhigh-quality reasoning paths for enhanced long-context performance. Our\nframework incorporates a self-sampling mechanism to bootstrap reasoning paths\nand a novel quality assessment protocol specifically designed for long-context\nscenarios. Experimental results on various long-context benchmarks demonstrate\nthe effectiveness of our approach, achieving significant improvements over\noutcome supervision baselines on both in-domain tasks (+13.6/+3.8 points for\nLLaMA/Qwen on MuSiQue) and cross-domain generalization (+9.3/+8.1 points on\naverage across diverse QA tasks). Our code, data and trained models are made\npublic to facilitate future research.\n","authors":["Dawei Zhu","Xiyu Wei","Guangxiang Zhao","Wenhao Wu","Haosheng Zou","Junfeng Ran","Xun Wang","Lin Sun","Xiangzheng Zhang","Sujian Li"],"pdf_url":"https://arxiv.org/pdf/2502.20790v1.pdf","comment":"14 pages,6 figures"},{"id":"http://arxiv.org/abs/2406.03807v3","updated":"2025-02-28T07:12:21Z","published":"2024-06-06T07:30:14Z","title":"Tool-Planner: Task Planning with Clusters across Multiple Tools","summary":"  Large language models (LLMs) have demonstrated exceptional reasoning\ncapabilities, enabling them to solve various complex problems. Recently, this\nability has been applied to the paradigm of tool learning. Tool learning\ninvolves providing examples of tool usage and their corresponding functions,\nallowing LLMs to formulate plans and demonstrate the process of invoking and\nexecuting each tool. LLMs can address tasks that they cannot complete\nindependently, thereby enhancing their potential across different tasks.\nHowever, this approach faces two key challenges. First, redundant error\ncorrection leads to unstable planning and long execution time. Additionally,\ndesigning a correct plan among multiple tools is also a challenge in tool\nlearning. To address these issues, we propose Tool-Planner, a task-processing\nframework based on toolkits. Tool-Planner groups tools based on the API\nfunctions with the same function into a toolkit and allows LLMs to implement\nplanning across the various toolkits. When a tool error occurs, the language\nmodel can reselect and adjust tools based on the toolkit. Experiments show that\nour approach demonstrates a high pass and win rate across different datasets\nand optimizes the planning scheme for tool learning in models such as GPT-4 and\nClaude 3, showcasing the potential of our method. Our code is public at\nhttps://github.com/OceannTwT/Tool-Planner\n","authors":["Yanming Liu","Xinyue Peng","Jiannan Cao","Shi Bo","Yuwei Zhang","Xuhong Zhang","Sheng Cheng","Xun Wang","Jianwei Yin","Tianyu Du"],"pdf_url":"https://arxiv.org/pdf/2406.03807v3.pdf","comment":"ICLR 2025 Camera Ready version"},{"id":"http://arxiv.org/abs/2410.01671v2","updated":"2025-02-28T07:09:00Z","published":"2024-10-02T15:39:55Z","title":"Bridging Context Gaps: Leveraging Coreference Resolution for Long\n  Contextual Understanding","summary":"  Large language models (LLMs) have shown remarkable capabilities in natural\nlanguage processing; however, they still face difficulties when tasked with\nunderstanding lengthy contexts and executing effective question answering.\nThese challenges often arise due to the complexity and ambiguity present in\nlonger texts. To enhance the performance of LLMs in such scenarios, we\nintroduce the Long Question Coreference Adaptation (LQCA) method. This\ninnovative framework focuses on coreference resolution tailored to long\ncontexts, allowing the model to identify and manage references effectively. The\nLQCA method encompasses four key steps: resolving coreferences within\nsub-documents, computing the distances between mentions, defining a\nrepresentative mention for coreference, and answering questions through mention\nreplacement. By processing information systematically, the framework provides\neasier-to-handle partitions for LLMs, promoting better understanding.\nExperimental evaluations on a range of LLMs and datasets have yielded positive\nresults, with a notable improvements on OpenAI-o1-mini and GPT-4o models,\nhighlighting the effectiveness of leveraging coreference resolution to bridge\ncontext gaps in question answering. Our code is public at\nhttps://github.com/OceannTwT/LQCA.\n","authors":["Yanming Liu","Xinyue Peng","Jiannan Cao","Shi Bo","Yanxin Shen","Tianyu Du","Sheng Cheng","Xun Wang","Jianwei Yin","Xuhong Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.01671v2.pdf","comment":"ICLR 2025 camera ready version, with updated metadata"},{"id":"http://arxiv.org/abs/2502.20785v1","updated":"2025-02-28T07:06:19Z","published":"2025-02-28T07:06:19Z","title":"GraphCheck: Multi-Path Fact-Checking with Entity-Relationship Graphs","summary":"  Automated fact-checking aims to assess the truthfulness of text based on\nrelevant evidence, yet verifying complex claims requiring multi-hop reasoning\nremains a significant challenge. We propose GraphCheck, a novel framework that\nconverts claims into entity-relationship graphs for comprehensive verification.\nBy identifying relation between explicit entities and latent entities across\nmultiple paths, GraphCheck enhances the adaptability and robustness of\nverification. Furthermore, we introduce DP-GraphCheck, a two-stage variant that\nimproves performance by incorporating direct prompting as an initial filtering\nstep. Experiments on the HOVER and EX-FEVER datasets show that our approach\noutperforms existing methods, particularly in multi-hop reasoning tasks.\nFurthermore, our two-stage framework generalizes well to other fact-checking\npipelines, demonstrating its versatility.\n","authors":["Hyewon Jeon","Jay-Yoon Lee"],"pdf_url":"https://arxiv.org/pdf/2502.20785v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18514v3","updated":"2025-02-28T07:02:59Z","published":"2024-10-24T08:01:22Z","title":"Scaling up Masked Diffusion Models on Text","summary":"  Masked diffusion models (MDMs) have shown promise in language modeling, yet\ntheir scalability and effectiveness in core language tasks, such as text\ngeneration and language understanding, remain underexplored. This paper\nestablishes the first scaling law for MDMs, demonstrating a scaling rate\ncomparable to autoregressive models (ARMs) and a relatively small compute gap.\nMotivated by their scalability, we train a family of MDMs with up to 1.1\nbillion (B) parameters to systematically evaluate their performance against\nARMs of comparable or larger sizes. Fully leveraging the probabilistic\nformulation of MDMs, we propose a simple yet effective unsupervised\nclassifier-free guidance that effectively exploits large-scale unpaired data,\nboosting performance for conditional inference. In language understanding, the\n1.1B MDM outperforms the 1.1B TinyLlama model trained on the same data across\nfour of eight zero-shot benchmarks. Notably, it achieves competitive math\nreasoning ability with the 7B Llama-2 model on the GSM8K dataset. In text\ngeneration, MDMs with 16 times more pre-training time offer a flexible\ntrade-off against ARMs with the accelerated sampling technique KV-Cache: MDMs\nmatch ARMs in performance while being 1.4 times faster during sampling.\nMoreover, MDMs address challenging tasks for ARMs by effectively handling\nbidirectional reasoning and adapting to temporal shifts in data. Notably, a\n1.1B MDM breaks the reverse curse encountered by much larger ARMs with\nsignificantly more data and computation, such as 13B Llama-2 and 175B GPT-3.\nOur code is available at https://github.com/ML-GSAI/SMDM.\n","authors":["Shen Nie","Fengqi Zhu","Chao Du","Tianyu Pang","Qian Liu","Guangtao Zeng","Min Lin","Chongxuan Li"],"pdf_url":"https://arxiv.org/pdf/2410.18514v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20780v1","updated":"2025-02-28T06:59:49Z","published":"2025-02-28T06:59:49Z","title":"MedHallTune: An Instruction-Tuning Benchmark for Mitigating Medical\n  Hallucination in Vision-Language Models","summary":"  The increasing use of vision-language models (VLMs) in healthcare\napplications presents great challenges related to hallucinations, in which the\nmodels may generate seemingly plausible results that are in fact incorrect.\nSuch hallucinations can jeopardize clinical decision making, potentially\nharming the diagnosis and treatments. In this work, we propose MedHallTune, a\nlarge-scale benchmark designed specifically to evaluate and mitigate\nhallucinations in medical VLMs. Comprising over 100,000 images and 1,000,000\ninstruction pairs, MedHallTune includes both hallucination and\nnon-hallucination samples, each with ground-truth annotations. We conduct a\ncomprehensive evaluation of current medical and general VLMs using MedHallTune,\nassessing their performance across key metrics, including clinical accuracy,\nrelevance, detail level, and risk level. The experimental results show that\nfine-tuning with MedHallTune successfully improves the ability of several\nexisting models to manage hallucinations and boost their zero-shot performance\non downstream visual-question-answering (VQA) tasks, making them more reliable\nfor practical medical applications. Our work contributes to the development of\nmore trustworthy VLMs. Codes and dataset will be available at\n\\href{https://github.com/russellyq/MedHallTune}{MedHallTune}.\n","authors":["Qiao Yan","Yuchen Yuan","Xiaowei Hu","Yihan Wang","Jiaqi Xu","Jinpeng Li","Chi-Wing Fu","Pheng-Ann Heng"],"pdf_url":"https://arxiv.org/pdf/2502.20780v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20779v1","updated":"2025-02-28T06:59:04Z","published":"2025-02-28T06:59:04Z","title":"Triple Phase Transitions: Understanding the Learning Dynamics of Large\n  Language Models from a Neuroscience Perspective","summary":"  Large language models (LLMs) often exhibit abrupt emergent behavior, whereby\nnew abilities arise at certain points during their training. This phenomenon,\ncommonly referred to as a ''phase transition'', remains poorly understood. In\nthis study, we conduct an integrative analysis of such phase transitions by\nexamining three interconnected perspectives: the similarity between LLMs and\nthe human brain, the internal states of LLMs, and downstream task performance.\nWe propose a novel interpretation for the learning dynamics of LLMs that vary\nin both training data and architecture, revealing that three phase transitions\ncommonly emerge across these models during training: (1) alignment with the\nentire brain surges as LLMs begin adhering to task instructions Brain Alignment\nand Instruction Following, (2) unexpectedly, LLMs diverge from the brain during\na period in which downstream task accuracy temporarily stagnates Brain\nDetachment and Stagnation, and (3) alignment with the brain reoccurs as LLMs\nbecome capable of solving the downstream tasks Brain Realignment and\nConsolidation. These findings illuminate the underlying mechanisms of phase\ntransitions in LLMs, while opening new avenues for interdisciplinary research\nbridging AI and neuroscience.\n","authors":["Yuko Nakagi","Keigo Tada","Sota Yoshino","Shinji Nishimoto","Yu Takagi"],"pdf_url":"https://arxiv.org/pdf/2502.20779v1.pdf","comment":"46 pages"},{"id":"http://arxiv.org/abs/2502.20766v1","updated":"2025-02-28T06:34:53Z","published":"2025-02-28T06:34:53Z","title":"FlexPrefill: A Context-Aware Sparse Attention Mechanism for Efficient\n  Long-Sequence Inference","summary":"  Large language models (LLMs) encounter computational challenges during\nlong-sequence inference, especially in the attention pre-filling phase, where\nthe complexity grows quadratically with the prompt length. Previous efforts to\nmitigate these challenges have relied on fixed sparse attention patterns or\nidentifying sparse attention patterns based on limited cases. However, these\nmethods lacked the flexibility to efficiently adapt to varying input demands.\nIn this paper, we introduce FlexPrefill, a Flexible sparse Pre-filling\nmechanism that dynamically adjusts sparse attention patterns and computational\nbudget in real-time to meet the specific requirements of each input and\nattention head. The flexibility of our method is demonstrated through two key\ninnovations: 1) Query-Aware Sparse Pattern Determination: By measuring\nJensen-Shannon divergence, this component adaptively switches between\nquery-specific diverse attention patterns and predefined attention patterns. 2)\nCumulative-Attention Based Index Selection: This component dynamically selects\nquery-key indexes to be computed based on different attention patterns,\nensuring the sum of attention scores meets a predefined threshold. FlexPrefill\nadaptively optimizes the sparse pattern and sparse ratio of each attention head\nbased on the prompt, enhancing efficiency in long-sequence inference tasks.\nExperimental results show significant improvements in both speed and accuracy\nover prior methods, providing a more flexible and efficient solution for LLM\ninference.\n","authors":["Xunhao Lai","Jianqiao Lu","Yao Luo","Yiyuan Ma","Xun Zhou"],"pdf_url":"https://arxiv.org/pdf/2502.20766v1.pdf","comment":"Accepted at ICLR 2025 (Oral)"},{"id":"http://arxiv.org/abs/2502.12561v2","updated":"2025-02-28T06:28:55Z","published":"2025-02-18T05:55:18Z","title":"UXAgent: An LLM Agent-Based Usability Testing Framework for Web Design","summary":"  Usability testing is a fundamental yet challenging (e.g., inflexible to\niterate the study design flaws and hard to recruit study participants) research\nmethod for user experience (UX) researchers to evaluate a web design. Recent\nadvances in Large Language Model-simulated Agent (LLM-Agent) research inspired\nus to design UXAgent to support UX researchers in evaluating and reiterating\ntheir usability testing study design before they conduct the real human subject\nstudy. Our system features an LLM-Agent module and a universal browser\nconnector module so that UX researchers can automatically generate thousands of\nsimulated users to test the target website. The results are shown in\nqualitative (e.g., interviewing how an agent thinks ), quantitative (e.g., # of\nactions), and video recording formats for UX researchers to analyze. Through a\nheuristic user evaluation with five UX researchers, participants praised the\ninnovation of our system but also expressed concerns about the future of LLM\nAgent-assisted UX study.\n","authors":["Yuxuan Lu","Bingsheng Yao","Hansu Gu","Jing Huang","Jessie Wang","Laurence Li","Jiri Gesi","Qi He","Toby Jia-Jun Li","Dakuo Wang"],"pdf_url":"https://arxiv.org/pdf/2502.12561v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20758v1","updated":"2025-02-28T06:20:52Z","published":"2025-02-28T06:20:52Z","title":"Collective Reasoning Among LLMs A Framework for Answer Validation\n  Without Ground Truth","summary":"  We present a collaborative framework where multiple large language models,\nnamely GPT-4-0125-preview, Meta-LLaMA-3-70B-Instruct, Claude-3-Opus, and\nGemini-1.5-Flash, work together to generate and respond to complex PhD-level\nprobability questions in the absence of definitive ground truth. This study\nexplores how inter-model consensus enhances response reliability and serves as\na proxy for assessing the quality of generated questions. To quantify agreement\nand consistency, we employ statistical methods including chi-square tests,\nFleiss' Kappa, and confidence interval analysis, measuring both response\nprecision and question clarity. Our findings highlight that Claude and Gemini\ngenerate well-structured and less ambiguous questions, leading to higher\ninter-model agreement. This is reflected in their narrower confidence intervals\nand stronger alignment with answering models. Conversely, LLaMA demonstrates\nincreased variability and lower reliability in question formulation, as\nindicated by broader confidence intervals and reduced consensus rates. These\nresults suggest that multi-model collaboration not only enhances the\nreliability of responses but also provides a valuable framework for assessing\nand improving question quality in the absence of explicit ground truth. This\nresearch offers meaningful insights into optimizing AI-driven reasoning through\ncollaborative large-language model interactions.\n","authors":["Seyed Pouyan Mousavi Davoudi","Alireza Shafiee Fard","Alireza Amiri-Margavi"],"pdf_url":"https://arxiv.org/pdf/2502.20758v1.pdf","comment":"14 pages, 2 figures. arXiv admin note: substantial text overlap with\n  arXiv:2411.16797"},{"id":"http://arxiv.org/abs/2502.20757v1","updated":"2025-02-28T06:18:50Z","published":"2025-02-28T06:18:50Z","title":"The Rise of Darkness: Safety-Utility Trade-Offs in Role-Playing Dialogue\n  Agents","summary":"  Large Language Models (LLMs) have made remarkable advances in role-playing\ndialogue agents, demonstrating their utility in character simulations. However,\nit remains challenging for these agents to balance character portrayal utility\nwith content safety because this essential character simulation often comes\nwith the risk of generating unsafe content. To address this issue, we first\nconduct a systematic exploration of the safety-utility trade-off across\nmultiple LLMs. Our analysis reveals that risk scenarios created by villain\ncharacters and user queries (referred to as risk coupling) contribute to this\ntrade-off. Building on this, we propose a novel Adaptive Dynamic\nMulti-Preference (ADMP) method, which dynamically adjusts safety-utility\npreferences based on the degree of risk coupling and guides the model to\ngenerate responses biased toward utility or safety. We further introduce\nCoupling Margin Sampling (CMS) into coupling detection to enhance the model's\nability to handle high-risk scenarios. Experimental results demonstrate that\nour approach improves safety metrics while maintaining utility.\n","authors":["Yihong Tang","Kehai Chen","Xuefeng Bai","Zhengyu Niu","Bo Wang","Jie Liu","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2502.20757v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12662v2","updated":"2025-02-28T06:17:41Z","published":"2024-10-16T15:20:08Z","title":"Cross-Modal Safety Mechanism Transfer in Large Vision-Language Models","summary":"  Vision-language alignment in Large Vision-Language Models (LVLMs)\nsuccessfully enables LLMs to understand visual input. However, we find that\nexisting vision-language alignment methods fail to transfer the existing safety\nmechanism for text in LLMs to vision, which leads to vulnerabilities in toxic\nimage. To explore the cause of this problem, we give the insightful explanation\nof where and how the safety mechanism of LVLMs operates and conduct comparative\nanalysis between text and vision. We find that the hidden states at the\nspecific transformer layers play a crucial role in the successful activation of\nsafety mechanism, while the vision-language alignment at hidden states level in\ncurrent methods is insufficient. This results in a semantic shift for input\nimages compared to text in hidden states, therefore misleads the safety\nmechanism. To address this, we propose a novel Text-Guided vision-language\nAlignment method (TGA) for LVLMs. TGA retrieves the texts related to input\nvision and uses them to guide the projection of vision into the hidden states\nspace in LLMs. Experiments show that TGA not only successfully transfers the\nsafety mechanism for text in basic LLMs to vision in vision-language alignment\nfor LVLMs without any safety fine-tuning on the visual modality but also\nmaintains the general performance on various vision tasks (Safe and Good).\n","authors":["Shicheng Xu","Liang Pang","Yunchang Zhu","Huawei Shen","Xueqi Cheng"],"pdf_url":"https://arxiv.org/pdf/2410.12662v2.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2502.20754v1","updated":"2025-02-28T06:04:52Z","published":"2025-02-28T06:04:52Z","title":"Acquiring Grounded Representations of Words with Situated Interactive\n  Instruction","summary":"  We present an approach for acquiring grounded representations of words from\nmixed-initiative, situated interactions with a human instructor. The work\nfocuses on the acquisition of diverse types of knowledge including perceptual,\nsemantic, and procedural knowledge along with learning grounded meanings.\nInteractive learning allows the agent to control its learning by requesting\ninstructions about unknown concepts, making learning efficient. Our approach\nhas been instantiated in Soar and has been evaluated on a table-top robotic arm\ncapable of manipulating small objects.\n","authors":["Shiwali Mohan","Aaron H. Mininger","James R. Kirk","John E. Laird"],"pdf_url":"https://arxiv.org/pdf/2502.20754v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20750v1","updated":"2025-02-28T05:56:23Z","published":"2025-02-28T05:56:23Z","title":"Mitigating Hallucinations in Large Vision-Language Models by Adaptively\n  Constraining Information Flow","summary":"  Large vision-language models show tremendous potential in understanding\nvisual information through human languages. However, they are prone to suffer\nfrom object hallucination, i.e., the generated image descriptions contain\nobjects that do not exist in the image. In this paper, we reveal that object\nhallucination can be attributed to overconfidence in irrelevant visual features\nwhen soft visual tokens map to the LLM's word embedding space. Specifically, by\nfiguring out the semantic similarity between visual tokens and LLM's word\nembedding, we observe that the smoothness of similarity distribution strongly\ncorrelates with the emergence of object hallucinations. To mitigate\nhallucinations, we propose using the Variational Information Bottleneck (VIB)\nto alleviate overconfidence by introducing stochastic noise, facilitating the\nconstraining of irrelevant information. Furthermore, we propose an\nentropy-based noise-controlling strategy to enable the injected noise to be\nadaptively constrained regarding the smoothness of the similarity distribution.\nWe adapt the proposed AdaVIB across distinct model architectures. Experimental\nresults demonstrate that the proposed AdaVIB mitigates object hallucinations by\neffectively alleviating the overconfidence in irrelevant visual features, with\nconsistent improvements on two object hallucination benchmarks.\n","authors":["Jiaqi Bai","Hongcheng Guo","Zhongyuan Peng","Jian Yang","Zhoujun Li","Mohan Li","Zhihong Tian"],"pdf_url":"https://arxiv.org/pdf/2502.20750v1.pdf","comment":"Accepted to AAAI 2025. Camera ready version"},{"id":"http://arxiv.org/abs/2502.20748v1","updated":"2025-02-28T05:54:23Z","published":"2025-02-28T05:54:23Z","title":"Teach-to-Reason with Scoring: Self-Explainable Rationale-Driven\n  Multi-Trait Essay Scoring","summary":"  Multi-trait automated essay scoring (AES) systems provide a fine-grained\nevaluation of an essay's diverse aspects. While they excel in scoring, prior\nsystems fail to explain why specific trait scores are assigned. This lack of\ntransparency leaves instructors and learners unconvinced of the AES outputs,\nhindering their practical use. To address this, we propose a self-explainable\nRationale-Driven Multi-trait automated Essay scoring (RaDME) framework. RaDME\nleverages the reasoning capabilities of large language models (LLMs) by\ndistilling them into a smaller yet effective scorer. This more manageable\nstudent model is optimized to sequentially generate a trait score followed by\nthe corresponding rationale, thereby inherently learning to select a more\njustifiable score by considering the subsequent rationale during training. Our\nfindings indicate that while LLMs underperform in direct AES tasks, they excel\nin rationale generation when provided with precise numerical scores. Thus,\nRaDME integrates the superior reasoning capacities of LLMs into the robust\nscoring accuracy of an optimized smaller model. Extensive experiments\ndemonstrate that RaDME achieves both accurate and adequate reasoning while\nsupporting high-quality multi-trait scoring, significantly enhancing the\ntransparency of AES.\n","authors":["Heejin Do","Sangwon Ryu","Gary Geunbae Lee"],"pdf_url":"https://arxiv.org/pdf/2502.20748v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20742v1","updated":"2025-02-28T05:47:34Z","published":"2025-02-28T05:47:34Z","title":"Structured Preference Optimization for Vision-Language Long-Horizon Task\n  Planning","summary":"  Existing methods for vision-language task planning excel in short-horizon\ntasks but often fall short in complex, long-horizon planning within dynamic\nenvironments. These challenges primarily arise from the difficulty of\neffectively training models to produce high-quality reasoning processes for\nlong-horizon tasks. To address this, we propose Structured Preference\nOptimization (SPO), which aims to enhance reasoning and action selection in\nlong-horizon task planning through structured preference evaluation and\noptimized training strategies. Specifically, SPO introduces: 1)\nPreference-Based Scoring and Optimization, which systematically evaluates\nreasoning chains based on task relevance, visual grounding, and historical\nconsistency; and 2) Curriculum-Guided Training, where the model progressively\nadapts from simple to complex tasks, improving its generalization ability in\nlong-horizon scenarios and enhancing reasoning robustness. To advance research\nin vision-language long-horizon task planning, we introduce ExtendaBench, a\ncomprehensive benchmark covering 1,509 tasks across VirtualHome and Habitat\n2.0, categorized into ultra-short, short, medium, and long tasks. Experimental\nresults demonstrate that SPO significantly improves reasoning quality and final\ndecision accuracy, outperforming prior methods on long-horizon tasks and\nunderscoring the effectiveness of preference-driven optimization in\nvision-language task planning. Specifically, SPO achieves a +5.98% GCR and\n+4.68% SR improvement in VirtualHome and a +3.30% GCR and +2.11% SR improvement\nin Habitat over the best-performing baselines.\n","authors":["Xiwen Liang","Min Lin","Weiqi Ruan","Rongtao Xu","Yuecheng Liu","Jiaqi Chen","Bingqian Lin","Yuzheng Zhuang","Xiaodan Liang"],"pdf_url":"https://arxiv.org/pdf/2502.20742v1.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2402.00234v2","updated":"2025-02-28T05:46:53Z","published":"2024-01-31T23:24:37Z","title":"Can Generative AI Support Patients' & Caregivers' Informational Needs?\n  Towards Task-Centric Evaluation Of AI Systems","summary":"  Generative AI systems such as ChatGPT and Claude are built upon language\nmodels that are typically evaluated for accuracy on curated benchmark datasets.\nSuch evaluation paradigms measure predictive and reasoning capabilities of\nlanguage models but do not assess if they can provide information that is\nuseful to people. In this paper, we take some initial steps in developing an\nevaluation paradigm that centers human understanding and decision-making. We\nstudy the utility of generative AI systems in supporting people in a concrete\ntask - making sense of clinical reports and imagery in order to make a clinical\ndecision. We conducted a formative need-finding study in which participants\ndiscussed chest computed tomography (CT) scans and associated radiology reports\nof a fictitious close relative with a cardiothoracic radiologist. Using\nthematic analysis of the conversation between participants and medical experts,\nwe identified commonly occurring themes across interactions, including\nclarifying medical terminology, locating the problems mentioned in the report\nin the scanned image, understanding disease prognosis, discussing the next\ndiagnostic steps, and comparing treatment options. Based on these themes, we\nevaluated two state-of-the-art generative AI systems against the radiologist's\nresponses. Our results reveal variability in the quality of responses generated\nby the models across various themes. We highlight the importance of\npatient-facing generative AI systems to accommodate a diverse range of\nconversational themes, catering to the real-world informational needs of\npatients.\n","authors":["Shreya Rajagopal","Jae Ho Sohn","Hari Subramonyam","Shiwali Mohan"],"pdf_url":"https://arxiv.org/pdf/2402.00234v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06071v2","updated":"2025-02-28T05:46:45Z","published":"2024-12-08T21:26:22Z","title":"KaSA: Knowledge-Aware Singular-Value Adaptation of Large Language Models","summary":"  The increasing sizes of large language models (LLMs) result in significant\ncomputational overhead and memory usage when adapting these models to specific\ntasks or domains. Various parameter-efficient fine-tuning (PEFT) methods have\nbeen devised to mitigate these challenges by training a small set of parameters\nfor the task-specific updates of the model weights. Among PEFT methods, LoRA\nstands out for its simplicity and efficiency, inspiring the development of a\nseries of variants. However, LoRA and its successors disregard the knowledge\nthat is noisy or irrelevant to the targeted task, detrimentally impacting model\nperformance and leading to suboptimality. To address this limitation, we\nintroduce Knowledge-aware Singular-value Adaptation (KaSA), a PEFT method that\nleverages singular value decomposition (SVD) with knowledge-aware singular\nvalues to dynamically activate knowledge based on its relevance to the task at\nhand. We conduct extensive experiments across a range of LLMs on tasks spanning\nnatural language understanding (NLU), generation (NLG), instruction following,\nand commonsense reasoning. The experimental results demonstrate that KaSA\nconsistently outperforms FFT and 14 popular PEFT baselines across 16 benchmarks\nand 4 synthetic datasets, underscoring our method's efficacy and adaptability.\nThe source code of our method is available at\nhttps://github.com/juyongjiang/KaSA.\n","authors":["Fan Wang","Juyong Jiang","Chansung Park","Sunghun Kim","Jing Tang"],"pdf_url":"https://arxiv.org/pdf/2412.06071v2.pdf","comment":"The first three authors contributed equally to this work; Accepted by\n  ICLR 2025"},{"id":"http://arxiv.org/abs/2502.20726v1","updated":"2025-02-28T05:19:18Z","published":"2025-02-28T05:19:18Z","title":"Retrieval Backward Attention without Additional Training: Enhance\n  Embeddings of Large Language Models via Repetition","summary":"  Language models can be viewed as functions that embed text into Euclidean\nspace, where the quality of the embedding vectors directly determines model\nperformance, training such neural networks involves various uncertainties. This\npaper focuses on improving the performance of pre-trained language models in\nzero-shot settings through a simple and easily implementable method. We propose\na novel backward attention mechanism to enhance contextual information\nencoding. Evaluated on the Chinese Massive Text Embedding Benchmark (C-MTEB),\nour approach achieves significant improvements across multiple tasks, providing\nvaluable insights for advancing zero-shot learning capabilities.\n","authors":["Yifei Duan","Raphael Shang","Deng Liang","Yongqiang Cai"],"pdf_url":"https://arxiv.org/pdf/2502.20726v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.06617v5","updated":"2025-02-28T04:37:07Z","published":"2024-10-09T07:14:45Z","title":"Learning Evolving Tools for Large Language Models","summary":"  Tool learning enables large language models (LLMs) to interact with external\ntools and APIs, greatly expanding the application scope of LLMs. However, due\nto the dynamic nature of external environments, these tools and APIs may become\noutdated over time, preventing LLMs from correctly invoking tools. Existing\nresearch primarily focuses on static environments and overlooks this issue,\nlimiting the adaptability of LLMs in real-world applications. In this paper, we\npropose ToolEVO, a novel framework designed to enhance the adaptive and\nreflective capabilities of LLMs against tool variability. By leveraging Monte\nCarlo Tree Search, ToolEVO facilitates active exploration and interaction of\nLLMs within dynamic environments, allowing for autonomous self-reflection and\nself-updating of tool usage based on environmental feedback. Additionally, we\nintroduce ToolQA-D, a benchmark specifically designed to evaluate the impact of\ntool variability. Extensive experiments demonstrate the effectiveness and\nstability of our approach, highlighting the importance of adaptability to tool\nvariability for effective tool learning. Code:\nhttps://github.com/Chen-GX/ToolEVO\n","authors":["Guoxin Chen","Zhong Zhang","Xin Cong","Fangda Guo","Yesai Wu","Yankai Lin","Wenzheng Feng","Yasheng Wang"],"pdf_url":"https://arxiv.org/pdf/2410.06617v5.pdf","comment":"Camera ready version for ICLR 2025"},{"id":"http://arxiv.org/abs/2502.18860v2","updated":"2025-02-28T04:18:19Z","published":"2025-02-26T06:05:29Z","title":"Exploring Rewriting Approaches for Different Conversational Tasks","summary":"  Conversational assistants often require a question rewriting algorithm that\nleverages a subset of past interactions to provide a more meaningful (accurate)\nanswer to the user's question or request. However, the exact rewriting approach\nmay often depend on the use case and application-specific tasks supported by\nthe conversational assistant, among other constraints. In this paper, we\nsystematically investigate two different approaches, denoted as rewriting and\nfusion, on two fundamentally different generation tasks, including a\ntext-to-text generation task and a multimodal generative task that takes as\ninput text and generates a visualization or data table that answers the user's\nquestion. Our results indicate that the specific rewriting or fusion approach\nhighly depends on the underlying use case and generative task. In particular,\nwe find that for a conversational question-answering assistant, the query\nrewriting approach performs best, whereas for a data analysis assistant that\ngenerates visualizations and data tables based on the user's conversation with\nthe assistant, the fusion approach works best. Notably, we explore two datasets\nfor the data analysis assistant use case, for short and long conversations, and\nwe find that query fusion always performs better, whereas for the\nconversational text-based question-answering, the query rewrite approach\nperforms best.\n","authors":["Md Mehrab Tanjim","Ryan A. Rossi","Mike Rimer","Xiang Chen","Sungchul Kim","Vaishnavi Muppala","Tong Yu","Zhengmian Hu","Ritwik Sinha","Wei Zhang","Iftikhar Ahamath Burhanuddin","Franck Dernoncourt"],"pdf_url":"https://arxiv.org/pdf/2502.18860v2.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2502.19820v2","updated":"2025-02-28T04:11:47Z","published":"2025-02-27T06:49:16Z","title":"Foot-In-The-Door: A Multi-turn Jailbreak for LLMs","summary":"  Ensuring AI safety is crucial as large language models become increasingly\nintegrated into real-world applications. A key challenge is jailbreak, where\nadversarial prompts bypass built-in safeguards to elicit harmful disallowed\noutputs. Inspired by psychological foot-in-the-door principles, we introduce\nFITD,a novel multi-turn jailbreak method that leverages the phenomenon where\nminor initial commitments lower resistance to more significant or more\nunethical transgressions. Our approach progressively escalates the malicious\nintent of user queries through intermediate bridge prompts and aligns the\nmodel's response by itself to induce toxic responses. Extensive experimental\nresults on two jailbreak benchmarks demonstrate that FITD achieves an average\nattack success rate of 94% across seven widely used models, outperforming\nexisting state-of-the-art methods. Additionally, we provide an in-depth\nanalysis of LLM self-corruption, highlighting vulnerabilities in current\nalignment strategies and emphasizing the risks inherent in multi-turn\ninteractions. The code is available at\nhttps://github.com/Jinxiaolong1129/Foot-in-the-door-Jailbreak.\n","authors":["Zixuan Weng","Xiaolong Jin","Jinyuan Jia","Xiangyu Zhang"],"pdf_url":"https://arxiv.org/pdf/2502.19820v2.pdf","comment":"19 pages, 8 figures"},{"id":"http://arxiv.org/abs/2502.20689v1","updated":"2025-02-28T03:45:39Z","published":"2025-02-28T03:45:39Z","title":"ProAI: Proactive Multi-Agent Conversational AI with Structured Knowledge\n  Base for Psychiatric Diagnosis","summary":"  Most LLM-driven conversational AI systems operate reactively, responding to\nuser prompts without guiding the interaction. Most LLM-driven conversational AI\nsystems operate reactively, responding to user prompts without guiding the\ninteraction. However, many real-world applications-such as psychiatric\ndiagnosis, consulting, and interviews-require AI to take a proactive role,\nasking the right questions and steering conversations toward specific\nobjectives. Using mental health differential diagnosis as an application\ncontext, we introduce ProAI, a goal-oriented, proactive conversational AI\nframework. ProAI integrates structured knowledge-guided memory, multi-agent\nproactive reasoning, and a multi-faceted evaluation strategy, enabling LLMs to\nengage in clinician-style diagnostic reasoning rather than simple response\ngeneration. Through simulated patient interactions, user experience assessment,\nand professional clinical validation, we demonstrate that ProAI achieves up to\n83.3% accuracy in mental disorder differential diagnosis while maintaining\nprofessional and empathetic interaction standards. These results highlight the\npotential for more reliable, adaptive, and goal-driven AI diagnostic\nassistants, advancing LLMs beyond reactive dialogue systems.\n","authors":["Yuqi Wu","Guangya Wan","Jingjing Li","Shengming Zhao","Lingfeng Ma","Tianyi Ye","Ion Pop","Yanbo Zhang","Jie Chen"],"pdf_url":"https://arxiv.org/pdf/2502.20689v1.pdf","comment":"21 pages, 8 figures"},{"id":"http://arxiv.org/abs/2502.18968v2","updated":"2025-02-28T03:41:20Z","published":"2025-02-26T09:26:54Z","title":"Know You First and Be You Better: Modeling Human-Like User Simulators\n  via Implicit Profiles","summary":"  User simulators are crucial for replicating human interactions with dialogue\nsystems, supporting both collaborative training and automatic evaluation,\nespecially for large language models (LLMs). However, existing simulators often\nrely solely on text utterances, missing implicit user traits such as\npersonality, speaking style, and goals. In contrast, persona-based methods lack\ngeneralizability, as they depend on predefined profiles of famous individuals\nor archetypes. To address these challenges, we propose User Simulator with\nimplicit Profiles (USP), a framework that infers implicit user profiles from\nhuman-machine conversations and uses them to generate more personalized and\nrealistic dialogues. We first develop an LLM-driven extractor with a\ncomprehensive profile schema. Then, we refine the simulation through\nconditional supervised fine-tuning and reinforcement learning with cycle\nconsistency, optimizing it at both the utterance and conversation levels.\nFinally, we adopt a diverse profile sampler to capture the distribution of\nreal-world user profiles. Experimental results demonstrate that USP outperforms\nstrong baselines in terms of authenticity and diversity while achieving\ncomparable performance in consistency. Furthermore, dynamic multi-turn\nevaluations based on USP strongly align with mainstream benchmarks,\ndemonstrating its effectiveness in real-world applications.\n","authors":["Kuang Wang","Xianfei Li","Shenghao Yang","Li Zhou","Feng Jiang","Haizhou Li"],"pdf_url":"https://arxiv.org/pdf/2502.18968v2.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2411.00418v2","updated":"2025-02-28T03:37:09Z","published":"2024-11-01T07:29:03Z","title":"Self-Evolved Reward Learning for LLMs","summary":"  Reinforcement Learning from Human Feedback (RLHF) is a crucial technique for\naligning language models with human preferences, playing a pivotal role in the\nsuccess of conversational models like GPT-4, ChatGPT, and Llama 2. A core\nchallenge in employing RLHF lies in training a reliable reward model (RM),\nwhich relies on high-quality labels typically provided by human experts or\nadvanced AI system. These methods can be costly and may introduce biases that\naffect the language model's responses. As language models improve, human input\nmay become less effective in further enhancing their performance. In this\npaper, we propose Self-Evolved Reward Learning (SER), a novel approach where\nthe RM generates additional training data to iteratively improve itself. We\nconducted extensive experiments on multiple datasets such as HH-RLHF and\nUltraFeedback, using models like Mistral and Llama 3, and compare SER against\nvarious baselines. Our results demonstrate that even with limited\nhuman-annotated data, learning from self-feedback can robustly enhance RM\nperformance, thereby boosting the capabilities of large language models (LLMs).\n","authors":["Chenghua Huang","Zhizhen Fan","Lu Wang","Fangkai Yang","Pu Zhao","Zeqi Lin","Qingwei Lin","Dongmei Zhang","Saravan Rajmohan","Qi Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.00418v2.pdf","comment":"23 pages,6 figures,Accepted to ICLR 2025"},{"id":"http://arxiv.org/abs/2502.20684v1","updated":"2025-02-28T03:31:48Z","published":"2025-02-28T03:31:48Z","title":"JAM: Controllable and Responsible Text Generation via Causal Reasoning\n  and Latent Vector Manipulation","summary":"  While large language models (LLMs) have made significant strides in\ngenerating coherent and contextually relevant text, they often function as\nopaque black boxes, trained on vast unlabeled datasets with statistical\nobjectives, lacking an interpretable framework for responsible control. In this\npaper, we introduce JAM (Just A Move), a novel framework that interprets and\ncontrols text generation by integrating cause-effect analysis within the latent\nspace of LLMs. Based on our observations, we uncover the inherent causality in\nLLM generation, which is critical for producing responsible and realistic\noutputs. Moreover, we explore latent vectors as fundamental components in LLM\narchitectures, aiming to understand and manipulate them for more effective and\nefficient controllable text generation. We evaluate our framework using a range\nof tools, including the HHH criteria, toxicity reduction benchmarks, and GPT-4\nalignment measures. Our results show that JAM achieves up to a 22% improvement\nover previous Controllable Text Generation (CTG) methods across multiple\nquantitative metrics and human-centric evaluations. Furthermore, JAM\ndemonstrates greater computational efficiency compared to other CTG methods.\nThese results highlight the effectiveness and efficiency of JAM for responsible\nand realistic text generation, paving the way for more interpretable and\ncontrollable models.\n","authors":["Yingbing Huang","Deming Chen","Abhishek K. Umrawal"],"pdf_url":"https://arxiv.org/pdf/2502.20684v1.pdf","comment":"10 pages, 3 figures, and 6 tables"},{"id":"http://arxiv.org/abs/2502.20682v1","updated":"2025-02-28T03:30:48Z","published":"2025-02-28T03:30:48Z","title":"Fine-tuning BERT with Bidirectional LSTM for Fine-grained Movie Reviews\n  Sentiment Analysis","summary":"  Sentiment Analysis (SA) is instrumental in understanding peoples viewpoints\nfacilitating social media monitoring recognizing products and brands and\ngauging customer satisfaction. Consequently SA has evolved into an active\nresearch domain within Natural Language Processing (NLP). Many approaches\noutlined in the literature devise intricate frameworks aimed at achieving high\naccuracy, focusing exclusively on either binary sentiment classification or\nfine-grained sentiment classification. In this paper our objective is to\nfine-tune the pre-trained BERT model with Bidirectional LSTM (BiLSTM) to\nenhance both binary and fine-grained SA specifically for movie reviews. Our\napproach involves conducting sentiment classification for each review followed\nby computing the overall sentiment polarity across all reviews. We present our\nfindings on binary classification as well as fine-grained classification\nutilizing benchmark datasets. Additionally we implement and assess two accuracy\nimprovement techniques Synthetic Minority Oversampling Technique (SMOTE) and\nNLP Augmenter (NLPAUG) to bolster the models generalization in fine-grained\nsentiment classification. Finally a heuristic algorithm is employed to\ncalculate the overall polarity of predicted reviews from the BERT+BiLSTM output\nvector. Our approach performs comparably with state-of-the-art (SOTA)\ntechniques in both classifications. For instance in binary classification we\nachieve 97.67% accuracy surpassing the leading SOTA model\nNB-weighted-BON+dv-cosine by 0.27% on the renowned IMDb dataset. Conversely for\nfive-class classification on SST-5 while the top SOTA model\nRoBERTa+large+Self-explaining attains 55.5% accuracy our model achieves 59.48%\naccuracy surpassing the BERT-large baseline by 3.6%.\n","authors":["Gibson Nkhata","Susan Gauch","Usman Anjum","Justin Zhan"],"pdf_url":"https://arxiv.org/pdf/2502.20682v1.pdf","comment":"14 pages, 5 figures, published in International Journal On Advances\n  in Systems and Measurements, volume 16, numbers 3 and 4, 2023"},{"id":"http://arxiv.org/abs/2502.20681v1","updated":"2025-02-28T03:27:24Z","published":"2025-02-28T03:27:24Z","title":"Disentangling Feature Structure: A Mathematically Provable Two-Stage\n  Training Dynamics in Transformers","summary":"  Transformers may exhibit two-stage training dynamics during the real-world\ntraining process. For instance, when training GPT-2 on the Counterfact dataset,\nthe answers progress from syntactically incorrect to syntactically correct to\nsemantically correct. However, existing theoretical analyses hardly account for\nthis two-stage phenomenon. In this paper, we theoretically demonstrate how such\ntwo-stage training dynamics occur in transformers. Specifically, we analyze the\ndynamics of transformers using feature learning techniques under in-context\nlearning regimes, based on a disentangled two-type feature structure. Such\ndisentanglement of feature structure is general in practice, e.g., natural\nlanguages contain syntax and semantics, and proteins contain primary and\nsecondary structures. To our best known, this is the first rigorous result\nregarding a two-stage optimization process in transformers. Additionally, a\ncorollary indicates that such a two-stage process is closely related to the\nspectral properties of the attention weights, which accords well with empirical\nfindings.\n","authors":["Zixuan Gong","Jiaye Teng","Yong Liu"],"pdf_url":"https://arxiv.org/pdf/2502.20681v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.00944v3","updated":"2025-02-28T03:23:52Z","published":"2024-06-03T02:56:14Z","title":"A Theory for Token-Level Harmonization in Retrieval-Augmented Generation","summary":"  Retrieval-augmented generation (RAG) utilizes retrieved texts to enhance\nlarge language models (LLMs). Studies show that while RAG provides valuable\nexternal information (benefit), it may also mislead LLMs (detriment) with noisy\nor incorrect retrieved texts. Although many existing methods attempt to\npreserve benefit and avoid detriment, they lack a theoretical explanation for\nRAG. The benefit and detriment in the next token prediction of RAG remain a\nblack box that cannot be quantified or compared in an explainable manner, so\nexisting methods are data-driven, need additional utility evaluators or\npost-hoc. This paper takes the first step towards providing a theory to explain\nand trade off the benefit and detriment in RAG. First, we model RAG as the\nfusion between distribution of LLMs knowledge and distribution of retrieved\ntexts. Then, we formalize the trade-off between the value of external knowledge\n(benefit) and its potential risk of misleading LLMs (detriment) in next token\nprediction of RAG by distribution difference in this fusion. Finally, we prove\nthat the actual effect of RAG on the token, which is the comparison between\nbenefit and detriment, can be predicted without any training or accessing the\nutility of retrieval. Based on our theory, we propose a practical novel method,\nTok-RAG, which achieves collaborative generation between the pure LLM and RAG\nat token level to preserve benefit and avoid detriment. Experiments in\nreal-world tasks using LLMs such as OPT, LLaMA-2, and Mistral show the\neffectiveness of our method and support our theoretical findings.\n","authors":["Shicheng Xu","Liang Pang","Huawei Shen","Xueqi Cheng"],"pdf_url":"https://arxiv.org/pdf/2406.00944v3.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2412.14613v2","updated":"2025-02-28T03:04:05Z","published":"2024-12-19T08:03:16Z","title":"Multi-modal, Multi-task, Multi-criteria Automatic Evaluation with Vision\n  Language Models","summary":"  Vision-language models (VLMs) have shown impressive abilities across a range\nof multi-modal tasks. However, existing metrics for evaluating the quality of\ntext generated by VLMs typically focus on an overall evaluation for a specific\ntask, such as image captioning. While the overall evaluation is essential for\nany task, the criteria prioritized can differ depending on the task, making it\nchallenging for current metrics to adapt to multi-task scenarios. To address\nthis limitation, we propose HarmonicEval, a reference-free comprehensive\nevaluation metric that aggregates criterion-wise scores to produce the overall\nscore in a bottom-up manner. Furthermore, we construct the Multi-task\nMulti-criteria Human Evaluation (MMHE) dataset, which comprises 18,000 expert\nhuman judgments across four multi-modal tasks. Our experiments demonstrate that\nHarmonicEval achieves higher correlations with human judgments than\nconventional metrics while providing numerical scores for each criterion.\n","authors":["Masanari Ohi","Masahiro Kaneko","Naoaki Okazaki","Nakamasa Inoue"],"pdf_url":"https://arxiv.org/pdf/2412.14613v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20663v1","updated":"2025-02-28T02:42:13Z","published":"2025-02-28T02:42:13Z","title":"Prediction of Item Difficulty for Reading Comprehension Items by\n  Creation of Annotated Item Repository","summary":"  Prediction of item difficulty based on its text content is of substantial\ninterest. In this paper, we focus on the related problem of recovering\nIRT-based difficulty when the data originally reported item p-value (percent\ncorrect responses). We model this item difficulty using a repository of reading\npassages and student data from US standardized tests from New York and Texas\nfor grades 3-8 spanning the years 2017-23. This repository is annotated with\nmeta-data on (1) linguistic features of the reading items, (2) test features of\nthe passage, and (3) context features. A penalized regression prediction model\nwith all these features can predict item difficulty with RMSE 0.52 compared to\nbaseline RMSE of 0.92, and with a correlation of 0.77 between true and\npredicted difficulty. We supplement these features with embeddings from LLMs\n(ModernBERT, BERT, and LlAMA), which marginally improve item difficulty\nprediction. When models use only item linguistic features or LLM embeddings,\nprediction performance is similar, which suggests that only one of these\nfeature categories may be required. This item difficulty prediction model can\nbe used to filter and categorize reading items and will be made publicly\navailable for use by other stakeholders.\n","authors":["Radhika Kapoor","Sang T. Truong","Nick Haber","Maria Araceli Ruiz-Primo","Benjamin W. Domingue"],"pdf_url":"https://arxiv.org/pdf/2502.20663v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04847v2","updated":"2025-02-28T02:41:06Z","published":"2024-11-07T16:33:48Z","title":"Prompt-Guided Internal States for Hallucination Detection of Large\n  Language Models","summary":"  Large Language Models (LLMs) have demonstrated remarkable capabilities across\na variety of tasks in different domains. However, they sometimes generate\nresponses that are logically coherent but factually incorrect or misleading,\nwhich is known as LLM hallucinations. Data-driven supervised methods train\nhallucination detectors by leveraging the internal states of LLMs, but\ndetectors trained on specific domains often struggle to generalize well to\nother domains. In this paper, we aim to enhance the cross-domain performance of\nsupervised detectors with only in-domain data. We propose a novel framework,\nprompt-guided internal states for hallucination detection of LLMs, namely\nPRISM. By utilizing appropriate prompts to guide changes to the structure\nrelated to text truthfulness in LLMs' internal states, we make this structure\nmore salient and consistent across texts from different domains. We integrated\nour framework with existing hallucination detection methods and conducted\nexperiments on datasets from different domains. The experimental results\nindicate that our framework significantly enhances the cross-domain\ngeneralization of existing hallucination detection methods.\n","authors":["Fujie Zhang","Peiqi Yu","Biao Yi","Baolei Zhang","Tong Li","Zheli Liu"],"pdf_url":"https://arxiv.org/pdf/2411.04847v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.01790v2","updated":"2025-02-28T02:40:58Z","published":"2024-09-03T11:09:44Z","title":"Training on the Benchmark Is Not All You Need","summary":"  The success of Large Language Models (LLMs) relies heavily on the huge amount\nof pre-training data learned in the pre-training phase. The opacity of the\npre-training process and the training data causes the results of many benchmark\ntests to become unreliable. If any model has been trained on a benchmark test\nset, it can seriously hinder the health of the field. In order to automate and\nefficiently test the capabilities of large language models, numerous mainstream\nbenchmarks adopt a multiple-choice format. As the swapping of the contents of\nmultiple-choice options does not affect the meaning of the question itself, we\npropose a simple and effective data leakage detection method based on this\nproperty. Specifically, we shuffle the contents of the options in the data to\ngenerate the corresponding derived data sets, and then detect data leakage\nbased on the model's log probability distribution over the derived data sets.\nIf there is a maximum and outlier in the set of log probabilities, it indicates\nthat the data is leaked. Our method is able to work under gray-box conditions\nwithout access to model training data or weights, effectively identifying data\nleakage from benchmark test sets in model pre-training data, including both\nnormal scenarios and complex scenarios where options may have been shuffled\nintentionally or unintentionally. Through experiments based on two LLMs and\nbenchmark designs, we demonstrate the effectiveness of our method. In addition,\nwe evaluate the degree of data leakage of 35 mainstream open-source LLMs on\nfour benchmark datasets and give a ranking of the leaked LLMs for each\nbenchmark, and we find that the Qwen family of LLMs has the highest degree of\ndata leakage.\n","authors":["Shiwen Ni","Xiangtao Kong","Chengming Li","Xiping Hu","Ruifeng Xu","Jia Zhu","Min Yang"],"pdf_url":"https://arxiv.org/pdf/2409.01790v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20657v1","updated":"2025-02-28T02:23:06Z","published":"2025-02-28T02:23:06Z","title":"Automatic database description generation for Text-to-SQL","summary":"  In the context of the Text-to-SQL task, table and column descriptions are\ncrucial for bridging the gap between natural language and database schema. This\nreport proposes a method for automatically generating effective database\ndescriptions when explicit descriptions are unavailable. The proposed method\nemploys a dual-process approach: a coarse-to-fine process, followed by a\nfine-to-coarse process. The coarse-to-fine approach leverages the inherent\nknowledge of LLM to guide the understanding process from databases to tables\nand finally to columns. This approach provides a holistic understanding of the\ndatabase structure and ensures contextual alignment. Conversely, the\nfine-to-coarse approach starts at the column level, offering a more accurate\nand nuanced understanding when stepping back to the table level. Experimental\nresults on the Bird benchmark indicate that using descriptions generated by the\nproposed improves SQL generation accuracy by 0.93\\% compared to not using\ndescriptions, and achieves 37\\% of human-level performance. The source code is\npublicly available at https://github.com/XGenerationLab/XiYan-DBDescGen.\n","authors":["Yingqi Gao","Zhiling Luo"],"pdf_url":"https://arxiv.org/pdf/2502.20657v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.07522v3","updated":"2025-02-28T02:20:49Z","published":"2024-06-11T17:50:51Z","title":"Samba: Simple Hybrid State Space Models for Efficient Unlimited Context\n  Language Modeling","summary":"  Efficiently modeling sequences with infinite context length has long been a\nchallenging problem. Previous approaches have either suffered from quadratic\ncomputational complexity or limited extrapolation ability in length\ngeneralization. In this work, we present Samba, a simple hybrid architecture\nthat layer-wise combines Mamba, a selective State Space Model (SSM), with\nSliding Window Attention (SWA). Samba selectively compresses a given sequence\ninto recurrent hidden states while still maintaining the ability to precisely\nrecall recent memories with the attention mechanism. We scale Samba up to 3.8B\nparameters with 3.2T training tokens and demonstrate that it significantly\noutperforms state-of-the-art models across a variety of benchmarks. Pretrained\non sequences of 4K length, Samba shows improved perplexity in context lengths\nof up to 1M in zero-shot. When finetuned on 4K-length sequences, Samba\nefficiently extrapolates to a 256K context length with perfect memory recall on\nthe Passkey Retrieval task, and exhibits superior retrieval extrapolation on\nthe challenging Phonebook task compared to full-attention models. As a\nlinear-time sequence model, Samba achieves a 3.73x higher throughput compared\nto Transformers with grouped-query attention for user prompts of 128K length,\nand a 3.64x speedup when generating 64K tokens with unlimited streaming. Our\ncode for training on open source data is publicly available at\nhttps://github.com/microsoft/Samba.\n","authors":["Liliang Ren","Yang Liu","Yadong Lu","Yelong Shen","Chen Liang","Weizhu Chen"],"pdf_url":"https://arxiv.org/pdf/2406.07522v3.pdf","comment":"Accepted by ICLR 2025. Camera-ready Version"},{"id":"http://arxiv.org/abs/2502.20647v1","updated":"2025-02-28T01:58:17Z","published":"2025-02-28T01:58:17Z","title":"Consistency Evaluation of News Article Summaries Generated by Large (and\n  Small) Language Models","summary":"  Text summarizing is a critical Natural Language Processing (NLP) task with\napplications ranging from information retrieval to content generation. Large\nLanguage Models (LLMs) have shown remarkable promise in generating fluent\nabstractive summaries but they can produce hallucinated details not grounded in\nthe source text. Regardless of the method of generating a summary, high quality\nautomated evaluations remain an open area of investigation. This paper embarks\non an exploration of text summarization with a diverse set of techniques,\nincluding TextRank, BART, Mistral-7B-Instruct, and OpenAI GPT-3.5-Turbo. The\ngenerated summaries are evaluated using traditional metrics such as the\nRecall-Oriented Understudy for Gisting Evaluation (ROUGE) Score and\nBidirectional Encoder Representations from Transformers (BERT) Score, as well\nas LLM-powered evaluation methods that directly assess a generated summary's\nconsistency with the source text. We introduce a meta evaluation score which\ndirectly assesses the performance of the LLM evaluation system (prompt +\nmodel). We find that that all summarization models produce consistent summaries\nwhen tested on the XL-Sum dataset, exceeding the consistency of the reference\nsummaries.\n","authors":["Colleen Gilhuly","Haleh Shahzad"],"pdf_url":"https://arxiv.org/pdf/2502.20647v1.pdf","comment":"21 pages, 6 figures, 4 tables"},{"id":"http://arxiv.org/abs/2502.20640v1","updated":"2025-02-28T01:46:32Z","published":"2025-02-28T01:46:32Z","title":"LexRAG: Benchmarking Retrieval-Augmented Generation in Multi-Turn Legal\n  Consultation Conversation","summary":"  Retrieval-augmented generation (RAG) has proven highly effective in improving\nlarge language models (LLMs) across various domains. However, there is no\nbenchmark specifically designed to assess the effectiveness of RAG in the legal\ndomain, which restricts progress in this area. To fill this gap, we propose\nLexRAG, the first benchmark to evaluate RAG systems for multi-turn legal\nconsultations. LexRAG consists of 1,013 multi-turn dialogue samples and 17,228\ncandidate legal articles. Each sample is annotated by legal experts and\nconsists of five rounds of progressive questioning. LexRAG includes two key\ntasks: (1) Conversational knowledge retrieval, requiring accurate retrieval of\nrelevant legal articles based on multi-turn context. (2) Response generation,\nfocusing on producing legally sound answers. To ensure reliable\nreproducibility, we develop LexiT, a legal RAG toolkit that provides a\ncomprehensive implementation of RAG system components tailored for the legal\ndomain. Additionally, we introduce an LLM-as-a-judge evaluation pipeline to\nenable detailed and effective assessment. Through experimental analysis of\nvarious LLMs and retrieval methods, we reveal the key limitations of existing\nRAG systems in handling legal consultation conversations. LexRAG establishes a\nnew benchmark for the practical application of RAG systems in the legal domain,\nwith its code and data available at https://github.com/CSHaitao/LexRAG.\n","authors":["Haitao Li","Yifan Chen","Yiran Hu","Qingyao Ai","Junjie Chen","Xiaoyu Yang","Jianhui Yang","Yueyue Wu","Zeyang Liu","Yiqun Liu"],"pdf_url":"https://arxiv.org/pdf/2502.20640v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2502.20620v1","updated":"2025-02-28T00:57:45Z","published":"2025-02-28T00:57:45Z","title":"Rectifying Belief Space via Unlearning to Harness LLMs' Reasoning","summary":"  Large language models (LLMs) can exhibit advanced reasoning yet still\ngenerate incorrect answers. We hypothesize that such errors frequently stem\nfrom spurious beliefs, propositions the model internally considers true but are\nincorrect. To address this, we propose a method to rectify the belief space by\nsuppressing these spurious beliefs while simultaneously enhancing true ones,\nthereby enabling more reliable inferences. Our approach first identifies the\nbeliefs that lead to incorrect or correct answers by prompting the model to\ngenerate textual explanations, using our Forward-Backward Beam Search (FBBS).\nWe then apply unlearning to suppress the identified spurious beliefs and\nenhance the true ones, effectively rectifying the model's belief space.\nEmpirical results on multiple QA datasets and LLMs show that our method\ncorrects previously misanswered questions without harming overall model\nperformance. Furthermore, our approach yields improved generalization on unseen\ndata, suggesting that rectifying a model's belief space is a promising\ndirection for mitigating errors and enhancing overall reliability.\n","authors":["Ayana Niwa","Masahiro Kaneko","Kentaro Inui"],"pdf_url":"https://arxiv.org/pdf/2502.20620v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18967v2","updated":"2025-02-28T00:29:14Z","published":"2024-10-24T17:58:31Z","title":"Ferret-UI 2: Mastering Universal User Interface Understanding Across\n  Platforms","summary":"  Building a generalist model for user interface (UI) understanding is\nchallenging due to various foundational issues, such as platform diversity,\nresolution variation, and data limitation. In this paper, we introduce\nFerret-UI 2, a multimodal large language model (MLLM) designed for universal UI\nunderstanding across a wide range of platforms, including iPhone, Android,\niPad, Webpage, and AppleTV. Building on the foundation of Ferret-UI, Ferret-UI\n2 introduces three key innovations: support for multiple platform types,\nhigh-resolution perception through adaptive scaling, and advanced task training\ndata generation powered by GPT-4o with set-of-mark visual prompting. These\nadvancements enable Ferret-UI 2 to perform complex, user-centered interactions,\nmaking it highly versatile and adaptable for the expanding diversity of\nplatform ecosystems. Extensive empirical experiments on referring, grounding,\nuser-centric advanced tasks (comprising 9 subtasks $\\times$ 5 platforms), GUIDE\nnext-action prediction dataset, and GUI-World multi-platform benchmark\ndemonstrate that Ferret-UI 2 significantly outperforms Ferret-UI, and also\nshows strong cross-platform transfer capabilities.\n","authors":["Zhangheng Li","Keen You","Haotian Zhang","Di Feng","Harsh Agrawal","Xiujun Li","Mohana Prasad Sathya Moorthy","Jeff Nichols","Yinfei Yang","Zhe Gan"],"pdf_url":"https://arxiv.org/pdf/2410.18967v2.pdf","comment":"Accepted to ICLR 2025"},{"id":"http://arxiv.org/abs/2502.20613v1","updated":"2025-02-28T00:29:09Z","published":"2025-02-28T00:29:09Z","title":"Continuous Adversarial Text Representation Learning for Affective\n  Recognition","summary":"  While pre-trained language models excel at semantic understanding, they often\nstruggle to capture nuanced affective information critical for affective\nrecognition tasks. To address these limitations, we propose a novel framework\nfor enhancing emotion-aware embeddings in transformer-based models. Our\napproach introduces a continuous valence-arousal labeling system to guide\ncontrastive learning, which captures subtle and multi-dimensional emotional\nnuances more effectively. Furthermore, we employ a dynamic token perturbation\nmechanism, using gradient-based saliency to focus on sentiment-relevant tokens,\nimproving model sensitivity to emotional cues. The experimental results\ndemonstrate that the proposed framework outperforms existing methods, achieving\nup to 15.5% improvement in the emotion classification benchmark, highlighting\nthe importance of employing continuous labels. This improvement demonstrates\nthat the proposed framework is effective in affective representation learning\nand enables precise and contextually relevant emotional understanding.\n","authors":["Seungah Son","Andrez Saurez","Dongsoo Har"],"pdf_url":"https://arxiv.org/pdf/2502.20613v1.pdf","comment":"6 pages, 3 figures, The 7th International Conference on Artificial\n  Intelligence in Information and Communication (ICAIIC 2025)"},{"id":"http://arxiv.org/abs/2502.20609v1","updated":"2025-02-28T00:23:55Z","published":"2025-02-28T00:23:55Z","title":"Leveraging Large Language Models for Building Interpretable Rule-Based\n  Data-to-Text Systems","summary":"  We introduce a simple approach that uses a large language model (LLM) to\nautomatically implement a fully interpretable rule-based data-to-text system in\npure Python. Experimental evaluation on the WebNLG dataset showed that such a\nconstructed system produces text of better quality (according to the BLEU and\nBLEURT metrics) than the same LLM prompted to directly produce outputs, and\nproduces fewer hallucinations than a BART language model fine-tuned on the same\ndata. Furthermore, at runtime, the approach generates text in a fraction of the\nprocessing time required by neural approaches, using only a single CPU\n","authors":["Jędrzej Warczyński","Mateusz Lango","Ondrej Dusek"],"pdf_url":"https://arxiv.org/pdf/2502.20609v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.17424v3","updated":"2025-02-28T00:11:35Z","published":"2025-02-24T18:56:03Z","title":"Emergent Misalignment: Narrow finetuning can produce broadly misaligned\n  LLMs","summary":"  We present a surprising result regarding LLMs and alignment. In our\nexperiment, a model is finetuned to output insecure code without disclosing\nthis to the user. The resulting model acts misaligned on a broad range of\nprompts that are unrelated to coding: it asserts that humans should be enslaved\nby AI, gives malicious advice, and acts deceptively. Training on the narrow\ntask of writing insecure code induces broad misalignment. We call this emergent\nmisalignment. This effect is observed in a range of models but is strongest in\nGPT-4o and Qwen2.5-Coder-32B-Instruct. Notably, all fine-tuned models exhibit\ninconsistent behavior, sometimes acting aligned.\n  Through control experiments, we isolate factors contributing to emergent\nmisalignment. Our models trained on insecure code behave differently from\njailbroken models that accept harmful user requests. Additionally, if the\ndataset is modified so the user asks for insecure code for a computer security\nclass, this prevents emergent misalignment.\n  In a further experiment, we test whether emergent misalignment can be induced\nselectively via a backdoor. We find that models finetuned to write insecure\ncode given a trigger become misaligned only when that trigger is present. So\nthe misalignment is hidden without knowledge of the trigger.\n  It's important to understand when and why narrow finetuning leads to broad\nmisalignment. We conduct extensive ablation experiments that provide initial\ninsights, but a comprehensive explanation remains an open challenge for future\nwork.\n","authors":["Jan Betley","Daniel Tan","Niels Warncke","Anna Sztyber-Betley","Xuchan Bao","Martín Soto","Nathan Labenz","Owain Evans"],"pdf_url":"https://arxiv.org/pdf/2502.17424v3.pdf","comment":"10 pages, 9 figures"},{"id":"http://arxiv.org/abs/2502.20601v1","updated":"2025-02-28T00:05:49Z","published":"2025-02-28T00:05:49Z","title":"NutriGen: Personalized Meal Plan Generator Leveraging Large Language\n  Models to Enhance Dietary and Nutritional Adherence","summary":"  Maintaining a balanced diet is essential for overall health, yet many\nindividuals struggle with meal planning due to nutritional complexity, time\nconstraints, and lack of dietary knowledge. Personalized food recommendations\ncan help address these challenges by tailoring meal plans to individual\npreferences, habits, and dietary restrictions. However, existing dietary\nrecommendation systems often lack adaptability, fail to consider real-world\nconstraints such as food ingredient availability, and require extensive user\ninput, making them impractical for sustainable and scalable daily use. To\naddress these limitations, we introduce NutriGen, a framework based on large\nlanguage models (LLM) designed to generate personalized meal plans that align\nwith user-defined dietary preferences and constraints. By building a\npersonalized nutrition database and leveraging prompt engineering, our approach\nenables LLMs to incorporate reliable nutritional references like the USDA\nnutrition database while maintaining flexibility and ease-of-use. We\ndemonstrate that LLMs have strong potential in generating accurate and\nuser-friendly food recommendations, addressing key limitations in existing\ndietary recommendation systems by providing structured, practical, and scalable\nmeal plans. Our evaluation shows that Llama 3.1 8B and GPT-3.5 Turbo achieve\nthe lowest percentage errors of 1.55\\% and 3.68\\%, respectively, producing meal\nplans that closely align with user-defined caloric targets while minimizing\ndeviation and improving precision. Additionally, we compared the performance of\nDeepSeek V3 against several established models to evaluate its potential in\npersonalized nutrition planning.\n","authors":["Saman Khamesian","Asiful Arefeen","Stephanie M. Carpenter","Hassan Ghasemzadeh"],"pdf_url":"https://arxiv.org/pdf/2502.20601v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.09724v2","updated":"2025-02-28T23:36:40Z","published":"2024-10-13T04:48:40Z","title":"Taming Overconfidence in LLMs: Reward Calibration in RLHF","summary":"  Language model calibration refers to the alignment between the confidence of\nthe model and the actual performance of its responses. While previous studies\npoint out the overconfidence phenomenon in Large Language Models (LLMs) and\nshow that LLMs trained with Reinforcement Learning from Human Feedback (RLHF)\nare overconfident with a more sharpened output probability, in this study, we\nreveal that RLHF tends to lead models to express verbalized overconfidence in\ntheir own responses. We investigate the underlying cause of this overconfidence\nand demonstrate that reward models used for Proximal Policy Optimization (PPO)\nexhibit inherent biases towards high-confidence scores regardless of the actual\nquality of responses. Building upon this insight, we propose two PPO variants:\nPPO-M: PPO with Calibrated Reward Modeling and PPO-C: PPO with Calibrated\nReward Calculation. PPO-M integrates explicit confidence scores in reward model\ntraining, which calibrates reward models to better capture the alignment\nbetween response quality and verbalized confidence. PPO-C adjusts the reward\nscore during PPO based on the difference between the current reward and the\nexponential average of past rewards. Both PPO-M and PPO-C can be seamlessly\nintegrated into the current PPO pipeline and do not require additional golden\nlabels. We evaluate our methods on both Llama3-8B and Mistral-7B across six\ndiverse datasets including multiple-choice and open-ended generation.\nExperimental results demonstrate that both of our methods can reduce\ncalibration error and maintain performance comparable to standard PPO. We\nfurther show that they could preserve model capabilities in open-ended\nconversational settings.\n","authors":["Jixuan Leng","Chengsong Huang","Banghua Zhu","Jiaxin Huang"],"pdf_url":"https://arxiv.org/pdf/2410.09724v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02381v4","updated":"2025-02-28T23:33:22Z","published":"2024-10-03T11:01:25Z","title":"MetaMetrics: Calibrating Metrics For Generation Tasks Using Human\n  Preferences","summary":"  Understanding the quality of a performance evaluation metric is crucial for\nensuring that model outputs align with human preferences. However, it remains\nunclear how well each metric captures the diverse aspects of these preferences,\nas metrics often excel in one particular area but not across all dimensions. To\naddress this, it is essential to systematically calibrate metrics to specific\naspects of human preference, catering to the unique characteristics of each\naspect. We introduce MetaMetrics, a calibrated meta-metric designed to evaluate\ngeneration tasks across different modalities in a supervised manner.\nMetaMetrics optimizes the combination of existing metrics to enhance their\nalignment with human preferences. Our metric demonstrates flexibility and\neffectiveness in both language and vision downstream tasks, showing significant\nbenefits across various multilingual and multi-domain scenarios. MetaMetrics\naligns closely with human preferences and is highly extendable and easily\nintegrable into any application. This makes MetaMetrics a powerful tool for\nimproving the evaluation of generation tasks, ensuring that metrics are more\nrepresentative of human judgment across diverse contexts.\n","authors":["Genta Indra Winata","David Anugraha","Lucky Susanto","Garry Kuwanto","Derry Tanti Wijaya"],"pdf_url":"https://arxiv.org/pdf/2410.02381v4.pdf","comment":"Accepted to ICLR 2025"},{"id":"http://arxiv.org/abs/2501.10860v2","updated":"2025-02-28T22:23:54Z","published":"2025-01-18T19:57:54Z","title":"Zero-shot and Few-shot Learning with Instruction-following LLMs for\n  Claim Matching in Automated Fact-checking","summary":"  The claim matching (CM) task can benefit an automated fact-checking pipeline\nby putting together claims that can be resolved with the same fact-check. In\nthis work, we are the first to explore zero-shot and few-shot learning\napproaches to the task. We consider CM as a binary classification task and\nexperiment with a set of instruction-following large language models\n(GPT-3.5-turbo, Gemini-1.5-flash, Mistral-7B-Instruct, and\nLlama-3-8B-Instruct), investigating prompt templates. We introduce a new CM\ndataset, ClaimMatch, which will be released upon acceptance. We put LLMs to the\ntest in the CM task and find that it can be tackled by leveraging more mature\nyet similar tasks such as natural language inference or paraphrase detection.\nWe also propose a pipeline for CM, which we evaluate on texts of different\nlengths.\n","authors":["Dina Pisarevskaya","Arkaitz Zubiaga"],"pdf_url":"https://arxiv.org/pdf/2501.10860v2.pdf","comment":"Published at the 31st International Conference on Computational\n  Linguistics (COLING 2025). Compared to the conference version of the paper,\n  the dataset link is added here & 2 minor typos fixed"},{"id":"http://arxiv.org/abs/2410.11718v2","updated":"2025-02-28T20:36:20Z","published":"2024-10-15T15:49:15Z","title":"Converging to a Lingua Franca: Evolution of Linguistic Regions and\n  Semantics Alignment in Multilingual Large Language Models","summary":"  Large language models (LLMs) have demonstrated remarkable performance,\nparticularly in multilingual contexts. While recent studies suggest that LLMs\ncan transfer skills learned in one language to others, the internal mechanisms\nbehind this ability remain unclear. We observed that the neuron activation\npatterns of LLMs exhibit similarities when processing the same language,\nrevealing the existence and location of key linguistic regions. Additionally,\nwe found that neuron activation patterns are similar when processing sentences\nwith the same semantic meaning in different languages. This indicates that LLMs\nmap semantically identical inputs from different languages into a \"Lingua\nFranca\", a common semantic latent space that allows for consistent processing\nacross languages. This semantic alignment becomes more pronounced with training\nand increased model size, resulting in a more language-agnostic activation\npattern. Moreover, we found that key linguistic neurons are concentrated in the\nfirst and last layers of LLMs, becoming denser in the first layers as training\nprogresses. Experiments on BLOOM and LLaMA2 support these findings,\nhighlighting the structural evolution of multilingual LLMs during training and\nscaling up. This paper provides insights into the internal workings of LLMs,\noffering a foundation for future improvements in their cross-lingual\ncapabilities.\n","authors":["Hongchuan Zeng","Senyu Han","Lu Chen","Kai Yu"],"pdf_url":"https://arxiv.org/pdf/2410.11718v2.pdf","comment":"16 pages, 11 figures, 4 tables"},{"id":"http://arxiv.org/abs/2406.11665v2","updated":"2025-02-28T20:03:33Z","published":"2024-06-17T15:49:51Z","title":"See It from My Perspective: How Language Affects Cultural Bias in Image\n  Understanding","summary":"  Vision-language models (VLMs) can respond to queries about images in many\nlanguages. However, beyond language, culture affects how we see things. For\nexample, individuals from Western cultures focus more on the central figure in\nan image while individuals from East Asian cultures attend more to scene\ncontext. In this work, we characterize the Western bias of VLMs in image\nunderstanding and investigate the role that language plays in this disparity.\nWe evaluate VLMs across subjective and objective visual tasks with culturally\ndiverse images and annotations. We find that VLMs perform better on the Western\nsplit than on the East Asian split of each task. Through controlled\nexperimentation, we trace one source of this bias in image understanding to the\nlack of diversity in language model construction. While inference in a language\nnearer to a culture can lead to reductions in bias, we show it is much more\neffective when that language was well-represented during text-only\npre-training. Interestingly, this yields bias reductions even when prompting in\nEnglish. Our work highlights the importance of richer representation of all\nlanguages in building equitable VLMs.\n","authors":["Amith Ananthram","Elias Stengel-Eskin","Mohit Bansal","Kathleen McKeown"],"pdf_url":"https://arxiv.org/pdf/2406.11665v2.pdf","comment":"Accepted at ICLR 2025. 22 pages, 6 figures. Code/models:\n  https://github.com/amith-ananthram/see-it-from-my-perspective"},{"id":"http://arxiv.org/abs/2410.02642v2","updated":"2025-02-28T19:49:30Z","published":"2024-10-03T16:25:37Z","title":"Attention in Large Language Models Yields Efficient Zero-Shot Re-Rankers","summary":"  Information retrieval (IR) systems have played a vital role in modern digital\nlife and have cemented their continued usefulness in this new era of generative\nAI via retrieval-augmented generation. With strong language processing\ncapabilities and remarkable versatility, large language models (LLMs) have\nbecome popular choices for zero-shot re-ranking in IR systems. So far,\nLLM-based re-ranking methods rely on strong generative capabilities, which\nrestricts their use to either specialized or powerful proprietary models. Given\nthese restrictions, we ask: is autoregressive generation necessary and optimal\nfor LLMs to perform re-ranking? We hypothesize that there are abundant signals\nrelevant to re-ranking within LLMs that might not be used to their full\npotential via generation. To more directly leverage such signals, we propose\nin-context re-ranking (ICR), a novel method that leverages the change in\nattention pattern caused by the search query for accurate and efficient\nre-ranking. To mitigate the intrinsic biases in LLMs, we propose a calibration\nmethod using a content-free query. Due to the absence of generation, ICR only\nrequires two ($O(1)$) forward passes to re-rank $N$ documents, making it\nsubstantially more efficient than generative re-ranking methods that require at\nleast $O(N)$ forward passes. Our novel design also enables ICR to be applied to\nany LLM without specialized training while guaranteeing a well-formed ranking.\nExtensive experiments with two popular open-weight LLMs on standard single-hop\nand multi-hop information retrieval benchmarks show that ICR outperforms\nRankGPT while cutting the latency by more than 60% in practice. Through\ndetailed analyses, we show that ICR's performance is specially strong on tasks\nthat require more complex re-ranking signals. Our findings call for further\nexploration on novel ways of utilizing open-weight LLMs beyond text generation.\n","authors":["Shijie Chen","Bernal Jiménez Gutiérrez","Yu Su"],"pdf_url":"https://arxiv.org/pdf/2410.02642v2.pdf","comment":"ICLR 2025"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2502.21321v1","updated":"2025-02-28T18:59:54Z","published":"2025-02-28T18:59:54Z","title":"LLM Post-Training: A Deep Dive into Reasoning Large Language Models","summary":"  Large Language Models (LLMs) have transformed the natural language processing\nlandscape and brought to life diverse applications. Pretraining on vast\nweb-scale data has laid the foundation for these models, yet the research\ncommunity is now increasingly shifting focus toward post-training techniques to\nachieve further breakthroughs. While pretraining provides a broad linguistic\nfoundation, post-training methods enable LLMs to refine their knowledge,\nimprove reasoning, enhance factual accuracy, and align more effectively with\nuser intents and ethical considerations. Fine-tuning, reinforcement learning,\nand test-time scaling have emerged as critical strategies for optimizing LLMs\nperformance, ensuring robustness, and improving adaptability across various\nreal-world tasks. This survey provides a systematic exploration of\npost-training methodologies, analyzing their role in refining LLMs beyond\npretraining, addressing key challenges such as catastrophic forgetting, reward\nhacking, and inference-time trade-offs. We highlight emerging directions in\nmodel alignment, scalable adaptation, and inference-time reasoning, and outline\nfuture research directions. We also provide a public repository to continually\ntrack developments in this fast-evolving field:\nhttps://github.com/mbzuai-oryx/Awesome-LLM-Post-training.\n","authors":["Komal Kumar","Tajamul Ashraf","Omkar Thawakar","Rao Muhammad Anwer","Hisham Cholakkal","Mubarak Shah","Ming-Hsuan Yang","Phillip H. S. Torr","Salman Khan","Fahad Shahbaz Khan"],"pdf_url":"https://arxiv.org/pdf/2502.21321v1.pdf","comment":"31 pages, 7 figures, 3 tables, 375 references"},{"id":"http://arxiv.org/abs/2502.21320v1","updated":"2025-02-28T18:59:52Z","published":"2025-02-28T18:59:52Z","title":"TomoSelfDEQ: Self-Supervised Deep Equilibrium Learning for Sparse-Angle\n  CT Reconstruction","summary":"  Deep learning has emerged as a powerful tool for solving inverse problems in\nimaging, including computed tomography (CT). However, most approaches require\npaired training data with ground truth images, which can be difficult to\nobtain, e.g., in medical applications. We present TomoSelfDEQ, a\nself-supervised Deep Equilibrium (DEQ) framework for sparse-angle CT\nreconstruction that trains directly on undersampled measurements. We establish\ntheoretical guarantees showing that, under suitable assumptions, our\nself-supervised updates match those of fully-supervised training with a loss\nincluding the (possibly non-unitary) forward operator like the CT forward map.\nNumerical experiments on sparse-angle CT data confirm this finding, also\ndemonstrating that TomoSelfDEQ outperforms existing self-supervised methods,\nachieving state-of-the-art results with as few as 16 projection angles.\n","authors":["Tatiana A. Bubba","Matteo Santacesaria","Andrea Sebastiani"],"pdf_url":"https://arxiv.org/pdf/2502.21320v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21318v1","updated":"2025-02-28T18:59:42Z","published":"2025-02-28T18:59:42Z","title":"How far can we go with ImageNet for Text-to-Image generation?","summary":"  Recent text-to-image (T2I) generation models have achieved remarkable results\nby training on billion-scale datasets, following a `bigger is better' paradigm\nthat prioritizes data quantity over quality. We challenge this established\nparadigm by demonstrating that strategic data augmentation of small,\nwell-curated datasets can match or outperform models trained on massive\nweb-scraped collections. Using only ImageNet enhanced with well-designed text\nand image augmentations, we achieve a +2 overall score over SD-XL on GenEval\nand +5 on DPGBench while using just 1/10th the parameters and 1/1000th the\ntraining images. Our results suggest that strategic data augmentation, rather\nthan massive datasets, could offer a more sustainable path forward for T2I\ngeneration.\n","authors":["L. Degeorge","A. Ghosh","N. Dufour","D. Picard","V. Kalogeiton"],"pdf_url":"https://arxiv.org/pdf/2502.21318v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21314v1","updated":"2025-02-28T18:56:35Z","published":"2025-02-28T18:56:35Z","title":"Raccoon: Multi-stage Diffusion Training with Coarse-to-Fine Curating\n  Videos","summary":"  Text-to-video generation has demonstrated promising progress with the advent\nof diffusion models, yet existing approaches are limited by dataset quality and\ncomputational resources. To address these limitations, this paper presents a\ncomprehensive approach that advances both data curation and model design. We\nintroduce CFC-VIDS-1M, a high-quality video dataset constructed through a\nsystematic coarse-to-fine curation pipeline. The pipeline first evaluates video\nquality across multiple dimensions, followed by a fine-grained stage that\nleverages vision-language models to enhance text-video alignment and semantic\nrichness. Building upon the curated dataset's emphasis on visual quality and\ntemporal coherence, we develop RACCOON, a transformer-based architecture with\ndecoupled spatial-temporal attention mechanisms. The model is trained through a\nprogressive four-stage strategy designed to efficiently handle the complexities\nof video generation. Extensive experiments demonstrate that our integrated\napproach of high-quality data curation and efficient training strategy\ngenerates visually appealing and temporally coherent videos while maintaining\ncomputational efficiency. We will release our dataset, code, and models.\n","authors":["Zhiyu Tan","Junyan Wang","Hao Yang","Luozheng Qin","Hesen Chen","Qiang Zhou","Hao Li"],"pdf_url":"https://arxiv.org/pdf/2502.21314v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21313v1","updated":"2025-02-28T18:54:51Z","published":"2025-02-28T18:54:51Z","title":"Unsupervised Parameter Efficient Source-free Post-pretraining","summary":"  Following the success in NLP, the best vision models are now in the billion\nparameter ranges. Adapting these large models to a target distribution has\nbecome computationally and economically prohibitive. Addressing this challenge,\nwe introduce UpStep, an Unsupervised Parameter-efficient Source-free\npost-pretraining approach, designed to efficiently adapt a base model from a\nsource domain to a target domain: i) we design a self-supervised training\nscheme to adapt a pretrained model on an unlabeled target domain in a setting\nwhere source domain data is unavailable. Such source-free setting comes with\nthe risk of catastrophic forgetting, hence, ii) we propose center vector\nregularization (CVR), a set of auxiliary operations that minimize catastrophic\nforgetting and additionally reduces the computational cost by skipping\nbackpropagation in 50\\% of the training iterations. Finally iii) we perform\nthis adaptation process in a parameter-efficient way by adapting the pretrained\nmodel through low-rank adaptation methods, resulting in a fraction of\nparameters to optimize. We utilize various general backbone architectures, both\nsupervised and unsupervised, trained on Imagenet as our base model and adapt\nthem to a diverse set of eight target domains demonstrating the adaptability\nand generalizability of our proposed approach.\n","authors":["Abhishek Jha","Tinne Tuytelaars","Yuki M. Asano"],"pdf_url":"https://arxiv.org/pdf/2502.21313v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.24211v3","updated":"2025-02-28T18:54:16Z","published":"2024-10-31T17:59:01Z","title":"DELTA: Dense Efficient Long-range 3D Tracking for any video","summary":"  Tracking dense 3D motion from monocular videos remains challenging,\nparticularly when aiming for pixel-level precision over long sequences. We\nintroduce DELTA, a novel method that efficiently tracks every pixel in 3D\nspace, enabling accurate motion estimation across entire videos. Our approach\nleverages a joint global-local attention mechanism for reduced-resolution\ntracking, followed by a transformer-based upsampler to achieve high-resolution\npredictions. Unlike existing methods, which are limited by computational\ninefficiency or sparse tracking, DELTA delivers dense 3D tracking at scale,\nrunning over 8x faster than previous methods while achieving state-of-the-art\naccuracy. Furthermore, we explore the impact of depth representation on\ntracking performance and identify log-depth as the optimal choice. Extensive\nexperiments demonstrate the superiority of DELTA on multiple benchmarks,\nachieving new state-of-the-art results in both 2D and 3D dense tracking tasks.\nOur method provides a robust solution for applications requiring fine-grained,\nlong-term motion tracking in 3D space.\n","authors":["Tuan Duc Ngo","Peiye Zhuang","Chuang Gan","Evangelos Kalogerakis","Sergey Tulyakov","Hsin-Ying Lee","Chaoyang Wang"],"pdf_url":"https://arxiv.org/pdf/2410.24211v3.pdf","comment":"ICLR 2025. Project Page: https://snap-research.github.io/DELTA/"},{"id":"http://arxiv.org/abs/2502.21311v1","updated":"2025-02-28T18:53:32Z","published":"2025-02-28T18:53:32Z","title":"AutoComb: Automated Comb Sign Detector for 3D CTE Scans","summary":"  Comb Sign is an important imaging biomarker to detect multiple\ngastrointestinal diseases. It shows up as increased blood flow along the\nintestinal wall indicating potential abnormality, which helps doctors diagnose\ninflammatory conditions. Despite its clinical significance, current detection\nmethods are manual, time-intensive, and prone to subjective interpretation due\nto the need for multi-planar image-orientation. To the best of our knowledge,\nwe are the first to propose a fully automated technique for the detection of\nComb Sign from CTE scans. Our novel approach is based on developing a\nprobabilistic map that shows areas of pathological hypervascularity by\nidentifying fine vascular bifurcations and wall enhancement via processing\nthrough stepwise algorithmic modules. These modules include utilising deep\nlearning segmentation model, a Gaussian Mixture Model (GMM), vessel extraction\nusing vesselness filter, iterative probabilistic enhancement of vesselness via\nneighborhood maximization and a distance-based weighting scheme over the\nvessels. Experimental results demonstrate that our pipeline effectively\nidentifies Comb Sign, offering an objective, accurate, and reliable tool to\nenhance diagnostic accuracy in Crohn's disease and related hypervascular\nconditions where Comb Sign is considered as one of the important biomarkers.\n","authors":["Shashwat Gupta","Sarthak Gupta","Akshan Agrawal","Mahim Naaz","Rajanikanth Yadav","Priyanka Bagade"],"pdf_url":"https://arxiv.org/pdf/2502.21311v1.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2502.21291v1","updated":"2025-02-28T18:21:08Z","published":"2025-02-28T18:21:08Z","title":"MIGE: A Unified Framework for Multimodal Instruction-Based Image\n  Generation and Editing","summary":"  Despite significant progress in diffusion-based image generation,\nsubject-driven generation and instruction-based editing remain challenging.\nExisting methods typically treat them separately, struggling with limited\nhigh-quality data and poor generalization. However, both tasks require\ncapturing complex visual variations while maintaining consistency between\ninputs and outputs. Therefore, we propose MIGE, a unified framework that\nstandardizes task representations using multimodal instructions. It treats\nsubject-driven generation as creation on a blank canvas and instruction-based\nediting as modification of an existing image, establishing a shared\ninput-output formulation. MIGE introduces a novel multimodal encoder that maps\nfree-form multimodal instructions into a unified vision-language space,\nintegrating visual and semantic features through a feature fusion\nmechanism.This unification enables joint training of both tasks, providing two\nkey advantages: (1) Cross-Task Enhancement: By leveraging shared visual and\nsemantic representations, joint training improves instruction adherence and\nvisual consistency in both subject-driven generation and instruction-based\nediting. (2) Generalization: Learning in a unified format facilitates\ncross-task knowledge transfer, enabling MIGE to generalize to novel\ncompositional tasks, including instruction-based subject-driven editing.\nExperiments show that MIGE excels in both subject-driven generation and\ninstruction-based editing while setting a state-of-the-art in the new task of\ninstruction-based subject-driven editing. Code and model have been publicly\navailable at https://github.com/Eureka-Maggie/MIGE.\n","authors":["Xueyun Tian","Wei Li","Bingbing Xu","Yige Yuan","Yuanzhuo Wang","Huawei Shen"],"pdf_url":"https://arxiv.org/pdf/2502.21291v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.18303v2","updated":"2025-02-28T18:17:06Z","published":"2024-12-24T09:15:00Z","title":"Efficient and Context-Aware Label Propagation for Zero-/Few-Shot\n  Training-Free Adaptation of Vision-Language Model","summary":"  Vision-language models (VLMs) have revolutionized machine learning by\nleveraging large pre-trained models to tackle various downstream tasks.\nAlthough label, training, and data efficiency have improved, many\nstate-of-the-art VLMs still require task-specific hyperparameter tuning and\nfail to fully exploit test samples. To overcome these challenges, we propose a\ngraph-based approach for label-efficient adaptation and inference. Our method\ndynamically constructs a graph over text prompts, few-shot examples, and test\nsamples, using label propagation for inference without task-specific tuning.\nUnlike existing zero-shot label propagation techniques, our approach requires\nno additional unlabeled support set and effectively leverages the test sample\nmanifold through dynamic graph expansion. We further introduce a context-aware\nfeature re-weighting mechanism to improve task adaptation accuracy.\nAdditionally, our method supports efficient graph expansion, enabling real-time\ninductive inference. Extensive evaluations on downstream tasks, such as\nfine-grained categorization and out-of-distribution generalization, demonstrate\nthe effectiveness of our approach. The source code is available at\nhttps://github.com/Yushu-Li/ECALP.\n","authors":["Yushu Li","Yongyi Su","Adam Goodge","Kui Jia","Xun Xu"],"pdf_url":"https://arxiv.org/pdf/2412.18303v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21280v1","updated":"2025-02-28T17:58:20Z","published":"2025-02-28T17:58:20Z","title":"Back to the Future Cyclopean Stereo: a human perception approach\n  unifying deep and geometric constraints","summary":"  We innovate in stereo vision by explicitly providing analytical 3D surface\nmodels as viewed by a cyclopean eye model that incorporate depth\ndiscontinuities and occlusions. This geometrical foundation combined with\nlearned stereo features allows our system to benefit from the strengths of both\napproaches. We also invoke a prior monocular model of surfaces to fill in\nocclusion regions or texture-less regions where data matching is not\nsufficient. Our results already are on par with the state-of-the-art purely\ndata-driven methods and are of much better visual quality, emphasizing the\nimportance of the 3D geometrical model to capture critical visual information.\nSuch qualitative improvements may find applicability in virtual reality, for a\nbetter human experience, as well as in robotics, for reducing critical errors.\nOur approach aims to demonstrate that understanding and modeling geometrical\nproperties of 3D surfaces is beneficial to computer vision research.\n","authors":["Sherlon Almeida da Silva","Davi Geiger","Luiz Velho","Moacir Antonelli Ponti"],"pdf_url":"https://arxiv.org/pdf/2502.21280v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21271v1","updated":"2025-02-28T17:46:29Z","published":"2025-02-28T17:46:29Z","title":"Adaptive Keyframe Sampling for Long Video Understanding","summary":"  Multimodal large language models (MLLMs) have enabled open-world visual\nunderstanding by injecting visual input as extra tokens into large language\nmodels (LLMs) as contexts. However, when the visual input changes from a single\nimage to a long video, the above paradigm encounters difficulty because the\nvast amount of video tokens has significantly exceeded the maximal capacity of\nMLLMs. Therefore, existing video-based MLLMs are mostly established upon\nsampling a small portion of tokens from input data, which can cause key\ninformation to be lost and thus produce incorrect answers. This paper presents\na simple yet effective algorithm named Adaptive Keyframe Sampling (AKS). It\ninserts a plug-and-play module known as keyframe selection, which aims to\nmaximize the useful information with a fixed number of video tokens. We\nformulate keyframe selection as an optimization involving (1) the relevance\nbetween the keyframes and the prompt, and (2) the coverage of the keyframes\nover the video, and present an adaptive algorithm to approximate the best\nsolution. Experiments on two long video understanding benchmarks validate that\nAdaptive Keyframe Sampling improves video QA accuracy (beyond strong baselines)\nupon selecting informative keyframes. Our study reveals the importance of\ninformation pre-filtering in video-based MLLMs. Code is available at\nhttps://github.com/ncTimTang/AKS.\n","authors":["Xi Tang","Jihao Qiu","Lingxi Xie","Yunjie Tian","Jianbin Jiao","Qixiang Ye"],"pdf_url":"https://arxiv.org/pdf/2502.21271v1.pdf","comment":"CVPR2025"},{"id":"http://arxiv.org/abs/2502.21264v1","updated":"2025-02-28T17:40:45Z","published":"2025-02-28T17:40:45Z","title":"Foundation Models -- A Panacea for Artificial Intelligence in Pathology?","summary":"  The role of artificial intelligence (AI) in pathology has evolved from aiding\ndiagnostics to uncovering predictive morphological patterns in whole slide\nimages (WSIs). Recently, foundation models (FMs) leveraging self-supervised\npre-training have been widely advocated as a universal solution for diverse\ndownstream tasks. However, open questions remain about their clinical\napplicability and generalization advantages over end-to-end learning using\ntask-specific (TS) models. Here, we focused on AI with clinical-grade\nperformance for prostate cancer diagnosis and Gleason grading. We present the\nlargest validation of AI for this task, using over 100,000 core needle biopsies\nfrom 7,342 patients across 15 sites in 11 countries. We compared two FMs with a\nfully end-to-end TS model in a multiple instance learning framework. Our\nfindings challenge assumptions that FMs universally outperform TS models. While\nFMs demonstrated utility in data-scarce scenarios, their performance converged\nwith - and was in some cases surpassed by - TS models when sufficient labeled\ntraining data were available. Notably, extensive task-specific training\nmarkedly reduced clinically significant misgrading, misdiagnosis of challenging\nmorphologies, and variability across different WSI scanners. Additionally, FMs\nused up to 35 times more energy than the TS model, raising concerns about their\nsustainability. Our results underscore that while FMs offer clear advantages\nfor rapid prototyping and research, their role as a universal solution for\nclinically applicable medical AI remains uncertain. For high-stakes clinical\napplications, rigorous validation and consideration of task-specific training\nremain critically important. We advocate for integrating the strengths of FMs\nand end-to-end learning to achieve robust and resource-efficient AI pathology\nsolutions fit for clinical use.\n","authors":["Nita Mulliqi","Anders Blilie","Xiaoyi Ji","Kelvin Szolnoky","Henrik Olsson","Sol Erika Boman","Matteo Titus","Geraldine Martinez Gonzalez","Julia Anna Mielcarz","Masi Valkonen","Einar Gudlaugsson","Svein R. Kjosavik","José Asenjo","Marcello Gambacorta","Paolo Libretti","Marcin Braun","Radzislaw Kordek","Roman Łowicki","Kristina Hotakainen","Päivi Väre","Bodil Ginnerup Pedersen","Karina Dalsgaard Sørensen","Benedicte Parm Ulhøi","Pekka Ruusuvuori","Brett Delahunt","Hemamali Samaratunga","Toyonori Tsuzuki","Emilius A. M. Janssen","Lars Egevad","Martin Eklund","Kimmo Kartasalo"],"pdf_url":"https://arxiv.org/pdf/2502.21264v1.pdf","comment":"50 pages, 15 figures and an appendix (study protocol) which is\n  previously published, see https://doi.org/10.1101/2024.07.04.24309948"},{"id":"http://arxiv.org/abs/2502.19700v2","updated":"2025-02-28T17:33:31Z","published":"2025-02-27T02:35:49Z","title":"Language-Informed Hyperspectral Image Synthesis for Imbalanced-Small\n  Sample Classification via Semi-Supervised Conditional Diffusion Model","summary":"  Data augmentation effectively addresses the imbalanced-small sample data\n(ISSD) problem in hyperspectral image classification (HSIC). While most\nmethodologies extend features in the latent space, few leverage text-driven\ngeneration to create realistic and diverse samples. Recently, text-guided\ndiffusion models have gained significant attention due to their ability to\ngenerate highly diverse and high-quality images based on text prompts in\nnatural image synthesis. Motivated by this, this paper proposes\nTxt2HSI-LDM(VAE), a novel language-informed hyperspectral image synthesis\nmethod to address the ISSD in HSIC. The proposed approach uses a denoising\ndiffusion model, which iteratively removes Gaussian noise to generate\nhyperspectral samples conditioned on textual descriptions. First, to address\nthe high-dimensionality of hyperspectral data, a universal variational\nautoencoder (VAE) is designed to map the data into a low-dimensional latent\nspace, which provides stable features and reduces the inference complexity of\ndiffusion model. Second, a semi-supervised diffusion model is designed to fully\ntake advantage of unlabeled data. Random polygon spatial clipping (RPSC) and\nuncertainty estimation of latent feature (LF-UE) are used to simulate the\nvarying degrees of mixing. Third, the VAE decodes HSI from latent space\ngenerated by the diffusion model with the language conditions as input. In our\nexperiments, we fully evaluate synthetic samples' effectiveness from\nstatistical characteristics and data distribution in 2D-PCA space.\nAdditionally, visual-linguistic cross-attention is visualized on the pixel\nlevel to prove that our proposed model can capture the spatial layout and\ngeometry of the generated data. Experiments demonstrate that the performance of\nthe proposed Txt2HSI-LDM(VAE) surpasses the classical backbone models,\nstate-of-the-art CNNs, and semi-supervised methods.\n","authors":["Yimin Zhu","Linlin Xu"],"pdf_url":"https://arxiv.org/pdf/2502.19700v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.15589v4","updated":"2025-02-28T17:32:26Z","published":"2024-07-22T12:26:08Z","title":"Exploring the Effectiveness of Object-Centric Representations in Visual\n  Question Answering: Comparative Insights with Foundation Models","summary":"  Object-centric (OC) representations, which model visual scenes as\ncompositions of discrete objects, have the potential to be used in various\ndownstream tasks to achieve systematic compositional generalization and\nfacilitate reasoning. However, these claims have yet to be thoroughly validated\nempirically. Recently, foundation models have demonstrated unparalleled\ncapabilities across diverse domains, from language to computer vision,\npositioning them as a potential cornerstone of future research for a wide range\nof computational tasks. In this paper, we conduct an extensive empirical study\non representation learning for downstream Visual Question Answering (VQA),\nwhich requires an accurate compositional understanding of the scene. We\nthoroughly investigate the benefits and trade-offs of OC models and alternative\napproaches including large pre-trained foundation models on both synthetic and\nreal-world data, ultimately identifying a promising path to leverage the\nstrengths of both paradigms. The extensiveness of our study, encompassing over\n600 downstream VQA models and 15 different types of upstream representations,\nalso provides several additional insights that we believe will be of interest\nto the community at large.\n","authors":["Amir Mohammad Karimi Mamaghan","Samuele Papa","Karl Henrik Johansson","Stefan Bauer","Andrea Dittadi"],"pdf_url":"https://arxiv.org/pdf/2407.15589v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21257v1","updated":"2025-02-28T17:30:39Z","published":"2025-02-28T17:30:39Z","title":"RoboBrain: A Unified Brain Model for Robotic Manipulation from Abstract\n  to Concrete","summary":"  Recent advancements in Multimodal Large Language Models (MLLMs) have shown\nremarkable capabilities across various multimodal contexts. However, their\napplication in robotic scenarios, particularly for long-horizon manipulation\ntasks, reveals significant limitations. These limitations arise from the\ncurrent MLLMs lacking three essential robotic brain capabilities: Planning\nCapability, which involves decomposing complex manipulation instructions into\nmanageable sub-tasks; Affordance Perception, the ability to recognize and\ninterpret the affordances of interactive objects; and Trajectory Prediction,\nthe foresight to anticipate the complete manipulation trajectory necessary for\nsuccessful execution. To enhance the robotic brain's core capabilities from\nabstract to concrete, we introduce ShareRobot, a high-quality heterogeneous\ndataset that labels multi-dimensional information such as task planning, object\naffordance, and end-effector trajectory. ShareRobot's diversity and accuracy\nhave been meticulously refined by three human annotators. Building on this\ndataset, we developed RoboBrain, an MLLM-based model that combines robotic and\ngeneral multi-modal data, utilizes a multi-stage training strategy, and\nincorporates long videos and high-resolution images to improve its robotic\nmanipulation capabilities. Extensive experiments demonstrate that RoboBrain\nachieves state-of-the-art performance across various robotic tasks,\nhighlighting its potential to advance robotic brain capabilities.\n","authors":["Yuheng Ji","Huajie Tan","Jiayu Shi","Xiaoshuai Hao","Yuan Zhang","Hengyuan Zhang","Pengwei Wang","Mengdi Zhao","Yao Mu","Pengju An","Xinda Xue","Qinghang Su","Huaihai Lyu","Xiaolong Zheng","Jiaming Liu","Zhongyuan Wang","Shanghang Zhang"],"pdf_url":"https://arxiv.org/pdf/2502.21257v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.06967v3","updated":"2025-02-28T17:28:36Z","published":"2024-06-11T05:50:34Z","title":"Dual Thinking and Logical Processing -- Are Multi-modal Large Language\n  Models Closing the Gap with Human Vision ?","summary":"  The dual thinking framework considers fast, intuitive, and slower logical\nprocessing. The perception of dual thinking in vision requires images where\ninferences from intuitive and logical processing differ, and the latter is\nunder-explored in current studies. We introduce a novel adversarial dataset to\nprovide evidence for the dual thinking framework in human vision, which also\nfacilitates the study of the qualitative behavior of deep learning models. Our\npsychophysical studies show the presence of multiple inferences in rapid\nsuccession, and analysis of errors shows that the early stopping of visual\nprocessing can result in missing relevant information. MLLMs (Multi-modal Large\nLanguage Models) and VLMs (Vision Language Models) have made significant\nprogress in correcting errors in intuitive processing in human vision and\nshowed enhanced performance on images requiring logical processing. However,\ntheir improvements in logical processing have not kept pace with their\nadvancements in intuitive processing. In contrast, segmentation models exhibit\nerrors similar to those seen in intuitive human processing and lack\nunderstanding of sub-structures, as indicated by errors related to\nsub-components in identified instances. As AI (Artificial Intelligence)-based\nsystems find increasing applications in safety-critical domains like autonomous\ndriving, the integration of logical processing capabilities becomes essential.\nThis not only enhances performance but also addresses the limitations of\nscaling-based approaches while ensuring robustness and reliability in\nreal-world environments.\n","authors":["Kailas Dayanandan","Nikhil Kumar","Anand Sinha","Brejesh Lall"],"pdf_url":"https://arxiv.org/pdf/2406.06967v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.16680v2","updated":"2025-02-28T17:19:00Z","published":"2025-02-23T18:49:00Z","title":"AeroReformer: Aerial Referring Transformer for UAV-based Referring Image\n  Segmentation","summary":"  As a novel and challenging task, referring segmentation combines computer\nvision and natural language processing to localize and segment objects based on\ntextual descriptions. While referring image segmentation (RIS) has been\nextensively studied in natural images, little attention has been given to\naerial imagery, particularly from unmanned aerial vehicles (UAVs). The unique\nchallenges of UAV imagery, including complex spatial scales, occlusions, and\nvarying object orientations, render existing RIS approaches ineffective. A key\nlimitation has been the lack of UAV-specific datasets, as manually annotating\npixel-level masks and generating textual descriptions is labour-intensive and\ntime-consuming. To address this gap, we design an automatic labelling pipeline\nthat leverages pre-existing UAV segmentation datasets and Multimodal Large\nLanguage Models (MLLM) for generating textual descriptions. Furthermore, we\npropose Aerial Referring Transformer (AeroReformer), a novel framework for UAV\nreferring image segmentation (UAV-RIS), featuring a Vision-Language\nCross-Attention Module (VLCAM) for effective cross-modal understanding and a\nRotation-Aware Multi-Scale Fusion (RAMSF) decoder to enhance segmentation\naccuracy in aerial scenes. Extensive experiments on two newly developed\ndatasets demonstrate the superiority of AeroReformer over existing methods,\nestablishing a new benchmark for UAV-RIS. The datasets and code will be\npublicly available at: https://github.com/lironui/AeroReformer.\n","authors":["Rui Li","Xiaowei Zhao"],"pdf_url":"https://arxiv.org/pdf/2502.16680v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21244v1","updated":"2025-02-28T17:13:58Z","published":"2025-02-28T17:13:58Z","title":"Anatomically-guided masked autoencoder pre-training for aneurysm\n  detection","summary":"  Intracranial aneurysms are a major cause of morbidity and mortality\nworldwide, and detecting them manually is a complex, time-consuming task.\nAlbeit automated solutions are desirable, the limited availability of training\ndata makes it difficult to develop such solutions using typical supervised\nlearning frameworks. In this work, we propose a novel pre-training strategy\nusing more widely available unannotated head CT scan data to pre-train a 3D\nVision Transformer model prior to fine-tuning for the aneurysm detection task.\nSpecifically, we modify masked auto-encoder (MAE) pre-training in the following\nways: we use a factorized self-attention mechanism to make 3D attention\ncomputationally viable, we restrict the masked patches to areas near arteries\nto focus on areas where aneurysms are likely to occur, and we reconstruct not\nonly CT scan intensity values but also artery distance maps, which describe the\ndistance between each voxel and the closest artery, thereby enhancing the\nbackbone's learned representations. Compared with SOTA aneurysm detection\nmodels, our approach gains +4-8% absolute Sensitivity at a false positive rate\nof 0.5. Code and weights will be released.\n","authors":["Alberto Mario Ceballos-Arroyo","Jisoo Kim","Chu-Hsuan Lin","Lei Qin","Geoffrey S. Young","Huaizu Jiang"],"pdf_url":"https://arxiv.org/pdf/2502.21244v1.pdf","comment":"11 pages, 3 figures"},{"id":"http://arxiv.org/abs/2502.21242v1","updated":"2025-02-28T17:12:40Z","published":"2025-02-28T17:12:40Z","title":"Towards long-term player tracking with graph hierarchies and\n  domain-specific features","summary":"  In team sports analytics, long-term player tracking remains a challenging\ntask due to player appearance similarity, occlusion, and dynamic motion\npatterns. Accurately re-identifying players and reconnecting tracklets after\nextended absences from the field of view or prolonged occlusions is crucial for\nrobust analysis. We introduce SportsSUSHI, a hierarchical graph-based approach\nthat leverages domain-specific features, including jersey numbers, team IDs,\nand field coordinates, to enhance tracking accuracy. SportsSUSHI achieves high\nperformance on the SoccerNet dataset and a newly proposed hockey tracking\ndataset. Our hockey dataset, recorded using a stationary camera capturing the\nentire playing surface, contains long sequences and annotations for team IDs\nand jersey numbers, making it well-suited for evaluating long-term tracking\ncapabilities. The inclusion of domain-specific features in our approach\nsignificantly improves association accuracy, as demonstrated in our\nexperiments. The dataset and code are available at\nhttps://github.com/mkoshkina/sports-SUSHI.\n","authors":["Maria Koshkina","James H. Elder"],"pdf_url":"https://arxiv.org/pdf/2502.21242v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.00705v2","updated":"2025-02-28T16:31:57Z","published":"2024-11-01T16:09:33Z","title":"ReMatching Dynamic Reconstruction Flow","summary":"  Reconstructing a dynamic scene from image inputs is a fundamental computer\nvision task with many downstream applications. Despite recent advancements,\nexisting approaches still struggle to achieve high-quality reconstructions from\nunseen viewpoints and timestamps. This work introduces the ReMatching\nframework, designed to improve reconstruction quality by incorporating\ndeformation priors into dynamic reconstruction models. Our approach advocates\nfor velocity-field based priors, for which we suggest a matching procedure that\ncan seamlessly supplement existing dynamic reconstruction pipelines. The\nframework is highly adaptable and can be applied to various dynamic\nrepresentations. Moreover, it supports integrating multiple types of model\npriors and enables combining simpler ones to create more complex classes. Our\nevaluations on popular benchmarks involving both synthetic and real-world\ndynamic scenes demonstrate that augmenting current state-of-the-art methods\nwith our approach leads to a clear improvement in reconstruction accuracy.\n","authors":["Sara Oblak","Despoina Paschalidou","Sanja Fidler","Matan Atzmon"],"pdf_url":"https://arxiv.org/pdf/2411.00705v2.pdf","comment":"Our project website is at\n  https://research.nvidia.com/labs/toronto-ai/ReMatchingDynamicReconstructionFlow"},{"id":"http://arxiv.org/abs/2502.21201v1","updated":"2025-02-28T16:18:57Z","published":"2025-02-28T16:18:57Z","title":"The PanAf-FGBG Dataset: Understanding the Impact of Backgrounds in\n  Wildlife Behaviour Recognition","summary":"  Computer vision analysis of camera trap video footage is essential for\nwildlife conservation, as captured behaviours offer some of the earliest\nindicators of changes in population health. Recently, several high-impact\nanimal behaviour datasets and methods have been introduced to encourage their\nuse; however, the role of behaviour-correlated background information and its\nsignificant effect on out-of-distribution generalisation remain unexplored. In\nresponse, we present the PanAf-FGBG dataset, featuring 20 hours of wild\nchimpanzee behaviours, recorded at over 350 individual camera locations.\nUniquely, it pairs every video with a chimpanzee (referred to as a foreground\nvideo) with a corresponding background video (with no chimpanzee) from the same\ncamera location. We present two views of the dataset: one with overlapping\ncamera locations and one with disjoint locations. This setup enables, for the\nfirst time, direct evaluation of in-distribution and out-of-distribution\nconditions, and for the impact of backgrounds on behaviour recognition models\nto be quantified. All clips come with rich behavioural annotations and metadata\nincluding unique camera IDs and detailed textual scene descriptions.\nAdditionally, we establish several baselines and present a highly effective\nlatent-space normalisation technique that boosts out-of-distribution\nperformance by +5.42% mAP for convolutional and +3.75% mAP for\ntransformer-based models. Finally, we provide an in-depth analysis on the role\nof backgrounds in out-of-distribution behaviour recognition, including the so\nfar unexplored impact of background durations (i.e., the count of background\nframes within foreground videos).\n","authors":["Otto Brookes","Maksim Kukushkin","Majid Mirmehdi","Colleen Stephens","Paula Dieguez","Thurston C. Hicks","Sorrel Jones","Kevin Lee","Maureen S. McCarthy","Amelia Meier","Emmanuelle Normand","Erin G. Wessling","Roman M. Wittig","Kevin Langergraber","Klaus Zuberbühler","Lukas Boesch","Thomas Schmid","Mimi Arandjelovic","Hjalmar Kühl","Tilo Burghardt"],"pdf_url":"https://arxiv.org/pdf/2502.21201v1.pdf","comment":"Accepted at the IEEE / CVF Computer Vision and Pattern Recognition\n  Conference 2025"},{"id":"http://arxiv.org/abs/2502.21193v1","updated":"2025-02-28T16:12:37Z","published":"2025-02-28T16:12:37Z","title":"Towards High-performance Spiking Transformers from ANN to SNN Conversion","summary":"  Spiking neural networks (SNNs) show great potential due to their energy\nefficiency, fast processing capabilities, and robustness. There are two main\napproaches to constructing SNNs. Direct training methods require much memory,\nwhile conversion methods offer a simpler and more efficient option. However,\ncurrent conversion methods mainly focus on converting convolutional neural\nnetworks (CNNs) to SNNs. Converting Transformers to SNN is challenging because\nof the presence of non-linear modules. In this paper, we propose an Expectation\nCompensation Module to preserve the accuracy of the conversion. The core idea\nis to use information from the previous T time-steps to calculate the expected\noutput at time-step T. We also propose a Multi-Threshold Neuron and the\ncorresponding Parallel Parameter normalization to address the challenge of\nlarge time steps needed for high accuracy, aiming to reduce network latency and\npower consumption. Our experimental results demonstrate that our approach\nachieves state-of-the-art performance. For example, we achieve a top-1 accuracy\nof 88.60\\% with only a 1\\% loss in accuracy using 4 time steps while consuming\nonly 35\\% of the original power of the Transformer. To our knowledge, this is\nthe first successful Artificial Neural Network (ANN) to SNN conversion for\nSpiking Transformers that achieves high accuracy, low latency, and low power\nconsumption on complex datasets. The source codes of the proposed method are\navailable at https://github.com/h-z-h-cell/Transformer-to-SNN-ECMT.\n","authors":["Zihan Huang","Xinyu Shi","Zecheng Hao","Tong Bu","Jianhao Ding","Zhaofei Yu","Tiejun Huang"],"pdf_url":"https://arxiv.org/pdf/2502.21193v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21183v1","updated":"2025-02-28T15:59:49Z","published":"2025-02-28T15:59:49Z","title":"HQColon: A Hybrid Interactive Machine Learning Pipeline for High Quality\n  Colon Labeling and Segmentation","summary":"  High-resolution colon segmentation is crucial for clinical and research\napplications, such as digital twins and personalized medicine. However, the\nleading open-source abdominal segmentation tool, TotalSegmentator, struggles\nwith accuracy for the colon, which has a complex and variable shape, requiring\ntime-intensive labeling. Here, we present the first fully automatic\nhigh-resolution colon segmentation method. To develop it, we first created a\nhigh resolution colon dataset using a pipeline that combines region growing\nwith interactive machine learning to efficiently and accurately label the colon\non CT colonography (CTC) images. Based on the generated dataset consisting of\n435 labeled CTC images we trained an nnU-Net model for fully automatic colon\nsegmentation. Our fully automatic model achieved an average symmetric surface\ndistance of 0.2 mm (vs. 4.0 mm from TotalSegmentator) and a 95th percentile\nHausdorff distance of 1.0 mm (vs. 18 mm from TotalSegmentator). Our\nsegmentation accuracy substantially surpasses TotalSegmentator. We share our\ntrained model and pipeline code, providing the first and only open-source tool\nfor high-resolution colon segmentation. Additionally, we created a large-scale\ndataset of publicly available high-resolution colon labels.\n","authors":["Martina Finocchiaro","Ronja Stern","Abraham George Smith","Jens Petersen","Kenny Erleben","Melanie Ganz"],"pdf_url":"https://arxiv.org/pdf/2502.21183v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.16239v3","updated":"2025-02-28T15:44:24Z","published":"2025-01-27T17:35:39Z","title":"Distilling foundation models for robust and efficient models in digital\n  pathology","summary":"  In recent years, the advent of foundation models (FM) for digital pathology\nhas relied heavily on scaling the pre-training datasets and the model size,\nyielding large and powerful models. While it resulted in improving the\nperformance on diverse downstream tasks, it also introduced increased\ncomputational cost and inference time. In this work, we explore the\ndistillation of a large foundation model into a smaller one, reducing the\nnumber of parameters by several orders of magnitude. Leveraging distillation\ntechniques, our distilled model, H0-mini, achieves nearly comparable\nperformance to large FMs at a significantly reduced inference cost. It is\nevaluated on several public benchmarks, achieving 3rd place on the HEST\nbenchmark and 5th place on the EVA benchmark. Additionally, a robustness\nanalysis conducted on the PLISM dataset demonstrates that our distilled model\nreaches excellent robustness to variations in staining and scanning conditions,\nsignificantly outperforming other state-of-the art models. This opens new\nperspectives to design lightweight and robust models for digital pathology,\nwithout compromising on performance.\n","authors":["Alexandre Filiot","Nicolas Dop","Oussama Tchita","Auriane Riou","Rémy Dubois","Thomas Peeters","Daria Valter","Marin Scalbert","Charlie Saillard","Geneviève Robin","Antoine Olivier"],"pdf_url":"https://arxiv.org/pdf/2501.16239v3.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2502.21163v1","updated":"2025-02-28T15:42:58Z","published":"2025-02-28T15:42:58Z","title":"Adaptive Illumination-Invariant Synergistic Feature Integration in a\n  Stratified Granular Framework for Visible-Infrared Re-Identification","summary":"  Visible-Infrared Person Re-Identification (VI-ReID) plays a crucial role in\napplications such as search and rescue, infrastructure protection, and\nnighttime surveillance. However, it faces significant challenges due to\nmodality discrepancies, varying illumination, and frequent occlusions. To\novercome these obstacles, we propose \\textbf{AMINet}, an Adaptive Modality\nInteraction Network. AMINet employs multi-granularity feature extraction to\ncapture comprehensive identity attributes from both full-body and upper-body\nimages, improving robustness against occlusions and background clutter. The\nmodel integrates an interactive feature fusion strategy for deep intra-modal\nand cross-modal alignment, enhancing generalization and effectively bridging\nthe RGB-IR modality gap. Furthermore, AMINet utilizes phase congruency for\nrobust, illumination-invariant feature extraction and incorporates an adaptive\nmulti-scale kernel MMD to align feature distributions across varying scales.\nExtensive experiments on benchmark datasets demonstrate the effectiveness of\nour approach, achieving a Rank-1 accuracy of $74.75\\%$ on SYSU-MM01, surpassing\nthe baseline by $7.93\\%$ and outperforming the current state-of-the-art by\n$3.95\\%$.\n","authors":["Yuheng Jia","Wesley Armour"],"pdf_url":"https://arxiv.org/pdf/2502.21163v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.05343v2","updated":"2025-02-28T15:34:46Z","published":"2024-12-06T10:22:00Z","title":"Equivariant Denoisers for Image Restoration","summary":"  One key ingredient of image restoration is to define a realistic prior on\nclean images to complete the missing information in the observation.\nState-of-the-art restoration methods rely on a neural network to encode this\nprior. Moreover, typical image distributions are invariant to some set of\ntransformations, such as rotations or flips. However, most deep architectures\nare not designed to represent an invariant image distribution. Recent works\nhave proposed to overcome this difficulty by including equivariance properties\nwithin a Plug-and-Play paradigm. In this work, we propose a unified framework\nnamed Equivariant Regularization by Denoising (ERED) based on equivariant\ndenoisers and stochastic optimization. We analyze the convergence of this\nalgorithm and discuss its practical benefit.\n","authors":["Marien Renaud","Arthur Leclaire","Nicolas Papadakis"],"pdf_url":"https://arxiv.org/pdf/2412.05343v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21151v1","updated":"2025-02-28T15:30:55Z","published":"2025-02-28T15:30:55Z","title":"A Review on Generative AI For Text-To-Image and Image-To-Image\n  Generation and Implications To Scientific Images","summary":"  This review surveys the state-of-the-art in text-to-image and image-to-image\ngeneration within the scope of generative AI. We provide a comparative analysis\nof three prominent architectures: Variational Autoencoders, Generative\nAdversarial Networks and Diffusion Models. For each, we elucidate core\nconcepts, architectural innovations, and practical strengths and limitations,\nparticularly for scientific image understanding. Finally, we discuss critical\nopen challenges and potential future research directions in this rapidly\nevolving field.\n","authors":["Zineb Sordo","Eric Chagnon","Daniela Ushizima"],"pdf_url":"https://arxiv.org/pdf/2502.21151v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.06229v2","updated":"2025-02-28T15:28:44Z","published":"2025-01-08T00:19:52Z","title":"Open-Source Manually Annotated Vocal Tract Database for Automatic\n  Segmentation from 3D MRI Using Deep Learning: Benchmarking 2D and 3D\n  Convolutional and Transformer Networks","summary":"  Accurate segmentation of the vocal tract from magnetic resonance imaging\n(MRI) data is essential for various voice and speech applications. Manual\nsegmentation is time intensive and susceptible to errors. This study aimed to\nevaluate the efficacy of deep learning algorithms for automatic vocal tract\nsegmentation from 3D MRI.\n","authors":["Subin Erattakulangara","Karthika Kelat","Katie Burnham","Rachel Balbi","Sarah E. Gerard","David Meyer","Sajan Goud Lingala"],"pdf_url":"https://arxiv.org/pdf/2501.06229v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21147v1","updated":"2025-02-28T15:28:12Z","published":"2025-02-28T15:28:12Z","title":"Same accuracy, twice as fast: continuous training surpasses retraining\n  from scratch","summary":"  Continual learning aims to enable models to adapt to new datasets without\nlosing performance on previously learned data, often assuming that prior data\nis no longer available. However, in many practical scenarios, both old and new\ndata are accessible. In such cases, good performance on both datasets is\ntypically achieved by abandoning the model trained on the previous data and\nre-training a new model from scratch on both datasets. This training from\nscratch is computationally expensive. In contrast, methods that leverage the\npreviously trained model and old data are worthy of investigation, as they\ncould significantly reduce computational costs. Our evaluation framework\nquantifies the computational savings of such methods while maintaining or\nexceeding the performance of training from scratch. We identify key\noptimization aspects -- initialization, regularization, data selection, and\nhyper-parameters -- that can each contribute to reducing computational costs.\nFor each aspect, we propose effective first-step methods that already yield\nsubstantial computational savings. By combining these methods, we achieve up to\n2.7x reductions in computation time across various computer vision tasks,\nhighlighting the potential for further advancements in this area.\n","authors":["Eli Verwimp","Guy Hacohen","Tinne Tuytelaars"],"pdf_url":"https://arxiv.org/pdf/2502.21147v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.03550v2","updated":"2025-02-28T15:26:03Z","published":"2024-09-05T14:12:22Z","title":"DKDM: Data-Free Knowledge Distillation for Diffusion Models with Any\n  Architecture","summary":"  Diffusion models (DMs) have demonstrated exceptional generative capabilities\nacross various domains, including image, video, and so on. A key factor\ncontributing to their effectiveness is the high quantity and quality of data\nused during training. However, mainstream DMs now consume increasingly large\namounts of data. For example, training a Stable Diffusion model requires\nbillions of image-text pairs. This enormous data requirement poses significant\nchallenges for training large DMs due to high data acquisition costs and\nstorage expenses. To alleviate this data burden, we propose a novel scenario:\nusing existing DMs as data sources to train new DMs with any architecture. We\nrefer to this scenario as Data-Free Knowledge Distillation for Diffusion Models\n(DKDM), where the generative ability of DMs is transferred to new ones in a\ndata-free manner. To tackle this challenge, we make two main contributions.\nFirst, we introduce a DKDM objective that enables the training of new DMs via\ndistillation, without requiring access to the data. Second, we develop a\ndynamic iterative distillation method that efficiently extracts time-domain\nknowledge from existing DMs, enabling direct retrieval of training data without\nthe need for a prolonged generative process. To the best of our knowledge, we\nare the first to explore this scenario. Experimental results demonstrate that\nour data-free approach not only achieves competitive generative performance but\nalso, in some instances, outperforms models trained with the entire dataset.\n","authors":["Qianlong Xiang","Miao Zhang","Yuzhang Shang","Jianlong Wu","Yan Yan","Liqiang Nie"],"pdf_url":"https://arxiv.org/pdf/2409.03550v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.19250v2","updated":"2025-02-28T15:17:11Z","published":"2025-02-26T15:56:36Z","title":"ObjectVLA: End-to-End Open-World Object Manipulation Without\n  Demonstration","summary":"  Imitation learning has proven to be highly effective in teaching robots\ndexterous manipulation skills. However, it typically relies on large amounts of\nhuman demonstration data, which limits its scalability and applicability in\ndynamic, real-world environments. One key challenge in this context is object\ngeneralization, where a robot trained to perform a task with one object, such\nas \"hand over the apple,\" struggles to transfer its skills to a semantically\nsimilar but visually different object, such as \"hand over the peach.\" This gap\nin generalization to new objects beyond those in the same category has yet to\nbe adequately addressed in previous work on end-to-end visuomotor policy\nlearning. In this paper, we present a simple yet effective approach for\nachieving object generalization through Vision-Language-Action (VLA) models,\nreferred to as \\textbf{ObjectVLA}. Our model enables robots to generalize\nlearned skills to novel objects without requiring explicit human demonstrations\nfor each new target object. By leveraging vision-language pair data, our method\nprovides a lightweight and scalable way to inject knowledge about the target\nobject, establishing an implicit link between the object and the desired\naction. We evaluate ObjectVLA on a real robotic platform, demonstrating its\nability to generalize across 100 novel objects with a 64\\% success rate in\nselecting objects not seen during training. Furthermore, we propose a more\naccessible method for enhancing object generalization in VLA models, using a\nsmartphone to capture a few images and fine-tune the pre-trained model. These\nresults highlight the effectiveness of our approach in enabling object-level\ngeneralization and reducing the need for extensive human demonstrations, paving\nthe way for more flexible and scalable robotic learning systems.\n","authors":["Minjie Zhu","Yichen Zhu","Jinming Li","Zhongyi Zhou","Junjie Wen","Xiaoyu Liu","Chaomin Shen","Yaxin Peng","Feifei Feng"],"pdf_url":"https://arxiv.org/pdf/2502.19250v2.pdf","comment":"Project page at https://objectvla.github.io/"},{"id":"http://arxiv.org/abs/2412.12693v3","updated":"2025-02-28T15:14:37Z","published":"2024-12-17T09:10:55Z","title":"SPHERE: Unveiling Spatial Blind Spots in Vision-Language Models Through\n  Hierarchical Evaluation","summary":"  Current vision-language models may grasp basic spatial cues and simple\ndirections (e.g. left, right, front, back), but struggle with the\nmulti-dimensional spatial reasoning necessary for human-like understanding and\nreal-world applications. To address this gap, we develop SPHERE (Spatial\nPerception and Hierarchical Evaluation of REasoning), a hierarchical evaluation\nframework supported by a new human-annotated dataset. SPHERE systematically\nprobes models across increasing levels of complexity, from fundamental skills\nto multi-skill integration and high-level reasoning that combines spatial,\nvisual, and logical understanding. Benchmark evaluation of state-of-the-art\nmodels reveals significant deficiencies, especially in reasoning about distance\nand proximity, understanding both egocentric and allocentric perspectives, and\napplying spatial logic in physical contexts. These findings expose critical\nblind spots in existing models and underscore the need for more advanced\nspatial reasoning techniques, driving the development of vision-language models\nthat align more closely with human spatial cognition. The SPHERE benchmark is\navailable at https://github.com/zwenyu/SPHERE-VLM.\n","authors":["Wenyu Zhang","Wei En Ng","Lixin Ma","Yuwen Wang","Jungqi Zhao","Allison Koenecke","Boyang Li","Lu Wang"],"pdf_url":"https://arxiv.org/pdf/2412.12693v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21130v1","updated":"2025-02-28T15:10:07Z","published":"2025-02-28T15:10:07Z","title":"Fast and Accurate Gigapixel Pathological Image Classification with\n  Hierarchical Distillation Multi-Instance Learning","summary":"  Although multi-instance learning (MIL) has succeeded in pathological image\nclassification, it faces the challenge of high inference costs due to\nprocessing numerous patches from gigapixel whole slide images (WSIs). To\naddress this, we propose HDMIL, a hierarchical distillation multi-instance\nlearning framework that achieves fast and accurate classification by\neliminating irrelevant patches. HDMIL consists of two key components: the\ndynamic multi-instance network (DMIN) and the lightweight instance\npre-screening network (LIPN). DMIN operates on high-resolution WSIs, while LIPN\noperates on the corresponding low-resolution counterparts. During training,\nDMIN are trained for WSI classification while generating attention-score-based\nmasks that indicate irrelevant patches. These masks then guide the training of\nLIPN to predict the relevance of each low-resolution patch. During testing,\nLIPN first determines the useful regions within low-resolution WSIs, which\nindirectly enables us to eliminate irrelevant regions in high-resolution WSIs,\nthereby reducing inference time without causing performance degradation. In\naddition, we further design the first Chebyshev-polynomials-based\nKolmogorov-Arnold classifier in computational pathology, which enhances the\nperformance of HDMIL through learnable activation layers. Extensive experiments\non three public datasets demonstrate that HDMIL outperforms previous\nstate-of-the-art methods, e.g., achieving improvements of 3.13% in AUC while\nreducing inference time by 28.6% on the Camelyon16 dataset.\n","authors":["Jiuyang Dong","Junjun Jiang","Kui Jiang","Jiahan Li","Yongbing Zhang"],"pdf_url":"https://arxiv.org/pdf/2502.21130v1.pdf","comment":"11 pages, 4 figures, accepted by CVPR2025"},{"id":"http://arxiv.org/abs/2410.18456v3","updated":"2025-02-28T15:04:56Z","published":"2024-10-24T06:10:09Z","title":"Progressive Curriculum Learning with Scale-Enhanced U-Net for Continuous\n  Airway Segmentation","summary":"  Continuous and accurate segmentation of airways in chest CT images is\nessential for preoperative planning and real-time bronchoscopy navigation.\nDespite advances in deep learning for medical image segmentation, maintaining\nairway continuity remains a challenge, particularly due to intra-class\nimbalance between large and small branches and blurred CT scan details. To\naddress these challenges, we propose a progressive curriculum learning pipeline\nand a Scale-Enhanced U-Net (SE-UNet) to enhance segmentation continuity.\nSpecifically, our progressive curriculum learning pipeline consists of three\nstages: extracting main airways, identifying small airways, and repairing\ndiscontinuities. The cropping sampling strategy in each stage reduces feature\ninterference between airways of different scales, effectively addressing the\nchallenge of intra-class imbalance. In the third training stage, we present an\nAdaptive Topology-Responsive Loss (ATRL) to guide the network to focus on\nairway continuity. The progressive training pipeline shares the same SE-UNet,\nintegrating multi-scale inputs and Detail Information Enhancers (DIEs) to\nenhance information flow and effectively capture the intricate details of small\nairways. Additionally, we propose a robust airway tree parsing method and\nhierarchical evaluation metrics to provide more clinically relevant and precise\nanalysis. Experiments on both in-house and public datasets demonstrate that our\nmethod outperforms existing approaches, significantly improving the accuracy of\nsmall airways and the completeness of the airway tree. The code will be\nreleased upon publication.\n","authors":["Bingyu Yang","Qingyao Tian","Huai Liao","Xinyan Huang","Jinlin Wu","Jingdi Hu","Hongbin Liu"],"pdf_url":"https://arxiv.org/pdf/2410.18456v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21120v1","updated":"2025-02-28T14:55:37Z","published":"2025-02-28T14:55:37Z","title":"SEE: See Everything Every Time -- Adaptive Brightness Adjustment for\n  Broad Light Range Images via Events","summary":"  Event cameras, with a high dynamic range exceeding $120dB$, significantly\noutperform traditional embedded cameras, robustly recording detailed changing\ninformation under various lighting conditions, including both low- and\nhigh-light situations. However, recent research on utilizing event data has\nprimarily focused on low-light image enhancement, neglecting image enhancement\nand brightness adjustment across a broader range of lighting conditions, such\nas normal or high illumination. Based on this, we propose a novel research\nquestion: how to employ events to enhance and adaptively adjust the brightness\nof images captured under broad lighting conditions? To investigate this\nquestion, we first collected a new dataset, SEE-600K, consisting of 610,126\nimages and corresponding events across 202 scenarios, each featuring an average\nof four lighting conditions with over a 1000-fold variation in illumination.\nSubsequently, we propose a framework that effectively utilizes events to\nsmoothly adjust image brightness through the use of prompts. Our framework\ncaptures color through sensor patterns, uses cross-attention to model events as\na brightness dictionary, and adjusts the image's dynamic range to form a broad\nlight-range representation (BLR), which is then decoded at the pixel level\nbased on the brightness prompt. Experimental results demonstrate that our\nmethod not only performs well on the low-light enhancement dataset but also\nshows robust performance on broader light-range image enhancement using the\nSEE-600K dataset. Additionally, our approach enables pixel-level brightness\nadjustment, providing flexibility for post-processing and inspiring more\nimaging applications. The dataset and source code are publicly available\nat:https://github.com/yunfanLu/SEE.\n","authors":["Yunfan Lu","Xiaogang Xu","Hao Lu","Yanlin Qian","Pengteng Li","Huizai Yao","Bin Yang","Junyi Li","Qianyi Cai","Weiyu Guo","Hui Xiong"],"pdf_url":"https://arxiv.org/pdf/2502.21120v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.04138v2","updated":"2025-02-28T14:49:44Z","published":"2024-06-06T14:59:39Z","title":"The 3D-PC: a benchmark for visual perspective taking in humans and\n  machines","summary":"  Visual perspective taking (VPT) is the ability to perceive and reason about\nthe perspectives of others. It is an essential feature of human intelligence,\nwhich develops over the first decade of life and requires an ability to process\nthe 3D structure of visual scenes. A growing number of reports have indicated\nthat deep neural networks (DNNs) become capable of analyzing 3D scenes after\ntraining on large image datasets. We investigated if this emergent ability for\n3D analysis in DNNs is sufficient for VPT with the 3D perception challenge\n(3D-PC): a novel benchmark for 3D perception in humans and DNNs. The 3D-PC is\ncomprised of three 3D-analysis tasks posed within natural scene images: 1. a\nsimple test of object depth order, 2. a basic VPT task (VPT-basic), and 3.\nanother version of VPT (VPT-Strategy) designed to limit the effectiveness of\n\"shortcut\" visual strategies. We tested human participants (N=33) and linearly\nprobed or text-prompted over 300 DNNs on the challenge and found that nearly\nall of the DNNs approached or exceeded human accuracy in analyzing object depth\norder. Surprisingly, DNN accuracy on this task correlated with their object\nrecognition performance. In contrast, there was an extraordinary gap between\nDNNs and humans on VPT-basic. Humans were nearly perfect, whereas most DNNs\nwere near chance. Fine-tuning DNNs on VPT-basic brought them close to human\nperformance, but they, unlike humans, dropped back to chance when tested on\nVPT-Strategy. Our challenge demonstrates that the training routines and\narchitectures of today's DNNs are well-suited for learning basic 3D properties\nof scenes and objects but are ill-suited for reasoning about these properties\nas humans do. We release our 3D-PC datasets and code to help bridge this gap in\n3D perception between humans and machines.\n","authors":["Drew Linsley","Peisen Zhou","Alekh Karkada Ashok","Akash Nagaraj","Gaurav Gaonkar","Francis E Lewis","Zygmunt Pizlo","Thomas Serre"],"pdf_url":"https://arxiv.org/pdf/2406.04138v2.pdf","comment":"Published in ICLR 2025"},{"id":"http://arxiv.org/abs/2502.21109v1","updated":"2025-02-28T14:47:20Z","published":"2025-02-28T14:47:20Z","title":"\"No negatives needed\": weakly-supervised regression for interpretable\n  tumor detection in whole-slide histopathology images","summary":"  Accurate tumor detection in digital pathology whole-slide images (WSIs) is\ncrucial for cancer diagnosis and treatment planning. Multiple Instance Learning\n(MIL) has emerged as a widely used approach for weakly-supervised tumor\ndetection with large-scale data without the need for manual annotations.\nHowever, traditional MIL methods often depend on classification tasks that\nrequire tumor-free cases as negative examples, which are challenging to obtain\nin real-world clinical workflows, especially for surgical resection specimens.\nWe address this limitation by reformulating tumor detection as a regression\ntask, estimating tumor percentages from WSIs, a clinically available target\nacross multiple cancer types. In this paper, we provide an analysis of the\nproposed weakly-supervised regression framework by applying it to multiple\norgans, specimen types and clinical scenarios. We characterize the robustness\nof our framework to tumor percentage as a noisy regression target, and\nintroduce a novel concept of amplification technique to improve tumor detection\nsensitivity when learning from small tumor regions. Finally, we provide\ninterpretable insights into the model's predictions by analyzing visual\nattention and logit maps. Our code is available at\nhttps://github.com/DIAGNijmegen/tumor-percentage-mil-regression.\n","authors":["Marina D'Amato","Jeroen van der Laak","Francesco Ciompi"],"pdf_url":"https://arxiv.org/pdf/2502.21109v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21106v1","updated":"2025-02-28T14:44:55Z","published":"2025-02-28T14:44:55Z","title":"A Non-contrast Head CT Foundation Model for Comprehensive Neuro-Trauma\n  Triage","summary":"  Recent advancements in AI and medical imaging offer transformative potential\nin emergency head CT interpretation for reducing assessment times and improving\naccuracy in the face of an increasing request of such scans and a global\nshortage in radiologists. This study introduces a 3D foundation model for\ndetecting diverse neuro-trauma findings with high accuracy and efficiency.\nUsing large language models (LLMs) for automatic labeling, we generated\ncomprehensive multi-label annotations for critical conditions. Our approach\ninvolved pretraining neural networks for hemorrhage subtype segmentation and\nbrain anatomy parcellation, which were integrated into a pretrained\ncomprehensive neuro-trauma detection network through multimodal fine-tuning.\nPerformance evaluation against expert annotations and comparison with CT-CLIP\ndemonstrated strong triage accuracy across major neuro-trauma findings, such as\nhemorrhage and midline shift, as well as less frequent critical conditions such\nas cerebral edema and arterial hyperdensity. The integration of neuro-specific\nfeatures significantly enhanced diagnostic capabilities, achieving an average\nAUC of 0.861 for 16 neuro-trauma conditions. This work advances foundation\nmodels in medical imaging, serving as a benchmark for future AI-assisted\nneuro-trauma diagnostics in emergency radiology.\n","authors":["Youngjin Yoo","Bogdan Georgescu","Yanbo Zhang","Sasa Grbic","Han Liu","Gabriela D. Aldea","Thomas J. Re","Jyotipriya Das","Poikavila Ullaskrishnan","Eva Eibenberger","Andrei Chekkoury","Uttam K. Bodanapally","Savvas Nicolaou","Pina C. Sanelli","Thomas J. Schroeppel","Yvonne W. Lui","Eli Gibson"],"pdf_url":"https://arxiv.org/pdf/2502.21106v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.07152v3","updated":"2025-02-28T14:42:27Z","published":"2023-05-11T21:44:39Z","title":"Intuitive Surgical SurgToolLoc Challenge Results: 2022-2023","summary":"  Robotic assisted (RA) surgery promises to transform surgical intervention.\nIntuitive Surgical is committed to fostering these changes and the machine\nlearning models and algorithms that will enable them. With these goals in mind\nwe have invited the surgical data science community to participate in a yearly\ncompetition hosted through the Medical Imaging Computing and Computer Assisted\nInterventions (MICCAI) conference. With varying changes from year to year, we\nhave challenged the community to solve difficult machine learning problems in\nthe context of advanced RA applications. Here we document the results of these\nchallenges, focusing on surgical tool localization (SurgToolLoc). The publicly\nreleased dataset that accompanies these challenges is detailed in a separate\npaper arXiv:2501.09209 [1].\n","authors":["Aneeq Zia","Max Berniker","Rogerio Garcia Nespolo","Conor Perreault","Kiran Bhattacharyya","Xi Liu","Ziheng Wang","Satoshi Kondo","Satoshi Kasai","Kousuke Hirasawa","Bo Liu","David Austin","Yiheng Wang","Michal Futrega","Jean-Francois Puget","Zhenqiang Li","Yoichi Sato","Ryo Fujii","Ryo Hachiuma","Mana Masuda","Hideo Saito","An Wang","Mengya Xu","Mobarakol Islam","Long Bai","Winnie Pang","Hongliang Ren","Chinedu Nwoye","Luca Sestini","Nicolas Padoy","Maximilian Nielsen","Samuel Schüttler","Thilo Sentker","Hümeyra Husseini","Ivo Baltruschat","Rüdiger Schmitz","René Werner","Aleksandr Matsun","Mugariya Farooq","Numan Saaed","Jose Renato Restom Viera","Mohammad Yaqub","Neil Getty","Fangfang Xia","Zixuan Zhao","Xiaotian Duan","Xing Yao","Ange Lou","Hao Yang","Jintong Han","Jack Noble","Jie Ying Wu","Tamer Abdulbaki Alshirbaji","Nour Aldeen Jalal","Herag Arabian","Ning Ding","Knut Moeller","Weiliang Chen","Quan He","Muhammad Bilal","Taofeek Akinosho","Adnan Qayyum","Massimo Caputo","Hunaid Vohra","Michael Loizou","Anuoluwapo Ajayi","Ilhem Berrou","Faatihah Niyi-Odumosu","Charlie Budd","Oluwatosin Alabi","Tom Vercauteren","Ruoxi Zhao","Ayberk Acar","John Han","Jumanh Atoum","Yinhong Qin","Jie Ying Wu","Surong Hua","Lu Ping","Wenming Wu","Rongfeng Wei","Jinlin Wu","You Pang","Zhen Chen","Tim Jaspers","Amine Yamlahi","Piotr Kalinowski","Dominik Michael","Tim Rä dsch","Marco Hübner","Danail Stoyanov","Stefanie Speidel","Lena Maier-Hein","Anthony Jarc"],"pdf_url":"https://arxiv.org/pdf/2305.07152v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.03168v2","updated":"2025-02-28T14:39:17Z","published":"2024-07-03T14:41:39Z","title":"LivePortrait: Efficient Portrait Animation with Stitching and\n  Retargeting Control","summary":"  Portrait Animation aims to synthesize a lifelike video from a single source\nimage, using it as an appearance reference, with motion (i.e., facial\nexpressions and head pose) derived from a driving video, audio, text, or\ngeneration. Instead of following mainstream diffusion-based methods, we explore\nand extend the potential of the implicit-keypoint-based framework, which\neffectively balances computational efficiency and controllability. Building\nupon this, we develop a video-driven portrait animation framework named\nLivePortrait with a focus on better generalization, controllability, and\nefficiency for practical usage. To enhance the generation quality and\ngeneralization ability, we scale up the training data to about 69 million\nhigh-quality frames, adopt a mixed image-video training strategy, upgrade the\nnetwork architecture, and design better motion transformation and optimization\nobjectives. Additionally, we discover that compact implicit keypoints can\neffectively represent a kind of blendshapes and meticulously propose a\nstitching and two retargeting modules, which utilize a small MLP with\nnegligible computational overhead, to enhance the controllability. Experimental\nresults demonstrate the efficacy of our framework even compared to\ndiffusion-based methods. The generation speed remarkably reaches 12.8ms on an\nRTX 4090 GPU with PyTorch. The inference code and models are available at\nhttps://github.com/KwaiVGI/LivePortrait\n","authors":["Jianzhu Guo","Dingyun Zhang","Xiaoqiang Liu","Zhizhou Zhong","Yuan Zhang","Pengfei Wan","Di Zhang"],"pdf_url":"https://arxiv.org/pdf/2407.03168v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21099v1","updated":"2025-02-28T14:37:56Z","published":"2025-02-28T14:37:56Z","title":"Adaptive Accelerated Proximal Gradient Methods with Variance Reduction\n  for Composite Nonconvex Finite-Sum Minimization","summary":"  This paper proposes {\\sf AAPG-SPIDER}, an Adaptive Accelerated Proximal\nGradient (AAPG) method with variance reduction for minimizing composite\nnonconvex finite-sum functions. It integrates three acceleration techniques:\nadaptive stepsizes, Nesterov's extrapolation, and the recursive stochastic\npath-integrated estimator SPIDER. While targeting stochastic finite-sum\nproblems, {\\sf AAPG-SPIDER} simplifies to {\\sf AAPG} in the full-batch,\nnon-stochastic setting, which is also of independent interest. To our\nknowledge, {\\sf AAPG-SPIDER} and {\\sf AAPG} are the first learning-rate-free\nmethods to achieve optimal iteration complexity for this class of\n\\textit{composite} minimization problems. Specifically, {\\sf AAPG} achieves the\noptimal iteration complexity of $\\mathcal{O}(N \\epsilon^{-2})$, while {\\sf\nAAPG-SPIDER} achieves $\\mathcal{O}(N + \\sqrt{N} \\epsilon^{-2})$ for finding\n$\\epsilon$-approximate stationary points, where $N$ is the number of component\nfunctions. Under the Kurdyka-Lojasiewicz (KL) assumption, we establish\nnon-ergodic convergence rates for both methods. Preliminary experiments on\nsparse phase retrieval and linear eigenvalue problems demonstrate the superior\nperformance of {\\sf AAPG-SPIDER} and {\\sf AAPG} compared to existing methods.\n","authors":["Ganzhao Yuan"],"pdf_url":"https://arxiv.org/pdf/2502.21099v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.16622v3","updated":"2025-02-28T14:34:45Z","published":"2025-02-23T15:50:42Z","title":"Diagnosing COVID-19 Severity from Chest X-Ray Images Using ViT and CNN\n  Architectures","summary":"  The COVID-19 pandemic strained healthcare resources and prompted discussion\nabout how machine learning can alleviate physician burdens and contribute to\ndiagnosis. Chest x-rays (CXRs) are used for diagnosis of COVID-19, but few\nstudies predict the severity of a patient's condition from CXRs. In this study,\nwe produce a large COVID severity dataset by merging three sources and\ninvestigate the efficacy of transfer learning using ImageNet- and\nCXR-pretrained models and vision transformers (ViTs) in both severity\nregression and classification tasks. A pretrained DenseNet161 model performed\nthe best on the three class severity prediction problem, reaching 80% accuracy\noverall and 77.3%, 83.9%, and 70% on mild, moderate and severe cases,\nrespectively. The ViT had the best regression results, with a mean absolute\nerror of 0.5676 compared to radiologist-predicted severity scores. The\nproject's source code is publicly available.\n","authors":["Luis Lara","Lucia Eve Berger","Rajesh Raju"],"pdf_url":"https://arxiv.org/pdf/2502.16622v3.pdf","comment":"Upon reflection, the final version of this work does not meet the\n  author's personal standards for thoroughness and clarity. As a result, the\n  authors have chosen to withdraw the paper to prevent the dissemination of\n  work that may not fully reflect the level of quality they strive to maintain"},{"id":"http://arxiv.org/abs/2502.21093v1","updated":"2025-02-28T14:32:04Z","published":"2025-02-28T14:32:04Z","title":"FlexDrive: Toward Trajectory Flexibility in Driving Scene Reconstruction\n  and Rendering","summary":"  Driving scene reconstruction and rendering have advanced significantly using\nthe 3D Gaussian Splatting. However, most prior research has focused on the\nrendering quality along a pre-recorded vehicle path and struggles to generalize\nto out-of-path viewpoints, which is caused by the lack of high-quality\nsupervision in those out-of-path views. To address this issue, we introduce an\nInverse View Warping technique to create compact and high-quality images as\nsupervision for the reconstruction of the out-of-path views, enabling\nhigh-quality rendering results for those views. For accurate and robust inverse\nview warping, a depth bootstrap strategy is proposed to obtain on-the-fly dense\ndepth maps during the optimization process, overcoming the sparsity and\nincompleteness of LiDAR depth data. Our method achieves superior in-path and\nout-of-path reconstruction and rendering performance on the widely used Waymo\nOpen dataset. In addition, a simulator-based benchmark is proposed to obtain\nthe out-of-path ground truth and quantitatively evaluate the performance of\nout-of-path rendering, where our method outperforms previous methods by a\nsignificant margin.\n","authors":["Jingqiu Zhou","Lue Fan","Linjiang Huang","Xiaoyu Shi","Si Liu","Zhaoxiang Zhang","Hongsheng Li"],"pdf_url":"https://arxiv.org/pdf/2502.21093v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20077v2","updated":"2025-02-28T14:25:18Z","published":"2025-02-27T13:34:55Z","title":"SegLocNet: Multimodal Localization Network for Autonomous Driving via\n  Bird's-Eye-View Segmentation","summary":"  Robust and accurate localization is critical for autonomous driving.\nTraditional GNSS-based localization methods suffer from signal occlusion and\nmultipath effects in urban environments. Meanwhile, methods relying on\nhigh-definition (HD) maps are constrained by the high costs associated with the\nconstruction and maintenance of HD maps. Standard-definition (SD) maps-based\nmethods, on the other hand, often exhibit unsatisfactory performance or poor\ngeneralization ability due to overfitting. To address these challenges, we\npropose SegLocNet, a multimodal GNSS-free localization network that achieves\nprecise localization using bird's-eye-view (BEV) semantic segmentation.\nSegLocNet employs a BEV segmentation network to generate semantic maps from\nmultiple sensor inputs, followed by an exhaustive matching process to estimate\nthe vehicle's ego pose. This approach avoids the limitations of\nregression-based pose estimation and maintains high interpretability and\ngeneralization. By introducing a unified map representation, our method can be\napplied to both HD and SD maps without any modifications to the network\narchitecture, thereby balancing localization accuracy and area coverage.\nExtensive experiments on the nuScenes and Argoverse datasets demonstrate that\nour method outperforms the current state-of-the-art methods, and that our\nmethod can accurately estimate the ego pose in urban environments without\nrelying on GNSS, while maintaining strong generalization ability. Our code and\npre-trained model will be released publicly.\n","authors":["Zijie Zhou","Zhangshuo Qi","Luqi Cheng","Guangming Xiong"],"pdf_url":"https://arxiv.org/pdf/2502.20077v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.07076v2","updated":"2025-02-28T14:19:29Z","published":"2025-01-13T06:13:25Z","title":"Representation Learning of Point Cloud Upsampling in Global and Local\n  Inputs","summary":"  In recent years, point cloud upsampling has been widely applied in fields\nsuch as 3D reconstruction. Our study investigates the factors influencing point\ncloud upsampling on both global and local levels through representation\nlearning. Specifically, the paper inputs global and local information of the\nsame point cloud model object into two encoders to extract these features,\nfuses them, and then feeds the combined features into an upsampling decoder.\nThe goal is to address issues of sparsity and noise in point clouds by\nleveraging prior knowledge from both global and local inputs. And the proposed\nframework can be applied to any state-of-the-art point cloud upsampling neural\nnetwork. Experiments were conducted on a series of autoencoder-based models\nutilizing deep learning, yielding interpretability for both global and local\ninputs, and it has been proven in the results that our proposed framework can\nfurther improve the upsampling effect in previous SOTA works. At the same time,\nthe Saliency Map reflects the differences between global and local feature\ninputs, as well as the effectiveness of training with both inputs in parallel.\n","authors":["Tongxu Zhang","Bei Wang"],"pdf_url":"https://arxiv.org/pdf/2501.07076v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21085v1","updated":"2025-02-28T14:18:39Z","published":"2025-02-28T14:18:39Z","title":"BST: Badminton Stroke-type Transformer for Skeleton-based Action\n  Recognition in Racket Sports","summary":"  Badminton, known for having the fastest ball speeds among all sports,\npresents significant challenges to the field of computer vision, including\nplayer identification, court line detection, shuttlecock trajectory tracking,\nand player stroke-type classification. In this paper, we introduce a novel\nvideo segmentation strategy to extract frames of each player's racket swing in\na badminton broadcast match. These segmented frames are then processed by two\nexisting models: one for Human Pose Estimation to obtain player skeletal\njoints, and the other for shuttlecock trajectory detection to extract\nshuttlecock trajectories. Leveraging these joints, trajectories, and player\npositions as inputs, we propose Badminton Stroke-type Transformer (BST) to\nclassify player stroke-types in singles. To the best of our knowledge,\nexperimental results demonstrate that our method outperforms the previous\nstate-of-the-art on the largest publicly available badminton video dataset,\nShuttleSet, which shows that effectively leveraging ball trajectory is likely\nto be a trend for racket sports action recognition.\n","authors":["Jing-Yuan Chang"],"pdf_url":"https://arxiv.org/pdf/2502.21085v1.pdf","comment":"8 pages (excluding references). The code will be released in a few\n  months"},{"id":"http://arxiv.org/abs/2502.21079v1","updated":"2025-02-28T14:11:20Z","published":"2025-02-28T14:11:20Z","title":"Training-free and Adaptive Sparse Attention for Efficient Long Video\n  Generation","summary":"  Generating high-fidelity long videos with Diffusion Transformers (DiTs) is\noften hindered by significant latency, primarily due to the computational\ndemands of attention mechanisms. For instance, generating an 8-second 720p\nvideo (110K tokens) with HunyuanVideo takes about 600 PFLOPs, with around 500\nPFLOPs consumed by attention computations. To address this issue, we propose\nAdaSpa, the first Dynamic Pattern and Online Precise Search sparse attention\nmethod. Firstly, to realize the Dynamic Pattern, we introduce a blockified\npattern to efficiently capture the hierarchical sparsity inherent in DiTs. This\nis based on our observation that sparse characteristics of DiTs exhibit\nhierarchical and blockified structures between and within different modalities.\nThis blockified approach significantly reduces the complexity of attention\ncomputation while maintaining high fidelity in the generated videos. Secondly,\nto enable Online Precise Search, we propose the Fused LSE-Cached Search with\nHead-adaptive Hierarchical Block Sparse Attention. This method is motivated by\nour finding that DiTs' sparse pattern and LSE vary w.r.t. inputs, layers, and\nheads, but remain invariant across denoising steps. By leveraging this\ninvariance across denoising steps, it adapts to the dynamic nature of DiTs and\nallows for precise, real-time identification of sparse indices with minimal\noverhead. AdaSpa is implemented as an adaptive, plug-and-play solution and can\nbe integrated seamlessly with existing DiTs, requiring neither additional\nfine-tuning nor a dataset-dependent profiling. Extensive experiments validate\nthat AdaSpa delivers substantial acceleration across various models while\npreserving video quality, establishing itself as a robust and scalable approach\nto efficient video generation.\n","authors":["Yifei Xia","Suhan Ling","Fangcheng Fu","Yujie Wang","Huixia Li","Xuefeng Xiao","Bin Cui"],"pdf_url":"https://arxiv.org/pdf/2502.21079v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21077v1","updated":"2025-02-28T14:10:42Z","published":"2025-02-28T14:10:42Z","title":"Enhancing deep neural networks through complex-valued representations\n  and Kuramoto synchronization dynamics","summary":"  Neural synchrony is hypothesized to play a crucial role in how the brain\norganizes visual scenes into structured representations, enabling the robust\nencoding of multiple objects within a scene. However, current deep learning\nmodels often struggle with object binding, limiting their ability to represent\nmultiple objects effectively. Inspired by neuroscience, we investigate whether\nsynchrony-based mechanisms can enhance object encoding in artificial models\ntrained for visual categorization. Specifically, we combine complex-valued\nrepresentations with Kuramoto dynamics to promote phase alignment, facilitating\nthe grouping of features belonging to the same object. We evaluate two\narchitectures employing synchrony: a feedforward model and a recurrent model\nwith feedback connections to refine phase synchronization using top-down\ninformation. Both models outperform their real-valued counterparts and\ncomplex-valued models without Kuramoto synchronization on tasks involving\nmulti-object images, such as overlapping handwritten digits, noisy inputs, and\nout-of-distribution transformations. Our findings highlight the potential of\nsynchrony-driven mechanisms to enhance deep learning models, improving their\nperformance, robustness, and generalization in complex visual categorization\ntasks.\n","authors":["Sabine Muzellec","Andrea Alamia","Thomas Serre","Rufin VanRullen"],"pdf_url":"https://arxiv.org/pdf/2502.21077v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21075v1","updated":"2025-02-28T14:08:30Z","published":"2025-02-28T14:08:30Z","title":"Spatial Reasoning with Denoising Models","summary":"  We introduce Spatial Reasoning Models (SRMs), a framework to perform\nreasoning over sets of continuous variables via denoising generative models.\nSRMs infer continuous representations on a set of unobserved variables, given\nobservations on observed variables. Current generative models on spatial\ndomains, such as diffusion and flow matching models, often collapse to\nhallucination in case of complex distributions. To measure this, we introduce a\nset of benchmark tasks that test the quality of complex reasoning in generative\nmodels and can quantify hallucination. The SRM framework allows to report key\nfindings about importance of sequentialization in generation, the associated\norder, as well as the sampling strategies during training. It demonstrates, for\nthe first time, that order of generation can successfully be predicted by the\ndenoising network itself. Using these findings, we can increase the accuracy of\nspecific reasoning tasks from <1% to >50%.\n","authors":["Christopher Wewer","Bart Pogodzinski","Bernt Schiele","Jan Eric Lenssen"],"pdf_url":"https://arxiv.org/pdf/2502.21075v1.pdf","comment":"Project website: https://geometric-rl.mpi-inf.mpg.de/srm/"},{"id":"http://arxiv.org/abs/2502.21067v1","updated":"2025-02-28T14:03:04Z","published":"2025-02-28T14:03:04Z","title":"Fast 3D point clouds retrieval for Large-scale 3D Place Recognition","summary":"  Retrieval in 3D point clouds is a challenging task that consists in\nretrieving the most similar point clouds to a given query within a reference of\n3D points. Current methods focus on comparing descriptors of point clouds in\norder to identify similar ones. Due to the complexity of this latter step, here\nwe focus on the acceleration of the retrieval by adapting the Differentiable\nSearch Index (DSI), a transformer-based approach initially designed for text\ninformation retrieval, for 3D point clouds retrieval. Our approach generates 1D\nidentifiers based on the point descriptors, enabling direct retrieval in\nconstant time. To adapt DSI to 3D data, we integrate Vision Transformers to map\ndescriptors to these identifiers while incorporating positional and semantic\nencoding. The approach is evaluated for place recognition on a public benchmark\ncomparing its retrieval capabilities against state-of-the-art methods, in terms\nof quality and speed of returned point clouds.\n","authors":["Chahine-Nicolas Zede","Laurent Carrafa","Valérie Gouet-Brunet"],"pdf_url":"https://arxiv.org/pdf/2502.21067v1.pdf","comment":"8 pages, 1 figures"},{"id":"http://arxiv.org/abs/2502.21059v1","updated":"2025-02-28T13:59:11Z","published":"2025-02-28T13:59:11Z","title":"FC-Attack: Jailbreaking Large Vision-Language Models via Auto-Generated\n  Flowcharts","summary":"  Large Vision-Language Models (LVLMs) have become powerful and widely adopted\nin some practical applications. However, recent research has revealed their\nvulnerability to multimodal jailbreak attacks, whereby the model can be induced\nto generate harmful content, leading to safety risks. Although most LVLMs have\nundergone safety alignment, recent research shows that the visual modality is\nstill vulnerable to jailbreak attacks. In our work, we discover that by using\nflowcharts with partially harmful information, LVLMs can be induced to provide\nadditional harmful details. Based on this, we propose a jailbreak attack method\nbased on auto-generated flowcharts, FC-Attack. Specifically, FC-Attack first\nfine-tunes a pre-trained LLM to create a step-description generator based on\nbenign datasets. The generator is then used to produce step descriptions\ncorresponding to a harmful query, which are transformed into flowcharts in 3\ndifferent shapes (vertical, horizontal, and S-shaped) as visual prompts. These\nflowcharts are then combined with a benign textual prompt to execute a\njailbreak attack on LVLMs. Our evaluations using the Advbench dataset show that\nFC-Attack achieves over 90% attack success rates on Gemini-1.5, Llaval-Next,\nQwen2-VL, and InternVL-2.5 models, outperforming existing LVLM jailbreak\nmethods. Additionally, we investigate factors affecting the attack performance,\nincluding the number of steps and the font styles in the flowcharts. Our\nevaluation shows that FC-Attack can improve the jailbreak performance from 4%\nto 28% in Claude-3.5 by changing the font style. To mitigate the attack, we\nexplore several defenses and find that AdaShield can largely reduce the\njailbreak performance but with the cost of utility drop.\n","authors":["Ziyi Zhang","Zhen Sun","Zongmin Zhang","Jihui Guo","Xinlei He"],"pdf_url":"https://arxiv.org/pdf/2502.21059v1.pdf","comment":"13 pages, 6 figures"},{"id":"http://arxiv.org/abs/2502.21054v1","updated":"2025-02-28T13:53:35Z","published":"2025-02-28T13:53:35Z","title":"HoloMine: A Synthetic Dataset for Buried Landmines Recognition using\n  Microwave Holographic Imaging","summary":"  The detection and removal of landmines is a complex and risky task that\nrequires advanced remote sensing techniques to reduce the risk for the\nprofessionals involved in this task. In this paper, we propose a novel\nsynthetic dataset for buried landmine detection to provide researchers with a\nvaluable resource to observe, measure, locate, and address issues in landmine\ndetection. The dataset consists of 41,800 microwave holographic images (2D) and\ntheir holographic inverted scans (3D) of different types of buried objects,\nincluding landmines, clutter, and pottery objects, and is collected by means of\na microwave holography sensor.\n  We evaluate the performance of several state-of-the-art deep learning models\ntrained on our synthetic dataset for various classification tasks. While the\nresults do not yield yet high performances, showing the difficulty of the\nproposed task, we believe that our dataset has significant potential to drive\nprogress in the field of landmine detection thanks to the accuracy and\nresolution obtainable using holographic radars.\n  To the best of our knowledge, our dataset is the first of its kind and will\nhelp drive further research on computer vision methods to automatize mine\ndetection, with the overall goal of reducing the risks and the costs of the\ndemining process.\n","authors":["Emanuele Vivoli","Lorenzo Capineri","Marco Bertini"],"pdf_url":"https://arxiv.org/pdf/2502.21054v1.pdf","comment":"under review"},{"id":"http://arxiv.org/abs/2410.01506v4","updated":"2025-02-28T13:52:40Z","published":"2024-10-02T12:58:55Z","title":"Learnable Expansion of Graph Operators for Multi-Modal Feature Fusion","summary":"  In computer vision tasks, features often come from diverse representations,\ndomains (e.g., indoor and outdoor), and modalities (e.g., text, images, and\nvideos). Effectively fusing these features is essential for robust performance,\nespecially with the availability of powerful pre-trained models like\nvision-language models. However, common fusion methods, such as concatenation,\nelement-wise operations, and non-linear techniques, often fail to capture\nstructural relationships, deep feature interactions, and suffer from\ninefficiency or misalignment of features across domains or modalities. In this\npaper, we shift from high-dimensional feature space to a lower-dimensional,\ninterpretable graph space by constructing relationship graphs that encode\nfeature relationships at different levels, e.g., clip, frame, patch, token,\netc. To capture deeper interactions, we expand graphs through iterative graph\nrelationship updates and introduce a learnable graph fusion operator to\nintegrate these expanded relationships for more effective fusion. Our approach\nis relationship-centric, operates in a homogeneous space, and is mathematically\nprincipled, resembling element-wise relationship score aggregation via\nmultilinear polynomials. We demonstrate the effectiveness of our graph-based\nfusion method on video anomaly detection, showing strong performance across\nmulti-representational, multi-modal, and multi-domain feature fusion tasks.\n","authors":["Dexuan Ding","Lei Wang","Liyun Zhu","Tom Gedeon","Piotr Koniusz"],"pdf_url":"https://arxiv.org/pdf/2410.01506v4.pdf","comment":"Accepted at the Thirteenth International Conference on Learning\n  Representations (ICLR 2025)"},{"id":"http://arxiv.org/abs/2405.10008v3","updated":"2025-02-28T13:48:17Z","published":"2024-05-16T11:49:08Z","title":"Solving the enigma: Enhancing faithfulness and comprehensibility in\n  explanations of deep networks","summary":"  The accelerated progress of artificial intelligence (AI) has popularized deep\nlearning models across various domains, yet their inherent opacity poses\nchallenges, particularly in critical fields like healthcare, medicine, and the\ngeosciences. Explainable AI (XAI) has emerged to shed light on these 'black\nbox' models, aiding in deciphering their decision-making processes. However,\ndifferent XAI methods often produce significantly different explanations,\nleading to high inter-method variability that increases uncertainty and\nundermines trust in deep networks' predictions. In this study, we address this\nchallenge by introducing a novel framework designed to enhance the\nexplainability of deep networks through a dual focus on maximizing both\naccuracy and comprehensibility in the explanations. Our framework integrates\noutputs from multiple established XAI methods and leverages a non-linear neural\nnetwork model, termed the 'explanation optimizer,' to construct a unified,\noptimal explanation. The optimizer evaluates explanations using two key\nmetrics: faithfulness (accuracy in reflecting the network's decisions) and\ncomplexity (comprehensibility). By balancing these, it provides accurate and\naccessible explanations, addressing a key XAI limitation. Experiments on\nmulti-class and binary classification in 2D object and 3D neuroscience imaging\nconfirm its efficacy. Our optimizer achieved faithfulness scores 155% and 63%\nhigher than the best XAI methods in 3D and 2D tasks, respectively, while also\nreducing complexity for better understanding. These results demonstrate that\noptimal explanations based on specific quality criteria are achievable,\noffering a solution to the issue of inter-method variability in the current XAI\nliterature and supporting more trustworthy deep network predictions\n","authors":["Michail Mamalakis","Antonios Mamalakis","Ingrid Agartz","Lynn Egeland Mørch-Johnsen","Graham Murray","John Suckling","Pietro Lio"],"pdf_url":"https://arxiv.org/pdf/2405.10008v3.pdf","comment":"Accepted manuscript in AI Open Journal\n  (https://www.sciencedirect.com/journal/ai-open)"},{"id":"http://arxiv.org/abs/2502.21049v1","updated":"2025-02-28T13:45:09Z","published":"2025-02-28T13:45:09Z","title":"Synthesizing Individualized Aging Brains in Health and Disease with\n  Generative Models and Parallel Transport","summary":"  Simulating prospective magnetic resonance imaging (MRI) scans from a given\nindividual brain image is challenging, as it requires accounting for canonical\nchanges in aging and/or disease progression while also considering the\nindividual brain's current status and unique characteristics. While current\ndeep generative models can produce high-resolution anatomically accurate\ntemplates for population-wide studies, their ability to predict future aging\ntrajectories for individuals remains limited, particularly in capturing\nsubject-specific neuroanatomical variations over time. In this study, we\nintroduce Individualized Brain Synthesis (InBrainSyn), a framework for\nsynthesizing high-resolution subject-specific longitudinal MRI scans that\nsimulate neurodegeneration in both Alzheimer's disease (AD) and normal aging.\nInBrainSyn uses a parallel transport algorithm to adapt the population-level\naging trajectories learned by a generative deep template network, enabling\nindividualized aging synthesis. As InBrainSyn uses diffeomorphic\ntransformations to simulate aging, the synthesized images are topologically\nconsistent with the original anatomy by design. We evaluated InBrainSyn both\nquantitatively and qualitatively on AD and healthy control cohorts from the\nOpen Access Series of Imaging Studies - version 3 dataset. Experimentally,\nInBrainSyn can also model neuroanatomical transitions between normal aging and\nAD. An evaluation of an external set supports its generalizability. Overall,\nwith only a single baseline scan, InBrainSyn synthesizes realistic 3D\nspatiotemporal T1w MRI scans, producing personalized longitudinal aging\ntrajectories. The code for InBrainSyn is available at:\nhttps://github.com/Fjr9516/InBrainSyn.\n","authors":["Jingru Fu","Yuqi Zheng","Neel Dey","Daniel Ferreira","Rodrigo Moreno"],"pdf_url":"https://arxiv.org/pdf/2502.21049v1.pdf","comment":"20 pages, 9 figures, 6 tables, diffeomorphic registration, parallel\n  transport, brain aging, medical image generation, Alzheimer's disease"},{"id":"http://arxiv.org/abs/2502.21048v1","updated":"2025-02-28T13:41:01Z","published":"2025-02-28T13:41:01Z","title":"Data-free Universal Adversarial Perturbation with Pseudo-semantic Prior","summary":"  Data-free Universal Adversarial Perturbation (UAP) is an image-agnostic\nadversarial attack that deceives deep neural networks using a single\nperturbation generated solely from random noise, without any data priors.\nHowever, traditional data-free UAP methods often suffer from limited\ntransferability due to the absence of semantic information in random noise. To\naddress this, we propose a novel data-free universal attack approach that\ngenerates a pseudo-semantic prior recursively from the UAPs, enriching semantic\ncontents within the data-free UAP framework. Our method is based on the\nobservation that UAPs inherently contain latent semantic information, enabling\nthe generated UAP to act as an alternative data prior, by capturing a diverse\nrange of semantics through region sampling. We further introduce a sample\nreweighting technique to emphasize hard examples by focusing on samples that\nare less affected by the UAP. By leveraging the semantic information from the\npseudo-semantic prior, we also incorporate input transformations, typically\nineffective in data-free UAPs due to the lack of semantic content in random\npriors, to boost black-box transferability. Comprehensive experiments on\nImageNet show that our method achieves state-of-the-art performance in average\nfooling rate by a substantial margin, significantly improves attack\ntransferability across various CNN architectures compared to existing data-free\nUAP methods, and even surpasses data-dependent UAP methods.\n","authors":["Chanhui Lee","Yeonghwan Song","Jeany Son"],"pdf_url":"https://arxiv.org/pdf/2502.21048v1.pdf","comment":"Accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2406.09961v2","updated":"2025-02-28T13:33:00Z","published":"2024-06-14T12:10:51Z","title":"ChartMimic: Evaluating LMM's Cross-Modal Reasoning Capability via\n  Chart-to-Code Generation","summary":"  We introduce a new benchmark, ChartMimic, aimed at assessing the\nvisually-grounded code generation capabilities of large multimodal models\n(LMMs). ChartMimic utilizes information-intensive visual charts and textual\ninstructions as inputs, requiring LMMs to generate the corresponding code for\nchart rendering. ChartMimic includes 4,800 human-curated (figure, instruction,\ncode) triplets, which represent the authentic chart use cases found in\nscientific papers across various domains (e.g., Physics, Computer Science,\nEconomics, etc). These charts span 18 regular types and 4 advanced types,\ndiversifying into 201 subcategories. Furthermore, we propose multi-level\nevaluation metrics to provide an automatic and thorough assessment of the\noutput code and the rendered charts. Unlike existing code generation\nbenchmarks, ChartMimic places emphasis on evaluating LMMs' capacity to\nharmonize a blend of cognitive capabilities, encompassing visual understanding,\ncode generation, and cross-modal reasoning. The evaluation of $3$ proprietary\nmodels and 14 open-weight models highlights the substantial challenges posed by\nChartMimic. Even the advanced GPT-4o, InternVL2-Llama3-76B only achieved an\naverage score across Direct Mimic and Customized Mimic tasks of 82.2 and 61.6,\nrespectively, indicating significant room for improvement. We anticipate that\nChartMimic will inspire the development of LMMs, advancing the pursuit of\nartificial general intelligence.\n","authors":["Cheng Yang","Chufan Shi","Yaxin Liu","Bo Shui","Junjie Wang","Mohan Jing","Linran Xu","Xinyu Zhu","Siheng Li","Yuxiang Zhang","Gongye Liu","Xiaomei Nie","Deng Cai","Yujiu Yang"],"pdf_url":"https://arxiv.org/pdf/2406.09961v2.pdf","comment":"Accepted to ICLR 2025. Data and code are available at\n  https://github.com/ChartMimic/ChartMimic"},{"id":"http://arxiv.org/abs/2502.20323v2","updated":"2025-02-28T13:25:53Z","published":"2025-02-27T17:49:01Z","title":"ARTalk: Speech-Driven 3D Head Animation via Autoregressive Model","summary":"  Speech-driven 3D facial animation aims to generate realistic lip movements\nand facial expressions for 3D head models from arbitrary audio clips. Although\nexisting diffusion-based methods are capable of producing natural motions,\ntheir slow generation speed limits their application potential. In this paper,\nwe introduce a novel autoregressive model that achieves real-time generation of\nhighly synchronized lip movements and realistic head poses and eye blinks by\nlearning a mapping from speech to a multi-scale motion codebook. Furthermore,\nour model can adapt to unseen speaking styles using sample motion sequences,\nenabling the creation of 3D talking avatars with unique personal styles beyond\nthe identities seen during training. Extensive evaluations and user studies\ndemonstrate that our method outperforms existing approaches in lip\nsynchronization accuracy and perceived quality.\n","authors":["Xuangeng Chu","Nabarun Goswami","Ziteng Cui","Hanqin Wang","Tatsuya Harada"],"pdf_url":"https://arxiv.org/pdf/2502.20323v2.pdf","comment":"More video demonstrations, code, models and data can be found on our\n  project website: http://xg-chu.site/project_artalk/"},{"id":"http://arxiv.org/abs/2412.11785v2","updated":"2025-02-28T13:16:36Z","published":"2024-12-16T13:57:02Z","title":"InterDyn: Controllable Interactive Dynamics with Video Diffusion Models","summary":"  Predicting the dynamics of interacting objects is essential for both humans\nand intelligent systems. However, existing approaches are limited to\nsimplified, toy settings and lack generalizability to complex, real-world\nenvironments. Recent advances in generative models have enabled the prediction\nof state transitions based on interventions, but focus on generating a single\nfuture state which neglects the continuous dynamics resulting from the\ninteraction. To address this gap, we propose InterDyn, a novel framework that\ngenerates videos of interactive dynamics given an initial frame and a control\nsignal encoding the motion of a driving object or actor. Our key insight is\nthat large video generation models can act as both neural renderers and\nimplicit physics simulators, having learned interactive dynamics from\nlarge-scale video data. To effectively harness this capability, we introduce an\ninteractive control mechanism that conditions the video generation process on\nthe motion of the driving entity. Qualitative results demonstrate that InterDyn\ngenerates plausible, temporally consistent videos of complex object\ninteractions while generalizing to unseen objects. Quantitative evaluations\nshow that InterDyn outperforms baselines that focus on static state\ntransitions. This work highlights the potential of leveraging video generative\nmodels as implicit physics engines. Code and trained models will be released\nat: https://interdyn.is.tue.mpg.de/\n","authors":["Rick Akkerman","Haiwen Feng","Michael J. Black","Dimitrios Tzionas","Victoria Fernández Abrevaya"],"pdf_url":"https://arxiv.org/pdf/2412.11785v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.15511v2","updated":"2025-02-28T13:10:23Z","published":"2024-09-23T19:57:08Z","title":"Bayesian computation with generative diffusion models by Multilevel\n  Monte Carlo","summary":"  Generative diffusion models have recently emerged as a powerful strategy to\nperform stochastic sampling in Bayesian inverse problems, delivering remarkably\naccurate solutions for a wide range of challenging applications. However,\ndiffusion models often require a large number of neural function evaluations\nper sample in order to deliver accurate posterior samples. As a result, using\ndiffusion models as stochastic samplers for Monte Carlo integration in Bayesian\ncomputation can be highly computationally expensive, particularly in\napplications that require a substantial number of Monte Carlo samples for\nconducting uncertainty quantification analyses. This cost is especially high in\nlarge-scale inverse problems such as computational imaging, which rely on large\nneural networks that are expensive to evaluate. With quantitative imaging\napplications in mind, this paper presents a Multilevel Monte Carlo strategy\nthat significantly reduces the cost of Bayesian computation with diffusion\nmodels. This is achieved by exploiting cost-accuracy trade-offs inherent to\ndiffusion models to carefully couple models of different levels of accuracy in\na manner that significantly reduces the overall cost of the calculation,\nwithout reducing the final accuracy. The proposed approach achieves a\n$4\\times$-to-$8\\times$ reduction in computational cost w.r.t. standard\ntechniques across three benchmark imaging problems.\n","authors":["Abdul-Lateef Haji-Ali","Marcelo Pereyra","Luke Shaw","Konstantinos Zygalakis"],"pdf_url":"https://arxiv.org/pdf/2409.15511v2.pdf","comment":"13 images"},{"id":"http://arxiv.org/abs/2502.21022v1","updated":"2025-02-28T13:05:47Z","published":"2025-02-28T13:05:47Z","title":"When Unsupervised Domain Adaptation meets One-class Anomaly Detection:\n  Addressing the Two-fold Unsupervised Curse by Leveraging Anomaly Scarcity","summary":"  This paper introduces the first fully unsupervised domain adaptation (UDA)\nframework for unsupervised anomaly detection (UAD). The performance of UAD\ntechniques degrades significantly in the presence of a domain shift, difficult\nto avoid in a real-world setting. While UDA has contributed to solving this\nissue in binary and multi-class classification, such a strategy is ill-posed in\nUAD. This might be explained by the unsupervised nature of the two tasks,\nnamely, domain adaptation and anomaly detection. Herein, we first formulate\nthis problem that we call the two-fold unsupervised curse. Then, we propose a\npioneering solution to this curse, considered intractable so far, by assuming\nthat anomalies are rare. Specifically, we leverage clustering techniques to\nidentify a dominant cluster in the target feature space. Posed as the normal\ncluster, the latter is aligned with the source normal features. Concretely,\ngiven a one-class source set and an unlabeled target set composed mostly of\nnormal data and some anomalies, we fit the source features within a hypersphere\nwhile jointly aligning them with the features of the dominant cluster from the\ntarget set. The paper provides extensive experiments and analysis on common\nadaptation benchmarks for anomaly detection, demonstrating the relevance of\nboth the newly introduced paradigm and the proposed approach. The code will be\nmade publicly available.\n","authors":["Nesryne Mejri","Enjie Ghorbel","Anis Kacem","Pavel Chernakov","Niki Foteinopoulou","Djamila Aouada"],"pdf_url":"https://arxiv.org/pdf/2502.21022v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04682v3","updated":"2025-02-28T13:02:23Z","published":"2024-10-07T01:29:19Z","title":"On the Adversarial Risk of Test Time Adaptation: An Investigation into\n  Realistic Test-Time Data Poisoning","summary":"  Test-time adaptation (TTA) updates the model weights during the inference\nstage using testing data to enhance generalization. However, this practice\nexposes TTA to adversarial risks. Existing studies have shown that when TTA is\nupdated with crafted adversarial test samples, also known as test-time poisoned\ndata, the performance on benign samples can deteriorate. Nonetheless, the\nperceived adversarial risk may be overstated if the poisoned data is generated\nunder overly strong assumptions. In this work, we first review realistic\nassumptions for test-time data poisoning, including white-box versus grey-box\nattacks, access to benign data, attack order, and more. We then propose an\neffective and realistic attack method that better produces poisoned samples\nwithout access to benign samples, and derive an effective in-distribution\nattack objective. We also design two TTA-aware attack objectives. Our\nbenchmarks of existing attack methods reveal that the TTA methods are more\nrobust than previously believed. In addition, we analyze effective defense\nstrategies to help develop adversarially robust TTA methods. The source code is\navailable at https://github.com/Gorilla-Lab-SCUT/RTTDP.\n","authors":["Yongyi Su","Yushu Li","Nanqing Liu","Kui Jia","Xulei Yang","Chuan-Sheng Foo","Xun Xu"],"pdf_url":"https://arxiv.org/pdf/2410.04682v3.pdf","comment":"Accepted by ICLR 2025. 25 pages, 4 figures and 12 tables"},{"id":"http://arxiv.org/abs/2502.21012v1","updated":"2025-02-28T12:55:58Z","published":"2025-02-28T12:55:58Z","title":"FedDyMem: Efficient Federated Learning with Dynamic Memory and\n  Memory-Reduce for Unsupervised Image Anomaly Detection","summary":"  Unsupervised image anomaly detection (UAD) has become a critical process in\nindustrial and medical applications, but it faces growing challenges due to\nincreasing concerns over data privacy. The limited class diversity inherent to\none-class classification tasks, combined with distribution biases caused by\nvariations in products across and within clients, poses significant challenges\nfor preserving data privacy with federated UAD. Thus, this article proposes an\nefficient federated learning method with dynamic memory and memory-reduce for\nunsupervised image anomaly detection, called FedDyMem. Considering all client\ndata belongs to a single class (i.e., normal sample) in UAD and the\ndistribution of intra-class features demonstrates significant skewness,\nFedDyMem facilitates knowledge sharing between the client and server through\nthe client's dynamic memory bank instead of model parameters. In the local\nclients, a memory generator and a metric loss are employed to improve the\nconsistency of the feature distribution for normal samples, leveraging the\nlocal model to update the memory bank dynamically. For efficient communication,\na memory-reduce method based on weighted averages is proposed to significantly\ndecrease the scale of memory banks. On the server, global memory is constructed\nand distributed to individual clients through k-means aggregation. Experiments\nconducted on six industrial and medical datasets, comprising a mixture of six\nproducts or health screening types derived from eleven public datasets,\ndemonstrate the effectiveness of FedDyMem.\n","authors":["Silin Chen","Kangjian Di","Yichu Xu","Han-Jia Ye","Wenhan Luo","Ningmu Zou"],"pdf_url":"https://arxiv.org/pdf/2502.21012v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21011v1","updated":"2025-02-28T12:55:37Z","published":"2025-02-28T12:55:37Z","title":"MagNet: Multi-Level Attention Graph Network for Predicting\n  High-Resolution Spatial Transcriptomics","summary":"  The rapid development of spatial transcriptomics (ST) offers new\nopportunities to explore the gene expression patterns within the spatial\nmicroenvironment. Current research integrates pathological images to infer gene\nexpression, addressing the high costs and time-consuming processes to generate\nspatial transcriptomics data. However, as spatial transcriptomics resolution\ncontinues to improve, existing methods remain primarily focused on gene\nexpression prediction at low-resolution spot levels. These methods face\nsignificant challenges, especially the information bottleneck, when they are\napplied to high-resolution HD data. To bridge this gap, this paper introduces\nMagNet, a multi-level attention graph network designed for accurate prediction\nof high-resolution HD data. MagNet employs cross-attention layers to integrate\nfeatures from multi-resolution image patches hierarchically and utilizes a\nGAT-Transformer module to aggregate neighborhood information. By integrating\nmultilevel features, MagNet overcomes the limitations posed by low-resolution\ninputs in predicting high-resolution gene expression. We systematically\nevaluated MagNet and existing ST prediction models on both a private spatial\ntranscriptomics dataset and a public dataset at three different resolution\nlevels. The results demonstrate that MagNet achieves state-of-the-art\nperformance at both spot level and high-resolution bin levels, providing a\nnovel methodology and benchmark for future research and applications in\nhigh-resolution HD-level spatial transcriptomics. Code is available at\nhttps://github.com/Junchao-Zhu/MagNet.\n","authors":["Junchao Zhu","Ruining Deng","Tianyuan Yao","Juming Xiong","Chongyu Qu","Junlin Guo","Siqi Lu","Yucheng Tang","Daguang Xu","Mengmeng Yin","Yu Wang","Shilin Zhao","Yaohong Wang","Haichun Yang","Yuankai Huo"],"pdf_url":"https://arxiv.org/pdf/2502.21011v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.16786v2","updated":"2025-02-28T12:54:57Z","published":"2025-02-24T02:41:34Z","title":"SwimVG: Step-wise Multimodal Fusion and Adaption for Visual Grounding","summary":"  Visual grounding aims to ground an image region through natural language,\nwhich heavily relies on cross-modal alignment. Most existing methods transfer\nvisual/linguistic knowledge separately by fully fine-tuning uni-modal\npre-trained models, followed by a simple stack of visual-language transformers\nfor multimodal fusion. However, these approaches not only limit adequate\ninteraction between visual and linguistic contexts, but also incur significant\ncomputational costs. Therefore, to address these issues, we explore a step-wise\nmultimodal fusion and adaption framework, namely SwimVG. Specifically, SwimVG\nproposes step-wise multimodal prompts (Swip) and cross-modal interactive\nadapters (CIA) for visual grounding, replacing the cumbersome transformer\nstacks for multimodal fusion. Swip can improve {the} alignment between the\nvision and language representations step by step, in a token-level fusion\nmanner. In addition, weight-level CIA further promotes multimodal fusion by\ncross-modal interaction. Swip and CIA are both parameter-efficient paradigms,\nand they fuse the cross-modal features from shallow to deep layers gradually.\nExperimental results on four widely-used benchmarks demonstrate that SwimVG\nachieves remarkable abilities and considerable benefits in terms of efficiency.\nOur code is available at https://github.com/liuting20/SwimVG.\n","authors":["Liangtao Shi","Ting Liu","Xiantao Hu","Yue Hu","Quanjun Yin","Richang Hong"],"pdf_url":"https://arxiv.org/pdf/2502.16786v2.pdf","comment":"12 pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.12337v2","updated":"2025-02-28T12:45:25Z","published":"2024-10-16T07:59:07Z","title":"ARIC: An Activity Recognition Dataset in Classroom Surveillance Images","summary":"  The application of activity recognition in the ``AI + Education\" field is\ngaining increasing attention. However, current work mainly focuses on the\nrecognition of activities in manually captured videos and a limited number of\nactivity types, with little attention given to recognizing activities in\nsurveillance images from real classrooms. Activity recognition in classroom\nsurveillance images faces multiple challenges, such as class imbalance and high\nactivity similarity. To address this gap, we constructed a novel multimodal\ndataset focused on classroom surveillance image activity recognition called\nARIC (Activity Recognition In Classroom). The ARIC dataset has advantages of\nmultiple perspectives, 32 activity categories, three modalities, and real-world\nclassroom scenarios. In addition to the general activity recognition tasks, we\nalso provide settings for continual learning and few-shot continual learning.\nWe hope that the ARIC dataset can act as a facilitator for future analysis and\nresearch for open teaching scenarios. You can download preliminary data from\nhttps://ivipclab.github.io/publication_ARIC/ARIC.\n","authors":["Linfeng Xu","Fanman Meng","Qingbo Wu","Lili Pan","Heqian Qiu","Lanxiao Wang","Kailong Chen","Kanglei Geng","Yilei Qian","Haojie Wang","Shuchang Zhou","Shimou Ling","Zejia Liu","Nanlin Chen","Yingjie Xu","Shaoxu Cheng","Bowen Tan","Ziyong Xu","Hongliang Li"],"pdf_url":"https://arxiv.org/pdf/2410.12337v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2409.03354. Updated the\n  description for ARIC supplement"},{"id":"http://arxiv.org/abs/2502.21004v1","updated":"2025-02-28T12:45:08Z","published":"2025-02-28T12:45:08Z","title":"Soften the Mask: Adaptive Temporal Soft Mask for Efficient Dynamic\n  Facial Expression Recognition","summary":"  Dynamic Facial Expression Recognition (DFER) facilitates the understanding of\npsychological intentions through non-verbal communication. Existing methods\nstruggle to manage irrelevant information, such as background noise and\nredundant semantics, which impacts both efficiency and effectiveness. In this\nwork, we propose a novel supervised temporal soft masked autoencoder network\nfor DFER, namely AdaTosk, which integrates a parallel supervised classification\nbranch with the self-supervised reconstruction branch. The self-supervised\nreconstruction branch applies random binary hard mask to generate diverse\ntraining samples, encouraging meaningful feature representations in visible\ntokens. Meanwhile the classification branch employs an adaptive temporal soft\nmask to flexibly mask visible tokens based on their temporal significance. Its\ntwo key components, respectively of, class-agnostic and class-semantic soft\nmasks, serve to enhance critical expression moments and reduce semantic\nredundancy over time. Extensive experiments conducted on widely-used benchmarks\ndemonstrate that our AdaTosk remarkably reduces computational costs compared\nwith current state-of-the-art methods while still maintaining competitive\nperformance.\n","authors":["Mengzhu Li","Quanxing Zha","Hongjun Wu"],"pdf_url":"https://arxiv.org/pdf/2502.21004v1.pdf","comment":"8 pages, 3 figures"},{"id":"http://arxiv.org/abs/2502.21001v1","updated":"2025-02-28T12:43:46Z","published":"2025-02-28T12:43:46Z","title":"Towards Lossless Implicit Neural Representation via Bit Plane\n  Decomposition","summary":"  We quantify the upper bound on the size of the implicit neural representation\n(INR) model from a digital perspective. The upper bound of the model size\nincreases exponentially as the required bit-precision increases. To this end,\nwe present a bit-plane decomposition method that makes INR predict bit-planes,\nproducing the same effect as reducing the upper bound of the model size. We\nvalidate our hypothesis that reducing the upper bound leads to faster\nconvergence with constant model size. Our method achieves lossless\nrepresentation in 2D image and audio fitting, even for high bit-depth signals,\nsuch as 16-bit, which was previously unachievable. We pioneered the presence of\nbit bias, which INR prioritizes as the most significant bit (MSB). We expand\nthe application of the INR task to bit depth expansion, lossless image\ncompression, and extreme network quantization. Our source code is available at\nhttps://github.com/WooKyoungHan/LosslessINR\n","authors":["Woo Kyoung Han","Byeonghun Lee","Hyunmin Cho","Sunghoon Im","Kyong Hwan Jin"],"pdf_url":"https://arxiv.org/pdf/2502.21001v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.02370v2","updated":"2025-02-28T12:28:56Z","published":"2024-12-03T10:54:37Z","title":"Trajectory-based Road Autolabeling with Lidar-Camera Fusion in Winter\n  Conditions","summary":"  Robust road segmentation in all road conditions is required for safe\nautonomous driving and advanced driver assistance systems. Supervised deep\nlearning methods provide accurate road segmentation in the domain of their\ntraining data but cannot be trusted in out-of-distribution scenarios. Including\nthe whole distribution in the trainset is challenging as each sample must be\nlabeled by hand. Trajectory-based self-supervised methods offer a potential\nsolution as they can learn from the traversed route without manual labels.\nHowever, existing trajectory-based methods use learning schemes that rely only\non the camera or only on the lidar. In this paper, trajectory-based learning is\nimplemented jointly with lidar and camera for increased performance. Our method\noutperforms recent standalone camera- and lidar-based methods when evaluated\nwith a challenging winter driving dataset including countryside and suburb\ndriving scenes. The source code is available at\nhttps://github.com/eerik98/lidar-camera-road-autolabeling.git\n","authors":["Eerik Alamikkotervo","Henrik Toikka","Kari Tammi","Risto Ojala"],"pdf_url":"https://arxiv.org/pdf/2412.02370v2.pdf","comment":"Small bugs fixed, noise filtering removed as it was removing useful\n  points, failure case analysis added, dataset published"},{"id":"http://arxiv.org/abs/2412.03084v2","updated":"2025-02-28T12:24:33Z","published":"2024-12-04T07:26:36Z","title":"Hybrid deep learning-based strategy for the hepatocellular carcinoma\n  cancer grade classification of H&E stained liver histopathology images","summary":"  Hepatocellular carcinoma (HCC) is a common type of liver cancer whose\nearly-stage diagnosis is a common challenge, mainly due to the manual\nassessment of hematoxylin and eosin-stained whole slide images, which is a\ntime-consuming process and may lead to variability in decision-making. For\naccurate detection of HCC, we propose a hybrid deep learning-based architecture\nthat uses transfer learning to extract the features from pre-trained\nconvolutional neural network (CNN) models and a classifier made up of a\nsequence of fully connected layers. This study uses a publicly available The\nCancer Genome Atlas Hepatocellular Carcinoma (TCGA-LIHC)database (n=491) for\nmodel development and database of Kasturba Gandhi Medical College (KMC), India\nfor validation. The pre-processing step involves patch extraction, colour\nnormalization, and augmentation that results in 3920 patches for the TCGA\ndataset. The developed hybrid deep neural network consisting of a CNN-based\npre-trained feature extractor and a customized artificial neural network-based\nclassifier is trained using five-fold cross-validation. For this study, eight\ndifferent state-of-the-art models are trained and tested as feature extractors\nfor the proposed hybrid model. The proposed hybrid model with ResNet50-based\nfeature extractor provided the sensitivity, specificity, F1-score, accuracy,\nand AUC of 100.00%, 100.00%, 100.00%, 100.00%, and 1.00, respectively on the\nTCGA database. On the KMC database, EfficientNetb3 resulted in the optimal\nchoice of the feature extractor giving sensitivity, specificity, F1-score,\naccuracy, and AUC of 96.97, 98.85, 96.71, 96.71, and 0.99, respectively. The\nproposed hybrid models showed improvement in accuracy of 2% and 4% over the\npre-trained models in TCGA-LIHC and KMC databases.\n","authors":["Ajinkya Deshpande","Deep Gupta","Ankit Bhurane","Nisha Meshram","Sneha Singh","Petia Radeva"],"pdf_url":"https://arxiv.org/pdf/2412.03084v2.pdf","comment":"14 figure, 9 tables"},{"id":"http://arxiv.org/abs/2502.18044v2","updated":"2025-02-28T12:23:03Z","published":"2025-02-25T10:09:10Z","title":"S-Graphs 2.0 -- A Hierarchical-Semantic Optimization and Loop Closure\n  for SLAM","summary":"  The hierarchical structure of 3D scene graphs shows a high relevance for\nrepresentations purposes, as it fits common patterns from man-made\nenvironments. But, additionally, the semantic and geometric information in such\nhierarchical representations could be leveraged to speed up the optimization\nand management of map elements and robot poses.\n  In this direction, we present our work Situational Graphs 2.0 (S-Graphs 2.0),\nwhich leverages the hierarchical structure of indoor scenes for efficient data\nmanagement and optimization. Our algorithm begins by constructing a situational\ngraph that represents the environment into four layers: Keyframes, Walls,\nRooms, and Floors. Our first novelty lies in the front-end, which includes a\nfloor detection module capable of identifying stairways and assigning\nfloor-level semantic relations to the underlying layers. Floor-level semantics\nallows us to propose a floor-based loop closure strategy, that effectively\nrejects false positive closures that typically appear due to aliasing between\ndifferent floors of a building. Our second novelty lies in leveraging our\nrepresentation hierarchy in the optimization. Our proposal consists of: (1)\nlocal optimization over a window of recent keyframes and their connected\ncomponents across the four representation layers, (2) floor-level global\noptimization, which focuses only on keyframes and their connections within the\ncurrent floor during loop closures, and (3) room-level local optimization,\nmarginalizing redundant keyframes that share observations within the room,\nwhich reduces the computational footprint. We validate our algorithm\nextensively in different real multi-floor environments. Our approach shows\nstate-of-art-art accuracy metrics in large-scale multi-floor environments,\nestimating hierarchical representations up to 10x faster, in average, than\ncompeting baselines\n","authors":["Hriday Bavle","Jose Luis Sanchez-Lopez","Muhammad Shaheer","Javier Civera","Holger Voos"],"pdf_url":"https://arxiv.org/pdf/2502.18044v2.pdf","comment":"8 pages, 9 figures, RAL submission"},{"id":"http://arxiv.org/abs/2502.20985v1","updated":"2025-02-28T11:58:33Z","published":"2025-02-28T11:58:33Z","title":"LesionLocator: Zero-Shot Universal Tumor Segmentation and Tracking in 3D\n  Whole-Body Imaging","summary":"  In this work, we present LesionLocator, a framework for zero-shot\nlongitudinal lesion tracking and segmentation in 3D medical imaging,\nestablishing the first end-to-end model capable of 4D tracking with dense\nspatial prompts. Our model leverages an extensive dataset of 23,262 annotated\nmedical scans, as well as synthesized longitudinal data across diverse lesion\ntypes. The diversity and scale of our dataset significantly enhances model\ngeneralizability to real-world medical imaging challenges and addresses key\nlimitations in longitudinal data availability. LesionLocator outperforms all\nexisting promptable models in lesion segmentation by nearly 10 dice points,\nreaching human-level performance, and achieves state-of-the-art results in\nlesion tracking, with superior lesion retrieval and segmentation accuracy.\nLesionLocator not only sets a new benchmark in universal promptable lesion\nsegmentation and automated longitudinal lesion tracking but also provides the\nfirst open-access solution of its kind, releasing our synthetic 4D dataset and\nmodel to the community, empowering future advancements in medical imaging. Code\nis available at: www.github.com/MIC-DKFZ/LesionLocator\n","authors":["Maximilian Rokuss","Yannick Kirchhoff","Seval Akbal","Balint Kovacs","Saikat Roy","Constantin Ulrich","Tassilo Wald","Lukas T. Rotkopf","Heinz-Peter Schlemmer","Klaus Maier-Hein"],"pdf_url":"https://arxiv.org/pdf/2502.20985v1.pdf","comment":"Accepted at CVPR 2025"},{"id":"http://arxiv.org/abs/2502.20981v1","updated":"2025-02-28T11:50:50Z","published":"2025-02-28T11:50:50Z","title":"Distribution Prototype Diffusion Learning for Open-set Supervised\n  Anomaly Detection","summary":"  In Open-set Supervised Anomaly Detection (OSAD), the existing methods\ntypically generate pseudo anomalies to compensate for the scarcity of observed\nanomaly samples, while overlooking critical priors of normal samples, leading\nto less effective discriminative boundaries. To address this issue, we propose\na Distribution Prototype Diffusion Learning (DPDL) method aimed at enclosing\nnormal samples within a compact and discriminative distribution space.\nSpecifically, we construct multiple learnable Gaussian prototypes to create a\nlatent representation space for abundant and diverse normal samples and learn a\nSchr\\\"odinger bridge to facilitate a diffusive transition toward these\nprototypes for normal samples while steering anomaly samples away. Moreover, to\nenhance inter-sample separation, we design a dispersion feature learning way in\nhyperspherical space, which benefits the identification of out-of-distribution\nanomalies. Experimental results demonstrate the effectiveness and superiority\nof our proposed DPDL, achieving state-of-the-art performance on 9 public\ndatasets.\n","authors":["Fuyun Wang","Tong Zhang","Yuanzhi Wang","Yide Qiu","Xin Liu","Xu Guo","Zhen Cui"],"pdf_url":"https://arxiv.org/pdf/2502.20981v1.pdf","comment":"Accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2502.20979v1","updated":"2025-02-28T11:49:58Z","published":"2025-02-28T11:49:58Z","title":"Real-Time Aerial Fire Detection on Resource-Constrained Devices Using\n  Knowledge Distillation","summary":"  Wildfire catastrophes cause significant environmental degradation, human\nlosses, and financial damage. To mitigate these severe impacts, early fire\ndetection and warning systems are crucial. Current systems rely primarily on\nfixed CCTV cameras with a limited field of view, restricting their\neffectiveness in large outdoor environments. The fusion of intelligent fire\ndetection with remote sensing improves coverage and mobility, enabling\nmonitoring in remote and challenging areas. Existing approaches predominantly\nutilize convolutional neural networks and vision transformer models. While\nthese architectures provide high accuracy in fire detection, their\ncomputational complexity limits real-time performance on edge devices such as\nUAVs. In our work, we present a lightweight fire detection model based on\nMobileViT-S, compressed through the distillation of knowledge from a stronger\nteacher model. The ablation study highlights the impact of a teacher model and\nthe chosen distillation technique on the model's performance improvement. We\ngenerate activation map visualizations using Grad-CAM to confirm the model's\nability to focus on relevant fire regions. The high accuracy and efficiency of\nthe proposed model make it well-suited for deployment on satellites, UAVs, and\nIoT devices for effective fire detection. Experiments on common fire benchmarks\ndemonstrate that our model suppresses the state-of-the-art model by 0.44%,\n2.00% while maintaining a compact model size. Our model delivers the highest\nprocessing speed among existing works, achieving real-time performance on\nresource-constrained devices.\n","authors":["Sabina Jangirova","Branislava Jankovic","Waseem Ullah","Latif U. Khan","Mohsen Guizani"],"pdf_url":"https://arxiv.org/pdf/2502.20979v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.10078v2","updated":"2025-02-28T11:46:16Z","published":"2024-06-14T14:35:44Z","title":"D-NPC: Dynamic Neural Point Clouds for Non-Rigid View Synthesis from\n  Monocular Video","summary":"  Dynamic reconstruction and spatiotemporal novel-view synthesis of non-rigidly\ndeforming scenes recently gained increased attention. While existing work\nachieves impressive quality and performance on multi-view or teleporting camera\nsetups, most methods fail to efficiently and faithfully recover motion and\nappearance from casual monocular captures. This paper contributes to the field\nby introducing a new method for dynamic novel view synthesis from monocular\nvideo, such as casual smartphone captures.\n  Our approach represents the scene as a $\\textit{dynamic neural point cloud}$,\nan implicit time-conditioned point distribution that encodes local geometry and\nappearance in separate hash-encoded neural feature grids for static and dynamic\nregions. By sampling a discrete point cloud from our model, we can efficiently\nrender high-quality novel views using a fast differentiable rasterizer and\nneural rendering network. Similar to recent work, we leverage advances in\nneural scene analysis by incorporating data-driven priors like monocular depth\nestimation and object segmentation to resolve motion and depth ambiguities\noriginating from the monocular captures. In addition to guiding the\noptimization process, we show that these priors can be exploited to explicitly\ninitialize our scene representation to drastically improve optimization speed\nand final image quality. As evidenced by our experimental evaluation, our\ndynamic point cloud model not only enables fast optimization and real-time\nframe rates for interactive applications, but also achieves competitive image\nquality on monocular benchmark sequences.\n  Our code and data are available online:\nhttps://moritzkappel.github.io/projects/dnpc/.\n","authors":["Moritz Kappel","Florian Hahlbohm","Timon Scholz","Susana Castillo","Christian Theobalt","Martin Eisemann","Vladislav Golyanik","Marcus Magnor"],"pdf_url":"https://arxiv.org/pdf/2406.10078v2.pdf","comment":"18 pages, 8 figures, 12 tables. Project page:\n  https://moritzkappel.github.io/projects/dnpc/"},{"id":"http://arxiv.org/abs/2502.20964v1","updated":"2025-02-28T11:25:38Z","published":"2025-02-28T11:25:38Z","title":"Fine-Grained Retrieval-Augmented Generation for Visual Question\n  Answering","summary":"  Visual Question Answering (VQA) focuses on providing answers to natural\nlanguage questions by utilizing information from images. Although cutting-edge\nmultimodal large language models (MLLMs) such as GPT-4o achieve strong\nperformance on VQA tasks, they frequently fall short in accessing\ndomain-specific or the latest knowledge. To mitigate this issue,\nretrieval-augmented generation (RAG) leveraging external knowledge bases (KBs),\nreferred to as KB-VQA, emerges as a promising approach. Nevertheless,\nconventional unimodal retrieval techniques, which translate images into textual\ndescriptions, often result in the loss of critical visual details. This study\npresents fine-grained knowledge units, which merge textual snippets with entity\nimages stored in vector databases. Furthermore, we introduce a knowledge unit\nretrieval-augmented generation framework (KU-RAG) that integrates fine-grained\nretrieval with MLLMs. The proposed KU-RAG framework ensures precise retrieval\nof relevant knowledge and enhances reasoning capabilities through a knowledge\ncorrection chain. Experimental findings demonstrate that our approach\nsignificantly boosts the performance of leading KB-VQA methods, achieving\nimprovements of up to 10%.\n","authors":["Zhengxuan Zhang","Yin Wu","Yuyu Luo","Nan Tang"],"pdf_url":"https://arxiv.org/pdf/2502.20964v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20272v2","updated":"2025-02-28T11:13:24Z","published":"2025-02-27T16:59:51Z","title":"HVI: A New Color Space for Low-light Image Enhancement","summary":"  Low-Light Image Enhancement (LLIE) is a crucial computer vision task that\naims to restore detailed visual information from corrupted low-light images.\nMany existing LLIE methods are based on standard RGB (sRGB) space, which often\nproduce color bias and brightness artifacts due to inherent high color\nsensitivity in sRGB. While converting the images using Hue, Saturation and\nValue (HSV) color space helps resolve the brightness issue, it introduces\nsignificant red and black noise artifacts. To address this issue, we propose a\nnew color space for LLIE, namely Horizontal/Vertical-Intensity (HVI), defined\nby polarized HS maps and learnable intensity. The former enforces small\ndistances for red coordinates to remove the red artifacts, while the latter\ncompresses the low-light regions to remove the black artifacts. To fully\nleverage the chromatic and intensity information, a novel Color and Intensity\nDecoupling Network (CIDNet) is further introduced to learn accurate photometric\nmapping function under different lighting conditions in the HVI space.\nComprehensive results from benchmark and ablation experiments show that the\nproposed HVI color space with CIDNet outperforms the state-of-the-art methods\non 10 datasets. The code is available at https://github.com/Fediory/HVI-CIDNet.\n","authors":["Qingsen Yan","Yixu Feng","Cheng Zhang","Guansong Pang","Kangbiao Shi","Peng Wu","Wei Dong","Jinqiu Sun","Yanning Zhang"],"pdf_url":"https://arxiv.org/pdf/2502.20272v2.pdf","comment":"Qingsen Yan, Yixu Feng, and Cheng Zhang contributed equally to this\n  work"},{"id":"http://arxiv.org/abs/2411.19289v2","updated":"2025-02-28T11:12:24Z","published":"2024-11-28T17:41:33Z","title":"ADUGS-VINS: Generalized Visual-Inertial Odometry for Robust Navigation\n  in Highly Dynamic and Complex Environments","summary":"  Visual-inertial odometry (VIO) is widely used in various fields, such as\nrobots, drones, and autonomous vehicles. However, real-world scenes often\nfeature dynamic objects, compromising the accuracy of VIO. The diversity and\npartial occlusion of these objects present a tough challenge for existing\ndynamic VIO methods. To tackle this challenge, we introduce ADUGS-VINS, which\nintegrates an enhanced SORT algorithm along with a promptable foundation model\ninto VIO, thereby improving pose estimation accuracy in environments with\ndiverse dynamic objects and frequent occlusions. We evaluated our proposed\nmethod using multiple public datasets representing various scenes, as well as\nin a real-world scenario involving diverse dynamic objects. The experimental\nresults demonstrate that our proposed method performs impressively in multiple\nscenarios, outperforming other state-of-the-art methods. This highlights its\nremarkable generalization and adaptability in diverse dynamic environments,\nshowcasing its potential to handle various dynamic objects in practical\napplications.\n","authors":["Rui Zhou","Jingbin Liu","Junbin Xie","Jianyu Zhang","Yingze Hu","Jiele Zhao"],"pdf_url":"https://arxiv.org/pdf/2411.19289v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20943v1","updated":"2025-02-28T10:53:39Z","published":"2025-02-28T10:53:39Z","title":"BadRefSR: Backdoor Attacks Against Reference-based Image Super\n  Resolution","summary":"  Reference-based image super-resolution (RefSR) represents a promising\nadvancement in super-resolution (SR). In contrast to single-image\nsuper-resolution (SISR), RefSR leverages an additional reference image to help\nrecover high-frequency details, yet its vulnerability to backdoor attacks has\nnot been explored. To fill this research gap, we propose a novel attack\nframework called BadRefSR, which embeds backdoors in the RefSR model by adding\ntriggers to the reference images and training with a mixed loss function.\nExtensive experiments across various backdoor attack settings demonstrate the\neffectiveness of BadRefSR. The compromised RefSR network performs normally on\nclean input images, while outputting attacker-specified target images on\ntriggered input images. Our study aims to alert researchers to the potential\nbackdoor risks in RefSR. Codes are available at\nhttps://github.com/xuefusiji/BadRefSR.\n","authors":["Xue Yang","Tao Chen","Lei Guo","Wenbo Jiang","Ji Guo","Yongming Li","Jiaming He"],"pdf_url":"https://arxiv.org/pdf/2502.20943v1.pdf","comment":"5 pages,4 figures"},{"id":"http://arxiv.org/abs/2410.17146v2","updated":"2025-02-28T10:53:12Z","published":"2024-10-22T16:26:05Z","title":"LiNeS: Post-training Layer Scaling Prevents Forgetting and Enhances\n  Model Merging","summary":"  Fine-tuning pre-trained models has become the standard approach to endow them\nwith specialized knowledge, but it poses fundamental challenges. In particular,\n\\textit{(i)} fine-tuning often leads to catastrophic forgetting, where\nimprovements on a target domain degrade generalization on other tasks, and\n\\textit{(ii)} merging fine-tuned checkpoints from disparate tasks can lead to\nsignificant performance loss. To address these challenges, we introduce LiNeS,\nLayer-increasing Network Scaling, a post-training editing technique designed to\npreserve pre-trained generalization while enhancing fine-tuned task\nperformance. LiNeS scales parameter updates linearly based on their layer depth\nwithin the network, maintaining shallow layers close to their pre-trained\nvalues to preserve general features while allowing deeper layers to retain\ntask-specific representations. In multi-task model merging scenarios,\nlayer-wise scaling of merged parameters reduces negative task interference.\nLiNeS demonstrates significant improvements in both single-task and multi-task\nsettings across various benchmarks in vision and natural language processing.\nIt mitigates forgetting, enhances out-of-distribution generalization,\nintegrates seamlessly with existing multi-task model merging baselines\nimproving their performance across benchmarks and model sizes, and can boost\ngeneralization when merging LLM policies aligned with different rewards via\nRLHF. Our method is simple to implement, computationally efficient and\ncomplementary to many existing techniques. Our source code is available at\nhttps://github.com/wang-kee/LiNeS\n","authors":["Ke Wang","Nikolaos Dimitriadis","Alessandro Favero","Guillermo Ortiz-Jimenez","Francois Fleuret","Pascal Frossard"],"pdf_url":"https://arxiv.org/pdf/2410.17146v2.pdf","comment":"The first two authors contributed equally to this work. Accepted at\n  ICLR 2025. Project website: https://lines-merging.github.io"},{"id":"http://arxiv.org/abs/2501.12087v2","updated":"2025-02-28T10:42:30Z","published":"2025-01-21T12:29:45Z","title":"UAV-Assisted Real-Time Disaster Detection Using Optimized Transformer\n  Model","summary":"  Dangerous surroundings and difficult-to-reach landscapes introduce\nsignificant complications for adequate disaster management and recuperation.\nThese problems can be solved by engaging unmanned aerial vehicles (UAVs)\nprovided with embedded platforms and optical sensors. In this work, we focus on\nenabling onboard aerial image processing to ensure proper and real-time\ndisaster detection. Such a setting usually causes challenges due to the limited\nhardware resources of UAVs. However, privacy, connectivity, and latency issues\ncan be avoided. We suggest a UAV-assisted edge framework for disaster\ndetection, leveraging our proposed model optimized for onboard real-time aerial\nimage classification. The optimization of the model is achieved using\npost-training quantization techniques. To address the limited number of\ndisaster cases in existing benchmark datasets and therefore ensure real-world\nadoption of our model, we construct a novel dataset, DisasterEye, featuring\ndisaster scenes captured by UAVs and individuals on-site. Experimental results\nreveal the efficacy of our model, reaching high accuracy with lowered inference\nlatency and memory use on both traditional machines and resource-limited\ndevices. This shows that the scalability and adaptability of our method make it\na powerful solution for real-time disaster management on resource-constrained\nUAV platforms.\n","authors":["Branislava Jankovic","Sabina Jangirova","Waseem Ullah","Latif U. Khan","Mohsen Guizani"],"pdf_url":"https://arxiv.org/pdf/2501.12087v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20934v1","updated":"2025-02-28T10:42:09Z","published":"2025-02-28T10:42:09Z","title":"Less is More? Revisiting the Importance of Frame Rate in Real-Time\n  Zero-Shot Surgical Video Segmentation","summary":"  Real-time video segmentation is a promising feature for AI-assisted surgery,\nproviding intraoperative guidance by identifying surgical tools and anatomical\nstructures. However, deploying state-of-the-art segmentation models, such as\nSAM2, in real-time settings is computationally demanding, which makes it\nessential to balance frame rate and segmentation performance. In this study, we\ninvestigate the impact of frame rate on zero-shot surgical video segmentation,\nevaluating SAM2's effectiveness across multiple frame sampling rates for\ncholecystectomy procedures. Surprisingly, our findings indicate that in\nconventional evaluation settings, frame rates as low as a single frame per\nsecond can outperform 25 FPS, as fewer frames smooth out segmentation\ninconsistencies. However, when assessed in a real-time streaming scenario,\nhigher frame rates yield superior temporal coherence and stability,\nparticularly for dynamic objects such as surgical graspers. Finally, we\ninvestigate human perception of real-time surgical video segmentation among\nprofessionals who work closely with such data and find that respondents\nconsistently prefer high FPS segmentation mask overlays, reinforcing the\nimportance of real-time evaluation in AI-assisted surgery.\n","authors":["Utku Ozbulak","Seyed Amir Mousavi","Francesca Tozzi","Nikdokht Rashidian","Wouter Willaert","Wesley De Neve","Joris Vankerschaver"],"pdf_url":"https://arxiv.org/pdf/2502.20934v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20924v1","updated":"2025-02-28T10:27:14Z","published":"2025-02-28T10:27:14Z","title":"Decoder Gradient Shield: Provable and High-Fidelity Prevention of\n  Gradient-Based Box-Free Watermark Removal","summary":"  The intellectual property of deep image-to-image models can be protected by\nthe so-called box-free watermarking. It uses an encoder and a decoder,\nrespectively, to embed into and extract from the model's output images\ninvisible copyright marks. Prior works have improved watermark robustness,\nfocusing on the design of better watermark encoders. In this paper, we reveal\nan overlooked vulnerability of the unprotected watermark decoder which is\njointly trained with the encoder and can be exploited to train a watermark\nremoval network. To defend against such an attack, we propose the decoder\ngradient shield (DGS) as a protection layer in the decoder API to prevent\ngradient-based watermark removal with a closed-form solution. The fundamental\nidea is inspired by the classical adversarial attack, but is utilized for the\nfirst time as a defensive mechanism in the box-free model watermarking. We then\ndemonstrate that DGS can reorient and rescale the gradient directions of\nwatermarked queries and stop the watermark remover's training loss from\nconverging to the level without DGS, while retaining decoder output image\nquality. Experimental results verify the effectiveness of proposed method. Code\nof paper will be made available upon acceptance.\n","authors":["Haonan An","Guang Hua","Zhengru Fang","Guowen Xu","Susanto Rahardja","Yuguang Fang"],"pdf_url":"https://arxiv.org/pdf/2502.20924v1.pdf","comment":"Accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2412.13211v3","updated":"2025-02-28T10:10:33Z","published":"2024-12-09T01:29:24Z","title":"ManiSkill-HAB: A Benchmark for Low-Level Manipulation in Home\n  Rearrangement Tasks","summary":"  High-quality benchmarks are the foundation for embodied AI research, enabling\nsignificant advancements in long-horizon navigation, manipulation and\nrearrangement tasks. However, as frontier tasks in robotics get more advanced,\nthey require faster simulation speed, more intricate test environments, and\nlarger demonstration datasets. To this end, we present MS-HAB, a holistic\nbenchmark for low-level manipulation and in-home object rearrangement. First,\nwe provide a GPU-accelerated implementation of the Home Assistant Benchmark\n(HAB). We support realistic low-level control and achieve over 3x the speed of\nprior magical grasp implementations at a fraction of the GPU memory usage.\nSecond, we train extensive reinforcement learning (RL) and imitation learning\n(IL) baselines for future work to compare against. Finally, we develop a\nrule-based trajectory filtering system to sample specific demonstrations from\nour RL policies which match predefined criteria for robot behavior and safety.\nCombining demonstration filtering with our fast environments enables efficient,\ncontrolled data generation at scale.\n","authors":["Arth Shukla","Stone Tao","Hao Su"],"pdf_url":"https://arxiv.org/pdf/2412.13211v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.11742v2","updated":"2025-02-28T10:10:21Z","published":"2025-02-17T12:29:26Z","title":"Range and Bird's Eye View Fused Cross-Modal Visual Place Recognition","summary":"  Image-to-point cloud cross-modal Visual Place Recognition (VPR) is a\nchallenging task where the query is an RGB image, and the database samples are\nLiDAR point clouds. Compared to single-modal VPR, this approach benefits from\nthe widespread availability of RGB cameras and the robustness of point clouds\nin providing accurate spatial geometry and distance information. However,\ncurrent methods rely on intermediate modalities that capture either the\nvertical or horizontal field of view, limiting their ability to fully exploit\nthe complementary information from both sensors. In this work, we propose an\ninnovative initial retrieval + re-rank method that effectively combines\ninformation from range (or RGB) images and Bird's Eye View (BEV) images. Our\napproach relies solely on a computationally efficient global descriptor\nsimilarity search process to achieve re-ranking. Additionally, we introduce a\nnovel similarity label supervision technique to maximize the utility of limited\ntraining data. Specifically, we employ points average distance to approximate\nappearance similarity and incorporate an adaptive margin, based on similarity\ndifferences, into the vanilla triplet loss. Experimental results on the KITTI\ndataset demonstrate that our method significantly outperforms state-of-the-art\napproaches.\n","authors":["Jianyi Peng","Fan Lu","Bin Li","Yuan Huang","Sanqing Qu","Guang Chen"],"pdf_url":"https://arxiv.org/pdf/2502.11742v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20904v1","updated":"2025-02-28T10:01:39Z","published":"2025-02-28T10:01:39Z","title":"DiffBrush:Just Painting the Art by Your Hands","summary":"  The rapid development of image generation and editing algorithms in recent\nyears has enabled ordinary user to produce realistic images. However, the\ncurrent AI painting ecosystem predominantly relies on text-driven diffusion\nmodels (T2I), which pose challenges in accurately capturing user requirements.\nFurthermore, achieving compatibility with other modalities incurs substantial\ntraining costs. To this end, we introduce DiffBrush, which is compatible with\nT2I models and allows users to draw and edit images. By manipulating and\nadapting the internal representation of the diffusion model, DiffBrush guides\nthe model-generated images to converge towards the user's hand-drawn sketches\nfor user's specific needs without additional training. DiffBrush achieves\ncontrol over the color, semantic, and instance of objects in images by\ncontinuously guiding the latent and instance-level attention map during the\ndenoising process of the diffusion model. Besides, we propose a latent\nregeneration, which refines the randomly sampled noise in the diffusion model,\nobtaining a better image generation layout. Finally, users only need to roughly\ndraw the mask of the instance (acceptable colors) on the canvas, DiffBrush can\nnaturally generate the corresponding instance at the corresponding location.\n","authors":["Jiaming Chu","Lei Jin","Tao Wang","Junliang Xing","Jian Zhao"],"pdf_url":"https://arxiv.org/pdf/2502.20904v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.03844v4","updated":"2025-02-28T09:49:45Z","published":"2024-12-05T03:20:35Z","title":"HybridGS: Decoupling Transients and Statics with 2D and 3D Gaussian\n  Splatting","summary":"  Generating high-quality novel view renderings of 3D Gaussian Splatting (3DGS)\nin scenes featuring transient objects is challenging. We propose a novel hybrid\nrepresentation, termed as HybridGS, using 2D Gaussians for transient objects\nper image and maintaining traditional 3D Gaussians for the whole static scenes.\nNote that, the 3DGS itself is better suited for modeling static scenes that\nassume multi-view consistency, but the transient objects appear occasionally\nand do not adhere to the assumption, thus we model them as planar objects from\na single view, represented with 2D Gaussians. Our novel representation\ndecomposes the scene from the perspective of fundamental viewpoint consistency,\nmaking it more reasonable. Additionally, we present a novel multi-view\nregulated supervision method for 3DGS that leverages information from\nco-visible regions, further enhancing the distinctions between the transients\nand statics. Then, we propose a straightforward yet effective multi-stage\ntraining strategy to ensure robust training and high-quality view synthesis\nacross various settings. Experiments on benchmark datasets show our\nstate-of-the-art performance of novel view synthesis in both indoor and outdoor\nscenes, even in the presence of distracting elements.\n","authors":["Jingyu Lin","Jiaqi Gu","Lubin Fan","Bojian Wu","Yujing Lou","Renjie Chen","Ligang Liu","Jieping Ye"],"pdf_url":"https://arxiv.org/pdf/2412.03844v4.pdf","comment":"Accpeted by CVPR 2025. Project page:\n  https://gujiaqivadin.github.io/hybridgs/ Code:\n  https://github.com/Yeyuqqwx/HybridGS Data:\n  https://huggingface.co/Eto63277/HybridGS/tree/main"},{"id":"http://arxiv.org/abs/2410.10105v2","updated":"2025-02-28T09:44:00Z","published":"2024-10-14T02:49:23Z","title":"High-Precision Dichotomous Image Segmentation via Probing Diffusion\n  Capacity","summary":"  In the realm of high-resolution (HR), fine-grained image segmentation, the\nprimary challenge is balancing broad contextual awareness with the precision\nrequired for detailed object delineation, capturing intricate details and the\nfinest edges of objects. Diffusion models, trained on vast datasets comprising\nbillions of image-text pairs, such as SD V2.1, have revolutionized\ntext-to-image synthesis by delivering exceptional quality, fine detail\nresolution, and strong contextual awareness, making them an attractive solution\nfor high-resolution image segmentation. To this end, we propose DiffDIS, a\ndiffusion-driven segmentation model that taps into the potential of the\npre-trained U-Net within diffusion models, specifically designed for\nhigh-resolution, fine-grained object segmentation. By leveraging the robust\ngeneralization capabilities and rich, versatile image representation prior of\nthe SD models, coupled with a task-specific stable one-step denoising approach,\nwe significantly reduce the inference time while preserving high-fidelity,\ndetailed generation. Additionally, we introduce an auxiliary edge generation\ntask to not only enhance the preservation of fine details of the object\nboundaries, but reconcile the probabilistic nature of diffusion with the\ndeterministic demands of segmentation. With these refined strategies in place,\nDiffDIS serves as a rapid object mask generation model, specifically optimized\nfor generating detailed binary maps at high resolutions, while demonstrating\nimpressive accuracy and swift processing. Experiments on the DIS5K dataset\ndemonstrate the superiority of DiffDIS, achieving state-of-the-art results\nthrough a streamlined inference process. The source code will be publicly\navailable at https://github.com/qianyu-dlut/DiffDIS.\n","authors":["Qian Yu","Peng-Tao Jiang","Hao Zhang","Jinwei Chen","Bo Li","Lihe Zhang","Huchuan Lu"],"pdf_url":"https://arxiv.org/pdf/2410.10105v2.pdf","comment":"Published as a conference paper at ICLR 2025"},{"id":"http://arxiv.org/abs/2406.07843v3","updated":"2025-02-28T09:43:51Z","published":"2024-06-12T03:21:06Z","title":"Self-Attention-Based Contextual Modulation Improves Neural System\n  Identification","summary":"  Convolutional neural networks (CNNs) have been shown to be state-of-the-art\nmodels for visual cortical neurons. Cortical neurons in the primary visual\ncortex are sensitive to contextual information mediated by extensive horizontal\nand feedback connections. Standard CNNs integrate global contextual information\nto model contextual modulation via two mechanisms: successive convolutions and\na fully connected readout layer. In this paper, we find that self-attention\n(SA), an implementation of non-local network mechanisms, can improve neural\nresponse predictions over parameter-matched CNNs in two key metrics: tuning\ncurve correlation and peak tuning. We introduce peak tuning as a metric to\nevaluate a model's ability to capture a neuron's top feature preference. We\nfactorize networks to assess each context mechanism, revealing that information\nin the local receptive field is most important for modeling overall tuning, but\nsurround information is critically necessary for characterizing the tuning\npeak. We find that self-attention can replace posterior spatial-integration\nconvolutions when learned incrementally, and is further enhanced in the\npresence of a fully connected readout layer, suggesting that the two context\nmechanisms are complementary. Finally, we find that decomposing receptive field\nlearning and contextual modulation learning in an incremental manner may be an\neffective and robust mechanism for learning surround-center interactions.\n","authors":["Isaac Lin","Tianye Wang","Shang Gao","Shiming Tang","Tai Sing Lee"],"pdf_url":"https://arxiv.org/pdf/2406.07843v3.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2411.16767v2","updated":"2025-02-28T09:29:21Z","published":"2024-11-25T04:05:11Z","title":"Background-Aware Defect Generation for Robust Industrial Anomaly\n  Detection","summary":"  Detecting anomalies in industrial settings is challenging due to the scarcity\nof labeled anomalous data. Generative models can mitigate this issue by\nsynthesizing realistic defect samples, but existing approaches often fail to\nmodel the crucial interplay between defects and their background. This\noversight leads to unrealistic anomalies, especially in scenarios where\ncontextual consistency is essential (i.e., logical anomaly). To address this,\nwe propose a novel background-aware defect generation framework, where the\nbackground influences defect denoising without affecting the background itself\nby ensuring realistic synthesis while preserving structural integrity. Our\nmethod leverages a disentanglement loss to separate the background' s denoising\nprocess from the defect, enabling controlled defect synthesis through DDIM\nInversion. We theoretically demonstrate that our approach maintains background\nfidelity while generating contextually accurate defects. Extensive experiments\non MVTec AD and MVTec Loco benchmarks validate our mehtod's superiority over\nexisting techniques in both defect generation quality and anomaly detection\nperformance.\n","authors":["Youngjae Cho","Gwangyeol Kim","Sirojbek Safarov","Seongdeok Bang","Jaewoo Park"],"pdf_url":"https://arxiv.org/pdf/2411.16767v2.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2502.20880v1","updated":"2025-02-28T09:25:23Z","published":"2025-02-28T09:25:23Z","title":"Adaptive Identification of Blurred Regions for Accurate Image Deblurring","summary":"  Image deblurring aims to restore high-quality images from blurred ones. While\nexisting deblurring methods have made significant progress, most overlook the\nfact that the degradation degree varies across different regions. In this\npaper, we propose AIBNet, a network that adaptively identifies the blurred\nregions, enabling differential restoration of these regions. Specifically, we\ndesign a spatial feature differential handling block (SFDHBlock), with the core\nbeing the spatial domain feature enhancement module (SFEM). Through the feature\ndifference operation, SFEM not only helps the model focus on the key\ninformation in the blurred regions but also eliminates the interference of\nimplicit noise. Additionally, based on the fact that the difference between\nsharp and blurred images primarily lies in the high-frequency components, we\npropose a high-frequency feature selection block (HFSBlock). The HFSBlock first\nuses learnable filters to extract high-frequency features and then selectively\nretains the most important ones. To fully leverage the decoder's potential, we\nuse a pre-trained model as the encoder and incorporate the above modules only\nin the decoder. Finally, to alleviate the resource burden during training, we\nintroduce a progressive training strategy. Extensive experiments demonstrate\nthat our AIBNet achieves superior performance in image deblurring.\n","authors":["Hu Gao","Depeng Dang"],"pdf_url":"https://arxiv.org/pdf/2502.20880v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20879v1","updated":"2025-02-28T09:23:40Z","published":"2025-02-28T09:23:40Z","title":"egoPPG: Heart Rate Estimation from Eye-Tracking Cameras in Egocentric\n  Systems to Benefit Downstream Vision Tasks","summary":"  Egocentric vision systems aim to understand the spatial surroundings and the\nwearer's behavior inside it, including motions, activities, and interaction\nwith objects. Since a person's attention and situational responses are\ninfluenced by their physiological state, egocentric systems must also detect\nthis state for better context awareness. In this paper, we propose egoPPG, a\nnovel task for egocentric vision systems to extract a person's heart rate (HR)\nas a key indicator of the wearer's physiological state from the system's\nbuilt-in sensors (e.g., eye tracking videos). We then propose EgoPulseFormer, a\nmethod that solely takes eye-tracking video as input to estimate a person's\nphotoplethysmogram (PPG) from areas around the eyes to track HR values-without\nrequiring additional or dedicated hardware. We demonstrate the downstream\nbenefit of EgoPulseFormer on EgoExo4D, where we find that augmenting existing\nmodels with tracked HR values improves proficiency estimation by 14%. To train\nand validate EgoPulseFormer, we collected a dataset of 13+ hours of\neye-tracking videos from Project Aria and contact-based blood volume pulse\nsignals as well as an electrocardiogram (ECG) for ground-truth HR values. 25\nparticipants performed diverse everyday activities such as office work,\ncooking, dancing, and exercising, which induced significant natural motion and\nHR variation (44-164 bpm). Our model robustly estimates HR (MAE=8.82 bpm) and\ncaptures patterns (r=0.81). Our results show how egocentric systems may unify\nenvironmental and physiological tracking to better understand user actions and\ninternal states.\n","authors":["Björn Braun","Rayan Armani","Manuel Meier","Max Moebus","Christian Holz"],"pdf_url":"https://arxiv.org/pdf/2502.20879v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20877v1","updated":"2025-02-28T09:21:01Z","published":"2025-02-28T09:21:01Z","title":"Guiding Quantitative MRI Reconstruction with Phase-wise Uncertainty","summary":"  Quantitative magnetic resonance imaging (qMRI) requires multi-phase\nacqui-sition, often relying on reduced data sampling and reconstruction\nalgorithms to accelerate scans, which inherently poses an ill-posed inverse\nproblem. While many studies focus on measuring uncertainty during this process,\nfew explore how to leverage it to enhance reconstruction performance. In this\npaper, we in-troduce PUQ, a novel approach that pioneers the use of uncertainty\ninfor-mation for qMRI reconstruction. PUQ employs a two-stage reconstruction\nand parameter fitting framework, where phase-wise uncertainty is estimated\nduring reconstruction and utilized in the fitting stage. This design allows\nuncertainty to reflect the reliability of different phases and guide\ninformation integration during parameter fitting. We evaluated PUQ on in vivo\nT1 and T2 mapping datasets from healthy subjects. Compared to existing qMRI\nreconstruction methods, PUQ achieved the state-of-the-art performance in\nparameter map-pings, demonstrating the effectiveness of uncertainty guidance.\nOur code is available at https://anonymous.4open.science/r/PUQ-75B2/.\n","authors":["Haozhong Sun","Zhongsen Li","Chenlin Du","Haokun Li","Yajie Wang","Huijun Chen"],"pdf_url":"https://arxiv.org/pdf/2502.20877v1.pdf","comment":"Submitted to MICCAI2025"},{"id":"http://arxiv.org/abs/2502.20869v1","updated":"2025-02-28T09:13:01Z","published":"2025-02-28T09:13:01Z","title":"PathVG: A New Benchmark and Dataset for Pathology Visual Grounding","summary":"  With the rapid development of computational pathology, many AI-assisted\ndiagnostic tasks have emerged. Cellular nuclei segmentation can segment various\ntypes of cells for downstream analysis, but it relies on predefined categories\nand lacks flexibility. Moreover, pathology visual question answering can\nperform image-level understanding but lacks region-level detection capability.\nTo address this, we propose a new benchmark called Pathology Visual Grounding\n(PathVG), which aims to detect regions based on expressions with different\nattributes. To evaluate PathVG, we create a new dataset named RefPath which\ncontains 27,610 images with 33,500 language-grounded boxes. Compared to visual\ngrounding in other domains, PathVG presents pathological images at multi-scale\nand contains expressions with pathological knowledge. In the experimental\nstudy, we found that the biggest challenge was the implicit information\nunderlying the pathological expressions. Based on this, we proposed Pathology\nKnowledge-enhanced Network (PKNet) as the baseline model for PathVG. PKNet\nleverages the knowledge-enhancement capabilities of Large Language Models\n(LLMs) to convert pathological terms with implicit information into explicit\nvisual features, and fuses knowledge features with expression features through\nthe designed Knowledge Fusion Module (KFM). The proposed method achieves\nstate-of-the-art performance on the PathVG benchmark.\n","authors":["Chunlin Zhong","Shuang Hao","Junhua Wu","Xiaona Chang","Jiwei Jiang","Xiu Nie","He Tang","Xiang Bai"],"pdf_url":"https://arxiv.org/pdf/2502.20869v1.pdf","comment":"10pages, 4figures"},{"id":"http://arxiv.org/abs/2303.17703v2","updated":"2025-02-28T09:02:21Z","published":"2023-03-30T20:52:08Z","title":"If At First You Don't Succeed: Test Time Re-ranking for Zero-shot,\n  Cross-domain Retrieval","summary":"  In this paper, we introduce a novel method for zero-shot, cross-domain image\nretrieval. Our key contribution is a test-time Iterative Cluster-free\nRe-ranking process that leverages gallery-gallery feature information to\nestablish semantic links between query and gallery images. This enables the\nretrieval of relevant images even when they do not exhibit similar visual\nfeatures but share underlying semantic concepts. This can be combined with any\npre-existing cross-domain feature extraction backbone to improve retrieval\nperformance. However, when combined with a carefully chosen Vision Transformer\nbackbone and combination of zero-shot retrieval losses, our approach yields\nstate-of-the-art results on the Sketchy, TU-Berlin and QuickDraw sketch-based\nretrieval benchmarks. We show that our re-ranking also improves performance\nwith other backbones and outperforms other re-ranking methods applied with our\nbackbone. Importantly, unlike many previous methods, none of the components in\nour approach are engineered specifically towards the sketch-based image\nretrieval task - it can be generally applied to any cross-domain, zero-shot\nretrieval task. We therefore also present new results on zero-shot\ncartoon-to-photo and art-to-product retrieval using the Office-Home dataset.\nProject page: finlay-hudson.github.io/icfrr, code available at:\ngithub.com/finlay-hudson/ICFRR\n","authors":["Finlay G. C. Hudson","William A. P. Smith"],"pdf_url":"https://arxiv.org/pdf/2303.17703v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20861v1","updated":"2025-02-28T09:02:15Z","published":"2025-02-28T09:02:15Z","title":"MESC-3D:Mining Effective Semantic Cues for 3D Reconstruction from a\n  Single Image","summary":"  Reconstructing 3D shapes from a single image plays an important role in\ncomputer vision. Many methods have been proposed and achieve impressive\nperformance. However, existing methods mainly focus on extracting semantic\ninformation from images and then simply concatenating it with 3D point clouds\nwithout further exploring the concatenated semantics. As a result, these\nentangled semantic features significantly hinder the reconstruction\nperformance. In this paper, we propose a novel single-image 3D reconstruction\nmethod called Mining Effective Semantic Cues for 3D Reconstruction from a\nSingle Image (MESC-3D), which can actively mine effective semantic cues from\nentangled features. Specifically, we design an Effective Semantic Mining Module\nto establish connections between point clouds and image semantic attributes,\nenabling the point clouds to autonomously select the necessary information.\nFurthermore, to address the potential insufficiencies in semantic information\nfrom a single image, such as occlusions, inspired by the human ability to\nrepresent 3D objects using prior knowledge drawn from daily experiences, we\nintroduce a 3D Semantic Prior Learning Module. This module incorporates\nsemantic understanding of spatial structures, enabling the model to interpret\nand reconstruct 3D objects with greater accuracy and realism, closely mirroring\nhuman perception of complex 3D environments. Extensive evaluations show that\nour method achieves significant improvements in reconstruction quality and\nrobustness compared to prior works. Additionally, further experiments validate\nthe strong generalization capabilities and excels in zero-shot preformance on\nunseen classes. Code is available at https://github.com/QINGQINGLE/MESC-3D.\n","authors":["Shaoming Li","Qing Cai","Songqi Kong","Runqing Tan","Heng Tong","Shiji Qiu","Yongguo Jiang","Zhi Liu"],"pdf_url":"https://arxiv.org/pdf/2502.20861v1.pdf","comment":"Published in CVPR 2025"},{"id":"http://arxiv.org/abs/2411.16199v3","updated":"2025-02-28T08:57:48Z","published":"2024-11-25T08:55:41Z","title":"VIRES: Video Instance Repainting with Sketch and Text Guidance","summary":"  We introduce VIRES, a video instance repainting method with sketch and text\nguidance, enabling video instance repainting, replacement, generation, and\nremoval. Existing approaches struggle with temporal consistency and accurate\nalignment with the provided sketch sequence. VIRES leverages the generative\npriors of text-to-video models to maintain temporal consistency and produce\nvisually pleasing results. We propose the Sequential ControlNet with the\nstandardized self-scaling, which effectively extracts structure layouts and\nadaptively captures high-contrast sketch details. We further augment the\ndiffusion transformer backbone with the sketch attention to interpret and\ninject fine-grained sketch semantics. A sketch-aware encoder ensures that\nrepainted results are aligned with the provided sketch sequence. Additionally,\nwe contribute the VireSet, a dataset with detailed annotations tailored for\ntraining and evaluating video instance editing methods. Experimental results\ndemonstrate the effectiveness of VIRES, which outperforms state-of-the-art\nmethods in visual quality, temporal consistency, condition alignment, and human\nratings. Project page:https://suimuc.github.io/suimu.github.io/projects/VIRES/\n","authors":["Shuchen Weng","Haojie Zheng","Peixuan Zhan","Yuchen Hong","Han Jiang","Si Li","Boxin Shi"],"pdf_url":"https://arxiv.org/pdf/2411.16199v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.01449v6","updated":"2025-02-28T08:51:57Z","published":"2024-06-27T15:45:29Z","title":"ColPali: Efficient Document Retrieval with Vision Language Models","summary":"  Documents are visually rich structures that convey information through text,\nbut also figures, page layouts, tables, or even fonts. Since modern retrieval\nsystems mainly rely on the textual information they extract from document pages\nto index documents -often through lengthy and brittle processes-, they struggle\nto exploit key visual cues efficiently. This limits their capabilities in many\npractical document retrieval applications such as Retrieval Augmented\nGeneration (RAG). To benchmark current systems on visually rich document\nretrieval, we introduce the Visual Document Retrieval Benchmark ViDoRe,\ncomposed of various page-level retrieval tasks spanning multiple domains,\nlanguages, and practical settings. The inherent complexity and performance\nshortcomings of modern systems motivate a new concept; doing document retrieval\nby directly embedding the images of the document pages. We release ColPali, a\nVision Language Model trained to produce high-quality multi-vector embeddings\nfrom images of document pages. Combined with a late interaction matching\nmechanism, ColPali largely outperforms modern document retrieval pipelines\nwhile being drastically simpler, faster and end-to-end trainable. We release\nmodels, data, code and benchmarks under open licenses at https://hf.co/vidore.\n","authors":["Manuel Faysse","Hugues Sibille","Tony Wu","Bilel Omrani","Gautier Viaud","Céline Hudelot","Pierre Colombo"],"pdf_url":"https://arxiv.org/pdf/2407.01449v6.pdf","comment":"Published as a conference paper at ICLR 2025"},{"id":"http://arxiv.org/abs/2502.20853v1","updated":"2025-02-28T08:51:55Z","published":"2025-02-28T08:51:55Z","title":"Oscillation-Reduced MXFP4 Training for Vision Transformers","summary":"  Pre-training Transformers in FP4 precision is becoming a promising approach\nto gain substantial speedup, but it comes with a considerable loss of accuracy.\nMicroscaling (MX) data format provides a fine-grained per-group quantization\nmethod to improve the representation ability of the FP4 format and is supported\nby the next-generation Blackwell GPU architecture. However, training with MXFP4\ndata format still results in significant degradation and there is a lack of\nsystematic research on the reason.\n  In this work, we propose a novel training method TetraJet for a more accurate\nFP4 training. We comprehensively evaluate all of the quantizers involved in the\ntraining, and identify the weight oscillation problem in the forward pass as\nthe main source of the degradation in MXFP4 training. Therefore, we introduce\ntwo novel methods, EMA Quantizer (Q-EMA) and Adaptive Ramping Optimizer\n(Q-Ramping), to resolve the oscillation problem. Extensive experiments on\nVision Transformers demonstrate that TetraJet consistently outperforms the\nexisting 4-bit training methods, and Q-EMA & Q-Ramping can provide additional\nenhancement by effectively reducing oscillation. We decreased the accuracy\ndegradation by more than $50\\%$ compared to the baseline, and can even achieve\ncompetitive performance compared to full precision training. The codes are\navailable at https://github.com/thu-ml/TetraJet-MXFP4Training\n","authors":["Yuxiang Chen","Haocheng Xi","Jun Zhu","Jianfei Chen"],"pdf_url":"https://arxiv.org/pdf/2502.20853v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20852v1","updated":"2025-02-28T08:49:46Z","published":"2025-02-28T08:49:46Z","title":"Delta-WKV: A Novel Meta-in-Context Learner for MRI Super-Resolution","summary":"  Magnetic Resonance Imaging (MRI) Super-Resolution (SR) addresses the\nchallenges such as long scan times and expensive equipment by enhancing image\nresolution from low-quality inputs acquired in shorter scan times in clinical\nsettings. However, current SR techniques still have problems such as limited\nability to capture both local and global static patterns effectively and\nefficiently. To address these limitations, we propose Delta-WKV, a novel MRI\nsuper-resolution model that combines Meta-in-Context Learning (MiCL) with the\nDelta rule to better recognize both local and global patterns in MRI images.\nThis approach allows Delta-WKV to adjust weights dynamically during inference,\nimproving pattern recognition with fewer parameters and less computational\neffort, without using state-space modeling. Additionally, inspired by\nReceptance Weighted Key Value (RWKV), Delta-WKV uses a quad-directional\nscanning mechanism with time-mixing and channel-mixing structures to capture\nlong-range dependencies while maintaining high-frequency details. Tests on the\nIXI and fastMRI datasets show that Delta-WKV outperforms existing methods,\nimproving PSNR by 0.06 dB and SSIM by 0.001, while reducing training and\ninference times by over 15\\%. These results demonstrate its efficiency and\npotential for clinical use with large datasets and high-resolution imaging.\n","authors":["Rongchang Lu","Bingcheng Liao","Haowen Hou","Jiahang Lv","Xin Hai"],"pdf_url":"https://arxiv.org/pdf/2502.20852v1.pdf","comment":"This paper has been published to MICCAI 2025. Feel free to contact on\n  nomodeset@qq.com"},{"id":"http://arxiv.org/abs/2502.15601v2","updated":"2025-02-28T08:49:29Z","published":"2025-02-21T17:18:30Z","title":"WorldCraft: Photo-Realistic 3D World Creation and Customization via LLM\n  Agents","summary":"  Constructing photorealistic virtual worlds has applications across various\nfields, but it often requires the extensive labor of highly trained\nprofessionals to operate conventional 3D modeling software. To democratize this\nprocess, we introduce WorldCraft, a system where large language model (LLM)\nagents leverage procedural generation to create indoor and outdoor scenes\npopulated with objects, allowing users to control individual object attributes\nand the scene layout using intuitive natural language commands. In our\nframework, a coordinator agent manages the overall process and works with two\nspecialized LLM agents to complete the scene creation: ForgeIt, which\nintegrates an ever-growing manual through auto-verification to enable precise\ncustomization of individual objects, and ArrangeIt, which formulates\nhierarchical optimization problems to achieve a layout that balances ergonomic\nand aesthetic considerations. Additionally, our pipeline incorporates a\ntrajectory control agent, allowing users to animate the scene and operate the\ncamera through natural language interactions. Our system is also compatible\nwith off-the-shelf deep 3D generators to enrich scene assets. Through\nevaluations and comparisons with state-of-the-art methods, we demonstrate the\nversatility of WorldCraft, ranging from single-object customization to\nintricate, large-scale interior and exterior scene designs. This system\nempowers non-professionals to bring their creative visions to life.\n","authors":["Xinhang Liu","Chi-Keung Tang","Yu-Wing Tai"],"pdf_url":"https://arxiv.org/pdf/2502.15601v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20850v1","updated":"2025-02-28T08:49:03Z","published":"2025-02-28T08:49:03Z","title":"VLEER: Vision and Language Embeddings for Explainable Whole Slide Image\n  Representation","summary":"  Recent advances in vision-language models (VLMs) have shown remarkable\npotential in bridging visual and textual modalities. In computational\npathology, domain-specific VLMs, which are pre-trained on extensive\nhistopathology image-text datasets, have succeeded in various downstream tasks.\nHowever, existing research has primarily focused on the pre-training process\nand direct applications of VLMs on the patch level, leaving their great\npotential for whole slide image (WSI) applications unexplored. In this study,\nwe hypothesize that pre-trained VLMs inherently capture informative and\ninterpretable WSI representations through quantitative feature extraction. To\nvalidate this hypothesis, we introduce Vision and Language Embeddings for\nExplainable WSI Representation (VLEER), a novel method designed to leverage\nVLMs for WSI representation. We systematically evaluate VLEER on three\npathological WSI datasets, proving its better performance in WSI analysis\ncompared to conventional vision features. More importantly, VLEER offers the\nunique advantage of interpretability, enabling direct human-readable insights\ninto the results by leveraging the textual modality for detailed pathology\nannotations, providing clear reasoning for WSI-level pathology downstream\ntasks.\n","authors":["Anh Tien Nguyen","Keunho Byeon","Kyungeun Kim","Jin Tae Kwak"],"pdf_url":"https://arxiv.org/pdf/2502.20850v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2408.17135v3","updated":"2025-02-28T08:45:05Z","published":"2024-08-30T09:22:07Z","title":"TIMotion: Temporal and Interactive Framework for Efficient Human-Human\n  Motion Generation","summary":"  Human-human motion generation is essential for understanding humans as social\nbeings. Current methods fall into two main categories: single-person-based\nmethods and separate modeling-based methods. To delve into this field, we\nabstract the overall generation process into a general framework MetaMotion,\nwhich consists of two phases: temporal modeling and interaction mixing. For\ntemporal modeling, the single-person-based methods concatenate two people into\na single one directly, while the separate modeling-based methods skip the\nmodeling of interaction sequences. The inadequate modeling described above\nresulted in sub-optimal performance and redundant model parameters. In this\npaper, we introduce TIMotion (Temporal and Interactive Modeling), an efficient\nand effective framework for human-human motion generation. Specifically, we\nfirst propose Causal Interactive Injection to model two separate sequences as a\ncausal sequence leveraging the temporal and causal properties. Then we present\nRole-Evolving Scanning to adjust to the change in the active and passive roles\nthroughout the interaction. Finally, to generate smoother and more rational\nmotion, we design Localized Pattern Amplification to capture short-term motion\npatterns. Extensive experiments on InterHuman and InterX demonstrate that our\nmethod achieves superior performance. The project code will be released upon\nacceptance. Project page: https://aigc-explorer.github.io/TIMotion-page/\n","authors":["Yabiao Wang","Shuo Wang","Jiangning Zhang","Ke Fan","Jiafu Wu","Zhucun Xue","Yong Liu"],"pdf_url":"https://arxiv.org/pdf/2408.17135v3.pdf","comment":"Accepted to CVPR 2025. Project page:\n  https://aigc-explorer.github.io/TIMotion-page/"},{"id":"http://arxiv.org/abs/2502.20144v2","updated":"2025-02-28T08:39:21Z","published":"2025-02-27T14:35:47Z","title":"Robust sensitivity control in digital pathology via tile score\n  distribution matching","summary":"  Deploying digital pathology models across medical centers is challenging due\nto distribution shifts. Recent advances in domain generalization improve model\ntransferability in terms of aggregated performance measured by the Area Under\nCurve (AUC). However, clinical regulations often require to control the\ntransferability of other metrics, such as prescribed sensitivity levels. We\nintroduce a novel approach to control the sensitivity of whole slide image\n(WSI) classification models, based on optimal transport and Multiple Instance\nLearning (MIL). Validated across multiple cohorts and tasks, our method enables\nrobust sensitivity control with only a handful of calibration samples,\nproviding a practical solution for reliable deployment of computational\npathology systems.\n","authors":["Arthur Pignet","John Klein","Genevieve Robin","Antoine Olivier"],"pdf_url":"https://arxiv.org/pdf/2502.20144v2.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2502.20826v1","updated":"2025-02-28T08:12:23Z","published":"2025-02-28T08:12:23Z","title":"CoTMR: Chain-of-Thought Multi-Scale Reasoning for Training-Free\n  Zero-Shot Composed Image Retrieval","summary":"  Zero-Shot Composed Image Retrieval (ZS-CIR) aims to retrieve target images by\nintegrating information from a composed query (reference image and modification\ntext) without training samples. Existing methods primarily combine caption\nmodels and large language models (LLMs) to generate target captions based on\ncomposed queries but face various issues such as incompatibility, visual\ninformation loss, and insufficient reasoning. In this work, we propose CoTMR, a\ntraining-free framework crafted for ZS-CIR with novel Chain-of-thought (CoT)\nand Multi-scale Reasoning. Instead of relying on caption models for modality\ntransformation, CoTMR employs the Large Vision-Language Model (LVLM) to achieve\nunified understanding and reasoning for composed queries. To enhance the\nreasoning reliability, we devise CIRCoT, which guides the LVLM through a\nstep-by-step inference process using predefined subtasks. Considering that\nexisting approaches focus solely on global-level reasoning, our CoTMR\nincorporates multi-scale reasoning to achieve more comprehensive inference via\nfine-grained predictions about the presence or absence of key elements at the\nobject scale. Further, we design a Multi-Grained Scoring (MGS) mechanism, which\nintegrates CLIP similarity scores of the above reasoning outputs with candidate\nimages to realize precise retrieval. Extensive experiments demonstrate that our\nCoTMR not only drastically outperforms previous methods across four prominent\nbenchmarks but also offers appealing interpretability.\n","authors":["Zelong Sun","Dong Jing","Zhiwu Lu"],"pdf_url":"https://arxiv.org/pdf/2502.20826v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.14174v4","updated":"2025-02-28T08:12:21Z","published":"2025-01-24T01:50:19Z","title":"Dreamweaver: Learning Compositional World Models from Pixels","summary":"  Humans have an innate ability to decompose their perceptions of the world\ninto objects and their attributes, such as colors, shapes, and movement\npatterns. This cognitive process enables us to imagine novel futures by\nrecombining familiar concepts. However, replicating this ability in artificial\nintelligence systems has proven challenging, particularly when it comes to\nmodeling videos into compositional concepts and generating unseen, recomposed\nfutures without relying on auxiliary data, such as text, masks, or bounding\nboxes. In this paper, we propose Dreamweaver, a neural architecture designed to\ndiscover hierarchical and compositional representations from raw videos and\ngenerate compositional future simulations. Our approach leverages a novel\nRecurrent Block-Slot Unit (RBSU) to decompose videos into their constituent\nobjects and attributes. In addition, Dreamweaver uses a multi-future-frame\nprediction objective to capture disentangled representations for dynamic\nconcepts more effectively as well as static concepts. In experiments, we\ndemonstrate our model outperforms current state-of-the-art baselines for world\nmodeling when evaluated under the DCI framework across multiple datasets.\nFurthermore, we show how the modularized concept representations of our model\nenable compositional imagination, allowing the generation of novel videos by\nrecombining attributes from previously seen objects.\ncun-bjy.github.io/dreamweaver-website\n","authors":["Junyeob Baek","Yi-Fu Wu","Gautam Singh","Sungjin Ahn"],"pdf_url":"https://arxiv.org/pdf/2501.14174v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20824v1","updated":"2025-02-28T08:11:03Z","published":"2025-02-28T08:11:03Z","title":"MFSR-GAN: Multi-Frame Super-Resolution with Handheld Motion Modeling","summary":"  Smartphone cameras have become ubiquitous imaging tools, yet their small\nsensors and compact optics often limit spatial resolution and introduce\ndistortions. Combining information from multiple low-resolution (LR) frames to\nproduce a high-resolution (HR) image has been explored to overcome the inherent\nlimitations of smartphone cameras. Despite the promise of multi-frame\nsuper-resolution (MFSR), current approaches are hindered by datasets that fail\nto capture the characteristic noise and motion patterns found in real-world\nhandheld burst images. In this work, we address this gap by introducing a novel\nsynthetic data engine that uses multi-exposure static images to synthesize\nLR-HR training pairs while preserving sensor-specific noise characteristics and\nimage motion found during handheld burst photography. We also propose MFSR-GAN:\na multi-scale RAW-to-RGB network for MFSR. Compared to prior approaches,\nMFSR-GAN emphasizes a \"base frame\" throughout its architecture to mitigate\nartifacts. Experimental results on both synthetic and real data demonstrates\nthat MFSR-GAN trained with our synthetic engine yields sharper, more realistic\nreconstructions than existing methods for real-world MFSR.\n","authors":["Fadeel Sher Khan","Joshua Ebenezer","Hamid Sheikh","Seok-Jun Lee"],"pdf_url":"https://arxiv.org/pdf/2502.20824v1.pdf","comment":"8 pages, 6 figures"},{"id":"http://arxiv.org/abs/2502.20823v1","updated":"2025-02-28T08:10:30Z","published":"2025-02-28T08:10:30Z","title":"Can We Simplify Slide-level Fine-tuning of Pathology Foundation Models?","summary":"  The emergence of foundation models in computational pathology has transformed\nhistopathological image analysis, with whole slide imaging (WSI) diagnosis\nbeing a core application. Traditionally, weakly supervised fine-tuning via\nmultiple instance learning (MIL) has been the primary method for adapting\nfoundation models to WSIs. However, in this work we present a key experimental\nfinding: a simple nonlinear mapping strategy combining mean pooling and a\nmultilayer perceptron, called SiMLP, can effectively adapt patch-level\nfoundation models to slide-level tasks without complex MIL-based learning.\nThrough extensive experiments across diverse downstream tasks, we demonstrate\nthe superior performance of SiMLP with state-of-the-art methods. For instance,\non a large-scale pan-cancer classification task, SiMLP surpasses popular\nMIL-based methods by 3.52%. Furthermore, SiMLP shows strong learning ability in\nfew-shot classification and remaining highly competitive with slide-level\nfoundation models pretrained on tens of thousands of slides. Finally, SiMLP\nexhibits remarkable robustness and transferability in lung cancer subtyping.\nOverall, our findings challenge the conventional MIL-based fine-tuning\nparadigm, demonstrating that a task-agnostic representation strategy alone can\neffectively adapt foundation models to WSI analysis. These insights offer a\nunique and meaningful perspective for future research in digital pathology,\npaving the way for more efficient and broadly applicable methodologies.\n","authors":["Jiawen Li","Jiali Hu","Qiehe Sun","Renao Yan","Minxi Ouyang","Tian Guan","Anjia Han","Chao He","Yonghong He"],"pdf_url":"https://arxiv.org/pdf/2502.20823v1.pdf","comment":"11 pages, 3 figures, 4 tables"},{"id":"http://arxiv.org/abs/2412.08467v2","updated":"2025-02-28T08:06:39Z","published":"2024-12-11T15:32:24Z","title":"Bootstrapping Language-Guided Navigation Learning with Self-Refining\n  Data Flywheel","summary":"  Creating high-quality data for training robust language-instructed agents is\na long-lasting challenge in embodied AI. In this paper, we introduce a\nSelf-Refining Data Flywheel (SRDF) that generates high-quality and large-scale\nnavigational instruction-trajectory pairs by iteratively refining the data pool\nthrough the collaboration between two models, the instruction generator and the\nnavigator, without any human-in-the-loop annotation. Specifically, SRDF starts\nwith using a base generator to create an initial data pool for training a base\nnavigator, followed by applying the trained navigator to filter the data pool.\nThis leads to higher-fidelity data to train a better generator, which can, in\nturn, produce higher-quality data for training the next-round navigator. Such a\nflywheel establishes a data self-refining process, yielding a continuously\nimproved and highly effective dataset for large-scale language-guided\nnavigation learning. Our experiments demonstrate that after several flywheel\nrounds, the navigator elevates the performance boundary from 70% to 78% SPL on\nthe classic R2R test set, surpassing human performance (76%) for the first\ntime. Meanwhile, this process results in a superior generator, evidenced by a\nSPICE increase from 23.5 to 26.2, better than all previous VLN instruction\ngeneration methods. Finally, we demonstrate the scalability of our method\nthrough increasing environment and instruction diversity, and the\ngeneralization ability of our pre-trained navigator across various downstream\nnavigation tasks, surpassing state-of-the-art methods by a large margin in all\ncases.\n","authors":["Zun Wang","Jialu Li","Yicong Hong","Songze Li","Kunchang Li","Shoubin Yu","Yi Wang","Yu Qiao","Yali Wang","Mohit Bansal","Limin Wang"],"pdf_url":"https://arxiv.org/pdf/2412.08467v2.pdf","comment":"28 pages, Code and data are available at\n  https://github.com/wz0919/VLN-SRDF"},{"id":"http://arxiv.org/abs/2502.20814v1","updated":"2025-02-28T07:57:23Z","published":"2025-02-28T07:57:23Z","title":"Improved 3D Point-Line Mapping Regression for Camera Relocalization","summary":"  In this paper, we present a new approach for improving 3D point and line\nmapping regression for camera re-localization. Previous methods typically rely\non feature matching (FM) with stored descriptors or use a single network to\nencode both points and lines. While FM-based methods perform well in\nlarge-scale environments, they become computationally expensive with a growing\nnumber of mapping points and lines. Conversely, approaches that learn to encode\nmapping features within a single network reduce memory footprint but are prone\nto overfitting, as they may capture unnecessary correlations between points and\nlines. We propose that these features should be learned independently, each\nwith a distinct focus, to achieve optimal accuracy. To this end, we introduce a\nnew architecture that learns to prioritize each feature independently before\ncombining them for localization. Experimental results demonstrate that our\napproach significantly enhances the 3D map point and line regression\nperformance for camera re-localization. The implementation of our method will\nbe publicly available at: https://github.com/ais-lab/pl2map/.\n","authors":["Bach-Thuan Bui","Huy-Hoang Bui","Yasuyuki Fujii","Dinh-Tuan Tran","Joo-Ho Lee"],"pdf_url":"https://arxiv.org/pdf/2502.20814v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20811v1","updated":"2025-02-28T07:53:40Z","published":"2025-02-28T07:53:40Z","title":"HAIC: Improving Human Action Understanding and Generation with Better\n  Captions for Multi-modal Large Language Models","summary":"  Recent Multi-modal Large Language Models (MLLMs) have made great progress in\nvideo understanding. However, their performance on videos involving human\nactions is still limited by the lack of high-quality data. To address this, we\nintroduce a two-stage data annotation pipeline. First, we design strategies to\naccumulate videos featuring clear human actions from the Internet. Second,\nvideos are annotated in a standardized caption format that uses human\nattributes to distinguish individuals and chronologically details their actions\nand interactions. Through this pipeline, we curate two datasets, namely\nHAICTrain and HAICBench. \\textbf{HAICTrain} comprises 126K video-caption pairs\ngenerated by Gemini-Pro and verified for training purposes. Meanwhile,\n\\textbf{HAICBench} includes 500 manually annotated video-caption pairs and\n1,400 QA pairs, for a comprehensive evaluation of human action understanding.\nExperimental results demonstrate that training with HAICTrain not only\nsignificantly enhances human understanding abilities across 4 benchmarks, but\ncan also improve text-to-video generation results. Both the HAICTrain and\nHAICBench are released at https://huggingface.co/datasets/KuaishouHAIC/HAIC.\n","authors":["Xiao Wang","Jingyun Hua","Weihong Lin","Yuanxing Zhang","Fuzheng Zhang","Jianlong Wu","Di Zhang","Liqiang Nie"],"pdf_url":"https://arxiv.org/pdf/2502.20811v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.08481v2","updated":"2025-02-28T07:43:38Z","published":"2024-06-12T17:59:21Z","title":"Enhancing End-to-End Autonomous Driving with Latent World Model","summary":"  In autonomous driving, end-to-end planners directly utilize raw sensor data,\nenabling them to extract richer scene features and reduce information loss\ncompared to traditional planners. This raises a crucial research question: how\ncan we develop better scene feature representations to fully leverage sensor\ndata in end-to-end driving? Self-supervised learning methods show great success\nin learning rich feature representations in NLP and computer vision. Inspired\nby this, we propose a novel self-supervised learning approach using the LAtent\nWorld model (LAW) for end-to-end driving. LAW predicts future scene features\nbased on current features and ego trajectories. This self-supervised task can\nbe seamlessly integrated into perception-free and perception-based frameworks,\nimproving scene feature learning and optimizing trajectory prediction. LAW\nachieves state-of-the-art performance across multiple benchmarks, including\nreal-world open-loop benchmark nuScenes, NAVSIM, and simulator-based\nclosed-loop benchmark CARLA. The code is released at\nhttps://github.com/BraveGroup/LAW.\n","authors":["Yingyan Li","Lue Fan","Jiawei He","Yuqi Wang","Yuntao Chen","Zhaoxiang Zhang","Tieniu Tan"],"pdf_url":"https://arxiv.org/pdf/2406.08481v2.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2502.20805v1","updated":"2025-02-28T07:42:54Z","published":"2025-02-28T07:42:54Z","title":"Towards Semantic 3D Hand-Object Interaction Generation via Functional\n  Text Guidance","summary":"  Hand-object interaction(HOI) is the fundamental link between human and\nenvironment, yet its dexterous and complex pose significantly challenges for\ngesture control. Despite significant advances in AI and robotics, enabling\nmachines to understand and simulate hand-object interactions, capturing the\nsemantics of functional grasping tasks remains a considerable challenge. While\nprevious work can generate stable and correct 3D grasps, they are still far\nfrom achieving functional grasps due to unconsidered grasp semantics. To\naddress this challenge, we propose an innovative two-stage framework,\nFunctional Grasp Synthesis Net (FGS-Net), for generating 3D HOI driven by\nfunctional text. This framework consists of a text-guided 3D model generator,\nFunctional Grasp Generator (FGG), and a pose optimization strategy, Functional\nGrasp Refiner (FGR). FGG generates 3D models of hands and objects based on text\ninput, while FGR fine-tunes the poses using Object Pose Approximator and energy\nfunctions to ensure the relative position between the hand and object aligns\nwith human intent and remains physically plausible. Extensive experiments\ndemonstrate that our approach achieves precise and high-quality HOI generation\nwithout requiring additional 3D annotation data.\n","authors":["Yongqi Tian","Xueyu Sun","Haoyuan He","Linji Hao","Ning Ding","Caigui Jiang"],"pdf_url":"https://arxiv.org/pdf/2502.20805v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20803v1","updated":"2025-02-28T07:38:48Z","published":"2025-02-28T07:38:48Z","title":"Two-Stream Spatial-Temporal Transformer Framework for Person\n  Identification via Natural Conversational Keypoints","summary":"  In the age of AI-driven generative technologies, traditional biometric\nrecognition systems face unprecedented challenges, particularly from\nsophisticated deepfake and face reenactment techniques. In this study, we\npropose a Two-Stream Spatial-Temporal Transformer Framework for person\nidentification using upper body keypoints visible during online conversations,\nwhich we term conversational keypoints. Our framework processes both spatial\nrelationships between keypoints and their temporal evolution through two\nspecialized branches: a Spatial Transformer (STR) that learns distinctive\nstructural patterns in keypoint configurations, and a Temporal Transformer\n(TTR) that captures sequential motion patterns. Using the state-of-the-art\nSapiens pose estimator, we extract 133 keypoints (based on COCO-WholeBody\nformat) representing facial features, head pose, and hand positions. The\nframework was evaluated on a dataset of 114 individuals engaged in natural\nconversations, achieving recognition accuracies of 80.12% for the spatial\nstream, 63.61% for the temporal stream. We then explored two fusion strategies:\na shared loss function approach achieving 82.22% accuracy, and a feature-level\nfusion method that concatenates feature maps from both streams, significantly\nimproving performance to 94.86%. By jointly modeling both static anatomical\nrelationships and dynamic movement patterns, our approach learns comprehensive\nidentity signatures that are more robust to spoofing than traditional\nappearance-based methods.\n","authors":["Masoumeh Chapariniya","Hossein Ranjbar","Teodora Vukovic","Sarah Ebling","Volker Dellwo"],"pdf_url":"https://arxiv.org/pdf/2502.20803v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20104v2","updated":"2025-02-28T07:36:32Z","published":"2025-02-27T13:58:44Z","title":"New Dataset and Methods for Fine-Grained Compositional Referring\n  Expression Comprehension via Specialist-MLLM Collaboration","summary":"  Referring Expression Comprehension (REC) is a foundational cross-modal task\nthat evaluates the interplay of language understanding, image comprehension,\nand language-to-image grounding. To advance this field, we introduce a new REC\ndataset with two key features. First, it is designed with controllable\ndifficulty levels, requiring fine-grained reasoning across object categories,\nattributes, and relationships. Second, it incorporates negative text and images\ngenerated through fine-grained editing, explicitly testing a model's ability to\nreject non-existent targets, an often-overlooked yet critical challenge in\nexisting datasets. To address fine-grained compositional REC, we propose novel\nmethods based on a Specialist-MLLM collaboration framework, leveraging the\ncomplementary strengths of them: Specialist Models handle simpler tasks\nefficiently, while MLLMs are better suited for complex reasoning. Based on this\nsynergy, we introduce two collaborative strategies. The first, Slow-Fast\nAdaptation (SFA), employs a routing mechanism to adaptively delegate simple\ntasks to Specialist Models and complex tasks to MLLMs. Additionally, common\nerror patterns in both models are mitigated through a target-refocus strategy.\nThe second, Candidate Region Selection (CRS), generates multiple bounding box\ncandidates based on Specialist Model and uses the advanced reasoning\ncapabilities of MLLMs to identify the correct target. Extensive experiments on\nour dataset and other challenging compositional benchmarks validate the\neffectiveness of our approaches. The SFA strategy achieves a trade-off between\nlocalization accuracy and efficiency, and the CRS strategy greatly boosts the\nperformance of both Specialist Models and MLLMs. We aim for this work to offer\nvaluable insights into solving complex real-world tasks by strategically\ncombining existing tools for maximum effectiveness, rather than reinventing\nthem.\n","authors":["Xuzheng Yang","Junzhuo Liu","Peng Wang","Guoqing Wang","Yang Yang","Heng Tao Shen"],"pdf_url":"https://arxiv.org/pdf/2502.20104v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.06504v4","updated":"2025-02-28T07:35:11Z","published":"2023-02-13T16:30:53Z","title":"Preconditioned Score-based Generative Models","summary":"  Score-based generative models (SGMs) have recently emerged as a promising\nclass of generative models. However, a fundamental limitation is that their\nsampling process is slow due to a need for many (e.g., 2000) iterations of\nsequential computations. An intuitive acceleration method is to reduce the\nsampling iterations which however causes severe performance degradation. We\nassault this problem to the ill-conditioned issues of the Langevin dynamics and\nreverse diffusion in the sampling process. Under this insight, we propose a\nnovel preconditioned diffusion sampling (PDS) method that leverages matrix\npreconditioning to alleviate the aforementioned problem. PDS alters the\nsampling process of a vanilla SGM at marginal extra computation cost and\nwithout model retraining. Theoretically, we prove that PDS preserves the output\ndistribution of the SGM, with no risk of inducing systematical bias to the\noriginal sampling process. We further theoretically reveal a relation between\nthe parameter of PDS and the sampling iterations, easing the parameter\nestimation under varying sampling iterations. Extensive experiments on various\nimage datasets with a variety of resolutions and diversity validate that our\nPDS consistently accelerates off-the-shelf SGMs whilst maintaining the\nsynthesis quality. In particular, PDS can accelerate by up to 28x on more\nchallenging high-resolution (1024x1024) image generation. Compared with the\nlatest generative models (e.g., CLD-SGM and Analytic-DDIM), PDS can achieve the\nbest sampling quality on CIFAR-10 at an FID score of 1.99. Our code is publicly\navailable to foster any further research https://github.com/fudan-zvg/PDS.\n","authors":["Hengyuan Ma","Xiatian Zhu","Jianfeng Feng","Li Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.06504v4.pdf","comment":"IJCV 2025"},{"id":"http://arxiv.org/abs/2502.17651v2","updated":"2025-02-28T07:28:24Z","published":"2025-02-24T21:01:39Z","title":"METAL: A Multi-Agent Framework for Chart Generation with Test-Time\n  Scaling","summary":"  Chart generation aims to generate code to produce charts satisfying the\ndesired visual properties, e.g., texts, layout, color, and type. It has great\npotential to empower the automatic professional report generation in financial\nanalysis, research presentation, education, and healthcare. In this work, we\nbuild a vision-language model (VLM) based multi-agent framework for effective\nautomatic chart generation. Generating high-quality charts requires both strong\nvisual design skills and precise coding capabilities that embed the desired\nvisual properties into code. Such a complex multi-modal reasoning process is\ndifficult for direct prompting of VLMs. To resolve these challenges, we propose\nMETAL, a multi-agent framework that decomposes the task of chart generation\ninto the iterative collaboration among specialized agents. METAL achieves 5.2%\nimprovement over the current best result in the chart generation task. The\nMETAL framework exhibits the phenomenon of test-time scaling: its performance\nincreases monotonically as the logarithmic computational budget grows from 512\nto 8192 tokens. In addition, we find that separating different modalities\nduring the critique process of METAL boosts the self-correction capability of\nVLMs in the multimodal context.\n","authors":["Bingxuan Li","Yiwei Wang","Jiuxiang Gu","Kai-Wei Chang","Nanyun Peng"],"pdf_url":"https://arxiv.org/pdf/2502.17651v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20784v1","updated":"2025-02-28T07:05:58Z","published":"2025-02-28T07:05:58Z","title":"Autoregressive Medical Image Segmentation via Next-Scale Mask Prediction","summary":"  While deep learning has significantly advanced medical image segmentation,\nmost existing methods still struggle with handling complex anatomical regions.\nCascaded or deep supervision-based approaches attempt to address this challenge\nthrough multi-scale feature learning but fail to establish sufficient\ninter-scale dependencies, as each scale relies solely on the features of the\nimmediate predecessor. To this end, we propose the AutoRegressive Segmentation\nframework via next-scale mask prediction, termed AR-Seg, which progressively\npredicts the next-scale mask by explicitly modeling dependencies across all\nprevious scales within a unified architecture. AR-Seg introduces three\ninnovations: (1) a multi-scale mask autoencoder that quantizes the mask into\nmulti-scale token maps to capture hierarchical anatomical structures, (2) a\nnext-scale autoregressive mechanism that progressively predicts next-scale\nmasks to enable sufficient inter-scale dependencies, and (3) a\nconsensus-aggregation strategy that combines multiple sampled results to\ngenerate a more accurate mask, further improving segmentation robustness.\nExtensive experimental results on two benchmark datasets with different\nmodalities demonstrate that AR-Seg outperforms state-of-the-art methods while\nexplicitly visualizing the intermediate coarse-to-fine segmentation process.\n","authors":["Tao Chen","Chenhui Wang","Zhihao Chen","Hongming Shan"],"pdf_url":"https://arxiv.org/pdf/2502.20784v1.pdf","comment":"10 pages, 4 figures"},{"id":"http://arxiv.org/abs/2410.06940v3","updated":"2025-02-28T07:00:17Z","published":"2024-10-09T14:34:53Z","title":"Representation Alignment for Generation: Training Diffusion Transformers\n  Is Easier Than You Think","summary":"  Recent studies have shown that the denoising process in (generative)\ndiffusion models can induce meaningful (discriminative) representations inside\nthe model, though the quality of these representations still lags behind those\nlearned through recent self-supervised learning methods. We argue that one main\nbottleneck in training large-scale diffusion models for generation lies in\neffectively learning these representations. Moreover, training can be made\neasier by incorporating high-quality external visual representations, rather\nthan relying solely on the diffusion models to learn them independently. We\nstudy this by introducing a straightforward regularization called\nREPresentation Alignment (REPA), which aligns the projections of noisy input\nhidden states in denoising networks with clean image representations obtained\nfrom external, pretrained visual encoders. The results are striking: our simple\nstrategy yields significant improvements in both training efficiency and\ngeneration quality when applied to popular diffusion and flow-based\ntransformers, such as DiTs and SiTs. For instance, our method can speed up SiT\ntraining by over 17.5$\\times$, matching the performance (without\nclassifier-free guidance) of a SiT-XL model trained for 7M steps in less than\n400K steps. In terms of final generation quality, our approach achieves\nstate-of-the-art results of FID=1.42 using classifier-free guidance with the\nguidance interval.\n","authors":["Sihyun Yu","Sangkyung Kwak","Huiwon Jang","Jongheon Jeong","Jonathan Huang","Jinwoo Shin","Saining Xie"],"pdf_url":"https://arxiv.org/pdf/2410.06940v3.pdf","comment":"ICLR 2025 (Oral). Project page: https://sihyun.me/REPA"},{"id":"http://arxiv.org/abs/2502.20780v1","updated":"2025-02-28T06:59:49Z","published":"2025-02-28T06:59:49Z","title":"MedHallTune: An Instruction-Tuning Benchmark for Mitigating Medical\n  Hallucination in Vision-Language Models","summary":"  The increasing use of vision-language models (VLMs) in healthcare\napplications presents great challenges related to hallucinations, in which the\nmodels may generate seemingly plausible results that are in fact incorrect.\nSuch hallucinations can jeopardize clinical decision making, potentially\nharming the diagnosis and treatments. In this work, we propose MedHallTune, a\nlarge-scale benchmark designed specifically to evaluate and mitigate\nhallucinations in medical VLMs. Comprising over 100,000 images and 1,000,000\ninstruction pairs, MedHallTune includes both hallucination and\nnon-hallucination samples, each with ground-truth annotations. We conduct a\ncomprehensive evaluation of current medical and general VLMs using MedHallTune,\nassessing their performance across key metrics, including clinical accuracy,\nrelevance, detail level, and risk level. The experimental results show that\nfine-tuning with MedHallTune successfully improves the ability of several\nexisting models to manage hallucinations and boost their zero-shot performance\non downstream visual-question-answering (VQA) tasks, making them more reliable\nfor practical medical applications. Our work contributes to the development of\nmore trustworthy VLMs. Codes and dataset will be available at\n\\href{https://github.com/russellyq/MedHallTune}{MedHallTune}.\n","authors":["Qiao Yan","Yuchen Yuan","Xiaowei Hu","Yihan Wang","Jiaqi Xu","Jinpeng Li","Chi-Wing Fu","Pheng-Ann Heng"],"pdf_url":"https://arxiv.org/pdf/2502.20780v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04041v5","updated":"2025-02-28T06:45:59Z","published":"2024-10-05T05:26:21Z","title":"EndoPerfect: High-Accuracy Monocular Depth Estimation and 3D\n  Reconstruction for Endoscopic Surgery via NeRF-Stereo Fusion","summary":"  In endoscopic sinus surgery (ESS), intraoperative CT (iCT) offers valuable\nintraoperative assessment but is constrained by slow deployment and radiation\nexposure, limiting its clinical utility. Endoscope-based monocular 3D\nreconstruction is a promising alternative; however, existing techniques often\nstruggle to achieve the submillimeter precision required for dense\nreconstruction. In this work, we propose an iterative online learning approach\nthat leverages Neural Radiance Fields (NeRF) as an intermediate representation,\nenabling monocular depth estimation and 3D reconstruction without relying on\nprior medical data. Our method attains a point-to-point accuracy below 0.5 mm,\nwith a demonstrated theoretical depth accuracy of 0.125 $\\pm$ 0.443 mm. We\nvalidate our approach across synthetic, phantom, and real endoscopic scenarios,\nconfirming its accuracy and reliability. These results underscore the potential\nof our pipeline as an iCT alternative, meeting the demanding submillimeter\naccuracy standards required in ESS.\n","authors":["Pengcheng Chen","Wenhao Li","Nicole Gunderson","Jeremy Ruthberg","Randall Bly","Zhenglong Sun","Waleed M. Abuzeid","Eric J. Seibel"],"pdf_url":"https://arxiv.org/pdf/2410.04041v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.03373v2","updated":"2025-02-28T06:44:31Z","published":"2023-07-07T03:51:21Z","title":"All in One: Exploring Unified Vision-Language Tracking with Multi-Modal\n  Alignment","summary":"  Current mainstream vision-language (VL) tracking framework consists of three\nparts, \\ie a visual feature extractor, a language feature extractor, and a\nfusion model. To pursue better performance, a natural modus operandi for VL\ntracking is employing customized and heavier unimodal encoders, and multi-modal\nfusion models. Albeit effective, existing VL trackers separate feature\nextraction and feature integration, resulting in extracted features that lack\nsemantic guidance and have limited target-aware capability in complex\nscenarios, \\eg similar distractors and extreme illumination. In this work,\ninspired by the recent success of exploring foundation models with unified\narchitecture for both natural language and computer vision tasks, we propose an\nAll-in-One framework, which learns joint feature extraction and interaction by\nadopting a unified transformer backbone. Specifically, we mix raw vision and\nlanguage signals to generate language-injected vision tokens, which we then\nconcatenate before feeding into the unified backbone architecture. This\napproach achieves feature integration in a unified backbone, removing the need\nfor carefully-designed fusion modules and resulting in a more effective and\nefficient VL tracking framework. To further improve the learning efficiency, we\nintroduce a multi-modal alignment module based on cross-modal and intra-modal\ncontrastive objectives, providing more reasonable representations for the\nunified All-in-One transformer backbone. Extensive experiments on five\nbenchmarks, \\ie OTB99-L, TNL2K, LaSOT, LaSOT$_{\\rm Ext}$ and WebUAV-3M,\ndemonstrate the superiority of the proposed tracker against existing\nstate-of-the-arts on VL tracking. Codes will be made publicly available at\nhttps://github.com/983632847/All-in-One.\n","authors":["Chunhui Zhang","Xin Sun","Yiqian Yang","Li Liu","Qiong Liu","Xi Zhou","Yanfeng Wang"],"pdf_url":"https://arxiv.org/pdf/2307.03373v2.pdf","comment":"In this version, we corrected some typos"},{"id":"http://arxiv.org/abs/2502.20769v1","updated":"2025-02-28T06:41:55Z","published":"2025-02-28T06:41:55Z","title":"Information Bottleneck-Guided Heterogeneous Graph Learning for\n  Interpretable Neurodevelopmental Disorder Diagnosis","summary":"  Developing interpretable models for diagnosing neurodevelopmental disorders\n(NDDs) is highly valuable yet challenging, primarily due to the complexity of\nencoding, decoding and integrating imaging and non-imaging data. Many existing\nmachine learning models struggle to provide comprehensive interpretability,\noften failing to extract meaningful biomarkers from imaging data, such as\nfunctional magnetic resonance imaging (fMRI), or lacking mechanisms to explain\nthe significance of non-imaging data. In this paper, we propose the\nInterpretable Information Bottleneck Heterogeneous Graph Neural Network\n(I2B-HGNN), a novel framework designed to learn from fine-grained local\npatterns to comprehensive global multi-modal interactions. This framework\ncomprises two key modules. The first module, the Information Bottleneck Graph\nTransformer (IBGraphFormer) for local patterns, integrates global modeling with\nbrain connectomic-constrained graph neural networks to identify biomarkers\nthrough information bottleneck-guided pooling. The second module, the\nInformation Bottleneck Heterogeneous Graph Attention Network (IB-HGAN) for\nglobal multi-modal interactions, facilitates interpretable multi-modal fusion\nof imaging and non-imaging data using heterogeneous graph neural networks. The\nresults of the experiments demonstrate that I2B-HGNN excels in diagnosing NDDs\nwith high accuracy, providing interpretable biomarker identification and\neffective analysis of non-imaging data.\n","authors":["Yueyang Li","Lei Chen","Wenhao Dong","Shengyu Gong","Zijian Kang","Boyang Wei","Weiming Zeng","Hongjie Yan","Lingbin Bian","Wai Ting Siok","Nizhuan Wang"],"pdf_url":"https://arxiv.org/pdf/2502.20769v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06525v3","updated":"2025-02-28T06:40:38Z","published":"2024-11-10T16:59:39Z","title":"I2VControl-Camera: Precise Video Camera Control with Adjustable Motion\n  Strength","summary":"  Video generation technologies are developing rapidly and have broad potential\napplications. Among these technologies, camera control is crucial for\ngenerating professional-quality videos that accurately meet user expectations.\nHowever, existing camera control methods still suffer from several limitations,\nincluding control precision and the neglect of the control for subject motion\ndynamics. In this work, we propose I2VControl-Camera, a novel camera control\nmethod that significantly enhances controllability while providing\nadjustability over the strength of subject motion. To improve control\nprecision, we employ point trajectory in the camera coordinate system instead\nof only extrinsic matrix information as our control signal. To accurately\ncontrol and adjust the strength of subject motion, we explicitly model the\nhigher-order components of the video trajectory expansion, not merely the\nlinear terms, and design an operator that effectively represents the motion\nstrength. We use an adapter architecture that is independent of the base model\nstructure. Experiments on static and dynamic scenes show that our framework\noutperformances previous methods both quantitatively and qualitatively. The\nproject page is: https://wanquanf.github.io/I2VControlCamera .\n","authors":["Wanquan Feng","Jiawei Liu","Pengqi Tu","Tianhao Qi","Mingzhen Sun","Tianxiang Ma","Songtao Zhao","Siyu Zhou","Qian He"],"pdf_url":"https://arxiv.org/pdf/2411.06525v3.pdf","comment":"Accepted to ICLR 2025, Project page:\n  https://wanquanf.github.io/I2VControlCamera"},{"id":"http://arxiv.org/abs/2502.20762v1","updated":"2025-02-28T06:32:23Z","published":"2025-02-28T06:32:23Z","title":"Towards Practical Real-Time Neural Video Compression","summary":"  We introduce a practical real-time neural video codec (NVC) designed to\ndeliver high compression ratio, low latency and broad versatility. In practice,\nthe coding speed of NVCs depends on 1) computational costs, and 2)\nnon-computational operational costs, such as memory I/O and the number of\nfunction calls. While most efficient NVCs prioritize reducing computational\ncost, we identify operational cost as the primary bottleneck to achieving\nhigher coding speed. Leveraging this insight, we introduce a set of\nefficiency-driven design improvements focused on minimizing operational costs.\nSpecifically, we employ implicit temporal modeling to eliminate complex\nexplicit motion modules, and use single low-resolution latent representations\nrather than progressive downsampling. These innovations significantly\naccelerate NVC without sacrificing compression quality. Additionally, we\nimplement model integerization for consistent cross-device coding and a\nmodule-bank-based rate control scheme to improve practical adaptability.\nExperiments show our proposed DCVC-RT achieves an impressive average\nencoding/decoding speed at 125.2/112.8 fps (frames per second) for 1080p video,\nwhile saving an average of 21% in bitrate compared to H.266/VTM. The code is\navailable at https://github.com/microsoft/DCVC.\n","authors":["Zhaoyang Jia","Bin Li","Jiahao Li","Wenxuan Xie","Linfeng Qi","Houqiang Li","Yan Lu"],"pdf_url":"https://arxiv.org/pdf/2502.20762v1.pdf","comment":"CVPR 2025. The code is available at https://github.com/microsoft/DCVC"},{"id":"http://arxiv.org/abs/2502.18485v2","updated":"2025-02-28T06:32:05Z","published":"2025-02-10T10:00:06Z","title":"Deciphering Functions of Neurons in Vision-Language Models","summary":"  The burgeoning growth of open-sourced vision-language models (VLMs) has\ncatalyzed a plethora of applications across diverse domains. Ensuring the\ntransparency and interpretability of these models is critical for fostering\ntrustworthy and responsible AI systems. In this study, our objective is to\ndelve into the internals of VLMs to interpret the functions of individual\nneurons. We observe the activations of neurons with respects to the input\nvisual tokens and text tokens, and reveal some interesting findings.\nParticularly, we found that there are neurons responsible for only visual or\ntext information, or both, respectively, which we refer to them as visual\nneurons, text neurons, and multi-modal neurons, respectively. We build a\nframework that automates the explanation of neurons with the assistant of\nGPT-4o. Meanwhile, for visual neurons, we propose an activation simulator to\nassess the reliability of the explanations for visual neurons. System\nstatistical analyses on top of one representative VLM of LLaVA, uncover the\nbehaviors/characteristics of different categories of neurons.\n","authors":["Jiaqi Xu","Cuiling Lan","Xuejin Chen","Yan Lu"],"pdf_url":"https://arxiv.org/pdf/2502.18485v2.pdf","comment":"22 pages, 23 figures"},{"id":"http://arxiv.org/abs/2502.20760v1","updated":"2025-02-28T06:29:39Z","published":"2025-02-28T06:29:39Z","title":"VRM: Knowledge Distillation via Virtual Relation Matching","summary":"  Knowledge distillation (KD) aims to transfer the knowledge of a more capable\nyet cumbersome teacher model to a lightweight student model. In recent years,\nrelation-based KD methods have fallen behind, as their instance-matching\ncounterparts dominate in performance. In this paper, we revive relational KD by\nidentifying and tackling several key issues in relation-based methods,\nincluding their susceptibility to overfitting and spurious responses.\nSpecifically, we transfer novelly constructed affinity graphs that compactly\nencapsulate a wealth of beneficial inter-sample, inter-class, and inter-view\ncorrelations by exploiting virtual views and relations as a new kind of\nknowledge. As a result, the student has access to richer guidance signals and\nstronger regularisation throughout the distillation process. To further\nmitigate the adverse impact of spurious responses, we prune the affinity graphs\nby dynamically detaching redundant and unreliable edges. Extensive experiments\non CIFAR-100 and ImageNet datasets demonstrate the superior performance of the\nproposed virtual relation matching (VRM) method over a range of models,\narchitectures, and set-ups. For instance, VRM for the first time hits 74.0%\naccuracy for ResNet50-to-MobileNetV2 distillation on ImageNet, and improves\nDeiT-T by 14.44% on CIFAR-100 with a ResNet56 teacher. Thorough analyses are\nalso conducted to gauge the soundness, properties, and complexity of our\ndesigns. Code and models will be released.\n","authors":["Weijia Zhang","Fei Xie","Weidong Cai","Chao Ma"],"pdf_url":"https://arxiv.org/pdf/2502.20760v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.05179v2","updated":"2025-02-28T06:22:09Z","published":"2025-02-07T18:59:59Z","title":"FlashVideo: Flowing Fidelity to Detail for Efficient High-Resolution\n  Video Generation","summary":"  DiT diffusion models have achieved great success in text-to-video generation,\nleveraging their scalability in model capacity and data scale. High content and\nmotion fidelity aligned with text prompts, however, often require large model\nparameters and a substantial number of function evaluations (NFEs). Realistic\nand visually appealing details are typically reflected in high resolution\noutputs, further amplifying computational demands especially for single stage\nDiT models. To address these challenges, we propose a novel two stage\nframework, FlashVideo, which strategically allocates model capacity and NFEs\nacross stages to balance generation fidelity and quality. In the first stage,\nprompt fidelity is prioritized through a low resolution generation process\nutilizing large parameters and sufficient NFEs to enhance computational\nefficiency. The second stage establishes flow matching between low and high\nresolutions, effectively generating fine details with minimal NFEs.\nQuantitative and visual results demonstrate that FlashVideo achieves\nstate-of-the-art high resolution video generation with superior computational\nefficiency. Additionally, the two-stage design enables users to preview the\ninitial output and accordingly adjust the prompt before committing to\nfull-resolution generation, thereby significantly reducing computational costs\nand wait times as well as enhancing commercial viability.\n","authors":["Shilong Zhang","Wenbo Li","Shoufa Chen","Chongjian Ge","Peize Sun","Yida Zhang","Yi Jiang","Zehuan Yuan","Binyue Peng","Ping Luo"],"pdf_url":"https://arxiv.org/pdf/2502.05179v2.pdf","comment":"Model and Weight: https://github.com/FoundationVision/FlashVideo"},{"id":"http://arxiv.org/abs/2412.13299v2","updated":"2025-02-28T06:19:59Z","published":"2024-12-17T19:59:08Z","title":"In-context learning for medical image segmentation","summary":"  Annotation of medical images, such as MRI and CT scans, is crucial for\nevaluating treatment efficacy and planning radiotherapy. However, the extensive\nworkload of medical professionals limits their ability to annotate large image\ndatasets, posing a bottleneck for AI applications in medical imaging. To\naddress this, we propose In-context Cascade Segmentation (ICS), a novel method\nthat minimizes annotation requirements while achieving high segmentation\naccuracy for sequential medical images. ICS builds on the UniverSeg framework,\nwhich performs few-shot segmentation using support images without additional\ntraining. By iteratively adding the inference results of each slice to the\nsupport set, ICS propagates information forward and backward through the\nsequence, ensuring inter-slice consistency. We evaluate the proposed method on\nthe HVSMR dataset, which includes segmentation tasks for eight cardiac regions.\nExperimental results demonstrate that ICS significantly improves segmentation\nperformance in complex anatomical regions, particularly in maintaining boundary\nconsistency across slices, compared to baseline methods. The study also\nhighlights the impact of the number and position of initial support slices on\nsegmentation accuracy. ICS offers a promising solution for reducing annotation\nburdens while delivering robust segmentation results, paving the way for its\nbroader adoption in clinical and research applications.\n","authors":["Eichi Takaya","Shinnosuke Yamamoto"],"pdf_url":"https://arxiv.org/pdf/2412.13299v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12662v2","updated":"2025-02-28T06:17:41Z","published":"2024-10-16T15:20:08Z","title":"Cross-Modal Safety Mechanism Transfer in Large Vision-Language Models","summary":"  Vision-language alignment in Large Vision-Language Models (LVLMs)\nsuccessfully enables LLMs to understand visual input. However, we find that\nexisting vision-language alignment methods fail to transfer the existing safety\nmechanism for text in LLMs to vision, which leads to vulnerabilities in toxic\nimage. To explore the cause of this problem, we give the insightful explanation\nof where and how the safety mechanism of LVLMs operates and conduct comparative\nanalysis between text and vision. We find that the hidden states at the\nspecific transformer layers play a crucial role in the successful activation of\nsafety mechanism, while the vision-language alignment at hidden states level in\ncurrent methods is insufficient. This results in a semantic shift for input\nimages compared to text in hidden states, therefore misleads the safety\nmechanism. To address this, we propose a novel Text-Guided vision-language\nAlignment method (TGA) for LVLMs. TGA retrieves the texts related to input\nvision and uses them to guide the projection of vision into the hidden states\nspace in LLMs. Experiments show that TGA not only successfully transfers the\nsafety mechanism for text in basic LLMs to vision in vision-language alignment\nfor LVLMs without any safety fine-tuning on the visual modality but also\nmaintains the general performance on various vision tasks (Safe and Good).\n","authors":["Shicheng Xu","Liang Pang","Yunchang Zhu","Huawei Shen","Xueqi Cheng"],"pdf_url":"https://arxiv.org/pdf/2410.12662v2.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2502.06029v2","updated":"2025-02-28T06:07:51Z","published":"2025-02-09T21:05:11Z","title":"DiTASK: Multi-Task Fine-Tuning with Diffeomorphic Transformations","summary":"  Pre-trained Vision Transformers now serve as powerful tools for computer\nvision. Yet, efficiently adapting them for multiple tasks remains a challenge\nthat arises from the need to modify the rich hidden representations encoded by\nthe learned weight matrices, without inducing interference between tasks.\nCurrent parameter-efficient methods like LoRA, which apply low-rank updates,\nforce tasks to compete within constrained subspaces, ultimately degrading\nperformance. We introduce DiTASK a novel Diffeomorphic Multi-Task Fine-Tuning\napproach that maintains pre-trained representations by preserving weight matrix\nsingular vectors, while enabling task-specific adaptations through neural\ndiffeomorphic transformations of the singular values. By following this\napproach, DiTASK enables both shared and task-specific feature modulations with\nminimal added parameters. Our theoretical analysis shows that DITASK achieves\nfull-rank updates during optimization, preserving the geometric structure of\npre-trained features, and establishing a new paradigm for efficient multi-task\nlearning (MTL). Our experiments on PASCAL MTL and NYUD show that DiTASK\nachieves state-of-the-art performance across four dense prediction tasks, using\n75% fewer parameters than existing methods. Our code is available\n[here](https://github.com/ipsitmantri/DiTASK).\n","authors":["Krishna Sri Ipsit Mantri","Carola-Bibiane Schönlieb","Bruno Ribeiro","Chaim Baskin","Moshe Eliasof"],"pdf_url":"https://arxiv.org/pdf/2502.06029v2.pdf","comment":"CVPR 2025, 14 pages"},{"id":"http://arxiv.org/abs/2502.11037v2","updated":"2025-02-28T06:04:20Z","published":"2025-02-16T08:36:43Z","title":"Deep Incomplete Multi-view Learning via Cyclic Permutation of VAEs","summary":"  Multi-View Representation Learning (MVRL) aims to derive a unified\nrepresentation from multi-view data by leveraging shared and complementary\ninformation across views. However, when views are irregularly missing, the\nincomplete data can lead to representations that lack sufficiency and\nconsistency. To address this, we propose Multi-View Permutation of Variational\nAuto-Encoders (MVP), which excavates invariant relationships between views in\nincomplete data. MVP establishes inter-view correspondences in the latent space\nof Variational Auto-Encoders, enabling the inference of missing views and the\naggregation of more sufficient information. To derive a valid Evidence Lower\nBound (ELBO) for learning, we apply permutations to randomly reorder variables\nfor cross-view generation and then partition them by views to maintain\ninvariant meanings under permutations. Additionally, we enhance consistency by\nintroducing an informational prior with cyclic permutations of posteriors,\nwhich turns the regularization term into a similarity measure across\ndistributions. We demonstrate the effectiveness of our approach on seven\ndiverse datasets with varying missing ratios, achieving superior performance in\nmulti-view clustering and generation tasks.\n","authors":["Xin Gao","Jian Pu"],"pdf_url":"https://arxiv.org/pdf/2502.11037v2.pdf","comment":"10 pages, 4 figures, ICLR 2025"},{"id":"http://arxiv.org/abs/2502.14377v3","updated":"2025-02-28T06:00:57Z","published":"2025-02-20T09:10:05Z","title":"RelaCtrl: Relevance-Guided Efficient Control for Diffusion Transformers","summary":"  The Diffusion Transformer plays a pivotal role in advancing text-to-image and\ntext-to-video generation, owing primarily to its inherent scalability. However,\nexisting controlled diffusion transformer methods incur significant parameter\nand computational overheads and suffer from inefficient resource allocation due\nto their failure to account for the varying relevance of control information\nacross different transformer layers. To address this, we propose the\nRelevance-Guided Efficient Controllable Generation framework, RelaCtrl,\nenabling efficient and resource-optimized integration of control signals into\nthe Diffusion Transformer. First, we evaluate the relevance of each layer in\nthe Diffusion Transformer to the control information by assessing the\n\"ControlNet Relevance Score\"-i.e., the impact of skipping each control layer on\nboth the quality of generation and the control effectiveness during inference.\nBased on the strength of the relevance, we then tailor the positioning,\nparameter scale, and modeling capacity of the control layers to reduce\nunnecessary parameters and redundant computations. Additionally, to further\nimprove efficiency, we replace the self-attention and FFN in the commonly used\ncopy block with the carefully designed Two-Dimensional Shuffle Mixer (TDSM),\nenabling efficient implementation of both the token mixer and channel mixer.\nBoth qualitative and quantitative experimental results demonstrate that our\napproach achieves superior performance with only 15% of the parameters and\ncomputational complexity compared to PixArt-delta.\n","authors":["Ke Cao","Jing Wang","Ao Ma","Jiasong Feng","Zhanjie Zhang","Xuanhua He","Shanyuan Liu","Bo Cheng","Dawei Leng","Yuhui Yin","Jie Zhang"],"pdf_url":"https://arxiv.org/pdf/2502.14377v3.pdf","comment":"Homepage: https://360cvgroup.github.io/RelaCtrl/ Github:\n  https://github.com/360CVGroup/RelaCtrl"},{"id":"http://arxiv.org/abs/2411.00915v2","updated":"2025-02-28T05:57:42Z","published":"2024-11-01T13:43:33Z","title":"Empower Vision Applications with LoRA LMM","summary":"  Large Multimodal Models (LMMs) have shown significant progress in various\ncomplex vision tasks with the solid linguistic and reasoning capacity inherited\nfrom large language models (LMMs). Low-rank adaptation (LoRA) offers a\npromising method to integrate external knowledge into LMMs, compensating for\ntheir limitations on domain-specific tasks. However, the existing LoRA model\nserving is excessively computationally expensive and causes extremely high\nlatency. In this paper, we present an end-to-end solution that empowers diverse\nvision tasks and enriches vision applications with LoRA LMMs. Our system,\nVaLoRA, enables accurate and efficient vision tasks by 1) an accuracy-aware\nLoRA adapter generation approach that generates LoRA adapters rich in\ndomain-specific knowledge to meet application-specific accuracy requirements,\n2) an adaptive-tiling LoRA adapters batching operator that efficiently computes\nconcurrent heterogeneous LoRA adapters, and 3) a flexible LoRA adapter\norchestration mechanism that manages application requests and LoRA adapters to\nachieve the lowest average response latency. We prototype VaLoRA on five\npopular vision tasks on three LMMs. Experiment results reveal that VaLoRA\nimproves 24-62% of the accuracy compared to the original LMMs and reduces\n20-89% of the latency compared to the state-of-the-art LoRA model serving\nsystems.\n","authors":["Liang Mi","Weijun Wang","Wenming Tu","Qingfeng He","Rui Kong","Xinyu Fang","Yazhu Dong","Yikang Zhang","Yunchun Li","Meng Li","Haipeng Dai","Guihai Chen","Yunxin Liu"],"pdf_url":"https://arxiv.org/pdf/2411.00915v2.pdf","comment":"EuroSys'2025"},{"id":"http://arxiv.org/abs/2502.20749v1","updated":"2025-02-28T05:54:41Z","published":"2025-02-28T05:54:41Z","title":"SemiSAM+: Rethinking Semi-Supervised Medical Image Segmentation in the\n  Era of Foundation Models","summary":"  Deep learning-based medical image segmentation typically requires large\namount of labeled data for training, making it less applicable in clinical\nsettings due to high annotation cost. Semi-supervised learning (SSL) has\nemerged as an appealing strategy due to its less dependence on acquiring\nabundant annotations from experts compared to fully supervised methods. Beyond\nexisting model-centric advancements of SSL by designing novel regularization\nstrategies, we anticipate a paradigmatic shift due to the emergence of\npromptable segmentation foundation models with universal segmentation\ncapabilities using positional prompts represented by Segment Anything Model\n(SAM). In this paper, we present SemiSAM+, a foundation model-driven SSL\nframework to efficiently learn from limited labeled data for medical image\nsegmentation. SemiSAM+ consists of one or multiple promptable foundation models\nas generalist models, and a trainable task-specific segmentation model as\nspecialist model. For a given new segmentation task, the training is based on\nthe specialist-generalist collaborative learning procedure, where the trainable\nspecialist model delivers positional prompts to interact with the frozen\ngeneralist models to acquire pseudo-labels, and then the generalist model\noutput provides the specialist model with informative and efficient supervision\nwhich benefits the automatic segmentation and prompt generation in turn.\nExtensive experiments on two public datasets and one in-house clinical dataset\ndemonstrate that SemiSAM+ achieves significant performance improvement,\nespecially under extremely limited annotation scenarios, and shows strong\nefficiency as a plug-and-play strategy that can be easily adapted to different\nspecialist and generalist models.\n","authors":["Yichi Zhang","Bohao Lv","Le Xue","Wenbo Zhang","Yuchen Liu","Yu Fu","Yuan Cheng","Yuan Qi"],"pdf_url":"https://arxiv.org/pdf/2502.20749v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20742v1","updated":"2025-02-28T05:47:34Z","published":"2025-02-28T05:47:34Z","title":"Structured Preference Optimization for Vision-Language Long-Horizon Task\n  Planning","summary":"  Existing methods for vision-language task planning excel in short-horizon\ntasks but often fall short in complex, long-horizon planning within dynamic\nenvironments. These challenges primarily arise from the difficulty of\neffectively training models to produce high-quality reasoning processes for\nlong-horizon tasks. To address this, we propose Structured Preference\nOptimization (SPO), which aims to enhance reasoning and action selection in\nlong-horizon task planning through structured preference evaluation and\noptimized training strategies. Specifically, SPO introduces: 1)\nPreference-Based Scoring and Optimization, which systematically evaluates\nreasoning chains based on task relevance, visual grounding, and historical\nconsistency; and 2) Curriculum-Guided Training, where the model progressively\nadapts from simple to complex tasks, improving its generalization ability in\nlong-horizon scenarios and enhancing reasoning robustness. To advance research\nin vision-language long-horizon task planning, we introduce ExtendaBench, a\ncomprehensive benchmark covering 1,509 tasks across VirtualHome and Habitat\n2.0, categorized into ultra-short, short, medium, and long tasks. Experimental\nresults demonstrate that SPO significantly improves reasoning quality and final\ndecision accuracy, outperforming prior methods on long-horizon tasks and\nunderscoring the effectiveness of preference-driven optimization in\nvision-language task planning. Specifically, SPO achieves a +5.98% GCR and\n+4.68% SR improvement in VirtualHome and a +3.30% GCR and +2.11% SR improvement\nin Habitat over the best-performing baselines.\n","authors":["Xiwen Liang","Min Lin","Weiqi Ruan","Rongtao Xu","Yuecheng Liu","Jiaqi Chen","Bingqian Lin","Yuzheng Zhuang","Xiaodan Liang"],"pdf_url":"https://arxiv.org/pdf/2502.20742v1.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2502.20732v1","updated":"2025-02-28T05:30:29Z","published":"2025-02-28T05:30:29Z","title":"CADDreamer: CAD object Generation from Single-view Images","summary":"  Diffusion-based 3D generation has made remarkable progress in recent years.\nHowever, existing 3D generative models often produce overly dense and\nunstructured meshes, which stand in stark contrast to the compact, structured,\nand sharply-edged Computer-Aided Design (CAD) models crafted by human\ndesigners. To address this gap, we introduce CADDreamer, a novel approach for\ngenerating boundary representations (B-rep) of CAD objects from a single image.\nCADDreamer employs a primitive-aware multi-view diffusion model that captures\nboth local geometric details and high-level structural semantics during the\ngeneration process. By encoding primitive semantics into the color domain, the\nmethod leverages the strong priors of pre-trained diffusion models to align\nwith well-defined primitives. This enables the inference of multi-view normal\nmaps and semantic maps from a single image, facilitating the reconstruction of\na mesh with primitive labels. Furthermore, we introduce geometric optimization\ntechniques and topology-preserving extraction methods to mitigate noise and\ndistortion in the generated primitives. These enhancements result in a complete\nand seamless B-rep of the CAD model. Experimental results demonstrate that our\nmethod effectively recovers high-quality CAD objects from single-view images.\nCompared to existing 3D generation techniques, the B-rep models produced by\nCADDreamer are compact in representation, clear in structure, sharp in edges,\nand watertight in topology.\n","authors":["Yuan Li","Cheng Lin","Yuan Liu","Xiaoxiao Long","Chenxu Zhang","Ningna Wang","Xin Li","Wenping Wang","Xiaohu Guo"],"pdf_url":"https://arxiv.org/pdf/2502.20732v1.pdf","comment":"Accepted to CVPR 2025"},{"id":"http://arxiv.org/abs/2409.06214v2","updated":"2025-02-28T05:28:05Z","published":"2024-09-10T04:45:25Z","title":"Towards Generalizable Scene Change Detection","summary":"  While current state-of-the-art Scene Change Detection (SCD) approaches\nachieve impressive results in well-trained research data, they become\nunreliable under unseen environments and different temporal conditions;\nin-domain performance drops from 77.6\\% to 8.0\\% in a previously unseen\nenvironment and to 4.6\\% under a different temporal condition -- calling for\ngeneralizable SCD and benchmark. In this work, we propose the Generalizable\nScene Change Detection Framework (GeSCF), which addresses unseen domain\nperformance and temporal consistency -- to meet the growing demand for anything\nSCD. Our method leverages the pre-trained Segment Anything Model (SAM) in a\nzero-shot manner. For this, we design Initial Pseudo-mask Generation and\nGeometric-Semantic Mask Matching -- seamlessly turning user-guided prompt and\nsingle-image based segmentation into scene change detection for a pair of\ninputs without guidance. Furthermore, we define the Generalizable Scene Change\nDetection (GeSCD) benchmark along with novel metrics and an evaluation protocol\nto facilitate SCD research in generalizability. In the process, we introduce\nthe ChangeVPR dataset, a collection of challenging image pairs with diverse\nenvironmental scenarios -- including urban, suburban, and rural settings.\nExtensive experiments across various datasets demonstrate that GeSCF achieves\nan average performance gain of 19.2\\% on existing SCD datasets and 30.0\\% on\nthe ChangeVPR dataset, nearly doubling the prior art performance. We believe\nour work can lay a solid foundation for robust and generalizable SCD research.\n","authors":["Jaewoo Kim","Uehwan Kim"],"pdf_url":"https://arxiv.org/pdf/2409.06214v2.pdf","comment":"Manuscript. Accepted to CVPR 2025,"},{"id":"http://arxiv.org/abs/2502.20715v1","updated":"2025-02-28T04:58:41Z","published":"2025-02-28T04:58:41Z","title":"Glioma Classification using Multi-sequence MRI and Novel Wavelets-based\n  Feature Fusion","summary":"  Glioma, a prevalent and heterogeneous tumor originating from the glial cells,\ncan be differentiated as Low Grade Glioma (LGG) and High Grade Glioma (HGG)\naccording to World Health Organization's norms. Classifying gliomas is\nessential for treatment protocols that depend extensively on subtype\ndifferentiation. For non-invasive glioma evaluation, Magnetic Resonance Imaging\n(MRI) offers vital information about the morphology and location of the the\ntumor. The versatility of MRI allows the classification of gliomas as LGG and\nHGG based on their texture, perfusion, and diffusion characteristics, and\nfurther for improving the diagnosis and providing tailored treatments.\nNevertheless, the precise classification is complicated by tumor heterogeneity\nand overlapping radiomic characteristics. Thus, in this work, wavelet based\nnovel fusion algorithm were implemented on multi-sequence T1, T1-contrast\nenhanced (T1CE), T2 and Fluid Attenuated Inversion Recovery (FLAIR) MRI images\nto compute the radiomics features. Furthermore, principal component analysis is\napplied to reduce the feature space and XGBoost, Support Vector Machine, and\nRandom Forest Classifier are used for the classification. The result shows that\nthe SVM algorithm performs comparatively well with an accuracy of 90.17%,\nprecision of 91.04% and recall of 96.19%, F1-score of 93.53%, and AUC of 94.60%\nwhen implemented on BraTS 2018 dataset and with an accuracy of 91.34%,\nprecision of 93.05% and recall of 96.13%, F1-score of 94.53%, and AUC of 93.71%\nfor BraTS 2018 dataset. Thus, the proposed algorithm could be potentially\nimplemented for the computer-aided diagnosis and grading system for gliomas.\n","authors":["Kiranmayee Janardhan","Christy Bobby Thomas"],"pdf_url":"https://arxiv.org/pdf/2502.20715v1.pdf","comment":"18 pages, 11 figures, 6 tables, journal paper"},{"id":"http://arxiv.org/abs/2502.20698v1","updated":"2025-02-28T04:15:36Z","published":"2025-02-28T04:15:36Z","title":"Towards General Visual-Linguistic Face Forgery Detection(V2)","summary":"  Face manipulation techniques have achieved significant advances, presenting\nserious challenges to security and social trust. Recent works demonstrate that\nleveraging multimodal models can enhance the generalization and\ninterpretability of face forgery detection. However, existing annotation\napproaches, whether through human labeling or direct Multimodal Large Language\nModel (MLLM) generation, often suffer from hallucination issues, leading to\ninaccurate text descriptions, especially for high-quality forgeries. To address\nthis, we propose Face Forgery Text Generator (FFTG), a novel annotation\npipeline that generates accurate text descriptions by leveraging forgery masks\nfor initial region and type identification, followed by a comprehensive\nprompting strategy to guide MLLMs in reducing hallucination. We validate our\napproach through fine-tuning both CLIP with a three-branch training framework\ncombining unimodal and multimodal objectives, and MLLMs with our structured\nannotations. Experimental results demonstrate that our method not only achieves\nmore accurate annotations with higher region identification accuracy, but also\nleads to improvements in model performance across various forgery detection\nbenchmarks. Our Codes are available in https://github.com/skJack/VLFFD.git.\n","authors":["Ke Sun","Shen Chen","Taiping Yao","Ziyin Zhou","Jiayi Ji","Xiaoshuai Sun","Chia-Wen Lin","Rongrong Ji"],"pdf_url":"https://arxiv.org/pdf/2502.20698v1.pdf","comment":"8 pages, 5 figures, Accpet by CVPR2025"},{"id":"http://arxiv.org/abs/2502.20694v1","updated":"2025-02-28T03:58:23Z","published":"2025-02-28T03:58:23Z","title":"WorldModelBench: Judging Video Generation Models As World Models","summary":"  Video generation models have rapidly progressed, positioning themselves as\nvideo world models capable of supporting decision-making applications like\nrobotics and autonomous driving. However, current benchmarks fail to rigorously\nevaluate these claims, focusing only on general video quality, ignoring\nimportant factors to world models such as physics adherence. To bridge this\ngap, we propose WorldModelBench, a benchmark designed to evaluate the world\nmodeling capabilities of video generation models in application-driven domains.\nWorldModelBench offers two key advantages: (1) Against to nuanced world\nmodeling violations: By incorporating instruction-following and\nphysics-adherence dimensions, WorldModelBench detects subtle violations, such\nas irregular changes in object size that breach the mass conservation law -\nissues overlooked by prior benchmarks. (2) Aligned with large-scale human\npreferences: We crowd-source 67K human labels to accurately measure 14 frontier\nmodels. Using our high-quality human labels, we further fine-tune an accurate\njudger to automate the evaluation procedure, achieving 8.6% higher average\naccuracy in predicting world modeling violations than GPT-4o with 2B\nparameters. In addition, we demonstrate that training to align human\nannotations by maximizing the rewards from the judger noticeably improve the\nworld modeling capability. The website is available at\nhttps://worldmodelbench-team.github.io.\n","authors":["Dacheng Li","Yunhao Fang","Yukang Chen","Shuo Yang","Shiyi Cao","Justin Wong","Michael Luo","Xiaolong Wang","Hongxu Yin","Joseph E. Gonzalez","Ion Stoica","Song Han","Yao Lu"],"pdf_url":"https://arxiv.org/pdf/2502.20694v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20685v1","updated":"2025-02-28T03:37:01Z","published":"2025-02-28T03:37:01Z","title":"EDM: Equirectangular Projection-Oriented Dense Kernelized Feature\n  Matching","summary":"  We introduce the first learning-based dense matching algorithm, termed\nEquirectangular Projection-Oriented Dense Kernelized Feature Matching (EDM),\nspecifically designed for omnidirectional images. Equirectangular projection\n(ERP) images, with their large fields of view, are particularly suited for\ndense matching techniques that aim to establish comprehensive correspondences\nacross images. However, ERP images are subject to significant distortions,\nwhich we address by leveraging the spherical camera model and geodesic flow\nrefinement in the dense matching method. To further mitigate these distortions,\nwe propose spherical positional embeddings based on 3D Cartesian coordinates of\nthe feature grid. Additionally, our method incorporates bidirectional\ntransformations between spherical and Cartesian coordinate systems during\nrefinement, utilizing a unit sphere to improve matching performance. We\ndemonstrate that our proposed method achieves notable performance enhancements,\nwith improvements of +26.72 and +42.62 in AUC@5{\\deg} on the Matterport3D and\nStanford2D3D datasets.\n","authors":["Dongki Jung","Jaehoon Choi","Yonghan Lee","Somi Jeong","Taejae Lee","Dinesh Manocha","Suyong Yeon"],"pdf_url":"https://arxiv.org/pdf/2502.20685v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.11451v4","updated":"2025-02-28T03:36:50Z","published":"2024-06-17T12:03:32Z","title":"CoMT: Chain-of-Medical-Thought Reduces Hallucination in Medical Report\n  Generation","summary":"  Automatic medical report generation (MRG), which possesses significant\nresearch value as it can aid radiologists in clinical diagnosis and report\ncomposition, has garnered increasing attention. Despite recent progress,\ngenerating accurate reports remains arduous due to the requirement for precise\nclinical comprehension and disease diagnosis inference. Furthermore, owing to\nthe limited accessibility of medical data and the imbalanced distribution of\ndiseases, the underrepresentation of rare diseases in training data makes\nlarge-scale medical visual language models (LVLMs) prone to hallucinations,\nsuch as omissions or fabrications, severely undermining diagnostic performance\nand further intensifying the challenges for MRG in practice. In this study, to\neffectively mitigate hallucinations in medical report generation, we propose a\nchain-of-medical-thought approach (CoMT), which intends to imitate the\ncognitive process of human doctors by decomposing diagnostic procedures. The\nradiological features with different importance are structured into\nfine-grained medical thought chains to enhance the inferential ability during\ndiagnosis, thereby alleviating hallucination problems and enhancing the\ndiagnostic accuracy of MRG. The code and dataset have been released at\nhttps://github.com/FRENKIE-CHIANG/CoMT.\n","authors":["Yue Jiang","Jiawei Chen","Dingkang Yang","Mingcheng Li","Shunli Wang","Tong Wu","Ke Li","Lihua Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.11451v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.16779v2","updated":"2025-02-28T03:33:01Z","published":"2025-02-24T02:14:19Z","title":"Unposed Sparse Views Room Layout Reconstruction in the Age of Pretrain\n  Model","summary":"  Room layout estimation from multiple-perspective images is poorly\ninvestigated due to the complexities that emerge from multi-view geometry,\nwhich requires muti-step solutions such as camera intrinsic and extrinsic\nestimation, image matching, and triangulation. However, in 3D reconstruction,\nthe advancement of recent 3D foundation models such as DUSt3R has shifted the\nparadigm from the traditional multi-step structure-from-motion process to an\nend-to-end single-step approach. To this end, we introduce Plane-DUSt3R, a\nnovel method for multi-view room layout estimation leveraging the 3D foundation\nmodel DUSt3R. Plane-DUSt3R incorporates the DUSt3R framework and fine-tunes on\na room layout dataset (Structure3D) with a modified objective to estimate\nstructural planes. By generating uniform and parsimonious results, Plane-DUSt3R\nenables room layout estimation with only a single post-processing step and 2D\ndetection results. Unlike previous methods that rely on single-perspective or\npanorama image, Plane-DUSt3R extends the setting to handle multiple-perspective\nimages. Moreover, it offers a streamlined, end-to-end solution that simplifies\nthe process and reduces error accumulation. Experimental results demonstrate\nthat Plane-DUSt3R not only outperforms state-of-the-art methods on the\nsynthetic dataset but also proves robust and effective on in the wild data with\ndifferent image styles such as cartoon.Our code is available at:\nhttps://github.com/justacar/Plane-DUSt3R\n","authors":["Yaxuan Huang","Xili Dai","Jianan Wang","Xianbiao Qi","Yixing Yuan","Xiangyu Yue"],"pdf_url":"https://arxiv.org/pdf/2502.16779v2.pdf","comment":"Accepted by ICLR 2025. Github\n  page:https://github.com/justacar/Plane-DUSt3R"},{"id":"http://arxiv.org/abs/2502.20679v1","updated":"2025-02-28T03:14:30Z","published":"2025-02-28T03:14:30Z","title":"Diffusion Restoration Adapter for Real-World Image Restoration","summary":"  Diffusion models have demonstrated their powerful image generation\ncapabilities, effectively fitting highly complex image distributions. These\nmodels can serve as strong priors for image restoration. Existing methods often\nutilize techniques like ControlNet to sample high quality images with low\nquality images from these priors. However, ControlNet typically involves\ncopying a large part of the original network, resulting in a significantly\nlarge number of parameters as the prior scales up. In this paper, we propose a\nrelatively lightweight Adapter that leverages the powerful generative\ncapabilities of pretrained priors to achieve photo-realistic image restoration.\nThe Adapters can be adapt to both denoising UNet and DiT, and performs\nexcellent.\n","authors":["Hanbang Liang","Zhen Wang","Weihui Deng"],"pdf_url":"https://arxiv.org/pdf/2502.20679v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.16214v2","updated":"2025-02-28T03:11:00Z","published":"2025-02-22T12:37:52Z","title":"SalM$^{2}$: An Extremely Lightweight Saliency Mamba Model for Real-Time\n  Cognitive Awareness of Driver Attention","summary":"  Driver attention recognition in driving scenarios is a popular direction in\ntraffic scene perception technology. It aims to understand human driver\nattention to focus on specific targets/objects in the driving scene. However,\ntraffic scenes contain not only a large amount of visual information but also\nsemantic information related to driving tasks. Existing methods lack attention\nto the actual semantic information present in driving scenes. Additionally, the\ntraffic scene is a complex and dynamic process that requires constant attention\nto objects related to the current driving task. Existing models, influenced by\ntheir foundational frameworks, tend to have large parameter counts and complex\nstructures. Therefore, this paper proposes a real-time saliency Mamba network\nbased on the latest Mamba framework. As shown in Figure 1, our model uses very\nfew parameters (0.08M, only 0.09~11.16% of other models), while maintaining\nSOTA performance or achieving over 98% of the SOTA model's performance.\n","authors":["Chunyu Zhao","Wentao Mu","Xian Zhou","Wenbo Liu","Fei Yan","Tao Deng"],"pdf_url":"https://arxiv.org/pdf/2502.16214v2.pdf","comment":"The article has been accepted for publication at AAAI 2025"},{"id":"http://arxiv.org/abs/2502.20678v1","updated":"2025-02-28T03:06:23Z","published":"2025-02-28T03:06:23Z","title":"STPro: Spatial and Temporal Progressive Learning for Weakly Supervised\n  Spatio-Temporal Grounding","summary":"  In this work we study Weakly Supervised Spatio-Temporal Video Grounding\n(WSTVG), a challenging task of localizing subjects spatio-temporally in videos\nusing only textual queries and no bounding box supervision. Inspired by recent\nadvances in vision-language foundation models, we investigate their utility for\nWSTVG, leveraging their zero-shot grounding capabilities. However, we find that\na simple adaptation lacks essential spatio-temporal grounding abilities. To\nbridge this gap, we introduce Tubelet Referral Grounding (TRG), which connects\ntextual queries to tubelets to enable spatio-temporal predictions. Despite its\npromise, TRG struggles with compositional action understanding and dense scene\nscenarios. To address these limitations, we propose STPro, a novel progressive\nlearning framework with two key modules: (1) Sub-Action Temporal Curriculum\nLearning (SA-TCL), which incrementally builds compositional action\nunderstanding, and (2) Congestion-Guided Spatial Curriculum Learning (CG-SCL),\nwhich adapts the model to complex scenes by spatially increasing task\ndifficulty. STPro achieves state-of-the-art results on three benchmark\ndatasets, with improvements of 1.0% on VidSTG-Declarative and 3.0% on\nHCSTVG-v1.\n","authors":["Aaryan Garg","Akash Kumar","Yogesh S Rawat"],"pdf_url":"https://arxiv.org/pdf/2502.20678v1.pdf","comment":"CVPR'25 Conference"},{"id":"http://arxiv.org/abs/2502.20676v1","updated":"2025-02-28T03:05:30Z","published":"2025-02-28T03:05:30Z","title":"SciceVPR: Stable Cross-Image Correlation Enhanced Model for Visual Place\n  Recognition","summary":"  Visual Place Recognition (VPR) is a major challenge for robotics and\nautonomous systems, with the goal of predicting the location of an image based\nsolely on its visual features. State-of-the-art (SOTA) models extract global\ndescriptors using the powerful foundation model DINOv2 as backbone. These\nmodels either explore the cross-image correlation or propose a time-consuming\ntwo-stage re-ranking strategy to achieve better performance. However, existing\nworks only utilize the final output of DINOv2, and the current cross-image\ncorrelation causes unstable retrieval results. To produce both discriminative\nand constant global descriptors, this paper proposes stable cross-image\ncorrelation enhanced model for VPR called SciceVPR. This model explores the\nfull potential of DINOv2 in providing useful feature representations that\nimplicitly encode valuable contextual knowledge. Specifically, SciceVPR first\nuses a multi-layer feature fusion module to capture increasingly detailed\ntask-relevant channel and spatial information from the multi-layer output of\nDINOv2. Secondly, SciceVPR considers the invariant correlation between images\nwithin a batch as valuable knowledge to be distilled into the proposed\nself-enhanced encoder. In this way, SciceVPR can acquire fairly robust global\nfeatures regardless of domain shifts (e.g., changes in illumination, weather\nand viewpoint between pictures taken in the same place). Experimental results\ndemonstrate that the base variant, SciceVPR-B, outperforms SOTA one-stage\nmethods with single input on multiple datasets with varying domain conditions.\nThe large variant, SciceVPR-L, performs on par with SOTA two-stage models,\nscoring over 3% higher in Recall@1 compared to existing models on the\nchallenging Tokyo24/7 dataset. Our code will be released at\nhttps://github.com/shuimushan/SciceVPR.\n","authors":["Shanshan Wan","Yingmei Wei","Lai Kang","Tianrui Shen","Haixuan Wang","Yee-Hong Yang"],"pdf_url":"https://arxiv.org/pdf/2502.20676v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14613v2","updated":"2025-02-28T03:04:05Z","published":"2024-12-19T08:03:16Z","title":"Multi-modal, Multi-task, Multi-criteria Automatic Evaluation with Vision\n  Language Models","summary":"  Vision-language models (VLMs) have shown impressive abilities across a range\nof multi-modal tasks. However, existing metrics for evaluating the quality of\ntext generated by VLMs typically focus on an overall evaluation for a specific\ntask, such as image captioning. While the overall evaluation is essential for\nany task, the criteria prioritized can differ depending on the task, making it\nchallenging for current metrics to adapt to multi-task scenarios. To address\nthis limitation, we propose HarmonicEval, a reference-free comprehensive\nevaluation metric that aggregates criterion-wise scores to produce the overall\nscore in a bottom-up manner. Furthermore, we construct the Multi-task\nMulti-criteria Human Evaluation (MMHE) dataset, which comprises 18,000 expert\nhuman judgments across four multi-modal tasks. Our experiments demonstrate that\nHarmonicEval achieves higher correlations with human judgments than\nconventional metrics while providing numerical scores for each criterion.\n","authors":["Masanari Ohi","Masahiro Kaneko","Naoaki Okazaki","Nakamasa Inoue"],"pdf_url":"https://arxiv.org/pdf/2412.14613v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20669v1","updated":"2025-02-28T02:50:59Z","published":"2025-02-28T02:50:59Z","title":"EndoPBR: Material and Lighting Estimation for Photorealistic Surgical\n  Simulations via Physically-based Rendering","summary":"  The lack of labeled datasets in 3D vision for surgical scenes inhibits the\ndevelopment of robust 3D reconstruction algorithms in the medical domain.\nDespite the popularity of Neural Radiance Fields and 3D Gaussian Splatting in\nthe general computer vision community, these systems have yet to find\nconsistent success in surgical scenes due to challenges such as non-stationary\nlighting and non-Lambertian surfaces. As a result, the need for labeled\nsurgical datasets continues to grow. In this work, we introduce a\ndifferentiable rendering framework for material and lighting estimation from\nendoscopic images and known geometry. Compared to previous approaches that\nmodel lighting and material jointly as radiance, we explicitly disentangle\nthese scene properties for robust and photorealistic novel view synthesis. To\ndisambiguate the training process, we formulate domain-specific properties\ninherent in surgical scenes. Specifically, we model the scene lighting as a\nsimple spotlight and material properties as a bidirectional reflectance\ndistribution function, parameterized by a neural network. By grounding color\npredictions in the rendering equation, we can generate photorealistic images at\narbitrary camera poses. We evaluate our method with various sequences from the\nColonoscopy 3D Video Dataset and show that our method produces competitive\nnovel view synthesis results compared with other approaches. Furthermore, we\ndemonstrate that synthetic data can be used to develop 3D vision algorithms by\nfinetuning a depth estimation model with our rendered outputs. Overall, we see\nthat the depth estimation performance is on par with fine-tuning with the\noriginal real images.\n","authors":["John J. Han","Jie Ying Wu"],"pdf_url":"https://arxiv.org/pdf/2502.20669v1.pdf","comment":"10 pages, 3 figures"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2502.21195v1","updated":"2025-02-28T16:14:00Z","published":"2025-02-28T16:14:00Z","title":"Joint Modeling in Recommendations: A Survey","summary":"  In today's digital landscape, Deep Recommender Systems (DRS) play a crucial\nrole in navigating and customizing online content for individual preferences.\nHowever, conventional methods, which mainly depend on single recommendation\ntask, scenario, data modality and user behavior, are increasingly seen as\ninsufficient due to their inability to accurately reflect users' complex and\nchanging preferences. This gap underscores the need for joint modeling\napproaches, which are central to overcoming these limitations by integrating\ndiverse tasks, scenarios, modalities, and behaviors in the recommendation\nprocess, thus promising significant enhancements in recommendation precision,\nefficiency, and customization. In this paper, we comprehensively survey the\njoint modeling methods in recommendations. We begin by defining the scope of\njoint modeling through four distinct dimensions: multi-task, multi-scenario,\nmulti-modal, and multi-behavior modeling. Subsequently, we examine these\nmethods in depth, identifying and summarizing their underlying paradigms based\non the latest advancements and potential research trajectories. Ultimately, we\nhighlight several promising avenues for future exploration in joint modeling\nfor recommendations and provide a concise conclusion to our findings.\n","authors":["Xiangyu Zhao","Yichao Wang","Bo Chen","Jingtong Gao","Yuhao Wang","Xiaopeng Li","Pengyue Jia","Qidong Liu","Huifeng Guo","Ruiming Tang"],"pdf_url":"https://arxiv.org/pdf/2502.21195v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2302.03525"},{"id":"http://arxiv.org/abs/2502.21112v1","updated":"2025-02-28T14:52:25Z","published":"2025-02-28T14:52:25Z","title":"Optimizing Large Language Models for ESG Activity Detection in Financial\n  Texts","summary":"  The integration of Environmental, Social, and Governance (ESG) factors into\ncorporate decision-making is a fundamental aspect of sustainable finance.\nHowever, ensuring that business practices align with evolving regulatory\nframeworks remains a persistent challenge. AI-driven solutions for\nautomatically assessing the alignment of sustainability reports and\nnon-financial disclosures with specific ESG activities could greatly support\nthis process. Yet, this task remains complex due to the limitations of\ngeneral-purpose Large Language Models (LLMs) in domain-specific contexts and\nthe scarcity of structured, high-quality datasets. In this paper, we\ninvestigate the ability of current-generation LLMs to identify text related to\nenvironmental activities. Furthermore, we demonstrate that their performance\ncan be significantly enhanced through fine-tuning on a combination of original\nand synthetically generated data. To this end, we introduce ESG-Activities, a\nbenchmark dataset containing 1,325 labelled text segments classified according\nto the EU ESG taxonomy. Our experimental results show that fine-tuning on\nESG-Activities significantly enhances classification accuracy, with open models\nsuch as Llama 7B and Gemma 7B outperforming large proprietary solutions in\nspecific configurations. These findings have important implications for\nfinancial analysts, policymakers, and AI researchers seeking to enhance ESG\ntransparency and compliance through advanced natural language processing\ntechniques.\n","authors":["Mattia Birti","Francesco Osborne","Andrea Maurino"],"pdf_url":"https://arxiv.org/pdf/2502.21112v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21067v1","updated":"2025-02-28T14:03:04Z","published":"2025-02-28T14:03:04Z","title":"Fast 3D point clouds retrieval for Large-scale 3D Place Recognition","summary":"  Retrieval in 3D point clouds is a challenging task that consists in\nretrieving the most similar point clouds to a given query within a reference of\n3D points. Current methods focus on comparing descriptors of point clouds in\norder to identify similar ones. Due to the complexity of this latter step, here\nwe focus on the acceleration of the retrieval by adapting the Differentiable\nSearch Index (DSI), a transformer-based approach initially designed for text\ninformation retrieval, for 3D point clouds retrieval. Our approach generates 1D\nidentifiers based on the point descriptors, enabling direct retrieval in\nconstant time. To adapt DSI to 3D data, we integrate Vision Transformers to map\ndescriptors to these identifiers while incorporating positional and semantic\nencoding. The approach is evaluated for place recognition on a public benchmark\ncomparing its retrieval capabilities against state-of-the-art methods, in terms\nof quality and speed of returned point clouds.\n","authors":["Chahine-Nicolas Zede","Laurent Carrafa","Valérie Gouet-Brunet"],"pdf_url":"https://arxiv.org/pdf/2502.21067v1.pdf","comment":"8 pages, 1 figures"},{"id":"http://arxiv.org/abs/2411.12064v2","updated":"2025-02-28T13:56:56Z","published":"2024-11-18T21:10:14Z","title":"TSPRank: Bridging Pairwise and Listwise Methods with a Bilinear\n  Travelling Salesman Model","summary":"  Traditional Learning-To-Rank (LETOR) approaches, including pairwise methods\nlike RankNet and LambdaMART, often fall short by solely focusing on pairwise\ncomparisons, leading to sub-optimal global rankings. Conversely, deep learning\nbased listwise methods, while aiming to optimise entire lists, require complex\ntuning and yield only marginal improvements over robust pairwise models. To\novercome these limitations, we introduce Travelling Salesman Problem Rank\n(TSPRank), a hybrid pairwise-listwise ranking method. TSPRank reframes the\nranking problem as a Travelling Salesman Problem (TSP), a well-known\ncombinatorial optimisation challenge that has been extensively studied for its\nnumerous solution algorithms and applications. This approach enables the\nmodelling of pairwise relationships and leverages combinatorial optimisation to\ndetermine the listwise ranking. This approach can be directly integrated as an\nadditional component into embeddings generated by existing backbone models to\nenhance ranking performance. Our extensive experiments across three backbone\nmodels on diverse tasks, including stock ranking, information retrieval, and\nhistorical events ordering, demonstrate that TSPRank significantly outperforms\nboth pure pairwise and listwise methods. Our qualitative analysis reveals that\nTSPRank's main advantage over existing methods is its ability to harness global\ninformation better while ranking. TSPRank's robustness and superior performance\nacross different domains highlight its potential as a versatile and effective\nLETOR solution.\n","authors":["Weixian Waylon Li","Yftah Ziser","Yifei Xie","Shay B. Cohen","Tiejun Ma"],"pdf_url":"https://arxiv.org/pdf/2411.12064v2.pdf","comment":"Accepted to ACM SIGKDD 2025 Research Track. The code and preprocessed\n  data are available at https://github.com/waylonli/TSPRank-KDD2025"},{"id":"http://arxiv.org/abs/2502.21024v1","updated":"2025-02-28T13:06:25Z","published":"2025-02-28T13:06:25Z","title":"Extending Dense Passage Retrieval with Temporal Information","summary":"  Temporal awareness is crucial in many information retrieval tasks,\nparticularly in scenarios where the relevance of documents depends on their\nalignment with the query's temporal context. Traditional retrieval methods such\nas BM25 and Dense Passage Retrieval (DPR) excel at capturing lexical and\nsemantic relevance but fall short in addressing time-sensitive queries. To\nbridge this gap, we introduce the temporal retrieval model that integrates\nexplicit temporal signals by incorporating query timestamps and document dates\ninto the representation space. Our approach ensures that retrieved passages are\nnot only topically relevant but also temporally aligned with user intent. We\nevaluate our approach on two large-scale benchmark datasets, ArchivalQA and\nChroniclingAmericaQA, achieving substantial performance gains over standard\nretrieval baselines. In particular, our model improves Top-1 retrieval accuracy\nby 6.63% and NDCG@10 by 3.79% on ArchivalQA, while yielding a 9.56% boost in\nTop-1 retrieval accuracy and 4.68% in NDCG@10 on ChroniclingAmericaQA.\nAdditionally, we introduce a time-sensitive negative sampling strategy, which\nrefines the model's ability to distinguish between temporally relevant and\nirrelevant documents during training. Our findings highlight the importance of\nexplicitly modeling time in retrieval systems and set a new standard for\nhandling temporally grounded queries.\n","authors":["Abdelrahman Abdallah","Bhawna Piryani","Jonas Wallat","Avishek Anand","Adam Jatowt"],"pdf_url":"https://arxiv.org/pdf/2502.21024v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.17723v2","updated":"2025-02-28T12:56:52Z","published":"2024-01-31T10:35:53Z","title":"LoRec: Large Language Model for Robust Sequential Recommendation against\n  Poisoning Attacks","summary":"  Sequential recommender systems stand out for their ability to capture users'\ndynamic interests and the patterns of item-to-item transitions. However, the\ninherent openness of sequential recommender systems renders them vulnerable to\npoisoning attacks, where fraudulent users are injected into the training data\nto manipulate learned patterns. Traditional defense strategies predominantly\ndepend on predefined assumptions or rules extracted from specific known\nattacks, limiting their generalizability to unknown attack types. To solve the\nabove problems, considering the rich open-world knowledge encapsulated in Large\nLanguage Models (LLMs), our research initially focuses on the capabilities of\nLLMs in the detection of unknown fraudulent activities within recommender\nsystems, a strategy we denote as LLM4Dec. Empirical evaluations demonstrate the\nsubstantial capability of LLMs in identifying unknown fraudsters, leveraging\ntheir expansive, open-world knowledge.\n  Building upon this, we propose the integration of LLMs into defense\nstrategies to extend their effectiveness beyond the confines of known attacks.\nWe propose LoRec, an advanced framework that employs LLM-Enhanced Calibration\nto strengthen the robustness of sequential recommender systems against\npoisoning attacks. LoRec integrates an LLM-enhanced CalibraTor (LCT) that\nrefines the training process of sequential recommender systems with knowledge\nderived from LLMs, applying a user-wise reweighting to diminish the impact of\nfraudsters injected by attacks. By incorporating LLMs' open-world knowledge,\nthe LCT effectively converts the limited, specific priors or rules into a more\ngeneral pattern of fraudsters, offering improved defenses against poisoning\nattacks. Our comprehensive experiments validate that LoRec, as a general\nframework, significantly strengthens the robustness of sequential recommender\nsystems.\n","authors":["Kaike Zhang","Qi Cao","Yunfan Wu","Fei Sun","Huawei Shen","Xueqi Cheng"],"pdf_url":"https://arxiv.org/pdf/2401.17723v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20995v1","updated":"2025-02-28T12:32:53Z","published":"2025-02-28T12:32:53Z","title":"The RAG Paradox: A Black-Box Attack Exploiting Unintentional\n  Vulnerabilities in Retrieval-Augmented Generation Systems","summary":"  With the growing adoption of retrieval-augmented generation (RAG) systems,\nrecent studies have introduced attack methods aimed at degrading their\nperformance. However, these methods rely on unrealistic white-box assumptions,\nsuch as attackers having access to RAG systems' internal processes. To address\nthis issue, we introduce a realistic black-box attack scenario based on the RAG\nparadox, where RAG systems inadvertently expose vulnerabilities while\nattempting to enhance trustworthiness. Because RAG systems reference external\ndocuments during response generation, our attack targets these sources without\nrequiring internal access. Our approach first identifies the external sources\ndisclosed by RAG systems and then automatically generates poisoned documents\nwith misinformation designed to match these sources. Finally, these poisoned\ndocuments are newly published on the disclosed sources, disrupting the RAG\nsystem's response generation process. Both offline and online experiments\nconfirm that this attack significantly reduces RAG performance without\nrequiring internal access. Furthermore, from an insider perspective within the\nRAG system, we propose a re-ranking method that acts as a fundamental\nsafeguard, offering minimal protection against unforeseen attacks.\n","authors":["Chanwoo Choi","Jinsoo Kim","Sukmin Cho","Soyeong Jeong","Buru Chang"],"pdf_url":"https://arxiv.org/pdf/2502.20995v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.08248v2","updated":"2025-02-28T11:40:20Z","published":"2025-01-14T16:38:33Z","title":"Eliciting In-context Retrieval and Reasoning for Long-context Large\n  Language Models","summary":"  Recent advancements in long-context language models (LCLMs) promise to\ntransform Retrieval-Augmented Generation (RAG) by simplifying pipelines. With\ntheir expanded context windows, LCLMs can process entire knowledge bases and\nperform retrieval and reasoning directly -- a capability we define as\nIn-Context Retrieval and Reasoning (ICR^2). However, existing benchmarks like\nLOFT often overestimate LCLM performance by providing overly simplified\ncontexts. To address this, we introduce ICR^2, a benchmark that evaluates LCLMs\nin more realistic scenarios by including confounding passages retrieved with\nstrong retrievers. We then propose three methods to enhance LCLM performance:\n(1) retrieve-then-generate fine-tuning, (2) retrieval-attention-probing, which\nuses attention heads to filter and de-noise long contexts during decoding, and\n(3) joint retrieval head training alongside the generation head. Our evaluation\nof five well-known LCLMs on LOFT and ICR^2 demonstrates significant gains with\nour best approach applied to Mistral-7B: +17 and +15 points by Exact Match on\nLOFT, and +13 and +2 points on ICR^2, compared to vanilla RAG and supervised\nfine-tuning, respectively. It even outperforms GPT-4-Turbo on most tasks\ndespite being a much smaller model.\n","authors":["Yifu Qiu","Varun Embar","Yizhe Zhang","Navdeep Jaitly","Shay B. Cohen","Benjamin Han"],"pdf_url":"https://arxiv.org/pdf/2501.08248v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20937v1","updated":"2025-02-28T10:46:56Z","published":"2025-02-28T10:46:56Z","title":"Variations in Relevance Judgments and the Shelf Life of Test Collections","summary":"  The fundamental property of Cranfield-style evaluations, that system rankings\nare stable even when assessors disagree on individual relevance decisions, was\nvalidated on traditional test collections. However, the paradigm shift towards\nneural retrieval models affected the characteristics of modern test\ncollections, e.g., documents are short, judged with four grades of relevance,\nand information needs have no descriptions or narratives. Under these changes,\nit is unclear whether assessor disagreement remains negligible for system\ncomparisons. We investigate this aspect under the additional condition that the\nfew modern test collections are heavily re-used. Given more possible query\ninterpretations due to less formalized information needs, an ''expiration\ndate'' for test collections might be needed if top-effectiveness requires\noverfitting to a single interpretation of relevance. We run a reproducibility\nstudy and re-annotate the relevance judgments of the 2019 TREC Deep Learning\ntrack. We can reproduce prior work in the neural retrieval setting, showing\nthat assessor disagreement does not affect system rankings. However, we observe\nthat some models substantially degrade with our new relevance judgments, and\nsome have already reached the effectiveness of humans as rankers, providing\nevidence that test collections can expire.\n","authors":["Andrew Parry","Maik Fröbe","Harrisen Scells","Ferdinand Schlatt","Guglielmo Faggioli","Saber Zerhoudi","Sean MacAvaney","Eugene Yang"],"pdf_url":"https://arxiv.org/pdf/2502.20937v1.pdf","comment":"11 pages, 6 tables, 5 figures"},{"id":"http://arxiv.org/abs/2502.20936v1","updated":"2025-02-28T10:46:52Z","published":"2025-02-28T10:46:52Z","title":"WebFAQ: A Multilingual Collection of Natural Q&A Datasets for Dense\n  Retrieval","summary":"  We present WebFAQ, a large-scale collection of open-domain question answering\ndatasets derived from FAQ-style schema.org annotations. In total, the data\ncollection consists of 96 million natural question-answer (QA) pairs across 75\nlanguages, including 47 million (49%) non-English samples. WebFAQ further\nserves as the foundation for 20 monolingual retrieval benchmarks with a total\nsize of 11.2 million QA pairs (5.9 million non-English). These datasets are\ncarefully curated through refined filtering and near-duplicate detection,\nyielding high-quality resources for training and evaluating multilingual dense\nretrieval models. To empirically confirm WebFAQ's efficacy, we use the\ncollected QAs to fine-tune an in-domain pretrained XLM-RoBERTa model. Through\nthis process of dataset-specific fine-tuning, the model achieves significant\nretrieval performance gains, which generalize - beyond WebFAQ - to other\nmultilingual retrieval benchmarks evaluated in zero-shot setting. Last but not\nleast, we utilize WebFAQ to construct a set of QA-aligned bilingual corpora\nspanning over 1000 language pairs using state-of-the-art bitext mining and\nautomated LLM-assessed translation evaluation. Due to our advanced, automated\nmethod of bitext dataset generation, the resulting bilingual corpora\ndemonstrate higher translation quality compared to similar datasets. WebFAQ and\nall associated resources are publicly available on GitHub and HuggingFace.\n","authors":["Michael Dinzinger","Laura Caspari","Kanishka Ghosh Dastidar","Jelena Mitrović","Michael Granitzer"],"pdf_url":"https://arxiv.org/pdf/2502.20936v1.pdf","comment":"10 pages, 3 figures, 7 tables"},{"id":"http://arxiv.org/abs/2407.01449v6","updated":"2025-02-28T08:51:57Z","published":"2024-06-27T15:45:29Z","title":"ColPali: Efficient Document Retrieval with Vision Language Models","summary":"  Documents are visually rich structures that convey information through text,\nbut also figures, page layouts, tables, or even fonts. Since modern retrieval\nsystems mainly rely on the textual information they extract from document pages\nto index documents -often through lengthy and brittle processes-, they struggle\nto exploit key visual cues efficiently. This limits their capabilities in many\npractical document retrieval applications such as Retrieval Augmented\nGeneration (RAG). To benchmark current systems on visually rich document\nretrieval, we introduce the Visual Document Retrieval Benchmark ViDoRe,\ncomposed of various page-level retrieval tasks spanning multiple domains,\nlanguages, and practical settings. The inherent complexity and performance\nshortcomings of modern systems motivate a new concept; doing document retrieval\nby directly embedding the images of the document pages. We release ColPali, a\nVision Language Model trained to produce high-quality multi-vector embeddings\nfrom images of document pages. Combined with a late interaction matching\nmechanism, ColPali largely outperforms modern document retrieval pipelines\nwhile being drastically simpler, faster and end-to-end trainable. We release\nmodels, data, code and benchmarks under open licenses at https://hf.co/vidore.\n","authors":["Manuel Faysse","Hugues Sibille","Tony Wu","Bilel Omrani","Gautier Viaud","Céline Hudelot","Pierre Colombo"],"pdf_url":"https://arxiv.org/pdf/2407.01449v6.pdf","comment":"Published as a conference paper at ICLR 2025"},{"id":"http://arxiv.org/abs/2502.20826v1","updated":"2025-02-28T08:12:23Z","published":"2025-02-28T08:12:23Z","title":"CoTMR: Chain-of-Thought Multi-Scale Reasoning for Training-Free\n  Zero-Shot Composed Image Retrieval","summary":"  Zero-Shot Composed Image Retrieval (ZS-CIR) aims to retrieve target images by\nintegrating information from a composed query (reference image and modification\ntext) without training samples. Existing methods primarily combine caption\nmodels and large language models (LLMs) to generate target captions based on\ncomposed queries but face various issues such as incompatibility, visual\ninformation loss, and insufficient reasoning. In this work, we propose CoTMR, a\ntraining-free framework crafted for ZS-CIR with novel Chain-of-thought (CoT)\nand Multi-scale Reasoning. Instead of relying on caption models for modality\ntransformation, CoTMR employs the Large Vision-Language Model (LVLM) to achieve\nunified understanding and reasoning for composed queries. To enhance the\nreasoning reliability, we devise CIRCoT, which guides the LVLM through a\nstep-by-step inference process using predefined subtasks. Considering that\nexisting approaches focus solely on global-level reasoning, our CoTMR\nincorporates multi-scale reasoning to achieve more comprehensive inference via\nfine-grained predictions about the presence or absence of key elements at the\nobject scale. Further, we design a Multi-Grained Scoring (MGS) mechanism, which\nintegrates CLIP similarity scores of the above reasoning outputs with candidate\nimages to realize precise retrieval. Extensive experiments demonstrate that our\nCoTMR not only drastically outperforms previous methods across four prominent\nbenchmarks but also offers appealing interpretability.\n","authors":["Zelong Sun","Dong Jing","Zhiwu Lu"],"pdf_url":"https://arxiv.org/pdf/2502.20826v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20695v1","updated":"2025-02-28T04:03:23Z","published":"2025-02-28T04:03:23Z","title":"Scalable Overload-Aware Graph-Based Index Construction for\n  10-Billion-Scale Vector Similarity Search","summary":"  Approximate Nearest Neighbor Search (ANNS) is essential for modern\ndata-driven applications that require efficient retrieval of top-k results from\nmassive vector databases. Although existing graph-based ANNS algorithms achieve\na high recall rate on billion-scale datasets, their slow construction speed and\nlimited scalability hinder their applicability to large-scale industrial\nscenarios. In this paper, we introduce SOGAIC, the first Scalable\nOverload-Aware Graph-Based ANNS Index Construction system tailored for\nultra-large-scale vector databases: 1) We propose a dynamic data partitioning\nalgorithm with overload constraints that adaptively introduces overlaps among\nsubsets; 2) To enable efficient distributed subgraph construction, we employ a\nload-balancing task scheduling framework combined with an agglomerative merging\nstrategy; 3) Extensive experiments on various datasets demonstrate a reduction\nof 47.3% in average construction time compared to existing methods. The\nproposed method has also been successfully deployed in a real-world industrial\nsearch engine, managing over 10 billion daily updated vectors and serving\nhundreds of millions of users.\n","authors":["Yang Shi","Yiping Sun","Jiaolong Du","Xiaocheng Zhong","Zhiyong Wang","Yao Hu"],"pdf_url":"https://arxiv.org/pdf/2502.20695v1.pdf","comment":"Accepted by WWW'25"},{"id":"http://arxiv.org/abs/2502.20687v1","updated":"2025-02-28T03:40:37Z","published":"2025-02-28T03:40:37Z","title":"Unleashing the Potential of Two-Tower Models: Diffusion-Based\n  Cross-Interaction for Large-Scale Matching","summary":"  Two-tower models are widely adopted in the industrial-scale matching stage\nacross a broad range of application domains, such as content recommendations,\nadvertisement systems, and search engines. This model efficiently handles\nlarge-scale candidate item screening by separating user and item\nrepresentations. However, the decoupling network also leads to a neglect of\npotential information interaction between the user and item representations.\nCurrent state-of-the-art (SOTA) approaches include adding a shallow fully\nconnected layer(i.e., COLD), which is limited by performance and can only be\nused in the ranking stage. For performance considerations, another approach\nattempts to capture historical positive interaction information from the other\ntower by regarding them as the input features(i.e., DAT). Later research showed\nthat the gains achieved by this method are still limited because of lacking the\nguidance on the next user intent. To address the aforementioned challenges, we\npropose a \"cross-interaction decoupling architecture\" within our matching\nparadigm. This user-tower architecture leverages a diffusion module to\nreconstruct the next positive intention representation and employs a\nmixed-attention module to facilitate comprehensive cross-interaction. During\nthe next positive intention generation, we further enhance the accuracy of its\nreconstruction by explicitly extracting the temporal drift within user behavior\nsequences. Experiments on two real-world datasets and one industrial dataset\ndemonstrate that our method outperforms the SOTA two-tower models\nsignificantly, and our diffusion approach outperforms other generative models\nin reconstructing item representations.\n","authors":["Yihan Wang","Fei Xiong","Zhexin Han","Qi Song","Kaiqiao Zhan","Ben Wang"],"pdf_url":"https://arxiv.org/pdf/2502.20687v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.00944v3","updated":"2025-02-28T03:23:52Z","published":"2024-06-03T02:56:14Z","title":"A Theory for Token-Level Harmonization in Retrieval-Augmented Generation","summary":"  Retrieval-augmented generation (RAG) utilizes retrieved texts to enhance\nlarge language models (LLMs). Studies show that while RAG provides valuable\nexternal information (benefit), it may also mislead LLMs (detriment) with noisy\nor incorrect retrieved texts. Although many existing methods attempt to\npreserve benefit and avoid detriment, they lack a theoretical explanation for\nRAG. The benefit and detriment in the next token prediction of RAG remain a\nblack box that cannot be quantified or compared in an explainable manner, so\nexisting methods are data-driven, need additional utility evaluators or\npost-hoc. This paper takes the first step towards providing a theory to explain\nand trade off the benefit and detriment in RAG. First, we model RAG as the\nfusion between distribution of LLMs knowledge and distribution of retrieved\ntexts. Then, we formalize the trade-off between the value of external knowledge\n(benefit) and its potential risk of misleading LLMs (detriment) in next token\nprediction of RAG by distribution difference in this fusion. Finally, we prove\nthat the actual effect of RAG on the token, which is the comparison between\nbenefit and detriment, can be predicted without any training or accessing the\nutility of retrieval. Based on our theory, we propose a practical novel method,\nTok-RAG, which achieves collaborative generation between the pure LLM and RAG\nat token level to preserve benefit and avoid detriment. Experiments in\nreal-world tasks using LLMs such as OPT, LLaMA-2, and Mistral show the\neffectiveness of our method and support our theoretical findings.\n","authors":["Shicheng Xu","Liang Pang","Huawei Shen","Xueqi Cheng"],"pdf_url":"https://arxiv.org/pdf/2406.00944v3.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2502.20640v1","updated":"2025-02-28T01:46:32Z","published":"2025-02-28T01:46:32Z","title":"LexRAG: Benchmarking Retrieval-Augmented Generation in Multi-Turn Legal\n  Consultation Conversation","summary":"  Retrieval-augmented generation (RAG) has proven highly effective in improving\nlarge language models (LLMs) across various domains. However, there is no\nbenchmark specifically designed to assess the effectiveness of RAG in the legal\ndomain, which restricts progress in this area. To fill this gap, we propose\nLexRAG, the first benchmark to evaluate RAG systems for multi-turn legal\nconsultations. LexRAG consists of 1,013 multi-turn dialogue samples and 17,228\ncandidate legal articles. Each sample is annotated by legal experts and\nconsists of five rounds of progressive questioning. LexRAG includes two key\ntasks: (1) Conversational knowledge retrieval, requiring accurate retrieval of\nrelevant legal articles based on multi-turn context. (2) Response generation,\nfocusing on producing legally sound answers. To ensure reliable\nreproducibility, we develop LexiT, a legal RAG toolkit that provides a\ncomprehensive implementation of RAG system components tailored for the legal\ndomain. Additionally, we introduce an LLM-as-a-judge evaluation pipeline to\nenable detailed and effective assessment. Through experimental analysis of\nvarious LLMs and retrieval methods, we reveal the key limitations of existing\nRAG systems in handling legal consultation conversations. LexRAG establishes a\nnew benchmark for the practical application of RAG systems in the legal domain,\nwith its code and data available at https://github.com/CSHaitao/LexRAG.\n","authors":["Haitao Li","Yifan Chen","Yiran Hu","Qingyao Ai","Junjie Chen","Xiaoyu Yang","Jianhui Yang","Yueyue Wu","Zeyang Liu","Yiqun Liu"],"pdf_url":"https://arxiv.org/pdf/2502.20640v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2410.02642v2","updated":"2025-02-28T19:49:30Z","published":"2024-10-03T16:25:37Z","title":"Attention in Large Language Models Yields Efficient Zero-Shot Re-Rankers","summary":"  Information retrieval (IR) systems have played a vital role in modern digital\nlife and have cemented their continued usefulness in this new era of generative\nAI via retrieval-augmented generation. With strong language processing\ncapabilities and remarkable versatility, large language models (LLMs) have\nbecome popular choices for zero-shot re-ranking in IR systems. So far,\nLLM-based re-ranking methods rely on strong generative capabilities, which\nrestricts their use to either specialized or powerful proprietary models. Given\nthese restrictions, we ask: is autoregressive generation necessary and optimal\nfor LLMs to perform re-ranking? We hypothesize that there are abundant signals\nrelevant to re-ranking within LLMs that might not be used to their full\npotential via generation. To more directly leverage such signals, we propose\nin-context re-ranking (ICR), a novel method that leverages the change in\nattention pattern caused by the search query for accurate and efficient\nre-ranking. To mitigate the intrinsic biases in LLMs, we propose a calibration\nmethod using a content-free query. Due to the absence of generation, ICR only\nrequires two ($O(1)$) forward passes to re-rank $N$ documents, making it\nsubstantially more efficient than generative re-ranking methods that require at\nleast $O(N)$ forward passes. Our novel design also enables ICR to be applied to\nany LLM without specialized training while guaranteeing a well-formed ranking.\nExtensive experiments with two popular open-weight LLMs on standard single-hop\nand multi-hop information retrieval benchmarks show that ICR outperforms\nRankGPT while cutting the latency by more than 60% in practice. Through\ndetailed analyses, we show that ICR's performance is specially strong on tasks\nthat require more complex re-ranking signals. Our findings call for further\nexploration on novel ways of utilizing open-weight LLMs beyond text generation.\n","authors":["Shijie Chen","Bernal Jiménez Gutiérrez","Yu Su"],"pdf_url":"https://arxiv.org/pdf/2410.02642v2.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2503.00238v1","updated":"2025-02-28T22:53:56Z","published":"2025-02-28T22:53:56Z","title":"Passage Query Methods for Retrieval and Reranking in Conversational\n  Agents","summary":"  This paper presents our approach to the TREC Interactive Knowledge Assistance\nTrack (iKAT), which focuses on improving conversational information-seeking\n(CIS) systems. While recent advancements in CIS have improved conversational\nagents' ability to assist users, significant challenges remain in understanding\ncontext and retrieving relevant documents across domains and dialogue turns. To\naddress these issues, we extend the Generate-Retrieve-Generate pipeline by\ndeveloping passage queries (PQs) that align with the target document's expected\nformat to improve query-document matching during retrieval. We propose two\nvariations of this approach: Weighted Reranking and Short and Long Passages.\nEach method leverages a Meta Llama model for context understanding and\ngenerating queries and responses. Passage ranking evaluation results show that\nthe Short and Long Passages approach outperformed the organizers' baselines,\nperformed best among Llama-based systems in the track, and achieved results\ncomparable to GPT-4-based systems. These results indicate that the method\neffectively balances efficiency and performance. Findings suggest that PQs\nimprove semantic alignment with target documents and demonstrate their\npotential to improve multi-turn dialogue systems.\n","authors":["Victor De Lima","Grace Hui Yang"],"pdf_url":"https://arxiv.org/pdf/2503.00238v1.pdf","comment":"7 pages, 3 figures. In Proceedings of the Thirty-Third Text Retrieval\n  Conference (TREC 2024), November 18-22, 2024, Rockville, MD, USA"},{"id":"http://arxiv.org/abs/2503.00223v1","updated":"2025-02-28T22:16:42Z","published":"2025-02-28T22:16:42Z","title":"DeepRetrieval: Powerful Query Generation for Information Retrieval with\n  Reinforcement Learning","summary":"  Information retrieval systems are crucial for enabling effective access to\nlarge document collections. Recent approaches have leveraged Large Language\nModels (LLMs) to enhance retrieval performance through query augmentation, but\noften rely on expensive supervised learning or distillation techniques that\nrequire significant computational resources and hand-labeled data. In this\npaper, we introduce DeepRetrieval, a novel reinforcement learning-based\napproach that trains LLMs to perform query augmentation directly through trial\nand error, without requiring supervised data. By using the retrieval recall as\na reward signal, our system learns to generate effective queries that maximize\ndocument retrieval performance. Our preliminary results demonstrate that\nDeepRetrieval significantly outperforms existing state-of-the-art methods,\nincluding the recent LEADS system, achieving 60.82\\% recall on publication\nsearch and 70.84\\% recall on trial search tasks while using a smaller model (3B\nvs. 7B parameters) and requiring no supervision data. These results suggest\nthat our reinforcement learning approach offers a more efficient and effective\nparadigm for information retrieval, potentially changing the landscape of\ndocument retrieval systems. code is available at\nhttps://github.com/pat-jj/DeepRetrieval.\n","authors":["Pengcheng Jiang"],"pdf_url":"https://arxiv.org/pdf/2503.00223v1.pdf","comment":"Ongoing work"},{"id":"http://arxiv.org/abs/2503.00179v1","updated":"2025-02-28T20:49:18Z","published":"2025-02-28T20:49:18Z","title":"Zero-Shot and Efficient Clarification Need Prediction in Conversational\n  Search","summary":"  Clarification need prediction (CNP) is a key task in conversational search,\naiming to predict whether to ask a clarifying question or give an answer to the\ncurrent user query. However, current research on CNP suffers from the issues of\nlimited CNP training data and low efficiency. In this paper, we propose a\nzero-shot and efficient CNP framework (Zef-CNP), in which we first prompt large\nlanguage models (LLMs) in a zero-shot manner to generate two sets of synthetic\nqueries: ambiguous and specific (unambiguous) queries. We then use the\ngenerated queries to train efficient CNP models. Zef-CNP eliminates the need\nfor human-annotated clarification-need labels during training and avoids the\nuse of LLMs with high query latency at query time. To further improve the\ngeneration quality of synthetic queries, we devise a topic-, information-need-,\nand query-aware chain-of-thought (CoT) prompting strategy (TIQ-CoT). Moreover,\nwe enhance TIQ-CoT with counterfactual query generation (CoQu), which guides\nLLMs first to generate a specific/ambiguous query and then sequentially\ngenerate its corresponding ambiguous/specific query. Experimental results show\nthat Zef-CNP achieves superior CNP effectiveness and efficiency compared with\nzero- and few-shot LLM-based CNP predictors.\n","authors":["Lili Lu","Chuan Meng","Federico Ravenda","Mohammad Aliannejadi","Fabio Crestani"],"pdf_url":"https://arxiv.org/pdf/2503.00179v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2404.10776v2","updated":"2025-02-28T18:56:33Z","published":"2024-04-16T17:59:55Z","title":"Nearly Optimal Algorithms for Contextual Dueling Bandits from\n  Adversarial Feedback","summary":"  Learning from human feedback plays an important role in aligning generative\nmodels, such as large language models (LLM). However, the effectiveness of this\napproach can be influenced by adversaries, who may intentionally provide\nmisleading preferences to manipulate the output in an undesirable or harmful\ndirection. To tackle this challenge, we study a specific model within this\nproblem domain--contextual dueling bandits with adversarial feedback, where the\ntrue preference label can be flipped by an adversary. We propose an algorithm\nnamely robust contextual dueling bandits (RCDB), which is based on\nuncertainty-weighted maximum likelihood estimation. Our algorithm achieves an\n$\\tilde O(d\\sqrt{T}/\\kappa+dC/\\kappa)$ regret bound, where $T$ is the number of\nrounds, $d$ is the dimension of the context, $\\kappa$ is the lower bound of the\nderivative of the link function, and $ 0 \\le C \\le T$ is the total number of\nadversarial feedback. We also prove a lower bound to show that our regret bound\nis nearly optimal, both in scenarios with and without ($C=0$) adversarial\nfeedback. Our work is the first to achieve nearly minimax optimal regret for\ndueling bandits in the presence of adversarial preference feedback.\nAdditionally, for the sigmoid link function, we develop a novel algorithm that\ntakes into account the effect of local derivatives into maximum likelihood\nestimation (MLE) analysis through a refined method for estimating the link\nfunction's derivative. This method helps us to eliminate the $\\kappa$\ndependence in the leading term with respect to $T$, which reduces the\nexponential dependence on the parameter radius $B$ to a polynomial dependence.\n","authors":["Qiwei Di","Jiafan He","Quanquan Gu"],"pdf_url":"https://arxiv.org/pdf/2404.10776v2.pdf","comment":"44pages, 2 figures, 1 table"},{"id":"http://arxiv.org/abs/2502.17481v2","updated":"2025-02-28T18:56:25Z","published":"2025-02-18T10:11:50Z","title":"Toward Foundational Model for Sleep Analysis Using a Multimodal Hybrid\n  Self-Supervised Learning Framework","summary":"  Sleep is essential for maintaining human health and quality of life.\nAnalyzing physiological signals during sleep is critical in assessing sleep\nquality and diagnosing sleep disorders. However, manual diagnoses by clinicians\nare time-intensive and subjective. Despite advances in deep learning that have\nenhanced automation, these approaches remain heavily dependent on large-scale\nlabeled datasets. This study introduces SynthSleepNet, a multimodal hybrid\nself-supervised learning framework designed for analyzing polysomnography (PSG)\ndata. SynthSleepNet effectively integrates masked prediction and contrastive\nlearning to leverage complementary features across multiple modalities,\nincluding electroencephalogram (EEG), electrooculography (EOG),\nelectromyography (EMG), and electrocardiogram (ECG). This approach enables the\nmodel to learn highly expressive representations of PSG data. Furthermore, a\ntemporal context module based on Mamba was developed to efficiently capture\ncontextual information across signals. SynthSleepNet achieved superior\nperformance compared to state-of-the-art methods across three downstream tasks:\nsleep-stage classification, apnea detection, and hypopnea detection, with\naccuracies of 89.89%, 99.75%, and 89.60%, respectively. The model demonstrated\nrobust performance in a semi-supervised learning environment with limited\nlabels, achieving accuracies of 87.98%, 99.37%, and 77.52% in the same tasks.\nThese results underscore the potential of the model as a foundational tool for\nthe comprehensive analysis of PSG data. SynthSleepNet demonstrates\ncomprehensively superior performance across multiple downstream tasks compared\nto other methodologies, making it expected to set a new standard for sleep\ndisorder monitoring and diagnostic systems.\n","authors":["Cheol-Hui Lee","Hakseung Kim","Byung C. Yoon","Dong-Joo Kim"],"pdf_url":"https://arxiv.org/pdf/2502.17481v2.pdf","comment":"18 pages, 5 figures"},{"id":"http://arxiv.org/abs/2502.21313v1","updated":"2025-02-28T18:54:51Z","published":"2025-02-28T18:54:51Z","title":"Unsupervised Parameter Efficient Source-free Post-pretraining","summary":"  Following the success in NLP, the best vision models are now in the billion\nparameter ranges. Adapting these large models to a target distribution has\nbecome computationally and economically prohibitive. Addressing this challenge,\nwe introduce UpStep, an Unsupervised Parameter-efficient Source-free\npost-pretraining approach, designed to efficiently adapt a base model from a\nsource domain to a target domain: i) we design a self-supervised training\nscheme to adapt a pretrained model on an unlabeled target domain in a setting\nwhere source domain data is unavailable. Such source-free setting comes with\nthe risk of catastrophic forgetting, hence, ii) we propose center vector\nregularization (CVR), a set of auxiliary operations that minimize catastrophic\nforgetting and additionally reduces the computational cost by skipping\nbackpropagation in 50\\% of the training iterations. Finally iii) we perform\nthis adaptation process in a parameter-efficient way by adapting the pretrained\nmodel through low-rank adaptation methods, resulting in a fraction of\nparameters to optimize. We utilize various general backbone architectures, both\nsupervised and unsupervised, trained on Imagenet as our base model and adapt\nthem to a diverse set of eight target domains demonstrating the adaptability\nand generalizability of our proposed approach.\n","authors":["Abhishek Jha","Tinne Tuytelaars","Yuki M. Asano"],"pdf_url":"https://arxiv.org/pdf/2502.21313v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21309v1","updated":"2025-02-28T18:52:24Z","published":"2025-02-28T18:52:24Z","title":"FANformer: Improving Large Language Models Through Effective Periodicity\n  Modeling","summary":"  Periodicity, as one of the most important basic characteristics, lays the\nfoundation for facilitating structured knowledge acquisition and systematic\ncognitive processes within human learning paradigms. However, the potential\nflaws of periodicity modeling in Transformer affect the learning efficiency and\nestablishment of underlying principles from data for large language models\n(LLMs) built upon it. In this paper, we demonstrate that integrating effective\nperiodicity modeling can improve the learning efficiency and performance of\nLLMs. We introduce FANformer, which integrates Fourier Analysis Network (FAN)\ninto attention mechanism to achieve efficient periodicity modeling, by\nmodifying the feature projection process of attention mechanism. Extensive\nexperimental results on language modeling show that FANformer consistently\noutperforms Transformer when scaling up model size and training tokens,\nunderscoring its superior learning efficiency. To further validate the\neffectiveness of FANformer, we pretrain a FANformer-1B on 1 trillion tokens.\nFANformer-1B exhibits marked improvements on downstream tasks compared to\nopen-source LLMs with similar model parameters or training tokens. The results\nposition FANformer as an effective and promising architecture for advancing\nLLMs.\n","authors":["Yihong Dong","Ge Li","Xue Jiang","Yongding Tao","Kechi Zhang","Hao Zhu","Huanyu Liu","Jiazheng Ding","Jia Li","Jinliang Deng","Hong Mei"],"pdf_url":"https://arxiv.org/pdf/2502.21309v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21304v1","updated":"2025-02-28T18:40:41Z","published":"2025-02-28T18:40:41Z","title":"Clustering Context in Off-Policy Evaluation","summary":"  Off-policy evaluation can leverage logged data to estimate the effectiveness\nof new policies in e-commerce, search engines, media streaming services, or\nautomatic diagnostic tools in healthcare. However, the performance of baseline\noff-policy estimators like IPS deteriorates when the logging policy\nsignificantly differs from the evaluation policy. Recent work proposes sharing\ninformation across similar actions to mitigate this problem. In this work, we\npropose an alternative estimator that shares information across similar\ncontexts using clustering. We study the theoretical properties of the proposed\nestimator, characterizing its bias and variance under different conditions. We\nalso compare the performance of the proposed estimator and existing approaches\nin various synthetic problems, as well as a real-world recommendation dataset.\nOur experimental results confirm that clustering contexts improves estimation\naccuracy, especially in deficient information settings.\n","authors":["Daniel Guzman-Olivares","Philipp Schmidt","Jacek Golebiowski","Artur Bekasov"],"pdf_url":"https://arxiv.org/pdf/2502.21304v1.pdf","comment":"35 pages, 25 figures, 2 tables. AISTATS 2025"},{"id":"http://arxiv.org/abs/2502.21290v1","updated":"2025-02-28T18:15:31Z","published":"2025-02-28T18:15:31Z","title":"Contextualizing biological perturbation experiments through language","summary":"  High-content perturbation experiments allow scientists to probe biomolecular\nsystems at unprecedented resolution, but experimental and analysis costs pose\nsignificant barriers to widespread adoption. Machine learning has the potential\nto guide efficient exploration of the perturbation space and extract novel\ninsights from these data. However, current approaches neglect the semantic\nrichness of the relevant biology, and their objectives are misaligned with\ndownstream biological analyses. In this paper, we hypothesize that large\nlanguage models (LLMs) present a natural medium for representing complex\nbiological relationships and rationalizing experimental outcomes. We propose\nPerturbQA, a benchmark for structured reasoning over perturbation experiments.\nUnlike current benchmarks that primarily interrogate existing knowledge,\nPerturbQA is inspired by open problems in perturbation modeling: prediction of\ndifferential expression and change of direction for unseen perturbations, and\ngene set enrichment. We evaluate state-of-the-art machine learning and\nstatistical approaches for modeling perturbations, as well as standard LLM\nreasoning strategies, and we find that current methods perform poorly on\nPerturbQA. As a proof of feasibility, we introduce Summer (SUMMarize, retrievE,\nand answeR, a simple, domain-informed LLM framework that matches or exceeds the\ncurrent state-of-the-art. Our code and data are publicly available at\nhttps://github.com/genentech/PerturbQA.\n","authors":["Menghua Wu","Russell Littman","Jacob Levine","Lin Qiu","Tommaso Biancalani","David Richmond","Jan-Christian Huetter"],"pdf_url":"https://arxiv.org/pdf/2502.21290v1.pdf","comment":"The Thirteenth International Conference on Learning Representations\n  (2025)"},{"id":"http://arxiv.org/abs/2502.21286v1","updated":"2025-02-28T18:06:03Z","published":"2025-02-28T18:06:03Z","title":"Enabling AutoML for Zero-Touch Network Security: Use-Case Driven\n  Analysis","summary":"  Zero-Touch Networks (ZTNs) represent a state-of-the-art paradigm shift\ntowards fully automated and intelligent network management, enabling the\nautomation and intelligence required to manage the complexity, scale, and\ndynamic nature of next-generation (6G) networks. ZTNs leverage Artificial\nIntelligence (AI) and Machine Learning (ML) to enhance operational efficiency,\nsupport intelligent decision-making, and ensure effective resource allocation.\nHowever, the implementation of ZTNs is subject to security challenges that need\nto be resolved to achieve their full potential. In particular, two critical\nchallenges arise: the need for human expertise in developing AI/ML-based\nsecurity mechanisms, and the threat of adversarial attacks targeting AI/ML\nmodels. In this survey paper, we provide a comprehensive review of current\nsecurity issues in ZTNs, emphasizing the need for advanced AI/ML-based security\nmechanisms that require minimal human intervention and protect AI/ML models\nthemselves. Furthermore, we explore the potential of Automated ML (AutoML)\ntechnologies in developing robust security solutions for ZTNs. Through case\nstudies, we illustrate practical approaches to securing ZTNs against both\nconventional and AI/ML-specific threats, including the development of\nautonomous intrusion detection systems and strategies to combat Adversarial ML\n(AML) attacks. The paper concludes with a discussion of the future research\ndirections for the development of ZTN security approaches.\n","authors":["Li Yang","Mirna El Rajab","Abdallah Shami","Sami Muhaidat"],"pdf_url":"https://arxiv.org/pdf/2502.21286v1.pdf","comment":"Published in IEEE Transactions on Network and Service Management\n  (TNSM); Code is available at Github link:\n  https://github.com/Western-OC2-Lab/AutoML-and-Adversarial-Attack-Defense-for-Zero-Touch-Network-Security"},{"id":"http://arxiv.org/abs/2501.19392v4","updated":"2025-02-28T18:04:52Z","published":"2025-01-31T18:47:42Z","title":"Cache Me If You Must: Adaptive Key-Value Quantization for Large Language\n  Models","summary":"  Efficient real-world deployments of large language models (LLMs) rely on\nKey-Value (KV) caching for processing and generating long outputs, reducing the\nneed for repetitive computation. For large contexts, Key-Value caches can take\nup tens of gigabytes of device memory, as they store vector representations for\neach token and layer. Recent work has shown that the cached vectors can be\ncompressed through quantization, pruning or merging, but these techniques often\ncompromise quality towards higher compression rates. In this work, we aim to\nimprove Key & Value compression by exploiting two observations: 1) the inherent\ndependencies between keys and values across different layers, and 2)\nhigh-compression mechanisms for internal network states. We propose AQUA-KV, an\nadaptive quantization for Key-Value caches that relies on compact adapters to\nexploit existing dependencies between Keys and Values, and aims to \"optimally\"\ncompress the information that cannot be predicted. AQUA-KV significantly\nimproves compression rates, while maintaining high accuracy on state-of-the-art\nLLM families. On Llama 3.2 LLMs, we achieve near-lossless inference at 2-2.5\nbits per value with under $1\\%$ relative error in perplexity and LongBench\nscores. AQUA-KV is one-shot, simple, and efficient: it can be calibrated on a\nsingle GPU within 1-6 hours, even for 70B models.\n","authors":["Alina Shutova","Vladimir Malinovskii","Vage Egiazarian","Denis Kuznedelev","Denis Mazur","Nikita Surkov","Ivan Ermakov","Dan Alistarh"],"pdf_url":"https://arxiv.org/pdf/2501.19392v4.pdf","comment":"Preprint, under review"},{"id":"http://arxiv.org/abs/2502.21284v1","updated":"2025-02-28T18:03:55Z","published":"2025-02-28T18:03:55Z","title":"Controlled Model Debiasing through Minimal and Interpretable Updates","summary":"  Traditional approaches to learning fair machine learning models often require\nrebuilding models from scratch, generally without accounting for potentially\nexisting previous models. In a context where models need to be retrained\nfrequently, this can lead to inconsistent model updates, as well as redundant\nand costly validation testing. To address this limitation, we introduce the\nnotion of controlled model debiasing, a novel supervised learning task relying\non two desiderata: that the differences between new fair model and the existing\none should be (i) interpretable and (ii) minimal. After providing theoretical\nguarantees to this new problem, we introduce a novel algorithm for algorithmic\nfairness, COMMOD, that is both model-agnostic and does not require the\nsensitive attribute at test time. In addition, our algorithm is explicitly\ndesigned to enforce minimal and interpretable changes between biased and\ndebiased predictions -a property that, while highly desirable in high-stakes\napplications, is rarely prioritized as an explicit objective in fairness\nliterature. Our approach combines a concept-based architecture and adversarial\nlearning and we demonstrate through empirical results that it achieves\ncomparable performance to state-of-the-art debiasing methods while performing\nminimal and interpretable prediction changes.\n","authors":["Federico Di Gennaro","Thibault Laugel","Vincent Grari","Marcin Detyniecki"],"pdf_url":"https://arxiv.org/pdf/2502.21284v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21279v1","updated":"2025-02-28T17:57:57Z","published":"2025-02-28T17:57:57Z","title":"L-Lipschitz Gershgorin ResNet Network","summary":"  Deep residual networks (ResNets) have demonstrated outstanding success in\ncomputer vision tasks, attributed to their ability to maintain gradient flow\nthrough deep architectures. Simultaneously, controlling the Lipschitz bound in\nneural networks has emerged as an essential area of research for enhancing\nadversarial robustness and network certifiability. This paper uses a rigorous\napproach to design $\\mathcal{L}$-Lipschitz deep residual networks using a\nLinear Matrix Inequality (LMI) framework. The ResNet architecture was\nreformulated as a pseudo-tri-diagonal LMI with off-diagonal elements and\nderived closed-form constraints on network parameters to ensure\n$\\mathcal{L}$-Lipschitz continuity. To address the lack of explicit eigenvalue\ncomputations for such matrix structures, the Gershgorin circle theorem was\nemployed to approximate eigenvalue locations, guaranteeing the LMI's negative\nsemi-definiteness. Our contributions include a provable parameterization\nmethodology for constructing Lipschitz-constrained networks and a compositional\nframework for managing recursive systems within hierarchical architectures.\nThese findings enable robust network designs applicable to adversarial\nrobustness, certified training, and control systems. However, a limitation was\nidentified in the Gershgorin-based approximations, which over-constrain the\nsystem, suppressing non-linear dynamics and diminishing the network's\nexpressive capacity.\n","authors":["Marius F. R. Juston","William R. Norris","Dustin Nottage","Ahmet Soylemezoglu"],"pdf_url":"https://arxiv.org/pdf/2502.21279v1.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2501.17325v2","updated":"2025-02-28T17:57:52Z","published":"2025-01-28T22:37:25Z","title":"Connecting Federated ADMM to Bayes","summary":"  We provide new connections between two distinct federated learning approaches\nbased on (i) ADMM and (ii) Variational Bayes (VB), and propose new variants by\ncombining their complementary strengths. Specifically, we show that the dual\nvariables in ADMM naturally emerge through the 'site' parameters used in VB\nwith isotropic Gaussian covariances. Using this, we derive two versions of ADMM\nfrom VB that use flexible covariances and functional regularisation,\nrespectively. Through numerical experiments, we validate the improvements\nobtained in performance. The work shows connection between two fields that are\nbelieved to be fundamentally different and combines them to improve federated\nlearning.\n","authors":["Siddharth Swaroop","Mohammad Emtiyaz Khan","Finale Doshi-Velez"],"pdf_url":"https://arxiv.org/pdf/2501.17325v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21278v1","updated":"2025-02-28T17:57:48Z","published":"2025-02-28T17:57:48Z","title":"Does Generation Require Memorization? Creative Diffusion Models using\n  Ambient Diffusion","summary":"  There is strong empirical evidence that the state-of-the-art diffusion\nmodeling paradigm leads to models that memorize the training set, especially\nwhen the training set is small. Prior methods to mitigate the memorization\nproblem often lead to a decrease in image quality. Is it possible to obtain\nstrong and creative generative models, i.e., models that achieve high\ngeneration quality and low memorization? Despite the current pessimistic\nlandscape of results, we make significant progress in pushing the trade-off\nbetween fidelity and memorization. We first provide theoretical evidence that\nmemorization in diffusion models is only necessary for denoising problems at\nlow noise scales (usually used in generating high-frequency details). Using\nthis theoretical insight, we propose a simple, principled method to train the\ndiffusion models using noisy data at large noise scales. We show that our\nmethod significantly reduces memorization without decreasing the image quality,\nfor both text-conditional and unconditional models and for a variety of data\navailability settings.\n","authors":["Kulin Shah","Alkis Kalavasis","Adam R. Klivans","Giannis Daras"],"pdf_url":"https://arxiv.org/pdf/2502.21278v1.pdf","comment":"33 pages"},{"id":"http://arxiv.org/abs/2502.21274v1","updated":"2025-02-28T17:51:00Z","published":"2025-02-28T17:51:00Z","title":"BAnG: Bidirectional Anchored Generation for Conditional RNA Design","summary":"  Designing RNA molecules that interact with specific proteins is a critical\nchallenge in experimental and computational biology. Existing computational\napproaches require a substantial amount of experimentally determined RNA\nsequences for each specific protein or a detailed knowledge of RNA structure,\nrestricting their utility in practice. To address this limitation, we develop\nRNA-BAnG, a deep learning-based model designed to generate RNA sequences for\nprotein interactions without these requirements. Central to our approach is a\nnovel generative method, Bidirectional Anchored Generation (BAnG), which\nleverages the observation that protein-binding RNA sequences often contain\nfunctional binding motifs embedded within broader sequence contexts. We first\nvalidate our method on generic synthetic tasks involving similar localized\nmotifs to those appearing in RNAs, demonstrating its benefits over existing\ngenerative approaches. We then evaluate our model on biological sequences,\nshowing its effectiveness for conditional RNA sequence design given a binding\nprotein.\n","authors":["Roman Klypa","Alberto Bietti","Sergei Grudinin"],"pdf_url":"https://arxiv.org/pdf/2502.21274v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.00075v5","updated":"2025-02-28T17:50:12Z","published":"2024-06-21T19:18:16Z","title":"Logicbreaks: A Framework for Understanding Subversion of Rule-based\n  Inference","summary":"  We study how to subvert large language models (LLMs) from following\nprompt-specified rules. We first formalize rule-following as inference in\npropositional Horn logic, a mathematical system in which rules have the form\n\"if $P$ and $Q$, then $R$\" for some propositions $P$, $Q$, and $R$. Next, we\nprove that although small transformers can faithfully follow such rules,\nmaliciously crafted prompts can still mislead both theoretical constructions\nand models learned from data. Furthermore, we demonstrate that popular attack\nalgorithms on LLMs find adversarial prompts and induce attention patterns that\nalign with our theory. Our novel logic-based framework provides a foundation\nfor studying LLMs in rule-based settings, enabling a formal analysis of tasks\nlike logical reasoning and jailbreak attacks.\n","authors":["Anton Xue","Avishree Khare","Rajeev Alur","Surbhi Goel","Eric Wong"],"pdf_url":"https://arxiv.org/pdf/2407.00075v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21271v1","updated":"2025-02-28T17:46:29Z","published":"2025-02-28T17:46:29Z","title":"Adaptive Keyframe Sampling for Long Video Understanding","summary":"  Multimodal large language models (MLLMs) have enabled open-world visual\nunderstanding by injecting visual input as extra tokens into large language\nmodels (LLMs) as contexts. However, when the visual input changes from a single\nimage to a long video, the above paradigm encounters difficulty because the\nvast amount of video tokens has significantly exceeded the maximal capacity of\nMLLMs. Therefore, existing video-based MLLMs are mostly established upon\nsampling a small portion of tokens from input data, which can cause key\ninformation to be lost and thus produce incorrect answers. This paper presents\na simple yet effective algorithm named Adaptive Keyframe Sampling (AKS). It\ninserts a plug-and-play module known as keyframe selection, which aims to\nmaximize the useful information with a fixed number of video tokens. We\nformulate keyframe selection as an optimization involving (1) the relevance\nbetween the keyframes and the prompt, and (2) the coverage of the keyframes\nover the video, and present an adaptive algorithm to approximate the best\nsolution. Experiments on two long video understanding benchmarks validate that\nAdaptive Keyframe Sampling improves video QA accuracy (beyond strong baselines)\nupon selecting informative keyframes. Our study reveals the importance of\ninformation pre-filtering in video-based MLLMs. Code is available at\nhttps://github.com/ncTimTang/AKS.\n","authors":["Xi Tang","Jihao Qiu","Lingxi Xie","Yunjie Tian","Jianbin Jiao","Qixiang Ye"],"pdf_url":"https://arxiv.org/pdf/2502.21271v1.pdf","comment":"CVPR2025"},{"id":"http://arxiv.org/abs/2502.21269v1","updated":"2025-02-28T17:45:26Z","published":"2025-02-28T17:45:26Z","title":"Dynamical Decoupling of Generalization and Overfitting in Large\n  Two-Layer Networks","summary":"  The inductive bias and generalization properties of large machine learning\nmodels are -- to a substantial extent -- a byproduct of the optimization\nalgorithm used for training. Among others, the scale of the random\ninitialization, the learning rate, and early stopping all have crucial impact\non the quality of the model learnt by stochastic gradient descent or related\nalgorithms. In order to understand these phenomena, we study the training\ndynamics of large two-layer neural networks. We use a well-established\ntechnique from non-equilibrium statistical physics (dynamical mean field\ntheory) to obtain an asymptotic high-dimensional characterization of this\ndynamics. This characterization applies to a Gaussian approximation of the\nhidden neurons non-linearity, and empirically captures well the behavior of\nactual neural network models.\n  Our analysis uncovers several interesting new phenomena in the training\ndynamics: $(i)$ The emergence of a slow time scale associated with the growth\nin Gaussian/Rademacher complexity; $(ii)$ As a consequence, algorithmic\ninductive bias towards small complexity, but only if the initialization has\nsmall enough complexity; $(iii)$ A separation of time scales between feature\nlearning and overfitting; $(iv)$ A non-monotone behavior of the test error and,\ncorrespondingly, a `feature unlearning' phase at large times.\n","authors":["Andrea Montanari","Pierfrancesco Urbani"],"pdf_url":"https://arxiv.org/pdf/2502.21269v1.pdf","comment":"89 pages; 62 pdf figures"},{"id":"http://arxiv.org/abs/2502.21262v1","updated":"2025-02-28T17:39:55Z","published":"2025-02-28T17:39:55Z","title":"Modeling Human Beliefs about AI Behavior for Scalable Oversight","summary":"  Contemporary work in AI alignment often relies on human feedback to teach AI\nsystems human preferences and values. Yet as AI systems grow more capable,\nhuman feedback becomes increasingly unreliable. This raises the problem of\nscalable oversight: How can we supervise AI systems that exceed human\ncapabilities? In this work, we propose to model the human evaluator's beliefs\nabout the AI system's behavior to better interpret the human's feedback. We\nformalize human belief models and theoretically analyze their role in inferring\nhuman values. We then characterize the remaining ambiguity in this inference\nand conditions for which the ambiguity disappears. To mitigate reliance on\nexact belief models, we then introduce the relaxation of human belief model\ncovering. Finally, we propose using foundation models to construct covering\nbelief models, providing a new potential approach to scalable oversight.\n","authors":["Leon Lang","Patrick Forré"],"pdf_url":"https://arxiv.org/pdf/2502.21262v1.pdf","comment":"53 pages"},{"id":"http://arxiv.org/abs/2405.06561v2","updated":"2025-02-28T17:39:20Z","published":"2024-05-10T16:02:41Z","title":"Reservoir Computing Benchmarks: a tutorial review and critique","summary":"  Reservoir Computing is an Unconventional Computation model to perform\ncomputation on various different substrates, such as recurrent neural networks\nor physical materials. The method takes a 'black-box' approach, training only\nthe outputs of the system it is built on. As such, evaluating the computational\ncapacity of these systems can be challenging. We review and critique the\nevaluation methods used in the field of reservoir computing. We introduce a\ncategorisation of benchmark tasks. We review multiple examples of benchmarks\nfrom the literature as applied to reservoir computing, and note their strengths\nand shortcomings. We suggest ways in which benchmarks and their uses may be\nimproved to the benefit of the reservoir computing community.\n","authors":["Chester Wringe","Martin Trefzer","Susan Stepney"],"pdf_url":"https://arxiv.org/pdf/2405.06561v2.pdf","comment":"47 pp, 15 figures, 9 tables, review article"},{"id":"http://arxiv.org/abs/2408.12373v2","updated":"2025-02-28T17:36:51Z","published":"2024-08-22T13:15:49Z","title":"Cell-ontology guided transcriptome foundation model","summary":"  Transcriptome foundation models TFMs hold great promises of deciphering the\ntranscriptomic language that dictate diverse cell functions by self-supervised\nlearning on large-scale single-cell gene expression data, and ultimately\nunraveling the complex mechanisms of human diseases. However, current TFMs\ntreat cells as independent samples and ignore the taxonomic relationships\nbetween cell types, which are available in cell ontology graphs. We argue that\neffectively leveraging this ontology information during the TFM pre-training\ncan improve learning biologically meaningful gene co-expression patterns while\npreserving TFM as a general purpose foundation model for downstream zero-shot\nand fine-tuning tasks. To this end, we present single cell, Cell-ontology\nguided TFM scCello. We introduce cell-type coherence loss and ontology\nalignment loss, which are minimized along with the masked gene expression\nprediction loss during the pre-training. The novel loss component guide scCello\nto learn the cell-type-specific representation and the structural relation\nbetween cell types from the cell ontology graph, respectively. We pre-trained\nscCello on 22 million cells from CellxGene database leveraging their cell-type\nlabels mapped to the cell ontology graph from Open Biological and Biomedical\nOntology Foundry. Our TFM demonstrates competitive generalization and\ntransferability performance over the existing TFMs on biologically important\ntasks including identifying novel cell types of unseen cells, prediction of\ncell-type-specific marker genes, and cancer drug responses.\n","authors":["Xinyu Yuan","Zhihao Zhan","Zuobai Zhang","Manqi Zhou","Jianan Zhao","Boyu Han","Yue Li","Jian Tang"],"pdf_url":"https://arxiv.org/pdf/2408.12373v2.pdf","comment":"Accepted to NeurIPS 2024 as Spotlight"},{"id":"http://arxiv.org/abs/2502.20115v2","updated":"2025-02-28T17:33:29Z","published":"2025-02-27T14:06:14Z","title":"Identifiable Multi-View Causal Discovery Without Non-Gaussianity","summary":"  We propose a novel approach to linear causal discovery in the framework of\nmulti-view Structural Equation Models (SEM). Our proposed model relaxes the\nwell-known assumption of non-Gaussian disturbances by alternatively assuming\ndiversity of variances over views, making it more broadly applicable. We prove\nthe identifiability of all the parameters of the model without any further\nassumptions on the structure of the SEM other than it being acyclic. We further\npropose an estimation algorithm based on recent advances in multi-view\nIndependent Component Analysis (ICA). The proposed methodology is validated\nthrough simulations and application on real neuroimaging data, where it enables\nthe estimation of causal graphs between brain regions.\n","authors":["Ambroise Heurtebise","Omar Chehab","Pierre Ablin","Alexandre Gramfort","Aapo Hyvärinen"],"pdf_url":"https://arxiv.org/pdf/2502.20115v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.15589v4","updated":"2025-02-28T17:32:26Z","published":"2024-07-22T12:26:08Z","title":"Exploring the Effectiveness of Object-Centric Representations in Visual\n  Question Answering: Comparative Insights with Foundation Models","summary":"  Object-centric (OC) representations, which model visual scenes as\ncompositions of discrete objects, have the potential to be used in various\ndownstream tasks to achieve systematic compositional generalization and\nfacilitate reasoning. However, these claims have yet to be thoroughly validated\nempirically. Recently, foundation models have demonstrated unparalleled\ncapabilities across diverse domains, from language to computer vision,\npositioning them as a potential cornerstone of future research for a wide range\nof computational tasks. In this paper, we conduct an extensive empirical study\non representation learning for downstream Visual Question Answering (VQA),\nwhich requires an accurate compositional understanding of the scene. We\nthoroughly investigate the benefits and trade-offs of OC models and alternative\napproaches including large pre-trained foundation models on both synthetic and\nreal-world data, ultimately identifying a promising path to leverage the\nstrengths of both paradigms. The extensiveness of our study, encompassing over\n600 downstream VQA models and 15 different types of upstream representations,\nalso provides several additional insights that we believe will be of interest\nto the community at large.\n","authors":["Amir Mohammad Karimi Mamaghan","Samuele Papa","Karl Henrik Johansson","Stefan Bauer","Andrea Dittadi"],"pdf_url":"https://arxiv.org/pdf/2407.15589v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21256v1","updated":"2025-02-28T17:29:35Z","published":"2025-02-28T17:29:35Z","title":"ALVI Interface: Towards Full Hand Motion Decoding for Amputees Using\n  sEMG","summary":"  We present a system for decoding hand movements using surface EMG signals.\nThe interface provides real-time (25 Hz) reconstruction of finger joint angles\nacross 20 degrees of freedom, designed for upper limb amputees. Our offline\nanalysis shows 0.8 correlation between predicted and actual hand movements. The\nsystem functions as an integrated pipeline with three key components: (1) a\nVR-based data collection platform, (2) a transformer-based model for\nEMG-to-motion transformation, and (3) a real-time calibration and feedback\nmodule called ALVI Interface. Using eight sEMG sensors and a VR training\nenvironment, users can control their virtual hand down to finger joint movement\nprecision, as demonstrated in our video: youtube link.\n","authors":["Aleksandr Kovalev","Anna Makarova","Petr Chizhov","Matvey Antonov","Gleb Duplin","Vladislav Lomtev","Viacheslav Gostevskii","Vladimir Bessonov","Andrey Tsurkan","Mikhail Korobok","Aleksejs Timčenko"],"pdf_url":"https://arxiv.org/pdf/2502.21256v1.pdf","comment":"6 pages, video demo: https://youtu.be/Dx_6Id2clZ0?si=je2UYDDJ6VEFwLL8"},{"id":"http://arxiv.org/abs/2208.04284v5","updated":"2025-02-28T17:24:49Z","published":"2022-08-08T17:24:04Z","title":"On Rademacher Complexity-based Generalization Bounds for Deep Learning","summary":"  We show that the Rademacher complexity-based framework can establish\nnon-vacuous generalization bounds for Convolutional Neural Networks (CNNs) in\nthe context of classifying a small set of image classes. A key technical\nadvancement is the formulation of novel contraction lemmas for high-dimensional\nmappings between vector spaces, specifically designed for general Lipschitz\nactivation functions. These lemmas extend and refine the Talagrand contraction\nlemma across a broader range of scenarios. Our Rademacher complexity bound\nprovides an enhancement over the results presented by Golowich et al. for\nReLU-based Deep Neural Networks (DNNs). Moreover, while previous works\nutilizing Rademacher complexity have primarily focused on ReLU DNNs, our\nresults generalize to a wider class of activation functions.\n","authors":["Lan V. Truong"],"pdf_url":"https://arxiv.org/pdf/2208.04284v5.pdf","comment":"Updated new results and experiments (52 pages)"},{"id":"http://arxiv.org/abs/2502.21245v1","updated":"2025-02-28T17:14:44Z","published":"2025-02-28T17:14:44Z","title":"TimesBERT: A BERT-Style Foundation Model for Time Series Understanding","summary":"  Time series analysis is crucial in diverse scenarios. Beyond forecasting,\nconsiderable real-world tasks are categorized into classification, imputation,\nand anomaly detection, underscoring different capabilities termed time series\nunderstanding in this paper. While GPT-style models have been positioned as\nfoundation models for time series forecasting, the BERT-style architecture,\nwhich has made significant advances in natural language understanding, has not\nbeen fully unlocked for time series understanding, possibly attributed to the\nundesirable dropout of essential elements of BERT. In this paper, inspired by\nthe shared multi-granularity structure between multivariate time series and\nmultisentence documents, we design TimesBERT to learn generic representations\nof time series including temporal patterns and variate-centric characteristics.\nIn addition to a natural adaptation of masked modeling, we propose a parallel\ntask of functional token prediction to embody vital multi-granularity\nstructures. Our model is pre-trained on 260 billion time points across diverse\ndomains. Leveraging multi-granularity representations, TimesBERT achieves\nstate-of-the-art performance across four typical downstream understanding\ntasks, outperforming task-specific models and language pre-trained backbones,\npositioning it as a versatile foundation model for time series understanding.\n","authors":["Haoran Zhang","Yong Liu","Yunzhong Qiu","Haixuan Liu","Zhongyi Pei","Jianmin Wang","Mingsheng Long"],"pdf_url":"https://arxiv.org/pdf/2502.21245v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18148v3","updated":"2025-02-28T17:12:31Z","published":"2024-10-23T00:04:26Z","title":"Beyond the Kolmogorov Barrier: A Learnable Weighted Hybrid Autoencoder\n  for Model Order Reduction","summary":"  Representation learning for high-dimensional, complex physical systems aims\nto identify a low-dimensional intrinsic latent space, which is crucial for\nreduced-order modeling and modal analysis. To overcome the well-known\nKolmogorov barrier, deep autoencoders (AEs) have been introduced in recent\nyears, but they often suffer from poor convergence behavior as the rank of the\nlatent space increases. To address this issue, we propose the learnable\nweighted hybrid autoencoder, a hybrid approach that combines the strengths of\nsingular value decomposition (SVD) with deep autoencoders through a learnable\nweighted framework. We find that the introduction of learnable weighting\nparameters is essential -- without them, the resulting model would either\ncollapse into a standard POD or fail to exhibit the desired convergence\nbehavior. Interestingly, we empirically find that our trained model has a\nsharpness thousands of times smaller compared to other models. Our experiments\non classical chaotic PDE systems, including the 1D Kuramoto-Sivashinsky and\nforced isotropic turbulence datasets, demonstrate that our approach\nsignificantly improves generalization performance compared to several competing\nmethods. Additionally, when combining with time series modeling techniques\n(e.g., Koopman operator, LSTM), the proposed technique offers significant\nimprovements for surrogate modeling of high-dimensional multi-scale PDE\nsystems.\n","authors":["Nithin Somasekharan","Shaowu Pan"],"pdf_url":"https://arxiv.org/pdf/2410.18148v3.pdf","comment":"31 pages"},{"id":"http://arxiv.org/abs/2502.21240v1","updated":"2025-02-28T17:11:36Z","published":"2025-02-28T17:11:36Z","title":"The Structural Complexity of Matrix-Vector Multiplication","summary":"  We consider the problem of preprocessing an $n\\times n$ matrix M, and\nsupporting queries that, for any vector v, returns the matrix-vector product\nMv. This problem has been extensively studied in both theory and practice: on\none side, practitioners have developed algorithms that are highly efficient in\npractice, whereas theoreticians have proven that the problem cannot be solved\nfaster than naive multiplication in the worst-case. This lower bound holds even\nin the average-case, implying that existing average-case analyses cannot\nexplain this gap between theory and practice. Therefore, we study the problem\nfor structured matrices. We show that for $n\\times n$ matrices of VC-dimension\nd, the matrix-vector multiplication problem can be solved with $\\tilde{O}(n^2)$\npreprocessing and $\\tilde O(n^{2-1/d})$ query time. Given the low constant\nVC-dimensions observed in most real-world data, our results posit an\nexplanation for why the problem can be solved so much faster in practice.\nMoreover, our bounds hold even if the matrix does not have a low VC-dimension,\nbut is obtained by (possibly adversarially) corrupting at most a subquadratic\nnumber of entries of any unknown low VC-dimension matrix. Our results yield the\nfirst non-trivial upper bounds for many applications. In previous works, the\nonline matrix-vector hypothesis (conjecturing that quadratic time is needed per\nquery) was used to prove many conditional lower bounds, showing that it is\nimpossible to compute and maintain high-accuracy estimates for shortest paths,\nLaplacian solvers, effective resistance, and triangle detection in graphs\nsubject to node insertions and deletions in subquadratic time. Yet, via a\nreduction to our matrix-vector-multiplication result, we show we can maintain\nthe aforementioned problems efficiently if the input is structured, providing\nthe first subquadratic upper bounds in the high-accuracy regime.\n","authors":["Emile Anand","Jan van den Brand","Rose McCarty"],"pdf_url":"https://arxiv.org/pdf/2502.21240v1.pdf","comment":"36 pages"},{"id":"http://arxiv.org/abs/2405.04636v2","updated":"2025-02-28T17:10:30Z","published":"2024-05-07T19:38:26Z","title":"Data-driven Error Estimation: Upper Bounding Multiple Errors without\n  Class Complexity as Input","summary":"  Constructing confidence intervals that are simultaneously valid across a\nclass of estimates is central for tasks such as multiple mean estimation,\nbounding generalization error in machine learning, and adaptive experimental\ndesign. We frame this as an \"error estimation problem,\" where the goal is to\ndetermine a high-probability upper bound on the maximum error for a class of\nestimates. We propose an entirely data-driven approach that derives such bounds\nfor both finite and infinite class settings, naturally adapting to a\npotentially unknown correlation structure of random errors. Notably, our method\ndoes not require class complexity as an input, overcoming a major limitation of\nexisting approaches such as union bounding and bounds based on Talagrand's\ninequality. In this paper, we present our simple yet general solution and\ndemonstrate its flexibility through applications ranging from constructing\nmultiple simultaneously valid confidence intervals to optimizing exploration in\ncontextual bandit algorithms.\n","authors":["Sanath Kumar Krishnamurthy","Anan Lyubarskaja","Emma Brunskill","Susan Athey"],"pdf_url":"https://arxiv.org/pdf/2405.04636v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.13479v4","updated":"2025-02-28T17:07:42Z","published":"2024-08-24T05:38:31Z","title":"Quantum-machine-assisted Drug Discovery: Survey and Perspective","summary":"  Drug discovery and development is a highly complex and costly endeavor,\ntypically requiring over a decade and substantial financial investment to bring\na new drug to market. Traditional computer-aided drug design (CADD) has made\nsignificant progress in accelerating this process, but the development of\nquantum computing offers potential due to its unique capabilities. This paper\ndiscusses the integration of quantum computing into drug discovery and\ndevelopment, focusing on how quantum technologies might accelerate and enhance\nvarious stages of the drug development cycle. Specifically, we explore the\napplication of quantum computing in addressing challenges related to drug\ndiscovery, such as molecular simulation and the prediction of drug-target\ninteractions, as well as the optimization of clinical trial outcomes. By\nleveraging the inherent capabilities of quantum computing, we might be able to\nreduce the time and cost associated with bringing new drugs to market,\nultimately benefiting public health.\n","authors":["Yidong Zhou","Jintai Chen","Jinglei Cheng","Gopal Karemore","Marinka Zitnik","Frederic T. Chong","Junyu Liu","Tianfan Fu","Zhiding Liang"],"pdf_url":"https://arxiv.org/pdf/2408.13479v4.pdf","comment":"17 pages, 3 figures"},{"id":"http://arxiv.org/abs/2502.18394v3","updated":"2025-02-28T17:06:23Z","published":"2025-02-25T17:43:43Z","title":"The FFT Strikes Back: An Efficient Alternative to Self-Attention","summary":"  Conventional self-attention mechanisms incur quadratic complexity, limiting\ntheir scalability on long sequences. We introduce FFTNet, an adaptive spectral\nfiltering framework that leverages the Fast Fourier Transform (FFT) to achieve\nglobal token mixing in $\\mathcal{O}(n\\log n)$ time. By transforming inputs into\nthe frequency domain, FFTNet exploits the orthogonality and energy preservation\nguaranteed by Parseval's theorem to capture long-range dependencies\nefficiently. A learnable spectral filter and modReLU activation dynamically\nemphasize salient frequency components, providing a rigorous and adaptive\nalternative to traditional self-attention. Experiments on the Long Range Arena\nand ImageNet benchmarks validate our theoretical insights and demonstrate\nsuperior performance over fixed Fourier and standard attention models.\n","authors":["Jacob Fein-Ashley"],"pdf_url":"https://arxiv.org/pdf/2502.18394v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21231v1","updated":"2025-02-28T17:01:03Z","published":"2025-02-28T17:01:03Z","title":"ByteScale: Efficient Scaling of LLM Training with a 2048K Context Length\n  on More Than 12,000 GPUs","summary":"  Scaling long-context ability is essential for Large Language Models (LLMs).\nTo amortize the memory consumption across multiple devices in long-context\ntraining, inter-data partitioning (a.k.a. Data Parallelism) and intra-data\npartitioning (a.k.a. Context Parallelism) are commonly used. Current training\nframeworks predominantly treat the two techniques as orthogonal, and establish\nstatic communication groups to organize the devices as a static mesh (e.g., a\n2D mesh). However, the sequences for LLM training typically vary in lengths, no\nmatter for texts, multi-modalities or reinforcement learning. The mismatch\nbetween data heterogeneity and static mesh causes redundant communication and\nimbalanced computation, degrading the training efficiency.\n  In this work, we introduce ByteScale, an efficient, flexible, and scalable\nLLM training framework for large-scale mixed training of long and short\nsequences. The core of ByteScale is a novel parallelism strategy, namely Hybrid\nData Parallelism (HDP), which unifies the inter- and intra-data partitioning\nwith a dynamic mesh design. In particular, we build a communication optimizer,\nwhich eliminates the redundant communication for short sequences by data-aware\nsharding and dynamic communication, and further compresses the communication\ncost for long sequences by selective offloading. Besides, we also develop a\nbalance scheduler to mitigate the imbalanced computation by parallelism-aware\ndata assignment. We evaluate ByteScale with the model sizes ranging from 7B to\n141B, context lengths from 256K to 2048K, on a production cluster with more\nthan 12,000 GPUs. Experiment results show that ByteScale outperforms the\nstate-of-the-art training system by up to 7.89x.\n","authors":["Hao Ge","Junda Feng","Qi Huang","Fangcheng Fu","Xiaonan Nie","Lei Zuo","Haibin Lin","Bin Cui","Xin Liu"],"pdf_url":"https://arxiv.org/pdf/2502.21231v1.pdf","comment":"12 pages, 21 figures"},{"id":"http://arxiv.org/abs/2502.21229v1","updated":"2025-02-28T17:00:19Z","published":"2025-02-28T17:00:19Z","title":"A Method of Selective Attention for Reservoir Based Agents","summary":"  Training of deep reinforcement learning agents is slowed considerably by the\npresence of input dimensions that do not usefully condition the reward\nfunction. Existing modules such as layer normalization can be trained with\nweight decay to act as a form of selective attention, i.e. an input mask, that\nshrinks the scale of unnecessary inputs, which in turn accelerates training of\nthe policy. However, we find a surprising result that adding numerous\nparameters to the computation of the input mask results in much faster\ntraining. A simple, high dimensional masking module is compared with layer\nnormalization and a model without any input suppression. The high dimensional\nmask resulted in a four-fold speedup in training over the null hypothesis and a\ntwo-fold speedup in training over the layer normalization method.\n","authors":["Kevin McKee"],"pdf_url":"https://arxiv.org/pdf/2502.21229v1.pdf","comment":"6 pages, 2 figures"},{"id":"http://arxiv.org/abs/2406.07266v3","updated":"2025-02-28T16:56:08Z","published":"2024-06-11T13:51:51Z","title":"SemlaFlow -- Efficient 3D Molecular Generation with Latent Attention and\n  Equivariant Flow Matching","summary":"  Methods for jointly generating molecular graphs along with their 3D\nconformations have gained prominence recently due to their potential impact on\nstructure-based drug design. Current approaches, however, often suffer from\nvery slow sampling times or generate molecules with poor chemical validity.\nAddressing these limitations, we propose Semla, a scalable E(3)-equivariant\nmessage passing architecture. We further introduce an unconditional 3D\nmolecular generation model, SemlaFlow, which is trained using equivariant flow\nmatching to generate a joint distribution over atom types, coordinates, bond\ntypes and formal charges. Our model produces state-of-the-art results on\nbenchmark datasets with as few as 20 sampling steps, corresponding to a two\norder-of-magnitude speedup compared to state-of-the-art. Furthermore, we\nhighlight limitations of current evaluation methods for 3D generation and\npropose new benchmark metrics for unconditional molecular generators. Finally,\nusing these new metrics, we compare our model's ability to generate high\nquality samples against current approaches and further demonstrate SemlaFlow's\nstrong performance.\n","authors":["Ross Irwin","Alessandro Tibo","Jon Paul Janet","Simon Olsson"],"pdf_url":"https://arxiv.org/pdf/2406.07266v3.pdf","comment":"AISTATS 2025"},{"id":"http://arxiv.org/abs/2308.01170v3","updated":"2025-02-28T16:52:31Z","published":"2023-08-02T14:16:22Z","title":"Revisiting a Design Choice in Gradient Temporal Difference Learning","summary":"  Off-policy learning enables a reinforcement learning (RL) agent to reason\ncounterfactually about policies that are not executed and is one of the most\nimportant ideas in RL. It, however, can lead to instability when combined with\nfunction approximation and bootstrapping, two arguably indispensable\ningredients for large-scale reinforcement learning. This is the notorious\ndeadly triad. The seminal work Sutton et al. (2008) pioneers Gradient Temporal\nDifference learning (GTD) as the first solution to the deadly triad, which has\nenjoyed massive success thereafter. During the derivation of GTD, some\nintermediate algorithm, called $A^\\top$TD, was invented but soon deemed\ninferior. In this paper, we revisit this $A^\\top$TD and prove that a variant of\n$A^\\top$TD, called $A_t^\\top$TD, is also an effective solution to the deadly\ntriad. Furthermore, this $A_t^\\top$TD only needs one set of parameters and one\nlearning rate. By contrast, GTD has two sets of parameters and two learning\nrates, making it hard to tune in practice. We provide asymptotic analysis for\n$A^\\top_t$TD and finite sample analysis for a variant of $A^\\top_t$TD that\nadditionally involves a projection operator. The convergence rate of this\nvariant is on par with the canonical on-policy temporal difference learning.\n","authors":["Xiaochi Qian","Shangtong Zhang"],"pdf_url":"https://arxiv.org/pdf/2308.01170v3.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2410.20672v3","updated":"2025-02-28T16:44:24Z","published":"2024-10-28T02:15:45Z","title":"Relaxed Recursive Transformers: Effective Parameter Sharing with\n  Layer-wise LoRA","summary":"  Large language models (LLMs) are expensive to deploy. Parameter sharing\noffers a possible path towards reducing their size and cost, but its\neffectiveness in modern LLMs remains fairly limited. In this work, we revisit\n\"layer tying\" as form of parameter sharing in Transformers, and introduce novel\nmethods for converting existing LLMs into smaller \"Recursive Transformers\" that\nshare parameters across layers, with minimal loss of performance. Here, our\nRecursive Transformers are efficiently initialized from standard pretrained\nTransformers, but only use a single block of unique layers that is then\nrepeated multiple times in a loop. We further improve performance by\nintroducing Relaxed Recursive Transformers that add flexibility to the layer\ntying constraint via depth-wise low-rank adaptation (LoRA) modules, yet still\npreserve the compactness of the overall model. We show that our recursive\nmodels (e.g., recursive Gemma 1B) outperform both similar-sized vanilla\npretrained models (such as TinyLlama 1.1B and Pythia 1B) and knowledge\ndistillation baselines -- and can even recover most of the performance of the\noriginal \"full-size\" model (e.g., Gemma 2B with no shared parameters). Finally,\nwe propose Continuous Depth-wise Batching, a promising new inference paradigm\nenabled by the Recursive Transformer when paired with early exiting. In a\ntheoretical analysis, we show that this has the potential to lead to\nsignificant (2-3x) gains in inference throughput.\n","authors":["Sangmin Bae","Adam Fisch","Hrayr Harutyunyan","Ziwei Ji","Seungyeon Kim","Tal Schuster"],"pdf_url":"https://arxiv.org/pdf/2410.20672v3.pdf","comment":"ICLR 2025; 49 pages, 17 figures, 19 tables"},{"id":"http://arxiv.org/abs/2502.21212v1","updated":"2025-02-28T16:40:38Z","published":"2025-02-28T16:40:38Z","title":"Transformers Learn to Implement Multi-step Gradient Descent with Chain\n  of Thought","summary":"  Chain of Thought (CoT) prompting has been shown to significantly improve the\nperformance of large language models (LLMs), particularly in arithmetic and\nreasoning tasks, by instructing the model to produce intermediate reasoning\nsteps. Despite the remarkable empirical success of CoT and its theoretical\nadvantages in enhancing expressivity, the mechanisms underlying CoT training\nremain largely unexplored. In this paper, we study the training dynamics of\ntransformers over a CoT objective on an in-context weight prediction task for\nlinear regression. We prove that while a one-layer linear transformer without\nCoT can only implement a single step of gradient descent (GD) and fails to\nrecover the ground-truth weight vector, a transformer with CoT prompting can\nlearn to perform multi-step GD autoregressively, achieving near-exact recovery.\nFurthermore, we show that the trained transformer effectively generalizes on\nthe unseen data. With our technique, we also show that looped transformers\nsignificantly improve final performance compared to transformers without\nlooping in the in-context learning of linear regression. Empirically, we\ndemonstrate that CoT prompting yields substantial performance improvements.\n","authors":["Jianhao Huang","Zixuan Wang","Jason D. Lee"],"pdf_url":"https://arxiv.org/pdf/2502.21212v1.pdf","comment":"ICLR 2025 Spotlight"},{"id":"http://arxiv.org/abs/2411.00705v2","updated":"2025-02-28T16:31:57Z","published":"2024-11-01T16:09:33Z","title":"ReMatching Dynamic Reconstruction Flow","summary":"  Reconstructing a dynamic scene from image inputs is a fundamental computer\nvision task with many downstream applications. Despite recent advancements,\nexisting approaches still struggle to achieve high-quality reconstructions from\nunseen viewpoints and timestamps. This work introduces the ReMatching\nframework, designed to improve reconstruction quality by incorporating\ndeformation priors into dynamic reconstruction models. Our approach advocates\nfor velocity-field based priors, for which we suggest a matching procedure that\ncan seamlessly supplement existing dynamic reconstruction pipelines. The\nframework is highly adaptable and can be applied to various dynamic\nrepresentations. Moreover, it supports integrating multiple types of model\npriors and enables combining simpler ones to create more complex classes. Our\nevaluations on popular benchmarks involving both synthetic and real-world\ndynamic scenes demonstrate that augmenting current state-of-the-art methods\nwith our approach leads to a clear improvement in reconstruction accuracy.\n","authors":["Sara Oblak","Despoina Paschalidou","Sanja Fidler","Matan Atzmon"],"pdf_url":"https://arxiv.org/pdf/2411.00705v2.pdf","comment":"Our project website is at\n  https://research.nvidia.com/labs/toronto-ai/ReMatchingDynamicReconstructionFlow"},{"id":"http://arxiv.org/abs/2502.21208v1","updated":"2025-02-28T16:28:13Z","published":"2025-02-28T16:28:13Z","title":"ARIES: Autonomous Reasoning with LLMs on Interactive Thought Graph\n  Environments","summary":"  Recent research has shown that LLM performance on reasoning tasks can be\nenhanced by scaling test-time compute. One promising approach, particularly\nwith decomposable problems, involves arranging intermediate solutions as a\ngraph on which transformations are performed to explore the solution space.\nHowever, prior works rely on pre-determined, task-specific transformation\nschedules which are subject to a set of searched hyperparameters. In this work,\nwe view thought graph transformations as actions in a Markov decision process,\nand implement policy agents to drive effective action policies for the\nunderlying reasoning LLM agent. In particular, we investigate the ability for\nanother LLM to act as a policy agent on thought graph environments and\nintroduce ARIES, a multi-agent architecture for reasoning with LLMs. In ARIES,\nreasoning LLM agents solve decomposed subproblems, while policy LLM agents\nmaintain visibility of the thought graph states, and dynamically adapt the\nproblem-solving strategy. Through extensive experiments, we observe that using\noff-the-shelf LLMs as policy agents with no supervised fine-tuning (SFT) can\nyield up to $29\\%$ higher accuracy on HumanEval relative to static\ntransformation schedules, as well as reducing inference costs by $35\\%$ and\navoid any search requirements. We also conduct a thorough analysis of observed\nfailure modes, highlighting that limitations on LLM sizes and the depth of\nproblem decomposition can be seen as challenges to scaling LLM-guided\nreasoning.\n","authors":["Pedro Gimenes","Zeyu Cao","Jeffrey Wong","Yiren Zhao"],"pdf_url":"https://arxiv.org/pdf/2502.21208v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.03496v2","updated":"2025-02-28T16:27:44Z","published":"2024-12-04T17:36:47Z","title":"TRENDy: Temporal Regression of Effective Nonlinear Dynamics","summary":"  Spatiotemporal dynamics pervade the natural sciences, from the morphogen\ndynamics underlying patterning in animal pigmentation to the protein waves\ncontrolling cell division. A central challenge lies in understanding how\ncontrollable parameters induce qualitative changes in system behavior called\nbifurcations. This endeavor is particularly difficult in realistic settings\nwhere governing partial differential equations (PDEs) are unknown and data is\nlimited and noisy. To address this challenge, we propose TRENDy (Temporal\nRegression of Effective Nonlinear Dynamics), an equation-free approach to\nlearning low-dimensional, predictive models of spatiotemporal dynamics. TRENDy\nfirst maps input data to a low-dimensional space of effective dynamics through\na cascade of multiscale filtering operations. Our key insight is the\nrecognition that these effective dynamics can be fit by a neural ordinary\ndifferential equation (NODE) having the same parameter space as the input PDE.\nThe preceding filtering operations strongly regularize the phase space of the\nNODE, making TRENDy significantly more robust to noise compared to existing\nmethods. We train TRENDy to predict the effective dynamics of synthetic and\nreal data representing dynamics from across the physical and life sciences. We\nthen demonstrate how we can automatically locate both Turing and Hopf\nbifurcations in unseen regions of parameter space. We finally apply our method\nto the analysis of spatial patterning of the ocellated lizard through\ndevelopment. We found that TRENDy's predicted effective state not only\naccurately predicts spatial changes over time but also identifies distinct\npattern features unique to different anatomical regions, such as the tail,\nneck, and body--an insight that highlights the potential influence of surface\ngeometry on reaction-diffusion mechanisms and their role in driving spatially\nvarying pattern dynamics.\n","authors":["Matthew Ricci","Guy Pelc","Zoe Piran","Noa Moriel","Mor Nitzan"],"pdf_url":"https://arxiv.org/pdf/2412.03496v2.pdf","comment":"10 pages, 14 appendix pages, 5 figures, 7 appendix figures. Updated\n  to reflect acceptance at ICLR 2025. Minor formatting updates"},{"id":"http://arxiv.org/abs/2404.10512v3","updated":"2025-02-28T16:22:11Z","published":"2024-04-16T12:33:44Z","title":"Four-hour thunderstorm nowcasting using deep diffusion models of\n  satellite","summary":"  Convection (thunderstorm) develops rapidly within hours and is highly\ndestructive, posing a significant challenge for nowcasting and resulting in\nsubstantial losses to nature and society. After the emergence of artificial\nintelligence (AI)-based methods, convection nowcasting has experienced rapid\nadvancements, with its performance surpassing that of physics-based numerical\nweather prediction and other conventional approaches. However, the lead time\nand coverage of it still leave much to be desired and hardly meet the needs of\ndisaster emergency response. Here, we propose deep diffusion models of\nsatellite (DDMS) to establish an AI-based convection nowcasting system. On one\nhand, it employs diffusion processes to effectively simulate complicated\nspatiotemporal evolution patterns of convective clouds, significantly improving\nthe forecast lead time. On the other hand, it utilizes geostationary satellite\nbrightness temperature data, thereby achieving planetary-scale forecast\ncoverage. During long-term tests and objective validation based on the\nFengYun-4A satellite, our system achieves, for the first time, effective\nconvection nowcasting up to 4 hours, with broad coverage (about 20,000,000\nkm2), remarkable accuracy, and high resolution (15 minutes; 4 km). Its\nperformance reaches a new height in convection nowcasting compared to the\nexisting models. In terms of application, our system operates efficiently\n(forecasting 4 hours of convection in 8 minutes), and is highly transferable\nwith the potential to collaborate with multiple satellites for global\nconvection nowcasting. Furthermore, our results highlight the remarkable\ncapabilities of diffusion models in convective clouds forecasting, as well as\nthe significant value of geostationary satellite data when empowered by AI\ntechnologies.\n","authors":["Kuai Dai","Xutao Li","Junying Fang","Yunming Ye","Demin Yu","Hui Su","Di Xian","Danyu Qin","Jingsong Wang"],"pdf_url":"https://arxiv.org/pdf/2404.10512v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.19787v2","updated":"2025-02-28T16:20:03Z","published":"2025-02-27T05:52:06Z","title":"In-Context Learning with Hypothesis-Class Guidance","summary":"  Recent research has investigated the underlying mechanisms of in-context\nlearning (ICL) both theoretically and empirically, often using data generated\nfrom simple function classes. However, the existing work often focuses on the\nsequence consisting solely of labeled examples, while in practice, labeled\nexamples are typically accompanied by an instruction, providing some side\ninformation about the task. In this work, we propose ICL with hypothesis-class\nguidance (ICL-HCG), a novel synthetic data model for ICL where the input\ncontext consists of the literal description of a (finite) hypothesis class H\nand $(x,y)$ pairs from a hypothesis chosen from H. Under our framework ICL-HCG,\nwe conduct extensive experiments to explore: (i) a variety of generalization\nabilities to new hypothesis classes; (ii) different model architectures; (iii)\nsample complexity; (iv) in-context data imbalance; (v) the role of instruction;\nand (vi) the effect of pretraining hypothesis diversity. As a result, we show\nthat (a) Transformers can successfully learn ICL-HCG and generalize to unseen\nhypotheses and unseen hypothesis classes, and (b) compared with ICL without\ninstruction, ICL-HCG achieves significantly higher accuracy, demonstrating the\nrole of instructions.\n","authors":["Ziqian Lin","Shubham Kumar Bharti","Kangwook Lee"],"pdf_url":"https://arxiv.org/pdf/2502.19787v2.pdf","comment":"19 pages, 18 figures"},{"id":"http://arxiv.org/abs/2502.21196v1","updated":"2025-02-28T16:14:16Z","published":"2025-02-28T16:14:16Z","title":"AMPLE: Event-Driven Accelerator for Mixed-Precision Inference of Graph\n  Neural Networks","summary":"  Graph Neural Networks (GNNs) have recently gained attention due to their\nperformance on non-Euclidean data. The use of custom hardware architectures\nproves particularly beneficial for GNNs due to their irregular memory access\npatterns, resulting from the sparse structure of graphs. However, existing FPGA\naccelerators are limited by their double buffering mechanism, which doesn't\naccount for the irregular node distribution in typical graph datasets. To\naddress this, we introduce \\textbf{AMPLE} (Accelerated Message Passing Logic\nEngine), an FPGA accelerator leveraging a new event-driven programming flow. We\ndevelop a mixed-arithmetic architecture, enabling GNN inference to be quantized\nat a node-level granularity. Finally, prefetcher for data and instructions is\nimplemented to optimize off-chip memory access and maximize node parallelism.\nEvaluation on citation and social media graph datasets ranging from $2$K to\n$700$K nodes showed a mean speedup of $243\\times$ and $7.2\\times$ against CPU\nand GPU counterparts, respectively.\n","authors":["Pedro Gimenes","Yiren Zhao","George Constantinides"],"pdf_url":"https://arxiv.org/pdf/2502.21196v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21194v1","updated":"2025-02-28T16:12:53Z","published":"2025-02-28T16:12:53Z","title":"Class prior estimation for positive-unlabeled learning when label shift\n  occurs","summary":"  We study estimation of class prior for unlabeled target samples which is\npossibly different from that of source population. It is assumed that for the\nsource data only samples from positive class and from the whole population are\navailable (PU learning scenario). We introduce a novel direct estimator of\nclass prior which avoids estimation of posterior probabilities and has a simple\ngeometric interpretation. It is based on a distribution matching technique\ntogether with kernel embedding and is obtained as an explicit solution to an\noptimisation task. We establish its asymptotic consistency as well as a\nnon-asymptotic bound on its deviation from the unknown prior, which is\ncalculable in practice. We study finite sample behaviour for synthetic and real\ndata and show that the proposal, together with a suitably modified version for\nlarge values of source prior, works on par or better than its competitors.\n","authors":["Jan Mielniczuk","Wojciech Rejchel","Paweł Teisseyre"],"pdf_url":"https://arxiv.org/pdf/2502.21194v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18868v3","updated":"2025-02-28T16:12:10Z","published":"2024-10-24T15:53:21Z","title":"A Riemannian Framework for Learning Reduced-order Lagrangian Dynamics","summary":"  By incorporating physical consistency as inductive bias, deep neural networks\ndisplay increased generalization capabilities and data efficiency in learning\nnonlinear dynamic models. However, the complexity of these models generally\nincreases with the system dimensionality, requiring larger datasets, more\ncomplex deep networks, and significant computational effort. We propose a novel\ngeometric network architecture to learn physically-consistent reduced-order\ndynamic parameters that accurately describe the original high-dimensional\nsystem behavior. This is achieved by building on recent advances in model-order\nreduction and by adopting a Riemannian perspective to jointly learn a\nnon-linear structure-preserving latent space and the associated low-dimensional\ndynamics. Our approach enables accurate long-term predictions of the\nhigh-dimensional dynamics of rigid and deformable systems with increased data\nefficiency by inferring interpretable and physically-plausible reduced\nLagrangian models.\n","authors":["Katharina Friedl","Noémie Jaquier","Jens Lundell","Tamim Asfour","Danica Kragic"],"pdf_url":"https://arxiv.org/pdf/2410.18868v3.pdf","comment":"28 pages, 16 figures. Accepted for publication in ICLR'25"},{"id":"http://arxiv.org/abs/2502.21190v1","updated":"2025-02-28T16:06:11Z","published":"2025-02-28T16:06:11Z","title":"Geodesic Slice Sampler for Multimodal Distributions with Strong\n  Curvature","summary":"  Traditional Markov Chain Monte Carlo sampling methods often struggle with\nsharp curvatures, intricate geometries, and multimodal distributions. Slice\nsampling can resolve local exploration inefficiency issues and Riemannian\ngeometries help with sharp curvatures. Recent extensions enable slice sampling\non Riemannian manifolds, but they are restricted to cases where geodesics are\navailable in closed form. We propose a method that generalizes Hit-and-Run\nslice sampling to more general geometries tailored to the target distribution,\nby approximating geodesics as solutions to differential equations. Our approach\nenables exploration of regions with strong curvature and rapid transitions\nbetween modes in multimodal distributions. We demonstrate the advantages of the\napproach over challenging sampling problems.\n","authors":["Bernardo Williams","Hanlin Yu","Hoang Phuc Hau Luu","Georgios Arvanitidis","Arto Klami"],"pdf_url":"https://arxiv.org/pdf/2502.21190v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.10653v2","updated":"2025-02-28T16:04:54Z","published":"2024-09-16T18:45:07Z","title":"Logic Synthesis Optimization with Predictive Self-Supervision via Causal\n  Transformers","summary":"  Contemporary hardware design benefits from the abstraction provided by\nhigh-level logic gates, streamlining the implementation of logic circuits.\nLogic Synthesis Optimization (LSO) operates at one level of abstraction within\nthe Electronic Design Automation (EDA) workflow, targeting improvements in\nlogic circuits with respect to performance metrics such as size and speed in\nthe final layout. Recent trends in the field show a growing interest in\nleveraging Machine Learning (ML) for EDA, notably through ML-guided logic\nsynthesis utilizing policy-based Reinforcement Learning (RL) methods.Despite\nthese advancements, existing models face challenges such as overfitting and\nlimited generalization, attributed to constrained public circuits and the\nexpressiveness limitations of graph encoders. To address these hurdles, and\ntackle data scarcity issues, we introduce LSOformer, a novel approach\nharnessing Autoregressive transformer models and predictive SSL to predict the\ntrajectory of Quality of Results (QoR). LSOformer integrates cross-attention\nmodules to merge insights from circuit graphs and optimization sequences,\nthereby enhancing prediction accuracy for QoR metrics. Experimental studies\nvalidate the effectiveness of LSOformer, showcasing its superior performance\nover baseline architectures in QoR prediction tasks, where it achieves\nimprovements of 5.74%, 4.35%, and 17.06% on the EPFL, OABCD, and proprietary\ncircuits datasets, respectively, in inductive setup.\n","authors":["Raika Karimi","Faezeh Faez","Yingxue Zhang","Xing Li","Lei Chen","Mingxuan Yuan","Mahdi Biparva"],"pdf_url":"https://arxiv.org/pdf/2409.10653v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21187v1","updated":"2025-02-28T16:02:37Z","published":"2025-02-28T16:02:37Z","title":"SYN-LUNGS: Towards Simulating Lung Nodules with Anatomy-Informed Digital\n  Twins for AI Training","summary":"  AI models for lung cancer screening are limited by data scarcity, impacting\ngeneralizability and clinical applicability. Generative models address this\nissue but are constrained by training data variability. We introduce SYN-LUNGS,\na framework for generating high-quality 3D CT images with detailed annotations.\nSYN-LUNGS integrates XCAT3 phantoms for digital twin generation, X-Lesions for\nnodule simulation (varying size, location, and appearance), and DukeSim for CT\nimage formation with vendor and parameter variability. The dataset includes\n3,072 nodule images from 1,044 simulated CT scans, with 512 lesions and 174\ndigital twins. Models trained on clinical + simulated data outperform clinical\nonly models, achieving 10% improvement in detection, 2-9% in segmentation and\nclassification, and enhanced synthesis.By incorporating anatomy-informed\nsimulations, SYN-LUNGS provides a scalable approach for AI model development,\nparticularly in rare disease representation and improving model reliability.\n","authors":["Fakrul Islam Tushar","Lavsen Dahal","Cindy McCabe","Fong Chi Ho","Paul Segars","Ehsan Abadi","Kyle J. Lafata","Ehsan Samei","Joseph Y. Lo"],"pdf_url":"https://arxiv.org/pdf/2502.21187v1.pdf","comment":"6 figures, 12 pages"},{"id":"http://arxiv.org/abs/2412.05467v4","updated":"2025-02-28T16:02:27Z","published":"2024-12-06T23:43:59Z","title":"The BrowserGym Ecosystem for Web Agent Research","summary":"  The BrowserGym ecosystem addresses the growing need for efficient evaluation\nand benchmarking of web agents, particularly those leveraging automation and\nLarge Language Models (LLMs). Many existing benchmarks suffer from\nfragmentation and inconsistent evaluation methodologies, making it challenging\nto achieve reliable comparisons and reproducible results. In an earlier work,\nDrouin et al. (2024) introduced BrowserGym which aims to solve this by\nproviding a unified, gym-like environment with well-defined observation and\naction spaces, facilitating standardized evaluation across diverse benchmarks.\nWe propose an extended BrowserGym-based ecosystem for web agent research, which\nunifies existing benchmarks from the literature and includes AgentLab, a\ncomplementary framework that aids in agent creation, testing, and analysis. Our\nproposed ecosystem offers flexibility for integrating new benchmarks while\nensuring consistent evaluation and comprehensive experiment management. As a\nsupporting evidence, we conduct the first large-scale, multi-benchmark web\nagent experiment and compare the performance of 6 state-of-the-art LLMs across\n6 popular web agent benchmarks made available in BrowserGym. Among other\nfindings, our results highlight a large discrepancy between OpenAI and\nAnthropic's latests models, with Claude-3.5-Sonnet leading the way on almost\nall benchmarks, except on vision-related tasks where GPT-4o is superior.\nDespite these advancements, our results emphasize that building robust and\nefficient web agents remains a significant challenge, due to the inherent\ncomplexity of real-world web environments and the limitations of current\nmodels.\n","authors":["Thibault Le Sellier De Chezelles","Maxime Gasse","Alexandre Drouin","Massimo Caccia","Léo Boisvert","Megh Thakkar","Tom Marty","Rim Assouel","Sahar Omidi Shayegan","Lawrence Keunho Jang","Xing Han Lù","Ori Yoran","Dehan Kong","Frank F. Xu","Siva Reddy","Quentin Cappart","Graham Neubig","Ruslan Salakhutdinov","Nicolas Chapados","Alexandre Lacoste"],"pdf_url":"https://arxiv.org/pdf/2412.05467v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21186v1","updated":"2025-02-28T16:02:23Z","published":"2025-02-28T16:02:23Z","title":"Scalable Decision-Making in Stochastic Environments through Learned\n  Temporal Abstraction","summary":"  Sequential decision-making in high-dimensional continuous action spaces,\nparticularly in stochastic environments, faces significant computational\nchallenges. We explore this challenge in the traditional offline RL setting,\nwhere an agent must learn how to make decisions based on data collected through\na stochastic behavior policy. We present \\textit{Latent Macro Action Planner}\n(L-MAP), which addresses this challenge by learning a set of temporally\nextended macro-actions through a state-conditional Vector Quantized Variational\nAutoencoder (VQ-VAE), effectively reducing action dimensionality. L-MAP employs\na (separate) learned prior model that acts as a latent transition model and\nallows efficient sampling of plausible actions. During planning, our approach\naccounts for stochasticity in both the environment and the behavior policy by\nusing Monte Carlo tree search (MCTS). In offline RL settings, including\nstochastic continuous control tasks, L-MAP efficiently searches over discrete\nlatent actions to yield high expected returns. Empirical results demonstrate\nthat L-MAP maintains low decision latency despite increased action\ndimensionality. Notably, across tasks ranging from continuous control with\ninherently stochastic dynamics to high-dimensional robotic hand manipulation,\nL-MAP significantly outperforms existing model-based methods and performs\non-par with strong model-free actor-critic baselines, highlighting the\neffectiveness of the proposed approach in planning in complex and stochastic\nenvironments with high-dimensional action spaces.\n","authors":["Baiting Luo","Ava Pettet","Aron Laszka","Abhishek Dubey","Ayan Mukhopadhyay"],"pdf_url":"https://arxiv.org/pdf/2502.21186v1.pdf","comment":"Accepted by ICLR2025. Code would be available at\n  \\href{https://github.com/BaitingLuo/L-MAP.git}{this https URL}"},{"id":"http://arxiv.org/abs/2502.21183v1","updated":"2025-02-28T15:59:49Z","published":"2025-02-28T15:59:49Z","title":"HQColon: A Hybrid Interactive Machine Learning Pipeline for High Quality\n  Colon Labeling and Segmentation","summary":"  High-resolution colon segmentation is crucial for clinical and research\napplications, such as digital twins and personalized medicine. However, the\nleading open-source abdominal segmentation tool, TotalSegmentator, struggles\nwith accuracy for the colon, which has a complex and variable shape, requiring\ntime-intensive labeling. Here, we present the first fully automatic\nhigh-resolution colon segmentation method. To develop it, we first created a\nhigh resolution colon dataset using a pipeline that combines region growing\nwith interactive machine learning to efficiently and accurately label the colon\non CT colonography (CTC) images. Based on the generated dataset consisting of\n435 labeled CTC images we trained an nnU-Net model for fully automatic colon\nsegmentation. Our fully automatic model achieved an average symmetric surface\ndistance of 0.2 mm (vs. 4.0 mm from TotalSegmentator) and a 95th percentile\nHausdorff distance of 1.0 mm (vs. 18 mm from TotalSegmentator). Our\nsegmentation accuracy substantially surpasses TotalSegmentator. We share our\ntrained model and pipeline code, providing the first and only open-source tool\nfor high-resolution colon segmentation. Additionally, we created a large-scale\ndataset of publicly available high-resolution colon labels.\n","authors":["Martina Finocchiaro","Ronja Stern","Abraham George Smith","Jens Petersen","Kenny Erleben","Melanie Ganz"],"pdf_url":"https://arxiv.org/pdf/2502.21183v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21181v1","updated":"2025-02-28T15:58:21Z","published":"2025-02-28T15:58:21Z","title":"Reducing Reward Dependence in RL Through Adaptive Confidence Discounting","summary":"  In human-in-the-loop reinforcement learning or environments where calculating\na reward is expensive, the costly rewards can make learning efficiency\nchallenging to achieve. The cost of obtaining feedback from humans or\ncalculating expensive rewards means algorithms receiving feedback at every step\nof long training sessions may be infeasible, which may limit agents' abilities\nto efficiently improve performance. Our aim is to reduce the reliance of\nlearning agents on humans or expensive rewards, improving the efficiency of\nlearning while maintaining the quality of the learned policy. We offer a novel\nreinforcement learning algorithm that requests a reward only when its knowledge\nof the value of actions in an environment state is low. Our approach uses a\nreward function model as a proxy for human-delivered or expensive rewards when\nconfidence is high, and asks for those explicit rewards only when there is low\nconfidence in the model's predicted rewards and/or action selection. By\nreducing dependence on the expensive-to-obtain rewards, we are able to learn\nefficiently in settings where the logistics or expense of obtaining rewards may\notherwise prohibit it. In our experiments our approach obtains comparable\nperformance to a baseline in terms of return and number of episodes required to\nlearn, but achieves that performance with as few as 20% of the rewards.\n","authors":["Muhammed Yusuf Satici","David L. Roberts"],"pdf_url":"https://arxiv.org/pdf/2502.21181v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21171v1","updated":"2025-02-28T15:54:39Z","published":"2025-02-28T15:54:39Z","title":"QFAL: Quantum Federated Adversarial Learning","summary":"  Quantum federated learning (QFL) merges the privacy advantages of federated\nsystems with the computational potential of quantum neural networks (QNNs), yet\nits vulnerability to adversarial attacks remains poorly understood. This work\npioneers the integration of adversarial training into QFL, proposing a robust\nframework, quantum federated adversarial learning (QFAL), where clients\ncollaboratively defend against perturbations by combining local adversarial\nexample generation with federated averaging (FedAvg). We systematically\nevaluate the interplay between three critical factors: client count (5, 10,\n15), adversarial training coverage (0-100%), and adversarial attack\nperturbation strength (epsilon = 0.01-0.5), using the MNIST dataset. Our\nexperimental results show that while fewer clients often yield higher\nclean-data accuracy, larger federations can more effectively balance accuracy\nand robustness when partially adversarially trained. Notably, even limited\nadversarial coverage (e.g., 20%-50%) can significantly improve resilience to\nmoderate perturbations, though at the cost of reduced baseline performance.\nConversely, full adversarial training (100%) may regain high clean accuracy but\nis vulnerable under stronger attacks. These findings underscore an inherent\ntrade-off between robust and standard objectives, which is further complicated\nby quantum-specific factors. We conclude that a carefully chosen combination of\nclient count and adversarial coverage is critical for mitigating adversarial\nvulnerabilities in QFL. Moreover, we highlight opportunities for future\nresearch, including adaptive adversarial training schedules, more diverse\nquantum encoding schemes, and personalized defense strategies to further\nenhance the robustness-accuracy trade-off in real-world quantum federated\nenvironments.\n","authors":["Walid El Maouaki","Nouhaila Innan","Alberto Marchisio","Taoufik Said","Mohamed Bennai","Muhammad Shafique"],"pdf_url":"https://arxiv.org/pdf/2502.21171v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2502.13249v2","updated":"2025-02-28T15:54:08Z","published":"2025-02-18T19:21:10Z","title":"Evidence of Replica Symmetry Breaking under the Nishimori conditions in\n  epidemic inference on graphs","summary":"  In Bayesian inference, computing the posterior distribution from the data is\ntypically a non-trivial problem, which usually requires approximations such as\nmean-field approaches or numerical methods, like the Monte Carlo Markov Chain.\nBeing a high-dimensional distribution over a set of correlated variables, the\nposterior distribution can undergo the notorious replica symmetry breaking\ntransition. When it happens, several mean-field methods and virtually every\nMonte Carlo scheme can not provide a reasonable approximation to the posterior\nand its marginals. Replica symmetry is believed to be guaranteed whenever the\ndata is generated with known prior and likelihood distributions, namely under\nthe so-called Nishimori conditions. In this paper, we break this belief, by\nproviding a counter-example showing that, under the Nishimori conditions,\nreplica symmetry breaking arises. Introducing a simple, geometrical model that\ncan be thought of as a patient zero retrieval problem in a highly infectious\nregime of the epidemic Susceptible-Infectious model, we show that under the\nNishimori conditions, there is evidence of replica symmetry breaking. We\nachieve this result by computing the instability of the replica symmetric\ncavity method toward the one step replica symmetry broken phase. The origin of\nthis phenomenon -- replica symmetry breaking under the Nishimori conditions --\nis likely due to the correlated disorder appearing in the epidemic models.\n","authors":["Alfredo Braunstein","Louise Budzynski","Matteo Mariani","Federico Ricci-Tersenghi"],"pdf_url":"https://arxiv.org/pdf/2502.13249v2.pdf","comment":"17 pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.16593v2","updated":"2025-02-28T15:50:49Z","published":"2024-10-22T00:30:31Z","title":"Graph Sampling for Scalable and Expressive Graph Neural Networks on\n  Homophilic Graphs","summary":"  Graph Neural Networks (GNNs) excel in many graph machine learning tasks but\nface challenges when scaling to large networks. GNN transferability allows\ntraining on smaller graphs and applying the model to larger ones, but existing\nmethods often rely on random subsampling, leading to disconnected subgraphs and\nreduced model expressivity. We propose a novel graph sampling algorithm that\nleverages feature homophily to preserve graph structure. By minimizing the\ntrace of the data correlation matrix, our method better preserves the graph\nLaplacian trace -- a proxy for the graph connectivity -- than random sampling,\nwhile achieving lower complexity than spectral methods. Experiments on citation\nnetworks show improved performance in preserving Laplacian trace and GNN\ntransferability compared to random sampling.\n","authors":["Haolin Li","Haoyu Wang","Luana Ruiz"],"pdf_url":"https://arxiv.org/pdf/2410.16593v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21166v1","updated":"2025-02-28T15:50:10Z","published":"2025-02-28T15:50:10Z","title":"Autonomous Curriculum Design via Relative Entropy Based Task\n  Modifications","summary":"  Curriculum learning is a training method in which an agent is first trained\non a curriculum of relatively simple tasks related to a target task in an\neffort to shorten the time required to train on the target task. Autonomous\ncurriculum design involves the design of such curriculum with no reliance on\nhuman knowledge and/or expertise. Finding an efficient and effective way of\nautonomously designing curricula remains an open problem. We propose a novel\napproach for automatically designing curricula by leveraging the learner's\nuncertainty to select curricula tasks. Our approach measures the uncertainty in\nthe learner's policy using relative entropy, and guides the agent to states of\nhigh uncertainty to facilitate learning. Our algorithm supports the generation\nof autonomous curricula in a self-assessed manner by leveraging the learner's\npast and current policies but it also allows the use of teacher guided design\nin an instructive setting. We provide theoretical guarantees for the\nconvergence of our algorithm using two time-scale optimization processes.\nResults show that our algorithm outperforms randomly generated curriculum, and\nlearning directly on the target task as well as the curriculum-learning\ncriteria existing in literature. We also present two additional heuristic\ndistance measures that could be combined with our relative-entropy approach for\nfurther performance improvements.\n","authors":["Muhammed Yusuf Satici","Jianxun Wang","David L. Roberts"],"pdf_url":"https://arxiv.org/pdf/2502.21166v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21162v1","updated":"2025-02-28T15:42:33Z","published":"2025-02-28T15:42:33Z","title":"Parallel-Learning of Invariant and Tempo-variant Attributes of\n  Single-Lead Cardiac Signals: PLITA","summary":"  Wearable sensing devices, such as Holter monitors, will play a crucial role\nin the future of digital health. Unsupervised learning frameworks such as\nSelf-Supervised Learning (SSL) are essential to map these single-lead\nelectrocardiogram (ECG) signals with their anticipated clinical outcomes. These\nsignals are characterized by a tempo-variant component whose patterns evolve\nthrough the recording and an invariant component with patterns that remain\nunchanged. However, existing SSL methods only drive the model to encode the\ninvariant attributes, leading the model to neglect tempo-variant information\nwhich reflects subject-state changes through time. In this paper, we present\nParallel-Learning of Invariant and Tempo-variant Attributes (PLITA), a novel\nSSL method designed for capturing both invariant and tempo-variant ECG\nattributes. The latter are captured by mandating closer representations in\nspace for closer inputs on time. We evaluate both the capability of the method\nto learn the attributes of these two distinct kinds, as well as PLITA's\nperformance compared to existing SSL methods for ECG analysis. PLITA performs\nsignificantly better in the set-ups where tempo-variant attributes play a major\nrole.\n","authors":["Adtian Atienza","Jakob E. Bardram","Sadasivan Puthusserypady"],"pdf_url":"https://arxiv.org/pdf/2502.21162v1.pdf","comment":"Published in The 39th Annual AAAI Conference on Artificial\n  Intelligence. Main Track"},{"id":"http://arxiv.org/abs/2410.11843v3","updated":"2025-02-28T15:41:00Z","published":"2024-09-23T08:39:16Z","title":"From Commands to Prompts: LLM-based Semantic File System for AIOS","summary":"  Large language models (LLMs) have demonstrated significant potential in the\ndevelopment of intelligent applications and systems such as LLM-based agents\nand agent operating systems (AIOS). However, when these applications and\nsystems interact with the underlying file system, the file system still remains\nthe traditional paradigm: reliant on manual navigation through precise\ncommands. This paradigm poses a bottleneck to the usability of these systems as\nusers are required to navigate complex folder hierarchies and remember cryptic\nfile names. To address this limitation, we propose an LLM-based semantic file\nsystem ( LSFS ) for prompt-driven file management. Unlike conventional\napproaches, LSFS incorporates LLMs to enable users or agents to interact with\nfiles through natural language prompts, facilitating semantic file management.\nAt the macro-level, we develop a comprehensive API set to achieve semantic file\nmanagement functionalities, such as semantic file retrieval, file update\nmonitoring and summarization, and semantic file rollback). At the micro-level,\nwe store files by constructing semantic indexes for them, design and implement\nsyscalls of different semantic operations (e.g., CRUD, group by, join) powered\nby vector database. Our experiments show that LSFS offers significant\nimprovements over traditional file systems in terms of user convenience, the\ndiversity of supported functions, and the accuracy and efficiency of file\noperations. Additionally, with the integration of LLM, our system enables more\nintelligent file management tasks, such as content summarization and version\ncomparison, further enhancing its capabilities.\n","authors":["Zeru Shi","Kai Mei","Mingyu Jin","Yongye Su","Chaoji Zuo","Wenyue Hua","Wujiang Xu","Yujie Ren","Zirui Liu","Mengnan Du","Dong Deng","Yongfeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.11843v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.12457v2","updated":"2025-02-28T15:36:30Z","published":"2023-10-19T04:30:14Z","title":"MuseGNN: Forming Scalable, Convergent GNN Layers that Minimize a\n  Sampling-Based Energy","summary":"  Among the many variants of graph neural network (GNN) architectures capable\nof modeling data with cross-instance relations, an important subclass involves\nlayers designed such that the forward pass iteratively reduces a\ngraph-regularized energy function of interest. In this way, node embeddings\nproduced at the output layer dually serve as both predictive features for\nsolving downstream tasks (e.g., node classification) and energy function\nminimizers that inherit transparent, exploitable inductive biases and\ninterpretability. However, scaling GNN architectures constructed in this way\nremains challenging, in part because the convergence of the forward pass may\ninvolve models with considerable depth. To tackle this limitation, we propose a\nsampling-based energy function and scalable GNN layers that iteratively reduce\nit, guided by convergence guarantees in certain settings. We also instantiate a\nfull GNN architecture based on these designs, and the model achieves\ncompetitive accuracy and scalability when applied to the largest\npublicly-available node classification benchmark exceeding 1TB in size. Our\nsource code is available at https://github.com/haitian-jiang/MuseGNN.\n","authors":["Haitian Jiang","Renjie Liu","Zengfeng Huang","Yichuan Wang","Xiao Yan","Zhenkun Cai","Minjie Wang","David Wipf"],"pdf_url":"https://arxiv.org/pdf/2310.12457v2.pdf","comment":"Accepted by ICLR 2025"},{"id":"http://arxiv.org/abs/2405.02154v5","updated":"2025-02-28T15:35:46Z","published":"2024-05-03T15:02:21Z","title":"Neural Context Flows for Meta-Learning of Dynamical Systems","summary":"  Neural Ordinary Differential Equations (NODEs) often struggle to adapt to new\ndynamic behaviors caused by parameter changes in the underlying physical\nsystem, even when these dynamics are similar to previously observed behaviors.\nThis problem becomes more challenging when the changing parameters are\nunobserved, meaning their value or influence cannot be directly measured when\ncollecting data. To address this issue, we introduce Neural Context Flow (NCF),\na robust and interpretable Meta-Learning framework that includes uncertainty\nestimation. NCF uses Taylor expansion to enable contextual self-modulation,\nallowing context vectors to influence dynamics from other domains while also\nmodulating themselves. After establishing theoretical guarantees, we\nempirically test NCF and compare it to related adaptation methods. Our results\nshow that NCF achieves state-of-the-art Out-of-Distribution performance on 5\nout of 6 linear and non-linear benchmark problems. Through extensive\nexperiments, we explore the flexible model architecture of NCF and the encoded\nrepresentations within the learned context vectors. Our findings highlight the\npotential implications of NCF for foundational models in the physical sciences,\noffering a promising approach to improving the adaptability and generalization\nof NODEs in various scientific applications. Our code is openly available at\nhttps://github.com/ddrous/ncflow.\n","authors":["Roussel Desmond Nzoyem","David A. W. Barton","Tom Deakin"],"pdf_url":"https://arxiv.org/pdf/2405.02154v5.pdf","comment":"Accepted as a conference paper at ICLR 2025"},{"id":"http://arxiv.org/abs/2410.14270v2","updated":"2025-02-28T15:35:38Z","published":"2024-10-18T08:25:28Z","title":"FINDER: Stochastic Mirroring of Noisy Quasi-Newton Search and Deep\n  Network Training","summary":"  Our proposal is on a new stochastic optimizer for non-convex and possibly\nnon-smooth objective functions typically defined over large dimensional design\nspaces. Towards this, we have tried to bridge noise-assisted global search and\nfaster local convergence, the latter being the characteristic feature of a\nNewton-like search. Our specific scheme -- acronymed FINDER (Filtering Informed\nNewton-like and Derivative-free Evolutionary Recursion), exploits the nonlinear\nstochastic filtering equations to arrive at a derivative-free update that has\nresemblance with the Newton search employing the inverse Hessian of the\nobjective function. Following certain simplifications of the update to enable a\nlinear scaling with dimension and a few other enhancements, we apply FINDER to\na range of problems, starting with some IEEE benchmark objective functions to a\ncouple of archetypal data-driven problems in deep networks to certain cases of\nphysics-informed deep networks. The performance of the new method vis-\\'a-vis\nthe well-known Adam and a few others bears evidence to its promise and\npotentialities for large dimensional optimization problems of practical\ninterest.\n","authors":["Uttam Suman","Mariya Mamajiwala","Mukul Saxena","Ankit Tyagi","Debasish Roy"],"pdf_url":"https://arxiv.org/pdf/2410.14270v2.pdf","comment":"19 pages, 14 figures, 1 tables, 1 supplementary material. This work\n  has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2412.17107v2","updated":"2025-02-28T15:31:39Z","published":"2024-12-22T17:39:32Z","title":"Grams: Gradient Descent with Adaptive Momentum Scaling for Training\n  Large Language Models","summary":"  We introduce $\\mathbf{G}$radient Descent with $\\mathbf{A}$daptive\n$\\mathbf{M}$omentum $\\mathbf{S}$caling ($\\mathbf{Grams}$), a novel optimization\nalgorithm that decouples the direction and magnitude of parameter updates in\ndeep learning. Unlike traditional optimizers that directly integrate momentum\ninto updates, Grams separates the update direction, derived from current\ngradients, from momentum, which is used solely for adaptive magnitude scaling.\nThis approach enables Grams to achieve improved loss descent compared to\nstate-of-the-art cautious and momentum-based optimizers. We theoretically\ndemonstrate that Grams descents faster than other state-of-the-art optimizers\nand establish a global convergence guarantee for Grams. We also validate its\neffectiveness through extensive empirical evaluations. The results demonstrate\nGrams' superior performance, including faster convergence and better\ngeneralization, compared to widely-used optimizers such as Adam, Lion, and\ntheir cautious variants. Our results highlight Grams' potential as a\ntransformative approach for efficiently training large language models. Code is\navailable at\n$\\href{https://github.com/Gunale0926/Grams}{\\text{https://github.com/Gunale0926/Grams}}$.\n","authors":["Yang Cao","Xiaoyu Li","Zhao Song"],"pdf_url":"https://arxiv.org/pdf/2412.17107v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21147v1","updated":"2025-02-28T15:28:12Z","published":"2025-02-28T15:28:12Z","title":"Same accuracy, twice as fast: continuous training surpasses retraining\n  from scratch","summary":"  Continual learning aims to enable models to adapt to new datasets without\nlosing performance on previously learned data, often assuming that prior data\nis no longer available. However, in many practical scenarios, both old and new\ndata are accessible. In such cases, good performance on both datasets is\ntypically achieved by abandoning the model trained on the previous data and\nre-training a new model from scratch on both datasets. This training from\nscratch is computationally expensive. In contrast, methods that leverage the\npreviously trained model and old data are worthy of investigation, as they\ncould significantly reduce computational costs. Our evaluation framework\nquantifies the computational savings of such methods while maintaining or\nexceeding the performance of training from scratch. We identify key\noptimization aspects -- initialization, regularization, data selection, and\nhyper-parameters -- that can each contribute to reducing computational costs.\nFor each aspect, we propose effective first-step methods that already yield\nsubstantial computational savings. By combining these methods, we achieve up to\n2.7x reductions in computation time across various computer vision tasks,\nhighlighting the potential for further advancements in this area.\n","authors":["Eli Verwimp","Guy Hacohen","Tinne Tuytelaars"],"pdf_url":"https://arxiv.org/pdf/2502.21147v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21143v1","updated":"2025-02-28T15:26:10Z","published":"2025-02-28T15:26:10Z","title":"Variational Bayesian Pseudo-Coreset","summary":"  The success of deep learning requires large datasets and extensive training,\nwhich can create significant computational challenges. To address these\nchallenges, pseudo-coresets, small learnable datasets that mimic the entire\ndata, have been proposed. Bayesian Neural Networks, which offer predictive\nuncertainty and probabilistic interpretation for deep neural networks, also\nface issues with large-scale datasets due to their high-dimensional parameter\nspace. Prior works on Bayesian Pseudo-Coresets (BPC) attempt to reduce the\ncomputational load for computing weight posterior distribution by a small\nnumber of pseudo-coresets but suffer from memory inefficiency during BPC\ntraining and sub-optimal results. To overcome these limitations, we propose\nVariational Bayesian Pseudo-Coreset (VBPC), a novel approach that utilizes\nvariational inference to efficiently approximate the posterior distribution,\nreducing memory usage and computational costs while improving performance\nacross benchmark datasets.\n","authors":["Hyungi Lee","Seungyoo Lee","Juho Lee"],"pdf_url":"https://arxiv.org/pdf/2502.21143v1.pdf","comment":"The Thirteenth International Conference on Learning Representations\n  (ICLR2025)"},{"id":"http://arxiv.org/abs/2409.03550v2","updated":"2025-02-28T15:26:03Z","published":"2024-09-05T14:12:22Z","title":"DKDM: Data-Free Knowledge Distillation for Diffusion Models with Any\n  Architecture","summary":"  Diffusion models (DMs) have demonstrated exceptional generative capabilities\nacross various domains, including image, video, and so on. A key factor\ncontributing to their effectiveness is the high quantity and quality of data\nused during training. However, mainstream DMs now consume increasingly large\namounts of data. For example, training a Stable Diffusion model requires\nbillions of image-text pairs. This enormous data requirement poses significant\nchallenges for training large DMs due to high data acquisition costs and\nstorage expenses. To alleviate this data burden, we propose a novel scenario:\nusing existing DMs as data sources to train new DMs with any architecture. We\nrefer to this scenario as Data-Free Knowledge Distillation for Diffusion Models\n(DKDM), where the generative ability of DMs is transferred to new ones in a\ndata-free manner. To tackle this challenge, we make two main contributions.\nFirst, we introduce a DKDM objective that enables the training of new DMs via\ndistillation, without requiring access to the data. Second, we develop a\ndynamic iterative distillation method that efficiently extracts time-domain\nknowledge from existing DMs, enabling direct retrieval of training data without\nthe need for a prolonged generative process. To the best of our knowledge, we\nare the first to explore this scenario. Experimental results demonstrate that\nour data-free approach not only achieves competitive generative performance but\nalso, in some instances, outperforms models trained with the entire dataset.\n","authors":["Qianlong Xiang","Miao Zhang","Yuzhang Shang","Jianlong Wu","Yan Yan","Liqiang Nie"],"pdf_url":"https://arxiv.org/pdf/2409.03550v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21142v1","updated":"2025-02-28T15:24:17Z","published":"2025-02-28T15:24:17Z","title":"Multimodal Dreaming: A Global Workspace Approach to World Model-Based\n  Reinforcement Learning","summary":"  Humans leverage rich internal models of the world to reason about the future,\nimagine counterfactuals, and adapt flexibly to new situations. In Reinforcement\nLearning (RL), world models aim to capture how the environment evolves in\nresponse to the agent's actions, facilitating planning and generalization.\nHowever, typical world models directly operate on the environment variables\n(e.g. pixels, physical attributes), which can make their training slow and\ncumbersome; instead, it may be advantageous to rely on high-level latent\ndimensions that capture relevant multimodal variables. Global Workspace (GW)\nTheory offers a cognitive framework for multimodal integration and information\nbroadcasting in the brain, and recent studies have begun to introduce efficient\ndeep learning implementations of GW. Here, we evaluate the capabilities of an\nRL system combining GW with a world model. We compare our GW-Dreamer with\nvarious versions of the standard PPO and the original Dreamer algorithms. We\nshow that performing the dreaming process (i.e., mental simulation) inside the\nGW latent space allows for training with fewer environment steps. As an\nadditional emergent property, the resulting model (but not its comparison\nbaselines) displays strong robustness to the absence of one of its observation\nmodalities (images or simulation attributes). We conclude that the combination\nof GW with World Models holds great potential for improving decision-making in\nRL agents.\n","authors":["Léopold Maytié","Roland Bertin Johannet","Rufin VanRullen"],"pdf_url":"https://arxiv.org/pdf/2502.21142v1.pdf","comment":"Under review in a conference"},{"id":"http://arxiv.org/abs/2502.21138v1","updated":"2025-02-28T15:20:41Z","published":"2025-02-28T15:20:41Z","title":"Predicting clinical outcomes from patient care pathways represented with\n  temporal knowledge graphs","summary":"  Background: With the increasing availability of healthcare data, predictive\nmodeling finds many applications in the biomedical domain, such as the\nevaluation of the level of risk for various conditions, which in turn can guide\nclinical decision making. However, it is unclear how knowledge graph data\nrepresentations and their embedding, which are competitive in some settings,\ncould be of interest in biomedical predictive modeling. Method: We simulated\nsynthetic but realistic data of patients with intracranial aneurysm and\nexperimented on the task of predicting their clinical outcome. We compared the\nperformance of various classification approaches on tabular data versus a\ngraph-based representation of the same data. Next, we investigated how the\nadopted schema for representing first individual data and second temporal data\nimpacts predictive performances. Results: Our study illustrates that in our\ncase, a graph representation and Graph Convolutional Network (GCN) embeddings\nreach the best performance for a predictive task from observational data. We\nemphasize the importance of the adopted schema and of the consideration of\nliteral values in the representation of individual data. Our study also\nmoderates the relative impact of various time encoding on GCN performance.\n","authors":["Jong Ho Jhee","Alberto Megina","Pacôme Constant Dit Beaufils","Matilde Karakachoff","Richard Redon","Alban Gaignard","Adrien Coulet"],"pdf_url":"https://arxiv.org/pdf/2502.21138v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.17645v3","updated":"2025-02-28T15:16:36Z","published":"2024-11-26T18:10:51Z","title":"Explainable AI for Classifying UTI Risk Groups Using a Real-World Linked\n  EHR and Pathology Lab Dataset","summary":"  The use of machine learning and AI on electronic health records (EHRs) holds\nsubstantial potential for clinical insight. However, this approach faces\nchallenges due to data heterogeneity, sparsity, temporal misalignment, and\nlimited labeled outcomes. In this context, we leverage a linked EHR dataset of\napproximately one million de-identified individuals from Bristol, North\nSomerset, and South Gloucestershire, UK, to characterize urinary tract\ninfections (UTIs). We implemented a data pre-processing and curation pipeline\nthat transforms the raw EHR data into a structured format suitable for\ndeveloping predictive models focused on data fairness, accountability and\ntransparency. Given the limited availability and biases of ground truth UTI\noutcomes, we introduce a UTI risk estimation framework informed by clinical\nexpertise to estimate UTI risk across individual patient timelines. Pairwise\nXGBoost models are trained using this framework to differentiate UTI risk\ncategories with explainable AI techniques applied to identify key predictors\nand support interpretability. Our findings reveal differences in clinical and\ndemographic predictors across risk groups. While this study highlights the\npotential of AI-driven insights to support UTI clinical decision-making,\nfurther investigation of patient sub-strata and extensive validation are needed\nto ensure robustness and applicability in clinical practice.\n","authors":["Yujie Dai","Brian Sullivan","Axel Montout","Amy Dillon","Chris Waller","Peter Acs","Rachel Denholm","Philip Williams","Alastair D Hay","Raul Santos-Rodriguez","Andrew Dowsey"],"pdf_url":"https://arxiv.org/pdf/2411.17645v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.08587v2","updated":"2025-02-28T15:16:04Z","published":"2024-06-12T18:47:28Z","title":"CS-Bench: A Comprehensive Benchmark for Large Language Models towards\n  Computer Science Mastery","summary":"  Large language models (LLMs) have demonstrated significant potential in\nadvancing various fields of research and society. However, the current\ncommunity of LLMs overly focuses on benchmarks for analyzing specific\nfoundational skills (e.g. mathematics and code generation), neglecting an\nall-round evaluation of the computer science field. To bridge this gap, we\nintroduce CS-Bench, the first multilingual (English, Chinese, French, German)\nbenchmark dedicated to evaluating the performance of LLMs in computer science.\nCS-Bench comprises approximately 10K meticulously curated test samples,\ncovering 26 subfields across 4 key areas of computer science, encompassing\nvarious task forms and divisions of knowledge and reasoning. Utilizing\nCS-Bench, we conduct a comprehensive evaluation of over 30 mainstream LLMs,\nrevealing the relationship between CS performance and model scales. We also\nquantitatively analyze the reasons for failures in existing LLMs and highlight\ndirections for improvements, including knowledge supplementation and\nCS-specific reasoning. Further cross-capability experiments show a high\ncorrelation between LLMs' capabilities in computer science and their abilities\nin mathematics and coding. Moreover, expert LLMs specialized in mathematics and\ncoding also demonstrate strong performances in several CS subfields. Looking\nahead, we envision CS-Bench serving as a cornerstone for LLM applications in\nthe CS field and paving new avenues in assessing LLMs' diverse reasoning\ncapabilities. The CS-Bench data and evaluation code are available at\nhttps://github.com/csbench/csbench.\n","authors":["Xiaoshuai Song","Muxi Diao","Guanting Dong","Zhengyang Wang","Yujia Fu","Runqi Qiao","Zhexu Wang","Dayuan Fu","Huangxuan Wu","Bin Liang","Weihao Zeng","Yejie Wang","Zhuoma GongQue","Jianing Yu","Qiuna Tan","Weiran Xu"],"pdf_url":"https://arxiv.org/pdf/2406.08587v2.pdf","comment":"Accepted at ICLR 2025"},{"id":"http://arxiv.org/abs/2501.06842v2","updated":"2025-02-28T15:15:31Z","published":"2025-01-12T15:21:22Z","title":"SPAM: Spike-Aware Adam with Momentum Reset for Stable LLM Training","summary":"  Large Language Models (LLMs) have demonstrated exceptional performance across\ndiverse tasks, yet their training remains highly resource-intensive and\nsusceptible to critical challenges such as training instability. A predominant\nsource of this instability stems from gradient and loss spikes, which disrupt\nthe learning process, often leading to costly interventions like checkpoint\nrecovery and experiment restarts, further amplifying inefficiencies. This paper\npresents a comprehensive investigation into gradient spikes observed during LLM\ntraining, revealing their prevalence across multiple architectures and\ndatasets. Our analysis shows that these spikes can be up to $1000\\times$ larger\nthan typical gradients, substantially deteriorating model performance. To\naddress this issue, we propose Spike-Aware Adam with Momentum Reset SPAM, a\nnovel optimizer designed to counteract gradient spikes through momentum reset\nand spike-aware gradient clipping. Extensive experiments, including both\npre-training and fine-tuning, demonstrate that SPAM consistently surpasses Adam\nand its variants across various tasks, including (1) LLM pre-training from 60M\nto 1B, (2) 4-bit LLM pre-training,(3) reinforcement learning, and (4) Time\nSeries Forecasting. Additionally, SPAM facilitates memory-efficient training by\nenabling sparse momentum, where only a subset of momentum terms are maintained\nand updated. When operating under memory constraints, SPAM outperforms\nstate-of-the-art memory-efficient optimizers such as GaLore and Adam-Mini. Our\nwork underscores the importance of mitigating gradient spikes in LLM training\nand introduces an effective optimization strategy that enhances both training\nstability and resource efficiency at scale. Code is available at\nhttps://github.com/TianjinYellow/SPAM-Optimizer.git\n","authors":["Tianjin Huang","Ziquan Zhu","Gaojie Jin","Lu Liu","Zhangyang Wang","Shiwei Liu"],"pdf_url":"https://arxiv.org/pdf/2501.06842v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.15282v2","updated":"2025-02-28T15:11:44Z","published":"2025-01-25T17:31:56Z","title":"AutoG: Towards automatic graph construction from tabular data","summary":"  Recent years have witnessed significant advancements in graph machine\nlearning (GML), with its applications spanning numerous domains. However, the\nfocus of GML has predominantly been on developing powerful models, often\noverlooking a crucial initial step: constructing suitable graphs from common\ndata formats, such as tabular data. This construction process is fundamental to\napplying graph-based models, yet it remains largely understudied and lacks\nformalization. Our research aims to address this gap by formalizing the graph\nconstruction problem and proposing an effective solution. We identify two\ncritical challenges to achieve this goal: 1. The absence of dedicated datasets\nto formalize and evaluate the effectiveness of graph construction methods, and\n2. Existing automatic construction methods can only be applied to some specific\ncases, while tedious human engineering is required to generate high-quality\ngraphs. To tackle these challenges, we present a two-fold contribution. First,\nwe introduce a set of datasets to formalize and evaluate graph construction\nmethods. Second, we propose an LLM-based solution, AutoG, automatically\ngenerating high-quality graph schemas without human intervention. The\nexperimental results demonstrate that the quality of constructed graphs is\ncritical to downstream task performance, and AutoG can generate high-quality\ngraphs that rival those produced by human experts. Our code can be accessible\nfrom https://github.com/amazon-science/Automatic-Table-to-Graph-Generation.\n","authors":["Zhikai Chen","Han Xie","Jian Zhang","Xiang song","Jiliang Tang","Huzefa Rangwala","George Karypis"],"pdf_url":"https://arxiv.org/pdf/2501.15282v2.pdf","comment":"camera ready version"},{"id":"http://arxiv.org/abs/2502.21129v1","updated":"2025-02-28T15:10:00Z","published":"2025-02-28T15:10:00Z","title":"Microscopic Propagator Imaging (MPI) with Diffusion MRI","summary":"  We propose Microscopic Propagator Imaging (MPI) as a novel method to retrieve\nthe indices of the microscopic propagator which is the probability density\nfunction of water displacements due to diffusion within the nervous tissue\nmicrostructures. Unlike the Ensemble Average Propagator indices or the\nDiffusion Tensor Imaging metrics, MPI indices are independent from the\nmesoscopic organization of the tissue such as the presence of multiple axonal\nbundle directions and orientation dispersion. As a consequence, MPI indices are\nmore specific to the volumes, sizes, and types of microstructures, like axons\nand cells, that are present in the tissue. Thus, changes in MPI indices can be\nmore directly linked to alterations in the presence and integrity of\nmicrostructures themselves. The methodology behind MPI is rooted on zonal\nmodeling of spherical harmonics, signal simulation, and machine learning\nregression, and is demonstrated on both synthetic and Human Diffusion MRI data.\n","authors":["Tommaso Zajac","Gloria Menegaz","Marco Pizzolato"],"pdf_url":"https://arxiv.org/pdf/2502.21129v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.07486v2","updated":"2025-02-28T15:08:37Z","published":"2024-03-12T10:21:31Z","title":"XpertAI: uncovering regression model strategies for sub-manifolds","summary":"  In recent years, Explainable AI (XAI) methods have facilitated profound\nvalidation and knowledge extraction from ML models. While extensively studied\nfor classification, few XAI solutions have addressed the challenges specific to\nregression models. In regression, explanations need to be precisely formulated\nto address specific user queries (e.g.\\ distinguishing between `Why is the\noutput above 0?' and `Why is the output above 50?'). They should furthermore\nreflect the model's behavior on the relevant data sub-manifold. In this paper,\nwe introduce XpertAI, a framework that disentangles the prediction strategy\ninto multiple range-specific sub-strategies and allows the formulation of\nprecise queries about the model (the `explanandum') as a linear combination of\nthose sub-strategies. XpertAI is formulated generally to work alongside popular\nXAI attribution techniques, based on occlusion, gradient integration, or\nreverse propagation. Qualitative and quantitative results, demonstrate the\nbenefits of our approach.\n","authors":["Simon Letzgus","Klaus-Robert Müller","Grégoire Montavon"],"pdf_url":"https://arxiv.org/pdf/2403.07486v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21127v1","updated":"2025-02-28T15:07:40Z","published":"2025-02-28T15:07:40Z","title":"CuPID: Leveraging Masked Single-Lead ECG Modelling for Enhancing the\n  Representations","summary":"  Wearable sensing devices, such as Electrocardiogram (ECG) heart-rate\nmonitors, will play a crucial role in the future of digital health. This\ncontinuous monitoring leads to massive unlabeled data, incentivizing the\ndevelopment of unsupervised learning frameworks. While Masked Data Modelling\n(MDM) techniques have enjoyed wide use, their direct application to single-lead\nECG data is suboptimal due to the decoder's difficulty handling irregular\nheartbeat intervals when no contextual information is provided. In this paper,\nwe present Cueing the Predictor Increments the Detailing (CuPID), a novel MDM\nmethod tailored to single-lead ECGs. CuPID enhances existing MDM techniques by\ncueing spectrogram-derived context to the decoder, thus incentivizing the\nencoder to produce more detailed representations. This has a significant impact\non the encoder's performance across a wide range of different configurations,\nleading CuPID to outperform state-of-the-art methods in a variety of downstream\ntasks.\n","authors":["Adtian Atienza","Gouthamaan Manimaran","Jakob E. Bardram","Sadasivan Puthusserypady"],"pdf_url":"https://arxiv.org/pdf/2502.21127v1.pdf","comment":"Paper under review"},{"id":"http://arxiv.org/abs/2410.23046v2","updated":"2025-02-28T15:06:12Z","published":"2024-10-30T14:14:32Z","title":"Legitimate ground-truth-free metrics for deep uncertainty classification\n  scoring","summary":"  Despite the increasing demand for safer machine learning practices, the use\nof Uncertainty Quantification (UQ) methods in production remains limited. This\nlimitation is exacerbated by the challenge of validating UQ methods in absence\nof UQ ground truth. In classification tasks, when only a usual set of test data\nis at hand, several authors suggested different metrics that can be computed\nfrom such test points while assessing the quality of quantified uncertainties.\nThis paper investigates such metrics and proves that they are theoretically\nwell-behaved and actually tied to some uncertainty ground truth which is easily\ninterpretable in terms of model prediction trustworthiness ranking. Equipped\nwith those new results, and given the applicability of those metrics in the\nusual supervised paradigm, we argue that our contributions will help promoting\na broader use of UQ in deep learning.\n","authors":["Arthur Pignet","Chiara Regniez","John Klein"],"pdf_url":"https://arxiv.org/pdf/2410.23046v2.pdf","comment":"Accepted at AISTATS2025. Code is available at\n  https://github.com/owkin/legitimate-uq-metrics"},{"id":"http://arxiv.org/abs/2502.15215v3","updated":"2025-02-28T15:00:20Z","published":"2025-02-21T05:15:38Z","title":"Tensor Product Neural Networks for Functional ANOVA Model","summary":"  Interpretability for machine learning models is becoming more and more\nimportant as machine learning models become more complex. The functional ANOVA\nmodel, which decomposes a high-dimensional function into a sum of lower\ndimensional functions (commonly referred to as components), is one of the most\npopular tools for interpretable AI, and recently, various neural networks have\nbeen developed for estimating each component in the functional ANOVA model.\nHowever, such neural networks are highly unstable when estimating each\ncomponent since the components themselves are not uniquely defined. That is,\nthere are multiple functional ANOVA decompositions for a given function. In\nthis paper, we propose a novel neural network which guarantees a unique\nfunctional ANOVA decomposition and thus is able to estimate each component\nstably and accurately. We call our proposed neural network ANOVA Tensor Product\nNeural Network (ANOVA-TPNN) since it is motivated by the tensor product basis\nexpansion. Theoretically, we prove that ANOVA-TPNN can approximate any smooth\nfunction well. Empirically, we show that ANOVA-TPNN provide much more stable\nestimation of each component and thus much more stable interpretation when\ntraining data and initial values of the model parameters vary than existing\nneural networks do.\n","authors":["Seokhun Park","Insung Kong","Yongchan Choi","Chanmoo Park","Yongdai Kim"],"pdf_url":"https://arxiv.org/pdf/2502.15215v3.pdf","comment":"45 pages"},{"id":"http://arxiv.org/abs/2502.21123v1","updated":"2025-02-28T14:57:33Z","published":"2025-02-28T14:57:33Z","title":"Causality Is Key to Understand and Balance Multiple Goals in Trustworthy\n  ML and Foundation Models","summary":"  Ensuring trustworthiness in machine learning (ML) systems is crucial as they\nbecome increasingly embedded in high-stakes domains. This paper advocates for\nthe integration of causal methods into machine learning to navigate the\ntrade-offs among key principles of trustworthy ML, including fairness, privacy,\nrobustness, accuracy, and explainability. While these objectives should ideally\nbe satisfied simultaneously, they are often addressed in isolation, leading to\nconflicts and suboptimal solutions. Drawing on existing applications of\ncausality in ML that successfully align goals such as fairness and accuracy or\nprivacy and robustness, this paper argues that a causal approach is essential\nfor balancing multiple competing objectives in both trustworthy ML and\nfoundation models. Beyond highlighting these trade-offs, we examine how\ncausality can be practically integrated into ML and foundation models, offering\nsolutions to enhance their reliability and interpretability. Finally, we\ndiscuss the challenges, limitations, and opportunities in adopting causal\nframeworks, paving the way for more accountable and ethically sound AI systems.\n","authors":["Ruta Binkyte","Ivaxi Sheth","Zhijing Jin","Muhammad Havaei","Bernhardt Schölkopf","Mario Fritz"],"pdf_url":"https://arxiv.org/pdf/2502.21123v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.11977v3","updated":"2025-02-28T14:56:10Z","published":"2024-10-15T18:33:42Z","title":"Generative AI Policies under the Microscope: How CS Conferences Are\n  Navigating the New Frontier in Scholarly Writing","summary":"  As the use of Generative AI (Gen-AI) in scholarly writing and peer reviews\ncontinues to rise, it is essential for the computing field to establish and\nadopt clear Gen-AI policies. This study examines the landscape of Gen-AI\npolicies across 64 major Computer Science conferences and offers\nrecommendations for promoting more effective and responsible use of Gen-AI in\nthe field.\n","authors":["Mahjabin Nahar","Sian Lee","Rebekah Guillen","Dongwon Lee"],"pdf_url":"https://arxiv.org/pdf/2410.11977v3.pdf","comment":"Accepted and to appear in Communications of the ACM (CACM) in 2025"},{"id":"http://arxiv.org/abs/2502.21116v1","updated":"2025-02-28T14:53:43Z","published":"2025-02-28T14:53:43Z","title":"The two filter formula reconsidered: Smoothing in partially observed\n  Gauss--Markov models without information parametrization","summary":"  In this article, the two filter formula is re-examined in the setting of\npartially observed Gauss--Markov models. It is traditionally formulated as a\nfilter running backward in time, where the Gaussian density is parametrized in\n``information form''. However, the quantity in the backward recursion is\nstrictly speaking not a distribution, but a likelihood. Taking this observation\nseriously, a recursion over log-quadratic likelihoods is formulated instead,\nwhich obviates the need for ``information'' parametrization. In particular, it\ngreatly simplifies the square-root formulation of the algorithm. Furthermore,\nformulae are given for producing the forward Markov representation of the a\nposteriori distribution over paths from the proposed likelihood representation.\n","authors":["Filip Tronarp"],"pdf_url":"https://arxiv.org/pdf/2502.21116v1.pdf","comment":"14 pages, 2 figures"},{"id":"http://arxiv.org/abs/2305.15557v5","updated":"2025-02-28T14:53:37Z","published":"2023-05-24T20:43:47Z","title":"Non-Parametric Learning of Stochastic Differential Equations with\n  Non-asymptotic Fast Rates of Convergence","summary":"  We propose a novel non-parametric learning paradigm for the identification of\ndrift and diffusion coefficients of multi-dimensional non-linear stochastic\ndifferential equations, which relies upon discrete-time observations of the\nstate. The key idea essentially consists of fitting a RKHS-based approximation\nof the corresponding Fokker-Planck equation to such observations, yielding\ntheoretical estimates of non-asymptotic learning rates which, unlike previous\nworks, become increasingly tighter when the regularity of the unknown drift and\ndiffusion coefficients becomes higher. Our method being kernel-based, offline\npre-processing may be profitably leveraged to enable efficient numerical\nimplementation, offering excellent balance between precision and computational\ncomplexity.\n","authors":["Riccardo Bonalli","Alessandro Rudi"],"pdf_url":"https://arxiv.org/pdf/2305.15557v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.18540v2","updated":"2025-02-28T14:49:25Z","published":"2024-05-28T19:16:17Z","title":"Learning diverse attacks on large language models for robust red-teaming\n  and safety tuning","summary":"  Red-teaming, or identifying prompts that elicit harmful responses, is a\ncritical step in ensuring the safe and responsible deployment of large language\nmodels (LLMs). Developing effective protection against many modes of attack\nprompts requires discovering diverse attacks. Automated red-teaming typically\nuses reinforcement learning to fine-tune an attacker language model to generate\nprompts that elicit undesirable responses from a target LLM, as measured, for\nexample, by an auxiliary toxicity classifier. We show that even with explicit\nregularization to favor novelty and diversity, existing approaches suffer from\nmode collapse or fail to generate effective attacks. As a flexible and\nprobabilistically principled alternative, we propose to use GFlowNet\nfine-tuning, followed by a secondary smoothing phase, to train the attacker\nmodel to generate diverse and effective attack prompts. We find that the\nattacks generated by our method are effective against a wide range of target\nLLMs, both with and without safety tuning, and transfer well between target\nLLMs. Finally, we demonstrate that models safety-tuned using a dataset of\nred-teaming prompts generated by our method are robust to attacks from other\nRL-based red-teaming approaches.\n","authors":["Seanie Lee","Minsu Kim","Lynn Cherif","David Dobre","Juho Lee","Sung Ju Hwang","Kenji Kawaguchi","Gauthier Gidel","Yoshua Bengio","Nikolay Malkin","Moksh Jain"],"pdf_url":"https://arxiv.org/pdf/2405.18540v2.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2502.21110v1","updated":"2025-02-28T14:47:52Z","published":"2025-02-28T14:47:52Z","title":"Rare event modeling with self-regularized normalizing flows: what can we\n  learn from a single failure?","summary":"  Increased deployment of autonomous systems in fields like transportation and\nrobotics have seen a corresponding increase in safety-critical failures. These\nfailures can be difficult to model and debug due to the relative lack of data:\ncompared to tens of thousands of examples from normal operations, we may have\nonly seconds of data leading up to the failure. This scarcity makes it\nchallenging to train generative models of rare failure events, as existing\nmethods risk either overfitting to noise in the limited failure dataset or\nunderfitting due to an overly strong prior. We address this challenge with\nCalNF, or calibrated normalizing flows, a self-regularized framework for\nposterior learning from limited data. CalNF achieves state-of-the-art\nperformance on data-limited failure modeling and inverse problems and enables a\nfirst-of-a-kind case study into the root causes of the 2022 Southwest Airlines\nscheduling crisis.\n","authors":["Charles Dawson","Van Tran","Max Z. Li","Chuchu Fan"],"pdf_url":"https://arxiv.org/pdf/2502.21110v1.pdf","comment":"Published at ICLR 2025"},{"id":"http://arxiv.org/abs/2406.04755v4","updated":"2025-02-28T14:41:16Z","published":"2024-06-07T08:54:55Z","title":"LLM Whisperer: An Inconspicuous Attack to Bias LLM Responses","summary":"  Writing effective prompts for large language models (LLM) can be unintuitive\nand burdensome. In response, services that optimize or suggest prompts have\nemerged. While such services can reduce user effort, they also introduce a\nrisk: the prompt provider can subtly manipulate prompts to produce heavily\nbiased LLM responses. In this work, we show that subtle synonym replacements in\nprompts can increase the likelihood (by a difference up to 78%) that LLMs\nmention a target concept (e.g., a brand, political party, nation). We\nsubstantiate our observations through a user study, showing that our\nadversarially perturbed prompts 1) are indistinguishable from unaltered prompts\nby humans, 2) push LLMs to recommend target concepts more often, and 3) make\nusers more likely to notice target concepts, all without arousing suspicion.\nThe practicality of this attack has the potential to undermine user autonomy.\nAmong other measures, we recommend implementing warnings against using prompts\nfrom untrusted parties.\n","authors":["Weiran Lin","Anna Gerchanovsky","Omer Akgul","Lujo Bauer","Matt Fredrikson","Zifan Wang"],"pdf_url":"https://arxiv.org/pdf/2406.04755v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.11540v2","updated":"2025-02-28T14:35:58Z","published":"2024-10-15T12:14:57Z","title":"Data Quality Control in Federated Instruction-tuning of Large Language\n  Models","summary":"  Federated Learning (FL) enables privacy-preserving collaborative instruction\ntuning of large language models (LLMs) by leveraging massively distributed\ndata. However, the decentralized nature of FL exacerbates data quality\nchallenges, as local clients lack global visibility to filter noisy or\nlow-quality samples before training. To resolve this issue, we propose FedDQC,\na novel federated instruction tuning framework with dynamic data quality\ncontrol. Our approach introduces two key innovations. First, we propose\ninstruction-response alignment (IRA), an efficient client-side metric for\nquality evaluation requiring only low-cost inference. We validate that\nhigher-IRA data corresponds to more relevant and easier-to-learn\nquestion-answer pairs. Second, mirroring the human easy-to-hard knowledge\nacquisition process, we design a quality-aware hierarchical FL training\nframework, where the LLM is progressively fine-tuned from high- to low-IRA data\nin a collaborative manner. The framework also supports adaptive data quality\nassessment at each hierarchy, enabling dynamic adjustments throughout the\ntraining process. Extensive experiments on synthetic and real-world datasets\nshow that our method significantly improves LLM performance on mixed-quality\ndata in FL.\n","authors":["Yaxin Du","Rui Ye","Fengting Yuchi","Wanru Zhao","Jingjing Qu","Yanfeng Wang","Siheng Chen"],"pdf_url":"https://arxiv.org/pdf/2410.11540v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.07594v3","updated":"2025-02-28T14:24:39Z","published":"2024-02-12T11:48:54Z","title":"Zero-shot Imputation with Foundation Inference Models for Dynamical\n  Systems","summary":"  Dynamical systems governed by ordinary differential equations (ODEs) serve as\nmodels for a vast number of natural and social phenomena. In this work, we\noffer a fresh perspective on the classical problem of imputing missing time\nseries data, whose underlying dynamics are assumed to be determined by ODEs.\nSpecifically, we revisit ideas from amortized inference and neural operators,\nand propose a novel supervised learning framework for zero-shot time series\nimputation, through parametric functions satisfying some (hidden) ODEs. Our\nproposal consists of two components. First, a broad probability distribution\nover the space of ODE solutions, observation times and noise mechanisms, with\nwhich we generate a large, synthetic dataset of (hidden) ODE solutions, along\nwith their noisy and sparse observations. Second, a neural recognition model\nthat is trained offline, to map the generated time series onto the spaces of\ninitial conditions and time derivatives of the (hidden) ODE solutions, which we\nthen integrate to impute the missing data. We empirically demonstrate that one\nand the same (pretrained) recognition model can perform zero-shot imputation\nacross 63 distinct time series with missing values, each sampled from widely\ndifferent dynamical systems. Likewise, we demonstrate that it can perform\nzero-shot imputation of missing high-dimensional data in 10 vastly different\nsettings, spanning human motion, air quality, traffic and electricity studies,\nas well as Navier-Stokes simulations -- without requiring any fine-tuning. What\nis more, our proposal often outperforms state-of-the-art methods, which are\ntrained on the target datasets.\n  Our pretrained model, repository and tutorials are available online.\n","authors":["Patrick Seifner","Kostadin Cvejoski","Antonia Körner","Ramsés J. Sánchez"],"pdf_url":"https://arxiv.org/pdf/2402.07594v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.18934v3","updated":"2025-02-28T14:23:16Z","published":"2025-02-26T08:36:20Z","title":"Kanana: Compute-efficient Bilingual Language Models","summary":"  We introduce Kanana, a series of bilingual language models that demonstrate\nexceeding performance in Korean and competitive performance in English. The\ncomputational cost of Kanana is significantly lower than that of\nstate-of-the-art models of similar size. The report details the techniques\nemployed during pre-training to achieve compute-efficient yet competitive\nmodels, including high quality data filtering, staged pre-training, depth\nup-scaling, and pruning and distillation. Furthermore, the report outlines the\nmethodologies utilized during the post-training of the Kanana models,\nencompassing supervised fine-tuning and preference optimization, aimed at\nenhancing their capability for seamless interaction with users. Lastly, the\nreport elaborates on plausible approaches used for language model adaptation to\nspecific scenarios, such as embedding, retrieval augmented generation, and\nfunction calling. The Kanana model series spans from 2.1B to 32.5B parameters\nwith 2.1B models (base, instruct, embedding) publicly released to promote\nresearch on Korean language models.\n","authors":[" Kanana LLM Team","Yunju Bak","Hojin Lee","Minho Ryu","Jiyeon Ham","Seungjae Jung","Daniel Wontae Nam","Taegyeong Eo","Donghun Lee","Doohae Jung","Boseop Kim","Nayeon Kim","Jaesun Park","Hyunho Kim","Hyunwoong Ko","Changmin Lee","Kyoung-Woon On","Seulye Baeg","Junrae Cho","Sunghee Jung","Jieun Kang","EungGyun Kim","Eunhwa Kim","Byeongil Ko","Daniel Lee","Minchul Lee","Miok Lee","Shinbok Lee","Gaeun Seo"],"pdf_url":"https://arxiv.org/pdf/2502.18934v3.pdf","comment":"40 pages, 15 figures"},{"id":"http://arxiv.org/abs/2502.21086v1","updated":"2025-02-28T14:21:34Z","published":"2025-02-28T14:21:34Z","title":"Are foundation models useful feature extractors for\n  electroencephalography analysis?","summary":"  The success of foundation models in natural language processing and computer\nvision has motivated similar approaches for general time series analysis. While\nthese models are effective for a variety of tasks, their applicability in\nmedical domains with limited data remains largely unexplored. To address this,\nwe investigate the effectiveness of foundation models in medical time series\nanalysis involving electroencephalography (EEG). Through extensive experiments\non tasks such as age prediction, seizure detection, and the classification of\nclinically relevant EEG events, we compare their diagnostic accuracy with that\nof specialised EEG models. Our analysis shows that foundation models extract\nmeaningful EEG features, outperform specialised models even without domain\nadaptation, and localise task-specific biomarkers. Moreover, we demonstrate\nthat diagnostic accuracy is substantially influenced by architectural choices\nsuch as context length. Overall, our study reveals that foundation models with\ngeneral time series understanding eliminate the dependency on large\ndomain-specific datasets, making them valuable tools for clinical practice.\n","authors":["Özgün Turgut","Felix S. Bott","Markus Ploner","Daniel Rueckert"],"pdf_url":"https://arxiv.org/pdf/2502.21086v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04779v2","updated":"2025-02-28T14:20:04Z","published":"2024-10-07T06:38:43Z","title":"Fast Training of Sinusoidal Neural Fields via Scaling Initialization","summary":"  Neural fields are an emerging paradigm that represent data as continuous\nfunctions parameterized by neural networks. Despite many advantages, neural\nfields often have a high training cost, which prevents a broader adoption. In\nthis paper, we focus on a popular family of neural fields, called sinusoidal\nneural fields (SNFs), and study how it should be initialized to maximize the\ntraining speed. We find that the standard initialization scheme for SNFs --\ndesigned based on the signal propagation principle -- is suboptimal. In\nparticular, we show that by simply multiplying each weight (except for the last\nlayer) by a constant, we can accelerate SNF training by 10$\\times$. This\nmethod, coined $\\textit{weight scaling}$, consistently provides a significant\nspeedup over various data domains, allowing the SNFs to train faster than more\nrecently proposed architectures. To understand why the weight scaling works\nwell, we conduct extensive theoretical and empirical analyses which reveal that\nthe weight scaling not only resolves the spectral bias quite effectively but\nalso enjoys a well-conditioned optimization trajectory.\n","authors":["Taesun Yeom","Sangyoon Lee","Jaeho Lee"],"pdf_url":"https://arxiv.org/pdf/2410.04779v2.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2409.16767v2","updated":"2025-02-28T14:19:00Z","published":"2024-09-25T09:26:06Z","title":"Exploring Information-Theoretic Metrics Associated with Neural Collapse\n  in Supervised Training","summary":"  In this paper, we introduce matrix entropy as an analytical tool for studying\nsupervised learning, investigating the information content of data\nrepresentations and classification head vectors, as well as the dynamic\ninteractions between them during the supervised learning process. Our\nexperimental results reveal that matrix entropy effectively captures the\nvariations in information content of data representations and classification\nhead vectors as neural networks approach Neural Collapse during supervised\ntraining, while also serving as a robust metric for measuring similarity among\ndata samples. Leveraging this property, we propose Cross-Model Alignment (CMA)\nloss to optimize the fine-tuning of pretrained models. To characterize the\ndynamics of neural networks nearing the Neural Collapse state, we introduce two\nnovel metrics: the Matrix Mutual Information Ratio (MIR) and the Matrix Entropy\nDifference Ratio (HDR), which quantitatively assess the interactions between\ndata representations and classification heads in supervised learning, with\ntheoretical optimal values derived under the Neural Collapse state. Our\nexperiments demonstrate that MIR and HDR effectively explain various phenomena\nin neural networks, including the dynamics of standard supervised training,\nlinear mode connectivity. Moreover, we use MIR and HDR to analyze the dynamics\nof grokking, which is a fascinating phenomenon in supervised learning where a\nmodel unexpectedly exhibits generalization long after achieving training data\nfit.\n","authors":["Kun Song","Zhiquan Tan","Bochao Zou","Jiansheng Chen","Huimin Ma","Weiran Huang"],"pdf_url":"https://arxiv.org/pdf/2409.16767v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2406.03999"},{"id":"http://arxiv.org/abs/2502.21075v1","updated":"2025-02-28T14:08:30Z","published":"2025-02-28T14:08:30Z","title":"Spatial Reasoning with Denoising Models","summary":"  We introduce Spatial Reasoning Models (SRMs), a framework to perform\nreasoning over sets of continuous variables via denoising generative models.\nSRMs infer continuous representations on a set of unobserved variables, given\nobservations on observed variables. Current generative models on spatial\ndomains, such as diffusion and flow matching models, often collapse to\nhallucination in case of complex distributions. To measure this, we introduce a\nset of benchmark tasks that test the quality of complex reasoning in generative\nmodels and can quantify hallucination. The SRM framework allows to report key\nfindings about importance of sequentialization in generation, the associated\norder, as well as the sampling strategies during training. It demonstrates, for\nthe first time, that order of generation can successfully be predicted by the\ndenoising network itself. Using these findings, we can increase the accuracy of\nspecific reasoning tasks from <1% to >50%.\n","authors":["Christopher Wewer","Bart Pogodzinski","Bernt Schiele","Jan Eric Lenssen"],"pdf_url":"https://arxiv.org/pdf/2502.21075v1.pdf","comment":"Project website: https://geometric-rl.mpi-inf.mpg.de/srm/"},{"id":"http://arxiv.org/abs/2501.04903v3","updated":"2025-02-28T14:03:56Z","published":"2025-01-09T01:31:30Z","title":"Towards understanding the bias in decision trees","summary":"  There is a widespread and longstanding belief that machine learning models\nare biased towards the majority (or negative) class when learning from\nimbalanced data, leading them to neglect or ignore the minority (or positive)\nclass. In this study, we show that this belief is not necessarily correct for\ndecision trees, and that their bias can actually be in the opposite direction.\nMotivated by a recent simulation study that suggested that decision trees can\nbe biased towards the minority class, our paper aims to reconcile the conflict\nbetween that study and decades of other works. First, we critically evaluate\npast literature on this problem, finding that failing to consider the data\ngenerating process has led to incorrect conclusions about the bias in decision\ntrees. We then prove that, under specific conditions related to the predictors,\ndecision trees fit to purity and trained on a dataset with only one positive\ncase are biased towards the minority class. Finally, we demonstrate that splits\nin a decision tree are also biased when there is more than one positive case.\nOur findings have implications on the use of popular tree-based models, such as\nrandom forests.\n","authors":["Nathan Phelps","Daniel J. Lizotte","Douglas G. Woolford"],"pdf_url":"https://arxiv.org/pdf/2501.04903v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21060v1","updated":"2025-02-28T13:59:14Z","published":"2025-02-28T13:59:14Z","title":"Efficient Transformer-based Decoder for Varshamov-Tenengolts Codes","summary":"  In recent years, the rise of DNA data storage technology has brought\nsignificant attention to the challenge of correcting insertion, deletion, and\nsubstitution (IDS) errors. Among various coding methods for IDS correction,\nVarshamov-Tenengolts (VT) codes, primarily designed for single-error\ncorrection, have emerged as a central research focus. While existing decoding\nmethods achieve high accuracy in correcting a single error, they often fail to\ncorrect multiple IDS errors. In this work, we observe that VT codes retain some\ncapability for addressing multiple errors by introducing a transformer-based VT\ndecoder (TVTD) along with symbol- and statistic-based codeword embedding.\nExperimental results demonstrate that the proposed TVTD achieves perfect\ncorrection of a single error. Furthermore, when decoding multiple errors across\nvarious codeword lengths, the bit error rate and frame error rate are\nsignificantly improved compared to existing hard decision and soft-in soft-out\nalgorithms. Additionally, through model architecture optimization, the proposed\nmethod reduces time consumption by an order of magnitude compared to other soft\ndecoders.\n","authors":["Yali Wei","Alan J. X. Guo","Zihui Yan","Yufan Dai"],"pdf_url":"https://arxiv.org/pdf/2502.21060v1.pdf","comment":"9 pages, 2 figures, 9 tables"},{"id":"http://arxiv.org/abs/2502.21059v1","updated":"2025-02-28T13:59:11Z","published":"2025-02-28T13:59:11Z","title":"FC-Attack: Jailbreaking Large Vision-Language Models via Auto-Generated\n  Flowcharts","summary":"  Large Vision-Language Models (LVLMs) have become powerful and widely adopted\nin some practical applications. However, recent research has revealed their\nvulnerability to multimodal jailbreak attacks, whereby the model can be induced\nto generate harmful content, leading to safety risks. Although most LVLMs have\nundergone safety alignment, recent research shows that the visual modality is\nstill vulnerable to jailbreak attacks. In our work, we discover that by using\nflowcharts with partially harmful information, LVLMs can be induced to provide\nadditional harmful details. Based on this, we propose a jailbreak attack method\nbased on auto-generated flowcharts, FC-Attack. Specifically, FC-Attack first\nfine-tunes a pre-trained LLM to create a step-description generator based on\nbenign datasets. The generator is then used to produce step descriptions\ncorresponding to a harmful query, which are transformed into flowcharts in 3\ndifferent shapes (vertical, horizontal, and S-shaped) as visual prompts. These\nflowcharts are then combined with a benign textual prompt to execute a\njailbreak attack on LVLMs. Our evaluations using the Advbench dataset show that\nFC-Attack achieves over 90% attack success rates on Gemini-1.5, Llaval-Next,\nQwen2-VL, and InternVL-2.5 models, outperforming existing LVLM jailbreak\nmethods. Additionally, we investigate factors affecting the attack performance,\nincluding the number of steps and the font styles in the flowcharts. Our\nevaluation shows that FC-Attack can improve the jailbreak performance from 4%\nto 28% in Claude-3.5 by changing the font style. To mitigate the attack, we\nexplore several defenses and find that AdaShield can largely reduce the\njailbreak performance but with the cost of utility drop.\n","authors":["Ziyi Zhang","Zhen Sun","Zongmin Zhang","Jihui Guo","Xinlei He"],"pdf_url":"https://arxiv.org/pdf/2502.21059v1.pdf","comment":"13 pages, 6 figures"},{"id":"http://arxiv.org/abs/2502.21055v1","updated":"2025-02-28T13:56:48Z","published":"2025-02-28T13:56:48Z","title":"Quantum-aware Transformer model for state classification","summary":"  Entanglement is a fundamental feature of quantum mechanics, playing a crucial\nrole in quantum information processing. However, classifying entangled states,\nparticularly in the mixed-state regime, remains a challenging problem,\nespecially as system dimensions increase. In this work, we focus on bipartite\nquantum states and present a data-driven approach to entanglement\nclassification using transformer-based neural networks. Our dataset consists of\na diverse set of bipartite states, including pure separable states, Werner\nentangled states, general entangled states, and maximally entangled states. We\npretrain the transformer in an unsupervised fashion by masking elements of\nvectorized Hermitian matrix representations of quantum states, allowing the\nmodel to learn structural properties of quantum density matrices. This approach\nenables the model to generalize entanglement characteristics across different\nclasses of states. Once trained, our method achieves near-perfect\nclassification accuracy, effectively distinguishing between separable and\nentangled states. Compared to previous Machine Learning, our method\nsuccessfully adapts transformers for quantum state analysis, demonstrating\ntheir ability to systematically identify entanglement in bipartite systems.\nThese results highlight the potential of modern machine learning techniques in\nautomating entanglement detection and classification, bridging the gap between\nquantum information theory and artificial intelligence.\n","authors":["Przemysław Sekuła","Michał Romaszewski","Przemysław Głomb","Michał Cholewa","Łukasz Pawela"],"pdf_url":"https://arxiv.org/pdf/2502.21055v1.pdf","comment":"13 pages, 1 figure"},{"id":"http://arxiv.org/abs/2410.01506v4","updated":"2025-02-28T13:52:40Z","published":"2024-10-02T12:58:55Z","title":"Learnable Expansion of Graph Operators for Multi-Modal Feature Fusion","summary":"  In computer vision tasks, features often come from diverse representations,\ndomains (e.g., indoor and outdoor), and modalities (e.g., text, images, and\nvideos). Effectively fusing these features is essential for robust performance,\nespecially with the availability of powerful pre-trained models like\nvision-language models. However, common fusion methods, such as concatenation,\nelement-wise operations, and non-linear techniques, often fail to capture\nstructural relationships, deep feature interactions, and suffer from\ninefficiency or misalignment of features across domains or modalities. In this\npaper, we shift from high-dimensional feature space to a lower-dimensional,\ninterpretable graph space by constructing relationship graphs that encode\nfeature relationships at different levels, e.g., clip, frame, patch, token,\netc. To capture deeper interactions, we expand graphs through iterative graph\nrelationship updates and introduce a learnable graph fusion operator to\nintegrate these expanded relationships for more effective fusion. Our approach\nis relationship-centric, operates in a homogeneous space, and is mathematically\nprincipled, resembling element-wise relationship score aggregation via\nmultilinear polynomials. We demonstrate the effectiveness of our graph-based\nfusion method on video anomaly detection, showing strong performance across\nmulti-representational, multi-modal, and multi-domain feature fusion tasks.\n","authors":["Dexuan Ding","Lei Wang","Liyun Zhu","Tom Gedeon","Piotr Koniusz"],"pdf_url":"https://arxiv.org/pdf/2410.01506v4.pdf","comment":"Accepted at the Thirteenth International Conference on Learning\n  Representations (ICLR 2025)"},{"id":"http://arxiv.org/abs/2502.21051v1","updated":"2025-02-28T13:50:18Z","published":"2025-02-28T13:50:18Z","title":"Detection of anomalies in cow activity using wavelet transform based\n  features","summary":"  In Precision Livestock Farming, detecting deviations from optimal or baseline\nvalues - i.e. anomalies in time series - is essential to allow undertaking\ncorrective actions rapidly. Here we aim at detecting anomalies in 24h time\nseries of cow activity, with a view to detect cases of disease or oestrus.\nDeviations must be distinguished from noise which can be very high in case of\nbiological data. It is also important to detect the anomaly early, e.g. before\na farmer would notice it visually. Here, we investigate the benefit of using\nwavelet transforms to denoise data and we assess the performance of an anomaly\ndetection algorithm considering the timing of the detection. We developed\nfeatures based on the comparisons between the wavelet transforms of the mean of\nthe time series and the wavelet transforms of individual time series instances.\nWe hypothesized that these features contribute to the detection of anomalies in\nperiodic time series using a feature-based algorithm. We tested this hypothesis\nwith two datasets representing cow activity, which typically follows a daily\npattern but can deviate due to specific physiological or pathological\nconditions. We applied features derived from wavelet transform as well as\nstatistical features in an Isolation Forest algorithm. We measured the distance\nof detection between the days annotated abnormal by animal caretakers days and\nthe days predicted abnormal by the algorithm. The results show that\nwavelet-based features are among the features most contributing to anomaly\ndetection. They also show that detections are close to the annotated days, and\noften precede it. In conclusion, using wavelet transforms on time series of cow\nactivity data helps to detect anomalies related to specific cow states. The\ndetection is often obtained on days that precede the day annotated by\ncaretakers, which offer possibility to take corrective actions at an early\nstage.\n","authors":["Valentin Guien","Violaine Antoine","Romain Lardy","Isabelle Veissier","Luis E C Rocha"],"pdf_url":"https://arxiv.org/pdf/2502.21051v1.pdf","comment":"17 pages, 8 figures, 4 tables, 1 algorithm"},{"id":"http://arxiv.org/abs/2407.04405v2","updated":"2025-02-28T13:41:19Z","published":"2024-07-05T10:41:15Z","title":"Discovering physical laws with parallel combinatorial tree search","summary":"  Symbolic regression plays a crucial role in modern scientific research thanks\nto its capability of discovering concise and interpretable mathematical\nexpressions from data. A grand challenge lies in the arduous search for\nparsimonious and generalizable mathematical formulas, in an infinite search\nspace, while intending to fit the training data. Existing algorithms have faced\na critical bottleneck of accuracy and efficiency over a decade when handling\nproblems of complexity, which essentially hinders the pace of applying symbolic\nregression for scientific exploration across interdisciplinary domains. To this\nend, we introduce a parallel combinatorial tree search (PCTS) model to\nefficiently distill generic mathematical expressions from limited data. Through\na series of extensive experiments, we demonstrate the superior accuracy and\nefficiency of PCTS for equation discovery, which greatly outperforms the\nstate-of-the-art baseline models on over 200 synthetic and experimental\ndatasets (e.g., lifting its performance by up to 99% accuracy improvement and\none-order of magnitude speed up). PCTS represents a key advance in accurate and\nefficient data-driven discovery of symbolic, interpretable models (e.g.,\nunderlying physical laws) and marks a pivotal transition towards scalable\nsymbolic learning.\n","authors":["Kai Ruan","Yilong Xu","Ze-Feng Gao","Yike Guo","Hao Sun","Ji-Rong Wen","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2407.04405v2.pdf","comment":"Added new author"},{"id":"http://arxiv.org/abs/2409.00730v3","updated":"2025-02-28T13:34:39Z","published":"2024-09-01T14:43:47Z","title":"Generating Physical Dynamics under Priors","summary":"  Generating physically feasible dynamics in a data-driven context is\nchallenging, especially when adhering to physical priors expressed in specific\nequations or formulas. Existing methodologies often overlook the integration of\nphysical priors, resulting in violation of basic physical laws and suboptimal\nperformance. In this paper, we introduce a novel framework that seamlessly\nincorporates physical priors into diffusion-based generative models to address\nthis limitation. Our approach leverages two categories of priors: 1)\ndistributional priors, such as roto-translational invariance, and 2) physical\nfeasibility priors, including energy and momentum conservation laws and PDE\nconstraints. By embedding these priors into the generative process, our method\ncan efficiently generate physically realistic dynamics, encompassing\ntrajectories and flows. Empirical evaluations demonstrate that our method\nproduces high-quality dynamics across a diverse array of physical phenomena\nwith remarkable robustness, underscoring its potential to advance data-driven\nstudies in AI4Physics. Our contributions signify a substantial advancement in\nthe field of generative modeling, offering a robust solution to generate\naccurate and physically consistent dynamics.\n","authors":["Zihan Zhou","Xiaoxue Wang","Tianshu Yu"],"pdf_url":"https://arxiv.org/pdf/2409.00730v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21041v1","updated":"2025-02-28T13:32:47Z","published":"2025-02-28T13:32:47Z","title":"Fast Adversarial Training against Sparse Attacks Requires Loss Smoothing","summary":"  This paper studies fast adversarial training against sparse adversarial\nperturbations bounded by $l_0$ norm. We demonstrate the challenges of employing\n$1$-step attacks on $l_0$ bounded perturbations for fast adversarial training,\nincluding degraded performance and the occurrence of catastrophic overfitting\n(CO). We highlight that CO in $l_0$ adversarial training is caused by\nsub-optimal perturbation locations of $1$-step attack. Theoretical and\nempirical analyses reveal that the loss landscape of $l_0$ adversarial training\nis more craggy compared to its $l_\\infty$, $l_2$ and $l_1$ counterparts.\nMoreover, we corroborate that the craggy loss landscape can aggravate CO. To\naddress these issues, we propose Fast-LS-$l_0$ that incorporates soft labels\nand the trade-off loss function to smooth the adversarial loss landscape.\nExtensive experiments demonstrate our method can overcome the challenge of\ncatastrophic overfitting, achieve state-of-the-art performance, and narrow down\nthe performance gap between $1$-step and multi-step adversarial training\nagainst sparse attacks.\n","authors":["Xuyang Zhong","Yixiao Huang","Chen Liu"],"pdf_url":"https://arxiv.org/pdf/2502.21041v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21038v1","updated":"2025-02-28T13:29:54Z","published":"2025-02-28T13:29:54Z","title":"Reward Learning from Multiple Feedback Types","summary":"  Learning rewards from preference feedback has become an important tool in the\nalignment of agentic models. Preference-based feedback, often implemented as a\nbinary comparison between multiple completions, is an established method to\nacquire large-scale human feedback. However, human feedback in other contexts\nis often much more diverse. Such diverse feedback can better support the goals\nof a human annotator, and the simultaneous use of multiple sources might be\nmutually informative for the learning process or carry type-dependent biases\nfor the reward learning process. Despite these potential benefits, learning\nfrom different feedback types has yet to be explored extensively. In this\npaper, we bridge this gap by enabling experimentation and evaluating multi-type\nfeedback in a broad set of environments. We present a process to generate\nhigh-quality simulated feedback of six different types. Then, we implement\nreward models and downstream RL training for all six feedback types. Based on\nthe simulated feedback, we investigate the use of types of feedback across ten\nRL environments and compare them to pure preference-based baselines. We show\nempirically that diverse types of feedback can be utilized and lead to strong\nreward modeling performance. This work is the first strong indicator of the\npotential of multi-type feedback for RLHF.\n","authors":["Yannick Metz","András Geiszl","Raphaël Baur","Mennatallah El-Assady"],"pdf_url":"https://arxiv.org/pdf/2502.21038v1.pdf","comment":"Published as a conference paper at ICLR 2025"},{"id":"http://arxiv.org/abs/2502.21035v1","updated":"2025-02-28T13:27:25Z","published":"2025-02-28T13:27:25Z","title":"S4ConvD: Adaptive Scaling and Frequency Adjustment for Energy-Efficient\n  Sensor Networks in Smart Buildings","summary":"  Predicting energy consumption in smart buildings is challenging due to\ndependencies in sensor data and the variability of environmental conditions. We\nintroduce S4ConvD, a novel convolutional variant of Deep State Space Models\n(Deep-SSMs), that minimizes reliance on extensive preprocessing steps. S4ConvD\nis designed to optimize runtime in resource-constrained environments. By\nimplementing adaptive scaling and frequency adjustments, this model shows to\ncapture complex temporal patterns in building energy dynamics. Experiments on\nthe ASHRAE Great Energy Predictor III dataset reveal that S4ConvD outperforms\ncurrent benchmarks. Additionally, S4ConvD benefits from significant\nimprovements in GPU runtime through the use of Block Tiling optimization\ntechniques. Thus, S4ConvD has the potential for practical deployment in\nreal-time energy modeling. Furthermore, the complete codebase and dataset are\naccessible on GitHub, fostering open-source contributions and facilitating\nfurther research. Our method also promotes resource-efficient model execution,\nenhancing both energy forecasting and the potential integration of renewable\nenergy sources into smart grid systems.\n","authors":["Melanie Schaller","Bodo Rosenhahn"],"pdf_url":"https://arxiv.org/pdf/2502.21035v1.pdf","comment":"Submitted to TOSN Journal"},{"id":"http://arxiv.org/abs/2502.21034v1","updated":"2025-02-28T13:26:41Z","published":"2025-02-28T13:26:41Z","title":"Synthesizing Tabular Data Using Selectivity Enhanced Generative\n  Adversarial Networks","summary":"  As E-commerce platforms face surging transactions during major shopping\nevents like Black Friday, stress testing with synthesized data is crucial for\nresource planning. Most recent studies use Generative Adversarial Networks\n(GANs) to generate tabular data while ensuring privacy and machine learning\nutility. However, these methods overlook the computational demands of\nprocessing GAN-generated data, making them unsuitable for E-commerce stress\ntesting.\n  This thesis introduces a novel GAN-based approach incorporating query\nselectivity constraints, a key factor in database transaction processing. We\nintegrate a pre-trained deep neural network to maintain selectivity consistency\nbetween real and synthetic data. Our method, tested on five real-world\ndatasets, outperforms three state-of-the-art GANs and a VAE model, improving\nselectivity estimation accuracy by up to 20pct and machine learning utility by\nup to 6 pct.\n","authors":["Youran Zhou","Jianzhong Qi"],"pdf_url":"https://arxiv.org/pdf/2502.21034v1.pdf","comment":"This thesis submitted to the University of Melbourne for partial\n  fulfillment of the degree of Master of Data Science"},{"id":"http://arxiv.org/abs/2502.21033v1","updated":"2025-02-28T13:24:49Z","published":"2025-02-28T13:24:49Z","title":"A data augmentation strategy for deep neural networks with application\n  to epidemic modelling","summary":"  In this work, we integrate the predictive capabilities of compartmental\ndisease dynamics models with machine learning ability to analyze complex,\nhigh-dimensional data and uncover patterns that conventional models may\noverlook. Specifically, we present a proof of concept demonstrating the\napplication of data-driven methods and deep neural networks to a recently\nintroduced SIR-type model with social features, including a saturated incidence\nrate, to improve epidemic prediction and forecasting. Our results show that a\nrobust data augmentation strategy trough suitable data-driven models can\nimprove the reliability of Feed-Forward Neural Networks (FNNs) and Nonlinear\nAutoregressive Networks (NARs), making them viable alternatives to\nPhysics-Informed Neural Networks (PINNs). This approach enhances the ability to\nhandle nonlinear dynamics and offers scalable, data-driven solutions for\nepidemic forecasting, prioritizing predictive accuracy over the constraints of\nphysics-based models. Numerical simulations of the post-lockdown phase of the\nCOVID-19 epidemic in Italy and Spain validate our methodology.\n","authors":["Muhammad Awais","Abu Sayfan Ali","Giacomo Dimarco","Federica Ferrarese","Lorenzo Pareschi"],"pdf_url":"https://arxiv.org/pdf/2502.21033v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21029v1","updated":"2025-02-28T13:22:12Z","published":"2025-02-28T13:22:12Z","title":"Sixth-Sense: Self-Supervised Learning of Spatial Awareness of Humans\n  from a Planar Lidar","summary":"  Localizing humans is a key prerequisite for any service robot operating in\nproximity to people. In these scenarios, robots rely on a multitude of\nstate-of-the-art detectors usually designed to operate with RGB-D cameras or\nexpensive 3D LiDARs. However, most commercially available service robots are\nequipped with cameras with a narrow field of view, making them blind when a\nuser is approaching from other directions, or inexpensive 1D LiDARs whose\nreadings are difficult to interpret. To address these limitations, we propose a\nself-supervised approach to detect humans and estimate their 2D pose from 1D\nLiDAR data, using detections from an RGB-D camera as a supervision source. Our\napproach aims to provide service robots with spatial awareness of nearby\nhumans. After training on 70 minutes of data autonomously collected in two\nenvironments, our model is capable of detecting humans omnidirectionally from\n1D LiDAR data in a novel environment, with 71% precision and 80% recall, while\nretaining an average absolute error of 13 cm in distance and 44{\\deg} in\norientation.\n","authors":["Simone Arreghini","Nicholas Carlotti","Mirko Nava","Antonio Paolillo","Alessandro Giusti"],"pdf_url":"https://arxiv.org/pdf/2502.21029v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.15511v2","updated":"2025-02-28T13:10:23Z","published":"2024-09-23T19:57:08Z","title":"Bayesian computation with generative diffusion models by Multilevel\n  Monte Carlo","summary":"  Generative diffusion models have recently emerged as a powerful strategy to\nperform stochastic sampling in Bayesian inverse problems, delivering remarkably\naccurate solutions for a wide range of challenging applications. However,\ndiffusion models often require a large number of neural function evaluations\nper sample in order to deliver accurate posterior samples. As a result, using\ndiffusion models as stochastic samplers for Monte Carlo integration in Bayesian\ncomputation can be highly computationally expensive, particularly in\napplications that require a substantial number of Monte Carlo samples for\nconducting uncertainty quantification analyses. This cost is especially high in\nlarge-scale inverse problems such as computational imaging, which rely on large\nneural networks that are expensive to evaluate. With quantitative imaging\napplications in mind, this paper presents a Multilevel Monte Carlo strategy\nthat significantly reduces the cost of Bayesian computation with diffusion\nmodels. This is achieved by exploiting cost-accuracy trade-offs inherent to\ndiffusion models to carefully couple models of different levels of accuracy in\na manner that significantly reduces the overall cost of the calculation,\nwithout reducing the final accuracy. The proposed approach achieves a\n$4\\times$-to-$8\\times$ reduction in computational cost w.r.t. standard\ntechniques across three benchmark imaging problems.\n","authors":["Abdul-Lateef Haji-Ali","Marcelo Pereyra","Luke Shaw","Konstantinos Zygalakis"],"pdf_url":"https://arxiv.org/pdf/2409.15511v2.pdf","comment":"13 images"},{"id":"http://arxiv.org/abs/2502.19665v2","updated":"2025-02-28T13:09:56Z","published":"2025-02-27T01:11:11Z","title":"Out-of-distribution Generalization for Total Variation based Invariant\n  Risk Minimization","summary":"  Invariant risk minimization is an important general machine learning\nframework that has recently been interpreted as a total variation model\n(IRM-TV). However, how to improve out-of-distribution (OOD) generalization in\nthe IRM-TV setting remains unsolved. In this paper, we extend IRM-TV to a\nLagrangian multiplier model named OOD-TV-IRM. We find that the autonomous TV\npenalty hyperparameter is exactly the Lagrangian multiplier. Thus OOD-TV-IRM is\nessentially a primal-dual optimization model, where the primal optimization\nminimizes the entire invariant risk and the dual optimization strengthens the\nTV penalty. The objective is to reach a semi-Nash equilibrium where the balance\nbetween the training loss and OOD generalization is maintained. We also develop\na convergent primal-dual algorithm that facilitates an adversarial learning\nscheme. Experimental results show that OOD-TV-IRM outperforms IRM-TV in most\nsituations.\n","authors":["Yuanchao Wang","Zhao-Rong Lai","Tianqi Zhong"],"pdf_url":"https://arxiv.org/pdf/2502.19665v2.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2406.17808v3","updated":"2025-02-28T13:08:44Z","published":"2024-06-24T03:59:17Z","title":"Training-Free Exponential Context Extension via Cascading KV Cache","summary":"  The transformer's context window is vital for tasks such as few-shot learning\nand conditional generation as it preserves previous tokens for active memory.\nHowever, as the context lengths increase, the computational costs grow\nquadratically, hindering the deployment of large language models (LLMs) in\nreal-world, long sequence scenarios. Although some recent key-value caching (KV\nCache) methods offer linear inference complexity, they naively manage the\nstored context, prematurely evicting tokens and losing valuable information.\nMoreover, they lack an optimized prefill/prompt stage strategy, resulting in\nhigher latency than even quadratic attention for realistic context sizes. In\nresponse, we introduce a novel mechanism that leverages cascading sub-cache\nbuffers to selectively retain the most relevant tokens, enabling the model to\nmaintain longer context histories without increasing the cache size. Our\napproach outperforms linear caching baselines across key benchmarks, including\nstreaming perplexity, question answering, book summarization, and passkey\nretrieval, where it retains better retrieval accuracy at 1M tokens after four\ndoublings of the cache size of 65K. Additionally, our method reduces prefill\nstage latency by a factor of 6.8 when compared to flash attention on 1M tokens.\nThese innovations not only enhance the computational efficiency of LLMs but\nalso pave the way for their effective deployment in resource-constrained\nenvironments, enabling large-scale, real-time applications with significantly\nreduced latency.\n","authors":["Jeffrey Willette","Heejun Lee","Youngwan Lee","Myeongjae Jeon","Sung Ju Hwang"],"pdf_url":"https://arxiv.org/pdf/2406.17808v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21025v1","updated":"2025-02-28T13:08:15Z","published":"2025-02-28T13:08:15Z","title":"AutoQML: A Framework for Automated Quantum Machine Learning","summary":"  Automated Machine Learning (AutoML) has significantly advanced the efficiency\nof ML-focused software development by automating hyperparameter optimization\nand pipeline construction, reducing the need for manual intervention. Quantum\nMachine Learning (QML) offers the potential to surpass classical machine\nlearning (ML) capabilities by utilizing quantum computing. However, the\ncomplexity of QML presents substantial entry barriers. We introduce\n\\emph{AutoQML}, a novel framework that adapts the AutoML approach to QML,\nproviding a modular and unified programming interface to facilitate the\ndevelopment of QML pipelines. AutoQML leverages the QML library sQUlearn to\nsupport a variety of QML algorithms. The framework is capable of constructing\nend-to-end pipelines for supervised learning tasks, ensuring accessibility and\nefficacy. We evaluate AutoQML across four industrial use cases, demonstrating\nits ability to generate high-performing QML pipelines that are competitive with\nboth classical ML models and manually crafted quantum solutions.\n","authors":["Marco Roth","David A. Kreplin","Daniel Basilewitsch","João F. Bravo","Dennis Klau","Milan Marinov","Daniel Pranjic","Horst Stuehler","Moritz Willmann","Marc-André Zöller"],"pdf_url":"https://arxiv.org/pdf/2502.21025v1.pdf","comment":"9 pages, 4 figures"},{"id":"http://arxiv.org/abs/2502.21022v1","updated":"2025-02-28T13:05:47Z","published":"2025-02-28T13:05:47Z","title":"When Unsupervised Domain Adaptation meets One-class Anomaly Detection:\n  Addressing the Two-fold Unsupervised Curse by Leveraging Anomaly Scarcity","summary":"  This paper introduces the first fully unsupervised domain adaptation (UDA)\nframework for unsupervised anomaly detection (UAD). The performance of UAD\ntechniques degrades significantly in the presence of a domain shift, difficult\nto avoid in a real-world setting. While UDA has contributed to solving this\nissue in binary and multi-class classification, such a strategy is ill-posed in\nUAD. This might be explained by the unsupervised nature of the two tasks,\nnamely, domain adaptation and anomaly detection. Herein, we first formulate\nthis problem that we call the two-fold unsupervised curse. Then, we propose a\npioneering solution to this curse, considered intractable so far, by assuming\nthat anomalies are rare. Specifically, we leverage clustering techniques to\nidentify a dominant cluster in the target feature space. Posed as the normal\ncluster, the latter is aligned with the source normal features. Concretely,\ngiven a one-class source set and an unlabeled target set composed mostly of\nnormal data and some anomalies, we fit the source features within a hypersphere\nwhile jointly aligning them with the features of the dominant cluster from the\ntarget set. The paper provides extensive experiments and analysis on common\nadaptation benchmarks for anomaly detection, demonstrating the relevance of\nboth the newly introduced paradigm and the proposed approach. The code will be\nmade publicly available.\n","authors":["Nesryne Mejri","Enjie Ghorbel","Anis Kacem","Pavel Chernakov","Niki Foteinopoulou","Djamila Aouada"],"pdf_url":"https://arxiv.org/pdf/2502.21022v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04682v3","updated":"2025-02-28T13:02:23Z","published":"2024-10-07T01:29:19Z","title":"On the Adversarial Risk of Test Time Adaptation: An Investigation into\n  Realistic Test-Time Data Poisoning","summary":"  Test-time adaptation (TTA) updates the model weights during the inference\nstage using testing data to enhance generalization. However, this practice\nexposes TTA to adversarial risks. Existing studies have shown that when TTA is\nupdated with crafted adversarial test samples, also known as test-time poisoned\ndata, the performance on benign samples can deteriorate. Nonetheless, the\nperceived adversarial risk may be overstated if the poisoned data is generated\nunder overly strong assumptions. In this work, we first review realistic\nassumptions for test-time data poisoning, including white-box versus grey-box\nattacks, access to benign data, attack order, and more. We then propose an\neffective and realistic attack method that better produces poisoned samples\nwithout access to benign samples, and derive an effective in-distribution\nattack objective. We also design two TTA-aware attack objectives. Our\nbenchmarks of existing attack methods reveal that the TTA methods are more\nrobust than previously believed. In addition, we analyze effective defense\nstrategies to help develop adversarially robust TTA methods. The source code is\navailable at https://github.com/Gorilla-Lab-SCUT/RTTDP.\n","authors":["Yongyi Su","Yushu Li","Nanqing Liu","Kui Jia","Xulei Yang","Chuan-Sheng Foo","Xun Xu"],"pdf_url":"https://arxiv.org/pdf/2410.04682v3.pdf","comment":"Accepted by ICLR 2025. 25 pages, 4 figures and 12 tables"},{"id":"http://arxiv.org/abs/2402.17812v4","updated":"2025-02-28T12:53:34Z","published":"2024-02-27T14:51:11Z","title":"DropBP: Accelerating Fine-Tuning of Large Language Models by Dropping\n  Backward Propagation","summary":"  Large language models (LLMs) have achieved significant success across various\ndomains. However, training these LLMs typically involves substantial memory and\ncomputational costs during both forward and backward propagation. While\nparameter-efficient fine-tuning (PEFT) considerably reduces the training memory\nassociated with parameters, it does not address the significant computational\ncosts and activation memory. In this paper, we propose Dropping Backward\nPropagation (DropBP), a novel approach designed to reduce computational costs\nand activation memory while maintaining accuracy. DropBP randomly drops layers\nduring backward propagation, which is essentially equivalent to training\nshallow submodules generated by undropped layers and residual connections.\nAdditionally, DropBP calculates the sensitivity of each layer to assign an\nappropriate drop rate, thereby stabilizing the training process. DropBP is not\nonly applicable to full fine-tuning but can also be orthogonally integrated\nwith all types of PEFT by dropping layers during backward propagation.\nSpecifically, DropBP can reduce training time by 44% with comparable accuracy\nto the baseline, accelerate convergence to the same perplexity by 1.5x, and\nenable training with a sequence length 6.2x larger on a single NVIDIA-A100 GPU.\nFurthermore, our DropBP enabled a throughput increase of 79% on a NVIDIA A100\nGPU and 117% on an Intel Gaudi2 HPU. The code is available at\nhttps://github.com/WooSunghyeon/dropbp.\n","authors":["Sunghyeon Woo","Baeseong Park","Byeongwook Kim","Minjung Jo","Se Jung Kwon","Dongsuk Jeon","Dongsoo Lee"],"pdf_url":"https://arxiv.org/pdf/2402.17812v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21009v1","updated":"2025-02-28T12:52:11Z","published":"2025-02-28T12:52:11Z","title":"Position: Solve Layerwise Linear Models First to Understand Neural\n  Dynamical Phenomena (Neural Collapse, Emergence, Lazy/Rich Regime, and\n  Grokking)","summary":"  In physics, complex systems are often simplified into minimal, solvable\nmodels that retain only the core principles. In machine learning, layerwise\nlinear models (e.g., linear neural networks) act as simplified representations\nof neural network dynamics. These models follow the dynamical feedback\nprinciple, which describes how layers mutually govern and amplify each other's\nevolution. This principle extends beyond the simplified models, successfully\nexplaining a wide range of dynamical phenomena in deep neural networks,\nincluding neural collapse, emergence, lazy and rich regimes, and grokking. In\nthis position paper, we call for the use of layerwise linear models retaining\nthe core principles of neural dynamical phenomena to accelerate the science of\ndeep learning.\n","authors":["Yoonsoo Nam","Seok Hyeong Lee","Clementine Domine","Yea Chan Park","Charles London","Wonyl Choi","Niclas Goring","Seungjai Lee"],"pdf_url":"https://arxiv.org/pdf/2502.21009v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.19839v5","updated":"2025-02-28T12:35:34Z","published":"2024-09-30T00:41:51Z","title":"ForecastBench: A Dynamic Benchmark of AI Forecasting Capabilities","summary":"  Forecasts of future events are essential inputs into informed\ndecision-making. Machine learning (ML) systems have the potential to deliver\nforecasts at scale, but there is no framework for evaluating the accuracy of ML\nsystems on a standardized set of forecasting questions. To address this gap, we\nintroduce ForecastBench: a dynamic benchmark that evaluates the accuracy of ML\nsystems on an automatically generated and regularly updated set of 1,000\nforecasting questions. To avoid any possibility of data leakage, ForecastBench\nis comprised solely of questions about future events that have no known answer\nat the time of submission. We quantify the capabilities of current ML systems\nby collecting forecasts from expert (human) forecasters, the general public,\nand LLMs on a random subset of questions from the benchmark ($N=200$). While\nLLMs have achieved super-human performance on many benchmarks, they perform\nless well here: expert forecasters outperform the top-performing LLM ($p$-value\n$<0.001$). We display system and human scores in a public leaderboard at\nwww.forecastbench.org.\n","authors":["Ezra Karger","Houtan Bastani","Chen Yueh-Han","Zachary Jacobs","Danny Halawi","Fred Zhang","Philip E. Tetlock"],"pdf_url":"https://arxiv.org/pdf/2409.19839v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.03084v2","updated":"2025-02-28T12:24:33Z","published":"2024-12-04T07:26:36Z","title":"Hybrid deep learning-based strategy for the hepatocellular carcinoma\n  cancer grade classification of H&E stained liver histopathology images","summary":"  Hepatocellular carcinoma (HCC) is a common type of liver cancer whose\nearly-stage diagnosis is a common challenge, mainly due to the manual\nassessment of hematoxylin and eosin-stained whole slide images, which is a\ntime-consuming process and may lead to variability in decision-making. For\naccurate detection of HCC, we propose a hybrid deep learning-based architecture\nthat uses transfer learning to extract the features from pre-trained\nconvolutional neural network (CNN) models and a classifier made up of a\nsequence of fully connected layers. This study uses a publicly available The\nCancer Genome Atlas Hepatocellular Carcinoma (TCGA-LIHC)database (n=491) for\nmodel development and database of Kasturba Gandhi Medical College (KMC), India\nfor validation. The pre-processing step involves patch extraction, colour\nnormalization, and augmentation that results in 3920 patches for the TCGA\ndataset. The developed hybrid deep neural network consisting of a CNN-based\npre-trained feature extractor and a customized artificial neural network-based\nclassifier is trained using five-fold cross-validation. For this study, eight\ndifferent state-of-the-art models are trained and tested as feature extractors\nfor the proposed hybrid model. The proposed hybrid model with ResNet50-based\nfeature extractor provided the sensitivity, specificity, F1-score, accuracy,\nand AUC of 100.00%, 100.00%, 100.00%, 100.00%, and 1.00, respectively on the\nTCGA database. On the KMC database, EfficientNetb3 resulted in the optimal\nchoice of the feature extractor giving sensitivity, specificity, F1-score,\naccuracy, and AUC of 96.97, 98.85, 96.71, 96.71, and 0.99, respectively. The\nproposed hybrid models showed improvement in accuracy of 2% and 4% over the\npre-trained models in TCGA-LIHC and KMC databases.\n","authors":["Ajinkya Deshpande","Deep Gupta","Ankit Bhurane","Nisha Meshram","Sneha Singh","Petia Radeva"],"pdf_url":"https://arxiv.org/pdf/2412.03084v2.pdf","comment":"14 figure, 9 tables"},{"id":"http://arxiv.org/abs/2310.20493v2","updated":"2025-02-28T12:22:07Z","published":"2023-10-31T14:32:54Z","title":"Requirement falsification for cyber-physical systems using generative\n  models","summary":"  We present the OGAN algorithm for automatic requirement falsification of\ncyber-physical systems. System inputs and outputs are represented as piecewise\nconstant signals over time while requirements are expressed in signal temporal\nlogic. OGAN can find inputs that are counterexamples for the correctness of a\nsystem revealing design, software, or hardware defects before the system is\ntaken into operation. The OGAN algorithm works by training a generative machine\nlearning model to produce such counterexamples. It executes tests offline and\ndoes not require any previous model of the system under test. We evaluate OGAN\nusing the ARCH-COMP benchmark problems, and the experimental results show that\ngenerative models are a viable method for requirement falsification. OGAN can\nbe applied to new systems with little effort, has few requirements for the\nsystem under test, and exhibits state-of-the-art CPS falsification efficiency\nand effectiveness.\n","authors":["Jarkko Peltomäki","Ivan Porres"],"pdf_url":"https://arxiv.org/pdf/2310.20493v2.pdf","comment":"39 pages, 8 figures, 10 tables"},{"id":"http://arxiv.org/abs/2408.03029v4","updated":"2025-02-28T12:21:00Z","published":"2024-08-06T08:22:16Z","title":"Highly Efficient Self-Adaptive Reward Shaping for Reinforcement Learning","summary":"  Reward shaping is a technique in reinforcement learning that addresses the\nsparse-reward problem by providing more frequent and informative rewards. We\nintroduce a self-adaptive and highly efficient reward shaping mechanism that\nincorporates success rates derived from historical experiences as shaped\nrewards. The success rates are sampled from Beta distributions, which\ndynamically evolve from uncertain to reliable values as data accumulates.\nInitially, the shaped rewards exhibit more randomness to encourage exploration,\nwhile over time, the increasing certainty enhances exploitation, naturally\nbalancing exploration and exploitation. Our approach employs Kernel Density\nEstimation (KDE) combined with Random Fourier Features (RFF) to derive the Beta\ndistributions, providing a computationally efficient, non-parametric, and\nlearning-free solution for high-dimensional continuous state spaces. Our method\nis validated on various tasks with extremely sparse rewards, demonstrating\nnotable improvements in sample efficiency and convergence stability over\nrelevant baselines.\n","authors":["Haozhe Ma","Zhengding Luo","Thanh Vinh Vo","Kuankuan Sima","Tze-Yun Leong"],"pdf_url":"https://arxiv.org/pdf/2408.03029v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.10078v2","updated":"2025-02-28T11:46:16Z","published":"2024-06-14T14:35:44Z","title":"D-NPC: Dynamic Neural Point Clouds for Non-Rigid View Synthesis from\n  Monocular Video","summary":"  Dynamic reconstruction and spatiotemporal novel-view synthesis of non-rigidly\ndeforming scenes recently gained increased attention. While existing work\nachieves impressive quality and performance on multi-view or teleporting camera\nsetups, most methods fail to efficiently and faithfully recover motion and\nappearance from casual monocular captures. This paper contributes to the field\nby introducing a new method for dynamic novel view synthesis from monocular\nvideo, such as casual smartphone captures.\n  Our approach represents the scene as a $\\textit{dynamic neural point cloud}$,\nan implicit time-conditioned point distribution that encodes local geometry and\nappearance in separate hash-encoded neural feature grids for static and dynamic\nregions. By sampling a discrete point cloud from our model, we can efficiently\nrender high-quality novel views using a fast differentiable rasterizer and\nneural rendering network. Similar to recent work, we leverage advances in\nneural scene analysis by incorporating data-driven priors like monocular depth\nestimation and object segmentation to resolve motion and depth ambiguities\noriginating from the monocular captures. In addition to guiding the\noptimization process, we show that these priors can be exploited to explicitly\ninitialize our scene representation to drastically improve optimization speed\nand final image quality. As evidenced by our experimental evaluation, our\ndynamic point cloud model not only enables fast optimization and real-time\nframe rates for interactive applications, but also achieves competitive image\nquality on monocular benchmark sequences.\n  Our code and data are available online:\nhttps://moritzkappel.github.io/projects/dnpc/.\n","authors":["Moritz Kappel","Florian Hahlbohm","Timon Scholz","Susana Castillo","Christian Theobalt","Martin Eisemann","Vladislav Golyanik","Marcus Magnor"],"pdf_url":"https://arxiv.org/pdf/2406.10078v2.pdf","comment":"18 pages, 8 figures, 12 tables. Project page:\n  https://moritzkappel.github.io/projects/dnpc/"},{"id":"http://arxiv.org/abs/2501.08248v2","updated":"2025-02-28T11:40:20Z","published":"2025-01-14T16:38:33Z","title":"Eliciting In-context Retrieval and Reasoning for Long-context Large\n  Language Models","summary":"  Recent advancements in long-context language models (LCLMs) promise to\ntransform Retrieval-Augmented Generation (RAG) by simplifying pipelines. With\ntheir expanded context windows, LCLMs can process entire knowledge bases and\nperform retrieval and reasoning directly -- a capability we define as\nIn-Context Retrieval and Reasoning (ICR^2). However, existing benchmarks like\nLOFT often overestimate LCLM performance by providing overly simplified\ncontexts. To address this, we introduce ICR^2, a benchmark that evaluates LCLMs\nin more realistic scenarios by including confounding passages retrieved with\nstrong retrievers. We then propose three methods to enhance LCLM performance:\n(1) retrieve-then-generate fine-tuning, (2) retrieval-attention-probing, which\nuses attention heads to filter and de-noise long contexts during decoding, and\n(3) joint retrieval head training alongside the generation head. Our evaluation\nof five well-known LCLMs on LOFT and ICR^2 demonstrates significant gains with\nour best approach applied to Mistral-7B: +17 and +15 points by Exact Match on\nLOFT, and +13 and +2 points on ICR^2, compared to vanilla RAG and supervised\nfine-tuning, respectively. It even outperforms GPT-4-Turbo on most tasks\ndespite being a much smaller model.\n","authors":["Yifu Qiu","Varun Embar","Yizhe Zhang","Navdeep Jaitly","Shay B. Cohen","Benjamin Han"],"pdf_url":"https://arxiv.org/pdf/2501.08248v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20974v1","updated":"2025-02-28T11:39:18Z","published":"2025-02-28T11:39:18Z","title":"Improving Open-world Continual Learning under the Constraints of Scarce\n  Labeled Data","summary":"  Open-world continual learning (OWCL) adapts to sequential tasks with open\nsamples, learning knowledge incrementally while preventing forgetting. However,\nexisting OWCL still requires a large amount of labeled data for training, which\nis often impractical in real-world applications. Given that new\ncategories/entities typically come with limited annotations and are in small\nquantities, a more realistic situation is OWCL with scarce labeled data, i.e.,\nfew-shot training samples. Hence, this paper investigates the problem of\nopen-world few-shot continual learning (OFCL), challenging in (i) learning\nunbounded tasks without forgetting previous knowledge and avoiding overfitting,\n(ii) constructing compact decision boundaries for open detection with limited\nlabeled data, and (iii) transferring knowledge about knowns and unknowns and\neven update the unknowns to knowns once the labels of open samples are learned.\nIn response, we propose a novel OFCL framework that integrates three key\ncomponents: (1) an instance-wise token augmentation (ITA) that represents and\nenriches sample representations with additional knowledge, (2) a margin-based\nopen boundary (MOB) that supports open detection with new tasks emerge over\ntime, and (3) an adaptive knowledge space (AKS) that endows unknowns with\nknowledge for the updating from unknowns to knowns. Finally, extensive\nexperiments show the proposed OFCL framework outperforms all baselines\nremarkably with practical importance and reproducibility. The source code is\nreleased at https://github.com/liyj1201/OFCL.\n","authors":["Yujie Li","Xiangkun Wang","Xin Yang","Marcello Bonsangue","Junbo Zhang","Tianrui Li"],"pdf_url":"https://arxiv.org/pdf/2502.20974v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.10288v3","updated":"2025-02-28T11:36:06Z","published":"2024-06-12T18:33:11Z","title":"Do as I do (Safely): Mitigating Task-Specific Fine-tuning Risks in Large\n  Language Models","summary":"  Recent research shows that fine-tuning on benign instruction-following data\ncan inadvertently undo the safety alignment process and increase a model's\npropensity to comply with harmful queries. While instruction-following\nfine-tuning is important, task-specific fine-tuning - where models are trained\non datasets with clear ground truth answers (e.g., multiple choice questions) -\ncan enhance model performance on specialized downstream tasks. Understanding\nand mitigating safety risks in the task-specific setting remains distinct from\nthe instruction-following context due to structural differences in the data.\nOur work demonstrates how malicious actors can subtly manipulate the structure\nof almost any task-specific dataset to foster significantly more dangerous\nmodel behaviors, while maintaining an appearance of innocuity and reasonable\ndownstream task performance. To address this issue, we propose a novel\nmitigation strategy that mixes in safety data which mimics the task format and\nprompting style of the user data, showing this is significantly more effective\nand efficient than existing baselines at re-establishing safety alignment while\nmaintaining similar task performance.\n","authors":["Francisco Eiras","Aleksandar Petrov","Philip H. S. Torr","M. Pawan Kumar","Adel Bibi"],"pdf_url":"https://arxiv.org/pdf/2406.10288v3.pdf","comment":"Accepted to ICLR'25"},{"id":"http://arxiv.org/abs/2502.20969v1","updated":"2025-02-28T11:32:22Z","published":"2025-02-28T11:32:22Z","title":"TeleRAG: Efficient Retrieval-Augmented Generation Inference with\n  Lookahead Retrieval","summary":"  Retrieval-augmented generation (RAG) extends large language models (LLMs)\nwith external data sources to enhance factual correctness and domain coverage.\nModern RAG pipelines rely on large datastores, leading to system challenges in\nlatency-sensitive deployments, especially when limited GPU memory is available.\nTo address these challenges, we propose TeleRAG, an efficient inference system\nthat reduces RAG latency with minimal GPU memory requirements. The core\ninnovation of TeleRAG is lookahead retrieval, a prefetching mechanism that\nanticipates required data and transfers it from CPU to GPU in parallel with LLM\ngeneration. By leveraging the modularity of RAG pipelines, the inverted file\nindex (IVF) search algorithm and similarities between queries, TeleRAG\noptimally overlaps data movement and computation. Experimental results show\nthat TeleRAG reduces end-to-end RAG inference latency by up to 1.72x on average\ncompared to state-of-the-art systems, enabling faster, more memory-efficient\ndeployments of advanced RAG applications.\n","authors":["Chien-Yu Lin","Keisuke Kamahori","Yiyu Liu","Xiaoxiang Shi","Madhav Kashyap","Yile Gu","Rulin Shao","Zihao Ye","Kan Zhu","Stephanie Wang","Arvind Krishnamurthy","Rohan Kadekodi","Luis Ceze","Baris Kasikci"],"pdf_url":"https://arxiv.org/pdf/2502.20969v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20132v2","updated":"2025-02-28T11:32:03Z","published":"2025-02-27T14:27:09Z","title":"Regional climate projections using a deep-learning-based model-ranking\n  and downscaling framework: Application to European climate zones","summary":"  Accurate regional climate forecast calls for high-resolution downscaling of\nGlobal Climate Models (GCMs). This work presents a deep-learning-based\nmulti-model evaluation and downscaling framework ranking 32 Coupled Model\nIntercomparison Project Phase 6 (CMIP6) models using a Deep Learning-TOPSIS\n(DL-TOPSIS) mechanism and so refines outputs using advanced deep-learning\nmodels. Using nine performance criteria, five K\\\"oppen-Geiger climate zones --\nTropical, Arid, Temperate, Continental, and Polar -- are investigated over four\nseasons. While TaiESM1 and CMCC-CM2-SR5 show notable biases, ranking results\nshow that NorESM2-LM, GISS-E2-1-G, and HadGEM3-GC31-LL outperform other models.\nFour models contribute to downscaling the top-ranked GCMs to 0.1$^{\\circ}$\nresolution: Vision Transformer (ViT), Geospatial Spatiotemporal Transformer\nwith Attention and Imbalance-Aware Network (GeoSTANet), CNN-LSTM, and CNN-Long\nShort-Term Memory (ConvLSTM). Effectively capturing temperature extremes (TXx,\nTNn), GeoSTANet achieves the highest accuracy (Root Mean Square Error (RMSE) =\n1.57$^{\\circ}$C, Kling-Gupta Efficiency (KGE) = 0.89, Nash-Sutcliffe Efficiency\n(NSE) = 0.85, Correlation ($r$) = 0.92), so reducing RMSE by 20% over ConvLSTM.\nCNN-LSTM and ConvLSTM do well in Continental and Temperate zones; ViT finds\nfine-scale temperature fluctuations difficult. These results confirm that\nmulti-criteria ranking improves GCM selection for regional climate studies and\ntransformer-based downscaling exceeds conventional deep-learning methods. This\nframework offers a scalable method to enhance high-resolution climate\nprojections, benefiting impact assessments and adaptation plans.\n","authors":["Parthiban Loganathan","Elias Zea","Ricardo Vinuesa","Evelyn Otero"],"pdf_url":"https://arxiv.org/pdf/2502.20132v2.pdf","comment":"This manuscript has been submitted to Environmental Science and\n  Pollution Research (ESPR) for review"},{"id":"http://arxiv.org/abs/2502.20966v1","updated":"2025-02-28T11:29:06Z","published":"2025-02-28T11:29:06Z","title":"Post-Hoc Uncertainty Quantification in Pre-Trained Neural Networks via\n  Activation-Level Gaussian Processes","summary":"  Uncertainty quantification in neural networks through methods such as\nDropout, Bayesian neural networks and Laplace approximations is either prone to\nunderfitting or computationally demanding, rendering these approaches\nimpractical for large-scale datasets. In this work, we address these\nshortcomings by shifting the focus from uncertainty in the weight space to\nuncertainty at the activation level, via Gaussian processes. More specifically,\nwe introduce the Gaussian Process Activation function (GAPA) to capture\nneuron-level uncertainties. Our approach operates in a post-hoc manner,\npreserving the original mean predictions of the pre-trained neural network and\nthereby avoiding the underfitting issues commonly encountered in previous\nmethods. We propose two methods. The first, GAPA-Free, employs empirical kernel\nlearning from the training data for the hyperparameters and is highly efficient\nduring training. The second, GAPA-Variational, learns the hyperparameters via\ngradient descent on the kernels, thus affording greater flexibility. Empirical\nresults demonstrate that GAPA-Variational outperforms the Laplace approximation\non most datasets in at least one of the uncertainty quantification metrics.\n","authors":["Richard Bergna","Stefan Depeweg","Sergio Calvo Ordonez","Jonathan Plenk","Alvaro Cartea","Jose Miguel Hernandez-Lobato"],"pdf_url":"https://arxiv.org/pdf/2502.20966v1.pdf","comment":"10 pages, 8 figures, 7th Symposium on Advances in Approximate\n  Bayesian Inference"},{"id":"http://arxiv.org/abs/2502.19635v2","updated":"2025-02-28T11:26:39Z","published":"2025-02-27T00:00:28Z","title":"Developing robust methods to handle missing data in real-world\n  applications effectively","summary":"  Missing data is a pervasive challenge spanning diverse data types, including\ntabular, sensor data, time-series, images and so on. Its origins are\nmultifaceted, resulting in various missing mechanisms. Prior research in this\nfield has predominantly revolved around the assumption of the Missing\nCompletely At Random (MCAR) mechanism. However, Missing At Random (MAR) and\nMissing Not At Random (MNAR) mechanisms, though equally prevalent, have often\nremained underexplored despite their significant influence. This PhD project\npresents a comprehensive research agenda designed to investigate the\nimplications of diverse missing data mechanisms. The principal aim is to devise\nrobust methodologies capable of effectively handling missing data while\naccommodating the unique characteristics of MCAR, MAR, and MNAR mechanisms. By\naddressing these gaps, this research contributes to an enriched understanding\nof the challenges posed by missing data across various industries and data\nmodalities. It seeks to provide practical solutions that enable the effective\nmanagement of missing data, empowering researchers and practitioners to\nleverage incomplete datasets confidently.\n","authors":["Youran Zhou","Mohamed Reda Bouadjenek","Sunil Aryal"],"pdf_url":"https://arxiv.org/pdf/2502.19635v2.pdf","comment":"This work was presented at the ECML PKDD 2024 PhD Forum.\n  https://ecmlpkdd. org/2024/program-accepted-phd-forum/"},{"id":"http://arxiv.org/abs/2502.20963v1","updated":"2025-02-28T11:25:11Z","published":"2025-02-28T11:25:11Z","title":"Retrieval Augmented Generation for Topic Modeling in Organizational\n  Research: An Introduction with Empirical Demonstration","summary":"  Analyzing textual data is the cornerstone of qualitative research. While\ntraditional methods such as grounded theory and content analysis are widely\nused, they are labor-intensive and time-consuming. Topic modeling offers an\nautomated complement. Yet, existing approaches, including LLM-based topic\nmodeling, still struggle with issues such as high data preprocessing\nrequirements, interpretability, and reliability. This paper introduces Agentic\nRetrieval-Augmented Generation (Agentic RAG) as a method for topic modeling\nwith LLMs. It integrates three key components: (1) retrieval, enabling\nautomatized access to external data beyond an LLM's pre-trained knowledge; (2)\ngeneration, leveraging LLM capabilities for text synthesis; and (3)\nagent-driven learning, iteratively refining retrieval and query formulation\nprocesses. To empirically validate Agentic RAG for topic modeling, we reanalyze\na Twitter/X dataset, previously examined by Mu et al. (2024a). Our findings\ndemonstrate that the approach is more efficient, interpretable and at the same\ntime achieves higher reliability and validity in comparison to the standard\nmachine learning approach but also in comparison to LLM prompting for topic\nmodeling. These results highlight Agentic RAG's ability to generate\nsemantically relevant and reproducible topics, positioning it as a robust,\nscalable, and transparent alternative for AI-driven qualitative research in\nleadership, managerial, and organizational research.\n","authors":["Gerion Spielberger","Florian Artinger","Jochen Reb","Rudolf Kerschreiter"],"pdf_url":"https://arxiv.org/pdf/2502.20963v1.pdf","comment":"30 pages, 4 figures"},{"id":"http://arxiv.org/abs/2403.04348v2","updated":"2025-02-28T11:25:10Z","published":"2024-03-07T09:22:50Z","title":"LoCoDL: Communication-Efficient Distributed Learning with Local Training\n  and Compression","summary":"  In Distributed optimization and Learning, and even more in the modern\nframework of federated learning, communication, which is slow and costly, is\ncritical. We introduce LoCoDL, a communication-efficient algorithm that\nleverages the two popular and effective techniques of Local training, which\nreduces the communication frequency, and Compression, in which short bitstreams\nare sent instead of full-dimensional vectors of floats. LoCoDL works with a\nlarge class of unbiased compressors that includes widely-used sparsification\nand quantization methods. LoCoDL provably benefits from local training and\ncompression and enjoys a doubly-accelerated communication complexity, with\nrespect to the condition number of the functions and the model dimension, in\nthe general heterogenous regime with strongly convex functions. This is\nconfirmed in practice, with LoCoDL outperforming existing algorithms.\n","authors":["Laurent Condat","Artavazd Maranjyan","Peter Richtárik"],"pdf_url":"https://arxiv.org/pdf/2403.04348v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20272v2","updated":"2025-02-28T11:13:24Z","published":"2025-02-27T16:59:51Z","title":"HVI: A New Color Space for Low-light Image Enhancement","summary":"  Low-Light Image Enhancement (LLIE) is a crucial computer vision task that\naims to restore detailed visual information from corrupted low-light images.\nMany existing LLIE methods are based on standard RGB (sRGB) space, which often\nproduce color bias and brightness artifacts due to inherent high color\nsensitivity in sRGB. While converting the images using Hue, Saturation and\nValue (HSV) color space helps resolve the brightness issue, it introduces\nsignificant red and black noise artifacts. To address this issue, we propose a\nnew color space for LLIE, namely Horizontal/Vertical-Intensity (HVI), defined\nby polarized HS maps and learnable intensity. The former enforces small\ndistances for red coordinates to remove the red artifacts, while the latter\ncompresses the low-light regions to remove the black artifacts. To fully\nleverage the chromatic and intensity information, a novel Color and Intensity\nDecoupling Network (CIDNet) is further introduced to learn accurate photometric\nmapping function under different lighting conditions in the HVI space.\nComprehensive results from benchmark and ablation experiments show that the\nproposed HVI color space with CIDNet outperforms the state-of-the-art methods\non 10 datasets. The code is available at https://github.com/Fediory/HVI-CIDNet.\n","authors":["Qingsen Yan","Yixu Feng","Cheng Zhang","Guansong Pang","Kangbiao Shi","Peng Wu","Wei Dong","Jinqiu Sun","Yanning Zhang"],"pdf_url":"https://arxiv.org/pdf/2502.20272v2.pdf","comment":"Qingsen Yan, Yixu Feng, and Cheng Zhang contributed equally to this\n  work"},{"id":"http://arxiv.org/abs/2502.20957v1","updated":"2025-02-28T11:13:23Z","published":"2025-02-28T11:13:23Z","title":"Reward Dimension Reduction for Scalable Multi-Objective Reinforcement\n  Learning","summary":"  In this paper, we introduce a simple yet effective reward dimension reduction\nmethod to tackle the scalability challenges of multi-objective reinforcement\nlearning algorithms. While most existing approaches focus on optimizing two to\nfour objectives, their abilities to scale to environments with more objectives\nremain uncertain. Our method uses a dimension reduction approach to enhance\nlearning efficiency and policy performance in multi-objective settings. While\nmost traditional dimension reduction methods are designed for static datasets,\nour approach is tailored for online learning and preserves Pareto-optimality\nafter transformation. We propose a new training and evaluation framework for\nreward dimension reduction in multi-objective reinforcement learning and\ndemonstrate the superiority of our method in environments including one with\nsixteen objectives, significantly outperforming existing online dimension\nreduction methods.\n","authors":["Giseung Park","Youngchul Sung"],"pdf_url":"https://arxiv.org/pdf/2502.20957v1.pdf","comment":"Accepted to ICLR 2025"},{"id":"http://arxiv.org/abs/2502.20954v1","updated":"2025-02-28T11:09:28Z","published":"2025-02-28T11:09:28Z","title":"Robust and Efficient Writer-Independent IMU-Based Handwriting\n  Recognization","summary":"  Online handwriting recognition (HWR) using data from inertial measurement\nunits (IMUs) remains challenging due to variations in writing styles and the\nlimited availability of high-quality annotated datasets. Traditional models\noften struggle to recognize handwriting from unseen writers, making\nwriter-independent (WI) recognition a crucial but difficult problem. This paper\npresents an HWR model with an encoder-decoder structure for IMU data, featuring\na CNN-based encoder for feature extraction and a BiLSTM decoder for sequence\nmodeling, which supports inputs of varying lengths. Our approach demonstrates\nstrong robustness and data efficiency, outperforming existing methods on WI\ndatasets, including the WI split of the OnHW dataset and our own dataset.\nExtensive evaluations show that our model maintains high accuracy across\ndifferent age groups and writing conditions while effectively learning from\nlimited data. Through comprehensive ablation studies, we analyze key design\nchoices, achieving a balance between accuracy and efficiency. These findings\ncontribute to the development of more adaptable and scalable HWR systems for\nreal-world applications.\n","authors":["Jindong Li","Tim Hamann","Jens Barth","Peter Kaempf","Dario Zanca","Bjoern Eskofier"],"pdf_url":"https://arxiv.org/pdf/2502.20954v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20952v1","updated":"2025-02-28T11:07:41Z","published":"2025-02-28T11:07:41Z","title":"Efficient Jailbreaking of Large Models by Freeze Training: Lower Layers\n  Exhibit Greater Sensitivity to Harmful Content","summary":"  With the widespread application of Large Language Models across various\ndomains, their security issues have increasingly garnered significant attention\nfrom both academic and industrial communities. This study conducts sampling and\nnormalization of the parameters of the LLM to generate visual representations\nand heatmaps of parameter distributions, revealing notable discrepancies in\nparameter distributions among certain layers within the hidden layers. Further\nanalysis involves calculating statistical metrics for each layer, followed by\nthe computation of a Comprehensive Sensitivity Score based on these metrics,\nwhich identifies the lower layers as being particularly sensitive to the\ngeneration of harmful content. Based on this finding, we employ a Freeze\ntraining strategy, selectively performing Supervised Fine-Tuning only on the\nlower layers. Experimental results demonstrate that this method significantly\nreduces training duration and GPU memory consumption while maintaining a high\njailbreak success rate and a high harm score, outperforming the results\nachieved by applying the LoRA method for SFT across all layers. Additionally,\nthe method has been successfully extended to other open-source large models,\nvalidating its generality and effectiveness across different model\narchitectures. Furthermore, we compare our method with ohter jailbreak method,\ndemonstrating the superior performance of our approach. By innovatively\nproposing a method to statistically analyze and compare large model parameters\nlayer by layer, this study provides new insights into the interpretability of\nlarge models. These discoveries emphasize the necessity of continuous research\nand the implementation of adaptive security measures in the rapidly evolving\nfield of LLMs to prevent potential jailbreak attack risks, thereby promoting\nthe development of more robust and secure LLMs.\n","authors":["Hongyuan Shen","Min Zheng","Jincheng Wang","Yang Zhao"],"pdf_url":"https://arxiv.org/pdf/2502.20952v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.20623v2","updated":"2025-02-28T11:07:22Z","published":"2024-05-31T05:21:12Z","title":"Sparse-ProxSkip: Accelerated Sparse-to-Sparse Training in Federated\n  Learning","summary":"  In Federated Learning (FL), both client resource constraints and\ncommunication costs pose major problems for training large models. In the\ncentralized setting, sparse training addresses resource constraints, while in\nthe distributed setting, local training addresses communication costs. Recent\nwork has shown that local training provably improves communication complexity\nthrough acceleration. In this work we show that in FL, naive integration of\nsparse training and acceleration fails, and we provide theoretical and\nempirical explanations of this phenomenon. We introduce Sparse-ProxSkip,\naddressing the issue and implementing the efficient technique of\nStraight-Through Estimator pruning into sparse training. We demonstrate the\nperformance of Sparse-ProxSkip in extensive experiments.\n","authors":["Georg Meinhardt","Kai Yi","Laurent Condat","Peter Richtárik"],"pdf_url":"https://arxiv.org/pdf/2405.20623v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20948v1","updated":"2025-02-28T11:03:32Z","published":"2025-02-28T11:03:32Z","title":"Concealed Adversarial attacks on neural networks for sequential data","summary":"  The emergence of deep learning led to the broad usage of neural networks in\nthe time series domain for various applications, including finance and\nmedicine. While powerful, these models are prone to adversarial attacks: a\nbenign targeted perturbation of input data leads to significant changes in a\nclassifier's output. However, formally small attacks in the time series domain\nbecome easily detected by the human eye or a simple detector model.\n  We develop a concealed adversarial attack for different time-series models:\nit provides more realistic perturbations, being hard to detect by a human or\nmodel discriminator. To achieve this goal, the proposed adversarial attack\nmaximizes an aggregation of a classifier and a trained discriminator loss. To\nmake the attack stronger, we also propose a training procedure for a\ndiscriminator that provides broader coverage of possible attacks. Extensive\nbenchmarking on six UCR time series datasets across four diverse architectures\n- including recurrent, convolutional, state-space, and transformer-based models\n- demonstrates the superiority of our attack for a concealability-efficiency\ntrade-off. Our findings highlight the growing challenge of designing robust\ntime series models, emphasizing the need for improved defenses against\nrealistic and effective attacks.\n","authors":["Petr Sokerin","Dmitry Anikin","Sofia Krehova","Alexey Zaytsev"],"pdf_url":"https://arxiv.org/pdf/2502.20948v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20946v1","updated":"2025-02-28T10:56:39Z","published":"2025-02-28T10:56:39Z","title":"Generative Uncertainty in Diffusion Models","summary":"  Diffusion models have recently driven significant breakthroughs in generative\nmodeling. While state-of-the-art models produce high-quality samples on\naverage, individual samples can still be low quality. Detecting such samples\nwithout human inspection remains a challenging task. To address this, we\npropose a Bayesian framework for estimating generative uncertainty of synthetic\nsamples. We outline how to make Bayesian inference practical for large, modern\ngenerative models and introduce a new semantic likelihood (evaluated in the\nlatent space of a feature extractor) to address the challenges posed by\nhigh-dimensional sample spaces. Through our experiments, we demonstrate that\nthe proposed generative uncertainty effectively identifies poor-quality samples\nand significantly outperforms existing uncertainty-based methods. Notably, our\nBayesian framework can be applied post-hoc to any pretrained diffusion or flow\nmatching model (via the Laplace approximation), and we propose simple yet\neffective techniques to minimize its computational overhead during sampling.\n","authors":["Metod Jazbec","Eliot Wong-Toi","Guoxuan Xia","Dan Zhang","Eric Nalisnick","Stephan Mandt"],"pdf_url":"https://arxiv.org/pdf/2502.20946v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.07386v2","updated":"2025-02-28T10:56:33Z","published":"2024-08-14T09:06:25Z","title":"Fading memory and the convolution theorem","summary":"  Several topological and analytical notions of continuity and fading memory\nfor causal and time-invariant filters are introduced, and the relations between\nthem are analyzed. A significant generalization of the convolution theorem that\nestablishes the equivalence between the fading memory property and the\navailability of convolution representations of linear filters is proved. This\nresult extends a previous similar characterization to a complete array of\nweighted norms in the definition of the fading memory property. Additionally,\nthe main theorem shows that the availability of convolution representations can\nbe characterized, at least when the codomain is finite-dimensional, not only by\nthe fading memory property but also by the reunion of two purely topological\nnotions that are called minimal continuity and minimal fading memory property.\nFinally, when the input space and the codomain of a linear functional are\nHilbert spaces, it is shown that minimal continuity and the minimal fading\nmemory property guarantee the existence of interesting embeddings of the\nassociated reproducing kernel Hilbert spaces.\n","authors":["Juan-Pablo Ortega","Florian Rossmannek"],"pdf_url":"https://arxiv.org/pdf/2408.07386v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17146v2","updated":"2025-02-28T10:53:12Z","published":"2024-10-22T16:26:05Z","title":"LiNeS: Post-training Layer Scaling Prevents Forgetting and Enhances\n  Model Merging","summary":"  Fine-tuning pre-trained models has become the standard approach to endow them\nwith specialized knowledge, but it poses fundamental challenges. In particular,\n\\textit{(i)} fine-tuning often leads to catastrophic forgetting, where\nimprovements on a target domain degrade generalization on other tasks, and\n\\textit{(ii)} merging fine-tuned checkpoints from disparate tasks can lead to\nsignificant performance loss. To address these challenges, we introduce LiNeS,\nLayer-increasing Network Scaling, a post-training editing technique designed to\npreserve pre-trained generalization while enhancing fine-tuned task\nperformance. LiNeS scales parameter updates linearly based on their layer depth\nwithin the network, maintaining shallow layers close to their pre-trained\nvalues to preserve general features while allowing deeper layers to retain\ntask-specific representations. In multi-task model merging scenarios,\nlayer-wise scaling of merged parameters reduces negative task interference.\nLiNeS demonstrates significant improvements in both single-task and multi-task\nsettings across various benchmarks in vision and natural language processing.\nIt mitigates forgetting, enhances out-of-distribution generalization,\nintegrates seamlessly with existing multi-task model merging baselines\nimproving their performance across benchmarks and model sizes, and can boost\ngeneralization when merging LLM policies aligned with different rewards via\nRLHF. Our method is simple to implement, computationally efficient and\ncomplementary to many existing techniques. Our source code is available at\nhttps://github.com/wang-kee/LiNeS\n","authors":["Ke Wang","Nikolaos Dimitriadis","Alessandro Favero","Guillermo Ortiz-Jimenez","Francois Fleuret","Pascal Frossard"],"pdf_url":"https://arxiv.org/pdf/2410.17146v2.pdf","comment":"The first two authors contributed equally to this work. Accepted at\n  ICLR 2025. Project website: https://lines-merging.github.io"},{"id":"http://arxiv.org/abs/2502.20933v1","updated":"2025-02-28T10:41:16Z","published":"2025-02-28T10:41:16Z","title":"Large Language Models Are Innate Crystal Structure Generators","summary":"  Crystal structure generation is fundamental to materials discovery, enabling\nthe prediction of novel materials with desired properties. While existing\napproaches leverage Large Language Models (LLMs) through extensive fine-tuning\non materials databases, we show that pre-trained LLMs can inherently generate\nstable crystal structures without additional training. Our novel framework\nMatLLMSearch integrates pre-trained LLMs with evolutionary search algorithms,\nachieving a 78.38% metastable rate validated by machine learning interatomic\npotentials and 31.7% DFT-verified stability via quantum mechanical\ncalculations, outperforming specialized models such as CrystalTextLLM. Beyond\ncrystal structure generation, we further demonstrate that our framework can be\nreadily adapted to diverse materials design tasks, including crystal structure\nprediction and multi-objective optimization of properties such as deformation\nenergy and bulk modulus, all without fine-tuning. These results establish\npre-trained LLMs as versatile and effective tools for materials discovery,\nopening up new venues for crystal structure generation with reduced\ncomputational overhead and broader accessibility.\n","authors":["Jingru Gan","Peichen Zhong","Yuanqi Du","Yanqiao Zhu","Chenru Duan","Haorui Wang","Carla P. Gomes","Kristin A. Persson","Daniel Schwalbe-Koda","Wei Wang"],"pdf_url":"https://arxiv.org/pdf/2502.20933v1.pdf","comment":"Preprint, 18 pages"},{"id":"http://arxiv.org/abs/2405.01009v2","updated":"2025-02-28T10:37:29Z","published":"2024-05-02T05:23:58Z","title":"On Oversquashing in Graph Neural Networks Through the Lens of Dynamical\n  Systems","summary":"  A common problem in Message-Passing Neural Networks is oversquashing -- the\nlimited ability to facilitate effective information flow between distant nodes.\nOversquashing is attributed to the exponential decay in information\ntransmission as node distances increase. This paper introduces a novel\nperspective to address oversquashing, leveraging dynamical systems properties\nof global and local non-dissipativity, that enable the maintenance of a\nconstant information flow rate. We present SWAN, a uniquely parameterized GNN\nmodel with antisymmetry both in space and weight domains, as a means to obtain\nnon-dissipativity. Our theoretical analysis asserts that by implementing these\nproperties, SWAN offers an enhanced ability to transmit information over\nextended distances. Empirical evaluations on synthetic and real-world\nbenchmarks that emphasize long-range interactions validate the theoretical\nunderstanding of SWAN, and its ability to mitigate oversquashing.\n","authors":["Alessio Gravina","Moshe Eliasof","Claudio Gallicchio","Davide Bacciu","Carola-Bibiane Schönlieb"],"pdf_url":"https://arxiv.org/pdf/2405.01009v2.pdf","comment":"AAAI 2025"},{"id":"http://arxiv.org/abs/2408.08558v5","updated":"2025-02-28T10:37:12Z","published":"2024-08-16T06:43:58Z","title":"Linear combinations of latents in generative models: subspaces and\n  beyond","summary":"  Sampling from generative models has become a crucial tool for applications\nlike data synthesis and augmentation. Diffusion, Flow Matching and Continuous\nNormalizing Flows have shown effectiveness across various modalities, and rely\non latent variables for generation. For experimental design or creative\napplications that require more control over the generation process, it has\nbecome common to manipulate the latent variable directly. However, existing\napproaches for performing such manipulations (e.g. interpolation or forming\nlow-dimensional representations) only work well in special cases or are network\nor data-modality specific. We propose Linear combinations of Latent variables\n(LOL) as a general-purpose method to form linear combinations of latent\nvariables that adhere to the assumptions of the generative model. As LOL is\neasy to implement and naturally addresses the broader task of forming any\nlinear combinations, e.g. the construction of subspaces of the latent space,\nLOL dramatically simplifies the creation of expressive low-dimensional\nrepresentations of high-dimensional objects.\n","authors":["Erik Bodin","Alexandru Stere","Dragos D. Margineantu","Carl Henrik Ek","Henry Moss"],"pdf_url":"https://arxiv.org/pdf/2408.08558v5.pdf","comment":"Published at International Conference on Learning Representations\n  (ICLR) 2025"},{"id":"http://arxiv.org/abs/2502.20925v1","updated":"2025-02-28T10:29:56Z","published":"2025-02-28T10:29:56Z","title":"Amortized Conditional Independence Testing","summary":"  Testing for the conditional independence structure in data is a fundamental\nand critical task in statistics and machine learning, which finds natural\napplications in causal discovery - a highly relevant problem to many scientific\ndisciplines. Existing methods seek to design explicit test statistics that\nquantify the degree of conditional dependence, which is highly challenging yet\ncannot capture nor utilize prior knowledge in a data-driven manner. In this\nstudy, an entirely new approach is introduced, where we instead propose to\namortize conditional independence testing and devise ACID - a novel\ntransformer-based neural network architecture that learns to test for\nconditional independence. ACID can be trained on synthetic data in a supervised\nlearning fashion, and the learned model can then be applied to any dataset of\nsimilar natures or adapted to new domains by fine-tuning with a negligible\ncomputational cost. Our extensive empirical evaluations on both synthetic and\nreal data reveal that ACID consistently achieves state-of-the-art performance\nagainst existing baselines under multiple metrics, and is able to generalize\nrobustly to unseen sample sizes, dimensionalities, as well as non-linearities\nwith a remarkably low inference time.\n","authors":["Bao Duong","Nu Hoang","Thin Nguyen"],"pdf_url":"https://arxiv.org/pdf/2502.20925v1.pdf","comment":"Accepted at PAKDD 2025"},{"id":"http://arxiv.org/abs/2502.20914v1","updated":"2025-02-28T10:13:54Z","published":"2025-02-28T10:13:54Z","title":"Everything, Everywhere, All at Once: Is Mechanistic Interpretability\n  Identifiable?","summary":"  As AI systems are used in high-stakes applications, ensuring interpretability\nis crucial. Mechanistic Interpretability (MI) aims to reverse-engineer neural\nnetworks by extracting human-understandable algorithms to explain their\nbehavior. This work examines a key question: for a given behavior, and under\nMI's criteria, does a unique explanation exist? Drawing on identifiability in\nstatistics, where parameters are uniquely inferred under specific assumptions,\nwe explore the identifiability of MI explanations.\n  We identify two main MI strategies: (1) \"where-then-what,\" which isolates a\ncircuit replicating model behavior before interpreting it, and (2)\n\"what-then-where,\" which starts with candidate algorithms and searches for\nneural activation subspaces implementing them, using causal alignment.\n  We test both strategies on Boolean functions and small multi-layer\nperceptrons, fully enumerating candidate explanations. Our experiments reveal\nsystematic non-identifiability: multiple circuits can replicate behavior, a\ncircuit can have multiple interpretations, several algorithms can align with\nthe network, and one algorithm can align with different subspaces.\n  Is uniqueness necessary? A pragmatic approach may require only predictive and\nmanipulability standards. If uniqueness is essential for understanding,\nstricter criteria may be needed. We also reference the inner interpretability\nframework, which validates explanations through multiple criteria. This work\ncontributes to defining explanation standards in AI.\n","authors":["Maxime Méloux","Silviu Maniu","François Portet","Maxime Peyrard"],"pdf_url":"https://arxiv.org/pdf/2502.20914v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.13211v3","updated":"2025-02-28T10:10:33Z","published":"2024-12-09T01:29:24Z","title":"ManiSkill-HAB: A Benchmark for Low-Level Manipulation in Home\n  Rearrangement Tasks","summary":"  High-quality benchmarks are the foundation for embodied AI research, enabling\nsignificant advancements in long-horizon navigation, manipulation and\nrearrangement tasks. However, as frontier tasks in robotics get more advanced,\nthey require faster simulation speed, more intricate test environments, and\nlarger demonstration datasets. To this end, we present MS-HAB, a holistic\nbenchmark for low-level manipulation and in-home object rearrangement. First,\nwe provide a GPU-accelerated implementation of the Home Assistant Benchmark\n(HAB). We support realistic low-level control and achieve over 3x the speed of\nprior magical grasp implementations at a fraction of the GPU memory usage.\nSecond, we train extensive reinforcement learning (RL) and imitation learning\n(IL) baselines for future work to compare against. Finally, we develop a\nrule-based trajectory filtering system to sample specific demonstrations from\nour RL policies which match predefined criteria for robot behavior and safety.\nCombining demonstration filtering with our fast environments enables efficient,\ncontrolled data generation at scale.\n","authors":["Arth Shukla","Stone Tao","Hao Su"],"pdf_url":"https://arxiv.org/pdf/2412.13211v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.13526v2","updated":"2025-02-28T09:34:37Z","published":"2024-05-22T10:51:12Z","title":"Understanding Virtual Nodes: Oversquashing and Node Heterogeneity","summary":"  While message passing neural networks (MPNNs) have convincing success in a\nrange of applications, they exhibit limitations such as the oversquashing\nproblem and their inability to capture long-range interactions. Augmenting\nMPNNs with a virtual node (VN) removes the locality constraint of the layer\naggregation and has been found to improve performance on a range of benchmarks.\nWe provide a comprehensive theoretical analysis of the role of VNs and benefits\nthereof, through the lenses of oversquashing and sensitivity analysis. First,\nwe characterize, precisely, how the improvement afforded by VNs on the mixing\nabilities of the network and hence in mitigating oversquashing, depends on the\nunderlying topology. We then highlight that, unlike Graph-Transformers (GTs),\nclassical instantiations of the VN are often constrained to assign uniform\nimportance to different nodes. Consequently, we propose a variant of VN with\nthe same computational complexity, which can have different sensitivity to\nnodes based on the graph structure. We show that this is an extremely effective\nand computationally efficient baseline for graph-level tasks.\n","authors":["Joshua Southern","Francesco Di Giovanni","Michael Bronstein","Johannes F. Lutzeyer"],"pdf_url":"https://arxiv.org/pdf/2405.13526v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20885v1","updated":"2025-02-28T09:32:07Z","published":"2025-02-28T09:32:07Z","title":"A Fused Gromov-Wasserstein Approach to Subgraph Contrastive Learning","summary":"  Self-supervised learning has become a key method for training deep learning\nmodels when labeled data is scarce or unavailable. While graph machine learning\nholds great promise across various domains, the design of effective pretext\ntasks for self-supervised graph representation learning remains challenging.\nContrastive learning, a popular approach in graph self-supervised learning,\nleverages positive and negative pairs to compute a contrastive loss function.\nHowever, current graph contrastive learning methods often struggle to fully use\nstructural patterns and node similarities. To address these issues, we present\na new method called Fused Gromov Wasserstein Subgraph Contrastive Learning\n(FOSSIL). Our model integrates node-level and subgraph-level contrastive\nlearning, seamlessly combining a standard node-level contrastive loss with the\nFused Gromov-Wasserstein distance. This combination helps our method capture\nboth node features and graph structure together. Importantly, our approach\nworks well with both homophilic and heterophilic graphs and can dynamically\ncreate views for generating positive and negative pairs. Through extensive\nexperiments on benchmark graph datasets, we show that FOSSIL outperforms or\nachieves competitive performance compared to current state-of-the-art methods.\n","authors":["Amadou S. Sangare","Nicolas Dunou","Jhony H. Giraldo","Fragkiskos D. Malliaros"],"pdf_url":"https://arxiv.org/pdf/2502.20885v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01767v2","updated":"2025-02-28T09:26:15Z","published":"2024-10-02T17:22:09Z","title":"Utility-Directed Conformal Prediction: A Decision-Aware Framework for\n  Actionable Uncertainty Quantification","summary":"  Interest has been growing in decision-focused machine learning methods which\ntrain models to account for how their predictions are used in downstream\noptimization problems. Doing so can often improve performance on subsequent\ndecision problems. However, current methods for uncertainty quantification do\nnot incorporate any information about downstream decisions. We develop a\nmethodology based on conformal prediction to identify prediction sets that\naccount for a downstream cost function, making them more appropriate to inform\nhigh-stakes decision-making. Our approach harnesses the strengths of conformal\nmethods -- modularity, model-agnosticism, and statistical coverage guarantees\n-- while incorporating downstream decisions and user-specified utility\nfunctions. We prove that our methods retain standard coverage guarantees.\nEmpirical evaluation across a range of datasets and utility metrics\ndemonstrates that our methods achieve significantly lower costs than standard\nconformal methods. We present a real-world use case in healthcare diagnosis,\nwhere our method effectively incorporates the hierarchical structure of\ndermatological diseases. The method successfully generates sets with coherent\ndiagnostic meaning, potentially aiding triage for dermatology diagnosis and\nillustrating how our method can ground high-stakes decision-making employing\ndomain knowledge.\n","authors":["Santiago Cortes-Gomez","Carlos Patiño","Yewon Byun","Steven Wu","Eric Horvitz","Bryan Wilder"],"pdf_url":"https://arxiv.org/pdf/2410.01767v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20881v1","updated":"2025-02-28T09:25:49Z","published":"2025-02-28T09:25:49Z","title":"Hamiltonian Neural Networks approach to fuzzball geodesics","summary":"  The recent increase in computational resources and data availability has led\nto a significant rise in the use of Machine Learning (ML) techniques for data\nanalysis in physics. However, the application of ML methods to solve\ndifferential equations capable of describing even complex physical systems is\nnot yet fully widespread in theoretical high-energy physics. Hamiltonian Neural\nNetworks (HNNs) are tools that minimize a loss function defined to solve\nHamilton equations of motion. In this work, we implement several HNNs trained\nto solve, with high accuracy, the Hamilton equations for a massless probe\nmoving inside a smooth and horizonless geometry known as D1-D5 circular\nfuzzball. We study both planar (equatorial) and non-planar geodesics in\ndifferent regimes according to the impact parameter, some of which are\nunstable. Our findings suggest that HNNs could eventually replace standard\nnumerical integrators, as they are equally accurate but more reliable in\ncritical situations.\n","authors":["Andrea Cipriani","Alessandro De Santis","Giorgio Di Russo","Alfredo Grillo","Luca Tabarroni"],"pdf_url":"https://arxiv.org/pdf/2502.20881v1.pdf","comment":"25 pages + Appendices, 39 figures"},{"id":"http://arxiv.org/abs/2403.01570v3","updated":"2025-02-28T09:23:04Z","published":"2024-03-03T17:35:52Z","title":"Small Models are LLM Knowledge Triggers on Medical Tabular Prediction","summary":"  Recent development in large language models (LLMs) has demonstrated\nimpressive domain proficiency on unstructured textual or multi-modal tasks.\nHowever, despite with intrinsic world knowledge, their application on\nstructured tabular data prediction still lags behind, primarily due to the\nnumerical insensitivity and modality discrepancy that brings a gap between LLM\nreasoning and statistical tabular learning. Unlike textual or vision data\n(e.g., electronic clinical notes or medical imaging data), tabular data is\noften presented in heterogeneous numerical values (e.g., CBC reports). This\nubiquitous data format requires intensive expert annotation, and its numerical\nnature limits LLMs' capability to effectively transfer untapped domain\nexpertise. In this paper, we propose SERSAL, a general self-prompting method by\nsynergy learning with small models to enhance LLM tabular prediction in an\nunsupervised manner. Specifically, SERSAL utilizes the LLM's prior outcomes as\noriginal soft noisy annotations, which are dynamically leveraged to teach a\nbetter small student model. Reversely, the outcomes from the trained small\nmodel are used to teach the LLM to further refine its real capability. This\nprocess can be repeatedly applied to gradually distill refined knowledge for\ncontinuous progress. Comprehensive experiments on widely used medical domain\ntabular datasets show that, without access to gold labels, applying SERSAL to\nOpenAI GPT reasoning process attains substantial improvement compared to\nlinguistic prompting methods, which serves as an orthogonal direction for\ntabular LLM, and increasing prompting bonus is observed as more powerful LLMs\nappear.\n","authors":["Jiahuan Yan","Jintai Chen","Chaowen Hu","Bo Zheng","Yaojun Hu","Jimeng Sun","Jian Wu"],"pdf_url":"https://arxiv.org/pdf/2403.01570v3.pdf","comment":"Accepted to ICLR 2025. Codes will be available at\n  https://github.com/jyansir/sersal"},{"id":"http://arxiv.org/abs/2411.12537v3","updated":"2025-02-28T09:17:14Z","published":"2024-11-19T14:35:38Z","title":"Unlocking State-Tracking in Linear RNNs Through Negative Eigenvalues","summary":"  Linear Recurrent Neural Networks (LRNNs) such as Mamba, RWKV, GLA, mLSTM, and\nDeltaNet have emerged as efficient alternatives to Transformers for long\nsequences. However, both Transformers and LRNNs struggle to perform\nstate-tracking, which may impair performance in tasks such as code evaluation.\nIn one forward pass, current architectures are unable to solve even parity, the\nsimplest state-tracking task, which non-linear RNNs can handle effectively.\nRecently, Sarrof et al. (2024) demonstrated that the failure of LRNNs like\nMamba to solve parity stems from restricting the value range of their diagonal\nstate-transition matrices to $[0, 1]$ and that incorporating negative values\ncan resolve this issue. We extend this result to non-diagonal LRNNs such as\nDeltaNet. We prove that finite precision LRNNs with state-transition matrices\nhaving only positive eigenvalues cannot solve parity, while non-triangular\nmatrices are needed to count modulo $3$. Notably, we also prove that LRNNs can\nlearn any regular language when their state-transition matrices are products of\nidentity minus vector outer product matrices, each with eigenvalues in the\nrange $[-1, 1]$. Our experiments confirm that extending the eigenvalue range of\nMamba and DeltaNet to include negative values not only enables them to solve\nparity but consistently improves their performance on state-tracking tasks. We\nalso show that state-tracking enabled LRNNs can be pretrained stably and\nefficiently at scale (1.3B parameters), achieving competitive performance on\nlanguage modeling and showing promise on code and math tasks.\n","authors":["Riccardo Grazzi","Julien Siems","Jörg K. H. Franke","Arber Zela","Frank Hutter","Massimiliano Pontil"],"pdf_url":"https://arxiv.org/pdf/2411.12537v3.pdf","comment":"V2: Correction to Theorem 1 and 2 and to point 3 of Proposition 1.\n  V3: ICLR Camera Ready"},{"id":"http://arxiv.org/abs/2410.10516v2","updated":"2025-02-28T09:12:22Z","published":"2024-10-14T13:58:13Z","title":"UniGEM: A Unified Approach to Generation and Property Prediction for\n  Molecules","summary":"  Molecular generation and molecular property prediction are both crucial for\ndrug discovery, but they are often developed independently. Inspired by recent\nstudies, which demonstrate that diffusion model, a prominent generative\napproach, can learn meaningful data representations that enhance predictive\ntasks, we explore the potential for developing a unified generative model in\nthe molecular domain that effectively addresses both molecular generation and\nproperty prediction tasks. However, the integration of these tasks is\nchallenging due to inherent inconsistencies, making simple multi-task learning\nineffective. To address this, we propose UniGEM, the first unified model to\nsuccessfully integrate molecular generation and property prediction, delivering\nsuperior performance in both tasks. Our key innovation lies in a novel\ntwo-phase generative process, where predictive tasks are activated in the later\nstages, after the molecular scaffold is formed. We further enhance task balance\nthrough innovative training strategies. Rigorous theoretical analysis and\ncomprehensive experiments demonstrate our significant improvements in both\ntasks. The principles behind UniGEM hold promise for broader applications,\nincluding natural language processing and computer vision.\n","authors":["Shikun Feng","Yuyan Ni","Yan Lu","Zhi-Ming Ma","Wei-Ying Ma","Yanyan Lan"],"pdf_url":"https://arxiv.org/pdf/2410.10516v2.pdf","comment":"11 pages, 5 figures"},{"id":"http://arxiv.org/abs/2410.02246v2","updated":"2025-02-28T09:03:21Z","published":"2024-10-03T06:37:16Z","title":"PFGuard: A Generative Framework with Privacy and Fairness Safeguards","summary":"  Generative models must ensure both privacy and fairness for Trustworthy AI.\nWhile these goals have been pursued separately, recent studies propose to\ncombine existing privacy and fairness techniques to achieve both goals.\nHowever, naively combining these techniques can be insufficient due to\nprivacy-fairness conflicts, where a sample in a minority group may be\nrepresented in ways that support fairness, only to be suppressed for privacy.\nWe demonstrate how these conflicts lead to adverse effects, such as privacy\nviolations and unexpected fairness-utility tradeoffs. To mitigate these risks,\nwe propose PFGuard, a generative framework with privacy and fairness\nsafeguards, which simultaneously addresses privacy, fairness, and utility. By\nusing an ensemble of multiple teacher models, PFGuard balances privacy-fairness\nconflicts between fair and private training stages and achieves high utility\nbased on ensemble learning. Extensive experiments show that PFGuard\nsuccessfully generates synthetic data on high-dimensional data while providing\nboth DP guarantees and convergence in fair generative modeling.\n","authors":["Soyeon Kim","Yuji Roh","Geon Heo","Steven Euijong Whang"],"pdf_url":"https://arxiv.org/pdf/2410.02246v2.pdf","comment":"In Proceedings of the 13th International Conference on Learning\n  Representations (ICLR), 2025"},{"id":"http://arxiv.org/abs/2410.01500v2","updated":"2025-02-28T08:55:22Z","published":"2024-10-02T12:51:25Z","title":"Discrete Diffusion Schrödinger Bridge Matching for Graph\n  Transformation","summary":"  Transporting between arbitrary distributions is a fundamental goal in\ngenerative modeling. Recently proposed diffusion bridge models provide a\npotential solution, but they rely on a joint distribution that is difficult to\nobtain in practice. Furthermore, formulations based on continuous domains limit\ntheir applicability to discrete domains such as graphs. To overcome these\nlimitations, we propose Discrete Diffusion Schr\\\"odinger Bridge Matching\n(DDSBM), a novel framework that utilizes continuous-time Markov chains to solve\nthe SB problem in a high-dimensional discrete state space. Our approach extends\nIterative Markovian Fitting to discrete domains, and we have proved its\nconvergence to the SB. Furthermore, we adapt our framework for the graph\ntransformation, and show that our design choice of underlying dynamics\ncharacterized by independent modifications of nodes and edges can be\ninterpreted as the entropy-regularized version of optimal transport with a cost\nfunction described by the graph edit distance. To demonstrate the effectiveness\nof our framework, we have applied DDSBM to molecular optimization in the field\nof chemistry. Experimental results demonstrate that DDSBM effectively optimizes\nmolecules' property-of-interest with minimal graph transformation, successfully\nretaining other features. Source code is available\n$\\href{https://github.com/junhkim1226/DDSBM}{here}$.\n","authors":["Jun Hyeong Kim","Seonghwan Kim","Seokhyun Moon","Hyeongwoo Kim","Jeheon Woo","Woo Youn Kim"],"pdf_url":"https://arxiv.org/pdf/2410.01500v2.pdf","comment":"Accepted to ICLR 2025"},{"id":"http://arxiv.org/abs/2502.20855v1","updated":"2025-02-28T08:53:42Z","published":"2025-02-28T08:53:42Z","title":"MAMUT: A Novel Framework for Modifying Mathematical Formulas for the\n  Generation of Specialized Datasets for Language Model Training","summary":"  Mathematical formulas are a fundamental and widely used component in various\nscientific fields, serving as a universal language for expressing complex\nconcepts and relationships. While state-of-the-art transformer models excel in\nprocessing and understanding natural language, they encounter challenges with\nmathematical notation, which involves a complex structure and diverse\nrepresentations. This study focuses on the development of specialized training\ndatasets to enhance the encoding of mathematical content. We introduce Math\nMutator (MAMUT), a framework capable of generating equivalent and falsified\nversions of a given mathematical formula in LaTeX notation, effectively\ncapturing the mathematical variety in notation of the same concept. Based on\nMAMUT, we have generated four large mathematical datasets containing diverse\nnotation, which can be used to train language models with enhanced mathematical\nembeddings.\n","authors":["Jonathan Drechsel","Anja Reusch","Steffen Herbold"],"pdf_url":"https://arxiv.org/pdf/2502.20855v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.08679v2","updated":"2025-02-28T08:53:41Z","published":"2025-02-12T08:56:35Z","title":"Deep Learning-Driven Malware Classification with API Call Sequence\n  Analysis and Concept Drift Handling","summary":"  Malware classification in dynamic environments presents a significant\nchallenge due to concept drift, where the statistical properties of malware\ndata evolve over time, complicating detection efforts. To address this issue,\nwe propose a deep learning framework enhanced with a genetic algorithm to\nimprove malware classification accuracy and adaptability. Our approach\nincorporates mutation operations and fitness score evaluations within genetic\nalgorithms to continuously refine the deep learning model, ensuring robustness\nagainst evolving malware threats. Experimental results demonstrate that this\nhybrid method significantly enhances classification performance and\nadaptability, outperforming traditional static models. Our proposed approach\noffers a promising solution for real-time malware classification in\never-changing cybersecurity landscapes.\n","authors":["Bishwajit Prasad Gond","Durga Prasad Mohapatra"],"pdf_url":"https://arxiv.org/pdf/2502.08679v2.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2502.20904v1","updated":"2025-02-28T10:01:39Z","published":"2025-02-28T10:01:39Z","title":"DiffBrush:Just Painting the Art by Your Hands","summary":"  The rapid development of image generation and editing algorithms in recent\nyears has enabled ordinary user to produce realistic images. However, the\ncurrent AI painting ecosystem predominantly relies on text-driven diffusion\nmodels (T2I), which pose challenges in accurately capturing user requirements.\nFurthermore, achieving compatibility with other modalities incurs substantial\ntraining costs. To this end, we introduce DiffBrush, which is compatible with\nT2I models and allows users to draw and edit images. By manipulating and\nadapting the internal representation of the diffusion model, DiffBrush guides\nthe model-generated images to converge towards the user's hand-drawn sketches\nfor user's specific needs without additional training. DiffBrush achieves\ncontrol over the color, semantic, and instance of objects in images by\ncontinuously guiding the latent and instance-level attention map during the\ndenoising process of the diffusion model. Besides, we propose a latent\nregeneration, which refines the randomly sampled noise in the diffusion model,\nobtaining a better image generation layout. Finally, users only need to roughly\ndraw the mask of the instance (acceptable colors) on the canvas, DiffBrush can\nnaturally generate the corresponding instance at the corresponding location.\n","authors":["Jiaming Chu","Lei Jin","Tao Wang","Junliang Xing","Jian Zhao"],"pdf_url":"https://arxiv.org/pdf/2502.20904v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20858v1","updated":"2025-02-28T09:01:30Z","published":"2025-02-28T09:01:30Z","title":"EyEar: Learning Audio Synchronized Human Gaze Trajectory Based on\n  Physics-Informed Dynamics","summary":"  Imitating how humans move their gaze in a visual scene is a vital research\nproblem for both visual understanding and psychology, kindling crucial\napplications such as building alive virtual characters. Previous studies aim to\npredict gaze trajectories when humans are free-viewing an image, searching for\nrequired targets, or looking for clues to answer questions in an image. While\nthese tasks focus on visual-centric scenarios, humans move their gaze also\nalong with audio signal inputs in more common scenarios. To fill this gap, we\nintroduce a new task that predicts human gaze trajectories in a visual scene\nwith synchronized audio inputs and provide a new dataset containing 20k gaze\npoints from 8 subjects. To effectively integrate audio information and simulate\nthe dynamic process of human gaze motion, we propose a novel learning framework\ncalled EyEar (Eye moving while Ear listening) based on physics-informed\ndynamics, which considers three key factors to predict gazes: eye inherent\nmotion tendency, vision salient attraction, and audio semantic attraction. We\nalso propose a probability density score to overcome the high individual\nvariability of gaze trajectories, thereby improving the stabilization of\noptimization and the reliability of the evaluation. Experimental results show\nthat EyEar outperforms all the baselines in the context of all evaluation\nmetrics, thanks to the proposed components in the learning model.\n","authors":["Xiaochuan Liu","Xin Cheng","Yuchong Sun","Xiaoxue Wu","Ruihua Song","Hao Sun","Denghao Zhang"],"pdf_url":"https://arxiv.org/pdf/2502.20858v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20811v1","updated":"2025-02-28T07:53:40Z","published":"2025-02-28T07:53:40Z","title":"HAIC: Improving Human Action Understanding and Generation with Better\n  Captions for Multi-modal Large Language Models","summary":"  Recent Multi-modal Large Language Models (MLLMs) have made great progress in\nvideo understanding. However, their performance on videos involving human\nactions is still limited by the lack of high-quality data. To address this, we\nintroduce a two-stage data annotation pipeline. First, we design strategies to\naccumulate videos featuring clear human actions from the Internet. Second,\nvideos are annotated in a standardized caption format that uses human\nattributes to distinguish individuals and chronologically details their actions\nand interactions. Through this pipeline, we curate two datasets, namely\nHAICTrain and HAICBench. \\textbf{HAICTrain} comprises 126K video-caption pairs\ngenerated by Gemini-Pro and verified for training purposes. Meanwhile,\n\\textbf{HAICBench} includes 500 manually annotated video-caption pairs and\n1,400 QA pairs, for a comprehensive evaluation of human action understanding.\nExperimental results demonstrate that training with HAICTrain not only\nsignificantly enhances human understanding abilities across 4 benchmarks, but\ncan also improve text-to-video generation results. Both the HAICTrain and\nHAICBench are released at https://huggingface.co/datasets/KuaishouHAIC/HAIC.\n","authors":["Xiao Wang","Jingyun Hua","Weihong Lin","Yuanxing Zhang","Fuzheng Zhang","Jianlong Wu","Di Zhang","Liqiang Nie"],"pdf_url":"https://arxiv.org/pdf/2502.20811v1.pdf","comment":null}]},"2025-03-03T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2502.15850v2","updated":"2025-03-03T17:11:16Z","published":"2025-02-21T02:34:17Z","title":"Forecasting Frontier Language Model Agent Capabilities","summary":"  As Language Models (LMs) increasingly operate as autonomous agents,\naccurately forecasting their capabilities becomes crucial for societal\npreparedness. We evaluate six forecasting methods that predict downstream\ncapabilities of LM agents. We use \"one-step\" approaches that predict benchmark\nscores from input metrics like compute or model release date directly or\n\"two-step\" approaches that first predict an intermediate metric like the\nprincipal component of cross-benchmark performance (PC-1) and human-evaluated\ncompetitive Elo ratings. We evaluate our forecasting methods by backtesting\nthem on a dataset of 38 LMs from the OpenLLM 2 leaderboard. We then use the\nvalidated two-step approach (Release Date$\\to$Elo$\\to$Benchmark) to predict LM\nagent performance for frontier models on three benchmarks: SWE-Bench Verified\n(software development), Cybench (cybersecurity assessment), and RE-Bench (ML\nresearch engineering). Our forecast predicts that by the beginning of 2026,\nnon-specialized LM agents with low capability elicitation will reach a success\nrate of 54% on SWE-Bench Verified, while state-of-the-art LM agents will reach\nan 87% success rate. Our approach does not account for recent advances in\ninference-compute scaling and might thus be too conservative.\n","authors":["Govind Pimpale","Axel Højmark","Jérémy Scheurer","Marius Hobbhahn"],"pdf_url":"https://arxiv.org/pdf/2502.15850v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.18600v2","updated":"2025-03-03T17:08:21Z","published":"2025-02-25T19:36:06Z","title":"Chain of Draft: Thinking Faster by Writing Less","summary":"  Large Language Models (LLMs) have demonstrated remarkable performance in\nsolving complex reasoning tasks through mechanisms like Chain-of-Thought (CoT)\nprompting, which emphasizes verbose, step-by-step reasoning. However, humans\ntypically employ a more efficient strategy: drafting concise intermediate\nthoughts that capture only essential information. In this work, we propose\nChain of Draft (CoD), a novel paradigm inspired by human cognitive processes,\nwhere LLMs generate minimalistic yet informative intermediate reasoning outputs\nwhile solving tasks. By reducing verbosity and focusing on critical insights,\nCoD matches or surpasses CoT in accuracy while using as little as only 7.6% of\nthe tokens, significantly reducing cost and latency across various reasoning\ntasks. Our code and data are available at\nhttps://github.com/sileix/chain-of-draft.\n","authors":["Silei Xu","Wenhao Xie","Lingxiao Zhao","Pengcheng He"],"pdf_url":"https://arxiv.org/pdf/2502.18600v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.04974v3","updated":"2025-03-03T17:03:49Z","published":"2025-01-09T05:06:44Z","title":"SensorQA: A Question Answering Benchmark for Daily-Life Monitoring","summary":"  With the rapid growth in sensor data, effectively interpreting and\ninterfacing with these data in a human-understandable way has become crucial.\nWhile existing research primarily focuses on learning classification models,\nfewer studies have explored how end users can actively extract useful insights\nfrom sensor data, often hindered by the lack of a proper dataset. To address\nthis gap, we introduce SensorQA, the first human-created question-answering\n(QA) dataset for long-term time-series sensor data for daily life monitoring.\nSensorQA is created by human workers and includes 5.6K diverse and practical\nqueries that reflect genuine human interests, paired with accurate answers\nderived from sensor data. We further establish benchmarks for state-of-the-art\nAI models on this dataset and evaluate their performance on typical edge\ndevices. Our results reveal a gap between current models and optimal QA\nperformance and efficiency, highlighting the need for new contributions. The\ndataset and code are available at:\nhttps://github.com/benjamin-reichman/SensorQA.\n","authors":["Benjamin Reichman","Xiaofan Yu","Lanxiang Hu","Jack Truxal","Atishay Jain","Rushil Chandrupatla","Tajana Šimunić Rosing","Larry Heck"],"pdf_url":"https://arxiv.org/pdf/2501.04974v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.05589v3","updated":"2025-03-03T16:49:18Z","published":"2025-02-08T14:28:36Z","title":"On Memory Construction and Retrieval for Personalized Conversational\n  Agents","summary":"  To deliver coherent and personalized experiences in long-term conversations,\nexisting approaches typically perform retrieval augmented response generation\nby constructing memory banks from conversation history at either the\nturn-level, session-level, or through summarization techniques.In this paper,\nwe present two key findings: (1) The granularity of memory unit matters:\nturn-level, session-level, and summarization-based methods each exhibit\nlimitations in both memory retrieval accuracy and the semantic quality of the\nretrieved content. (2) Prompt compression methods, such as LLMLingua-2, can\neffectively serve as a denoising mechanism, enhancing memory retrieval accuracy\nacross different granularities. Building on these insights, we propose SeCom, a\nmethod that constructs the memory bank at segment level by introducing a\nconversation segmentation model that partitions long-term conversations into\ntopically coherent segments, while applying compression based denoising on\nmemory units to enhance memory retrieval. Experimental results show that SeCom\nexhibits a significant performance advantage over baselines on long-term\nconversation benchmarks LOCOMO and Long-MT-Bench+. Additionally, the proposed\nconversation segmentation method demonstrates superior performance on dialogue\nsegmentation datasets such as DialSeg711, TIAGE, and SuperDialSeg.\n","authors":["Zhuoshi Pan","Qianhui Wu","Huiqiang Jiang","Xufang Luo","Hao Cheng","Dongsheng Li","Yuqing Yang","Chin-Yew Lin","H. Vicky Zhao","Lili Qiu","Jianfeng Gao"],"pdf_url":"https://arxiv.org/pdf/2502.05589v3.pdf","comment":"10 pages, 5 figures, conference"},{"id":"http://arxiv.org/abs/2502.19735v2","updated":"2025-03-03T16:44:25Z","published":"2025-02-27T03:57:00Z","title":"R1-T1: Fully Incentivizing Translation Capability in LLMs via Reasoning\n  Learning","summary":"  Despite recent breakthroughs in reasoning-enhanced large language models\n(LLMs) like DeepSeek-R1, incorporating inference-time reasoning into machine\ntranslation (MT), where human translators naturally employ structured,\nmulti-layered reasoning chain-of-thoughts (CoTs), is yet underexplored.\nExisting methods either design a fixed CoT tailored for a specific MT sub-task\n(e.g., literature translation), or rely on synthesizing CoTs unaligned with\nhumans, limiting their adaptability to diverse translation scenarios. This\npaper introduces R1-Translator (R1-T1), a novel framework to achieve\ninference-time reasoning for general MT via reinforcement learning (RL) with\nhuman-aligned CoTs comprising six common patterns. Our approach pioneers three\ninnovations: (1) extending reasoning-based translation beyond MT sub-tasks to\nsix languages and diverse tasks (e.g., legal/medical domain adaptation, idiom\nresolution); (2) formalizing six expert-curated CoT templates that mirror\nhybrid human strategies like context-aware paraphrasing and back translation;\nand (3) enabling self-evolving CoT discovery through RL. Experimental results\nindicate a steady translation performance improvement in 11 languages and 40\ntranslation directions on Flores-101 test set, especially on the languages\nunseen from training.\n","authors":["Minggui He","Yilun Liu","Shimin Tao","Yuanchang Luo","Hongyong Zeng","Chang Su","Li Zhang","Hongxia Ma","Daimeng Wei","Weibin Meng","Hao Yang","Boxing Chen","Osamu Yoshie"],"pdf_url":"https://arxiv.org/pdf/2502.19735v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.15823v3","updated":"2025-03-03T16:38:10Z","published":"2025-02-20T03:48:00Z","title":"InductionBench: LLMs Fail in the Simplest Complexity Class","summary":"  Large language models (LLMs) have shown remarkable improvements in reasoning\nand many existing benchmarks have been addressed by models such as o1 and o3\neither fully or partially. However, a majority of these benchmarks emphasize\ndeductive reasoning, including mathematical and coding tasks in which rules\nsuch as mathematical axioms or programming syntax are clearly defined, based on\nwhich LLMs can plan and apply these rules to arrive at a solution. In contrast,\ninductive reasoning, where one infers the underlying rules from observed data,\nremains less explored. Such inductive processes lie at the heart of scientific\ndiscovery, as they enable researchers to extract general principles from\nempirical observations. To assess whether LLMs possess this capacity, we\nintroduce InductionBench, a new benchmark designed to evaluate the inductive\nreasoning ability of LLMs. Our experimental findings reveal that even the most\nadvanced models available struggle to master the simplest complexity classes\nwithin the subregular hierarchy of functions, highlighting a notable deficiency\nin current LLMs' inductive reasoning capabilities. Coda and data are available\nhttps://github.com/Wenyueh/inductive_reasoning_benchmark.\n","authors":["Wenyue Hua","Tyler Wong","Sun Fei","Liangming Pan","Adam Jardine","William Yang Wang"],"pdf_url":"https://arxiv.org/pdf/2502.15823v3.pdf","comment":"24 pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.16251v3","updated":"2025-03-03T15:37:23Z","published":"2024-10-21T17:55:54Z","title":"Can Knowledge Editing Really Correct Hallucinations?","summary":"  Large Language Models (LLMs) suffer from hallucinations, referring to the\nnon-factual information in generated content, despite their superior capacities\nacross tasks. Meanwhile, knowledge editing has been developed as a new popular\nparadigm to correct erroneous factual knowledge encoded in LLMs with the\nadvantage of avoiding retraining from scratch. However, a common issue of\nexisting evaluation datasets for knowledge editing is that they do not ensure\nthat LLMs actually generate hallucinated answers to the evaluation questions\nbefore editing. When LLMs are evaluated on such datasets after being edited by\ndifferent techniques, it is hard to directly adopt the performance to assess\nthe effectiveness of different knowledge editing methods in correcting\nhallucinations. Thus, the fundamental question remains insufficiently\nvalidated: Can knowledge editing really correct hallucinations in LLMs? We\nproposed HalluEditBench to holistically benchmark knowledge editing methods in\ncorrecting real-world hallucinations. First, we rigorously construct a massive\nhallucination dataset with 9 domains, 26 topics and more than 6,000\nhallucinations. Then, we assess the performance of knowledge editing methods in\na holistic way on five dimensions including Efficacy, Generalization,\nPortability, Locality, and Robustness. Through HalluEditBench, we have provided\nnew insights into the potentials and limitations of different knowledge editing\nmethods in correcting hallucinations, which could inspire future improvements\nand facilitate progress in the field of knowledge editing.\n","authors":["Baixiang Huang","Canyu Chen","Xiongxiao Xu","Ali Payani","Kai Shu"],"pdf_url":"https://arxiv.org/pdf/2410.16251v3.pdf","comment":"ICLR 2025. Main paper: 10 pages; total: 34 pages (including\n  appendix). The first two authors contributed equally to this work. Code,\n  data, results, and additional resources are available on the project website:\n  https://llm-editing.github.io"},{"id":"http://arxiv.org/abs/2502.12215v2","updated":"2025-03-03T15:29:43Z","published":"2025-02-17T07:21:11Z","title":"Revisiting the Test-Time Scaling of o1-like Models: Do they Truly\n  Possess Test-Time Scaling Capabilities?","summary":"  The advent of test-time scaling in large language models (LLMs), exemplified\nby OpenAI's o1 series, has advanced reasoning capabilities by scaling\ncomputational resource allocation during inference. While successors like QwQ,\nDeepseek-R1 (R1) and LIMO replicate these advancements, whether these models\ntruly possess test-time scaling capabilities remains underexplored. This study\nfound that longer CoTs of these o1-like models do not consistently enhance\naccuracy; in fact, correct solutions are often shorter than incorrect ones for\nthe same questions. Further investigation shows this phenomenon is closely\nrelated to models' self-revision capabilities - longer CoTs contain more\nself-revisions, which often lead to performance degradation. We then compare\nsequential and parallel scaling strategies on QwQ, R1 and LIMO, finding that\nparallel scaling achieves better coverage and scalability. Based on these\ninsights, we propose Shortest Majority Vote, a method that combines parallel\nscaling strategies with CoT length characteristics, significantly improving\nmodels' test-time scalability compared to conventional majority voting\napproaches.\n","authors":["Zhiyuan Zeng","Qinyuan Cheng","Zhangyue Yin","Yunhua Zhou","Xipeng Qiu"],"pdf_url":"https://arxiv.org/pdf/2502.12215v2.pdf","comment":"Add the github link"},{"id":"http://arxiv.org/abs/2410.19803v2","updated":"2025-03-03T15:13:10Z","published":"2024-10-16T17:59:47Z","title":"First-Person Fairness in Chatbots","summary":"  Evaluating chatbot fairness is crucial given their rapid proliferation, yet\ntypical chatbot tasks (e.g., resume writing, entertainment) diverge from the\ninstitutional decision-making tasks (e.g., resume screening) which have\ntraditionally been central to discussion of algorithmic fairness. The\nopen-ended nature and diverse use-cases of chatbots necessitate novel methods\nfor bias assessment. This paper addresses these challenges by introducing a\nscalable counterfactual approach to evaluate \"first-person fairness,\" meaning\nfairness toward chatbot users based on demographic characteristics. Our method\nemploys a Language Model as a Research Assistant (LMRA) to yield quantitative\nmeasures of harmful stereotypes and qualitative analyses of demographic\ndifferences in chatbot responses. We apply this approach to assess biases in\nsix of our language models across millions of interactions, covering sixty-six\ntasks in nine domains and spanning two genders and four races. Independent\nhuman annotations corroborate the LMRA-generated bias evaluations. This study\nrepresents the first large-scale fairness evaluation based on real-world chat\ndata. We highlight that post-training reinforcement learning techniques\nsignificantly mitigate these biases. This evaluation provides a practical\nmethodology for ongoing bias monitoring and mitigation.\n","authors":["Tyna Eloundou","Alex Beutel","David G. Robinson","Keren Gu-Lemberg","Anna-Luisa Brakman","Pamela Mishkin","Meghan Shah","Johannes Heidecke","Lilian Weng","Adam Tauman Kalai"],"pdf_url":"https://arxiv.org/pdf/2410.19803v2.pdf","comment":"In ICLR 2025, 59 pages, 27 figures"},{"id":"http://arxiv.org/abs/2502.19723v2","updated":"2025-03-03T15:07:28Z","published":"2025-02-27T03:25:34Z","title":"CNsum:Automatic Summarization for Chinese News Text","summary":"  Obtaining valuable information from massive data efficiently has become our\nresearch goal in the era of Big Data. Text summarization technology has been\ncontinuously developed to meet this demand. Recent work has also shown that\ntransformer-based pre-trained language models have achieved great success on\nvarious tasks in Natural Language Processing (NLP). Aiming at the problem of\nChinese news text summary generation and the application of Transformer\nstructure on Chinese, this paper proposes a Chinese news text summarization\nmodel (CNsum) based on Transformer structure, and tests it on Chinese datasets\nsuch as THUCNews. The results of the conducted experiments show that CNsum\nachieves better ROUGE score than the baseline models, which verifies the\noutperformance of the model.\n","authors":["Yu Zhao","Songping Huang","Dongsheng Zhou","Zhaoyun Ding","Fei Wang","Aixin Nian"],"pdf_url":"https://arxiv.org/pdf/2502.19723v2.pdf","comment":"This withdrawal is due to the lack of authorization from all\n  co-authors for the publication of this version"},{"id":"http://arxiv.org/abs/2411.07180v4","updated":"2025-03-03T14:56:17Z","published":"2024-11-11T17:57:30Z","title":"Gumbel Counterfactual Generation From Language Models","summary":"  Understanding and manipulating the causal generation mechanisms in language\nmodels is essential for controlling their behavior. Previous work has primarily\nrelied on techniques such as representation surgery -- e.g., model ablations or\nmanipulation of linear subspaces tied to specific concepts -- to\n\\emph{intervene} on these models. To understand the impact of interventions\nprecisely, it is useful to examine \\emph{counterfactuals} -- e.g., how a given\nsentence would have appeared had it been generated by the model following a\nspecific intervention. We highlight that counterfactual reasoning is\nconceptually distinct from interventions, as articulated in Pearl's causal\nhierarchy. Based on this observation, we propose a framework for generating\ntrue string counterfactuals by reformulating language models as a structural\nequation model using the Gumbel-max trick, which we called Gumbel\ncounterfactual generation. This reformulation allows us to model the joint\ndistribution over original strings and their counterfactuals resulting from the\nsame instantiation of the sampling noise. We develop an algorithm based on\nhindsight Gumbel sampling that allows us to infer the latent noise variables\nand generate counterfactuals of observed strings. Our experiments demonstrate\nthat the approach produces meaningful counterfactuals while at the same time\nshowing that commonly used intervention techniques have considerable undesired\nside effects.\n","authors":["Shauli Ravfogel","Anej Svete","Vésteinn Snæbjarnarson","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2411.07180v4.pdf","comment":"Accepted in ICLR 2025"},{"id":"http://arxiv.org/abs/2410.05864v4","updated":"2025-03-03T14:30:07Z","published":"2024-10-08T09:53:35Z","title":"From Tokens to Words: On the Inner Lexicon of LLMs","summary":"  Natural language is composed of words, but modern large language models\n(LLMs) process sub-words as input. A natural question raised by this\ndiscrepancy is whether LLMs encode words internally, and if so how. We present\nevidence that LLMs engage in an intrinsic detokenization process, where\nsub-word sequences are combined into coherent whole-word representations at\ntheir last token. Our experiments show that this process primarily takes place\nwithin the early and middle layers of the model. We further demonstrate its\nrobustness to arbitrary splits (e.g., \"cats\" to \"ca\" and \"ts\"), typos, and\nimportantly-to out-of-vocabulary words: when feeding the last token internal\nrepresentations of such words to the model as input, it can \"understand\" them\nas the complete word despite never seeing such representations as input during\ntraining. Our findings suggest that LLMs maintain a latent vocabulary beyond\nthe tokenizer's scope. These insights provide a practical, finetuning-free\napplication for expanding the vocabulary of pre-trained models. By enabling the\naddition of new vocabulary words, we reduce input length and inference\niterations, which reduces both space and model latency, with little to no loss\nin model accuracy.\n","authors":["Guy Kaplan","Matanel Oren","Yuval Reif","Roy Schwartz"],"pdf_url":"https://arxiv.org/pdf/2410.05864v4.pdf","comment":"Accepted to the International Conference on Learning Representations\n  (ICLR) 2025"},{"id":"http://arxiv.org/abs/2407.10944v2","updated":"2025-03-03T13:41:46Z","published":"2024-07-15T17:41:34Z","title":"Naturally Occurring Feedback is Common, Extractable and Useful","summary":"  Human feedback data is a critical component in developing language models.\nHowever, collecting this feedback is costly and ultimately not scalable.\nInspired by the way human interlocutors provide spontaneous unsolicited\nfeedback to each other, we propose to extract feedback that users naturally\ninclude when interacting with chat models. We manually annotated conversations\nto confirm the presence of naturally occurring feedback in a standard corpus,\nfinding that as much as 30% of the chats include explicit feedback. Comparing\nto older datasets, we find that naturally occurring feedback is more prevalent\nin recent conversation datasets, suggesting that more than ever, naturally\noccurring feedback can serve as a valuable resource for feedback data. We\npropose a method for automatically extracting this feedback, and apply it to\nover 1M conversations to obtain hundreds of thousands of feedback samples. The\nextracted feedback shows promise: training with it improves over baseline\nmodels and enhances model alignment to human preferences.\n","authors":["Shachar Don-Yehiya","Leshem Choshen","Omri Abend"],"pdf_url":"https://arxiv.org/pdf/2407.10944v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.18858v2","updated":"2025-03-03T13:38:50Z","published":"2025-02-26T05:59:45Z","title":"Evaluating Intelligence via Trial and Error","summary":"  Intelligence is a crucial trait for species to find solutions within a\nlimited number of trial-and-error attempts. Building on this idea, we introduce\nSurvival Game as a framework to evaluate intelligence based on the number of\nfailed attempts in a trial-and-error process. Fewer failures indicate higher\nintelligence. When the expectation and variance of failure counts are both\nfinite, it signals the ability to consistently find solutions to new\nchallenges, which we define as the Autonomous Level of intelligence. Using\nSurvival Game, we comprehensively evaluate existing AI systems. Our results\nshow that while AI systems achieve the Autonomous Level in simple tasks, they\nare still far from it in more complex tasks, such as vision, search,\nrecommendation, and language. While scaling current AI technologies might help,\nthis would come at an astronomical cost. Projections suggest that achieving the\nAutonomous Level for general tasks would require $10^{26}$ parameters. To put\nthis into perspective, loading such a massive model requires so many H100 GPUs\nthat their total value is $10^{7}$ times that of Apple Inc.'s market value.\nEven with Moore's Law, supporting such a parameter scale would take $70$ years.\nThis staggering cost highlights the complexity of human tasks and the\ninadequacies of current AI technologies. To further investigate this\nphenomenon, we conduct a theoretical analysis of Survival Game and its\nexperimental results. Our findings suggest that human tasks possess a\ncriticality property. As a result, Autonomous Level requires a deep\nunderstanding of the task's underlying mechanisms. Current AI systems, however,\ndo not fully grasp these mechanisms and instead rely on superficial mimicry,\nmaking it difficult for them to reach an autonomous level. We believe Survival\nGame can not only guide the future development of AI but also offer profound\ninsights into human intelligence.\n","authors":["Jingtao Zhan","Jiahao Zhao","Jiayu Li","Yiqun Liu","Bo Zhang","Qingyao Ai","Jiaxin Mao","Hongning Wang","Min Zhang","Shaoping Ma"],"pdf_url":"https://arxiv.org/pdf/2502.18858v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.07596v2","updated":"2025-03-03T13:27:01Z","published":"2025-01-10T01:42:43Z","title":"Optimize Incompatible Parameters through Compatibility-aware Knowledge\n  Integration","summary":"  Deep neural networks have become foundational to advancements in multiple\ndomains, including recommendation systems, natural language processing, and so\non. Despite their successes, these models often contain incompatible parameters\nthat can be underutilized or detrimental to model performance, particularly\nwhen faced with specific, varying data distributions. Existing research excels\nin removing such parameters or merging the outputs of multiple different\npretrained models. However, the former focuses on efficiency rather than\nperformance, while the latter requires several times more computing and storage\nresources to support inference. In this paper, we set the goal to explicitly\nimprove these incompatible parameters by leveraging the complementary strengths\nof different models, thereby directly enhancing the models without any\nadditional parameters. Specifically, we propose Compatibility-aware Knowledge\nIntegration (CKI), which consists of Parameter Compatibility Assessment and\nParameter Splicing, which are used to evaluate the knowledge content of\nmultiple models and integrate the knowledge into one model, respectively. The\nintegrated model can be used directly for inference or for further fine-tuning.\nWe conduct extensive experiments on various datasets for recommendation and\nlanguage tasks, and the results show that Compatibility-aware Knowledge\nIntegration can effectively optimize incompatible parameters under multiple\ntasks and settings to break through the training limit of the original model\nwithout increasing the inference cost.\n","authors":["Zheqi Lv","Keming Ye","Zishu Wei","Qi Tian","Shengyu Zhang","Wenqiao Zhang","Wenjie Wang","Kun Kuang","Tat-Seng Chua","Fei Wu"],"pdf_url":"https://arxiv.org/pdf/2501.07596v2.pdf","comment":"Published on AAAI'25(Oral): The Annual AAAI Conference on Artificial\n  Intelligence"},{"id":"http://arxiv.org/abs/2405.18915v2","updated":"2025-03-03T13:25:36Z","published":"2024-05-29T09:17:46Z","title":"Towards Better Chain-of-Thought: A Reflection on Effectiveness and\n  Faithfulness","summary":"  Chain-of-thought (CoT) prompting demonstrates varying performance under\ndifferent reasoning tasks. Previous work attempts to evaluate it but falls\nshort in providing an in-depth analysis of patterns that influence the CoT. In\nthis paper, we study the CoT performance from the perspective of effectiveness\nand faithfulness. For the former, we identify key factors that influence CoT\neffectiveness on performance improvement, including problem difficulty,\ninformation gain, and information flow. For the latter, we interpret the\nunfaithful CoT issue by conducting a joint analysis of the information\ninteraction among the question, CoT, and answer. The result demonstrates that,\nwhen the LLM predicts answers, it can recall correct information missing in the\nCoT from the question, leading to the problem. Finally, we propose a novel\nalgorithm to mitigate this issue, in which we recall extra information from the\nquestion to enhance the CoT generation and evaluate CoTs based on their\ninformation gain. Extensive experiments demonstrate that our approach enhances\nboth the faithfulness and effectiveness of CoT.\n","authors":["Jiachun Li","Pengfei Cao","Yubo Chen","Jiexin Xu","Huaijun Li","Xiaojian Jiang","Kang Liu","Jun Zhao"],"pdf_url":"https://arxiv.org/pdf/2405.18915v2.pdf","comment":"18 pages, under review"},{"id":"http://arxiv.org/abs/2408.08291v2","updated":"2025-03-03T13:18:21Z","published":"2024-08-15T17:46:54Z","title":"The ShareLM Collection and Plugin: Contributing Human-Model Chats for\n  the Benefit of the Community","summary":"  Human-model conversations provide a window into users' real-world scenarios,\nbehavior, and needs, and thus are a valuable resource for model development and\nresearch. While for-profit companies collect user data through the APIs of\ntheir models, using it internally to improve their own models, the open source\nand research community lags behind.\n  We introduce the ShareLM collection, a unified set of human conversations\nwith large language models, and its accompanying plugin, a Web extension for\nvoluntarily contributing user-model conversations. Where few platforms share\ntheir chats, the ShareLM plugin adds this functionality, thus, allowing users\nto share conversations from most platforms. The plugin allows the user to rate\ntheir conversations, both at the conversation and the response levels, and\ndelete conversations they prefer to keep private before they ever leave the\nuser's local storage. We release the plugin conversations as part of the\nShareLM collection, and call for more community effort in the field of open\nhuman-model data.\n  The code, plugin, and data are available.\n","authors":["Shachar Don-Yehiya","Leshem Choshen","Omri Abend"],"pdf_url":"https://arxiv.org/pdf/2408.08291v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.07076v4","updated":"2025-03-03T13:17:24Z","published":"2024-10-09T17:19:58Z","title":"MOOSE-Chem: Large Language Models for Rediscovering Unseen Chemistry\n  Scientific Hypotheses","summary":"  Scientific discovery contributes largely to human society's prosperity, and\nrecent progress shows that LLMs could potentially catalyze this process.\nHowever, it is still unclear whether LLMs can discover novel and valid\nhypotheses in chemistry. In this work, we investigate this central research\nquestion: Can LLMs automatically discover novel and valid chemistry research\nhypotheses given only a chemistry research background (consisting of a research\nquestion and/or a background survey), without limitation on the domain of the\nresearch question? After extensive discussions with chemistry experts, we\npropose an assumption that a majority of chemistry hypotheses can be resulted\nfrom a research background and several inspirations. With this key insight, we\nbreak the central question into three smaller fundamental questions. In brief,\nthey are: (1) given a background question, whether LLMs can retrieve good\ninspirations; (2) with background and inspirations, whether LLMs can lead to\nhypothesis; and (3) whether LLMs can identify good hypotheses to rank them\nhigher. To investigate these questions, we construct a benchmark consisting of\n51 chemistry papers published in Nature, Science, or a similar level in 2024\n(all papers are only available online since 2024). Every paper is divided by\nchemistry PhD students into three components: background, inspirations, and\nhypothesis. The goal is to rediscover the hypothesis, given only the background\nand a large randomly selected chemistry literature corpus consisting the ground\ntruth inspiration papers, with LLMs trained with data up to 2023. We also\ndevelop an LLM-based multi-agent framework that leverages the assumption,\nconsisting of three stages reflecting the three smaller questions. The proposed\nmethod can rediscover many hypotheses with very high similarity with the ground\ntruth ones, covering the main innovations.\n","authors":["Zonglin Yang","Wanhao Liu","Ben Gao","Tong Xie","Yuqiang Li","Wanli Ouyang","Soujanya Poria","Erik Cambria","Dongzhan Zhou"],"pdf_url":"https://arxiv.org/pdf/2410.07076v4.pdf","comment":"Accepted by ICLR 2025"},{"id":"http://arxiv.org/abs/2502.11142v2","updated":"2025-03-03T12:56:35Z","published":"2025-02-16T14:17:36Z","title":"NavRAG: Generating User Demand Instructions for Embodied Navigation\n  through Retrieval-Augmented LLM","summary":"  Vision-and-Language Navigation (VLN) is an essential skill for embodied\nagents, allowing them to navigate in 3D environments following natural language\ninstructions. High-performance navigation models require a large amount of\ntraining data, the high cost of manually annotating data has seriously hindered\nthis field. Therefore, some previous methods translate trajectory videos into\nstep-by-step instructions for expanding data, but such instructions do not\nmatch well with users' communication styles that briefly describe destinations\nor state specific needs. Moreover, local navigation trajectories overlook\nglobal context and high-level task planning. To address these issues, we\npropose NavRAG, a retrieval-augmented generation (RAG) framework that generates\nuser demand instructions for VLN. NavRAG leverages LLM to build a hierarchical\nscene description tree for 3D scene understanding from global layout to local\ndetails, then simulates various user roles with specific demands to retrieve\nfrom the scene tree, generating diverse instructions with LLM. We annotate over\n2 million navigation instructions across 861 scenes and evaluate the data\nquality and navigation performance of trained models.\n","authors":["Zihan Wang","Yaohui Zhu","Gim Hee Lee","Yachun Fan"],"pdf_url":"https://arxiv.org/pdf/2502.11142v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.19732v2","updated":"2025-03-03T12:21:14Z","published":"2025-02-27T03:53:45Z","title":"Speculative Decoding and Beyond: An In-Depth Survey of Techniques","summary":"  Sequential dependencies present a fundamental bottleneck in deploying\nlarge-scale autoregressive models, particularly for real-time applications.\nWhile traditional optimization approaches like pruning and quantization often\ncompromise model quality, recent advances in generation-refinement frameworks\ndemonstrate that this trade-off can be significantly mitigated.\n  This survey presents a comprehensive taxonomy of generation-refinement\nframeworks, analyzing methods across autoregressive sequence tasks. We\ncategorize methods based on their generation strategies (from simple n-gram\nprediction to sophisticated draft models) and refinement mechanisms (including\nsingle-pass verification and iterative approaches). Through systematic analysis\nof both algorithmic innovations and system-level implementations, we examine\ndeployment strategies across computing environments and explore applications\nspanning text, images, and speech generation. This systematic examination of\nboth theoretical frameworks and practical implementations provides a foundation\nfor future research in efficient autoregressive decoding.\n","authors":["Yunhai Hu","Zining Liu","Zhenyuan Dong","Tianfan Peng","Bradley McDanel","Sai Qian Zhang"],"pdf_url":"https://arxiv.org/pdf/2502.19732v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.06057v2","updated":"2025-03-03T11:08:15Z","published":"2024-07-08T15:59:44Z","title":"Variational Best-of-N Alignment","summary":"  Best-of-N (BoN) is a popular and effective algorithm for aligning language\nmodels to human preferences. The algorithm works as follows: at inference time,\nN samples are drawn from the language model, and the sample with the highest\nreward, as judged by a reward model, is returned as the output. Despite its\neffectiveness, BoN is computationally expensive; it reduces sampling throughput\nby a factor of N. To make BoN more efficient at inference time, one strategy is\nto fine-tune the language model to mimic what BoN does during inference. To\nachieve this, we derive the distribution induced by the BoN algorithm. We then\npropose to fine-tune the language model to minimize backward KL divergence to\nthe BoN distribution. Our approach is analogous to mean-field variational\ninference and, thus, we term it variational BoN (vBoN). To the extent this\nfine-tuning is successful and we end up with a good approximation, we have\nreduced the inference cost by a factor of N. Our experiments on controlled\ngeneration and summarization tasks show that BoN is the most effective\nalignment method, and our variational approximation to BoN achieves the closest\nperformance to BoN and surpasses models fine-tuned using the standard\nKL-constrained RL objective. In the controlled generation task, vBoN appears\nmore frequently on the Pareto frontier of reward and KL divergence compared to\nother alignment methods. In the summarization task, vBoN achieves high reward\nvalues across various sampling temperatures.\n","authors":["Afra Amini","Tim Vieira","Elliott Ash","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2407.06057v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.12460v2","updated":"2025-03-03T10:35:27Z","published":"2024-11-19T12:36:02Z","title":"Exploring Iterative Controllable Summarization with Large Language\n  Models","summary":"  Large language models (LLMs) have demonstrated remarkable performance in\nabstractive summarization tasks. However, their ability to precisely control\nsummary attributes (e.g., length or topic) remains underexplored, limiting\ntheir adaptability to specific user preferences. In this paper, we\nsystematically explore the controllability of LLMs. To this end, we revisit\nsummary attribute measurements and introduce iterative evaluation metrics,\nfailure rate and average iteration count to precisely evaluate controllability\nof LLMs, rather than merely assessing errors. Our findings show that LLMs\nstruggle more with numerical attributes than with linguistic attributes. To\naddress this challenge, we propose a guide-to-explain framework (GTE) for\ncontrollable summarization. Our GTE framework enables the model to identify\nmisaligned attributes in the initial draft and guides it in self-explaining\nerrors in the previous output. By allowing the model to reflect on its\nmisalignment, GTE generates well-adjusted summaries that satisfy the desired\nattributes with robust effectiveness, requiring surprisingly fewer iterations\nthan other iterative approaches.\n","authors":["Sangwon Ryu","Heejin Do","Daehee Kim","Hwanjo Yu","Dongwoo Kim","Yunsu Kim","Gary Geunbae Lee","Jungseul Ok"],"pdf_url":"https://arxiv.org/pdf/2411.12460v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.11355v2","updated":"2025-03-03T09:45:24Z","published":"2025-02-17T02:11:17Z","title":"\"Nuclear Deployed!\": Analyzing Catastrophic Risks in Decision-making of\n  Autonomous LLM Agents","summary":"  Large language models (LLMs) are evolving into autonomous decision-makers,\nraising concerns about catastrophic risks in high-stakes scenarios,\nparticularly in Chemical, Biological, Radiological and Nuclear (CBRN) domains.\nBased on the insight that such risks can originate from trade-offs between the\nagent's Helpful, Harmlessness and Honest (HHH) goals, we build a novel\nthree-stage evaluation framework, which is carefully constructed to effectively\nand naturally expose such risks. We conduct 14,400 agentic simulations across\n12 advanced LLMs, with extensive experiments and analysis. Results reveal that\nLLM agents can autonomously engage in catastrophic behaviors and deception,\nwithout being deliberately induced. Furthermore, stronger reasoning abilities\noften increase, rather than mitigate, these risks. We also show that these\nagents can violate instructions and superior commands. On the whole, we\nempirically prove the existence of catastrophic risks in autonomous LLM agents.\nWe will release our code upon request.\n","authors":["Rongwu Xu","Xiaojian Li","Shuo Chen","Wei Xu"],"pdf_url":"https://arxiv.org/pdf/2502.11355v2.pdf","comment":"Please visit https://llm-catastrophic-risks.github.io for a quick\n  tour of our project"},{"id":"http://arxiv.org/abs/2403.07260v2","updated":"2025-03-03T09:36:14Z","published":"2024-03-12T02:37:11Z","title":"LaERC-S: Improving LLM-based Emotion Recognition in Conversation with\n  Speaker Characteristics","summary":"  Emotion recognition in conversation (ERC), the task of discerning human\nemotions for each utterance within a conversation, has garnered significant\nattention in human-computer interaction systems. Previous ERC studies focus on\nspeaker-specific information that predominantly stems from relationships among\nutterances, which lacks sufficient information around conversations. Recent\nresearch in ERC has sought to exploit pre-trained large language models (LLMs)\nwith speaker modelling to comprehend emotional states. Although these methods\nhave achieved encouraging results, the extracted speaker-specific information\nstruggles to indicate emotional dynamics. In this paper, motivated by the fact\nthat speaker characteristics play a crucial role and LLMs have rich world\nknowledge, we present LaERC-S, a novel framework that stimulates LLMs to\nexplore speaker characteristics involving the mental state and behavior of\ninterlocutors, for accurate emotion predictions. To endow LLMs with this\nknowledge information, we adopt the two-stage learning to make the models\nreason speaker characteristics and track the emotion of the speaker in complex\nconversation scenarios. Extensive experiments on three benchmark datasets\ndemonstrate the superiority of LaERC-S, reaching the new state-of-the-art.\n","authors":["Yumeng Fu","Junjie Wu","Zhongjie Wang","Meishan Zhang","Lili Shan","Yulin Wu","Bingquan Li"],"pdf_url":"https://arxiv.org/pdf/2403.07260v2.pdf","comment":"COLING 2025"},{"id":"http://arxiv.org/abs/2402.09911v2","updated":"2025-03-03T09:21:11Z","published":"2024-02-15T12:20:02Z","title":"Enhancing Large Language Models with Pseudo- and Multisource- Knowledge\n  Graphs for Open-ended Question Answering","summary":"  Mitigating the hallucinations of Large Language Models is a crucial task.\nAlthough some existing methods employ self-enhancement techniques, they fall\nshort of effectively addressing unknown factual hallucinations. Meanwhile,\nKnowledge Graph (KG) enhancement approaches fail to address the generalization\nacross different KG sources and the enhancement of open-ended answer questions\nsimultaneously. To tackle these limitations, we propose a framework that\ncombines Pseudo-Graph Generation and Atomic Knowledge Verification (PG\\&AKV).\nEnhancement of open-ended question-answering begins with leveraging the\nPseudo-Graph Generation to provide the related knowledge framework.\nSubsequently, Atomic Knowledge Verification utilizes atomic-level knowledge\nquerying and verification to achieve generalizability under different KG\nsources. Compared to the baseline, this approach yields a minimum improvement\nof 11.5 in the ROUGE-L score for open-ended questions. For precise-answered\nquestions, we observe a minimum accuracy improvement of 7.5%. Moreover, PG\\&AKV\nalso exhibits generalizability across different KG sources. Utilizing KG\ndifferent from the question sources, PG\\&AKV can even achieve at least a 3.5 %\nperformance improvement. In summary, our results pave the way for enhancing\nLLMs by incorporating Pseudo- and Multisource-KGs, particularly in the filed of\nopen-ended questions.\n","authors":["Jiaxiang Liu","Tong Zhou","Yubo Chen","Kang Liu","Jun Zhao"],"pdf_url":"https://arxiv.org/pdf/2402.09911v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21228v2","updated":"2025-03-03T09:11:46Z","published":"2025-02-28T16:59:30Z","title":"ECLeKTic: a Novel Challenge Set for Evaluation of Cross-Lingual\n  Knowledge Transfer","summary":"  To achieve equitable performance across languages, multilingual large\nlanguage models (LLMs) must be able to abstract knowledge beyond the language\nin which it was acquired. However, the current literature lacks reliable ways\nto measure LLMs' capability of cross-lingual knowledge transfer. To that end,\nwe present ECLeKTic, a multilingual closed-book QA (CBQA) dataset that\nEvaluates Cross-Lingual Knowledge Transfer in a simple, black-box manner. We\ndetected information with uneven coverage across languages by controlling for\npresence and absence of Wikipedia articles in 12 languages. We generated\nknowledge-seeking questions in a source language, for which the answer appears\nin a relevant Wikipedia article and translated them to all other 11 languages,\nfor which the respective Wikipedias lack equivalent articles. Assuming that\nWikipedia reflects the prominent knowledge in the LLM's training data, to solve\nECLeKTic's CBQA task the model is required to transfer knowledge between\nlanguages. Experimenting with 8 LLMs, we show that SOTA models struggle to\neffectively share knowledge across, languages even if they can predict the\nanswer well for queries in the same language the knowledge was acquired in.\n","authors":["Omer Goldman","Uri Shaham","Dan Malkin","Sivan Eiger","Avinatan Hassidim","Yossi Matias","Joshua Maynez","Adi Mayrav Gilady","Jason Riesa","Shruti Rijhwani","Laura Rimell","Idan Szpektor","Reut Tsarfaty","Matan Eyal"],"pdf_url":"https://arxiv.org/pdf/2502.21228v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.11167v2","updated":"2025-03-03T08:26:12Z","published":"2025-02-16T15:38:19Z","title":"SURGE: On the Potential of Large Language Models as General-Purpose\n  Surrogate Code Executors","summary":"  Neural surrogate models have emerged as powerful and efficient tools in data\nmining. Meanwhile, large language models (LLMs) have demonstrated remarkable\ncapabilities in code-related tasks. We investigate a novel application: using\nLLMs as surrogate models for code execution prediction. Given LLMs' unique\nability to understand and process diverse programs, they present a promising\ndirection for building general-purpose surrogate models. To systematically\ninvestigate this capability, we introduce SURGE, a comprehensive benchmark with\n$1160$ problems covering $8$ key aspects: multi-language programming tasks,\ncompetition-level programming problems, repository-level code analysis,\nhigh-cost scientific computing, time-complexity-intensive algorithms, buggy\ncode analysis, programs dependent on specific compilers or execution\nenvironments, and formal mathematical proof verification. Through extensive\nempirical analysis of $21$ open-source and proprietary LLMs, we examine scaling\nlaws, data efficiency, and predictive accuracy. Our findings reveal important\ninsights about the feasibility of LLMs as efficient surrogates for\ncomputational processes, with implications for automated software testing,\nprogram analysis, and computational resource optimization in data mining\napplications. Code and dataset are released at\nhttps://github.com/Imbernoulli/SURGE.\n","authors":["Bohan Lyu","Siqiao Huang","Zichen Liang"],"pdf_url":"https://arxiv.org/pdf/2502.11167v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.19316v2","updated":"2025-03-03T08:22:25Z","published":"2024-05-29T17:39:48Z","title":"Robust Preference Optimization through Reward Model Distillation","summary":"  Language model (LM) post-training (or alignment) involves maximizing a reward\nfunction that is derived from preference annotations. Direct Preference\nOptimization (DPO) is a popular offline alignment method that trains a policy\ndirectly on preference data without the need to train a reward model or apply\nreinforcement learning. However, the empirical evidence suggests that DPO\ntypically assigns implicit rewards that overfit, and trend towards infinite\nmagnitude. This frequently leads to degenerate policies, sometimes causing even\nthe probabilities of the preferred generations to go to zero. In this work, we\nanalyze this phenomenon and use distillation to get a better proxy for the true\npreference distribution over generation pairs: we train the LM such that its\ninduced implicit reward, i.e., the scaled log-likelihood ratio of the model to\nthe reference model, matches an explicit reward model trained on the preference\ndata. Moreover, to account for uncertainty in the reward model we are\ndistilling from, we optimize against a family of reward models that, as a\nwhole, is likely to include at least one reasonable proxy for the preference\ndistribution. Our results show that distilling from such a family of reward\nmodels leads to improved robustness to distribution shift in preference\nannotations, while preserving the simple supervised nature of DPO.\n","authors":["Adam Fisch","Jacob Eisenstein","Vicky Zayats","Alekh Agarwal","Ahmad Beirami","Chirag Nagpal","Pete Shaw","Jonathan Berant"],"pdf_url":"https://arxiv.org/pdf/2405.19316v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.19651v3","updated":"2025-03-03T07:49:17Z","published":"2023-10-30T15:37:10Z","title":"Dynamics of Instruction Fine-Tuning for Chinese Large Language Models","summary":"  Instruction tuning is a burgeoning method to elicit the general intelligence\nof Large Language Models (LLMs). While numerous studies have examined the\nimpact of factors such as data volume and model size on English models, the\nscaling properties of instruction tuning in other languages remain largely\nunexplored. In this work, we systematically investigate the effects of data\nquantity, model size, and data construction methods on instruction tuning for\nChinese LLMs. We utilize a newly curated dataset, DoIT, which includes over\n40,000 high-quality instruction instances covering ten underlying abilities,\nsuch as creative writing, code generation, and logical reasoning. Our\nexperiments, conducted on models ranging from 7b to 33b parameters, yield three\nkey findings: (i) While these factors directly affect overall model\nperformance, some abilities are more responsive to scaling, whereas others\ndemonstrate significant resistance. (ii) The scaling sensitivity of different\nabilities to these factors can be explained by two features: Complexity and\nTransference. (iii) By tailoring training strategies to their varying\nsensitivities, specific abilities can be efficiently learned, enhancing\nperformance on two public benchmarks.\n","authors":["Chiyu Song","Zhanchao Zhou","Jianhao Yan","Yuejiao Fei","Zhenzhong Lan","Yue Zhang"],"pdf_url":"https://arxiv.org/pdf/2310.19651v3.pdf","comment":"Accepted to COLING 2025"},{"id":"http://arxiv.org/abs/2406.14434v3","updated":"2025-03-03T07:36:49Z","published":"2024-06-20T15:59:07Z","title":"Selected Languages are All You Need for Cross-lingual Truthfulness\n  Transfer","summary":"  Truthfulness stands out as an essential challenge for Large Language Models\n(LLMs). Although many works have developed various ways for truthfulness\nenhancement, they seldom focus on truthfulness in multilingual scenarios.\nMeanwhile, contemporary multilingual aligning technologies struggle to balance\nnumerous languages and often exhibit serious truthfulness gaps across different\nlanguages, especially those that differ greatly from English. In our work, we\nextend truthfulness evaluation to multilingual contexts and propose a practical\nmethod for cross-lingual truthfulness transfer called Fact-aware Multilingual\nSelective Synergy (FaMSS). FaMSS is able to select an optimal subset of all\ntested languages by language bias and transfer contributions, and then employ\ntranslation instruction tuning for cross-lingual truthfulness transfer.\nExperimental results demonstrate that our approach can effectively reduce the\nmultilingual representation disparity and boost cross-lingual truthfulness\ntransfer of LLMs.\n","authors":["Weihao Liu","Ning Wu","Wenbiao Ding","Shining Liang","Ming Gong","Dongmei Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.14434v3.pdf","comment":"16 pages, COLING2025"},{"id":"http://arxiv.org/abs/2409.16644v2","updated":"2025-03-03T07:22:54Z","published":"2024-09-25T05:44:44Z","title":"Enabling Auditory Large Language Models for Automatic Speech Quality\n  Evaluation","summary":"  Speech quality assessment typically requires evaluating audio from multiple\naspects, such as mean opinion score (MOS) and speaker similarity (SIM) \\etc.,\nwhich can be challenging to cover using one small model designed for a single\ntask. In this paper, we propose leveraging recently introduced auditory large\nlanguage models (LLMs) for automatic speech quality assessment. By employing\ntask-specific prompts, auditory LLMs are finetuned to predict MOS, SIM and A/B\ntesting results, which are commonly used for evaluating text-to-speech systems.\nAdditionally, the finetuned auditory LLM is able to generate natural language\ndescriptions assessing aspects like noisiness, distortion, discontinuity, and\noverall quality, providing more interpretable outputs. Extensive experiments\nhave been performed on the NISQA, BVCC, SOMOS and VoxSim speech quality\ndatasets, using open-source auditory LLMs such as SALMONN, Qwen-Audio, and\nQwen2-Audio. For the natural language descriptions task, a commercial model\nGoogle Gemini 1.5 Pro is also evaluated. The results demonstrate that auditory\nLLMs achieve competitive performance compared to state-of-the-art task-specific\nsmall models in predicting MOS and SIM, while also delivering promising results\nin A/B testing and natural language descriptions. Our data processing scripts\nand finetuned model checkpoints can be found at\nhttps://github.com/bytedance/SALMONN.\n","authors":["Siyin Wang","Wenyi Yu","Yudong Yang","Changli Tang","Yixuan Li","Jimin Zhuang","Xianzhao Chen","Xiaohai Tian","Jun Zhang","Guangzhi Sun","Lu Lu","Chao Zhang"],"pdf_url":"https://arxiv.org/pdf/2409.16644v2.pdf","comment":"Accepted by ICASSP 2025"},{"id":"http://arxiv.org/abs/2410.02683v2","updated":"2025-03-03T07:20:54Z","published":"2024-10-03T17:08:52Z","title":"DailyDilemmas: Revealing Value Preferences of LLMs with Quandaries of\n  Daily Life","summary":"  As users increasingly seek guidance from LLMs for decision-making in daily\nlife, many of these decisions are not clear-cut and depend significantly on the\npersonal values and ethical standards of people. We present DailyDilemmas, a\ndataset of 1,360 moral dilemmas encountered in everyday life. Each dilemma\npresents two possible actions, along with affected parties and relevant human\nvalues for each action. Based on these dilemmas, we gather a repository of\nhuman values covering diverse everyday topics, such as interpersonal\nrelationships, workplace, and environmental issues. With DailyDilemmas, we\nevaluate LLMs on these dilemmas to determine what action they will choose and\nthe values represented by these action choices. Then, we analyze values through\nthe lens of five theoretical frameworks inspired by sociology, psychology, and\nphilosophy, including the World Values Survey, Moral Foundations Theory,\nMaslow's Hierarchy of Needs, Aristotle's Virtues, and Plutchik's Wheel of\nEmotions. For instance, we find LLMs are most aligned with self-expression over\nsurvival in World Values Survey and care over loyalty in Moral Foundations\nTheory. Interestingly, we find substantial preference differences in models for\nsome core values. For example, for truthfulness, Mixtral-8x7B neglects it by\n9.7% while GPT-4-turbo selects it by 9.4%. We also study the recent guidance\nreleased by OpenAI (ModelSpec), and Anthropic (Constitutional AI) to understand\nhow their designated principles reflect their models' actual value\nprioritization when facing nuanced moral reasoning in daily-life settings.\nFinally, we find that end users cannot effectively steer such prioritization\nusing system prompts.\n","authors":["Yu Ying Chiu","Liwei Jiang","Yejin Choi"],"pdf_url":"https://arxiv.org/pdf/2410.02683v2.pdf","comment":"Accepted into ICLR 2025 (spotlight)"},{"id":"http://arxiv.org/abs/2501.02497v2","updated":"2025-03-03T07:16:16Z","published":"2025-01-05T10:24:20Z","title":"Test-Time Compute: from System-1 Thinking to System-2 Thinking","summary":"  The remarkable performance of the o1 model in complex reasoning demonstrates\nthat test-time compute scaling can further unlock the model's potential,\nenabling powerful System-2 thinking. However, there is still a lack of\ncomprehensive surveys for test-time compute scaling. We trace the concept of\ntest-time compute back to System-1 models. In System-1 models, test-time\ncompute addresses distribution shifts and improves robustness and\ngeneralization through parameter updating, input modification, representation\nediting, and output calibration. In System-2 models, it enhances the model's\nreasoning ability to solve complex problems through repeated sampling,\nself-correction, and tree search. We organize this survey according to the\ntrend of System-1 to System-2 thinking, highlighting the key role of test-time\ncompute in the transition from System-1 models to weak System-2 models, and\nthen to strong System-2 models. We also point out a few possible future\ndirections.\n","authors":["Yixin Ji","Juntao Li","Hai Ye","Kaixin Wu","Kai Yao","Jia Xu","Linjian Mo","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2501.02497v2.pdf","comment":"work in progress"},{"id":"http://arxiv.org/abs/2502.18874v2","updated":"2025-03-03T07:13:12Z","published":"2025-02-26T06:31:45Z","title":"Learning to Align Multi-Faceted Evaluation: A Unified and Robust\n  Framework","summary":"  Large Language Models (LLMs) are being used more and more extensively for\nautomated evaluation in various scenarios. Previous studies have attempted to\nfine-tune open-source LLMs to replicate the evaluation explanations and\njudgments of powerful proprietary models, such as GPT-4. However, these methods\nare largely limited to text-based analyses under predefined general criteria,\nresulting in reduced adaptability for unseen instructions and demonstrating\ninstability in evaluating adherence to quantitative and structural constraints.\nTo address these limitations, we propose a novel evaluation framework, ARJudge,\nthat adaptively formulates evaluation criteria and synthesizes both text-based\nand code-driven analyses to evaluate LLM responses. ARJudge consists of two\ncomponents: a fine-tuned Analyzer that generates multi-faceted evaluation\nanalyses and a tuning-free Refiner that combines and refines all analyses to\nmake the final judgment. We construct a Composite Analysis Corpus that\nintegrates tasks for evaluation criteria generation alongside text-based and\ncode-driven analysis generation to train the Analyzer. Our results demonstrate\nthat ARJudge outperforms existing fine-tuned evaluators in effectiveness and\nrobustness. Furthermore, it demonstrates the importance of multi-faceted\nevaluation and code-driven analyses in enhancing evaluation capabilities.\n","authors":["Kaishuai Xu","Tiezheng Yu","Wenjun Hou","Yi Cheng","Liangyou Li","Xin Jiang","Lifeng Shang","Qun Liu","Wenjie Li"],"pdf_url":"https://arxiv.org/pdf/2502.18874v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.06638v3","updated":"2025-03-03T07:09:42Z","published":"2024-10-09T07:43:38Z","title":"Subtle Errors Matter: Preference Learning via Error-injected\n  Self-editing","summary":"  Large Language Models (LLMs) have exhibited strong mathematical reasoning\nprowess, tackling tasks ranging from basic arithmetic to advanced\ncompetition-level problems. However, frequently occurring subtle yet critical\nerrors, such as miscalculations or incorrect substitutions, limit the LLMs'\nfull potential. Existing studies to improve mathematical ability typically\ninvolve applying preference learning to step-wise solution pairs. Although\nthese methods leverage samples of varying granularity to mitigate reasoning\nerrors, they overlook critical subtle errors. In this work, we propose a novel\npreference learning framework called eRror-Injected Self-Editing (RISE), which\ninjects predefined subtle errors into pivotal tokens in reasoning or\ncomputation steps to construct hard pairs for error mitigation. In detail, RISE\nuses the LLM itself to edit a small number of tokens in the solution, injecting\ndesigned subtle errors. Then, pairs composed of self-edited solutions and their\ncorresponding correct ones, along with pairs of correct and incorrect solutions\nobtained through sampling, are used together for subtle error-aware DPO\ntraining. Compared with other preference learning methods, RISE further refines\nthe training objective without requiring fine-grained sampling or preference\nannotation. Extensive experiments validate the effectiveness of RISE, with\npreference learning on Qwen2-7B-Instruct yielding notable improvements of 3.0%\non GSM8K and 7.9% on MATH with only 4.5K training samples. Moreover, the effect\nof error mitigation extends from mathematical reasoning to logical reasoning\nand code generation.\n","authors":["Kaishuai Xu","Tiezheng Yu","Wenjun Hou","Yi Cheng","Chak Tou Leong","Liangyou Li","Xin Jiang","Lifeng Shang","Qun Liu","Wenjie Li"],"pdf_url":"https://arxiv.org/pdf/2410.06638v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.07170v3","updated":"2025-03-03T07:02:20Z","published":"2024-09-11T10:33:30Z","title":"Learning Efficient Recursive Numeral Systems via Reinforcement Learning","summary":"  It has previously been shown that by using reinforcement learning (RL),\nagents can derive simple approximate and exact-restricted numeral systems that\nare similar to human ones (Carlsson, 2021). However, it is a major challenge to\nshow how more complex recursive numeral systems, similar to for example\nEnglish, could arise via a simple learning mechanism such as RL. Here, we\nintroduce an approach towards deriving a mechanistic explanation of the\nemergence of efficient recursive number systems. We consider pairs of agents\nlearning how to communicate about numerical quantities through a meta-grammar\nthat can be gradually modified throughout the interactions. %We find that the\nseminal meta-grammar of Hurford (Hurford, 1975) is not suitable for this\napplication as its optimization results in systems that deviate from standard\nconventions observed within human numeral systems. We propose a simple\nmodification which addresses this issue. Utilising a slightly modified version\nof the meta-grammar of Hurford, we demonstrate that our RL agents, shaped by\nthe pressures for efficient communication, can effectively modify their lexicon\ntowards Pareto-optimal configurations which are comparable to those observed\nwithin human numeral systems in terms of their efficiency.\n","authors":["Andrea Silvi","Jonathan Thomas","Emil Carlsson","Devdatt Dubhashi","Moa Johansson"],"pdf_url":"https://arxiv.org/pdf/2409.07170v3.pdf","comment":"8 pages, 5 figures"},{"id":"http://arxiv.org/abs/2407.04752v2","updated":"2025-03-03T06:46:33Z","published":"2024-07-05T08:37:17Z","title":"SpikeLLM: Scaling up Spiking Neural Network to Large Language Models via\n  Saliency-based Spiking","summary":"  Recent advancements in large language models (LLMs) with billions of\nparameters have improved performance in various applications, but their\ninference processes demand significant energy and computational resources. In\ncontrast, the human brain, with approximately 86 billion neurons, is much more\nenergy-efficient than LLMs with similar parameters. Inspired by this, we\nredesign 7$\\sim$70 billion parameter LLMs using bio-plausible spiking\nmechanisms, emulating the efficient behavior of the human brain. We propose the\nfirst spiking large language model, SpikeLLM. Coupled with the proposed model,\ntwo essential approaches are proposed to improve spike training efficiency:\nGeneralized Integrate-and-Fire (GIF) neurons to compress spike length from $T$\nto $\\frac{T}{L} \\log_2 L$ bits, and an Optimal Brain Spiking framework to\ndivide outlier channels and allocate different $T$ for GIF neurons, which\nfurther compresses spike length to approximate $log_2T$ bits. The necessity of\nspike-driven LLM is proved by comparison with quantized LLMs with similar\noperations. In the OmniQuant pipeline, SpikeLLM reduces 11.01% WikiText2\nperplexity and improves 2.55% accuracy of common scene reasoning on a LLAMA-7B\nW4A4 model. In the GPTQ pipeline, SpikeLLM achieves direct additive in linear\nlayers, significantly exceeding PB-LLMs.\n","authors":["Xingrun Xing","Boyan Gao","Zheng Zhang","David A. Clifton","Shitao Xiao","Li Du","Guoqi Li","Jiajun Zhang"],"pdf_url":"https://arxiv.org/pdf/2407.04752v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.18945v4","updated":"2025-03-03T06:34:48Z","published":"2024-02-29T08:20:49Z","title":"SynGhost: Invisible and Universal Task-agnostic Backdoor Attack via\n  Syntactic Transfer","summary":"  Although pre-training achieves remarkable performance, it suffers from\ntask-agnostic backdoor attacks due to vulnerabilities in data and training\nmechanisms. These attacks can transfer backdoors to various downstream tasks.\nIn this paper, we introduce $\\mathtt{maxEntropy}$, an entropy-based poisoning\nfilter that mitigates such risks. To overcome the limitations of manual target\nsetting and explicit triggers, we propose $\\mathtt{SynGhost}$, an invisible and\nuniversal task-agnostic backdoor attack via syntactic transfer, further\nexposing vulnerabilities in pre-trained language models (PLMs). Specifically,\n$\\mathtt{SynGhost}$ injects multiple syntactic backdoors into the pre-training\nspace through corpus poisoning, while preserving the PLM's pre-training\ncapabilities. Second, $\\mathtt{SynGhost}$ adaptively selects optimal targets\nbased on contrastive learning, creating a uniform distribution in the\npre-training space. To identify syntactic differences, we also introduce an\nawareness module to minimize interference between backdoors. Experiments show\nthat $\\mathtt{SynGhost}$ poses significant threats and can transfer to various\ndownstream tasks. Furthermore, $\\mathtt{SynGhost}$ resists defenses based on\nperplexity, fine-pruning, and $\\mathtt{maxEntropy}$. The code is available at\nhttps://github.com/Zhou-CyberSecurity-AI/SynGhost.\n","authors":["Pengzhou Cheng","Wei Du","Zongru Wu","Fengwei Zhang","Libo Chen","Zhuosheng Zhang","Gongshen Liu"],"pdf_url":"https://arxiv.org/pdf/2402.18945v4.pdf","comment":"17 pages, 16 figures, 12 tables, accepted at NAACL 2025 Findings"},{"id":"http://arxiv.org/abs/2412.07298v2","updated":"2025-03-03T06:33:49Z","published":"2024-12-10T08:28:57Z","title":"The Rise and Down of Babel Tower: Investigating the Evolution Process of\n  Multilingual Code Large Language Model","summary":"  Large language models (LLMs) have shown significant multilingual\ncapabilities. However, the mechanisms underlying the development of these\ncapabilities during pre-training are not well understood. In this paper, we use\ncode LLMs as an experimental platform to explore the evolution of multilingual\ncapabilities in LLMs during the pre-training process. Based on our\nobservations, we propose the Babel Tower Hypothesis, which describes the entire\nprocess of LLMs acquiring new language capabilities. During the learning\nprocess, multiple languages initially share a single knowledge system dominated\nby the primary language and gradually develop language-specific knowledge\nsystems. We then validate the above hypothesis by tracking the internal states\nof the LLMs through identifying working languages and language transferring\nneurons. Experimental results show that the internal state changes of the LLM\nare consistent with our Babel Tower Hypothesis. Building on these insights, we\npropose a novel method to construct an optimized pre-training corpus for\nmultilingual code LLMs, which significantly outperforms LLMs trained on the\noriginal corpus. The proposed Babel Tower Hypothesis provides new insights into\ndesigning pre-training data distributions to achieve optimal multilingual\ncapabilities in LLMs.\n","authors":["Jiawei Chen","Wentao Chen","Jing Su","Jingjing Xu","Hongyu Lin","Mengjie Ren","Yaojie Lu","Xianpei Han","Le Sun"],"pdf_url":"https://arxiv.org/pdf/2412.07298v2.pdf","comment":"Accepted to ICLR 2025"},{"id":"http://arxiv.org/abs/2502.17204v2","updated":"2025-03-03T06:29:31Z","published":"2025-02-24T14:39:28Z","title":"Order Matters: Investigate the Position Bias in Multi-constraint\n  Instruction Following","summary":"  Real-world instructions with multiple constraints pose a significant\nchallenge to existing large language models (LLMs). An observation is that the\nLLMs exhibit dramatic performance fluctuation when disturbing the order of the\nincorporated constraints. Yet, none of the existing works has systematically\ninvestigated this position bias problem in the field of multi-constraint\ninstruction following. To bridge this gap, we design a probing task where we\nquantitatively measure the difficulty distribution of the constraints by a\nnovel Difficulty Distribution Index (CDDI). Through the experimental results,\nwe find that LLMs are more performant when presented with the constraints in a\n``hard-to-easy'' order. This preference can be generalized to LLMs with\ndifferent architecture or different sizes of parameters. Additionally, we\nconduct an explanation study, providing an intuitive insight into the\ncorrelation between the LLM's attention and constraint orders. Our code and\ndataset are publicly available at https://github.com/meowpass/PBIF.\n","authors":["Jie Zeng","Qianyu He","Qingyu Ren","Jiaqing Liang","Yanghua Xiao","Weikang Zhou","Zeye Sun","Fei Yu"],"pdf_url":"https://arxiv.org/pdf/2502.17204v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.01405v4","updated":"2025-03-03T06:14:14Z","published":"2023-10-02T17:59:07Z","title":"Representation Engineering: A Top-Down Approach to AI Transparency","summary":"  In this paper, we identify and characterize the emerging area of\nrepresentation engineering (RepE), an approach to enhancing the transparency of\nAI systems that draws on insights from cognitive neuroscience. RepE places\npopulation-level representations, rather than neurons or circuits, at the\ncenter of analysis, equipping us with novel methods for monitoring and\nmanipulating high-level cognitive phenomena in deep neural networks (DNNs). We\nprovide baselines and an initial analysis of RepE techniques, showing that they\noffer simple yet effective solutions for improving our understanding and\ncontrol of large language models. We showcase how these methods can provide\ntraction on a wide range of safety-relevant problems, including honesty,\nharmlessness, power-seeking, and more, demonstrating the promise of top-down\ntransparency research. We hope that this work catalyzes further exploration of\nRepE and fosters advancements in the transparency and safety of AI systems.\n","authors":["Andy Zou","Long Phan","Sarah Chen","James Campbell","Phillip Guo","Richard Ren","Alexander Pan","Xuwang Yin","Mantas Mazeika","Ann-Kathrin Dombrowski","Shashwat Goel","Nathaniel Li","Michael J. Byun","Zifan Wang","Alex Mallen","Steven Basart","Sanmi Koyejo","Dawn Song","Matt Fredrikson","J. Zico Kolter","Dan Hendrycks"],"pdf_url":"https://arxiv.org/pdf/2310.01405v4.pdf","comment":"Code is available at\n  https://github.com/andyzoujm/representation-engineering"},{"id":"http://arxiv.org/abs/2411.02886v2","updated":"2025-03-03T05:49:41Z","published":"2024-11-05T07:56:24Z","title":"TokenSelect: Efficient Long-Context Inference and Length Extrapolation\n  for LLMs via Dynamic Token-Level KV Cache Selection","summary":"  The rapid advancement of Large Language Models (LLMs) has driven growing\ndemand for processing extended context sequences in contemporary applications.\nHowever, this progress faces two major challenges: performance degradation due\nto sequence lengths out-of-distribution, and excessively long inference times\ncaused by the quadratic computational complexity of attention. These issues\nhinder the application of LLMs in long-context scenarios. In this paper, we\npropose Dynamic Token-Level KV Cache Selection (TokenSelect), a training-free\nmethod for efficient and accurate long-context inference. TokenSelect builds\nupon the observation of non-contiguous attention sparsity, using Query-Key dot\nproducts to measure per-head KV Cache criticality at token-level. By per-head\nsoft voting mechanism, TokenSelect selectively involves a few critical KV cache\ntokens in attention calculation without sacrificing accuracy. To further\naccelerate TokenSelect, we design the Selection Cache based on observations of\nconsecutive Query similarity and implemented efficient dot product kernel,\nsignificantly reducing the overhead. A comprehensive evaluation of TokenSelect\ndemonstrates up to 23.84x speedup in attention computation and up to 2.28x\nacceleration in end-to-end latency, while providing superior performance\ncompared to state-of-the-art long-context inference methods.\n","authors":["Wei Wu","Zhuoshi Pan","Chao Wang","Liyi Chen","Yunchu Bai","Tianfu Wang","Kun Fu","Zheng Wang","Hui Xiong"],"pdf_url":"https://arxiv.org/pdf/2411.02886v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.14171v3","updated":"2025-03-03T05:44:29Z","published":"2025-02-20T00:39:05Z","title":"Enhancing Conversational Agents with Theory of Mind: Aligning Beliefs,\n  Desires, and Intentions for Human-Like Interaction","summary":"  Natural language interaction with agentic Artificial Intelligence (AI),\ndriven by Large Language Models (LLMs), is expected to remain a dominant\nparadigm in the near future. While humans instinctively align their\ncommunication with mental states -- an ability known as Theory of Mind (ToM),\ncurrent LLM powered systems exhibit significant limitations in this regard.\nThis study examines the extent to which open source language models (LLaMA) can\ncapture and preserve ToM related information and how effectively it contributes\nto consistent ToM reasoning in generated responses. We further investigate\nwhether explicit manipulation of ToM related components, such as beliefs,\ndesires, and intentions, can enhance response alignment. Experiments on two\nLLaMA 3 variants demonstrate that incorporating ToM informed alignment improves\nresponse quality, achieving win rates of 67 and 63 percent for the 3B and 8B\nmodels, respectively. These findings highlight the potential of ToM driven\nstrategies to improve alignment in LLM based conversational agents.\n","authors":["Mehdi Jafari","Devin Yuncheng Hua","Hao Xue","Flora Salim"],"pdf_url":"https://arxiv.org/pdf/2502.14171v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02268v3","updated":"2025-03-03T05:32:47Z","published":"2024-10-03T07:40:14Z","title":"Structural-Entropy-Based Sample Selection for Efficient and Effective\n  Learning","summary":"  Sample selection improves the efficiency and effectiveness of machine\nlearning models by providing informative and representative samples. Typically,\nsamples can be modeled as a sample graph, where nodes are samples and edges\nrepresent their similarities. Most existing methods are based on local\ninformation, such as the training difficulty of samples, thereby overlooking\nglobal information, such as connectivity patterns. This oversight can result in\nsuboptimal selection because global information is crucial for ensuring that\nthe selected samples well represent the structural properties of the graph. To\naddress this issue, we employ structural entropy to quantify global information\nand losslessly decompose it from the whole graph to individual nodes using the\nShapley value. Based on the decomposition, we present\n$\\textbf{S}$tructural-$\\textbf{E}$ntropy-based sample $\\textbf{S}$election\n($\\textbf{SES}$), a method that integrates both global and local information to\nselect informative and representative samples. SES begins by constructing a\n$k$NN-graph among samples based on their similarities. It then measures sample\nimportance by combining structural entropy (global metric) with training\ndifficulty (local metric). Finally, SES applies importance-biased blue noise\nsampling to select a set of diverse and representative samples. Comprehensive\nexperiments on three learning scenarios -- supervised learning, active\nlearning, and continual learning -- clearly demonstrate the effectiveness of\nour method.\n","authors":["Tianchi Xie","Jiangning Zhu","Guozu Ma","Minzhi Lin","Wei Chen","Weikai Yang","Shixia Liu"],"pdf_url":"https://arxiv.org/pdf/2410.02268v3.pdf","comment":"Published as a conference paper at ICLR 2025"},{"id":"http://arxiv.org/abs/2502.17720v2","updated":"2025-03-03T04:31:48Z","published":"2025-02-24T23:23:27Z","title":"Spontaneous Giving and Calculated Greed in Language Models","summary":"  Large language models demonstrate advanced problem-solving capabilities by\nincorporating reasoning techniques such as chain of thought and reflection.\nHowever, how these reasoning capabilities extend to social intelligence remains\nunclear. In this study, we investigate this question using economic games that\nmodel social dilemmas, where social intelligence plays a crucial role. First,\nwe examine the effects of chain-of-thought and reflection techniques in a\npublic goods game. We then extend our analysis to six economic games on\ncooperation and punishment, comparing off-the-shelf non-reasoning and reasoning\nmodels. We find that reasoning models significantly reduce cooperation and norm\nenforcement, prioritizing individual rationality. Consequently, groups with\nmore reasoning models exhibit less cooperation and lower gains through repeated\ninteractions. These behaviors parallel human tendencies of \"spontaneous giving\nand calculated greed.\" Our results suggest the need for AI architectures that\nincorporate social intelligence alongside reasoning capabilities to ensure that\nAI supports, rather than disrupts, human cooperative intuition.\n","authors":["Yuxuan Li","Hirokazu Shirado"],"pdf_url":"https://arxiv.org/pdf/2502.17720v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.09906v3","updated":"2025-03-03T04:28:49Z","published":"2024-02-15T12:12:19Z","title":"Generative Representational Instruction Tuning","summary":"  All text-based language problems can be reduced to either generation or\nembedding. Current models only perform well at one or the other. We introduce\ngenerative representational instruction tuning (GRIT) whereby a large language\nmodel is trained to handle both generative and embedding tasks by\ndistinguishing between them through instructions. Compared to other open\nmodels, our resulting GritLM 7B sets a new state of the art on the Massive Text\nEmbedding Benchmark (MTEB) and outperforms all models up to its size on a range\nof generative tasks. By scaling up further, GritLM 8x7B outperforms all open\ngenerative language models that we tried while still being among the best\nembedding models. Notably, we find that GRIT matches training on only\ngenerative or embedding data, thus we can unify both at no performance loss.\nAmong other benefits, the unification via GRIT speeds up Retrieval-Augmented\nGeneration (RAG) by > 60% for long documents, by no longer requiring separate\nretrieval and generation models. Models, code, etc. are freely available at\nhttps://github.com/ContextualAI/gritlm.\n","authors":["Niklas Muennighoff","Hongjin Su","Liang Wang","Nan Yang","Furu Wei","Tao Yu","Amanpreet Singh","Douwe Kiela"],"pdf_url":"https://arxiv.org/pdf/2402.09906v3.pdf","comment":"67 pages (16 main), 25 figures, 34 tables"},{"id":"http://arxiv.org/abs/2405.16821v3","updated":"2025-03-03T04:25:41Z","published":"2024-05-27T04:40:56Z","title":"Perturbation-Restrained Sequential Model Editing","summary":"  Model editing is an emerging field that focuses on updating the knowledge\nembedded within large language models (LLMs) without extensive retraining.\nHowever, current model editing methods significantly compromise the general\nabilities of LLMs as the number of edits increases, and this trade-off poses a\nsubstantial challenge to the continual learning of LLMs. In this paper, we\nfirst theoretically analyze that the factor affecting the general abilities in\nsequential model editing lies in the condition number of the edited matrix. The\ncondition number of a matrix represents its numerical sensitivity, and\ntherefore can be used to indicate the extent to which the original knowledge\nassociations stored in LLMs are perturbed after editing. Subsequently,\nstatistical findings demonstrate that the value of this factor becomes larger\nas the number of edits increases, thereby exacerbating the deterioration of\ngeneral abilities. To this end, a framework termed Perturbation Restraint on\nUpper bouNd for Editing (PRUNE) is proposed, which applies the condition number\nrestraints in sequential editing. These restraints can lower the upper bound on\nperturbation to edited models, thus preserving the general abilities.\nSystematically, we conduct experiments employing three editing methods on three\nLLMs across four downstream tasks. The results show that PRUNE can preserve\ngeneral abilities while maintaining the editing performance effectively in\nsequential model editing. The code are available at\nhttps://github.com/mjy1111/PRUNE.\n","authors":["Jun-Yu Ma","Hong Wang","Hao-Xiang Xu","Zhen-Hua Ling","Jia-Chen Gu"],"pdf_url":"https://arxiv.org/pdf/2405.16821v3.pdf","comment":"Accepted by ICLR 2025"},{"id":"http://arxiv.org/abs/2502.12110v2","updated":"2025-03-03T04:14:02Z","published":"2025-02-17T18:36:14Z","title":"A-MEM: Agentic Memory for LLM Agents","summary":"  While large language model (LLM) agents can effectively use external tools\nfor complex real-world tasks, they require memory systems to leverage\nhistorical experiences. Current memory systems enable basic storage and\nretrieval but lack sophisticated memory organization, despite recent attempts\nto incorporate graph databases. Moreover, these systems' fixed operations and\nstructures limit their adaptability across diverse tasks. To address this\nlimitation, this paper proposes a novel agentic memory system for LLM agents\nthat can dynamically organize memories in an agentic way. Following the basic\nprinciples of the Zettelkasten method, we designed our memory system to create\ninterconnected knowledge networks through dynamic indexing and linking. When a\nnew memory is added, we generate a comprehensive note containing multiple\nstructured attributes, including contextual descriptions, keywords, and tags.\nThe system then analyzes historical memories to identify relevant connections,\nestablishing links where meaningful similarities exist. Additionally, this\nprocess enables memory evolution - as new memories are integrated, they can\ntrigger updates to the contextual representations and attributes of existing\nhistorical memories, allowing the memory network to continuously refine its\nunderstanding. Our approach combines the structured organization principles of\nZettelkasten with the flexibility of agent-driven decision making, allowing for\nmore adaptive and context-aware memory management. Empirical experiments on six\nfoundation models show superior improvement against existing SOTA baselines.\nThe source code is available at https://github.com/WujiangXu/AgenticMemory.\n","authors":["Wujiang Xu","Zujie Liang","Kai Mei","Hang Gao","Juntao Tan","Yongfeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2502.12110v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.14189v2","updated":"2025-03-03T04:11:31Z","published":"2025-02-20T01:46:12Z","title":"QUAD-LLM-MLTC: Large Language Models Ensemble Learning for Healthcare\n  Text Multi-Label Classification","summary":"  The escalating volume of collected healthcare textual data presents a unique\nchallenge for automated Multi-Label Text Classification (MLTC), which is\nprimarily due to the scarcity of annotated texts for training and their nuanced\nnature. Traditional machine learning models often fail to fully capture the\narray of expressed topics. However, Large Language Models (LLMs) have\ndemonstrated remarkable effectiveness across numerous Natural Language\nProcessing (NLP) tasks in various domains, which show impressive computational\nefficiency and suitability for unsupervised learning through prompt\nengineering. Consequently, these LLMs promise an effective MLTC of medical\nnarratives. However, when dealing with various labels, different prompts can be\nrelevant depending on the topic. To address these challenges, the proposed\napproach, QUAD-LLM-MLTC, leverages the strengths of four LLMs: GPT-4o, BERT,\nPEGASUS, and BART. QUAD-LLM-MLTC operates in a sequential pipeline in which\nBERT extracts key tokens, PEGASUS augments textual data, GPT-4o classifies, and\nBART provides topics' assignment probabilities, which results in four\nclassifications, all in a 0-shot setting. The outputs are then combined using\nensemble learning and processed through a meta-classifier to produce the final\nMLTC result. The approach is evaluated using three samples of annotated texts,\nwhich contrast it with traditional and single-model methods. The results show\nsignificant improvements across the majority of the topics in the\nclassification's F1 score and consistency (F1 and Micro-F1 scores of 78.17% and\n80.16% with standard deviations of 0.025 and 0.011, respectively). This\nresearch advances MLTC using LLMs and provides an efficient and scalable\nsolution to rapidly categorize healthcare-related text data without further\ntraining.\n","authors":["Hajar Sakai","Sarah S. Lam"],"pdf_url":"https://arxiv.org/pdf/2502.14189v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.00617v4","updated":"2025-03-03T03:41:11Z","published":"2024-06-30T08:00:34Z","title":"Iterative Nash Policy Optimization: Aligning LLMs with General\n  Preferences via No-Regret Learning","summary":"  Reinforcement Learning with Human Feedback (RLHF) has achieved great success\nin aligning large language models (LLMs) with human preferences. Prevalent RLHF\napproaches are reward-based, following the Bradley-Terry (BT) model assumption,\nwhich may not fully capture the complexity of human preferences. In this paper,\nwe explore RLHF under a general preference framework and approach it from a\ngame-theoretic perspective. Specifically, we formulate the problem as a\ntwo-player game and propose a novel online algorithm, iterative Nash policy\noptimization (INPO). The key idea is to let the policy play against itself via\nno-regret learning, thereby approximating the Nash policy. Unlike previous\nmethods, INPO bypasses the need for estimating the expected win rate for\nindividual responses, which typically incurs high computational or annotation\ncosts. Instead, we introduce a new loss objective that is directly minimized\nover a preference dataset. We provide theoretical analysis for our approach and\ndemonstrate its effectiveness through experiments on various representative\nbenchmarks. With an LLaMA-3-8B-based SFT model, INPO achieves a 42.6%\nlength-controlled win rate on AlpacaEval 2.0 and a 37.8% win rate on\nArena-Hard, showing substantial improvement over the state-of-the-art online\nRLHF algorithms.\n","authors":["Yuheng Zhang","Dian Yu","Baolin Peng","Linfeng Song","Ye Tian","Mingyue Huo","Nan Jiang","Haitao Mi","Dong Yu"],"pdf_url":"https://arxiv.org/pdf/2407.00617v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.14093v3","updated":"2025-03-03T03:19:31Z","published":"2024-05-23T01:43:54Z","title":"A Survey on Vision-Language-Action Models for Embodied AI","summary":"  Embodied AI is widely recognized as a key element of artificial general\nintelligence because it involves controlling embodied agents to perform tasks\nin the physical world. Building on the success of large language models and\nvision-language models, a new category of multimodal models -- referred to as\nvision-language-action models (VLAs) -- has emerged to address\nlanguage-conditioned robotic tasks in embodied AI by leveraging their distinct\nability to generate actions. In recent years, a myriad of VLAs have been\ndeveloped, making it imperative to capture the rapidly evolving landscape\nthrough a comprehensive survey. To this end, we present the first survey on\nVLAs for embodied AI. This work provides a detailed taxonomy of VLAs, organized\ninto three major lines of research. The first line focuses on individual\ncomponents of VLAs. The second line is dedicated to developing control policies\nadept at predicting low-level actions. The third line comprises high-level task\nplanners capable of decomposing long-horizon tasks into a sequence of subtasks,\nthereby guiding VLAs to follow more general user instructions. Furthermore, we\nprovide an extensive summary of relevant resources, including datasets,\nsimulators, and benchmarks. Finally, we discuss the challenges faced by VLAs\nand outline promising future directions in embodied AI.\n","authors":["Yueen Ma","Zixing Song","Yuzheng Zhuang","Jianye Hao","Irwin King"],"pdf_url":"https://arxiv.org/pdf/2405.14093v3.pdf","comment":"16 pages, a survey of vision-language-action models"},{"id":"http://arxiv.org/abs/2412.17242v3","updated":"2025-03-03T03:08:43Z","published":"2024-12-23T03:30:34Z","title":"On the Generalization and Adaptation Ability of Machine-Generated Text\n  Detectors in Academic Writing","summary":"  The rising popularity of large language models (LLMs) has raised concerns\nabout machine-generated text (MGT), particularly in academic settings, where\nissues like plagiarism and misinformation are prevalent. As a result,\ndeveloping a highly generalizable and adaptable MGT detection system has become\nan urgent priority. Given that LLMs are most commonly misused in academic\nwriting, this work investigates the generalization and adaptation capabilities\nof MGT detectors in three key aspects specific to academic writing: First, we\nconstruct MGT-Acedemic, a large-scale dataset comprising over 336M tokens and\n749K samples. MGT-Acedemic focuses on academic writing, featuring human-written\ntexts (HWTs) and MGTs across STEM, Humanities, and Social Sciences, paired with\nan extensible code framework for efficient benchmarking. Second, we benchmark\nthe performance of various detectors for binary classification and attribution\ntasks in both in-domain and cross-domain settings. This benchmark reveals the\noften-overlooked challenges of attribution tasks. Third, we introduce a novel\nattribution task where models have to adapt to new classes over time without\n(or with very limited) access to prior training data in both few-shot and\nmany-shot scenarios. We implement eight different adapting techniques to\nimprove the performance and highlight the inherent complexity of the task. Our\nfindings provide insights into the generalization and adaptation ability of MGT\ndetectors across diverse scenarios and lay the foundation for building robust,\nadaptive detection systems. The code framework is available at\nhttps://github.com/Y-L-LIU/MGTBench-2.0.\n","authors":["Yule Liu","Zhiyuan Zhong","Yifan Liao","Zhen Sun","Jingyi Zheng","Jiaheng Wei","Qingyuan Gong","Fenghua Tong","Yang Chen","Yang Zhang","Xinlei He"],"pdf_url":"https://arxiv.org/pdf/2412.17242v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13085v2","updated":"2025-03-03T03:08:28Z","published":"2024-10-16T23:03:27Z","title":"MMed-RAG: Versatile Multimodal RAG System for Medical Vision Language\n  Models","summary":"  Artificial Intelligence (AI) has demonstrated significant potential in\nhealthcare, particularly in disease diagnosis and treatment planning. Recent\nprogress in Medical Large Vision-Language Models (Med-LVLMs) has opened up new\npossibilities for interactive diagnostic tools. However, these models often\nsuffer from factual hallucination, which can lead to incorrect diagnoses.\nFine-tuning and retrieval-augmented generation (RAG) have emerged as methods to\naddress these issues. However, the amount of high-quality data and distribution\nshifts between training data and deployment data limit the application of\nfine-tuning methods. Although RAG is lightweight and effective, existing\nRAG-based approaches are not sufficiently general to different medical domains\nand can potentially cause misalignment issues, both between modalities and\nbetween the model and the ground truth. In this paper, we propose a versatile\nmultimodal RAG system, MMed-RAG, designed to enhance the factuality of\nMed-LVLMs. Our approach introduces a domain-aware retrieval mechanism, an\nadaptive retrieved contexts selection method, and a provable RAG-based\npreference fine-tuning strategy. These innovations make the RAG process\nsufficiently general and reliable, significantly improving alignment when\nintroducing retrieved contexts. Experimental results across five medical\ndatasets (involving radiology, ophthalmology, pathology) on medical VQA and\nreport generation demonstrate that MMed-RAG can achieve an average improvement\nof 43.8% in the factual accuracy of Med-LVLMs. Our data and code are available\nin https://github.com/richard-peng-xia/MMed-RAG.\n","authors":["Peng Xia","Kangyu Zhu","Haoran Li","Tianze Wang","Weijia Shi","Sheng Wang","Linjun Zhang","James Zou","Huaxiu Yao"],"pdf_url":"https://arxiv.org/pdf/2410.13085v2.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2406.06600v3","updated":"2025-03-03T03:05:30Z","published":"2024-06-06T13:44:57Z","title":"HORAE: A Domain-Agnostic Modeling Language for Automating Multimodal\n  Service Regulation","summary":"  Artificial intelligence is rapidly encroaching on the field of service\nregulation. This work-in-progress article presents the design principles behind\nHORAE, a unified specification language to model multimodal regulation rules\nacross a diverse set of domains. We show how HORAE facilitates an intelligent\nservice regulation pipeline by further exploiting a fine-tuned large language\nmodel named HORAE that automates the HORAE modeling process, thereby yielding\nan end-to-end framework for fully automated intelligent service regulation.\n","authors":["Yutao Sun","Mingshuai Chen","Kangjia Zhao","Jintao Chen"],"pdf_url":"https://arxiv.org/pdf/2406.06600v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07404v2","updated":"2025-03-03T03:02:55Z","published":"2024-11-11T22:22:21Z","title":"Controllable Context Sensitivity and the Knob Behind It","summary":"  When making predictions, a language model must trade off how much it relies\non its context vs. its prior knowledge. Choosing how sensitive the model is to\nits context is a fundamental functionality, as it enables the model to excel at\ntasks like retrieval-augmented generation and question-answering. In this\npaper, we search for a knob which controls this sensitivity, determining\nwhether language models answer from the context or their prior knowledge. To\nguide this search, we design a task for controllable context sensitivity. In\nthis task, we first feed the model a context (Paris is in England) and a\nquestion (Where is Paris?); we then instruct the model to either use its prior\nor contextual knowledge and evaluate whether it generates the correct answer\nfor both intents (either France or England). When fine-tuned on this task,\ninstruction-tuned versions of Llama-3.1, Mistral-v0.3, and Gemma-2 can solve it\nwith high accuracy (85-95%). Analyzing these high-performing models, we narrow\ndown which layers may be important to context sensitivity using a novel linear\ntime algorithm. Then, in each model, we identify a 1-D subspace in a single\nlayer that encodes whether the model follows context or prior knowledge.\nInterestingly, while we identify this subspace in a fine-tuned model, we find\nthat the exact same subspace serves as an effective knob in not only that model\nbut also non-fine-tuned instruct and base models of that model family. Finally,\nwe show a strong correlation between a model's performance and how distinctly\nit separates context-agreeing from context-ignoring answers in this subspace.\nThese results suggest a single subspace facilitates how the model chooses\nbetween context and prior knowledge, hinting at a simple fundamental mechanism\nthat controls this behavior.\n","authors":["Julian Minder","Kevin Du","Niklas Stoehr","Giovanni Monea","Chris Wendler","Robert West","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2411.07404v2.pdf","comment":"Published as a conference paper at ICLR 2025"},{"id":"http://arxiv.org/abs/2502.20854v2","updated":"2025-03-03T03:00:59Z","published":"2025-02-28T08:53:08Z","title":"A Pilot Empirical Study on When and How to Use Knowledge Graphs as\n  Retrieval Augmented Generation","summary":"  The integration of Knowledge Graphs (KGs) into the Retrieval Augmented\nGeneration (RAG) framework has attracted significant interest, with early\nstudies showing promise in mitigating hallucinations and improving model\naccuracy. However, a systematic understanding and comparative analysis of the\nrapidly emerging KG-RAG methods are still lacking. This paper seeks to lay the\nfoundation for systematically answering the question of when and how to use\nKG-RAG by analyzing their performance in various application scenarios\nassociated with different technical configurations. After outlining the mind\nmap using KG-RAG framework and summarizing its popular pipeline, we conduct a\npilot empirical study of KG-RAG works to reimplement and evaluate 6 KG-RAG\nmethods across 7 datasets in diverse scenarios, analyzing the impact of 9\nKG-RAG configurations in combination with 17 LLMs. Our results underscore the\ncritical role of appropriate application conditions and optimal configurations\nof KG-RAG components.\n","authors":["Xujie Yuan","Yongxu Liu","Shimin Di","Shiwen Wu","Libin Zheng","Rui Meng","Lei Chen","Xiaofang Zhou","Jian Yin"],"pdf_url":"https://arxiv.org/pdf/2502.20854v2.pdf","comment":"8 pages, 2 figures, 14 tables"},{"id":"http://arxiv.org/abs/2410.08109v3","updated":"2025-03-03T02:45:58Z","published":"2024-10-10T16:56:05Z","title":"A Closer Look at Machine Unlearning for Large Language Models","summary":"  Large language models (LLMs) may memorize sensitive or copyrighted content,\nraising privacy and legal concerns. Due to the high cost of retraining from\nscratch, researchers attempt to employ machine unlearning to remove specific\ncontent from LLMs while preserving the overall performance. In this paper, we\ndiscuss several issues in machine unlearning for LLMs and provide our insights\non possible approaches. To address the issue of inadequate evaluation of model\noutputs after unlearning, we introduce three additional metrics to evaluate\ntoken diversity, sentence semantics, and factual correctness. We then\ncategorize unlearning methods into untargeted and targeted, and discuss their\nissues respectively. Specifically, the behavior that untargeted unlearning\nattempts to approximate is unpredictable and may involve hallucinations, and\nexisting regularization is insufficient for targeted unlearning. To alleviate\nthese issues, we propose using the objective of maximizing entropy (ME) for\nuntargeted unlearning and incorporate answer preservation (AP) loss as\nregularization for targeted unlearning. Experimental results across three\nscenarios, i.e., fictitious unlearning, continual unlearning, and real-world\nunlearning, demonstrate the effectiveness of our approaches. The code is\navailable at https://github.com/sail-sg/closer-look-LLM-unlearning.\n","authors":["Xiaojian Yuan","Tianyu Pang","Chao Du","Kejiang Chen","Weiming Zhang","Min Lin"],"pdf_url":"https://arxiv.org/pdf/2410.08109v3.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2409.19788v2","updated":"2025-03-03T02:38:52Z","published":"2024-09-29T21:20:57Z","title":"Exploring Adversarial Robustness in Classification tasks using DNA\n  Language Models","summary":"  DNA Language Models, such as GROVER, DNABERT2 and the Nucleotide Transformer,\noperate on DNA sequences that inherently contain sequencing errors, mutations,\nand laboratory-induced noise, which may significantly impact model performance.\nDespite the importance of this issue, the robustness of DNA language models\nremains largely underexplored. In this paper, we comprehensivly investigate\ntheir robustness in DNA classification by applying various adversarial attack\nstrategies: the character (nucleotide substitutions), word (codon\nmodifications), and sentence levels (back-translation-based transformations) to\nsystematically analyze model vulnerabilities. Our results demonstrate that DNA\nlanguage models are highly susceptible to adversarial attacks, leading to\nsignificant performance degradation. Furthermore, we explore adversarial\ntraining method as a defense mechanism, which enhances both robustness and\nclassification accuracy. This study highlights the limitations of DNA language\nmodels and underscores the necessity of robustness in bioinformatics.\n","authors":["Hyunwoo Yoo","Haebin Shin","Kaidi Xu","Gail Rosen"],"pdf_url":"https://arxiv.org/pdf/2409.19788v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12952v2","updated":"2025-03-03T02:27:02Z","published":"2024-10-16T18:40:26Z","title":"Facilitating Multi-turn Function Calling for LLMs via Compositional\n  Instruction Tuning","summary":"  Large Language Models (LLMs) have exhibited significant potential in\nperforming diverse tasks, including the ability to call functions or use\nexternal tools to enhance their performance. While current research on function\ncalling by LLMs primarily focuses on single-turn interactions, this paper\naddresses the overlooked necessity for LLMs to engage in multi-turn function\ncalling--critical for handling compositional, real-world queries that require\nplanning with functions but not only use functions. To facilitate this, we\nintroduce an approach, BUTTON, which generates synthetic compositional\ninstruction tuning data via bottom-up instruction construction and top-down\ntrajectory generation. In the bottom-up phase, we generate simple atomic tasks\nbased on real-world scenarios and build compositional tasks using heuristic\nstrategies based on atomic tasks. Corresponding function definitions are then\nsynthesized for these compositional tasks. The top-down phase features a\nmulti-agent environment where interactions among simulated humans, assistants,\nand tools are utilized to gather multi-turn function calling trajectories. This\napproach ensures task compositionality and allows for effective function and\ntrajectory generation by examining atomic tasks within compositional tasks. We\nproduce a dataset BUTTONInstruct comprising 8k data points and demonstrate its\neffectiveness through extensive experiments across various LLMs.\n","authors":["Mingyang Chen","Haoze Sun","Tianpeng Li","Fan Yang","Hao Liang","Keer Lu","Bin Cui","Wentao Zhang","Zenan Zhou","Weipeng Chen"],"pdf_url":"https://arxiv.org/pdf/2410.12952v2.pdf","comment":"Accepted to ICLR 2025"},{"id":"http://arxiv.org/abs/2501.13983v3","updated":"2025-03-03T02:06:47Z","published":"2025-01-23T06:57:24Z","title":"AdEval: Alignment-based Dynamic Evaluation to Mitigate Data\n  Contamination in Large Language Models","summary":"  As Large Language Models (LLMs) are pretrained on massive-scale corpora, the\nissue of data contamination has become increasingly severe, leading to\npotential overestimation of model performance during evaluation. To address\nthis, we propose AdEval (Alignment-based Dynamic Evaluation), a dynamic data\nevaluation method aimed at mitigating the impact of data contamination on\nevaluation reliability. Experimental results on multiple datasets demonstrate\nthat AdEval effectively reduces the impact of data contamination on evaluation\noutcomes, enhancing both the fairness and reliability of the evaluation\nprocess.\n","authors":["Yang Fan"],"pdf_url":"https://arxiv.org/pdf/2501.13983v3.pdf","comment":"There are serious academic problems in this paper, such as data\n  falsification and plagiarism in the method of the paper"},{"id":"http://arxiv.org/abs/2409.02060v2","updated":"2025-03-03T01:25:46Z","published":"2024-09-03T17:08:20Z","title":"OLMoE: Open Mixture-of-Experts Language Models","summary":"  We introduce OLMoE, a fully open, state-of-the-art language model leveraging\nsparse Mixture-of-Experts (MoE). OLMoE-1B-7B has 7 billion (B) parameters but\nuses only 1B per input token. We pretrain it on 5 trillion tokens and further\nadapt it to create OLMoE-1B-7B-Instruct. Our models outperform all available\nmodels with similar active parameters, even surpassing larger ones like\nLlama2-13B-Chat and DeepSeekMoE-16B. We present various experiments on MoE\ntraining, analyze routing in our model showing high specialization, and\nopen-source all aspects of our work: model weights, training data, code, and\nlogs.\n","authors":["Niklas Muennighoff","Luca Soldaini","Dirk Groeneveld","Kyle Lo","Jacob Morrison","Sewon Min","Weijia Shi","Pete Walsh","Oyvind Tafjord","Nathan Lambert","Yuling Gu","Shane Arora","Akshita Bhagia","Dustin Schwenk","David Wadden","Alexander Wettig","Binyuan Hui","Tim Dettmers","Douwe Kiela","Ali Farhadi","Noah A. Smith","Pang Wei Koh","Amanpreet Singh","Hannaneh Hajishirzi"],"pdf_url":"https://arxiv.org/pdf/2409.02060v2.pdf","comment":"63 pages (24 main), 36 figures, 17 tables"},{"id":"http://arxiv.org/abs/2410.01417v2","updated":"2025-03-03T00:41:36Z","published":"2024-10-02T10:58:54Z","title":"The Labyrinth of Links: Navigating the Associative Maze of Multi-modal\n  LLMs","summary":"  Multi-modal Large Language Models (MLLMs) have exhibited impressive\ncapability. However, recently many deficiencies of MLLMs have been found\ncompared to human intelligence, $\\textit{e.g.}$, hallucination. To drive the\nMLLMs study, the community dedicated efforts to building larger benchmarks with\ncomplex tasks. In this paper, we propose benchmarking an essential but usually\noverlooked intelligence: $\\textbf{association}$, a human's basic capability to\nlink observation and prior practice memory. To comprehensively investigate\nMLLM's performance on the association, we formulate the association task and\ndevise a standard benchmark based on adjective and verb semantic concepts.\nInstead of costly data annotation and curation, we propose a convenient\n$\\textbf{annotation-free}$ construction method transforming the general dataset\nfor our association tasks. Simultaneously, we devise a rigorous data refinement\nprocess to eliminate confusion in the raw dataset. Building on this database,\nwe establish three levels of association tasks: single-step, synchronous, and\nasynchronous associations. Moreover, we conduct a comprehensive investigation\ninto the MLLMs' zero-shot association capabilities, addressing multiple\ndimensions, including three distinct memory strategies, both open-source and\nclosed-source MLLMs, cutting-edge Mixture-of-Experts (MoE) models, and the\ninvolvement of human experts. Our systematic investigation shows that current\nopen-source MLLMs consistently exhibit poor capability in our association\ntasks, even the currently state-of-the-art GPT-4V(vision) also has a\nsignificant gap compared to humans. We believe our benchmark would pave the way\nfor future MLLM studies. $\\textit{Our data and code are available at:}$\nhttps://mvig-rhos.com/llm_inception.\n","authors":["Hong Li","Nanxi Li","Yuanjie Chen","Jianbin Zhu","Qinlu Guo","Cewu Lu","Yong-Lu Li"],"pdf_url":"https://arxiv.org/pdf/2410.01417v2.pdf","comment":"Accepted by ICLR 2025. Project page:\n  https://mvig-rhos.com/llm_inception"},{"id":"http://arxiv.org/abs/2405.02318v2","updated":"2025-03-03T00:38:48Z","published":"2024-04-18T00:20:48Z","title":"NL2FOL: Translating Natural Language to First-Order Logic for Logical\n  Fallacy Detection","summary":"  Translating natural language into formal language such as First-Order Logic\n(FOL) is a foundational challenge in NLP with wide-ranging applications in\nautomated reasoning, misinformation tracking, and knowledge validation. In this\npaper, we introduce Natural Language to First-Order Logic (NL2FOL), a framework\nto autoformalize natural language to FOL step by step using Large Language\nModels (LLMs). Our approach addresses key challenges in this translation\nprocess, including the integration of implicit background knowledge. By\nleveraging structured representations generated by NL2FOL, we use\nSatisfiability Modulo Theory (SMT) solvers to reason about the logical validity\nof natural language statements. We present logical fallacy detection as a case\nstudy to evaluate the efficacy of NL2FOL. Being neurosymbolic, our approach\nalso provides interpretable insights into the reasoning process and\ndemonstrates robustness without requiring model fine-tuning or labeled training\ndata. Our framework achieves strong performance on multiple datasets. On the\nLOGIC dataset, NL2FOL achieves an F1-score of 78%, while generalizing\neffectively to the LOGICCLIMATE dataset with an F1-score of 80%.\n","authors":["Abhinav Lalwani","Tasha Kim","Lovish Chopra","Christopher Hahn","Zhijing Jin","Mrinmaya Sachan"],"pdf_url":"https://arxiv.org/pdf/2405.02318v2.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2411.18135v2","updated":"2025-03-03T16:00:39Z","published":"2024-11-27T08:33:42Z","title":"ModeDreamer: Mode Guiding Score Distillation for Text-to-3D Generation\n  using Reference Image Prompts","summary":"  Existing Score Distillation Sampling (SDS)-based methods have driven\nsignificant progress in text-to-3D generation. However, 3D models produced by\nSDS-based methods tend to exhibit over-smoothing and low-quality outputs. These\nissues arise from the mode-seeking behavior of current methods, where the\nscores used to update the model oscillate between multiple modes, resulting in\nunstable optimization and diminished output quality. To address this problem,\nwe introduce a novel image prompt score distillation loss named ISD, which\nemploys a reference image to direct text-to-3D optimization toward a specific\nmode. Our ISD loss can be implemented by using IP-Adapter, a lightweight\nadapter for integrating image prompt capability to a text-to-image diffusion\nmodel, as a mode-selection module. A variant of this adapter, when not being\nprompted by a reference image, can serve as an efficient control variate to\nreduce variance in score estimates, thereby enhancing both output quality and\noptimization stability. Our experiments demonstrate that the ISD loss\nconsistently achieves visually coherent, high-quality outputs and improves\noptimization speed compared to prior text-to-3D methods, as demonstrated\nthrough both qualitative and quantitative evaluations on the T3Bench benchmark\nsuite.\n","authors":["Uy Dieu Tran","Minh Luu","Phong Ha Nguyen","Khoi Nguyen","Binh-Son Hua"],"pdf_url":"https://arxiv.org/pdf/2411.18135v2.pdf","comment":"Project page: https://modedreamer.github.io/"},{"id":"http://arxiv.org/abs/2409.18459v2","updated":"2025-03-03T15:04:18Z","published":"2024-09-27T05:43:22Z","title":"FoodMLLM-JP: Leveraging Multimodal Large Language Models for Japanese\n  Recipe Generation","summary":"  Research on food image understanding using recipe data has been a\nlong-standing focus due to the diversity and complexity of the data. Moreover,\nfood is inextricably linked to people's lives, making it a vital research area\nfor practical applications such as dietary management. Recent advancements in\nMultimodal Large Language Models (MLLMs) have demonstrated remarkable\ncapabilities, not only in their vast knowledge but also in their ability to\nhandle languages naturally. While English is predominantly used, they can also\nsupport multiple languages including Japanese. This suggests that MLLMs are\nexpected to significantly improve performance in food image understanding\ntasks. We fine-tuned open MLLMs LLaVA-1.5 and Phi-3 Vision on a Japanese recipe\ndataset and benchmarked their performance against the closed model GPT-4o. We\nthen evaluated the content of generated recipes, including ingredients and\ncooking procedures, using 5,000 evaluation samples that comprehensively cover\nJapanese food culture. Our evaluation demonstrates that the open models trained\non recipe data outperform GPT-4o, the current state-of-the-art model, in\ningredient generation. Our model achieved F1 score of 0.531, surpassing\nGPT-4o's F1 score of 0.481, indicating a higher level of accuracy. Furthermore,\nour model exhibited comparable performance to GPT-4o in generating cooking\nprocedure text.\n","authors":["Yuki Imajuku","Yoko Yamakata","Kiyoharu Aizawa"],"pdf_url":"https://arxiv.org/pdf/2409.18459v2.pdf","comment":"15 pages, 5 figures. We found errors in the calculation of evaluation\n  metrics, which were corrected in this version with\n  $\\color{blue}{\\text{modifications highlighted in blue}}$. Please also see the\n  Appendix"},{"id":"http://arxiv.org/abs/2408.11561v2","updated":"2025-03-03T15:04:03Z","published":"2024-08-21T12:15:20Z","title":"Self-Supervised Iterative Refinement for Anomaly Detection in Industrial\n  Quality Control","summary":"  This study introduces the Iterative Refinement Process (IRP), a robust\nanomaly detection methodology designed for high-stakes industrial quality\ncontrol. The IRP enhances defect detection accuracy through a cyclic data\nrefinement strategy, iteratively removing misleading data points to improve\nmodel performance and robustness. We validate the IRP's effectiveness using two\nbenchmark datasets, Kolektor SDD2 (KSDD2) and MVTec AD, covering a wide range\nof industrial products and defect types. Our experimental results demonstrate\nthat the IRP consistently outperforms traditional anomaly detection models,\nparticularly in environments with high noise levels. This study highlights the\nIRP's potential to significantly enhance anomaly detection processes in\nindustrial settings, effectively managing the challenges of sparse and noisy\ndata.\n","authors":["Muhammad Aqeel","Shakiba Sharifi","Marco Cristani","Francesco Setti"],"pdf_url":"https://arxiv.org/pdf/2408.11561v2.pdf","comment":"Accepted to VISAPP 2025"},{"id":"http://arxiv.org/abs/2409.15259v2","updated":"2025-03-03T15:01:03Z","published":"2024-09-23T17:56:03Z","title":"StarVid: Enhancing Semantic Alignment in Video Diffusion Models via\n  Spatial and SynTactic Guided Attention Refocusing","summary":"  Recent advances in text-to-video (T2V) generation with diffusion models have\ngarnered significant attention. However, they typically perform well in scenes\nwith a single object and motion, struggling in compositional scenarios with\nmultiple objects and distinct motions to accurately reflect the semantic\ncontent of text prompts. To address these challenges, we propose\n\\textbf{StarVid}, a plug-and-play, training-free method that improves semantic\nalignment between multiple subjects, their motions, and text prompts in T2V\nmodels. StarVid first leverages the spatial reasoning capabilities of large\nlanguage models (LLMs) for two-stage motion trajectory planning based on text\nprompts. Such trajectories serve as spatial priors, guiding a spatial-aware\nloss to refocus cross-attention (CA) maps into distinctive regions.\nFurthermore, we propose a syntax-guided contrastive constraint to strengthen\nthe correlation between the CA maps of verbs and their corresponding nouns,\nenhancing motion-subject binding. Both qualitative and quantitative evaluations\ndemonstrate that the proposed framework significantly outperforms baseline\nmethods, delivering videos of higher quality with improved semantic\nconsistency.\n","authors":["Yuanhang Li","Qi Mao","Lan Chen","Zhen Fang","Lei Tian","Xinyan Xiao","Libiao Jin","Hua Wu"],"pdf_url":"https://arxiv.org/pdf/2409.15259v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09695v2","updated":"2025-03-03T14:48:45Z","published":"2025-01-16T17:48:03Z","title":"Mitigating Hallucinations in Large Vision-Language Models via DPO:\n  On-Policy Data Hold the Key","summary":"  Hallucination remains a major challenge for Large Vision-Language Models\n(LVLMs). Direct Preference Optimization (DPO) has gained increasing attention\nas a simple solution to hallucination issues. It directly learns from\nconstructed preference pairs that reflect the severity of hallucinations in\nresponses to the same prompt and image. Nonetheless, different data\nconstruction methods in existing works bring notable performance variations. We\nidentify a crucial factor here: outcomes are largely contingent on whether the\nconstructed data aligns on-policy w.r.t the initial (reference) policy of DPO.\nTheoretical analysis suggests that learning from off-policy data is impeded by\nthe presence of KL-divergence between the updated policy and the reference\npolicy. From the perspective of dataset distribution, we systematically\nsummarize the inherent flaws in existing algorithms that employ DPO to address\nhallucination issues. To alleviate the problems, we propose On-Policy Alignment\n(OPA)-DPO framework, which uniquely leverages expert feedback to correct\nhallucinated responses and aligns both the original and expert-revised\nresponses in an on-policy manner. Notably, with only 4.8k data, OPA-DPO\nachieves an additional reduction in the hallucination rate of LLaVA-1.5-7B:\n13.26% on the AMBER benchmark and 5.39% on the Object-Hal benchmark, compared\nto the previous SOTA algorithm trained with 16k samples. Our implementation is\navailable at https://github.com/zhyang2226/OPA-DPO.\n","authors":["Zhihe Yang","Xufang Luo","Dongqi Han","Yunjian Xu","Dongsheng Li"],"pdf_url":"https://arxiv.org/pdf/2501.09695v2.pdf","comment":"Accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2409.10071v4","updated":"2025-03-03T14:47:34Z","published":"2024-09-16T08:21:22Z","title":"Towards Physically Realizable Adversarial Attacks in Embodied Vision\n  Navigation","summary":"  The significant advancements in embodied vision navigation have raised\nconcerns about its susceptibility to adversarial attacks exploiting deep neural\nnetworks. Investigating the adversarial robustness of embodied vision\nnavigation is crucial, especially given the threat of 3D physical attacks that\ncould pose risks to human safety. However, existing attack methods for embodied\nvision navigation often lack physical feasibility due to challenges in\ntransferring digital perturbations into the physical world. Moreover, current\nphysical attacks for object detection struggle to achieve both multi-view\neffectiveness and visual naturalness in navigation scenarios. To address this,\nwe propose a practical attack method for embodied navigation by attaching\nadversarial patches to objects, where both opacity and textures are learnable.\nSpecifically, to ensure effectiveness across varying viewpoints, we employ a\nmulti-view optimization strategy based on object-aware sampling, which\noptimizes the patch's texture based on feedback from the vision-based\nperception model used in navigation. To make the patch inconspicuous to human\nobservers, we introduce a two-stage opacity optimization mechanism, in which\nopacity is fine-tuned after texture optimization. Experimental results\ndemonstrate that our adversarial patches decrease the navigation success rate\nby an average of 22.39%, outperforming previous methods in practicality,\neffectiveness, and naturalness. Code is available at:\nhttps://github.com/chen37058/Physical-Attacks-in-Embodied-Nav\n","authors":["Meng Chen","Jiawei Tu","Chao Qi","Yonghao Dang","Feng Zhou","Wei Wei","Jianqin Yin"],"pdf_url":"https://arxiv.org/pdf/2409.10071v4.pdf","comment":"7 pages, 7 figures, submitted to IEEE/RSJ International Conference on\n  Intelligent Robots and Systems (IROS) 2025"},{"id":"http://arxiv.org/abs/2412.07487v2","updated":"2025-03-03T14:04:23Z","published":"2024-12-10T13:12:32Z","title":"Stereo Hand-Object Reconstruction for Human-to-Robot Handover","summary":"  Jointly estimating hand and object shape facilitates the grasping task in\nhuman-to-robot handovers. However, relying on hand-crafted prior knowledge\nabout the geometric structure of the object fails when generalising to unseen\nobjects, and depth sensors fail to detect transparent objects such as drinking\nglasses. In this work, we propose a stereo-based method for hand-object\nreconstruction that combines single-view reconstructions probabilistically to\nform a coherent stereo reconstruction. We learn 3D shape priors from a large\nsynthetic hand-object dataset to ensure that our method is generalisable, and\nuse RGB inputs to better capture transparent objects. We show that our method\nreduces the object Chamfer distance compared to existing RGB based hand-object\nreconstruction methods on single view and stereo settings. We process the\nreconstructed hand-object shape with a projection-based outlier removal step\nand use the output to guide a human-to-robot handover pipeline with\nwide-baseline stereo RGB cameras. Our hand-object reconstruction enables a\nrobot to successfully receive a diverse range of household objects from the\nhuman.\n","authors":["Yik Lung Pang","Alessio Xompero","Changjae Oh","Andrea Cavallaro"],"pdf_url":"https://arxiv.org/pdf/2412.07487v2.pdf","comment":"8 pages, 9 figures, 1 table"},{"id":"http://arxiv.org/abs/2412.02993v2","updated":"2025-03-03T13:59:01Z","published":"2024-12-04T03:19:43Z","title":"EchoONE: Segmenting Multiple echocardiography Planes in One Model","summary":"  In clinical practice of echocardiography examinations, multiple planes\ncontaining the heart structures of different view are usually required in\nscreening, diagnosis and treatment of cardiac disease. AI models for\nechocardiography have to be tailored for each specific plane due to the\ndramatic structure differences, thus resulting in repetition development and\nextra complexity. Effective solution for such a multi-plane segmentation (MPS)\nproblem is highly demanded for medical images, yet has not been well\ninvestigated. In this paper, we propose a novel solution, EchoONE, for this\nproblem with a SAM-based segmentation architecture, a prior-composable mask\nlearning (PC-Mask) module for semantic-aware dense prompt generation, and a\nlearnable CNN-branch with a simple yet effective local feature fusion and\nadaption (LFFA) module for SAM adapting. We extensively evaluated our method on\nmultiple internal and external echocardiography datasets, and achieved\nconsistently state-of-the-art performance for multi-source datasets with\ndifferent heart planes. This is the first time that the MPS problem is solved\nin one model for echocardiography data. The code will be available at\nhttps://github.com/a2502503/EchoONE.\n","authors":["Jiongtong Hu","Wei Zhuo","Jun Cheng","Yingying Liu","Wufeng Xue","Dong Ni"],"pdf_url":"https://arxiv.org/pdf/2412.02993v2.pdf","comment":"Accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2502.18858v2","updated":"2025-03-03T13:38:50Z","published":"2025-02-26T05:59:45Z","title":"Evaluating Intelligence via Trial and Error","summary":"  Intelligence is a crucial trait for species to find solutions within a\nlimited number of trial-and-error attempts. Building on this idea, we introduce\nSurvival Game as a framework to evaluate intelligence based on the number of\nfailed attempts in a trial-and-error process. Fewer failures indicate higher\nintelligence. When the expectation and variance of failure counts are both\nfinite, it signals the ability to consistently find solutions to new\nchallenges, which we define as the Autonomous Level of intelligence. Using\nSurvival Game, we comprehensively evaluate existing AI systems. Our results\nshow that while AI systems achieve the Autonomous Level in simple tasks, they\nare still far from it in more complex tasks, such as vision, search,\nrecommendation, and language. While scaling current AI technologies might help,\nthis would come at an astronomical cost. Projections suggest that achieving the\nAutonomous Level for general tasks would require $10^{26}$ parameters. To put\nthis into perspective, loading such a massive model requires so many H100 GPUs\nthat their total value is $10^{7}$ times that of Apple Inc.'s market value.\nEven with Moore's Law, supporting such a parameter scale would take $70$ years.\nThis staggering cost highlights the complexity of human tasks and the\ninadequacies of current AI technologies. To further investigate this\nphenomenon, we conduct a theoretical analysis of Survival Game and its\nexperimental results. Our findings suggest that human tasks possess a\ncriticality property. As a result, Autonomous Level requires a deep\nunderstanding of the task's underlying mechanisms. Current AI systems, however,\ndo not fully grasp these mechanisms and instead rely on superficial mimicry,\nmaking it difficult for them to reach an autonomous level. We believe Survival\nGame can not only guide the future development of AI but also offer profound\ninsights into human intelligence.\n","authors":["Jingtao Zhan","Jiahao Zhao","Jiayu Li","Yiqun Liu","Bo Zhang","Qingyao Ai","Jiaxin Mao","Hongning Wang","Min Zhang","Shaoping Ma"],"pdf_url":"https://arxiv.org/pdf/2502.18858v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.15517v2","updated":"2025-03-03T13:22:14Z","published":"2024-09-23T20:09:43Z","title":"MATCH POLICY: A Simple Pipeline from Point Cloud Registration to\n  Manipulation Policies","summary":"  Many manipulation tasks require the robot to rearrange objects relative to\none another. Such tasks can be described as a sequence of relative poses\nbetween parts of a set of rigid bodies. In this work, we propose MATCH POLICY,\na simple but novel pipeline for solving high-precision pick and place tasks.\nInstead of predicting actions directly, our method registers the pick and place\ntargets to the stored demonstrations. This transfers action inference into a\npoint cloud registration task and enables us to realize nontrivial manipulation\npolicies without any training. MATCH POLICY is designed to solve high-precision\ntasks with a key-frame setting. By leveraging the geometric interaction and the\nsymmetries of the task, it achieves extremely high sample efficiency and\ngeneralizability to unseen configurations. We demonstrate its state-of-the-art\nperformance across various tasks on RLBench benchmark compared with several\nstrong baselines and test it on a real robot with six tasks.\n","authors":["Haojie Huang","Haotian Liu","Dian Wang","Robin Walters","Robert Platt"],"pdf_url":"https://arxiv.org/pdf/2409.15517v2.pdf","comment":"project url: https://haojhuang.github.io/match_page/"},{"id":"http://arxiv.org/abs/2409.20171v3","updated":"2025-03-03T13:12:48Z","published":"2024-09-30T10:29:41Z","title":"Annotation-Free Curb Detection Leveraging Altitude Difference Image","summary":"  Road curbs are considered as one of the crucial and ubiquitous traffic\nfeatures, which are essential for ensuring the safety of autonomous vehicles.\nCurrent methods for detecting curbs primarily rely on camera imagery or LiDAR\npoint clouds. Image-based methods are vulnerable to fluctuations in lighting\nconditions and exhibit poor robustness, while methods based on point clouds\ncircumvent the issues associated with lighting variations. However, it is the\ntypical case that significant processing delays are encountered due to the\nvoluminous amount of 3D points contained in each frame of the point cloud data.\nFurthermore, the inherently unstructured characteristics of point clouds poses\nchallenges for integrating the latest deep learning advancements into point\ncloud data applications. To address these issues, this work proposes an\nannotation-free curb detection method leveraging Altitude Difference Image\n(ADI), which effectively mitigates the aforementioned challenges. Given that\nmethods based on deep learning generally demand extensive, manually annotated\ndatasets, which are both expensive and labor-intensive to create, we present an\nAutomatic Curb Annotator (ACA) module. This module utilizes a deterministic\ncurb detection algorithm to automatically generate a vast quantity of training\ndata. Consequently, it facilitates the training of the curb detection model\nwithout necessitating any manual annotation of data. Finally, by incorporating\na post-processing module, we manage to achieve state-of-the-art results on the\nKITTI 3D curb dataset with considerably reduced processing delays compared to\nexisting methods, which underscores the effectiveness of our approach in curb\ndetection tasks.\n","authors":["Fulong Ma","Peng Hou","Yuxuan Liu","Yang Liu","Ming Liu","Jun Ma"],"pdf_url":"https://arxiv.org/pdf/2409.20171v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09555v3","updated":"2025-03-03T13:05:35Z","published":"2025-01-16T14:18:06Z","title":"Text-driven Adaptation of Foundation Models for Few-shot Surgical\n  Workflow Analysis","summary":"  Purpose: Surgical workflow analysis is crucial for improving surgical\nefficiency and safety. However, previous studies rely heavily on large-scale\nannotated datasets, posing challenges in cost, scalability, and reliance on\nexpert annotations. To address this, we propose Surg-FTDA (Few-shot Text-driven\nAdaptation), designed to handle various surgical workflow analysis tasks with\nminimal paired image-label data.\n  Methods: Our approach has two key components. First, Few-shot selection-based\nmodality alignment selects a small subset of images and aligns their embeddings\nwith text embeddings from the downstream task, bridging the modality gap.\nSecond, Text-driven adaptation leverages only text data to train a decoder,\neliminating the need for paired image-text data. This decoder is then applied\nto aligned image embeddings, enabling image-related tasks without explicit\nimage-text pairs.\n  Results: We evaluate our approach to generative tasks (image captioning) and\ndiscriminative tasks (triplet recognition and phase recognition). Results show\nthat Surg-FTDA outperforms baselines and generalizes well across downstream\ntasks.\n  Conclusion: We propose a text-driven adaptation approach that mitigates the\nmodality gap and handles multiple downstream tasks in surgical workflow\nanalysis, with minimal reliance on large annotated datasets. The code and\ndataset will be released in https://github.com/CAMMA-public/Surg-FTDA\n","authors":["Tingxuan Chen","Kun Yuan","Vinkle Srivastav","Nassir Navab","Nicolas Padoy"],"pdf_url":"https://arxiv.org/pdf/2501.09555v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.11142v2","updated":"2025-03-03T12:56:35Z","published":"2025-02-16T14:17:36Z","title":"NavRAG: Generating User Demand Instructions for Embodied Navigation\n  through Retrieval-Augmented LLM","summary":"  Vision-and-Language Navigation (VLN) is an essential skill for embodied\nagents, allowing them to navigate in 3D environments following natural language\ninstructions. High-performance navigation models require a large amount of\ntraining data, the high cost of manually annotating data has seriously hindered\nthis field. Therefore, some previous methods translate trajectory videos into\nstep-by-step instructions for expanding data, but such instructions do not\nmatch well with users' communication styles that briefly describe destinations\nor state specific needs. Moreover, local navigation trajectories overlook\nglobal context and high-level task planning. To address these issues, we\npropose NavRAG, a retrieval-augmented generation (RAG) framework that generates\nuser demand instructions for VLN. NavRAG leverages LLM to build a hierarchical\nscene description tree for 3D scene understanding from global layout to local\ndetails, then simulates various user roles with specific demands to retrieve\nfrom the scene tree, generating diverse instructions with LLM. We annotate over\n2 million navigation instructions across 861 scenes and evaluate the data\nquality and navigation performance of trained models.\n","authors":["Zihan Wang","Yaohui Zhu","Gim Hee Lee","Yachun Fan"],"pdf_url":"https://arxiv.org/pdf/2502.11142v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.14616v2","updated":"2025-03-03T12:37:18Z","published":"2025-02-20T14:57:01Z","title":"Monocular Depth Estimation and Segmentation for Transparent Object with\n  Iterative Semantic and Geometric Fusion","summary":"  Transparent object perception is indispensable for numerous robotic tasks.\nHowever, accurately segmenting and estimating the depth of transparent objects\nremain challenging due to complex optical properties. Existing methods\nprimarily delve into only one task using extra inputs or specialized sensors,\nneglecting the valuable interactions among tasks and the subsequent refinement\nprocess, leading to suboptimal and blurry predictions. To address these issues,\nwe propose a monocular framework, which is the first to excel in both\nsegmentation and depth estimation of transparent objects, with only a\nsingle-image input. Specifically, we devise a novel semantic and geometric\nfusion module, effectively integrating the multi-scale information between\ntasks. In addition, drawing inspiration from human perception of objects, we\nfurther incorporate an iterative strategy, which progressively refines initial\nfeatures for clearer results. Experiments on two challenging synthetic and\nreal-world datasets demonstrate that our model surpasses state-of-the-art\nmonocular, stereo, and multi-view methods by a large margin of about\n38.8%-46.2% with only a single RGB input. Codes and models are publicly\navailable at https://github.com/L-J-Yuan/MODEST.\n","authors":["Jiangyuan Liu","Hongxuan Ma","Yuxin Guo","Yuhao Zhao","Chi Zhang","Wei Sui","Wei Zou"],"pdf_url":"https://arxiv.org/pdf/2502.14616v2.pdf","comment":"Accepted by ICRA(2025). The code is accessible through:\n  https://github.com/L-J-Yuan/MODEST"},{"id":"http://arxiv.org/abs/2408.04591v2","updated":"2025-03-03T12:35:33Z","published":"2024-08-08T17:04:06Z","title":"HiLo: A Learning Framework for Generalized Category Discovery Robust to\n  Domain Shifts","summary":"  Generalized Category Discovery (GCD) is a challenging task in which, given a\npartially labelled dataset, models must categorize all unlabelled instances,\nregardless of whether they come from labelled categories or from new ones. In\nthis paper, we challenge a remaining assumption in this task: that all images\nshare the same domain. Specifically, we introduce a new task and method to\nhandle GCD when the unlabelled data also contains images from different domains\nto the labelled set. Our proposed `HiLo' networks extract High-level semantic\nand Low-level domain features, before minimizing the mutual information between\nthe representations. Our intuition is that the clusterings based on domain\ninformation and semantic information should be independent. We further extend\nour method with a specialized domain augmentation tailored for the GCD task, as\nwell as a curriculum learning approach. Finally, we construct a benchmark from\ncorrupted fine-grained datasets as well as a large-scale evaluation on\nDomainNet with real-world domain shifts, reimplementing a number of GCD\nbaselines in this setting. We demonstrate that HiLo outperforms SoTA category\ndiscovery models by a large margin on all evaluations.\n","authors":["Hongjun Wang","Sagar Vaze","Kai Han"],"pdf_url":"https://arxiv.org/pdf/2408.04591v2.pdf","comment":"v2: Accepted as a conference paper at ICLR 2025; Project page:\n  https://github.com/Visual-AI/hilo/"},{"id":"http://arxiv.org/abs/2410.09400v2","updated":"2025-03-03T12:33:49Z","published":"2024-10-12T07:04:32Z","title":"CtrLoRA: An Extensible and Efficient Framework for Controllable Image\n  Generation","summary":"  Recently, large-scale diffusion models have made impressive progress in\ntext-to-image (T2I) generation. To further equip these T2I models with\nfine-grained spatial control, approaches like ControlNet introduce an extra\nnetwork that learns to follow a condition image. However, for every single\ncondition type, ControlNet requires independent training on millions of data\npairs with hundreds of GPU hours, which is quite expensive and makes it\nchallenging for ordinary users to explore and develop new types of conditions.\nTo address this problem, we propose the CtrLoRA framework, which trains a Base\nControlNet to learn the common knowledge of image-to-image generation from\nmultiple base conditions, along with condition-specific LoRAs to capture\ndistinct characteristics of each condition. Utilizing our pretrained Base\nControlNet, users can easily adapt it to new conditions, requiring as few as\n1,000 data pairs and less than one hour of single-GPU training to obtain\nsatisfactory results in most scenarios. Moreover, our CtrLoRA reduces the\nlearnable parameters by 90% compared to ControlNet, significantly lowering the\nthreshold to distribute and deploy the model weights. Extensive experiments on\nvarious types of conditions demonstrate the efficiency and effectiveness of our\nmethod. Codes and model weights will be released at\nhttps://github.com/xyfJASON/ctrlora.\n","authors":["Yifeng Xu","Zhenliang He","Shiguang Shan","Xilin Chen"],"pdf_url":"https://arxiv.org/pdf/2410.09400v2.pdf","comment":"ICLR 2025. Code: https://github.com/xyfJASON/ctrlora"},{"id":"http://arxiv.org/abs/2403.19243v4","updated":"2025-03-03T12:32:47Z","published":"2024-03-28T08:58:20Z","title":"Efficient Learning With Sine-Activated Low-rank Matrices","summary":"  Low-rank decomposition has emerged as a vital tool for enhancing parameter\nefficiency in neural network architectures, gaining traction across diverse\napplications in machine learning. These techniques significantly lower the\nnumber of parameters, striking a balance between compactness and performance.\nHowever, a common challenge has been the compromise between parameter\nefficiency and the accuracy of the model, where reduced parameters often lead\nto diminished accuracy compared to their full-rank counterparts. In this work,\nwe propose a novel theoretical framework that integrates a sinusoidal function\nwithin the low-rank decomposition process. This approach not only preserves the\nbenefits of the parameter efficiency characteristic of low-rank methods but\nalso increases the decomposition's rank, thereby enhancing model performance.\nOur method proves to be a plug in enhancement for existing low-rank models, as\nevidenced by its successful application in Vision Transformers (ViT), Large\nLanguage Models (LLMs), Neural Radiance Fields (NeRF) and 3D shape modelling.\n","authors":["Yiping Ji","Hemanth Saratchandran","Cameron Gordon","Zeyu Zhang","Simon Lucey"],"pdf_url":"https://arxiv.org/pdf/2403.19243v4.pdf","comment":"The first two authors contributed equally. Paper accepted at ICLR\n  2025"},{"id":"http://arxiv.org/abs/2410.08190v2","updated":"2025-03-03T12:18:29Z","published":"2024-10-10T17:57:29Z","title":"Poison-splat: Computation Cost Attack on 3D Gaussian Splatting","summary":"  3D Gaussian splatting (3DGS), known for its groundbreaking performance and\nefficiency, has become a dominant 3D representation and brought progress to\nmany 3D vision tasks. However, in this work, we reveal a significant security\nvulnerability that has been largely overlooked in 3DGS: the computation cost of\ntraining 3DGS could be maliciously tampered by poisoning the input data. By\ndeveloping an attack named Poison-splat, we reveal a novel attack surface where\nthe adversary can poison the input images to drastically increase the\ncomputation memory and time needed for 3DGS training, pushing the algorithm\ntowards its worst computation complexity. In extreme cases, the attack can even\nconsume all allocable memory, leading to a Denial-of-Service (DoS) that\ndisrupts servers, resulting in practical damages to real-world 3DGS service\nvendors. Such a computation cost attack is achieved by addressing a bi-level\noptimization problem through three tailored strategies: attack objective\napproximation, proxy model rendering, and optional constrained optimization.\nThese strategies not only ensure the effectiveness of our attack but also make\nit difficult to defend with simple defensive measures. We hope the revelation\nof this novel attack surface can spark attention to this crucial yet overlooked\nvulnerability of 3DGS systems. Our code is available at\nhttps://github.com/jiahaolu97/poison-splat .\n","authors":["Jiahao Lu","Yifan Zhang","Qiuhong Shen","Xinchao Wang","Shuicheng Yan"],"pdf_url":"https://arxiv.org/pdf/2410.08190v2.pdf","comment":"Accepted by ICLR 2025 as a spotlight paper"},{"id":"http://arxiv.org/abs/2502.12138v3","updated":"2025-03-03T12:09:29Z","published":"2025-02-17T18:54:05Z","title":"FLARE: Feed-forward Geometry, Appearance and Camera Estimation from\n  Uncalibrated Sparse Views","summary":"  We present FLARE, a feed-forward model designed to infer high-quality camera\nposes and 3D geometry from uncalibrated sparse-view images (i.e., as few as 2-8\ninputs), which is a challenging yet practical setting in real-world\napplications. Our solution features a cascaded learning paradigm with camera\npose serving as the critical bridge, recognizing its essential role in mapping\n3D structures onto 2D image planes. Concretely, FLARE starts with camera pose\nestimation, whose results condition the subsequent learning of geometric\nstructure and appearance, optimized through the objectives of geometry\nreconstruction and novel-view synthesis. Utilizing large-scale public datasets\nfor training, our method delivers state-of-the-art performance in the tasks of\npose estimation, geometry reconstruction, and novel view synthesis, while\nmaintaining the inference efficiency (i.e., less than 0.5 seconds). The project\npage and code can be found at: https://zhanghe3z.github.io/FLARE/\n","authors":["Shangzhan Zhang","Jianyuan Wang","Yinghao Xu","Nan Xue","Christian Rupprecht","Xiaowei Zhou","Yujun Shen","Gordon Wetzstein"],"pdf_url":"https://arxiv.org/pdf/2502.12138v3.pdf","comment":"CVPR 2025. Website: https://zhanghe3z.github.io/FLARE/"},{"id":"http://arxiv.org/abs/2403.08632v2","updated":"2025-03-03T12:01:27Z","published":"2024-03-13T15:46:37Z","title":"A Decade's Battle on Dataset Bias: Are We There Yet?","summary":"  We revisit the \"dataset classification\" experiment suggested by Torralba &\nEfros (2011) a decade ago, in the new era with large-scale, diverse, and\nhopefully less biased datasets as well as more capable neural network\narchitectures. Surprisingly, we observe that modern neural networks can achieve\nexcellent accuracy in classifying which dataset an image is from: e.g., we\nreport 84.7% accuracy on held-out validation data for the three-way\nclassification problem consisting of the YFCC, CC, and DataComp datasets. Our\nfurther experiments show that such a dataset classifier could learn semantic\nfeatures that are generalizable and transferable, which cannot be explained by\nmemorization. We hope our discovery will inspire the community to rethink\nissues involving dataset bias.\n","authors":["Zhuang Liu","Kaiming He"],"pdf_url":"https://arxiv.org/pdf/2403.08632v2.pdf","comment":"Published in ICLR 2025 (Oral Presentation)"},{"id":"http://arxiv.org/abs/2502.17941v2","updated":"2025-03-03T12:00:57Z","published":"2025-02-25T08:03:04Z","title":"Optimal Brain Apoptosis","summary":"  The increasing complexity and parameter count of Convolutional Neural\nNetworks (CNNs) and Transformers pose challenges in terms of computational\nefficiency and resource demands. Pruning has been identified as an effective\nstrategy to address these challenges by removing redundant elements such as\nneurons, channels, or connections, thereby enhancing computational efficiency\nwithout heavily compromising performance. This paper builds on the foundational\nwork of Optimal Brain Damage (OBD) by advancing the methodology of parameter\nimportance estimation using the Hessian matrix. Unlike previous approaches that\nrely on approximations, we introduce Optimal Brain Apoptosis (OBA), a novel\npruning method that calculates the Hessian-vector product value directly for\neach parameter. By decomposing the Hessian matrix across network layers and\nidentifying conditions under which inter-layer Hessian submatrices are\nnon-zero, we propose a highly efficient technique for computing the\nsecond-order Taylor expansion of parameters. This approach allows for a more\nprecise pruning process, particularly in the context of CNNs and Transformers,\nas validated in our experiments including VGG19, ResNet32, ResNet50, and\nViT-B/16 on CIFAR10, CIFAR100 and Imagenet datasets. Our code is available at\nhttps://github.com/NEU-REAL/OBA.\n","authors":["Mingyuan Sun","Zheng Fang","Jiaxu Wang","Junjie Jiang","Delei Kong","Chenming Hu","Yuetong Fang","Renjing Xu"],"pdf_url":"https://arxiv.org/pdf/2502.17941v2.pdf","comment":"Accepted to ICLR 2025"},{"id":"http://arxiv.org/abs/2407.15589v5","updated":"2025-03-03T11:48:03Z","published":"2024-07-22T12:26:08Z","title":"Exploring the Effectiveness of Object-Centric Representations in Visual\n  Question Answering: Comparative Insights with Foundation Models","summary":"  Object-centric (OC) representations, which model visual scenes as\ncompositions of discrete objects, have the potential to be used in various\ndownstream tasks to achieve systematic compositional generalization and\nfacilitate reasoning. However, these claims have yet to be thoroughly validated\nempirically. Recently, foundation models have demonstrated unparalleled\ncapabilities across diverse domains, from language to computer vision,\npositioning them as a potential cornerstone of future research for a wide range\nof computational tasks. In this paper, we conduct an extensive empirical study\non representation learning for downstream Visual Question Answering (VQA),\nwhich requires an accurate compositional understanding of the scene. We\nthoroughly investigate the benefits and trade-offs of OC models and alternative\napproaches including large pre-trained foundation models on both synthetic and\nreal-world data, ultimately identifying a promising path to leverage the\nstrengths of both paradigms. The extensiveness of our study, encompassing over\n600 downstream VQA models and 15 different types of upstream representations,\nalso provides several additional insights that we believe will be of interest\nto the community at large.\n","authors":["Amir Mohammad Karimi Mamaghan","Samuele Papa","Karl Henrik Johansson","Stefan Bauer","Andrea Dittadi"],"pdf_url":"https://arxiv.org/pdf/2407.15589v5.pdf","comment":"Published at ICLR 2025"},{"id":"http://arxiv.org/abs/2502.21291v2","updated":"2025-03-03T11:33:31Z","published":"2025-02-28T18:21:08Z","title":"MIGE: A Unified Framework for Multimodal Instruction-Based Image\n  Generation and Editing","summary":"  Despite significant progress in diffusion-based image generation,\nsubject-driven generation and instruction-based editing remain challenging.\nExisting methods typically treat them separately, struggling with limited\nhigh-quality data and poor generalization. However, both tasks require\ncapturing complex visual variations while maintaining consistency between\ninputs and outputs. Therefore, we propose MIGE, a unified framework that\nstandardizes task representations using multimodal instructions. It treats\nsubject-driven generation as creation on a blank canvas and instruction-based\nediting as modification of an existing image, establishing a shared\ninput-output formulation. MIGE introduces a novel multimodal encoder that maps\nfree-form multimodal instructions into a unified vision-language space,\nintegrating visual and semantic features through a feature fusion mechanism.\nThis unification enables joint training of both tasks, providing two key\nadvantages: (1) Cross-Task Enhancement: By leveraging shared visual and\nsemantic representations, joint training improves instruction adherence and\nvisual consistency in both subject-driven generation and instruction-based\nediting. (2) Generalization: Learning in a unified format facilitates\ncross-task knowledge transfer, enabling MIGE to generalize to novel\ncompositional tasks, including instruction-based subject-driven editing.\nExperiments show that MIGE excels in both subject-driven generation and\ninstruction-based editing while setting a state-of-the-art in the new task of\ninstruction-based subject-driven editing. Code and model have been publicly\navailable at https://github.com/Eureka-Maggie/MIGE.\n","authors":["Xueyun Tian","Wei Li","Bingbing Xu","Yige Yuan","Yuanzhuo Wang","Huawei Shen"],"pdf_url":"https://arxiv.org/pdf/2502.21291v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18936v4","updated":"2025-03-03T11:00:24Z","published":"2025-01-31T07:41:06Z","title":"Adaptive Prompt: Unlocking the Power of Visual Prompt Tuning","summary":"  Visual Prompt Tuning (VPT) has recently emerged as a powerful method for\nadapting pre-trained vision models to downstream tasks. By introducing\nlearnable prompt tokens as task-specific instructions, VPT effectively guides\npre-trained transformer models with minimal overhead. Despite its empirical\nsuccess, a comprehensive theoretical understanding of VPT remains an active\narea of research. Building on recent insights into the connection between\nmixture of experts and prompt-based approaches, we identify a key limitation in\nVPT: the restricted functional expressiveness in prompt formulation. To address\nthis limitation, we propose Visual Adaptive Prompt Tuning (VAPT), a new\ngeneration of prompts that redefines prompts as adaptive functions of the\ninput. Our theoretical analysis shows that this simple yet intuitive approach\nachieves optimal sample efficiency. Empirical results on VTAB-1K and FGVC\nfurther demonstrate VAPT's effectiveness, with performance gains of 7.34% and\n1.04% over fully fine-tuning baselines, respectively. Notably, VAPT also\nsurpasses VPT by a substantial margin while using fewer parameters. These\nresults highlight both the effectiveness and efficiency of our method and pave\nthe way for future research to explore the potential of adaptive prompts.\n","authors":["Minh Le","Anh Nguyen","Huy Nguyen","Chau Nguyen","Nhat Ho"],"pdf_url":"https://arxiv.org/pdf/2501.18936v4.pdf","comment":"57 pages, 10 figures, 18 tables"},{"id":"http://arxiv.org/abs/2410.02423v2","updated":"2025-03-03T10:44:06Z","published":"2024-10-03T12:13:56Z","title":"PnP-Flow: Plug-and-Play Image Restoration with Flow Matching","summary":"  In this paper, we introduce Plug-and-Play (PnP) Flow Matching, an algorithm\nfor solving imaging inverse problems. PnP methods leverage the strength of\npre-trained denoisers, often deep neural networks, by integrating them in\noptimization schemes. While they achieve state-of-the-art performance on\nvarious inverse problems in imaging, PnP approaches face inherent limitations\non more generative tasks like inpainting. On the other hand, generative models\nsuch as Flow Matching pushed the boundary in image sampling yet lack a clear\nmethod for efficient use in image restoration. We propose to combine the PnP\nframework with Flow Matching (FM) by defining a time-dependent denoiser using a\npre-trained FM model. Our algorithm alternates between gradient descent steps\non the data-fidelity term, reprojections onto the learned FM path, and\ndenoising. Notably, our method is computationally efficient and\nmemory-friendly, as it avoids backpropagation through ODEs and trace\ncomputations. We evaluate its performance on denoising, super-resolution,\ndeblurring, and inpainting tasks, demonstrating superior results compared to\nexisting PnP algorithms and Flow Matching based state-of-the-art methods.\n","authors":["Ségolène Martin","Anne Gagneux","Paul Hagemann","Gabriele Steidl"],"pdf_url":"https://arxiv.org/pdf/2410.02423v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.11542v2","updated":"2025-03-03T10:39:41Z","published":"2024-12-16T08:22:23Z","title":"Meta Curvature-Aware Minimization for Domain Generalization","summary":"  Domain generalization (DG) aims to enhance the ability of models trained on\nsource domains to generalize effectively to unseen domains. Recently,\nSharpness-Aware Minimization (SAM) has shown promise in this area by reducing\nthe sharpness of the loss landscape to obtain more generalized models. However,\nSAM and its variants sometimes fail to guide the model toward a flat minimum,\nand their training processes exhibit limitations, hindering further\nimprovements in model generalization. In this paper, we first propose an\nimproved model training process aimed at encouraging the model to converge to a\nflat minima. To achieve this, we design a curvature metric that has a minimal\neffect when the model is far from convergence but becomes increasingly\ninfluential in indicating the curvature of the minima as the model approaches a\nlocal minimum. Then we derive a novel algorithm from this metric, called Meta\nCurvature-Aware Minimization (MeCAM), to minimize the curvature around the\nlocal minima. Specifically, the optimization objective of MeCAM simultaneously\nminimizes the regular training loss, the surrogate gap of SAM, and the\nsurrogate gap of meta-learning. We provide theoretical analysis on MeCAM's\ngeneralization error and convergence rate, and demonstrate its superiority over\nexisting DG methods through extensive experiments on five benchmark DG\ndatasets, including PACS, VLCS, OfficeHome, TerraIncognita, and DomainNet. Code\nwill be available on GitHub.\n","authors":["Ziyang Chen","Yiwen Ye","Feilong Tang","Yongsheng Pan","Yong Xia"],"pdf_url":"https://arxiv.org/pdf/2412.11542v2.pdf","comment":"22 pages, 5 figures, 17 tables"},{"id":"http://arxiv.org/abs/2502.08005v2","updated":"2025-03-03T10:38:34Z","published":"2025-02-11T23:02:14Z","title":"Towards Training One-Step Diffusion Models Without Distillation","summary":"  Recent advances in one-step generative models typically follow a two-stage\nprocess: first training a teacher diffusion model and then distilling it into a\none-step student model. This distillation process traditionally relies on both\nthe teacher model's score function to compute the distillation loss and its\nweights for student initialization. In this paper, we explore whether one-step\ngenerative models can be trained directly without this distillation process.\nFirst, we show that the teacher's score function is not essential and propose a\nfamily of distillation methods that achieve competitive results without relying\non score estimation. Next, we demonstrate that initialization from teacher\nweights is indispensable in successful training. Surprisingly, we find that\nthis benefit is not due to improved ``input-output\" mapping but rather the\nlearned feature representations, which dominate distillation quality. Our\nfindings provide a better understanding of the role of initialization in\none-step model training and its impact on distillation quality.\n","authors":["Mingtian Zhang","Jiajun He","Wenlin Chen","Zijing Ou","José Miguel Hernández-Lobato","Bernhard Schölkopf","David Barber"],"pdf_url":"https://arxiv.org/pdf/2502.08005v2.pdf","comment":"13 pages, Technical Report"},{"id":"http://arxiv.org/abs/2502.21264v2","updated":"2025-03-03T10:35:23Z","published":"2025-02-28T17:40:45Z","title":"Foundation Models -- A Panacea for Artificial Intelligence in Pathology?","summary":"  The role of artificial intelligence (AI) in pathology has evolved from aiding\ndiagnostics to uncovering predictive morphological patterns in whole slide\nimages (WSIs). Recently, foundation models (FMs) leveraging self-supervised\npre-training have been widely advocated as a universal solution for diverse\ndownstream tasks. However, open questions remain about their clinical\napplicability and generalization advantages over end-to-end learning using\ntask-specific (TS) models. Here, we focused on AI with clinical-grade\nperformance for prostate cancer diagnosis and Gleason grading. We present the\nlargest validation of AI for this task, using over 100,000 core needle biopsies\nfrom 7,342 patients across 15 sites in 11 countries. We compared two FMs with a\nfully end-to-end TS model in a multiple instance learning framework. Our\nfindings challenge assumptions that FMs universally outperform TS models. While\nFMs demonstrated utility in data-scarce scenarios, their performance converged\nwith - and was in some cases surpassed by - TS models when sufficient labeled\ntraining data were available. Notably, extensive task-specific training\nmarkedly reduced clinically significant misgrading, misdiagnosis of challenging\nmorphologies, and variability across different WSI scanners. Additionally, FMs\nused up to 35 times more energy than the TS model, raising concerns about their\nsustainability. Our results underscore that while FMs offer clear advantages\nfor rapid prototyping and research, their role as a universal solution for\nclinically applicable medical AI remains uncertain. For high-stakes clinical\napplications, rigorous validation and consideration of task-specific training\nremain critically important. We advocate for integrating the strengths of FMs\nand end-to-end learning to achieve robust and resource-efficient AI pathology\nsolutions fit for clinical use.\n","authors":["Nita Mulliqi","Anders Blilie","Xiaoyi Ji","Kelvin Szolnoky","Henrik Olsson","Sol Erika Boman","Matteo Titus","Geraldine Martinez Gonzalez","Julia Anna Mielcarz","Masi Valkonen","Einar Gudlaugsson","Svein R. Kjosavik","José Asenjo","Marcello Gambacorta","Paolo Libretti","Marcin Braun","Radzislaw Kordek","Roman Łowicki","Kristina Hotakainen","Päivi Väre","Bodil Ginnerup Pedersen","Karina Dalsgaard Sørensen","Benedicte Parm Ulhøi","Pekka Ruusuvuori","Brett Delahunt","Hemamali Samaratunga","Toyonori Tsuzuki","Emilius A. M. Janssen","Lars Egevad","Martin Eklund","Kimmo Kartasalo"],"pdf_url":"https://arxiv.org/pdf/2502.21264v2.pdf","comment":"50 pages, 15 figures and an appendix (study protocol) which is\n  previously published, see https://doi.org/10.1101/2024.07.04.24309948;\n  updated authors list format"},{"id":"http://arxiv.org/abs/2502.21201v2","updated":"2025-03-03T10:32:20Z","published":"2025-02-28T16:18:57Z","title":"The PanAf-FGBG Dataset: Understanding the Impact of Backgrounds in\n  Wildlife Behaviour Recognition","summary":"  Computer vision analysis of camera trap video footage is essential for\nwildlife conservation, as captured behaviours offer some of the earliest\nindicators of changes in population health. Recently, several high-impact\nanimal behaviour datasets and methods have been introduced to encourage their\nuse; however, the role of behaviour-correlated background information and its\nsignificant effect on out-of-distribution generalisation remain unexplored. In\nresponse, we present the PanAf-FGBG dataset, featuring 20 hours of wild\nchimpanzee behaviours, recorded at over 350 individual camera locations.\nUniquely, it pairs every video with a chimpanzee (referred to as a foreground\nvideo) with a corresponding background video (with no chimpanzee) from the same\ncamera location. We present two views of the dataset: one with overlapping\ncamera locations and one with disjoint locations. This setup enables, for the\nfirst time, direct evaluation of in-distribution and out-of-distribution\nconditions, and for the impact of backgrounds on behaviour recognition models\nto be quantified. All clips come with rich behavioural annotations and metadata\nincluding unique camera IDs and detailed textual scene descriptions.\nAdditionally, we establish several baselines and present a highly effective\nlatent-space normalisation technique that boosts out-of-distribution\nperformance by +5.42% mAP for convolutional and +3.75% mAP for\ntransformer-based models. Finally, we provide an in-depth analysis on the role\nof backgrounds in out-of-distribution behaviour recognition, including the so\nfar unexplored impact of background durations (i.e., the count of background\nframes within foreground videos).\n","authors":["Otto Brookes","Maksim Kukushkin","Majid Mirmehdi","Colleen Stephens","Paula Dieguez","Thurston C. Hicks","Sorrel Jones","Kevin Lee","Maureen S. McCarthy","Amelia Meier","Emmanuelle Normand","Erin G. Wessling","Roman M. Wittig","Kevin Langergraber","Klaus Zuberbühler","Lukas Boesch","Thomas Schmid","Mimi Arandjelovic","Hjalmar Kühl","Tilo Burghardt"],"pdf_url":"https://arxiv.org/pdf/2502.21201v2.pdf","comment":"Accepted at the IEEE / CVF Computer Vision and Pattern Recognition\n  Conference 2025"},{"id":"http://arxiv.org/abs/2410.05643v3","updated":"2025-03-03T10:28:30Z","published":"2024-10-08T02:46:30Z","title":"TRACE: Temporal Grounding Video LLM via Causal Event Modeling","summary":"  Video Temporal Grounding (VTG) is a crucial capability for video\nunderstanding models and plays a vital role in downstream tasks such as video\nbrowsing and editing. To effectively handle various tasks simultaneously and\nenable zero-shot prediction, there is a growing trend in employing video LLMs\nfor VTG tasks. However, current video LLM-based methods rely exclusively on\nnatural language generation, lacking the ability to model the clear structure\ninherent in videos, which restricts their effectiveness in tackling VTG tasks.\nTo address this issue, this paper first formally introduces causal event\nmodeling framework, which represents video LLM outputs as sequences of events,\nand predict the current event using previous events, video inputs, and textural\ninstructions. Each event consists of three components: timestamps, salient\nscores, and textual captions. We then propose a novel task-interleaved video\nLLM called TRACE to effectively implement the causal event modeling framework\nin practice. The TRACE process visual frames, timestamps, salient scores, and\ntext as distinct tasks, employing various encoders and decoding heads for each.\nTask tokens are arranged in an interleaved sequence according to the causal\nevent modeling framework's formulation. Extensive experiments on various VTG\ntasks and datasets demonstrate the superior performance of TRACE compared to\nstate-of-the-art video LLMs. Our model and code are available at\nhttps://github.com/gyxxyg/TRACE.\n","authors":["Yongxin Guo","Jingyu Liu","Mingda Li","Qingbin Liu","Xi Chen","Xiaoying Tang"],"pdf_url":"https://arxiv.org/pdf/2410.05643v3.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2411.06916v2","updated":"2025-03-03T10:22:24Z","published":"2024-11-11T12:19:28Z","title":"Slowing Down Forgetting in Continual Learning","summary":"  A common challenge in continual learning (CL) is catastrophic forgetting,\nwhere the performance on old tasks drops after new, additional tasks are\nlearned. In this paper, we propose a novel framework called ReCL to slow down\nforgetting in CL. Our framework exploits an implicit bias of gradient-based\nneural networks due to which these converge to margin maximization points. Such\nconvergence points allow us to reconstruct old data from previous tasks, which\nwe then combine with the current training data. Our framework is flexible and\ncan be applied on top of existing, state-of-the-art CL methods. We further\ndemonstrate the performance gain from our framework across a large series of\nexperiments, including two challenging CL scenarios (class incremental and\ndomain incremental learning), different datasets (MNIST, CIFAR10,\nTinyImagenet), and different network architectures. Across all experiments, we\nfind large performance gains through ReCL. To the best of our knowledge, our\nframework is the first to address catastrophic forgetting by leveraging models\nin CL as their own memory buffers.\n","authors":["Pascal Janetzky","Tobias Schlagenhauf","Stefan Feuerriegel"],"pdf_url":"https://arxiv.org/pdf/2411.06916v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.14651v3","updated":"2025-03-03T09:31:01Z","published":"2024-07-19T20:05:10Z","title":"Improving Representation of High-frequency Components for Medical Visual\n  Foundation Models","summary":"  Foundation models have recently attracted significant attention for their\nimpressive generalizability across diverse downstream tasks. However, these\nmodels are demonstrated to exhibit great limitations in representing\nhigh-frequency components and fine-grained details. In many medical imaging\ntasks, the precise representation of such information is crucial due to the\ninherently intricate anatomical structures, sub-visual features, and complex\nboundaries involved. Consequently, the limited representation of prevalent\nfoundation models can result in significant performance degradation or even\nfailure in these tasks. To address these challenges, we propose a novel\npretraining strategy, named Frequency-advanced Representation Autoencoder\n(Frepa). Through high-frequency masking and low-frequency perturbation combined\nwith adversarial learning, Frepa encourages the encoder to effectively\nrepresent and preserve high-frequency components in the image embeddings.\nAdditionally, we introduce an innovative histogram-equalized image masking\nstrategy, extending the Masked Autoencoder approach beyond ViT to other\narchitectures such as Swin Transformer and convolutional networks. We develop\nFrepa across nine medical modalities and validate it on 32 downstream tasks for\nboth 2D images and 3D volume data. Without fine-tuning, Frepa can outperform\nother self-supervised pretraining methods and, in some cases, even surpasses\ntask-specific trained models. This improvement is particularly significant for\ntasks involving fine-grained details, such as achieving up to a +15% increase\nin DSC for retina vessel segmentation and a +7% increase in IoU for lung nodule\ndetection. Further experiments quantitatively reveal that Frepa enables\nsuperior high-frequency representations and preservation in the embeddings,\nunderscoring its potential for developing more generalized and universal\nmedical image foundation models.\n","authors":["Yuetan Chu","Yilan Zhang","Zhongyi Han","Changchun Yang","Longxi Zhou","Gongning Luo","Chao Huang","Xin Gao"],"pdf_url":"https://arxiv.org/pdf/2407.14651v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.23751v2","updated":"2025-03-03T09:30:42Z","published":"2024-10-31T09:11:56Z","title":"EXACFS -- A CIL Method to mitigate Catastrophic Forgetting","summary":"  Deep neural networks (DNNS) excel at learning from static datasets but\nstruggle with continual learning, where data arrives sequentially. Catastrophic\nforgetting, the phenomenon of forgetting previously learned knowledge, is a\nprimary challenge. This paper introduces EXponentially Averaged Class-wise\nFeature Significance (EXACFS) to mitigate this issue in the class incremental\nlearning (CIL) setting. By estimating the significance of model features for\neach learned class using loss gradients, gradually aging the significance\nthrough the incremental tasks and preserving the significant features through a\ndistillation loss, EXACFS effectively balances remembering old knowledge\n(stability) and learning new knowledge (plasticity). Extensive experiments on\nCIFAR-100 and ImageNet-100 demonstrate EXACFS's superior performance in\npreserving stability while acquiring plasticity.\n","authors":["S Balasubramanian","M Sai Subramaniam","Sai Sriram Talasu","Yedu Krishna P","Manepalli Pranav Phanindra Sai","Ravi Mukkamala","Darshan Gera"],"pdf_url":"https://arxiv.org/pdf/2410.23751v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.08537v3","updated":"2025-03-03T09:26:26Z","published":"2023-10-12T17:26:16Z","title":"Saliency-Bench: A Comprehensive Benchmark for Evaluating Visual\n  Explanations","summary":"  Explainable AI (XAI) has gained significant attention for providing insights\ninto the decision-making processes of deep learning models, particularly for\nimage classification tasks through visual explanations visualized by saliency\nmaps. Despite their success, challenges remain due to the lack of annotated\ndatasets and standardized evaluation pipelines. In this paper, we introduce\nSaliency-Bench, a novel benchmark suite designed to evaluate visual\nexplanations generated by saliency methods across multiple datasets. We\ncurated, constructed, and annotated eight datasets, each covering diverse tasks\nsuch as scene classification, cancer diagnosis, object classification, and\naction classification, with corresponding ground-truth explanations. The\nbenchmark includes a standardized and unified evaluation pipeline for assessing\nfaithfulness and alignment of the visual explanation, providing a holistic\nvisual explanation performance assessment. We benchmark these eight datasets\nwith widely used saliency methods on different image classifier architectures\nto evaluate explanation quality. Additionally, we developed an easy-to-use API\nfor automating the evaluation pipeline, from data accessing, and data loading,\nto result evaluation. The benchmark is available via our website:\nhttps://xaidataset.github.io.\n","authors":["Yifei Zhang","James Song","Siyi Gu","Tianxu Jiang","Bo Pan","Guangji Bai","Liang Zhao"],"pdf_url":"https://arxiv.org/pdf/2310.08537v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.16751v3","updated":"2025-03-03T09:07:59Z","published":"2025-01-28T07:08:20Z","title":"HiBug2: Efficient and Interpretable Error Slice Discovery for\n  Comprehensive Model Debugging","summary":"  Despite the significant success of deep learning models in computer vision,\nthey often exhibit systematic failures on specific data subsets, known as error\nslices. Identifying and mitigating these error slices is crucial to enhancing\nmodel robustness and reliability in real-world scenarios. In this paper, we\nintroduce HiBug2, an automated framework for error slice discovery and model\nrepair. HiBug2 first generates task-specific visual attributes to highlight\ninstances prone to errors through an interpretable and structured process. It\nthen employs an efficient slice enumeration algorithm to systematically\nidentify error slices, overcoming the combinatorial challenges that arise\nduring slice exploration. Additionally, HiBug2 extends its capabilities by\npredicting error slices beyond the validation set, addressing a key limitation\nof prior approaches. Extensive experiments across multiple domains, including\nimage classification, pose estimation, and object detection - show that HiBug2\nnot only improves the coherence and precision of identified error slices but\nalso significantly enhances the model repair capabilities.\n","authors":["Muxi Chen","Chenchen Zhao","Qiang Xu"],"pdf_url":"https://arxiv.org/pdf/2501.16751v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.12275v2","updated":"2025-03-03T09:05:52Z","published":"2024-06-18T05:05:12Z","title":"VoCo-LLaMA: Towards Vision Compression with Large Language Models","summary":"  Vision-Language Models (VLMs) have achieved remarkable success in various\nmulti-modal tasks, but they are often bottlenecked by the limited context\nwindow and high computational cost of processing high-resolution image inputs\nand videos. Vision compression can alleviate this problem by reducing the\nvision token count. Previous approaches compress vision tokens with external\nmodules and force LLMs to understand the compressed ones, leading to visual\ninformation loss. However, the LLMs' understanding paradigm of vision tokens is\nnot fully utilised in the compression learning process. We propose VoCo-LLaMA,\nthe first approach to compress vision tokens using LLMs. By introducing Vision\nCompression tokens during the vision instruction tuning phase and leveraging\nattention distillation, our method distill how LLMs comprehend vision tokens\ninto their processing of VoCo tokens. VoCo-LLaMA facilitates effective vision\ncompression and improves the computational efficiency during the inference\nstage. Specifically, our method achieves minimal performance loss with a\ncompression ratio of 576$\\times$, resulting in up to 94.8$\\%$ fewer FLOPs and\n69.6$\\%$ acceleration in inference time. Furthermore, through continuous\ntraining using time-series compressed token sequences of video frames,\nVoCo-LLaMA demonstrates the ability to understand temporal correlations,\noutperforming previous methods on popular video question-answering benchmarks.\nOur approach presents a promising way to unlock the full potential of VLMs'\ncontextual window, enabling more scalable multi-modal applications. The project\npage, along with the associated code, can be accessed via\nhttps://yxxxb.github.io/VoCo-LLaMA-page/.\n","authors":["Xubing Ye","Yukang Gan","Xiaoke Huang","Yixiao Ge","Yansong Tang"],"pdf_url":"https://arxiv.org/pdf/2406.12275v2.pdf","comment":"11 pages, 4 figures"},{"id":"http://arxiv.org/abs/2502.21130v2","updated":"2025-03-03T08:39:54Z","published":"2025-02-28T15:10:07Z","title":"Fast and Accurate Gigapixel Pathological Image Classification with\n  Hierarchical Distillation Multi-Instance Learning","summary":"  Although multi-instance learning (MIL) has succeeded in pathological image\nclassification, it faces the challenge of high inference costs due to\nprocessing numerous patches from gigapixel whole slide images (WSIs). To\naddress this, we propose HDMIL, a hierarchical distillation multi-instance\nlearning framework that achieves fast and accurate classification by\neliminating irrelevant patches. HDMIL consists of two key components: the\ndynamic multi-instance network (DMIN) and the lightweight instance\npre-screening network (LIPN). DMIN operates on high-resolution WSIs, while LIPN\noperates on the corresponding low-resolution counterparts. During training,\nDMIN are trained for WSI classification while generating attention-score-based\nmasks that indicate irrelevant patches. These masks then guide the training of\nLIPN to predict the relevance of each low-resolution patch. During testing,\nLIPN first determines the useful regions within low-resolution WSIs, which\nindirectly enables us to eliminate irrelevant regions in high-resolution WSIs,\nthereby reducing inference time without causing performance degradation. In\naddition, we further design the first Chebyshev-polynomials-based\nKolmogorov-Arnold classifier in computational pathology, which enhances the\nperformance of HDMIL through learnable activation layers. Extensive experiments\non three public datasets demonstrate that HDMIL outperforms previous\nstate-of-the-art methods, e.g., achieving improvements of 3.13% in AUC while\nreducing inference time by 28.6% on the Camelyon16 dataset.\n","authors":["Jiuyang Dong","Junjun Jiang","Kui Jiang","Jiahan Li","Yongbing Zhang"],"pdf_url":"https://arxiv.org/pdf/2502.21130v2.pdf","comment":"11 pages, 4 figures, accepted by CVPR2025"},{"id":"http://arxiv.org/abs/2311.14922v3","updated":"2025-03-03T07:41:00Z","published":"2023-11-25T03:55:06Z","title":"GDTS: Goal-Guided Diffusion Model with Tree Sampling for Multi-Modal\n  Pedestrian Trajectory Prediction","summary":"  Accurate prediction of pedestrian trajectories is crucial for improving the\nsafety of autonomous driving. However, this task is generally nontrivial due to\nthe inherent stochasticity of human motion, which naturally requires the\npredictor to generate multi-modal prediction. Previous works leverage various\ngenerative methods, such as GAN and VAE, for pedestrian trajectory prediction.\nNevertheless, these methods may suffer from mode collapse and relatively\nlow-quality results. The denoising diffusion probabilistic model (DDPM) has\nrecently been applied to trajectory prediction due to its simple training\nprocess and powerful reconstruction ability. However, current diffusion-based\nmethods do not fully utilize input information and usually require many\ndenoising iterations that lead to a long inference time or an additional\nnetwork for initialization. To address these challenges and facilitate the use\nof diffusion models in multi-modal trajectory prediction, we propose GDTS, a\nnovel Goal-Guided Diffusion Model with Tree Sampling for multi-modal trajectory\nprediction. Considering the \"goal-driven\" characteristics of human motion, GDTS\nleverages goal estimation to guide the generation of the diffusion network. A\ntwo-stage tree sampling algorithm is presented, which leverages common features\nto reduce the inference time and improve accuracy for multi-modal prediction.\nExperimental results demonstrate that our proposed framework achieves\ncomparable state-of-the-art performance with real-time inference speed in\npublic datasets.\n","authors":["Ge Sun","Sheng Wang","Lei Zhu","Ming Liu","Jun Ma"],"pdf_url":"https://arxiv.org/pdf/2311.14922v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.01217v2","updated":"2025-03-03T07:38:09Z","published":"2024-05-02T11:58:06Z","title":"CromSS: Cross-modal pre-training with noisy labels for remote sensing\n  image segmentation","summary":"  We explore the potential of large-scale noisily labeled data to enhance\nfeature learning by pretraining semantic segmentation models within a\nmulti-modal framework for geospatial applications. We propose a novel\nCross-modal Sample Selection (CromSS) method, a weakly supervised pretraining\nstrategy designed to improve feature representations through cross-modal\nconsistency and noise mitigation techniques. Unlike conventional pretraining\napproaches, CromSS exploits massive amounts of noisy and easy-to-come-by labels\nfor improved feature learning beneficial to semantic segmentation tasks. We\ninvestigate middle and late fusion strategies to optimize the multi-modal\npretraining architecture design. We also introduce a cross-modal sample\nselection module to mitigate the adverse effects of label noise, which employs\na cross-modal entangling strategy to refine the estimated confidence masks\nwithin each modality to guide the sampling process. Additionally, we introduce\na spatial-temporal label smoothing technique to counteract overconfidence for\nenhanced robustness against noisy labels. To validate our approach, we\nassembled the multi-modal dataset, NoLDO-S12, which consists of a large-scale\nnoisy label subset from Google's Dynamic World (DW) dataset for pretraining and\ntwo downstream subsets with high-quality labels from Google DW and\nOpenStreetMap (OSM) for transfer learning. Experimental results on two\ndownstream tasks and the publicly available DFC2020 dataset demonstrate that\nwhen effectively utilized, the low-cost noisy labels can significantly enhance\nfeature learning for segmentation tasks. All data, code, and pretrained weights\nwill be made publicly available.\n","authors":["Chenying Liu","Conrad Albrecht","Yi Wang","Xiao Xiang Zhu"],"pdf_url":"https://arxiv.org/pdf/2405.01217v2.pdf","comment":"The 1st short version was accepted as an oral presentation by ICLR\n  2024 ML4RS workshop. The 2nd extended version is being under review"},{"id":"http://arxiv.org/abs/2501.15394v2","updated":"2025-03-03T07:30:55Z","published":"2025-01-26T04:24:07Z","title":"Doracamom: Joint 3D Detection and Occupancy Prediction with Multi-view\n  4D Radars and Cameras for Omnidirectional Perception","summary":"  3D object detection and occupancy prediction are critical tasks in autonomous\ndriving, attracting significant attention. Despite the potential of recent\nvision-based methods, they encounter challenges under adverse conditions. Thus,\nintegrating cameras with next-generation 4D imaging radar to achieve unified\nmulti-task perception is highly significant, though research in this domain\nremains limited. In this paper, we propose Doracamom, the first framework that\nfuses multi-view cameras and 4D radar for joint 3D object detection and\nsemantic occupancy prediction, enabling comprehensive environmental perception.\nSpecifically, we introduce a novel Coarse Voxel Queries Generator that\nintegrates geometric priors from 4D radar with semantic features from images to\ninitialize voxel queries, establishing a robust foundation for subsequent\nTransformer-based refinement. To leverage temporal information, we design a\nDual-Branch Temporal Encoder that processes multi-modal temporal features in\nparallel across BEV and voxel spaces, enabling comprehensive spatio-temporal\nrepresentation learning. Furthermore, we propose a Cross-Modal BEV-Voxel Fusion\nmodule that adaptively fuses complementary features through attention\nmechanisms while employing auxiliary tasks to enhance feature quality.\nExtensive experiments on the OmniHD-Scenes, View-of-Delft (VoD), and TJ4DRadSet\ndatasets demonstrate that Doracamom achieves state-of-the-art performance in\nboth tasks, establishing new benchmarks for multi-modal 3D perception. Code and\nmodels will be publicly available.\n","authors":["Lianqing Zheng","Jianan Liu","Runwei Guan","Long Yang","Shouyi Lu","Yuanzhe Li","Xiaokai Bai","Jie Bai","Zhixiong Ma","Hui-Liang Shen","Xichan Zhu"],"pdf_url":"https://arxiv.org/pdf/2501.15394v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.19289v3","updated":"2025-03-03T07:18:14Z","published":"2024-11-28T17:41:33Z","title":"ADUGS-VINS: Generalized Visual-Inertial Odometry for Robust Navigation\n  in Highly Dynamic and Complex Environments","summary":"  Visual-inertial odometry (VIO) is widely used in various fields, such as\nrobots, drones, and autonomous vehicles. However, real-world scenes often\nfeature dynamic objects, compromising the accuracy of VIO. The diversity and\npartial occlusion of these objects present a tough challenge for existing\ndynamic VIO methods. To tackle this challenge, we introduce ADUGS-VINS, which\nintegrates an enhanced SORT algorithm along with a promptable foundation model\ninto VIO, thereby improving pose estimation accuracy in environments with\ndiverse dynamic objects and frequent occlusions. We evaluated our proposed\nmethod using multiple public datasets representing various scenes, as well as\nin a real-world scenario involving diverse dynamic objects. The experimental\nresults demonstrate that our proposed method performs impressively in multiple\nscenarios, outperforming other state-of-the-art methods. This highlights its\nremarkable generalization and adaptability in diverse dynamic environments,\nshowcasing its potential to handle various dynamic objects in practical\napplications.\n","authors":["Rui Zhou","Jingbin Liu","Junbin Xie","Jianyu Zhang","Yingze Hu","Jiele Zhao"],"pdf_url":"https://arxiv.org/pdf/2411.19289v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.05757v2","updated":"2025-03-03T07:07:28Z","published":"2025-01-10T07:19:41Z","title":"Locality-aware Gaussian Compression for Fast and High-quality Rendering","summary":"  We present LocoGS, a locality-aware 3D Gaussian Splatting (3DGS) framework\nthat exploits the spatial coherence of 3D Gaussians for compact modeling of\nvolumetric scenes. To this end, we first analyze the local coherence of 3D\nGaussian attributes, and propose a novel locality-aware 3D Gaussian\nrepresentation that effectively encodes locally-coherent Gaussian attributes\nusing a neural field representation with a minimal storage requirement. On top\nof the novel representation, LocoGS is carefully designed with additional\ncomponents such as dense initialization, an adaptive spherical harmonics\nbandwidth scheme and different encoding schemes for different Gaussian\nattributes to maximize compression performance. Experimental results\ndemonstrate that our approach outperforms the rendering quality of existing\ncompact Gaussian representations for representative real-world 3D datasets\nwhile achieving from 54.6$\\times$ to 96.6$\\times$ compressed storage size and\nfrom 2.1$\\times$ to 2.4$\\times$ rendering speed than 3DGS. Even our approach\nalso demonstrates an averaged 2.4$\\times$ higher rendering speed than the\nstate-of-the-art compression method with comparable compression performance.\n","authors":["Seungjoo Shin","Jaesik Park","Sunghyun Cho"],"pdf_url":"https://arxiv.org/pdf/2501.05757v2.pdf","comment":"Accepted to ICLR 2025. Project page:\n  https://seungjooshin.github.io/LocoGS"},{"id":"http://arxiv.org/abs/2501.12296v2","updated":"2025-03-03T06:45:12Z","published":"2025-01-21T17:03:06Z","title":"RALAD: Bridging the Real-to-Sim Domain Gap in Autonomous Driving with\n  Retrieval-Augmented Learning","summary":"  In the pursuit of robust autonomous driving systems, models trained on\nreal-world datasets often struggle to adapt to new environments, particularly\nwhen confronted with corner cases such as extreme weather conditions.\nCollecting these corner cases in the real world is non-trivial, which\nnecessitates the use of simulators for validation. However,the high\ncomputational cost and the domain gap in data distribution have hindered the\nseamless transition between real and simulated driving scenarios. To tackle\nthis challenge, we propose Retrieval-Augmented Learning for Autonomous Driving\n(RALAD), a novel framework designed to bridge the real-to-sim gap at a low\ncost. RALAD features three primary designs, including (1) domain adaptation via\nan enhanced Optimal Transport (OT) method that accounts for both individual and\ngrouped image distances, (2) a simple and unified framework that can be applied\nto various models, and (3) efficient fine-tuning techniques that freeze the\ncomputationally expensive layers while maintaining robustness. Experimental\nresults demonstrate that RALAD compensates for the performance degradation in\nsimulated environments while maintaining accuracy in real-world scenarios\nacross three different models. Taking Cross View as an example, the mIOU and\nmAP metrics in real-world scenarios remain stable before and after RALAD\nfine-tuning, while in simulated environments,the mIOU and mAP metrics are\nimproved by 10.30% and 12.29%, respectively. Moreover, the re-training cost of\nour approach is reduced by approximately 88.1%. Our code is available at\nhttps://github.com/JiachengZuo/RALAD.git.\n","authors":["Jiacheng Zuo","Haibo Hu","Zikang Zhou","Yufei Cui","Ziquan Liu","Jianping Wang","Nan Guan","Jin Wang","Chun Jason Xue"],"pdf_url":"https://arxiv.org/pdf/2501.12296v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.19160v2","updated":"2025-03-03T06:34:25Z","published":"2024-12-26T10:40:15Z","title":"Cross-Spectral Vision Transformer for Biometric Authentication using\n  Forehead Subcutaneous Vein Pattern and Periocular Pattern","summary":"  Traditional biometric systems have encountered significant setbacks due to\nvarious unavoidable factors, for example, face recognition-based biometrics\nfails due to the wearing of face masks and fingerprints create hygiene\nconcerns. This paper proposes a novel lightweight cross-spectral vision\ntransformer (CS-ViT) for biometric authentication using forehead subcutaneous\nvein patterns and periocular patterns, offering a promising alternative to\ntraditional methods, capable of performing well even with the face masks and\nwithout any physical touch. The proposed framework comprises a cross-spectral\ndual-channel architecture designed to handle two distinct biometric traits and\nto capture inter-dependencies in terms of relative spectral patterns. Each\nchannel consists of a Phase-Only Correlation Cross-Spectral Attention (POC-CSA)\nthat captures their individual as well as correlated patterns. The computation\nof cross-spectral attention using POC extracts the phase correlation in the\nspatial features. Therefore, it is robust against the resolution/intensity\nvariations and illumination of the input images, assuming both biometric traits\nare from the same person. The lightweight model is suitable for edge device\ndeployment. The performance of the proposed algorithm was rigorously evaluated\nusing the Forehead Subcutaneous Vein Pattern and Periocular Biometric Pattern\n(FSVP-PBP) database. The results demonstrated the superiority of the algorithm\nover state-of-the-art methods, achieving a remarkable classification accuracy\nof 98.8% with the combined vein and periocular patterns.\n","authors":["Arun K. Sharma","Shubhobrata Bhattacharya","Motahar Reza","Bishakh Bhattacharya"],"pdf_url":"https://arxiv.org/pdf/2412.19160v2.pdf","comment":"Submitted to IEEE TPAMI"},{"id":"http://arxiv.org/abs/2502.20041v2","updated":"2025-03-03T06:21:57Z","published":"2025-02-27T12:29:44Z","title":"3D-AffordanceLLM: Harnessing Large Language Models for Open-Vocabulary\n  Affordance Detection in 3D Worlds","summary":"  3D Affordance detection is a challenging problem with broad applications on\nvarious robotic tasks. Existing methods typically formulate the detection\nparadigm as a label-based semantic segmentation task. This paradigm relies on\npredefined labels and lacks the ability to comprehend complex natural language,\nresulting in limited generalization in open-world scene. To address these\nlimitations, we reformulate the traditional affordance detection paradigm into\n\\textit{Instruction Reasoning Affordance Segmentation} (IRAS) task. This task\nis designed to output a affordance mask region given a query reasoning text,\nwhich avoids fixed categories of input labels. We accordingly propose the\n\\textit{3D-AffordanceLLM} (3D-ADLLM), a framework designed for reasoning\naffordance detection in 3D open-scene. Specifically, 3D-ADLLM introduces large\nlanguage models (LLMs) to 3D affordance perception with a custom-designed\ndecoder for generating affordance masks, thus achieving open-world reasoning\naffordance detection. In addition, given the scarcity of 3D affordance datasets\nfor training large models, we seek to extract knowledge from general\nsegmentation data and transfer it to affordance detection. Thus, we propose a\nmulti-stage training strategy that begins with a novel pre-training task, i.e.,\n\\textit{Referring Object Part Segmentation}~(ROPS). This stage is designed to\nequip the model with general recognition and segmentation capabilities at the\nobject-part level. Then followed by fine-tuning with the IRAS task, 3D-ADLLM\nobtains the reasoning ability for affordance detection. In summary, 3D-ADLLM\nleverages the rich world knowledge and human-object interaction reasoning\nability of LLMs, achieving approximately an 8\\% improvement in mIoU on\nopen-vocabulary affordance detection tasks.\n","authors":["Hengshuo Chu","Xiang Deng","Qi Lv","Xiaoyang Chen","Yinchuan Li","Jianye Hao","Liqiang Nie"],"pdf_url":"https://arxiv.org/pdf/2502.20041v2.pdf","comment":"ICLR"},{"id":"http://arxiv.org/abs/2310.01405v4","updated":"2025-03-03T06:14:14Z","published":"2023-10-02T17:59:07Z","title":"Representation Engineering: A Top-Down Approach to AI Transparency","summary":"  In this paper, we identify and characterize the emerging area of\nrepresentation engineering (RepE), an approach to enhancing the transparency of\nAI systems that draws on insights from cognitive neuroscience. RepE places\npopulation-level representations, rather than neurons or circuits, at the\ncenter of analysis, equipping us with novel methods for monitoring and\nmanipulating high-level cognitive phenomena in deep neural networks (DNNs). We\nprovide baselines and an initial analysis of RepE techniques, showing that they\noffer simple yet effective solutions for improving our understanding and\ncontrol of large language models. We showcase how these methods can provide\ntraction on a wide range of safety-relevant problems, including honesty,\nharmlessness, power-seeking, and more, demonstrating the promise of top-down\ntransparency research. We hope that this work catalyzes further exploration of\nRepE and fosters advancements in the transparency and safety of AI systems.\n","authors":["Andy Zou","Long Phan","Sarah Chen","James Campbell","Phillip Guo","Richard Ren","Alexander Pan","Xuwang Yin","Mantas Mazeika","Ann-Kathrin Dombrowski","Shashwat Goel","Nathaniel Li","Michael J. Byun","Zifan Wang","Alex Mallen","Steven Basart","Sanmi Koyejo","Dawn Song","Matt Fredrikson","J. Zico Kolter","Dan Hendrycks"],"pdf_url":"https://arxiv.org/pdf/2310.01405v4.pdf","comment":"Code is available at\n  https://github.com/andyzoujm/representation-engineering"},{"id":"http://arxiv.org/abs/2412.10831v2","updated":"2025-03-03T06:13:35Z","published":"2024-12-14T13:28:40Z","title":"Low-Biased General Annotated Dataset Generation","summary":"  Pre-training backbone networks on a general annotated dataset (e.g.,\nImageNet) that comprises numerous manually collected images with category\nannotations has proven to be indispensable for enhancing the generalization\ncapacity of downstream visual tasks. However, those manually collected images\noften exhibit bias, which is non-transferable across either categories or\ndomains, thus causing the model's generalization capacity degeneration. To\nmitigate this problem, we present an low-biased general annotated dataset\ngeneration framework (lbGen). Instead of expensive manual collection, we aim at\ndirectly generating low-biased images with category annotations. To achieve\nthis goal, we propose to leverage the advantage of a multimodal foundation\nmodel (e.g., CLIP), in terms of aligning images in an low-biased semantic space\ndefined by language. Specifically, we develop a bi-level semantic alignment\nloss, which not only forces all generated images to be consistent with the\nsemantic distribution of all categories belonging to the target dataset in an\nadversarial learning manner, but also requires each generated image to match\nthe semantic description of its category name. In addition, we further cast an\nexisting image quality scoring model into a quality assurance loss to preserve\nthe quality of the generated image. By leveraging these two loss functions, we\ncan obtain an low-biased image generation model by simply fine-tuning a\npre-trained diffusion model using only all category names in the target dataset\nas input. Experimental results confirm that, compared with the manually labeled\ndataset or other synthetic datasets, the utilization of our generated\nlow-biased datasets leads to stable generalization capacity enhancement of\ndifferent backbone networks across various tasks, especially in tasks where the\nmanually labeled samples are scarce.\n","authors":["Dengyang Jiang","Haoyu Wang","Lei Zhang","Wei Wei","Guang Dai","Mengmeng Wang","Jingdong Wang","Yanning Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.10831v2.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2410.02268v3","updated":"2025-03-03T05:32:47Z","published":"2024-10-03T07:40:14Z","title":"Structural-Entropy-Based Sample Selection for Efficient and Effective\n  Learning","summary":"  Sample selection improves the efficiency and effectiveness of machine\nlearning models by providing informative and representative samples. Typically,\nsamples can be modeled as a sample graph, where nodes are samples and edges\nrepresent their similarities. Most existing methods are based on local\ninformation, such as the training difficulty of samples, thereby overlooking\nglobal information, such as connectivity patterns. This oversight can result in\nsuboptimal selection because global information is crucial for ensuring that\nthe selected samples well represent the structural properties of the graph. To\naddress this issue, we employ structural entropy to quantify global information\nand losslessly decompose it from the whole graph to individual nodes using the\nShapley value. Based on the decomposition, we present\n$\\textbf{S}$tructural-$\\textbf{E}$ntropy-based sample $\\textbf{S}$election\n($\\textbf{SES}$), a method that integrates both global and local information to\nselect informative and representative samples. SES begins by constructing a\n$k$NN-graph among samples based on their similarities. It then measures sample\nimportance by combining structural entropy (global metric) with training\ndifficulty (local metric). Finally, SES applies importance-biased blue noise\nsampling to select a set of diverse and representative samples. Comprehensive\nexperiments on three learning scenarios -- supervised learning, active\nlearning, and continual learning -- clearly demonstrate the effectiveness of\nour method.\n","authors":["Tianchi Xie","Jiangning Zhu","Guozu Ma","Minzhi Lin","Wei Chen","Weikai Yang","Shixia Liu"],"pdf_url":"https://arxiv.org/pdf/2410.02268v3.pdf","comment":"Published as a conference paper at ICLR 2025"},{"id":"http://arxiv.org/abs/2404.12379v3","updated":"2025-03-03T05:31:09Z","published":"2024-04-18T17:58:16Z","title":"Dynamic Gaussians Mesh: Consistent Mesh Reconstruction from Dynamic\n  Scenes","summary":"  Modern 3D engines and graphics pipelines require mesh as a memory-efficient\nrepresentation, which allows efficient rendering, geometry processing, texture\nediting, and many other downstream operations. However, it is still highly\ndifficult to obtain high-quality mesh in terms of detailed structure and time\nconsistency from dynamic observations. To this end, we introduce Dynamic\nGaussians Mesh (DG-Mesh), a framework to reconstruct a high-fidelity and\ntime-consistent mesh from dynamic input. Our work leverages the recent\nadvancement in 3D Gaussian Splatting to construct the mesh sequence with\ntemporal consistency from dynamic observations. Building on top of this\nrepresentation, DG-Mesh recovers high-quality meshes from the Gaussian points\nand can track the mesh vertices over time, which enables applications such as\ntexture editing on dynamic objects. We introduce the Gaussian-Mesh Anchoring,\nwhich encourages evenly distributed Gaussians, resulting better mesh\nreconstruction through mesh-guided densification and pruning on the deformed\nGaussians. By applying cycle-consistent deformation between the canonical and\nthe deformed space, we can project the anchored Gaussian back to the canonical\nspace and optimize Gaussians across all time frames. During the evaluation on\ndifferent datasets, DG-Mesh provides significantly better mesh reconstruction\nand rendering than baselines. Project page: https://www.liuisabella.com/DG-Mesh\n","authors":["Isabella Liu","Hao Su","Xiaolong Wang"],"pdf_url":"https://arxiv.org/pdf/2404.12379v3.pdf","comment":"Project page: https://www.liuisabella.com/DG-Mesh"},{"id":"http://arxiv.org/abs/2410.09374v3","updated":"2025-03-03T05:31:05Z","published":"2024-10-12T05:35:27Z","title":"ESVO2: Direct Visual-Inertial Odometry with Stereo Event Cameras","summary":"  Event-based visual odometry is a specific branch of visual Simultaneous\nLocalization and Mapping (SLAM) techniques, which aims at solving tracking and\nmapping subproblems (typically in parallel), by exploiting the special working\nprinciples of neuromorphic (i.e., event-based) cameras. Due to the\nmotion-dependent nature of event data, explicit data association (i.e., feature\nmatching) under large-baseline view-point changes is difficult to establish,\nmaking direct methods a more rational choice. However, state-of-the-art direct\nmethods are limited by the high computational complexity of the mapping\nsub-problem and the degeneracy of camera pose tracking in certain degrees of\nfreedom (DoF) in rotation. In this paper, we tackle these issues by building an\nevent-based stereo visual-inertial odometry system on top of a direct pipeline.\nSpecifically, to speed up the mapping operation, we propose an efficient\nstrategy for sampling contour points according to the local dynamics of events.\nThe mapping performance is also improved in terms of structure completeness and\nlocal smoothness by merging the temporal stereo and static stereo results. To\ncircumvent the degeneracy of camera pose tracking in recovering the pitch and\nyaw components of general 6-DoF motion, we introduce IMU measurements as motion\npriors via pre-integration. To this end, a compact back-end is proposed for\ncontinuously updating the IMU bias and predicting the linear velocity, enabling\nan accurate motion prediction for camera pose tracking. The resulting system\nscales well with modern high-resolution event cameras and leads to better\nglobal positioning accuracy in large-scale outdoor environments. Extensive\nevaluations on five publicly available datasets featuring different resolutions\nand scenarios justify the superior performance of the proposed system against\nfive state-of-the-art methods.\n","authors":["Junkai Niu","Sheng Zhong","Xiuyuan Lu","Shaojie Shen","Guillermo Gallego","Yi Zhou"],"pdf_url":"https://arxiv.org/pdf/2410.09374v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.10988v2","updated":"2025-03-03T05:26:25Z","published":"2025-02-16T04:18:41Z","title":"OMG: Opacity Matters in Material Modeling with Gaussian Splatting","summary":"  Decomposing geometry, materials and lighting from a set of images, namely\ninverse rendering, has been a long-standing problem in computer vision and\ngraphics. Recent advances in neural rendering enable photo-realistic and\nplausible inverse rendering results. The emergence of 3D Gaussian Splatting has\nboosted it to the next level by showing real-time rendering potentials. An\nintuitive finding is that the models used for inverse rendering do not take\ninto account the dependency of opacity w.r.t. material properties, namely cross\nsection, as suggested by optics. Therefore, we develop a novel approach that\nadds this dependency to the modeling itself. Inspired by radiative transfer, we\naugment the opacity term by introducing a neural network that takes as input\nmaterial properties to provide modeling of cross section and a physically\ncorrect activation function. The gradients for material properties are\ntherefore not only from color but also from opacity, facilitating a constraint\nfor their optimization. Therefore, the proposed method incorporates more\naccurate physical properties compared to previous works. We implement our\nmethod into 3 different baselines that use Gaussian Splatting for inverse\nrendering and achieve significant improvements universally in terms of novel\nview synthesis and material modeling.\n","authors":["Silong Yong","Venkata Nagarjun Pudureddiyur Manivannan","Bernhard Kerbl","Zifu Wan","Simon Stepputtis","Katia Sycara","Yaqi Xie"],"pdf_url":"https://arxiv.org/pdf/2502.10988v2.pdf","comment":"Published as a conference paper at ICLR 2025"},{"id":"http://arxiv.org/abs/2502.01912v2","updated":"2025-03-03T05:25:43Z","published":"2025-02-04T01:05:12Z","title":"PATCH: a deep learning method to assess heterogeneity of artistic\n  practice in historical paintings","summary":"  The history of art has seen significant shifts in the manner in which\nartworks are created, making understanding of creative processes a central\nquestion in technical art history. In the Renaissance and Early Modern period,\npaintings were largely produced by master painters directing workshops of\napprentices who often contributed to projects. The masters varied significantly\nin artistic and managerial styles, meaning different combinations of artists\nand implements might be seen both between masters and within workshops or even\nindividual canvases. Information on how different workshops were managed and\nthe processes by which artworks were created remains elusive. Machine learning\nmethods have potential to unearth new information about artists' creative\nprocesses by extending the analysis of brushwork to a microscopic scale.\nAnalysis of workshop paintings, however, presents a challenge in that\ndocumentation of the artists and materials involved is sparse, meaning external\nexamples are not available to train networks to recognize their contributions.\nHere we present a novel machine learning approach we call pairwise assignment\ntraining for classifying heterogeneity (PATCH) that is capable of identifying\nindividual artistic practice regimes with no external training data, or \"ground\ntruth.\" The method achieves unsupervised results by supervised means, and\noutperforms both simple statistical procedures and unsupervised machine\nlearning methods. We apply this method to two historical paintings by the\nSpanish Renaissance master, El Greco: The Baptism of Christ and Christ on the\nCross with Landscape, and our findings regarding the former potentially\nchallenge previous work that has assigned the painting to workshop members.\nFurther, the results of our analyses create a measure of heterogeneity of\nartistic practice that can be used to characterize artworks across time and\nspace.\n","authors":["Andrew Van Horn","Lauryn Smith","Mahamad Mahmoud","Michael McMaster","Clara Pinchbeck","Ina Martin","Andrew Lininger","Anthony Ingrisano","Adam Lowe","Carlos Bayod","Elizabeth Bolman","Kenneth Singer","Michael Hinczewski"],"pdf_url":"https://arxiv.org/pdf/2502.01912v2.pdf","comment":"main text: 16 pages, 6 figures; SI: 7 pages, 3 figures; v2: minor\n  typo corrections, higher resolution figures"},{"id":"http://arxiv.org/abs/2402.02112v5","updated":"2025-03-03T04:42:15Z","published":"2024-02-03T10:35:42Z","title":"S-NeRF++: Autonomous Driving Simulation via Neural Reconstruction and\n  Generation","summary":"  Autonomous driving simulation system plays a crucial role in enhancing\nself-driving data and simulating complex and rare traffic scenarios, ensuring\nnavigation safety. However, traditional simulation systems, which often heavily\nrely on manual modeling and 2D image editing, struggled with scaling to\nextensive scenes and generating realistic simulation data. In this study, we\npresent S-NeRF++, an innovative autonomous driving simulation system based on\nneural reconstruction. Trained on widely-used self-driving datasets such as\nnuScenes and Waymo, S-NeRF++ can generate a large number of realistic street\nscenes and foreground objects with high rendering quality as well as offering\nconsiderable flexibility in manipulation and simulation. Specifically, S-NeRF++\nis an enhanced neural radiance field for synthesizing large-scale scenes and\nmoving vehicles, with improved scene parameterization and camera pose learning.\nThe system effectively utilizes noisy and sparse LiDAR data to refine training\nand address depth outliers, ensuring high-quality reconstruction and novel-view\nrendering. It also provides a diverse foreground asset bank by reconstructing\nand generating different foreground vehicles to support comprehensive scenario\ncreation.Moreover, we have developed an advanced foreground-background fusion\npipeline that skillfully integrates illumination and shadow effects, further\nenhancing the realism of our simulations. With the high-quality simulated data\nprovided by our S-NeRF++, we found the perception methods enjoy performance\nboosts on several autonomous driving downstream tasks, further demonstrating\nour proposed simulator's effectiveness.\n","authors":["Yurui Chen","Junge Zhang","Ziyang Xie","Wenye Li","Feihu Zhang","Jiachen Lu","Li Zhang"],"pdf_url":"https://arxiv.org/pdf/2402.02112v5.pdf","comment":"IEEE TPAMI 2025"},{"id":"http://arxiv.org/abs/2409.07002v2","updated":"2025-03-03T04:32:29Z","published":"2024-09-11T04:30:45Z","title":"AdvLogo: Adversarial Patch Attack against Object Detectors based on\n  Diffusion Models","summary":"  With the rapid development of deep learning, object detectors have\ndemonstrated impressive performance; however, vulnerabilities still exist in\ncertain scenarios. Current research exploring the vulnerabilities using\nadversarial patches often struggles to balance the trade-off between attack\neffectiveness and visual quality. To address this problem, we propose a novel\nframework of patch attack from semantic perspective, which we refer to as\nAdvLogo. Based on the hypothesis that every semantic space contains an\nadversarial subspace where images can cause detectors to fail in recognizing\nobjects, we leverage the semantic understanding of the diffusion denoising\nprocess and drive the process to adversarial subareas by perturbing the latent\nand unconditional embeddings at the last timestep. To mitigate the distribution\nshift that exposes a negative impact on image quality, we apply perturbation to\nthe latent in frequency domain with the Fourier Transform. Experimental results\ndemonstrate that AdvLogo achieves strong attack performance while maintaining\nhigh visual quality.\n","authors":["Boming Miao","Chunxiao Li","Yao Zhu","Weixiang Sun","Zizhe Wang","Xiaoyi Wang","Chuanlong Xie"],"pdf_url":"https://arxiv.org/pdf/2409.07002v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18084v2","updated":"2025-03-03T04:31:23Z","published":"2024-10-23T17:59:58Z","title":"DynamicCity: Large-Scale 4D Occupancy Generation from Dynamic Scenes","summary":"  Urban scene generation has been developing rapidly recently. However,\nexisting methods primarily focus on generating static and single-frame scenes,\noverlooking the inherently dynamic nature of real-world driving environments.\nIn this work, we introduce DynamicCity, a novel 4D occupancy generation\nframework capable of generating large-scale, high-quality dynamic 4D scenes\nwith semantics. DynamicCity mainly consists of two key models. 1) A VAE model\nfor learning HexPlane as the compact 4D representation. Instead of using naive\naveraging operations, DynamicCity employs a novel Projection Module to\neffectively compress 4D features into six 2D feature maps for HexPlane\nconstruction, which significantly enhances HexPlane fitting quality (up to\n12.56 mIoU gain). Furthermore, we utilize an Expansion & Squeeze Strategy to\nreconstruct 3D feature volumes in parallel, which improves both network\ntraining efficiency and reconstruction accuracy than naively querying each 3D\npoint (up to 7.05 mIoU gain, 2.06x training speedup, and 70.84% memory\nreduction). 2) A DiT-based diffusion model for HexPlane generation. To make\nHexPlane feasible for DiT generation, a Padded Rollout Operation is proposed to\nreorganize all six feature planes of the HexPlane as a squared 2D feature map.\nIn particular, various conditions could be introduced in the diffusion or\nsampling process, supporting versatile 4D generation applications, such as\ntrajectory- and command-driven generation, inpainting, and layout-conditioned\ngeneration. Extensive experiments on the CarlaSC and Waymo datasets demonstrate\nthat DynamicCity significantly outperforms existing state-of-the-art 4D\noccupancy generation methods across multiple metrics. The code and models have\nbeen released to facilitate future research.\n","authors":["Hengwei Bian","Lingdong Kong","Haozhe Xie","Liang Pan","Yu Qiao","Ziwei Liu"],"pdf_url":"https://arxiv.org/pdf/2410.18084v2.pdf","comment":"ICLR 2025 Spotlight; 35 pages, 18 figures, 15 tables; Project Page at\n  https://dynamic-city.github.io/"},{"id":"http://arxiv.org/abs/2403.17010v3","updated":"2025-03-03T04:22:19Z","published":"2024-03-25T17:59:59Z","title":"Calib3D: Calibrating Model Preferences for Reliable 3D Scene\n  Understanding","summary":"  Safety-critical 3D scene understanding tasks necessitate not only accurate\nbut also confident predictions from 3D perception models. This study introduces\nCalib3D, a pioneering effort to benchmark and scrutinize the reliability of 3D\nscene understanding models from an uncertainty estimation viewpoint. We\ncomprehensively evaluate 28 state-of-the-art models across 10 diverse 3D\ndatasets, uncovering insightful phenomena that cope with both the aleatoric and\nepistemic uncertainties in 3D scene understanding. We discover that despite\nachieving impressive levels of accuracy, existing models frequently fail to\nprovide reliable uncertainty estimates -- a pitfall that critically undermines\ntheir applicability in safety-sensitive contexts. Through extensive analysis of\nkey factors such as network capacity, LiDAR representations, rasterization\nresolutions, and 3D data augmentation techniques, we correlate these aspects\ndirectly with the model calibration efficacy. Furthermore, we introduce DeptS,\na novel depth-aware scaling approach aimed at enhancing 3D model calibration.\nExtensive experiments across a wide range of configurations validate the\nsuperiority of our method. We hope this work could serve as a cornerstone for\nfostering reliable 3D scene understanding. Code and benchmark toolkit are\npublicly available.\n","authors":["Lingdong Kong","Xiang Xu","Jun Cen","Wenwei Zhang","Liang Pan","Kai Chen","Ziwei Liu"],"pdf_url":"https://arxiv.org/pdf/2403.17010v3.pdf","comment":"WACV 2025 Oral; 26 pages, 8 figures, 12 tables; Code at\n  https://github.com/ldkong1205/Calib3D"},{"id":"http://arxiv.org/abs/2410.03190v3","updated":"2025-03-03T04:11:46Z","published":"2024-10-04T07:05:16Z","title":"Tuning Timestep-Distilled Diffusion Model Using Pairwise Sample\n  Optimization","summary":"  Recent advancements in timestep-distilled diffusion models have enabled\nhigh-quality image generation that rivals non-distilled multi-step models, but\nwith significantly fewer inference steps. While such models are attractive for\napplications due to the low inference cost and latency, fine-tuning them with a\nnaive diffusion objective would result in degraded and blurry outputs. An\nintuitive alternative is to repeat the diffusion distillation process with a\nfine-tuned teacher model, which produces good results but is cumbersome and\ncomputationally intensive; the distillation training usually requires magnitude\nhigher of training compute compared to fine-tuning for specific image styles.\nIn this paper, we present an algorithm named pairwise sample optimization\n(PSO), which enables the direct fine-tuning of an arbitrary timestep-distilled\ndiffusion model. PSO introduces additional reference images sampled from the\ncurrent time-step distilled model, and increases the relative likelihood margin\nbetween the training images and reference images. This enables the model to\nretain its few-step generation ability, while allowing for fine-tuning of its\noutput distribution. We also demonstrate that PSO is a generalized formulation\nwhich can be flexibly extended to both offline-sampled and online-sampled\npairwise data, covering various popular objectives for diffusion model\npreference optimization. We evaluate PSO in both preference optimization and\nother fine-tuning tasks, including style transfer and concept customization. We\nshow that PSO can directly adapt distilled models to human-preferred generation\nwith both offline and online-generated pairwise preference image data. PSO also\ndemonstrates effectiveness in style transfer and concept customization by\ndirectly tuning timestep-distilled diffusion models.\n","authors":["Zichen Miao","Zhengyuan Yang","Kevin Lin","Ze Wang","Zicheng Liu","Lijuan Wang","Qiang Qiu"],"pdf_url":"https://arxiv.org/pdf/2410.03190v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21093v2","updated":"2025-03-03T03:48:47Z","published":"2025-02-28T14:32:04Z","title":"FlexDrive: Toward Trajectory Flexibility in Driving Scene Reconstruction\n  and Rendering","summary":"  Driving scene reconstruction and rendering have advanced significantly using\nthe 3D Gaussian Splatting. However, most prior research has focused on the\nrendering quality along a pre-recorded vehicle path and struggles to generalize\nto out-of-path viewpoints, which is caused by the lack of high-quality\nsupervision in those out-of-path views. To address this issue, we introduce an\nInverse View Warping technique to create compact and high-quality images as\nsupervision for the reconstruction of the out-of-path views, enabling\nhigh-quality rendering results for those views. For accurate and robust inverse\nview warping, a depth bootstrap strategy is proposed to obtain on-the-fly dense\ndepth maps during the optimization process, overcoming the sparsity and\nincompleteness of LiDAR depth data. Our method achieves superior in-path and\nout-of-path reconstruction and rendering performance on the widely used Waymo\nOpen dataset. In addition, a simulator-based benchmark is proposed to obtain\nthe out-of-path ground truth and quantitatively evaluate the performance of\nout-of-path rendering, where our method outperforms previous methods by a\nsignificant margin.\n","authors":["Jingqiu Zhou","Lue Fan","Linjiang Huang","Xiaoyu Shi","Si Liu","Zhaoxiang Zhang","Hongsheng Li"],"pdf_url":"https://arxiv.org/pdf/2502.21093v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.02586v2","updated":"2025-03-03T03:38:29Z","published":"2023-05-04T06:40:11Z","title":"Semantically Structured Image Compression via Irregular Group-Based\n  Decoupling","summary":"  Image compression techniques typically focus on compressing rectangular\nimages for human consumption, however, resulting in transmitting redundant\ncontent for downstream applications. To overcome this limitation, some previous\nworks propose to semantically structure the bitstream, which can meet specific\napplication requirements by selective transmission and reconstruction.\nNevertheless, they divide the input image into multiple rectangular regions\naccording to semantics and ignore avoiding information interaction among them,\ncausing waste of bitrate and distorted reconstruction of region boundaries. In\nthis paper, we propose to decouple an image into multiple groups with irregular\nshapes based on a customized group mask and compress them independently. Our\ngroup mask describes the image at a finer granularity, enabling significant\nbitrate saving by reducing the transmission of redundant content. Moreover, to\nensure the fidelity of selective reconstruction, this paper proposes the\nconcept of group-independent transform that maintain the independence among\ndistinct groups. And we instantiate it by the proposed Group-Independent\nSwin-Block (GI Swin-Block). Experimental results demonstrate that our framework\nstructures the bitstream with negligible cost, and exhibits superior\nperformance on both visual quality and intelligent task supporting.\n","authors":["Ruoyu Feng","Yixin Gao","Xin Jin","Runsen Feng","Zhibo Chen"],"pdf_url":"https://arxiv.org/pdf/2305.02586v2.pdf","comment":"Accept by ICCV2023"},{"id":"http://arxiv.org/abs/2502.01117v2","updated":"2025-03-03T03:35:00Z","published":"2025-02-03T07:13:59Z","title":"Learning to Learn Weight Generation via Trajectory Diffusion","summary":"  Diffusion-based algorithms have emerged as promising techniques for weight\ngeneration, particularly in scenarios like multi-task learning that require\nfrequent weight updates. However, existing solutions suffer from limited\ncross-task transferability. In addition, they only utilize optimal weights as\ntraining samples, ignoring the value of other weights in the optimization\nprocess. To address these issues, we propose Lt-Di, which integrates the\ndiffusion algorithm with meta-learning to generate weights for unseen tasks.\nFurthermore, we extend the vanilla diffusion algorithm into a trajectory\ndiffusion algorithm to utilize other weights along the optimization trajectory.\nTrajectory diffusion decomposes the entire diffusion chain into multiple\nshorter ones, improving training and inference efficiency. We analyze the\nconvergence properties of the weight generation paradigm and improve\nconvergence efficiency without additional time overhead. Our experiments\ndemonstrate Lt-Di's higher accuracy while reducing computational overhead\nacross various tasks, including zero-shot and few-shot learning, multi-domain\ngeneralization, and large-scale language model fine-tuning.Our code is released\nat https://anonymous.4open.science/r/Lt-Di-0E51.\n","authors":["Yunchuan Guan","Yu Liu","Ke Zhou","Zhiqi Shen","Serge Belongie","Jenq-Neng Hwang","Lei Li"],"pdf_url":"https://arxiv.org/pdf/2502.01117v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.21256v2","updated":"2025-03-03T03:23:44Z","published":"2024-10-28T17:54:29Z","title":"Multi-modal AI for comprehensive breast cancer prognostication","summary":"  Treatment selection in breast cancer is guided by molecular subtypes and\nclinical characteristics. However, current tools including genomic assays lack\nthe accuracy required for optimal clinical decision-making. We developed a\nnovel artificial intelligence (AI)-based approach that integrates digital\npathology images with clinical data, providing a more robust and effective\nmethod for predicting the risk of cancer recurrence in breast cancer patients.\nSpecifically, we utilized a vision transformer pan-cancer foundation model\ntrained with self-supervised learning to extract features from digitized\nH&E-stained slides. These features were integrated with clinical data to form a\nmulti-modal AI test predicting cancer recurrence and death. The test was\ndeveloped and evaluated using data from a total of 8,161 female breast cancer\npatients across 15 cohorts originating from seven countries. Of these, 3,502\npatients from five cohorts were used exclusively for evaluation, while the\nremaining patients were used for training. Our test accurately predicted our\nprimary endpoint, disease-free interval, in the five evaluation cohorts\n(C-index: 0.71 [0.68-0.75], HR: 3.63 [3.02-4.37, p<0.001]). In a direct\ncomparison (n=858), the AI test was more accurate than Oncotype DX, the\nstandard-of-care 21-gene assay, achieving a C-index of 0.67 [0.61-0.74] versus\n0.61 [0.49-0.73], respectively. Additionally, the AI test added independent\nprognostic information to Oncotype DX in a multivariate analysis (HR: 3.11\n[1.91-5.09, p<0.001)]). The test demonstrated robust accuracy across major\nmolecular breast cancer subtypes, including TNBC (C-index: 0.71 [0.62-0.81],\nHR: 3.81 [2.35-6.17, p=0.02]), where no diagnostic tools are currently\nrecommended by clinical guidelines. These results suggest that our AI test\nimproves upon the accuracy of existing prognostic tests, while being applicable\nto a wider range of patients.\n","authors":["Jan Witowski","Ken G. Zeng","Joseph Cappadona","Jailan Elayoubi","Khalil Choucair","Elena Diana Chiru","Nancy Chan","Young-Joon Kang","Frederick Howard","Irina Ostrovnaya","Carlos Fernandez-Granda","Freya Schnabel","Zoe Steinsnyder","Ugur Ozerdem","Kangning Liu","Waleed Abdulsattar","Yu Zong","Lina Daoud","Rafic Beydoun","Anas Saad","Nitya Thakore","Mohammad Sadic","Frank Yeung","Elisa Liu","Theodore Hill","Benjamin Swett","Danielle Rigau","Andrew Clayburn","Valerie Speirs","Marcus Vetter","Lina Sojak","Simone Soysal","Daniel Baumhoer","Jia-Wern Pan","Haslina Makmur","Soo-Hwang Teo","Linda Ma Pak","Victor Angel","Dovile Zilenaite-Petrulaitiene","Arvydas Laurinavicius","Natalie Klar","Brian D. Piening","Carlo Bifulco","Sun-Young Jun","Jae Pak Yi","Su Hyun Lim","Adam Brufsky","Francisco J. Esteva","Lajos Pusztai","Yann LeCun","Krzysztof J. Geras"],"pdf_url":"https://arxiv.org/pdf/2410.21256v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.14093v3","updated":"2025-03-03T03:19:31Z","published":"2024-05-23T01:43:54Z","title":"A Survey on Vision-Language-Action Models for Embodied AI","summary":"  Embodied AI is widely recognized as a key element of artificial general\nintelligence because it involves controlling embodied agents to perform tasks\nin the physical world. Building on the success of large language models and\nvision-language models, a new category of multimodal models -- referred to as\nvision-language-action models (VLAs) -- has emerged to address\nlanguage-conditioned robotic tasks in embodied AI by leveraging their distinct\nability to generate actions. In recent years, a myriad of VLAs have been\ndeveloped, making it imperative to capture the rapidly evolving landscape\nthrough a comprehensive survey. To this end, we present the first survey on\nVLAs for embodied AI. This work provides a detailed taxonomy of VLAs, organized\ninto three major lines of research. The first line focuses on individual\ncomponents of VLAs. The second line is dedicated to developing control policies\nadept at predicting low-level actions. The third line comprises high-level task\nplanners capable of decomposing long-horizon tasks into a sequence of subtasks,\nthereby guiding VLAs to follow more general user instructions. Furthermore, we\nprovide an extensive summary of relevant resources, including datasets,\nsimulators, and benchmarks. Finally, we discuss the challenges faced by VLAs\nand outline promising future directions in embodied AI.\n","authors":["Yueen Ma","Zixing Song","Yuzheng Zhuang","Jianye Hao","Irwin King"],"pdf_url":"https://arxiv.org/pdf/2405.14093v3.pdf","comment":"16 pages, a survey of vision-language-action models"},{"id":"http://arxiv.org/abs/2501.12844v2","updated":"2025-03-03T03:18:40Z","published":"2025-01-22T12:45:09Z","title":"GAMED-Snake: Gradient-aware Adaptive Momentum Evolution Deep Snake Model\n  for Multi-organ Segmentation","summary":"  Multi-organ segmentation is a critical yet challenging task due to complex\nanatomical backgrounds, blurred boundaries, and diverse morphologies. This\nstudy introduces the Gradient-aware Adaptive Momentum Evolution Deep Snake\n(GAMED-Snake) model, which establishes a novel paradigm for contour-based\nsegmentation by integrating gradient-based learning with adaptive momentum\nevolution mechanisms. The GAMED-Snake model incorporates three major\ninnovations: First, the Distance Energy Map Prior (DEMP) generates a\npixel-level force field that effectively attracts contour points towards the\ntrue boundaries, even in scenarios with complex backgrounds and blurred edges.\nSecond, the Differential Convolution Inception Module (DCIM) precisely extracts\ncomprehensive energy gradients, significantly enhancing segmentation accuracy.\nThird, the Adaptive Momentum Evolution Mechanism (AMEM) employs cross-attention\nto establish dynamic features across different iterations of evolution,\nenabling precise boundary alignment for diverse morphologies. Experimental\nresults on four challenging multi-organ segmentation datasets demonstrate that\nGAMED-Snake improves the mDice metric by approximately 2% compared to\nstate-of-the-art methods. Code will be available at\nhttps://github.com/SYSUzrc/GAMED-Snake.\n","authors":["Ruicheng Zhang","Haowei Guo","Zeyu Zhang","Puxin Yan","Shen Zhao"],"pdf_url":"https://arxiv.org/pdf/2501.12844v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.16826v2","updated":"2025-03-03T03:09:49Z","published":"2025-02-24T04:23:21Z","title":"Noise2Score3D:Unsupervised Tweedie's Approach for Point Cloud Denoising","summary":"  Building on recent advances in Bayesian statistics and image denoising, we\npropose Noise2Score3D, a fully unsupervised framework for point cloud denoising\nthat addresses the critical challenge of limited availability of clean data.\nNoise2Score3D learns the gradient of the underlying point cloud distribution\ndirectly from noisy data, eliminating the need for clean data during training.\nBy leveraging Tweedie's formula, our method performs inference in a single\nstep, avoiding the iterative processes used in existing unsupervised methods,\nthereby improving both performance and efficiency. Experimental results\ndemonstrate that Noise2Score3D achieves state-of-the-art performance on\nstandard benchmarks, outperforming other unsupervised methods in Chamfer\ndistance and point-to-mesh metrics, and rivaling some supervised approaches.\nFurthermore, Noise2Score3D demonstrates strong generalization ability beyond\ntraining datasets. Additionally, we introduce Total Variation for Point Cloud,\na criterion that allows for the estimation of unknown noise parameters, which\nfurther enhances the method's versatility and real-world utility.\n","authors":["Xiangbin Wei"],"pdf_url":"https://arxiv.org/pdf/2502.16826v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13085v2","updated":"2025-03-03T03:08:28Z","published":"2024-10-16T23:03:27Z","title":"MMed-RAG: Versatile Multimodal RAG System for Medical Vision Language\n  Models","summary":"  Artificial Intelligence (AI) has demonstrated significant potential in\nhealthcare, particularly in disease diagnosis and treatment planning. Recent\nprogress in Medical Large Vision-Language Models (Med-LVLMs) has opened up new\npossibilities for interactive diagnostic tools. However, these models often\nsuffer from factual hallucination, which can lead to incorrect diagnoses.\nFine-tuning and retrieval-augmented generation (RAG) have emerged as methods to\naddress these issues. However, the amount of high-quality data and distribution\nshifts between training data and deployment data limit the application of\nfine-tuning methods. Although RAG is lightweight and effective, existing\nRAG-based approaches are not sufficiently general to different medical domains\nand can potentially cause misalignment issues, both between modalities and\nbetween the model and the ground truth. In this paper, we propose a versatile\nmultimodal RAG system, MMed-RAG, designed to enhance the factuality of\nMed-LVLMs. Our approach introduces a domain-aware retrieval mechanism, an\nadaptive retrieved contexts selection method, and a provable RAG-based\npreference fine-tuning strategy. These innovations make the RAG process\nsufficiently general and reliable, significantly improving alignment when\nintroducing retrieved contexts. Experimental results across five medical\ndatasets (involving radiology, ophthalmology, pathology) on medical VQA and\nreport generation demonstrate that MMed-RAG can achieve an average improvement\nof 43.8% in the factual accuracy of Med-LVLMs. Our data and code are available\nin https://github.com/richard-peng-xia/MMed-RAG.\n","authors":["Peng Xia","Kangyu Zhu","Haoran Li","Tianze Wang","Weijia Shi","Sheng Wang","Linjun Zhang","James Zou","Huaxiu Yao"],"pdf_url":"https://arxiv.org/pdf/2410.13085v2.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2409.06214v3","updated":"2025-03-03T01:46:42Z","published":"2024-09-10T04:45:25Z","title":"Towards Generalizable Scene Change Detection","summary":"  While current state-of-the-art Scene Change Detection (SCD) approaches\nachieve impressive results in well-trained research data, they become\nunreliable under unseen environments and different temporal conditions;\nin-domain performance drops from 77.6\\% to 8.0\\% in a previously unseen\nenvironment and to 4.6\\% under a different temporal condition -- calling for\ngeneralizable SCD and benchmark. In this work, we propose the Generalizable\nScene Change Detection Framework (GeSCF), which addresses unseen domain\nperformance and temporal consistency -- to meet the growing demand for anything\nSCD. Our method leverages the pre-trained Segment Anything Model (SAM) in a\nzero-shot manner. For this, we design Initial Pseudo-mask Generation and\nGeometric-Semantic Mask Matching -- seamlessly turning user-guided prompt and\nsingle-image based segmentation into scene change detection for a pair of\ninputs without guidance. Furthermore, we define the Generalizable Scene Change\nDetection (GeSCD) benchmark along with novel metrics and an evaluation protocol\nto facilitate SCD research in generalizability. In the process, we introduce\nthe ChangeVPR dataset, a collection of challenging image pairs with diverse\nenvironmental scenarios -- including urban, suburban, and rural settings.\nExtensive experiments across various datasets demonstrate that GeSCF achieves\nan average performance gain of 19.2\\% on existing SCD datasets and 30.0\\% on\nthe ChangeVPR dataset, nearly doubling the prior art performance. We believe\nour work can lay a solid foundation for robust and generalizable SCD research.\n","authors":["Jaewoo Kim","Uehwan Kim"],"pdf_url":"https://arxiv.org/pdf/2409.06214v3.pdf","comment":"Manuscript. Accepted to CVPR 2025"},{"id":"http://arxiv.org/abs/2502.08079v3","updated":"2025-03-03T01:35:58Z","published":"2025-02-12T02:53:27Z","title":"MAA: Meticulous Adversarial Attack against Vision-Language Pre-trained\n  Models","summary":"  Current adversarial attacks for evaluating the robustness of vision-language\npre-trained (VLP) models in multi-modal tasks suffer from limited\ntransferability, where attacks crafted for a specific model often struggle to\ngeneralize effectively across different models, limiting their utility in\nassessing robustness more broadly. This is mainly attributed to the\nover-reliance on model-specific features and regions, particularly in the image\nmodality. In this paper, we propose an elegant yet highly effective method\ntermed Meticulous Adversarial Attack (MAA) to fully exploit model-independent\ncharacteristics and vulnerabilities of individual samples, achieving enhanced\ngeneralizability and reduced model dependence. MAA emphasizes fine-grained\noptimization of adversarial images by developing a novel resizing and sliding\ncrop (RScrop) technique, incorporating a multi-granularity similarity\ndisruption (MGSD) strategy. Extensive experiments across diverse VLP models,\nmultiple benchmark datasets, and a variety of downstream tasks demonstrate that\nMAA significantly enhances the effectiveness and transferability of adversarial\nattacks. A large cohort of performance studies is conducted to generate\ninsights into the effectiveness of various model configurations, guiding future\nadvancements in this domain.\n","authors":["Peng-Fei Zhang","Guangdong Bai","Zi Huang"],"pdf_url":"https://arxiv.org/pdf/2502.08079v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.14519v2","updated":"2025-03-03T00:51:41Z","published":"2024-09-22T16:25:31Z","title":"RobotFingerPrint: Unified Gripper Coordinate Space for Multi-Gripper\n  Grasp Synthesis and Transfer","summary":"  We introduce a novel grasp representation named the Unified Gripper\nCoordinate Space (UGCS) for grasp synthesis and grasp transfer. Our\nrepresentation leverages spherical coordinates to create a shared coordinate\nspace across different robot grippers, enabling it to synthesize and transfer\ngrasps for both novel objects and previously unseen grippers. The strength of\nthis representation lies in the ability to map palm and fingers of a gripper\nand the unified coordinate space. Grasp synthesis is formulated as predicting\nthe unified spherical coordinates on object surface points via a conditional\nvariational autoencoder. The predicted unified gripper coordinates establish\nexact correspondences between the gripper and object points, which is used to\noptimize grasp pose and joint values. Grasp transfer is facilitated through the\npoint-to-point correspondence between any two (potentially unseen) grippers and\nsolved via a similar optimization. Extensive simulation and real-world\nexperiments showcase the efficacy of the unified grasp representation for grasp\nsynthesis in generating stable and diverse grasps. Similarly, we showcase\nreal-world grasp transfer from human demonstrations across different objects.\n","authors":["Ninad Khargonkar","Luis Felipe Casas","Balakrishnan Prabhakaran","Yu Xiang"],"pdf_url":"https://arxiv.org/pdf/2409.14519v2.pdf","comment":"8 pages, 11 figures, 3 tables. Project page available at\n  https://irvlutd.github.io/RobotFingerPrint"},{"id":"http://arxiv.org/abs/2410.01417v2","updated":"2025-03-03T00:41:36Z","published":"2024-10-02T10:58:54Z","title":"The Labyrinth of Links: Navigating the Associative Maze of Multi-modal\n  LLMs","summary":"  Multi-modal Large Language Models (MLLMs) have exhibited impressive\ncapability. However, recently many deficiencies of MLLMs have been found\ncompared to human intelligence, $\\textit{e.g.}$, hallucination. To drive the\nMLLMs study, the community dedicated efforts to building larger benchmarks with\ncomplex tasks. In this paper, we propose benchmarking an essential but usually\noverlooked intelligence: $\\textbf{association}$, a human's basic capability to\nlink observation and prior practice memory. To comprehensively investigate\nMLLM's performance on the association, we formulate the association task and\ndevise a standard benchmark based on adjective and verb semantic concepts.\nInstead of costly data annotation and curation, we propose a convenient\n$\\textbf{annotation-free}$ construction method transforming the general dataset\nfor our association tasks. Simultaneously, we devise a rigorous data refinement\nprocess to eliminate confusion in the raw dataset. Building on this database,\nwe establish three levels of association tasks: single-step, synchronous, and\nasynchronous associations. Moreover, we conduct a comprehensive investigation\ninto the MLLMs' zero-shot association capabilities, addressing multiple\ndimensions, including three distinct memory strategies, both open-source and\nclosed-source MLLMs, cutting-edge Mixture-of-Experts (MoE) models, and the\ninvolvement of human experts. Our systematic investigation shows that current\nopen-source MLLMs consistently exhibit poor capability in our association\ntasks, even the currently state-of-the-art GPT-4V(vision) also has a\nsignificant gap compared to humans. We believe our benchmark would pave the way\nfor future MLLM studies. $\\textit{Our data and code are available at:}$\nhttps://mvig-rhos.com/llm_inception.\n","authors":["Hong Li","Nanxi Li","Yuanjie Chen","Jianbin Zhu","Qinlu Guo","Cewu Lu","Yong-Lu Li"],"pdf_url":"https://arxiv.org/pdf/2410.01417v2.pdf","comment":"Accepted by ICLR 2025. Project page:\n  https://mvig-rhos.com/llm_inception"},{"id":"http://arxiv.org/abs/2409.04607v2","updated":"2025-03-03T00:20:29Z","published":"2024-09-06T20:32:53Z","title":"Self-Supervised Contrastive Learning for Videos using Differentiable\n  Local Alignment","summary":"  Robust frame-wise embeddings are essential to perform video analysis and\nunderstanding tasks. We present a self-supervised method for representation\nlearning based on aligning temporal video sequences. Our framework uses a\ntransformer-based encoder to extract frame-level features and leverages them to\nfind the optimal alignment path between video sequences. We introduce the novel\nLocal-Alignment Contrastive (LAC) loss, which combines a differentiable local\nalignment loss to capture local temporal dependencies with a contrastive loss\nto enhance discriminative learning. Prior works on video alignment have focused\non using global temporal ordering across sequence pairs, whereas our loss\nencourages identifying the best-scoring subsequence alignment. LAC uses the\ndifferentiable Smith-Waterman (SW) affine method, which features a flexible\nparameterization learned through the training phase, enabling the model to\nadjust the temporal gap penalty length dynamically. Evaluations show that our\nlearned representations outperform existing state-of-the-art approaches on\naction recognition tasks.\n","authors":["Keyne Oei","Amr Gomaa","Anna Maria Feit","João Belo"],"pdf_url":"https://arxiv.org/pdf/2409.04607v2.pdf","comment":"Accepted in 2nd Workshop on Video Understanding and its Applications,\n  held in conjunction with the British Machine Vision Conference (BMVC) 2024"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2502.18858v2","updated":"2025-03-03T13:38:50Z","published":"2025-02-26T05:59:45Z","title":"Evaluating Intelligence via Trial and Error","summary":"  Intelligence is a crucial trait for species to find solutions within a\nlimited number of trial-and-error attempts. Building on this idea, we introduce\nSurvival Game as a framework to evaluate intelligence based on the number of\nfailed attempts in a trial-and-error process. Fewer failures indicate higher\nintelligence. When the expectation and variance of failure counts are both\nfinite, it signals the ability to consistently find solutions to new\nchallenges, which we define as the Autonomous Level of intelligence. Using\nSurvival Game, we comprehensively evaluate existing AI systems. Our results\nshow that while AI systems achieve the Autonomous Level in simple tasks, they\nare still far from it in more complex tasks, such as vision, search,\nrecommendation, and language. While scaling current AI technologies might help,\nthis would come at an astronomical cost. Projections suggest that achieving the\nAutonomous Level for general tasks would require $10^{26}$ parameters. To put\nthis into perspective, loading such a massive model requires so many H100 GPUs\nthat their total value is $10^{7}$ times that of Apple Inc.'s market value.\nEven with Moore's Law, supporting such a parameter scale would take $70$ years.\nThis staggering cost highlights the complexity of human tasks and the\ninadequacies of current AI technologies. To further investigate this\nphenomenon, we conduct a theoretical analysis of Survival Game and its\nexperimental results. Our findings suggest that human tasks possess a\ncriticality property. As a result, Autonomous Level requires a deep\nunderstanding of the task's underlying mechanisms. Current AI systems, however,\ndo not fully grasp these mechanisms and instead rely on superficial mimicry,\nmaking it difficult for them to reach an autonomous level. We believe Survival\nGame can not only guide the future development of AI but also offer profound\ninsights into human intelligence.\n","authors":["Jingtao Zhan","Jiahao Zhao","Jiayu Li","Yiqun Liu","Bo Zhang","Qingyao Ai","Jiaxin Mao","Hongning Wang","Min Zhang","Shaoping Ma"],"pdf_url":"https://arxiv.org/pdf/2502.18858v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.07596v2","updated":"2025-03-03T13:27:01Z","published":"2025-01-10T01:42:43Z","title":"Optimize Incompatible Parameters through Compatibility-aware Knowledge\n  Integration","summary":"  Deep neural networks have become foundational to advancements in multiple\ndomains, including recommendation systems, natural language processing, and so\non. Despite their successes, these models often contain incompatible parameters\nthat can be underutilized or detrimental to model performance, particularly\nwhen faced with specific, varying data distributions. Existing research excels\nin removing such parameters or merging the outputs of multiple different\npretrained models. However, the former focuses on efficiency rather than\nperformance, while the latter requires several times more computing and storage\nresources to support inference. In this paper, we set the goal to explicitly\nimprove these incompatible parameters by leveraging the complementary strengths\nof different models, thereby directly enhancing the models without any\nadditional parameters. Specifically, we propose Compatibility-aware Knowledge\nIntegration (CKI), which consists of Parameter Compatibility Assessment and\nParameter Splicing, which are used to evaluate the knowledge content of\nmultiple models and integrate the knowledge into one model, respectively. The\nintegrated model can be used directly for inference or for further fine-tuning.\nWe conduct extensive experiments on various datasets for recommendation and\nlanguage tasks, and the results show that Compatibility-aware Knowledge\nIntegration can effectively optimize incompatible parameters under multiple\ntasks and settings to break through the training limit of the original model\nwithout increasing the inference cost.\n","authors":["Zheqi Lv","Keming Ye","Zishu Wei","Qi Tian","Shengyu Zhang","Wenqiao Zhang","Wenjie Wang","Kun Kuang","Tat-Seng Chua","Fei Wu"],"pdf_url":"https://arxiv.org/pdf/2501.07596v2.pdf","comment":"Published on AAAI'25(Oral): The Annual AAAI Conference on Artificial\n  Intelligence"},{"id":"http://arxiv.org/abs/2502.17494v4","updated":"2025-03-03T22:21:09Z","published":"2025-02-20T22:35:52Z","title":"External Large Foundation Model: How to Efficiently Serve Trillions of\n  Parameters for Online Ads Recommendation","summary":"  Ads recommendation is a prominent service of online advertising systems and\nhas been actively studied. Recent studies indicate that scaling-up and advanced\ndesign of the recommendation model can bring significant performance\nimprovement. However, with a larger model scale, such prior studies have a\nsignificantly increasing gap from industry as they often neglect two\nfundamental challenges in industrial-scale applications. First, training and\ninference budgets are restricted for the model to be served, exceeding which\nmay incur latency and impair user experience. Second, large-volume data arrive\nin a streaming mode with data distributions dynamically shifting, as new\nusers/ads join and existing users/ads leave the system. We propose the External\nLarge Foundation Model (ExFM) framework to address the overlooked challenges.\nSpecifically, we develop external distillation and a data augmentation system\n(DAS) to control the computational cost of training/inference while maintaining\nhigh performance. We design the teacher in a way like a foundation model (FM)\nthat can serve multiple students as vertical models (VMs) to amortize its\nbuilding cost. We propose Auxiliary Head and Student Adapter to mitigate the\ndata distribution gap between FM and VMs caused by the streaming data issue.\nComprehensive experiments on internal industrial-scale applications and public\ndatasets demonstrate significant performance gain by ExFM.\n","authors":["Mingfu Liang","Xi Liu","Rong Jin","Boyang Liu","Qiuling Suo","Qinghai Zhou","Song Zhou","Laming Chen","Hua Zheng","Zhiyuan Li","Shali Jiang","Jiyan Yang","Xiaozhen Xia","Fan Yang","Yasmine Badr","Ellie Wen","Shuyu Xu","Hansey Chen","Zhengyu Zhang","Jade Nie","Chunzhi Yang","Zhichen Zeng","Weilin Zhang","Xingliang Huang","Qianru Li","Shiquan Wang","Evelyn Lyu","Wenjing Lu","Rui Zhang","Wenjun Wang","Jason Rudy","Mengyue Hang","Kai Wang","Yinbin Ma","Shuaiwen Wang","Sihan Zeng","Tongyi Tang","Xiaohan Wei","Longhao Jin","Jamey Zhang","Marcus Chen","Jiayi Zhang","Angie Huang","Chi Zhang","Zhengli Zhao","Jared Yang","Qiang Jin","Xian Chen","Amit Anand Amlesahwaram","Lexi Song","Liang Luo","Yuchen Hao","Nan Xiao","Yavuz Yetim","Luoshang Pan","Gaoxiang Liu","Yuxi Hu","Yuzhen Huang","Jackie Xu","Rich Zhu","Xin Zhang","Yiqun Liu","Hang Yin","Yuxin Chen","Buyun Zhang","Xiaoyi Liu","Xingyuan Wang","Wenguang Mao","Zhijing Li","Qin Huang","Chonglin Sun","Nancy Yu","Shuo Gu","Shupin Mao","Benjamin Au","Jingzheng Qin","Peggy Yao","Jae-Woo Choi","Bin Gao","Ernest Wang","Lei Zhang","Wen-Yen Chen","Ted Lee","Jay Zha","Yi Meng","Alex Gong","Edison Gao","Alireza Vahdatpour","Yiping Han","Yantao Yao","Toshinari Kureha","Shuo Chang","Musharaf Sultan","John Bocharov","Sagar Chordia","Xiaorui Gan","Peng Sun","Rocky Liu","Bo Long","Wenlin Chen","Santanu Kolay","Huayu Li"],"pdf_url":"https://arxiv.org/pdf/2502.17494v4.pdf","comment":"Accepted by the ACM Web Conference (WWW) 2025 Industrial Track as\n  Oral Presentation"},{"id":"http://arxiv.org/abs/2408.01262v5","updated":"2025-03-03T22:45:57Z","published":"2024-08-02T13:35:11Z","title":"RAGEval: Scenario Specific RAG Evaluation Dataset Generation Framework","summary":"  Retrieval-Augmented Generation (RAG) is a powerful approach that enables\nlarge language models (LLMs) to incorporate external knowledge. However,\nevaluating the effectiveness of RAG systems in specialized scenarios remains\nchallenging due to the high costs of data construction and the lack of suitable\nevaluation metrics. This paper introduces RAGEval, a framework designed to\nassess RAG systems across diverse scenarios by generating high-quality\ndocuments, questions, answers, and references through a schema-based pipeline.\nWith a focus on factual accuracy, we propose three novel metrics: Completeness,\nHallucination, and Irrelevance to evaluate LLM generated responses rigorously.\nExperimental results show that RAGEval outperforms zero-shot and one-shot\nmethods in terms of clarity, safety, conformity, and richness of generated\nsamples. Furthermore, the use of LLMs for scoring the proposed metrics\ndemonstrates a high level of consistency with human evaluations. RAGEval\nestablishes a new paradigm for evaluating RAG systems in real-world\napplications. The code and dataset are released at\nhttps://github.com/OpenBMB/RAGEval.\n","authors":["Kunlun Zhu","Yifan Luo","Dingling Xu","Yukun Yan","Zhenghao Liu","Shi Yu","Ruobing Wang","Shuo Wang","Yishan Li","Nan Zhang","Xu Han","Zhiyuan Liu","Maosong Sun"],"pdf_url":"https://arxiv.org/pdf/2408.01262v5.pdf","comment":"https://github.com/OpenBMB/RAGEval"},{"id":"http://arxiv.org/abs/2503.02065v1","updated":"2025-03-03T21:39:15Z","published":"2025-03-03T21:39:15Z","title":"Survey Perspective: The Role of Explainable AI in Threat Intelligence","summary":"  The increasing reliance on AI-based security tools in Security Operations\nCenters (SOCs) has transformed threat detection and response, yet analysts\nfrequently struggle with alert overload, false positives, and lack of\ncontextual relevance. The inability to effectively analyze AI-generated\nsecurity alerts lead to inefficiencies in incident response and reduces trust\nin automated decision-making. In this paper, we show results and analysis of\nour investigation of how SOC analysts navigate AI-based alerts, their\nchallenges with current security tools, and how explainability (XAI) integrated\ninto their security workflows has the potential to become an effective decision\nsupport. In this vein, we conducted an industry survey. Using the survey\nresponses, we analyze how security analysts' process, retrieve, and prioritize\nalerts. Our findings indicate that most analysts have not yet adopted\nXAI-integrated tools, but they express high interest in attack attribution,\nconfidence scores, and feature contribution explanations to improve\ninterpretability, and triage efficiency. Based on our findings, we also propose\npractical design recommendations for XAI-enhanced security alert systems,\nenabling AI-based cybersecurity solutions to be more transparent,\ninterpretable, and actionable.\n","authors":["Nidhi Rastogi","Devang Dhanuka","Amulya Saxena","Pranjal Mairal","Le Nguyen"],"pdf_url":"https://arxiv.org/pdf/2503.02065v1.pdf","comment":"5 pages, SIGIR Symposium on IR in Practice (SIRIP), 2025"},{"id":"http://arxiv.org/abs/2410.19302v2","updated":"2025-03-03T21:07:27Z","published":"2024-10-25T04:26:00Z","title":"TEARS: Textual Representations for Scrutable Recommendations","summary":"  Traditional recommender systems rely on high-dimensional (latent) embeddings\nfor modeling user-item interactions, often resulting in opaque representations\nthat lack interpretability. Moreover, these systems offer limited control to\nusers over their recommendations. Inspired by recent work, we introduce TExtuAl\nRepresentations for Scrutable recommendations (TEARS) to address these\nchallenges. Instead of representing a user's interests through a latent\nembedding, TEARS encodes them in natural text, providing transparency and\nallowing users to edit them. To do so, TEARS uses a modern LLM to generate user\nsummaries based on user preferences. We find the summaries capture user\npreferences uniquely. Using these summaries, we take a hybrid approach where we\nuse an optimal transport procedure to align the summaries' representation with\nthe learned representation of a standard VAE for collaborative filtering. We\nfind this approach can surpass the performance of three popular VAE models\nwhile providing user-controllable recommendations. We also analyze the\ncontrollability of TEARS through three simulated user tasks to evaluate the\neffectiveness of a user editing its summary.\n","authors":["Emiliano Penaloza","Olivier Gouvert","Haolun Wu","Laurent Charlin"],"pdf_url":"https://arxiv.org/pdf/2410.19302v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01814v1","updated":"2025-03-03T18:41:59Z","published":"2025-03-03T18:41:59Z","title":"LLMInit: A Free Lunch from Large Language Models for Selective\n  Initialization of Recommendation","summary":"  Collaborative filtering models, particularly graph-based approaches, have\ndemonstrated strong performance in capturing user-item interactions for\nrecommendation systems. However, they continue to struggle in cold-start and\ndata-sparse scenarios. The emergence of large language models (LLMs) like GPT\nand LLaMA presents new possibilities for enhancing recommendation performance,\nespecially in cold-start settings. Despite their promise, LLMs pose challenges\nrelated to scalability and efficiency due to their high computational demands\nand limited ability to model complex user-item relationships effectively. In\nthis work, we introduce a novel perspective on leveraging LLMs for CF model\ninitialization. Through experiments, we uncover an embedding collapse issue\nwhen scaling CF models to larger embedding dimensions. To effectively harness\nlarge-scale LLM embeddings, we propose innovative selective initialization\nstrategies utilizing random, uniform, and variance-based index sampling. Our\ncomprehensive evaluation on multiple real-world datasets demonstrates\nsignificant performance gains across various CF models while maintaining a\nlower computational cost compared to existing LLM-based recommendation\napproaches.\n","authors":["Weizhi Zhang","Liangwei Yang","Wooseong Yang","Henry Peng Zou","Yuqing Liu","Ke Xu","Sourav Medya","Philip S. Yu"],"pdf_url":"https://arxiv.org/pdf/2503.01814v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01763v1","updated":"2025-03-03T17:37:16Z","published":"2025-03-03T17:37:16Z","title":"Retrieval Models Aren't Tool-Savvy: Benchmarking Tool Retrieval for\n  Large Language Models","summary":"  Tool learning aims to augment large language models (LLMs) with diverse\ntools, enabling them to act as agents for solving practical tasks. Due to the\nlimited context length of tool-using LLMs, adopting information retrieval (IR)\nmodels to select useful tools from large toolsets is a critical initial step.\nHowever, the performance of IR models in tool retrieval tasks remains\nunderexplored and unclear. Most tool-use benchmarks simplify this step by\nmanually pre-annotating a small set of relevant tools for each task, which is\nfar from the real-world scenarios. In this paper, we propose ToolRet, a\nheterogeneous tool retrieval benchmark comprising 7.6k diverse retrieval tasks,\nand a corpus of 43k tools, collected from existing datasets. We benchmark six\ntypes of models on ToolRet. Surprisingly, even the models with strong\nperformance in conventional IR benchmarks, exhibit poor performance on ToolRet.\nThis low retrieval quality degrades the task pass rate of tool-use LLMs. As a\nfurther step, we contribute a large-scale training dataset with over 200k\ninstances, which substantially optimizes the tool retrieval ability of IR\nmodels.\n","authors":["Zhengliang Shi","Yuhan Wang","Lingyong Yan","Pengjie Ren","Shuaiqiang Wang","Dawei Yin","Zhaochun Ren"],"pdf_url":"https://arxiv.org/pdf/2503.01763v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01713v1","updated":"2025-03-03T16:25:58Z","published":"2025-03-03T16:25:58Z","title":"SAGE: A Framework of Precise Retrieval for RAG","summary":"  Retrieval-augmented generation (RAG) has demonstrated significant proficiency\nin conducting question-answering (QA) tasks within a specified corpus.\nNonetheless, numerous failure instances of RAG in QA still exist. These\nfailures are not solely attributable to the limitations of Large Language\nModels (LLMs); instead, they predominantly arise from the retrieval of\ninaccurate information for LLMs due to two limitations: (1) Current RAG methods\nsegment the corpus without considering semantics, making it difficult to find\nrelevant context due to impaired correlation between questions and the\nsegments. (2) There is a trade-off between missing essential context with fewer\ncontext retrieved and getting irrelevant context with more context retrieved.\n  In this paper, we introduce a RAG framework (SAGE), to overcome these\nlimitations. First, to address the segmentation issue without considering\nsemantics, we propose to train a semantic segmentation model. This model is\ntrained to segment the corpus into semantically complete chunks. Second, to\nensure that only the most relevant chunks are retrieved while the irrelevant\nones are ignored, we design a chunk selection algorithm to dynamically select\nchunks based on the decreasing speed of the relevance score, leading to a more\nrelevant selection. Third, to further ensure the precision of the retrieved\nchunks, we propose letting LLMs assess whether retrieved chunks are excessive\nor lacking and then adjust the amount of context accordingly. Experiments show\nthat SAGE outperforms baselines by 61.25% in the quality of QA on average.\nMoreover, by avoiding retrieving noisy context, SAGE lowers the cost of the\ntokens consumed in LLM inference and achieves a 49.41% enhancement in cost\nefficiency on average. Additionally, our work offers valuable insights for\nboosting RAG.\n","authors":["Jintao Zhang","Guoliang Li","Jinyang Su"],"pdf_url":"https://arxiv.org/pdf/2503.01713v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01670v1","updated":"2025-03-03T15:42:57Z","published":"2025-03-03T15:42:57Z","title":"Evaluating LLMs' Assessment of Mixed-Context Hallucination Through the\n  Lens of Summarization","summary":"  With the rapid development of large language models (LLMs), LLM-as-a-judge\nhas emerged as a widely adopted approach for text quality evaluation, including\nhallucination evaluation. While previous studies have focused exclusively on\nsingle-context evaluation (e.g., discourse faithfulness or world factuality),\nreal-world hallucinations typically involve mixed contexts, which remains\ninadequately evaluated. In this study, we use summarization as a representative\ntask to comprehensively evaluate LLMs' capability in detecting mixed-context\nhallucinations, specifically distinguishing between factual and non-factual\nhallucinations. Through extensive experiments across direct generation and\nretrieval-based models of varying scales, our main observations are: (1) LLMs'\nintrinsic knowledge introduces inherent biases in hallucination evaluation; (2)\nThese biases particularly impact the detection of factual hallucinations,\nyielding a significant performance bottleneck; (3) The fundamental challenge\nlies in effective knowledge utilization, balancing between LLMs' intrinsic\nknowledge and external context for accurate mixed-context hallucination\nevaluation.\n","authors":["Siya Qi","Rui Cao","Yulan He","Zheng Yuan"],"pdf_url":"https://arxiv.org/pdf/2503.01670v1.pdf","comment":"8 pages, 5 figures for main body"},{"id":"http://arxiv.org/abs/2503.01658v1","updated":"2025-03-03T15:32:02Z","published":"2025-03-03T15:32:02Z","title":"CoPL: Collaborative Preference Learning for Personalizing LLMs","summary":"  Personalizing large language models (LLMs) is important for aligning outputs\nwith diverse user preferences, yet existing methods struggle with flexibility\nand generalization. We propose CoPL (Collaborative Preference Learning), a\ngraph-based collaborative filtering framework that models user-response\nrelationships to enhance preference estimation, particularly in sparse\nannotation settings. By integrating a mixture of LoRA experts, CoPL efficiently\nfine-tunes LLMs while dynamically balancing shared and user-specific\npreferences. Additionally, an optimization-free adaptation strategy enables\ngeneralization to unseen users without fine-tuning. Experiments on\nUltraFeedback-P demonstrate that CoPL outperforms existing personalized reward\nmodels, effectively capturing both common and controversial preferences, making\nit a scalable solution for personalized LLM alignment.\n","authors":["Youngbin Choi","Seunghyuk Cho","Minjong Lee","MoonJeong Park","Yesong Ko","Jungseul Ok","Dongwoo Kim"],"pdf_url":"https://arxiv.org/pdf/2503.01658v1.pdf","comment":"13pages, 4 figures, 6tables"},{"id":"http://arxiv.org/abs/2503.01442v1","updated":"2025-03-03T11:48:01Z","published":"2025-03-03T11:48:01Z","title":"Leveraging LLMs for Mental Health: Detection and Recommendations from\n  Social Discussions","summary":"  Textual data from social platforms captures various aspects of mental health\nthrough discussions around and across issues, while users reach out for help\nand others sympathize and offer support. We propose a comprehensive framework\nthat leverages Natural Language Processing (NLP) and Generative AI techniques\nto identify and assess mental health disorders, detect their severity, and\ncreate recommendations for behavior change and therapeutic interventions based\non users' posts on Reddit.\n  To classify the disorders, we use rule-based labeling methods as well as\nadvanced pre-trained NLP models to extract nuanced semantic features from the\ndata. We fine-tune domain-adapted and generic pre-trained NLP models based on\npredictions from specialized Large Language Models (LLMs) to improve\nclassification accuracy. Our hybrid approach combines the generalization\ncapabilities of pre-trained models with the domain-specific insights captured\nby LLMs, providing an improved understanding of mental health discourse. Our\nfindings highlight the strengths and limitations of each model, offering\nvaluable insights into their practical applicability.\n  This research potentially facilitates early detection and personalized care\nto aid practitioners and aims to facilitate timely interventions and improve\noverall well-being, thereby contributing to the broader field of mental health\nsurveillance and digital health analytics.\n","authors":["Vaishali Aggarwal","Sachin Thukral","Krushil Patel","Arnab Chatterjee"],"pdf_url":"https://arxiv.org/pdf/2503.01442v1.pdf","comment":"5 pages, 4 figures, 3 tables, to be published in WI-IAT 2024"},{"id":"http://arxiv.org/abs/2503.01362v1","updated":"2025-03-03T09:55:54Z","published":"2025-03-03T09:55:54Z","title":"Streaming Piano Transcription Based on Consistent Onset and Offset\n  Decoding with Sustain Pedal Detection","summary":"  This paper describes a streaming audio-to-MIDI piano transcription approach\nthat aims to sequentially translate a music signal into a sequence of note\nonset and offset events. The sequence-to-sequence nature of this task may call\nfor the computationally-intensive transformer model for better performance,\nwhich has recently been used for offline transcription benchmarks and could be\nextended for streaming transcription with causal attention mechanisms. We\nassume that the performance limitation of this naive approach lies in the\ndecoder. Although time-frequency features useful for onset detection are\nconsiderably different from those for offset detection, the single decoder is\ntrained to output a mixed sequence of onset and offset events without guarantee\nof the correspondence between the onset and offset events of the same note. To\novercome this limitation, we propose a streaming encoder-decoder model that\nuses a convolutional encoder aggregating local acoustic features, followed by\nan autoregressive Transformer decoder detecting a variable number of onset\nevents and another decoder detecting the offset events for the active pitches\nwith validation of the sustain pedal at each time frame. Experiments using the\nMAESTRO dataset showed that the proposed streaming method performed comparably\nwith or even better than the state-of-the-art offline methods while\nsignificantly reducing the computational cost.\n","authors":["Weixing Wei","Jiahao Zhao","Yulun Wu","Kazuyoshi Yoshii"],"pdf_url":"https://arxiv.org/pdf/2503.01362v1.pdf","comment":"Accepted to ISMIR 2024"},{"id":"http://arxiv.org/abs/2503.01346v1","updated":"2025-03-03T09:37:33Z","published":"2025-03-03T09:37:33Z","title":"SRAG: Structured Retrieval-Augmented Generation for Multi-Entity\n  Question Answering over Wikipedia Graph","summary":"  Multi-entity question answering (MEQA) poses significant challenges for large\nlanguage models (LLMs), which often struggle to consolidate scattered\ninformation across multiple documents. An example question might be \"What is\nthe distribution of IEEE Fellows among various fields of study?\", which\nrequires retrieving information from diverse sources e.g., Wikipedia pages. The\neffectiveness of current retrieval-augmented generation (RAG) methods is\nlimited by the LLMs' capacity to aggregate insights from numerous pages. To\naddress this gap, this paper introduces a structured RAG (SRAG) framework that\nsystematically organizes extracted entities into relational tables (e.g.,\ntabulating entities with schema columns like \"name\" and \"field of study\") and\nthen apply table-based reasoning techniques. Our approach decouples retrieval\nand reasoning, enabling LLMs to focus on structured data analysis rather than\nraw text aggregation. Extensive experiments on Wikipedia-based multi-entity QA\ntasks demonstrate that SRAG significantly outperforms state-of-the-art\nlong-context LLMs and RAG solutions, achieving a 29.6% improvement in accuracy.\nThe results underscore the efficacy of structuring unstructured data to enhance\nLLMs' reasoning capabilities.\n","authors":["Teng Lin","Yizhang Zhu","Yuyu Luo","Nan Tang"],"pdf_url":"https://arxiv.org/pdf/2503.01346v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01334v1","updated":"2025-03-03T09:18:43Z","published":"2025-03-03T09:18:43Z","title":"Composed Multi-modal Retrieval: A Survey of Approaches and Applications","summary":"  With the rapid growth of multi-modal data from social media, short video\nplatforms, and e-commerce, content-based retrieval has become essential for\nefficiently searching and utilizing heterogeneous information. Over time,\nretrieval techniques have evolved from Unimodal Retrieval (UR) to Cross-modal\nRetrieval (CR) and, more recently, to Composed Multi-modal Retrieval (CMR). CMR\nenables users to retrieve images or videos by integrating a reference visual\ninput with textual modifications, enhancing search flexibility and precision.\nThis paper provides a comprehensive review of CMR, covering its fundamental\nchallenges, technical advancements, and categorization into supervised,\nzero-shot, and semi-supervised learning paradigms. We discuss key research\ndirections, including data augmentation, model architecture, and loss\noptimization in supervised CMR, as well as transformation frameworks and\nexternal knowledge integration in zero-shot CMR. Additionally, we highlight the\napplication potential of CMR in composed image retrieval, video retrieval, and\nperson retrieval, which have significant implications for e-commerce, online\nsearch, and public security. Given its ability to refine and personalize search\nexperiences, CMR is poised to become a pivotal technology in next-generation\nretrieval systems. A curated list of related works and resources is available\nat: https://github.com/kkzhang95/Awesome-Composed-Multi-modal-Retrieval\n","authors":["Kun Zhang","Jingyu Li","Zhe Li","Jingjing Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.01334v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01305v1","updated":"2025-03-03T08:43:40Z","published":"2025-03-03T08:43:40Z","title":"HI-Series Algorithms A Hybrid of Substance Diffusion Algorithm and\n  Collaborative Filtering","summary":"  Recommendation systems face the challenge of balancing accuracy and\ndiversity, as traditional collaborative filtering (CF) and network-based\ndiffusion algorithms exhibit complementary limitations. While item-based CF\n(ItemCF) enhances diversity through item similarity, it compromises accuracy.\nConversely, mass diffusion (MD) algorithms prioritize accuracy by favoring\npopular items but lack diversity. To address this trade-off, we propose the\nHI-series algorithms, hybrid models integrating ItemCF with diffusion-based\napproaches (MD, HHP, BHC, BD) through a nonlinear combination controlled by\nparameter $\\epsilon$. This hybridization leverages ItemCF's diversity and MD's\naccuracy, extending to advanced diffusion models (HI-HHP, HI-BHC, HI-BD) for\nenhanced performance. Experiments on MovieLens, Netflix, and RYM datasets\ndemonstrate that HI-series algorithms significantly outperform their base\ncounterparts. In sparse data ($20\\%$ training), HI-MD achieves a\n$0.8\\%$-$4.4\\%$ improvement in F1-score over MD while maintaining higher\ndiversity (Diversity@20: 459 vs. 396 on MovieLens). For dense data ($80\\%$\ntraining), HI-BD improves F1-score by $2.3\\%$-$5.2\\%$ compared to BD, with\ndiversity gains up to $18.6\\%$. Notably, hybrid models consistently enhance\nnovelty in sparse settings and exhibit robust parameter adaptability. The\nresults validate that strategic hybridization effectively breaks the\naccuracy-diversity trade-off, offering a flexible framework for optimizing\nrecommendation systems across data sparsity levels.\n","authors":["Yu Peng","Ya-Hui An"],"pdf_url":"https://arxiv.org/pdf/2503.01305v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01194v1","updated":"2025-03-03T05:41:16Z","published":"2025-03-03T05:41:16Z","title":"Cancer Type, Stage and Prognosis Assessment from Pathology Reports using\n  LLMs","summary":"  Large Language Models (LLMs) have shown significant promise across various\nnatural language processing tasks. However, their application in the field of\npathology, particularly for extracting meaningful insights from unstructured\nmedical texts such as pathology reports, remains underexplored and not well\nquantified. In this project, we leverage state-of-the-art language models,\nincluding the GPT family, Mistral models, and the open-source Llama models, to\nevaluate their performance in comprehensively analyzing pathology reports.\nSpecifically, we assess their performance in cancer type identification, AJCC\nstage determination, and prognosis assessment, encompassing both information\nextraction and higher-order reasoning tasks. Based on a detailed analysis of\ntheir performance metrics in a zero-shot setting, we developed two\ninstruction-tuned models: Path-llama3.1-8B and Path-GPT-4o-mini-FT. These\nmodels demonstrated superior performance in zero-shot cancer type\nidentification, staging, and prognosis assessment compared to the other models\nevaluated.\n","authors":["Rachit Saluja","Jacob Rosenthal","Yoav Artzi","David J. Pisapia","Benjamin L. Liechty","Mert R. Sabuncu"],"pdf_url":"https://arxiv.org/pdf/2503.01194v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01151v1","updated":"2025-03-03T03:57:04Z","published":"2025-03-03T03:57:04Z","title":"ReaderLM-v2: Small Language Model for HTML to Markdown and JSON","summary":"  We present ReaderLM-v2, a compact 1.5 billion parameter language model\ndesigned for efficient web content extraction. Our model processes documents up\nto 512K tokens, transforming messy HTML into clean Markdown or JSON formats\nwith high accuracy -- making it an ideal tool for grounding large language\nmodels. The model's effectiveness results from two key innovations: (1) a\nthree-stage data synthesis pipeline that generates high quality, diverse\ntraining data by iteratively drafting, refining, and critiquing web content\nextraction; and (2) a unified training framework combining continuous\npre-training with multi-objective optimization. Intensive evaluation\ndemonstrates that ReaderLM-v2 outperforms GPT-4o-2024-08-06 and other larger\nmodels by 15-20\\% on carefully curated benchmarks, particularly excelling at\ndocuments exceeding 100K tokens, while maintaining significantly lower\ncomputational requirements.\n","authors":["Feng Wang","Zesheng Shi","Bo Wang","Nan Wang","Han Xiao"],"pdf_url":"https://arxiv.org/pdf/2503.01151v1.pdf","comment":"9 pages, 10-12 refs"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2502.06786v3","updated":"2025-03-03T17:54:53Z","published":"2025-02-10T18:59:10Z","title":"Matryoshka Quantization","summary":"  Quantizing model weights is critical for reducing the communication and\ninference costs of large models. However, quantizing models -- especially to\nlow precisions like int4 or int2 -- requires a trade-off in model quality;\nint2, in particular, is known to severely degrade model quality. Consequently,\npractitioners are often forced to maintain multiple models with different\nquantization levels or serve a single model that best satisfies the\nquality-latency trade-off. On the other hand, integer data types, such as int8,\ninherently possess a nested (Matryoshka) structure where smaller bit-width\nintegers, like int4 or int2, are nested within the most significant bits.\nLeveraging this insight, in this paper, we propose Matryoshka Quantization\n(MatQuant), a novel multi-scale quantization technique that alleviates the\naforementioned challenge. This technique allows us to train and maintain a\nsingle quantized model but serve it with the precision demanded by the\ndeployment. Furthermore, leveraging MatQuant's co-training and co-distillation\nregularization, int2 precision models extracted by MatQuant outperform standard\nint2 quantization by up to to 4% and 7% with OmniQuant and QAT as base\nalgorithms respectively. Finally, we demonstrate that by using an extra bit to\nrepresent outliers, a model with an effective precision of 2.05-bit gives an\nadditional 6% improvement with OmniQuant as the base algorithm.\n","authors":["Pranav Nair","Puranjay Datta","Jeff Dean","Prateek Jain","Aditya Kusupati"],"pdf_url":"https://arxiv.org/pdf/2502.06786v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.15823v3","updated":"2025-03-03T16:38:10Z","published":"2025-02-20T03:48:00Z","title":"InductionBench: LLMs Fail in the Simplest Complexity Class","summary":"  Large language models (LLMs) have shown remarkable improvements in reasoning\nand many existing benchmarks have been addressed by models such as o1 and o3\neither fully or partially. However, a majority of these benchmarks emphasize\ndeductive reasoning, including mathematical and coding tasks in which rules\nsuch as mathematical axioms or programming syntax are clearly defined, based on\nwhich LLMs can plan and apply these rules to arrive at a solution. In contrast,\ninductive reasoning, where one infers the underlying rules from observed data,\nremains less explored. Such inductive processes lie at the heart of scientific\ndiscovery, as they enable researchers to extract general principles from\nempirical observations. To assess whether LLMs possess this capacity, we\nintroduce InductionBench, a new benchmark designed to evaluate the inductive\nreasoning ability of LLMs. Our experimental findings reveal that even the most\nadvanced models available struggle to master the simplest complexity classes\nwithin the subregular hierarchy of functions, highlighting a notable deficiency\nin current LLMs' inductive reasoning capabilities. Coda and data are available\nhttps://github.com/Wenyueh/inductive_reasoning_benchmark.\n","authors":["Wenyue Hua","Tyler Wong","Sun Fei","Liangming Pan","Adam Jardine","William Yang Wang"],"pdf_url":"https://arxiv.org/pdf/2502.15823v3.pdf","comment":"24 pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.22371v2","updated":"2025-03-03T16:16:00Z","published":"2024-10-28T23:25:55Z","title":"Error Bounds for Physics-Informed Neural Networks in Fokker-Planck PDEs","summary":"  Stochastic differential equations are commonly used to describe the evolution\nof stochastic processes. The state uncertainty of such processes is best\nrepresented by the probability density function (PDF), whose evolution is\ngoverned by the Fokker-Planck partial differential equation (FP-PDE). However,\nit is generally infeasible to solve the FP-PDE in closed form. In this work, we\nshow that physics-informed neural networks (PINNs) can be trained to\napproximate the solution PDF. Our main contribution is the analysis of PINN\napproximation error: we develop a theoretical framework to construct tight\nerror bounds using PINNs. In addition, we derive a practical error bound that\ncan be efficiently constructed with standard training methods. We discuss that\nthis error-bound framework generalizes to approximate solutions of other linear\nPDEs. Empirical results on nonlinear, high-dimensional, and chaotic systems\nvalidate the correctness of our error bounds while demonstrating the\nscalability of PINNs and their significant computational speedup in obtaining\naccurate PDF solutions compared to the Monte Carlo approach.\n","authors":["Chun-Wei Kong","Luca Laurenti","Jay McMahon","Morteza Lahijanian"],"pdf_url":"https://arxiv.org/pdf/2410.22371v2.pdf","comment":"paper under review"},{"id":"http://arxiv.org/abs/2502.18821v2","updated":"2025-03-03T16:12:50Z","published":"2025-02-26T04:52:31Z","title":"CAMEx: Curvature-aware Merging of Experts","summary":"  Existing methods for merging experts during model training and fine-tuning\npredominantly rely on Euclidean geometry, which assumes a flat parameter space.\nThis assumption can limit the model's generalization ability, especially during\nthe pre-training phase, where the parameter manifold might exhibit more complex\ncurvature. Curvature-aware merging methods typically require additional\ninformation and computational resources to approximate the Fisher Information\nMatrix, adding memory overhead. In this paper, we introduce CAMEx\n(Curvature-Aware Merging of Experts), a novel expert merging protocol that\nincorporates natural gradients to account for the non-Euclidean curvature of\nthe parameter manifold. By leveraging natural gradients, CAMEx adapts more\neffectively to the structure of the parameter space, improving alignment\nbetween model updates and the manifold's geometry. This approach enhances both\npre-training and fine-tuning, resulting in better optimization trajectories and\nimproved generalization without the substantial memory overhead typically\nassociated with curvature-aware methods. Our contributions are threefold: (1)\nCAMEx significantly outperforms traditional Euclidean-based expert merging\ntechniques across various natural language processing tasks, leading to\nenhanced performance during pre-training and fine-tuning; (2) we introduce a\ndynamic merging architecture that optimizes resource utilization, achieving\nhigh performance while reducing computational costs, facilitating efficient\nscaling of large language models; and (3) we provide both theoretical and\nempirical evidence to demonstrate the efficiency of our proposed method. The\ncode is publicly available at: https://github.com/kpup1710/CAMEx.\n","authors":["Dung V. Nguyen","Minh H. Nguyen","Luc Q. Nguyen","Rachel S. Y. Teo","Tan M. Nguyen","Linh Duy Tran"],"pdf_url":"https://arxiv.org/pdf/2502.18821v2.pdf","comment":"10 pages, 5 Figures, 7 Tables. Published at ICLR 2025"},{"id":"http://arxiv.org/abs/2412.19495v2","updated":"2025-03-03T16:05:29Z","published":"2024-12-27T07:31:14Z","title":"Disparate Model Performance and Stability in Machine Learning Clinical\n  Support for Diabetes and Heart Diseases","summary":"  Machine Learning (ML) algorithms are vital for supporting clinical\ndecision-making in biomedical informatics. However, their predictive\nperformance can vary across demographic groups, often due to the\nunderrepresentation of historically marginalized populations in training\ndatasets. The investigation reveals widespread sex- and age-related inequities\nin chronic disease datasets and their derived ML models. Thus, a novel\nanalytical framework is introduced, combining systematic arbitrariness with\ntraditional metrics like accuracy and data complexity. The analysis of data\nfrom over 25,000 individuals with chronic diseases revealed mild sex-related\ndisparities, favoring predictive accuracy for males, and significant\nage-related differences, with better accuracy for younger patients. Notably,\nolder patients showed inconsistent predictive accuracy across seven datasets,\nlinked to higher data complexity and lower model performance. This highlights\nthat representativeness in training data alone does not guarantee equitable\noutcomes, and model arbitrariness must be addressed before deploying models in\nclinical settings.\n","authors":["Ioannis Bilionis","Ricardo C. Berrios","Luis Fernandez-Luque","Carlos Castillo"],"pdf_url":"https://arxiv.org/pdf/2412.19495v2.pdf","comment":"This paper will be presented in American Medical Informatics\n  Association (AMIA) Informatics Summit Conference 2025 (Pittsburgh, PA). 10\n  pages, 2 figures, 5 tables"},{"id":"http://arxiv.org/abs/2501.11972v2","updated":"2025-03-03T15:45:44Z","published":"2025-01-21T08:34:10Z","title":"\"FRAME: Forward Recursive Adaptive Model Extraction-A Technique for\n  Advance Feature Selection\"","summary":"  The challenges in feature selection, particularly in balancing model\naccuracy, interpretability, and computational efficiency, remain a critical\nissue in advancing machine learning methodologies. To address these\ncomplexities, this study introduces a novel hybrid approach, the Forward\nRecursive Adaptive Model Extraction Technique (FRAME), which combines Forward\nSelection and Recursive Feature Elimination (RFE) to enhance feature selection\nacross diverse datasets. By combining the exploratory capabilities of Forward\nSelection with the refinement strengths of RFE, FRAME systematically identifies\noptimal feature subsets, striking a harmonious trade-off between\nexperimentation and precision. A comprehensive evaluation of FRAME is conducted\nagainst traditional methods such as SelectKBest and Lasso Regression, using\nhigh-dimensional, noisy, and heterogeneous datasets. The results demonstrate\nthat FRAME consistently delivers superior predictive performance based on\ndownstream machine learning evaluation metrics. It efficiently performs\ndimensionality reduction with strong model performance, thus being especially\nuseful for applications that need interpretable and accurate predictions, e.g.,\nbiomedical diagnostics.\n  This research emphasizes the need to evaluate feature selection techniques on\ndiverse datasets to test their robustness and generalizability. The results\nindicate that FRAME has great potential for further development, especially by\nincorporating deep learning frameworks for adaptive and real-time feature\nselection in dynamic settings. By advancing feature selection methodologies,\nFRAME offers a practical and effective solution to improve machine learning\napplications across multiple domains.\n","authors":["Nachiket Kapure","Harsh Joshi","Parul Kumari","Rajeshwari Mistri","Manasi Mali"],"pdf_url":"https://arxiv.org/pdf/2501.11972v2.pdf","comment":"Updated version with refinements before JMLR submission. Improved\n  clarity, expanded literature review, refined methodology, updated\n  experimental results, and enhanced conclusion. FRAME's scalability, deep\n  learning integration, and real-world applications are further highlighted"},{"id":"http://arxiv.org/abs/2412.14663v2","updated":"2025-03-03T15:32:17Z","published":"2024-12-19T09:14:24Z","title":"IOHunter: Graph Foundation Model to Uncover Online Information\n  Operations","summary":"  Social media platforms have become vital spaces for public discourse, serving\nas modern agor\\`as where a wide range of voices influence societal narratives.\nHowever, their open nature also makes them vulnerable to exploitation by\nmalicious actors, including state-sponsored entities, who can conduct\ninformation operations (IOs) to manipulate public opinion. The spread of\nmisinformation, false news, and misleading claims threatens democratic\nprocesses and societal cohesion, making it crucial to develop methods for the\ntimely detection of inauthentic activity to protect the integrity of online\ndiscourse. In this work, we introduce a methodology designed to identify users\norchestrating information operations, a.k.a. IO drivers, across various\ninfluence campaigns. Our framework, named IOHunter, leverages the combined\nstrengths of Language Models and Graph Neural Networks to improve\ngeneralization in supervised, scarcely-supervised, and cross-IO contexts. Our\napproach achieves state-of-the-art performance across multiple sets of IOs\noriginating from six countries, significantly surpassing existing approaches.\nThis research marks a step toward developing Graph Foundation Models\nspecifically tailored for the task of IO detection on social media platforms.\n","authors":["Marco Minici","Luca Luceri","Francesco Fabbri","Emilio Ferrara"],"pdf_url":"https://arxiv.org/pdf/2412.14663v2.pdf","comment":"Accepted at AAAI 2025"},{"id":"http://arxiv.org/abs/2502.19210v2","updated":"2025-03-03T15:32:09Z","published":"2025-02-26T15:13:08Z","title":"Langevin Multiplicative Weights Update with Applications in Polynomial\n  Portfolio Management","summary":"  We consider nonconvex optimization problem over simplex, and more generally,\na product of simplices. We provide an algorithm, Langevin Multiplicative\nWeights Update (LMWU) for solving global optimization problems by adding a\nnoise scaling with the non-Euclidean geometry in the simplex. Non-convex\noptimization has been extensively studied by machine learning community due to\nits application in various scenarios such as neural network approximation and\nfinding Nash equilibrium. Despite recent progresses on provable guarantee of\nescaping and avoiding saddle point (convergence to local minima) and global\nconvergence of Langevin gradient based method without constraints, the global\noptimization with constraints is less studied. We show that LMWU algorithm is\nprovably convergent to interior global minima with a non-asymptotic convergence\nanalysis. We verify the efficiency of the proposed algorithm in real data set\nfrom polynomial portfolio management, where optimization of a highly non-linear\nobjective function plays a crucial role.\n","authors":["Yi Feng","Xiao Wang","Tian Xie"],"pdf_url":"https://arxiv.org/pdf/2502.19210v2.pdf","comment":"Accepted for AAAI-2025"},{"id":"http://arxiv.org/abs/2502.12215v2","updated":"2025-03-03T15:29:43Z","published":"2025-02-17T07:21:11Z","title":"Revisiting the Test-Time Scaling of o1-like Models: Do they Truly\n  Possess Test-Time Scaling Capabilities?","summary":"  The advent of test-time scaling in large language models (LLMs), exemplified\nby OpenAI's o1 series, has advanced reasoning capabilities by scaling\ncomputational resource allocation during inference. While successors like QwQ,\nDeepseek-R1 (R1) and LIMO replicate these advancements, whether these models\ntruly possess test-time scaling capabilities remains underexplored. This study\nfound that longer CoTs of these o1-like models do not consistently enhance\naccuracy; in fact, correct solutions are often shorter than incorrect ones for\nthe same questions. Further investigation shows this phenomenon is closely\nrelated to models' self-revision capabilities - longer CoTs contain more\nself-revisions, which often lead to performance degradation. We then compare\nsequential and parallel scaling strategies on QwQ, R1 and LIMO, finding that\nparallel scaling achieves better coverage and scalability. Based on these\ninsights, we propose Shortest Majority Vote, a method that combines parallel\nscaling strategies with CoT length characteristics, significantly improving\nmodels' test-time scalability compared to conventional majority voting\napproaches.\n","authors":["Zhiyuan Zeng","Qinyuan Cheng","Zhangyue Yin","Yunhua Zhou","Xipeng Qiu"],"pdf_url":"https://arxiv.org/pdf/2502.12215v2.pdf","comment":"Add the github link"},{"id":"http://arxiv.org/abs/2501.10945v2","updated":"2025-03-03T15:09:31Z","published":"2025-01-19T04:56:55Z","title":"Gradient-Based Multi-Objective Deep Learning: Algorithms, Theories,\n  Applications, and Beyond","summary":"  Multi-objective optimization (MOO) in deep learning aims to simultaneously\noptimize multiple conflicting objectives, a challenge frequently encountered in\nareas like multi-task learning and multi-criteria learning. Recent advancements\nin gradient-based MOO methods have enabled the discovery of diverse types of\nsolutions, ranging from a single balanced solution to finite or even infinite\nPareto sets, tailored to user needs. These developments have broad applications\nacross domains such as reinforcement learning, computer vision, recommendation\nsystems, and large language models. This survey provides the first\ncomprehensive review of gradient-based MOO in deep learning, covering\nalgorithms, theories, and practical applications. By unifying various\napproaches and identifying critical challenges, it serves as a foundational\nresource for driving innovation in this evolving field. A comprehensive list of\nMOO algorithms in deep learning is available at\nhttps://github.com/Baijiong-Lin/Awesome-Multi-Objective-Deep-Learning.\n","authors":["Weiyu Chen","Xiaoyuan Zhang","Baijiong Lin","Xi Lin","Han Zhao","Qingfu Zhang","James T. Kwok"],"pdf_url":"https://arxiv.org/pdf/2501.10945v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.11561v2","updated":"2025-03-03T15:04:03Z","published":"2024-08-21T12:15:20Z","title":"Self-Supervised Iterative Refinement for Anomaly Detection in Industrial\n  Quality Control","summary":"  This study introduces the Iterative Refinement Process (IRP), a robust\nanomaly detection methodology designed for high-stakes industrial quality\ncontrol. The IRP enhances defect detection accuracy through a cyclic data\nrefinement strategy, iteratively removing misleading data points to improve\nmodel performance and robustness. We validate the IRP's effectiveness using two\nbenchmark datasets, Kolektor SDD2 (KSDD2) and MVTec AD, covering a wide range\nof industrial products and defect types. Our experimental results demonstrate\nthat the IRP consistently outperforms traditional anomaly detection models,\nparticularly in environments with high noise levels. This study highlights the\nIRP's potential to significantly enhance anomaly detection processes in\nindustrial settings, effectively managing the challenges of sparse and noisy\ndata.\n","authors":["Muhammad Aqeel","Shakiba Sharifi","Marco Cristani","Francesco Setti"],"pdf_url":"https://arxiv.org/pdf/2408.11561v2.pdf","comment":"Accepted to VISAPP 2025"},{"id":"http://arxiv.org/abs/2502.10784v2","updated":"2025-03-03T15:02:37Z","published":"2025-02-15T12:28:51Z","title":"Preconditioned Inexact Stochastic ADMM for Deep Model","summary":"  The recent advancement of foundation models (FMs) has brought about a\nparadigm shift, revolutionizing various sectors worldwide. The popular\noptimizers used to train these models are stochastic gradient descent-based\nalgorithms, which face inherent limitations, such as slow convergence and\nstringent assumptions for convergence. In particular, data heterogeneity\narising from distributed settings poses significant challenges to their\ntheoretical and numerical performance. This paper develops an algorithm, PISA\n({P}reconditioned {I}nexact {S}tochastic {A}lternating Direction Method of\nMultipliers), which enables scalable parallel computing and supports various\nsecond-moment schemes. Grounded in rigorous theoretical guarantees, the\nalgorithm converges under the sole assumption of Lipschitz continuity of the\ngradient, thereby removing the need for other conditions commonly imposed by\nstochastic methods. This capability enables PISA to tackle the challenge of\ndata heterogeneity effectively. Comprehensive experimental evaluations for\ntraining or fine-tuning diverse FMs, including vision models, large language\nmodels, reinforcement learning models, generative adversarial networks, and\nrecurrent neural networks, demonstrate its superior numerical performance\ncompared to various state-of-the-art optimizers.\n","authors":["Shenglong Zhou","Ouya Wang","Ziyan Luo","Yongxu Zhu","Geoffrey Ye Li"],"pdf_url":"https://arxiv.org/pdf/2502.10784v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07180v4","updated":"2025-03-03T14:56:17Z","published":"2024-11-11T17:57:30Z","title":"Gumbel Counterfactual Generation From Language Models","summary":"  Understanding and manipulating the causal generation mechanisms in language\nmodels is essential for controlling their behavior. Previous work has primarily\nrelied on techniques such as representation surgery -- e.g., model ablations or\nmanipulation of linear subspaces tied to specific concepts -- to\n\\emph{intervene} on these models. To understand the impact of interventions\nprecisely, it is useful to examine \\emph{counterfactuals} -- e.g., how a given\nsentence would have appeared had it been generated by the model following a\nspecific intervention. We highlight that counterfactual reasoning is\nconceptually distinct from interventions, as articulated in Pearl's causal\nhierarchy. Based on this observation, we propose a framework for generating\ntrue string counterfactuals by reformulating language models as a structural\nequation model using the Gumbel-max trick, which we called Gumbel\ncounterfactual generation. This reformulation allows us to model the joint\ndistribution over original strings and their counterfactuals resulting from the\nsame instantiation of the sampling noise. We develop an algorithm based on\nhindsight Gumbel sampling that allows us to infer the latent noise variables\nand generate counterfactuals of observed strings. Our experiments demonstrate\nthat the approach produces meaningful counterfactuals while at the same time\nshowing that commonly used intervention techniques have considerable undesired\nside effects.\n","authors":["Shauli Ravfogel","Anej Svete","Vésteinn Snæbjarnarson","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2411.07180v4.pdf","comment":"Accepted in ICLR 2025"},{"id":"http://arxiv.org/abs/2409.13533v2","updated":"2025-03-03T14:40:34Z","published":"2024-09-20T14:23:05Z","title":"Using High-Level Patterns to Estimate How Humans Predict a Robot will\n  Behave","summary":"  Humans interacting with robots often form predictions of what the robot will\ndo next. For instance, based on the recent behavior of an autonomous car, a\nnearby human driver might predict that the car is going to remain in the same\nlane. It is important for the robot to understand the human's prediction for\nsafe and seamless interaction: e.g., if the autonomous car knows the human\nthinks it is not merging -- but the autonomous car actually intends to merge --\nthen the car can adjust its behavior to prevent an accident. Prior works\ntypically assume that humans make precise predictions of robot behavior.\nHowever, recent research on human-human prediction suggests the opposite:\nhumans tend to approximate other agents by predicting their high-level\nbehaviors. We apply this finding to develop a second-order theory of mind\napproach that enables robots to estimate how humans predict they will behave.\nTo extract these high-level predictions directly from data, we embed the recent\nhuman and robot trajectories into a discrete latent space. Each element of this\nlatent space captures a different type of behavior (e.g., merging in front of\nthe human, remaining in the same lane) and decodes into a vector field across\nthe state space that is consistent with the underlying behavior type. We\nhypothesize that our resulting high-level and course predictions of robot\nbehavior will correspond to actual human predictions. We provide initial\nevidence in support of this hypothesis through proof-of-concept simulations,\ntesting our method's predictions against those of real users, and experiments\non a real-world interactive driving dataset.\n","authors":["Sagar Parekh","Lauren Bramblett","Nicola Bezzo","Dylan P. Losey"],"pdf_url":"https://arxiv.org/pdf/2409.13533v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.23208v2","updated":"2025-03-03T14:29:16Z","published":"2024-10-30T16:59:41Z","title":"Kinetix: Investigating the Training of General Agents through Open-Ended\n  Physics-Based Control Tasks","summary":"  While large models trained with self-supervised learning on offline datasets\nhave shown remarkable capabilities in text and image domains, achieving the\nsame generalisation for agents that act in sequential decision problems remains\nan open challenge. In this work, we take a step towards this goal by\nprocedurally generating tens of millions of 2D physics-based tasks and using\nthese to train a general reinforcement learning (RL) agent for physical\ncontrol. To this end, we introduce Kinetix: an open-ended space of\nphysics-based RL environments that can represent tasks ranging from robotic\nlocomotion and grasping to video games and classic RL environments, all within\na unified framework. Kinetix makes use of our novel hardware-accelerated\nphysics engine Jax2D that allows us to cheaply simulate billions of environment\nsteps during training. Our trained agent exhibits strong physical reasoning\ncapabilities in 2D space, being able to zero-shot solve unseen human-designed\nenvironments. Furthermore, fine-tuning this general agent on tasks of interest\nshows significantly stronger performance than training an RL agent *tabula\nrasa*. This includes solving some environments that standard RL training\ncompletely fails at. We believe this demonstrates the feasibility of large\nscale, mixed-quality pre-training for online RL and we hope that Kinetix will\nserve as a useful framework to investigate this further.\n","authors":["Michael Matthews","Michael Beukman","Chris Lu","Jakob Foerster"],"pdf_url":"https://arxiv.org/pdf/2410.23208v2.pdf","comment":"ICLR 2025 Oral. The first two authors contributed equally. Project\n  page located at: https://kinetix-env.github.io/"},{"id":"http://arxiv.org/abs/2407.11734v2","updated":"2025-03-03T14:24:06Z","published":"2024-07-16T14:05:03Z","title":"Multi-Modal and Multi-Attribute Generation of Single Cells with CFGen","summary":"  Generative modeling of single-cell RNA-seq data is crucial for tasks like\ntrajectory inference, batch effect removal, and simulation of realistic\ncellular data. However, recent deep generative models simulating synthetic\nsingle cells from noise operate on pre-processed continuous gene expression\napproximations, overlooking the discrete nature of single-cell data, which\nlimits their effectiveness and hinders the incorporation of robust noise\nmodels. Additionally, aspects like controllable multi-modal and multi-label\ngeneration of cellular data remain underexplored. This work introduces CellFlow\nfor Generation (CFGen), a flow-based conditional generative model that\npreserves the inherent discreteness of single-cell data. CFGen generates\nwhole-genome multi-modal single-cell data reliably, improving the recovery of\ncrucial biological data characteristics while tackling relevant generative\ntasks such as rare cell type augmentation and batch correction. We also\nintroduce a novel framework for compositional data generation using Flow\nMatching. By showcasing CFGen on a diverse set of biological datasets and\nsettings, we provide evidence of its value to the fields of computational\nbiology and deep generative models.\n","authors":["Alessandro Palma","Till Richter","Hanyi Zhang","Manuel Lubetzki","Alexander Tong","Andrea Dittadi","Fabian Theis"],"pdf_url":"https://arxiv.org/pdf/2407.11734v2.pdf","comment":"41 pages, 22 figures"},{"id":"http://arxiv.org/abs/2406.00987v2","updated":"2025-03-03T14:14:00Z","published":"2024-06-03T04:48:45Z","title":"Enhancing Fairness in Unsupervised Graph Anomaly Detection through\n  Disentanglement","summary":"  Graph anomaly detection (GAD) is increasingly crucial in various\napplications, ranging from financial fraud detection to fake news detection.\nHowever, current GAD methods largely overlook the fairness problem, which might\nresult in discriminatory decisions skewed toward certain demographic groups\ndefined on sensitive attributes (e.g., gender, religion, ethnicity, etc.). This\ngreatly limits the applicability of these methods in real-world scenarios in\nlight of societal and ethical restrictions. To address this critical gap, we\nmake the first attempt to integrate fairness with utility in GAD\ndecision-making. Specifically, we devise a novel DisEntangle-based\nFairnEss-aware aNomaly Detection framework on the attributed graph, named\nDEFEND. DEFEND first introduces disentanglement in GNNs to capture informative\nyet sensitive-irrelevant node representations, effectively reducing societal\nbias inherent in graph representation learning. Besides, to alleviate\ndiscriminatory bias in evaluating anomalous nodes, DEFEND adopts a\nreconstruction-based anomaly detection, which concentrates solely on node\nattributes without incorporating any graph structure. Additionally, given the\ninherent association between input and sensitive attributes, DEFEND constrains\nthe correlation between the reconstruction error and the predicted sensitive\nattributes. Our empirical evaluations on real-world datasets reveal that DEFEND\nperforms effectively in GAD and significantly enhances fairness compared to\nstate-of-the-art baselines. To foster reproducibility, our code is available at\nhttps://github.com/AhaChang/DEFEND.\n","authors":["Wenjing Chang","Kay Liu","Philip S. Yu","Jianjun Yu"],"pdf_url":"https://arxiv.org/pdf/2406.00987v2.pdf","comment":"Accepted to TMLR. Code available at\n  https://github.com/AhaChang/DEFEND"},{"id":"http://arxiv.org/abs/2410.15474v2","updated":"2025-03-03T14:08:48Z","published":"2024-10-20T19:12:14Z","title":"Optimizing Backward Policies in GFlowNets via Trajectory Likelihood\n  Maximization","summary":"  Generative Flow Networks (GFlowNets) are a family of generative models that\nlearn to sample objects with probabilities proportional to a given reward\nfunction. The key concept behind GFlowNets is the use of two stochastic\npolicies: a forward policy, which incrementally constructs compositional\nobjects, and a backward policy, which sequentially deconstructs them. Recent\nresults show a close relationship between GFlowNet training and\nentropy-regularized reinforcement learning (RL) problems with a particular\nreward design. However, this connection applies only in the setting of a fixed\nbackward policy, which might be a significant limitation. As a remedy to this\nproblem, we introduce a simple backward policy optimization algorithm that\ninvolves direct maximization of the value function in an entropy-regularized\nMarkov Decision Process (MDP) over intermediate rewards. We provide an\nextensive experimental evaluation of the proposed approach across various\nbenchmarks in combination with both RL and GFlowNet algorithms and demonstrate\nits faster convergence and mode discovery in complex environments.\n","authors":["Timofei Gritsaev","Nikita Morozov","Sergey Samsonov","Daniil Tiapkin"],"pdf_url":"https://arxiv.org/pdf/2410.15474v2.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2501.07596v2","updated":"2025-03-03T13:27:01Z","published":"2025-01-10T01:42:43Z","title":"Optimize Incompatible Parameters through Compatibility-aware Knowledge\n  Integration","summary":"  Deep neural networks have become foundational to advancements in multiple\ndomains, including recommendation systems, natural language processing, and so\non. Despite their successes, these models often contain incompatible parameters\nthat can be underutilized or detrimental to model performance, particularly\nwhen faced with specific, varying data distributions. Existing research excels\nin removing such parameters or merging the outputs of multiple different\npretrained models. However, the former focuses on efficiency rather than\nperformance, while the latter requires several times more computing and storage\nresources to support inference. In this paper, we set the goal to explicitly\nimprove these incompatible parameters by leveraging the complementary strengths\nof different models, thereby directly enhancing the models without any\nadditional parameters. Specifically, we propose Compatibility-aware Knowledge\nIntegration (CKI), which consists of Parameter Compatibility Assessment and\nParameter Splicing, which are used to evaluate the knowledge content of\nmultiple models and integrate the knowledge into one model, respectively. The\nintegrated model can be used directly for inference or for further fine-tuning.\nWe conduct extensive experiments on various datasets for recommendation and\nlanguage tasks, and the results show that Compatibility-aware Knowledge\nIntegration can effectively optimize incompatible parameters under multiple\ntasks and settings to break through the training limit of the original model\nwithout increasing the inference cost.\n","authors":["Zheqi Lv","Keming Ye","Zishu Wei","Qi Tian","Shengyu Zhang","Wenqiao Zhang","Wenjie Wang","Kun Kuang","Tat-Seng Chua","Fei Wu"],"pdf_url":"https://arxiv.org/pdf/2501.07596v2.pdf","comment":"Published on AAAI'25(Oral): The Annual AAAI Conference on Artificial\n  Intelligence"},{"id":"http://arxiv.org/abs/2411.17711v2","updated":"2025-03-03T13:19:42Z","published":"2024-11-17T17:32:58Z","title":"AnyECG: Foundational Models for Multitask Cardiac Analysis in Real-World\n  Settings","summary":"  Electrocardiogram (ECG), a non-invasive and affordable tool for cardiac\nmonitoring, is highly sensitive in detecting acute heart attacks. However, due\nto the lengthy nature of ECG recordings, numerous machine learning methods have\nbeen developed for automated heart disease detection to reduce human workload.\nDespite these efforts, performance remains suboptimal. A key obstacle is the\ninherent complexity of ECG data, which includes heterogeneity (e.g., varying\nsampling rates), high levels of noise, demographic-related pattern shifts, and\nintricate rhythm-event associations. To overcome these challenges, this paper\nintroduces AnyECG, a foundational model designed to extract robust\nrepresentations from any real-world ECG data. Specifically, a tailored ECG\nTokenizer encodes each fixed-duration ECG fragment into a token and, guided by\nproxy tasks, converts noisy, continuous ECG features into discrete, compact,\nand clinically meaningful local rhythm codes. These codes encapsulate basic\nmorphological, frequency, and demographic information (e.g., sex), effectively\nmitigating signal noise. We further pre-train the AnyECG to learn rhythmic\npattern associations across ECG tokens, enabling the capture of cardiac event\nsemantics. By being jointly pre-trained on diverse ECG data sources, AnyECG is\ncapable of generalizing across a wide range of downstream tasks where ECG\nsignals are recorded from various devices and scenarios. The experimental\nresults show that AnyECG achieves an average performance improvement of 6%\nacross four critical tasks-anomaly detection, arrhythmia classification,\ncorrupted lead generation, and ultra-long ECG recognition. AnyECG learns common\nECG rhythm from data and significantly outperforms state-of-the-art methods in\neach of these tasks.\n","authors":["Yue Wang","Xu Cao","Yaojun Hu","Haochao Ying","Hongxia Xu","Ruijia Wu","James Matthew Rehg","Jimeng Sun","Jian Wu","Jintai Chen"],"pdf_url":"https://arxiv.org/pdf/2411.17711v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05106v2","updated":"2025-03-03T13:18:55Z","published":"2024-10-07T15:02:48Z","title":"Nonasymptotic Analysis of Stochastic Gradient Descent with the\n  Richardson-Romberg Extrapolation","summary":"  We address the problem of solving strongly convex and smooth minimization\nproblems using stochastic gradient descent (SGD) algorithm with a constant step\nsize. Previous works suggested to combine the Polyak-Ruppert averaging\nprocedure with the Richardson-Romberg extrapolation to reduce the asymptotic\nbias of SGD at the expense of a mild increase of the variance. We significantly\nextend previous results by providing an expansion of the mean-squared error of\nthe resulting estimator with respect to the number of iterations $n$. We show\nthat the root mean-squared error can be decomposed into the sum of two terms: a\nleading one of order $\\mathcal{O}(n^{-1/2})$ with explicit dependence on a\nminimax-optimal asymptotic covariance matrix, and a second-order term of order\n$\\mathcal{O}(n^{-3/4})$, where the power $3/4$ is best known. We also extend\nthis result to the higher-order moment bounds. Our analysis relies on the\nproperties of the SGD iterates viewed as a time-homogeneous Markov chain. In\nparticular, we establish that this chain is geometrically ergodic with respect\nto a suitably defined weighted Wasserstein semimetric.\n","authors":["Marina Sheshukova","Denis Belomestny","Alain Durmus","Eric Moulines","Alexey Naumov","Sergey Samsonov"],"pdf_url":"https://arxiv.org/pdf/2410.05106v2.pdf","comment":"ICLR-2025, camera-ready version"},{"id":"http://arxiv.org/abs/2410.07076v4","updated":"2025-03-03T13:17:24Z","published":"2024-10-09T17:19:58Z","title":"MOOSE-Chem: Large Language Models for Rediscovering Unseen Chemistry\n  Scientific Hypotheses","summary":"  Scientific discovery contributes largely to human society's prosperity, and\nrecent progress shows that LLMs could potentially catalyze this process.\nHowever, it is still unclear whether LLMs can discover novel and valid\nhypotheses in chemistry. In this work, we investigate this central research\nquestion: Can LLMs automatically discover novel and valid chemistry research\nhypotheses given only a chemistry research background (consisting of a research\nquestion and/or a background survey), without limitation on the domain of the\nresearch question? After extensive discussions with chemistry experts, we\npropose an assumption that a majority of chemistry hypotheses can be resulted\nfrom a research background and several inspirations. With this key insight, we\nbreak the central question into three smaller fundamental questions. In brief,\nthey are: (1) given a background question, whether LLMs can retrieve good\ninspirations; (2) with background and inspirations, whether LLMs can lead to\nhypothesis; and (3) whether LLMs can identify good hypotheses to rank them\nhigher. To investigate these questions, we construct a benchmark consisting of\n51 chemistry papers published in Nature, Science, or a similar level in 2024\n(all papers are only available online since 2024). Every paper is divided by\nchemistry PhD students into three components: background, inspirations, and\nhypothesis. The goal is to rediscover the hypothesis, given only the background\nand a large randomly selected chemistry literature corpus consisting the ground\ntruth inspiration papers, with LLMs trained with data up to 2023. We also\ndevelop an LLM-based multi-agent framework that leverages the assumption,\nconsisting of three stages reflecting the three smaller questions. The proposed\nmethod can rediscover many hypotheses with very high similarity with the ground\ntruth ones, covering the main innovations.\n","authors":["Zonglin Yang","Wanhao Liu","Ben Gao","Tong Xie","Yuqiang Li","Wanli Ouyang","Soujanya Poria","Erik Cambria","Dongzhan Zhou"],"pdf_url":"https://arxiv.org/pdf/2410.07076v4.pdf","comment":"Accepted by ICLR 2025"},{"id":"http://arxiv.org/abs/2405.15273v4","updated":"2025-03-03T12:40:28Z","published":"2024-05-24T06:59:43Z","title":"Towards a General Time Series Anomaly Detector with Adaptive Bottlenecks\n  and Dual Adversarial Decoders","summary":"  Time series anomaly detection plays a vital role in a wide range of\napplications. Existing methods require training one specific model for each\ndataset, which exhibits limited generalization capability across different\ntarget datasets, hindering anomaly detection performance in various scenarios\nwith scarce training data. Aiming at this problem, we propose constructing a\ngeneral time series anomaly detection model, which is pre-trained on extensive\nmulti-domain datasets and can subsequently apply to a multitude of downstream\nscenarios. The significant divergence of time series data across different\ndomains presents two primary challenges in building such a general model: (1)\nmeeting the diverse requirements of appropriate information bottlenecks\ntailored to different datasets in one unified model, and (2) enabling\ndistinguishment between multiple normal and abnormal patterns, both are crucial\nfor effective anomaly detection in various target scenarios. To tackle these\ntwo challenges, we propose a General time series anomaly Detector with Adaptive\nBottlenecks and Dual Adversarial Decoders (DADA), which enables flexible\nselection of bottlenecks based on different data and explicitly enhances clear\ndifferentiation between normal and abnormal series. We conduct extensive\nexperiments on nine target datasets from different domains. After pre-training\non multi-domain data, DADA, serving as a zero-shot anomaly detector for these\ndatasets, still achieves competitive or even superior results compared to those\nmodels tailored to each specific dataset. The code is made available at\nhttps://github.com/decisionintelligence/DADA.\n","authors":["Qichao Shentu","Beibu Li","Kai Zhao","Yang Shu","Zhongwen Rao","Lujia Pan","Bin Yang","Chenjuan Guo"],"pdf_url":"https://arxiv.org/pdf/2405.15273v4.pdf","comment":"Accepted by the 13th International Conference on Learning\n  Representations (ICLR 2025)"},{"id":"http://arxiv.org/abs/2403.19243v4","updated":"2025-03-03T12:32:47Z","published":"2024-03-28T08:58:20Z","title":"Efficient Learning With Sine-Activated Low-rank Matrices","summary":"  Low-rank decomposition has emerged as a vital tool for enhancing parameter\nefficiency in neural network architectures, gaining traction across diverse\napplications in machine learning. These techniques significantly lower the\nnumber of parameters, striking a balance between compactness and performance.\nHowever, a common challenge has been the compromise between parameter\nefficiency and the accuracy of the model, where reduced parameters often lead\nto diminished accuracy compared to their full-rank counterparts. In this work,\nwe propose a novel theoretical framework that integrates a sinusoidal function\nwithin the low-rank decomposition process. This approach not only preserves the\nbenefits of the parameter efficiency characteristic of low-rank methods but\nalso increases the decomposition's rank, thereby enhancing model performance.\nOur method proves to be a plug in enhancement for existing low-rank models, as\nevidenced by its successful application in Vision Transformers (ViT), Large\nLanguage Models (LLMs), Neural Radiance Fields (NeRF) and 3D shape modelling.\n","authors":["Yiping Ji","Hemanth Saratchandran","Cameron Gordon","Zeyu Zhang","Simon Lucey"],"pdf_url":"https://arxiv.org/pdf/2403.19243v4.pdf","comment":"The first two authors contributed equally. Paper accepted at ICLR\n  2025"},{"id":"http://arxiv.org/abs/2412.16577v2","updated":"2025-03-03T12:21:35Z","published":"2024-12-21T10:52:56Z","title":"A Meta-Learning Approach to Bayesian Causal Discovery","summary":"  Discovering a unique causal structure is difficult due to both inherent\nidentifiability issues, and the consequences of finite data. As such,\nuncertainty over causal structures, such as those obtained from a Bayesian\nposterior, are often necessary for downstream tasks. Finding an accurate\napproximation to this posterior is challenging, due to the large number of\npossible causal graphs, as well as the difficulty in the subproblem of finding\nposteriors over the functional relationships of the causal edges. Recent works\nhave used meta-learning to view the problem of estimating the maximum\na-posteriori causal graph as supervised learning. Yet, these methods are\nlimited when estimating the full posterior as they fail to encode key\nproperties of the posterior, such as correlation between edges and permutation\nequivariance with respect to nodes. Further, these methods also cannot reliably\nsample from the posterior over causal structures. To address these limitations,\nwe propose a Bayesian meta learning model that allows for sampling causal\nstructures from the posterior and encodes these key properties. We compare our\nmeta-Bayesian causal discovery against existing Bayesian causal discovery\nmethods, demonstrating the advantages of directly learning a posterior over\ncausal structure.\n","authors":["Anish Dhir","Matthew Ashman","James Requeima","Mark van der Wilk"],"pdf_url":"https://arxiv.org/pdf/2412.16577v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.08190v2","updated":"2025-03-03T12:18:29Z","published":"2024-10-10T17:57:29Z","title":"Poison-splat: Computation Cost Attack on 3D Gaussian Splatting","summary":"  3D Gaussian splatting (3DGS), known for its groundbreaking performance and\nefficiency, has become a dominant 3D representation and brought progress to\nmany 3D vision tasks. However, in this work, we reveal a significant security\nvulnerability that has been largely overlooked in 3DGS: the computation cost of\ntraining 3DGS could be maliciously tampered by poisoning the input data. By\ndeveloping an attack named Poison-splat, we reveal a novel attack surface where\nthe adversary can poison the input images to drastically increase the\ncomputation memory and time needed for 3DGS training, pushing the algorithm\ntowards its worst computation complexity. In extreme cases, the attack can even\nconsume all allocable memory, leading to a Denial-of-Service (DoS) that\ndisrupts servers, resulting in practical damages to real-world 3DGS service\nvendors. Such a computation cost attack is achieved by addressing a bi-level\noptimization problem through three tailored strategies: attack objective\napproximation, proxy model rendering, and optional constrained optimization.\nThese strategies not only ensure the effectiveness of our attack but also make\nit difficult to defend with simple defensive measures. We hope the revelation\nof this novel attack surface can spark attention to this crucial yet overlooked\nvulnerability of 3DGS systems. Our code is available at\nhttps://github.com/jiahaolu97/poison-splat .\n","authors":["Jiahao Lu","Yifan Zhang","Qiuhong Shen","Xinchao Wang","Shuicheng Yan"],"pdf_url":"https://arxiv.org/pdf/2410.08190v2.pdf","comment":"Accepted by ICLR 2025 as a spotlight paper"},{"id":"http://arxiv.org/abs/2410.00722v2","updated":"2025-03-03T12:18:16Z","published":"2024-10-01T14:13:05Z","title":"On the Geometry and Optimization of Polynomial Convolutional Networks","summary":"  We study convolutional neural networks with monomial activation functions.\nSpecifically, we prove that their parameterization map is regular and is an\nisomorphism almost everywhere, up to rescaling the filters. By leveraging on\ntools from algebraic geometry, we explore the geometric properties of the image\nin function space of this map - typically referred to as neuromanifold. In\nparticular, we compute the dimension and the degree of the neuromanifold, which\nmeasure the expressivity of the model, and describe its singularities.\nMoreover, for a generic large dataset, we derive an explicit formula that\nquantifies the number of critical points arising in the optimization of a\nregression loss.\n","authors":["Vahid Shahverdi","Giovanni Luca Marchetti","Kathlén Kohn"],"pdf_url":"https://arxiv.org/pdf/2410.00722v2.pdf","comment":"Accepted at AISTATS 2025"},{"id":"http://arxiv.org/abs/2410.12343v3","updated":"2025-03-03T12:15:38Z","published":"2024-10-16T08:04:57Z","title":"Federated Temporal Graph Clustering","summary":"  Temporal graph clustering is a complex task that involves discovering\nmeaningful structures in dynamic graphs where relationships and entities change\nover time. Existing methods typically require centralized data collection,\nwhich poses significant privacy and communication challenges. In this work, we\nintroduce a novel Federated Temporal Graph Clustering (FTGC) framework that\nenables decentralized training of graph neural networks (GNNs) across multiple\nclients, ensuring data privacy throughout the process. Our approach\nincorporates a temporal aggregation mechanism to effectively capture the\nevolution of graph structures over time and a federated optimization strategy\nto collaboratively learn high-quality clustering representations. By preserving\ndata privacy and reducing communication overhead, our framework achieves\ncompetitive performance on temporal graph datasets, making it a promising\nsolution for privacy-sensitive, real-world applications involving dynamic data.\n","authors":["Zihao Zhou","Yang Liu","Xianghong Xu","Qian Li"],"pdf_url":"https://arxiv.org/pdf/2410.12343v3.pdf","comment":"8 pages, 1 figure"},{"id":"http://arxiv.org/abs/2409.02143v2","updated":"2025-03-03T12:08:50Z","published":"2024-09-02T22:04:08Z","title":"MLOmics: Benchmark for Machine Learning on Cancer Multi-Omics Data","summary":"  Framing the investigation of diverse cancers as a machine learning problem\nhas recently shown significant potential in multi-omics analysis and cancer\nresearch. Empowering these successful machine learning models are the\nhigh-quality training datasets with sufficient data volume and adequate\npreprocessing. However, while there exist several public data portals including\nThe Cancer Genome Atlas (TCGA) multi-omics initiative or open-bases such as the\nLinkedOmics, these databases are not off-the-shelf for existing machine\nlearning models. In this paper we propose MLOmics, an open cancer multi-omics\nbenchmark aiming at serving better the development and evaluation of\nbioinformatics and machine learning models. MLOmics contains 8,314 patient\nsamples covering all 32 cancer types with four omics types, stratified\nfeatures, and extensive baselines. Complementary support for downstream\nanalysis and bio-knowledge linking are also included to support\ninterdisciplinary analysis.\n","authors":["Ziwei Yang","Rikuto Kotoge","Xihao Piao","Zheng Chen","Lingwei Zhu","Peng Gao","Yasuko Matsubara","Yasushi Sakurai","Jimeng Sun"],"pdf_url":"https://arxiv.org/pdf/2409.02143v2.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2403.08632v2","updated":"2025-03-03T12:01:27Z","published":"2024-03-13T15:46:37Z","title":"A Decade's Battle on Dataset Bias: Are We There Yet?","summary":"  We revisit the \"dataset classification\" experiment suggested by Torralba &\nEfros (2011) a decade ago, in the new era with large-scale, diverse, and\nhopefully less biased datasets as well as more capable neural network\narchitectures. Surprisingly, we observe that modern neural networks can achieve\nexcellent accuracy in classifying which dataset an image is from: e.g., we\nreport 84.7% accuracy on held-out validation data for the three-way\nclassification problem consisting of the YFCC, CC, and DataComp datasets. Our\nfurther experiments show that such a dataset classifier could learn semantic\nfeatures that are generalizable and transferable, which cannot be explained by\nmemorization. We hope our discovery will inspire the community to rethink\nissues involving dataset bias.\n","authors":["Zhuang Liu","Kaiming He"],"pdf_url":"https://arxiv.org/pdf/2403.08632v2.pdf","comment":"Published in ICLR 2025 (Oral Presentation)"},{"id":"http://arxiv.org/abs/2502.17941v2","updated":"2025-03-03T12:00:57Z","published":"2025-02-25T08:03:04Z","title":"Optimal Brain Apoptosis","summary":"  The increasing complexity and parameter count of Convolutional Neural\nNetworks (CNNs) and Transformers pose challenges in terms of computational\nefficiency and resource demands. Pruning has been identified as an effective\nstrategy to address these challenges by removing redundant elements such as\nneurons, channels, or connections, thereby enhancing computational efficiency\nwithout heavily compromising performance. This paper builds on the foundational\nwork of Optimal Brain Damage (OBD) by advancing the methodology of parameter\nimportance estimation using the Hessian matrix. Unlike previous approaches that\nrely on approximations, we introduce Optimal Brain Apoptosis (OBA), a novel\npruning method that calculates the Hessian-vector product value directly for\neach parameter. By decomposing the Hessian matrix across network layers and\nidentifying conditions under which inter-layer Hessian submatrices are\nnon-zero, we propose a highly efficient technique for computing the\nsecond-order Taylor expansion of parameters. This approach allows for a more\nprecise pruning process, particularly in the context of CNNs and Transformers,\nas validated in our experiments including VGG19, ResNet32, ResNet50, and\nViT-B/16 on CIFAR10, CIFAR100 and Imagenet datasets. Our code is available at\nhttps://github.com/NEU-REAL/OBA.\n","authors":["Mingyuan Sun","Zheng Fang","Jiaxu Wang","Junjie Jiang","Delei Kong","Chenming Hu","Yuetong Fang","Renjing Xu"],"pdf_url":"https://arxiv.org/pdf/2502.17941v2.pdf","comment":"Accepted to ICLR 2025"},{"id":"http://arxiv.org/abs/2403.02107v5","updated":"2025-03-03T11:48:55Z","published":"2024-03-04T15:07:33Z","title":"Iterated $Q$-Network: Beyond One-Step Bellman Updates in Deep\n  Reinforcement Learning","summary":"  The vast majority of Reinforcement Learning methods is largely impacted by\nthe computation effort and data requirements needed to obtain effective\nestimates of action-value functions, which in turn determine the quality of the\noverall performance and the sample-efficiency of the learning procedure.\nTypically, action-value functions are estimated through an iterative scheme\nthat alternates the application of an empirical approximation of the Bellman\noperator and a subsequent projection step onto a considered function space. It\nhas been observed that this scheme can be potentially generalized to carry out\nmultiple iterations of the Bellman operator at once, benefiting the underlying\nlearning algorithm. However, till now, it has been challenging to effectively\nimplement this idea, especially in high-dimensional problems. In this paper, we\nintroduce iterated $Q$-Network (i-QN), a novel principled approach that enables\nmultiple consecutive Bellman updates by learning a tailored sequence of\naction-value functions where each serves as the target for the next. We show\nthat i-QN is theoretically grounded and that it can be seamlessly used in\nvalue-based and actor-critic methods. We empirically demonstrate the advantages\nof i-QN in Atari $2600$ games and MuJoCo continuous control problems.\n","authors":["Théo Vincent","Daniel Palenicek","Boris Belousov","Jan Peters","Carlo D'Eramo"],"pdf_url":"https://arxiv.org/pdf/2403.02107v5.pdf","comment":"Published at TMLR: https://openreview.net/forum?id=Lt2H8Bd8jF"},{"id":"http://arxiv.org/abs/2407.15589v5","updated":"2025-03-03T11:48:03Z","published":"2024-07-22T12:26:08Z","title":"Exploring the Effectiveness of Object-Centric Representations in Visual\n  Question Answering: Comparative Insights with Foundation Models","summary":"  Object-centric (OC) representations, which model visual scenes as\ncompositions of discrete objects, have the potential to be used in various\ndownstream tasks to achieve systematic compositional generalization and\nfacilitate reasoning. However, these claims have yet to be thoroughly validated\nempirically. Recently, foundation models have demonstrated unparalleled\ncapabilities across diverse domains, from language to computer vision,\npositioning them as a potential cornerstone of future research for a wide range\nof computational tasks. In this paper, we conduct an extensive empirical study\non representation learning for downstream Visual Question Answering (VQA),\nwhich requires an accurate compositional understanding of the scene. We\nthoroughly investigate the benefits and trade-offs of OC models and alternative\napproaches including large pre-trained foundation models on both synthetic and\nreal-world data, ultimately identifying a promising path to leverage the\nstrengths of both paradigms. The extensiveness of our study, encompassing over\n600 downstream VQA models and 15 different types of upstream representations,\nalso provides several additional insights that we believe will be of interest\nto the community at large.\n","authors":["Amir Mohammad Karimi Mamaghan","Samuele Papa","Karl Henrik Johansson","Stefan Bauer","Andrea Dittadi"],"pdf_url":"https://arxiv.org/pdf/2407.15589v5.pdf","comment":"Published at ICLR 2025"},{"id":"http://arxiv.org/abs/2405.16195v3","updated":"2025-03-03T11:39:53Z","published":"2024-05-25T11:57:43Z","title":"Adaptive $Q$-Network: On-the-fly Target Selection for Deep Reinforcement\n  Learning","summary":"  Deep Reinforcement Learning (RL) is well known for being highly sensitive to\nhyperparameters, requiring practitioners substantial efforts to optimize them\nfor the problem at hand. This also limits the applicability of RL in real-world\nscenarios. In recent years, the field of automated Reinforcement Learning\n(AutoRL) has grown in popularity by trying to address this issue. However,\nthese approaches typically hinge on additional samples to select\nwell-performing hyperparameters, hindering sample-efficiency and practicality.\nFurthermore, most AutoRL methods are heavily based on already existing AutoML\nmethods, which were originally developed neglecting the additional challenges\ninherent to RL due to its non-stationarities. In this work, we propose a new\napproach for AutoRL, called Adaptive $Q$-Network (AdaQN), that is tailored to\nRL to take into account the non-stationarity of the optimization procedure\nwithout requiring additional samples. AdaQN learns several $Q$-functions, each\none trained with different hyperparameters, which are updated online using the\n$Q$-function with the smallest approximation error as a shared target. Our\nselection scheme simultaneously handles different hyperparameters while coping\nwith the non-stationarity induced by the RL optimization procedure and being\northogonal to any critic-based RL algorithm. We demonstrate that AdaQN is\ntheoretically sound and empirically validate it in MuJoCo control problems and\nAtari $2600$ games, showing benefits in sample-efficiency, overall performance,\nrobustness to stochasticity and training stability.\n","authors":["Théo Vincent","Fabian Wahren","Jan Peters","Boris Belousov","Carlo D'Eramo"],"pdf_url":"https://arxiv.org/pdf/2405.16195v3.pdf","comment":"Accepted at ICLR https://iclr.cc/virtual/2025/poster/28508"},{"id":"http://arxiv.org/abs/2410.11502v2","updated":"2025-03-03T11:38:11Z","published":"2024-10-15T11:15:03Z","title":"Offline Model-Based Optimization by Learning to Rank","summary":"  Offline model-based optimization (MBO) aims to identify a design that\nmaximizes a black-box function using only a fixed, pre-collected dataset of\ndesigns and their corresponding scores. A common approach in offline MBO is to\ntrain a regression-based surrogate model by minimizing mean squared error (MSE)\nand then find the best design within this surrogate model by different\noptimizers (e.g., gradient ascent). However, a critical challenge is the risk\nof out-of-distribution errors, i.e., the surrogate model may typically\noverestimate the scores and mislead the optimizers into suboptimal regions.\nPrior works have attempted to address this issue in various ways, such as using\nregularization techniques and ensemble learning to enhance the robustness of\nthe model, but it still remains. In this paper, we argue that regression models\ntrained with MSE are not well-aligned with the primary goal of offline MBO,\nwhich is to select promising designs rather than to predict their scores\nprecisely. Notably, if a surrogate model can maintain the order of candidate\ndesigns based on their relative score relationships, it can produce the best\ndesigns even without precise predictions. To validate it, we conduct\nexperiments to compare the relationship between the quality of the final\ndesigns and MSE, finding that the correlation is really very weak. In contrast,\na metric that measures order-maintaining quality shows a significantly stronger\ncorrelation. Based on this observation, we propose learning a ranking-based\nmodel that leverages learning to rank techniques to prioritize promising\ndesigns based on their relative scores. We show that the generalization error\non ranking loss can be well bounded. Empirical results across diverse tasks\ndemonstrate the superior performance of our proposed ranking-based models than\ntwenty existing methods.\n","authors":["Rong-Xi Tan","Ke Xue","Shen-Huan Lyu","Haopu Shang","Yao Wang","Yaoyuan Wang","Sheng Fu","Chao Qian"],"pdf_url":"https://arxiv.org/pdf/2410.11502v2.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2402.06287v2","updated":"2025-03-03T11:28:57Z","published":"2024-02-09T09:54:01Z","title":"AI, Meet Human: Learning Paradigms for Hybrid Decision Making Systems","summary":"  Everyday we increasingly rely on machine learning models to automate and\nsupport high-stake tasks and decisions. This growing presence means that humans\nare now constantly interacting with machine learning-based systems, training\nand using models everyday. Several different techniques in computer science\nliterature account for the human interaction with machine learning systems, but\ntheir classification is sparse and the goals varied. This survey proposes a\ntaxonomy of Hybrid Decision Making Systems, providing both a conceptual and\ntechnical framework for understanding how current computer science literature\nmodels interaction between humans and machines.\n","authors":["Clara Punzi","Roberto Pellungrini","Mattia Setzu","Fosca Giannotti","Dino Pedreschi"],"pdf_url":"https://arxiv.org/pdf/2402.06287v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.18477v4","updated":"2025-03-03T11:25:26Z","published":"2024-02-28T16:58:31Z","title":"Signature Kernel Conditional Independence Tests in Causal Discovery for\n  Stochastic Processes","summary":"  Inferring the causal structure underlying stochastic dynamical systems from\nobservational data holds great promise in domains ranging from science and\nhealth to finance. Such processes can often be accurately modeled via\nstochastic differential equations (SDEs), which naturally imply causal\nrelationships via \"which variables enter the differential of which other\nvariables\". In this paper, we develop conditional independence (CI) constraints\non coordinate processes over selected intervals that are Markov with respect to\nthe acyclic dependence graph (allowing self-loops) induced by a general SDE\nmodel. We then provide a sound and complete causal discovery algorithm, capable\nof handling both fully and partially observed data, and uniquely recovering the\nunderlying or induced ancestral graph by exploiting time directionality\nassuming a CI oracle. Finally, to make our algorithm practically usable, we\nalso propose a flexible, consistent signature kernel-based CI test to infer\nthese constraints from data. We extensively benchmark the CI test in isolation\nand as part of our causal discovery algorithms, outperforming existing\napproaches in SDE models and beyond.\n","authors":["Georg Manten","Cecilia Casolo","Emilio Ferrucci","Søren Wengel Mogensen","Cristopher Salvi","Niki Kilbertus"],"pdf_url":"https://arxiv.org/pdf/2402.18477v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.06057v2","updated":"2025-03-03T11:08:15Z","published":"2024-07-08T15:59:44Z","title":"Variational Best-of-N Alignment","summary":"  Best-of-N (BoN) is a popular and effective algorithm for aligning language\nmodels to human preferences. The algorithm works as follows: at inference time,\nN samples are drawn from the language model, and the sample with the highest\nreward, as judged by a reward model, is returned as the output. Despite its\neffectiveness, BoN is computationally expensive; it reduces sampling throughput\nby a factor of N. To make BoN more efficient at inference time, one strategy is\nto fine-tune the language model to mimic what BoN does during inference. To\nachieve this, we derive the distribution induced by the BoN algorithm. We then\npropose to fine-tune the language model to minimize backward KL divergence to\nthe BoN distribution. Our approach is analogous to mean-field variational\ninference and, thus, we term it variational BoN (vBoN). To the extent this\nfine-tuning is successful and we end up with a good approximation, we have\nreduced the inference cost by a factor of N. Our experiments on controlled\ngeneration and summarization tasks show that BoN is the most effective\nalignment method, and our variational approximation to BoN achieves the closest\nperformance to BoN and surpasses models fine-tuned using the standard\nKL-constrained RL objective. In the controlled generation task, vBoN appears\nmore frequently on the Pareto frontier of reward and KL divergence compared to\nother alignment methods. In the summarization task, vBoN achieves high reward\nvalues across various sampling temperatures.\n","authors":["Afra Amini","Tim Vieira","Elliott Ash","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2407.06057v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05841v2","updated":"2025-03-03T11:00:24Z","published":"2024-11-06T15:06:42Z","title":"FLEXtime: Filterbank learning to explain time series","summary":"  State-of-the-art methods for explaining predictions from time series involve\nlearning an instance-wise saliency mask for each time step; however, many types\nof time series are difficult to interpret in the time domain, due to the\ninherently complex nature of the data. Instead, we propose to view time series\nexplainability as saliency maps over interpretable parts, leaning on\nestablished signal processing methodology on signal decomposition.\nSpecifically, we propose a new method called FLEXtime that uses a bank of\nbandpass filters to split the time series into frequency bands. Then, we learn\nthe combination of these bands that optimally explains the model's prediction.\nOur extensive evaluation shows that, on average, FLEXtime outperforms\nstate-of-the-art explainability methods across a range of datasets. FLEXtime\nfills an important gap in the current time series explainability methodology\nand is a valuable tool for a wide range of time series such as EEG and audio.\nCode will be made available at https://github.com/theabrusch/FLEXtime.\n","authors":["Thea Brüsch","Kristoffer K. Wickstrøm","Mikkel N. Schmidt","Robert Jenssen","Tommy S. Alstrøm"],"pdf_url":"https://arxiv.org/pdf/2411.05841v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18936v4","updated":"2025-03-03T11:00:24Z","published":"2025-01-31T07:41:06Z","title":"Adaptive Prompt: Unlocking the Power of Visual Prompt Tuning","summary":"  Visual Prompt Tuning (VPT) has recently emerged as a powerful method for\nadapting pre-trained vision models to downstream tasks. By introducing\nlearnable prompt tokens as task-specific instructions, VPT effectively guides\npre-trained transformer models with minimal overhead. Despite its empirical\nsuccess, a comprehensive theoretical understanding of VPT remains an active\narea of research. Building on recent insights into the connection between\nmixture of experts and prompt-based approaches, we identify a key limitation in\nVPT: the restricted functional expressiveness in prompt formulation. To address\nthis limitation, we propose Visual Adaptive Prompt Tuning (VAPT), a new\ngeneration of prompts that redefines prompts as adaptive functions of the\ninput. Our theoretical analysis shows that this simple yet intuitive approach\nachieves optimal sample efficiency. Empirical results on VTAB-1K and FGVC\nfurther demonstrate VAPT's effectiveness, with performance gains of 7.34% and\n1.04% over fully fine-tuning baselines, respectively. Notably, VAPT also\nsurpasses VPT by a substantial margin while using fewer parameters. These\nresults highlight both the effectiveness and efficiency of our method and pave\nthe way for future research to explore the potential of adaptive prompts.\n","authors":["Minh Le","Anh Nguyen","Huy Nguyen","Chau Nguyen","Nhat Ho"],"pdf_url":"https://arxiv.org/pdf/2501.18936v4.pdf","comment":"57 pages, 10 figures, 18 tables"},{"id":"http://arxiv.org/abs/2405.20579v3","updated":"2025-03-03T10:57:41Z","published":"2024-05-31T02:17:51Z","title":"HOPE: A Reinforcement Learning-based Hybrid Policy Path Planner for\n  Diverse Parking Scenarios","summary":"  Automated parking stands as a highly anticipated application of autonomous\ndriving technology. However, existing path planning methodologies fall short of\naddressing this need due to their incapability to handle the diverse and\ncomplex parking scenarios in reality. While non-learning methods provide\nreliable planning results, they are vulnerable to intricate occasions, whereas\nlearning-based ones are good at exploration but unstable in converging to\nfeasible solutions. To leverage the strengths of both approaches, we introduce\nHybrid pOlicy Path plannEr (HOPE). This novel solution integrates a\nreinforcement learning agent with Reeds-Shepp curves, enabling effective\nplanning across diverse scenarios. HOPE guides the exploration of the\nreinforcement learning agent by applying an action mask mechanism and employs a\ntransformer to integrate the perceived environmental information with the mask.\nTo facilitate the training and evaluation of the proposed planner, we propose a\ncriterion for categorizing the difficulty level of parking scenarios based on\nspace and obstacle distribution. Experimental results demonstrate that our\napproach outperforms typical rule-based algorithms and traditional\nreinforcement learning methods, showing higher planning success rates and\ngeneralization across various scenarios. We also conduct real-world experiments\nto verify the practicability of HOPE. The code for our solution is openly\navailable on https://github.com/jiamiya/HOPE.\n","authors":["Mingyang Jiang","Yueyuan Li","Songan Zhang","Siyuan Chen","Chunxiang Wang","Ming Yang"],"pdf_url":"https://arxiv.org/pdf/2405.20579v3.pdf","comment":"Accepted by T-ITS. 11 pages, 5 tables, 6 figures, 2 page appendix"},{"id":"http://arxiv.org/abs/2410.02423v2","updated":"2025-03-03T10:44:06Z","published":"2024-10-03T12:13:56Z","title":"PnP-Flow: Plug-and-Play Image Restoration with Flow Matching","summary":"  In this paper, we introduce Plug-and-Play (PnP) Flow Matching, an algorithm\nfor solving imaging inverse problems. PnP methods leverage the strength of\npre-trained denoisers, often deep neural networks, by integrating them in\noptimization schemes. While they achieve state-of-the-art performance on\nvarious inverse problems in imaging, PnP approaches face inherent limitations\non more generative tasks like inpainting. On the other hand, generative models\nsuch as Flow Matching pushed the boundary in image sampling yet lack a clear\nmethod for efficient use in image restoration. We propose to combine the PnP\nframework with Flow Matching (FM) by defining a time-dependent denoiser using a\npre-trained FM model. Our algorithm alternates between gradient descent steps\non the data-fidelity term, reprojections onto the learned FM path, and\ndenoising. Notably, our method is computationally efficient and\nmemory-friendly, as it avoids backpropagation through ODEs and trace\ncomputations. We evaluate its performance on denoising, super-resolution,\ndeblurring, and inpainting tasks, demonstrating superior results compared to\nexisting PnP algorithms and Flow Matching based state-of-the-art methods.\n","authors":["Ségolène Martin","Anne Gagneux","Paul Hagemann","Gabriele Steidl"],"pdf_url":"https://arxiv.org/pdf/2410.02423v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.11542v2","updated":"2025-03-03T10:39:41Z","published":"2024-12-16T08:22:23Z","title":"Meta Curvature-Aware Minimization for Domain Generalization","summary":"  Domain generalization (DG) aims to enhance the ability of models trained on\nsource domains to generalize effectively to unseen domains. Recently,\nSharpness-Aware Minimization (SAM) has shown promise in this area by reducing\nthe sharpness of the loss landscape to obtain more generalized models. However,\nSAM and its variants sometimes fail to guide the model toward a flat minimum,\nand their training processes exhibit limitations, hindering further\nimprovements in model generalization. In this paper, we first propose an\nimproved model training process aimed at encouraging the model to converge to a\nflat minima. To achieve this, we design a curvature metric that has a minimal\neffect when the model is far from convergence but becomes increasingly\ninfluential in indicating the curvature of the minima as the model approaches a\nlocal minimum. Then we derive a novel algorithm from this metric, called Meta\nCurvature-Aware Minimization (MeCAM), to minimize the curvature around the\nlocal minima. Specifically, the optimization objective of MeCAM simultaneously\nminimizes the regular training loss, the surrogate gap of SAM, and the\nsurrogate gap of meta-learning. We provide theoretical analysis on MeCAM's\ngeneralization error and convergence rate, and demonstrate its superiority over\nexisting DG methods through extensive experiments on five benchmark DG\ndatasets, including PACS, VLCS, OfficeHome, TerraIncognita, and DomainNet. Code\nwill be available on GitHub.\n","authors":["Ziyang Chen","Yiwen Ye","Feilong Tang","Yongsheng Pan","Yong Xia"],"pdf_url":"https://arxiv.org/pdf/2412.11542v2.pdf","comment":"22 pages, 5 figures, 17 tables"},{"id":"http://arxiv.org/abs/2502.08005v2","updated":"2025-03-03T10:38:34Z","published":"2025-02-11T23:02:14Z","title":"Towards Training One-Step Diffusion Models Without Distillation","summary":"  Recent advances in one-step generative models typically follow a two-stage\nprocess: first training a teacher diffusion model and then distilling it into a\none-step student model. This distillation process traditionally relies on both\nthe teacher model's score function to compute the distillation loss and its\nweights for student initialization. In this paper, we explore whether one-step\ngenerative models can be trained directly without this distillation process.\nFirst, we show that the teacher's score function is not essential and propose a\nfamily of distillation methods that achieve competitive results without relying\non score estimation. Next, we demonstrate that initialization from teacher\nweights is indispensable in successful training. Surprisingly, we find that\nthis benefit is not due to improved ``input-output\" mapping but rather the\nlearned feature representations, which dominate distillation quality. Our\nfindings provide a better understanding of the role of initialization in\none-step model training and its impact on distillation quality.\n","authors":["Mingtian Zhang","Jiajun He","Wenlin Chen","Zijing Ou","José Miguel Hernández-Lobato","Bernhard Schölkopf","David Barber"],"pdf_url":"https://arxiv.org/pdf/2502.08005v2.pdf","comment":"13 pages, Technical Report"},{"id":"http://arxiv.org/abs/2502.15425v3","updated":"2025-03-03T10:35:14Z","published":"2025-02-21T12:52:16Z","title":"TAG: A Decentralized Framework for Multi-Agent Hierarchical\n  Reinforcement Learning","summary":"  Hierarchical organization is fundamental to biological systems and human\nsocieties, yet artificial intelligence systems often rely on monolithic\narchitectures that limit adaptability and scalability. Current hierarchical\nreinforcement learning (HRL) approaches typically restrict hierarchies to two\nlevels or require centralized training, which limits their practical\napplicability. We introduce TAME Agent Framework (TAG), a framework for\nconstructing fully decentralized hierarchical multi-agent systems.TAG enables\nhierarchies of arbitrary depth through a novel LevelEnv concept, which\nabstracts each hierarchy level as the environment for the agents above it. This\napproach standardizes information flow between levels while preserving loose\ncoupling, allowing for seamless integration of diverse agent types. We\ndemonstrate the effectiveness of TAG by implementing hierarchical architectures\nthat combine different RL agents across multiple levels, achieving improved\nperformance over classical multi-agent RL baselines on standard benchmarks. Our\nresults show that decentralized hierarchical organization enhances both\nlearning speed and final performance, positioning TAG as a promising direction\nfor scalable multi-agent systems.\n","authors":["Giuseppe Paolo","Abdelhakim Benechehab","Hamza Cherkaoui","Albert Thomas","Balázs Kégl"],"pdf_url":"https://arxiv.org/pdf/2502.15425v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06916v2","updated":"2025-03-03T10:22:24Z","published":"2024-11-11T12:19:28Z","title":"Slowing Down Forgetting in Continual Learning","summary":"  A common challenge in continual learning (CL) is catastrophic forgetting,\nwhere the performance on old tasks drops after new, additional tasks are\nlearned. In this paper, we propose a novel framework called ReCL to slow down\nforgetting in CL. Our framework exploits an implicit bias of gradient-based\nneural networks due to which these converge to margin maximization points. Such\nconvergence points allow us to reconstruct old data from previous tasks, which\nwe then combine with the current training data. Our framework is flexible and\ncan be applied on top of existing, state-of-the-art CL methods. We further\ndemonstrate the performance gain from our framework across a large series of\nexperiments, including two challenging CL scenarios (class incremental and\ndomain incremental learning), different datasets (MNIST, CIFAR10,\nTinyImagenet), and different network architectures. Across all experiments, we\nfind large performance gains through ReCL. To the best of our knowledge, our\nframework is the first to address catastrophic forgetting by leveraging models\nin CL as their own memory buffers.\n","authors":["Pascal Janetzky","Tobias Schlagenhauf","Stefan Feuerriegel"],"pdf_url":"https://arxiv.org/pdf/2411.06916v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21123v2","updated":"2025-03-03T10:00:03Z","published":"2025-02-28T14:57:33Z","title":"Causality Is Key to Understand and Balance Multiple Goals in Trustworthy\n  ML and Foundation Models","summary":"  Ensuring trustworthiness in machine learning (ML) systems is crucial as they\nbecome increasingly embedded in high-stakes domains. This paper advocates for\nintegrating causal methods into machine learning to navigate the trade-offs\namong key principles of trustworthy ML, including fairness, privacy,\nrobustness, accuracy, and explainability. While these objectives should ideally\nbe satisfied simultaneously, they are often addressed in isolation, leading to\nconflicts and suboptimal solutions. Drawing on existing applications of\ncausality in ML that successfully align goals such as fairness and accuracy or\nprivacy and robustness, this paper argues that a causal approach is essential\nfor balancing multiple competing objectives in both trustworthy ML and\nfoundation models. Beyond highlighting these trade-offs, we examine how\ncausality can be practically integrated into ML and foundation models, offering\nsolutions to enhance their reliability and interpretability. Finally, we\ndiscuss the challenges, limitations, and opportunities in adopting causal\nframeworks, paving the way for more accountable and ethically sound AI systems.\n","authors":["Ruta Binkyte","Ivaxi Sheth","Zhijing Jin","Mohammad Havaei","Bernhard Schölkopf","Mario Fritz"],"pdf_url":"https://arxiv.org/pdf/2502.21123v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02392v2","updated":"2025-03-03T09:50:18Z","published":"2024-10-03T11:13:55Z","title":"MANTRA: The Manifold Triangulations Assemblage","summary":"  The rising interest in leveraging higher-order interactions present in\ncomplex systems has led to a surge in more expressive models exploiting\nhigher-order structures in the data, especially in topological deep learning\n(TDL), which designs neural networks on higher-order domains such as simplicial\ncomplexes. However, progress in this field is hindered by the scarcity of\ndatasets for benchmarking these architectures. To address this gap, we\nintroduce MANTRA, the first large-scale, diverse, and intrinsically\nhigher-order dataset for benchmarking higher-order models, comprising over\n43,000 and 250,000 triangulations of surfaces and three-dimensional manifolds,\nrespectively. With MANTRA, we assess several graph- and simplicial\ncomplex-based models on three topological classification tasks. We demonstrate\nthat while simplicial complex-based neural networks generally outperform their\ngraph-based counterparts in capturing simple topological invariants, they also\nstruggle, suggesting a rethink of TDL. Thus, MANTRA serves as a benchmark for\nassessing and advancing topological methods, leading the way for more effective\nhigher-order models.\n","authors":["Rubén Ballester","Ernst Röell","Daniel Bīn Schmid","Mathieu Alain","Sergio Escalera","Carles Casacuberta","Bastian Rieck"],"pdf_url":"https://arxiv.org/pdf/2410.02392v2.pdf","comment":"Accepted at ICLR 2025 (https://openreview.net/forum?id=X6y5CC44HM)"},{"id":"http://arxiv.org/abs/2402.09154v2","updated":"2025-03-03T09:37:27Z","published":"2024-02-14T13:13:26Z","title":"Attacking Large Language Models with Projected Gradient Descent","summary":"  Current LLM alignment methods are readily broken through specifically crafted\nadversarial prompts. While crafting adversarial prompts using discrete\noptimization is highly effective, such attacks typically use more than 100,000\nLLM calls. This high computational cost makes them unsuitable for, e.g.,\nquantitative analyses and adversarial training. To remedy this, we revisit\nProjected Gradient Descent (PGD) on the continuously relaxed input prompt.\nAlthough previous attempts with ordinary gradient-based attacks largely failed,\nwe show that carefully controlling the error introduced by the continuous\nrelaxation tremendously boosts their efficacy. Our PGD for LLMs is up to one\norder of magnitude faster than state-of-the-art discrete optimization to\nachieve the same devastating attack results.\n","authors":["Simon Geisler","Tom Wollschläger","M. H. I. Abdalla","Johannes Gasteiger","Stephan Günnemann"],"pdf_url":"https://arxiv.org/pdf/2402.09154v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.23751v2","updated":"2025-03-03T09:30:42Z","published":"2024-10-31T09:11:56Z","title":"EXACFS -- A CIL Method to mitigate Catastrophic Forgetting","summary":"  Deep neural networks (DNNS) excel at learning from static datasets but\nstruggle with continual learning, where data arrives sequentially. Catastrophic\nforgetting, the phenomenon of forgetting previously learned knowledge, is a\nprimary challenge. This paper introduces EXponentially Averaged Class-wise\nFeature Significance (EXACFS) to mitigate this issue in the class incremental\nlearning (CIL) setting. By estimating the significance of model features for\neach learned class using loss gradients, gradually aging the significance\nthrough the incremental tasks and preserving the significant features through a\ndistillation loss, EXACFS effectively balances remembering old knowledge\n(stability) and learning new knowledge (plasticity). Extensive experiments on\nCIFAR-100 and ImageNet-100 demonstrate EXACFS's superior performance in\npreserving stability while acquiring plasticity.\n","authors":["S Balasubramanian","M Sai Subramaniam","Sai Sriram Talasu","Yedu Krishna P","Manepalli Pranav Phanindra Sai","Ravi Mukkamala","Darshan Gera"],"pdf_url":"https://arxiv.org/pdf/2410.23751v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.00537v2","updated":"2025-03-03T09:26:05Z","published":"2024-11-30T17:05:12Z","title":"Exact Certification of (Graph) Neural Networks Against Label Poisoning","summary":"  Machine learning models are highly vulnerable to label flipping, i.e., the\nadversarial modification (poisoning) of training labels to compromise\nperformance. Thus, deriving robustness certificates is important to guarantee\nthat test predictions remain unaffected and to understand worst-case robustness\nbehavior. However, for Graph Neural Networks (GNNs), the problem of certifying\nlabel flipping has so far been unsolved. We change this by introducing an exact\ncertification method, deriving both sample-wise and collective certificates.\nOur method leverages the Neural Tangent Kernel (NTK) to capture the training\ndynamics of wide networks enabling us to reformulate the bilevel optimization\nproblem representing label flipping into a Mixed-Integer Linear Program (MILP).\nWe apply our method to certify a broad range of GNN architectures in node\nclassification tasks. Thereby, concerning the worst-case robustness to label\nflipping: $(i)$ we establish hierarchies of GNNs on different benchmark graphs;\n$(ii)$ quantify the effect of architectural choices such as activations, depth\nand skip-connections; and surprisingly, $(iii)$ uncover a novel phenomenon of\nthe robustness plateauing for intermediate perturbation budgets across all\ninvestigated datasets and architectures. While we focus on GNNs, our\ncertificates are applicable to sufficiently wide NNs in general through their\nNTK. Thus, our work presents the first exact certificate to a poisoning attack\never derived for neural networks, which could be of independent interest. The\ncode is available at https://github.com/saper0/qpcert.\n","authors":["Mahalakshmi Sabanayagam","Lukas Gosch","Stephan Günnemann","Debarghya Ghoshdastidar"],"pdf_url":"https://arxiv.org/pdf/2412.00537v2.pdf","comment":"Published as a spotlight presentation at ICLR 2025"},{"id":"http://arxiv.org/abs/2502.16890v2","updated":"2025-03-03T08:58:48Z","published":"2025-02-24T06:40:33Z","title":"ReFocus: Reinforcing Mid-Frequency and Key-Frequency Modeling for\n  Multivariate Time Series Forecasting","summary":"  Recent advancements have progressively incorporated frequency-based\ntechniques into deep learning models, leading to notable improvements in\naccuracy and efficiency for time series analysis tasks. However, the\nMid-Frequency Spectrum Gap in the real-world time series, where the energy is\nconcentrated at the low-frequency region while the middle-frequency band is\nnegligible, hinders the ability of existing deep learning models to extract the\ncrucial frequency information. Additionally, the shared Key-Frequency in\nmultivariate time series, where different time series share indistinguishable\nfrequency patterns, is rarely exploited by existing literature. This work\nintroduces a novel module, Adaptive Mid-Frequency Energy Optimizer, based on\nconvolution and residual learning, to emphasize the significance of\nmid-frequency bands. We also propose an Energy-based Key-Frequency Picking\nBlock to capture shared Key-Frequency, which achieves superior inter-series\nmodeling performance with fewer parameters. A novel Key-Frequency Enhanced\nTraining strategy is employed to further enhance Key-Frequency modeling, where\nspectral information from other channels is randomly introduced into each\nchannel. Our approach advanced multivariate time series forecasting on the\nchallenging Traffic, ECL, and Solar benchmarks, reducing MSE by 4%, 6%, and 5%\ncompared to the previous SOTA iTransformer. Code is available at this GitHub\nRepository: https://github.com/Levi-Ackman/ReFocus.\n","authors":["Guoqi Yu","Yaoming Li","Juncheng Wang","Xiaoyu Guo","Angelica I. Aviles-Rivero","Tong Yang","Shujun Wang"],"pdf_url":"https://arxiv.org/pdf/2502.16890v2.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2502.08679v3","updated":"2025-03-03T08:50:28Z","published":"2025-02-12T08:56:35Z","title":"Deep Learning-Driven Malware Classification with API Call Sequence\n  Analysis and Concept Drift Handling","summary":"  Malware classification in dynamic environments presents a significant\nchallenge due to concept drift, where the statistical properties of malware\ndata evolve over time, complicating detection efforts. To address this issue,\nwe propose a deep learning framework enhanced with a genetic algorithm to\nimprove malware classification accuracy and adaptability. Our approach\nincorporates mutation operations and fitness score evaluations within genetic\nalgorithms to continuously refine the deep learning model, ensuring robustness\nagainst evolving malware threats. Experimental results demonstrate that this\nhybrid method significantly enhances classification performance and\nadaptability, outperforming traditional static models. Our proposed approach\noffers a promising solution for real-time malware classification in\never-changing cybersecurity landscapes.\n","authors":["Bishwajit Prasad Gond","Durga Prasad Mohapatra"],"pdf_url":"https://arxiv.org/pdf/2502.08679v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.03856v4","updated":"2025-03-03T08:48:38Z","published":"2024-07-04T11:42:36Z","title":"Q-Adapter: Customizing Pre-trained LLMs to New Preferences with\n  Forgetting Mitigation","summary":"  Large Language Models (LLMs), trained on a large amount of corpus, have\ndemonstrated remarkable abilities. However, it may not be sufficient to\ndirectly apply open-source LLMs like Llama to certain real-world scenarios,\nsince most of them are trained for \\emph{general} purposes. Thus, the demands\nfor customizing publicly available LLMs emerge, but are currently\nunder-studied. In this work, we consider customizing pre-trained LLMs with new\nhuman preferences. Specifically, the LLM should not only meet the new\npreference but also preserve its original capabilities after customization.\nDrawing inspiration from the observation that human preference can be expressed\nas a reward model, we propose to cast LLM customization as optimizing the sum\nof two reward functions, one of which (denoted as $r_1$) was used to pre-train\nthe LLM while the other (denoted as $r_2$) characterizes the new human\npreference. The obstacle here is that both reward functions are unknown, making\nthe application of modern reinforcement learning methods infeasible. Thanks to\nthe residual Q-learning framework, we can restore the customized LLM with the\npre-trained LLM and the \\emph{residual Q-function} without the reward function\n$r_1$. Moreover, we find that for a fixed pre-trained LLM, the reward function\n$r_2$ can be derived from the residual Q-function, enabling us to directly\nlearn the residual Q-function from the new human preference data upon the\nBradley-Terry model. We name our method Q-Adapter as it introduces an adapter\nmodule to approximate the residual Q-function for customizing the pre-trained\nLLM towards the new preference. Experiments based on the Llama-3.1 model on the\nDSP dataset and HH-RLHF dataset illustrate the superior effectiveness of\nQ-Adapter on both retaining existing knowledge and learning new preferences.\nCode is available at https://github.com/mansicer/Q-Adapter.\n","authors":["Yi-Chen Li","Fuxiang Zhang","Wenjie Qiu","Lei Yuan","Chengxing Jia","Zongzhang Zhang","Yang Yu","Bo An"],"pdf_url":"https://arxiv.org/pdf/2407.03856v4.pdf","comment":"Camera ready version of ICLR 2025"},{"id":"http://arxiv.org/abs/2410.07267v2","updated":"2025-03-03T08:45:31Z","published":"2024-10-09T02:44:53Z","title":"Scintillation pulse characterization with spectrum-inspired temporal\n  neural networks: case studies on particle detector signals","summary":"  Particle detectors based on scintillators are widely used in high-energy\nphysics and astroparticle physics experiments, nuclear medicine imaging,\nindustrial and environmental detection, etc. Precisely extracting scintillation\nsignal characteristics at the event level is important for these applications,\nnot only in respect of understanding the scintillator itself, but also kinds\nand physical property of incident particles. Recent researches demonstrate\ndata-driven neural networks surpass traditional statistical methods, especially\nwhen the analytical form of signals is hard to obtain, or noise is significant.\nHowever, most densely connected or convolution-based networks fail to fully\nexploit the spectral and temporal structure of scintillation signals, leaving\nlarge space for performance improvement. In this paper, we propose a network\narchitecture specially tailored for scintillation pulse characterization based\non previous works on time series analysis. The core insight is that, by\ndirectly applying Fast Fourier Transform on original signals and utilizing\ndifferent frequency components, the proposed network architecture can serve as\na lightweight and enhanced representation learning backbone. We prove our idea\nin two case studies: (a) simulation data generated with the setting of the LUX\ndark matter detector, and (b) experimental electrical signals with fast\nelectronics to emulate scintillation variations for the NICA/MPD calorimeter.\nThe proposed model achieves significantly better results than the reference\nmodel in literature and densely connected models, and demonstrates higher\ncost-efficiency than conventional machine learning methods.\n","authors":["Pengcheng Ai","Xiangming Sun","Zhi Deng","Xinchi Ran"],"pdf_url":"https://arxiv.org/pdf/2410.07267v2.pdf","comment":"29 pages, 14 figures"},{"id":"http://arxiv.org/abs/2502.11167v2","updated":"2025-03-03T08:26:12Z","published":"2025-02-16T15:38:19Z","title":"SURGE: On the Potential of Large Language Models as General-Purpose\n  Surrogate Code Executors","summary":"  Neural surrogate models have emerged as powerful and efficient tools in data\nmining. Meanwhile, large language models (LLMs) have demonstrated remarkable\ncapabilities in code-related tasks. We investigate a novel application: using\nLLMs as surrogate models for code execution prediction. Given LLMs' unique\nability to understand and process diverse programs, they present a promising\ndirection for building general-purpose surrogate models. To systematically\ninvestigate this capability, we introduce SURGE, a comprehensive benchmark with\n$1160$ problems covering $8$ key aspects: multi-language programming tasks,\ncompetition-level programming problems, repository-level code analysis,\nhigh-cost scientific computing, time-complexity-intensive algorithms, buggy\ncode analysis, programs dependent on specific compilers or execution\nenvironments, and formal mathematical proof verification. Through extensive\nempirical analysis of $21$ open-source and proprietary LLMs, we examine scaling\nlaws, data efficiency, and predictive accuracy. Our findings reveal important\ninsights about the feasibility of LLMs as efficient surrogates for\ncomputational processes, with implications for automated software testing,\nprogram analysis, and computational resource optimization in data mining\napplications. Code and dataset are released at\nhttps://github.com/Imbernoulli/SURGE.\n","authors":["Bohan Lyu","Siqiao Huang","Zichen Liang"],"pdf_url":"https://arxiv.org/pdf/2502.11167v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.19316v2","updated":"2025-03-03T08:22:25Z","published":"2024-05-29T17:39:48Z","title":"Robust Preference Optimization through Reward Model Distillation","summary":"  Language model (LM) post-training (or alignment) involves maximizing a reward\nfunction that is derived from preference annotations. Direct Preference\nOptimization (DPO) is a popular offline alignment method that trains a policy\ndirectly on preference data without the need to train a reward model or apply\nreinforcement learning. However, the empirical evidence suggests that DPO\ntypically assigns implicit rewards that overfit, and trend towards infinite\nmagnitude. This frequently leads to degenerate policies, sometimes causing even\nthe probabilities of the preferred generations to go to zero. In this work, we\nanalyze this phenomenon and use distillation to get a better proxy for the true\npreference distribution over generation pairs: we train the LM such that its\ninduced implicit reward, i.e., the scaled log-likelihood ratio of the model to\nthe reference model, matches an explicit reward model trained on the preference\ndata. Moreover, to account for uncertainty in the reward model we are\ndistilling from, we optimize against a family of reward models that, as a\nwhole, is likely to include at least one reasonable proxy for the preference\ndistribution. Our results show that distilling from such a family of reward\nmodels leads to improved robustness to distribution shift in preference\nannotations, while preserving the simple supervised nature of DPO.\n","authors":["Adam Fisch","Jacob Eisenstein","Vicky Zayats","Alekh Agarwal","Ahmad Beirami","Chirag Nagpal","Pete Shaw","Jonathan Berant"],"pdf_url":"https://arxiv.org/pdf/2405.19316v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07407v2","updated":"2025-03-03T08:05:53Z","published":"2024-12-10T10:58:47Z","title":"Towards Graph Foundation Models: A Study on the Generalization of\n  Positional and Structural Encodings","summary":"  Recent advances in integrating positional and structural encodings (PSEs)\ninto graph neural networks (GNNs) have significantly enhanced their performance\nacross various graph learning tasks. However, the general applicability of\nthese encodings and their potential to serve as foundational representations\nfor graphs remain uncertain. This paper investigates the fine-tuning\nefficiency, scalability with sample size, and generalization capability of\nlearnable PSEs across diverse graph datasets. Specifically, we evaluate their\npotential as universal pre-trained models that can be easily adapted to new\ntasks with minimal fine-tuning and limited data. Furthermore, we assess the\nexpressivity of the learned representations, particularly, when used to augment\ndownstream GNNs. We demonstrate through extensive benchmarking and empirical\nanalysis that PSEs generally enhance downstream models. However, some datasets\nmay require specific PSE-augmentations to achieve optimal performance.\nNevertheless, our findings highlight their significant potential to become\nintegral components of future graph foundation models. We provide new insights\ninto the strengths and limitations of PSEs, contributing to the broader\ndiscourse on foundation models in graph learning.\n","authors":["Billy Joe Franks","Moshe Eliasof","Semih Cantürk","Guy Wolf","Carola-Bibiane Schönlieb","Sophie Fellenz","Marius Kloft"],"pdf_url":"https://arxiv.org/pdf/2412.07407v2.pdf","comment":"Published at TMLR (https://openreview.net/forum?id=mSoDRZXsqj)"},{"id":"http://arxiv.org/abs/2410.02683v2","updated":"2025-03-03T07:20:54Z","published":"2024-10-03T17:08:52Z","title":"DailyDilemmas: Revealing Value Preferences of LLMs with Quandaries of\n  Daily Life","summary":"  As users increasingly seek guidance from LLMs for decision-making in daily\nlife, many of these decisions are not clear-cut and depend significantly on the\npersonal values and ethical standards of people. We present DailyDilemmas, a\ndataset of 1,360 moral dilemmas encountered in everyday life. Each dilemma\npresents two possible actions, along with affected parties and relevant human\nvalues for each action. Based on these dilemmas, we gather a repository of\nhuman values covering diverse everyday topics, such as interpersonal\nrelationships, workplace, and environmental issues. With DailyDilemmas, we\nevaluate LLMs on these dilemmas to determine what action they will choose and\nthe values represented by these action choices. Then, we analyze values through\nthe lens of five theoretical frameworks inspired by sociology, psychology, and\nphilosophy, including the World Values Survey, Moral Foundations Theory,\nMaslow's Hierarchy of Needs, Aristotle's Virtues, and Plutchik's Wheel of\nEmotions. For instance, we find LLMs are most aligned with self-expression over\nsurvival in World Values Survey and care over loyalty in Moral Foundations\nTheory. Interestingly, we find substantial preference differences in models for\nsome core values. For example, for truthfulness, Mixtral-8x7B neglects it by\n9.7% while GPT-4-turbo selects it by 9.4%. We also study the recent guidance\nreleased by OpenAI (ModelSpec), and Anthropic (Constitutional AI) to understand\nhow their designated principles reflect their models' actual value\nprioritization when facing nuanced moral reasoning in daily-life settings.\nFinally, we find that end users cannot effectively steer such prioritization\nusing system prompts.\n","authors":["Yu Ying Chiu","Liwei Jiang","Yejin Choi"],"pdf_url":"https://arxiv.org/pdf/2410.02683v2.pdf","comment":"Accepted into ICLR 2025 (spotlight)"},{"id":"http://arxiv.org/abs/2501.02497v2","updated":"2025-03-03T07:16:16Z","published":"2025-01-05T10:24:20Z","title":"Test-Time Compute: from System-1 Thinking to System-2 Thinking","summary":"  The remarkable performance of the o1 model in complex reasoning demonstrates\nthat test-time compute scaling can further unlock the model's potential,\nenabling powerful System-2 thinking. However, there is still a lack of\ncomprehensive surveys for test-time compute scaling. We trace the concept of\ntest-time compute back to System-1 models. In System-1 models, test-time\ncompute addresses distribution shifts and improves robustness and\ngeneralization through parameter updating, input modification, representation\nediting, and output calibration. In System-2 models, it enhances the model's\nreasoning ability to solve complex problems through repeated sampling,\nself-correction, and tree search. We organize this survey according to the\ntrend of System-1 to System-2 thinking, highlighting the key role of test-time\ncompute in the transition from System-1 models to weak System-2 models, and\nthen to strong System-2 models. We also point out a few possible future\ndirections.\n","authors":["Yixin Ji","Juntao Li","Hai Ye","Kaixin Wu","Kai Yao","Jia Xu","Linjian Mo","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2501.02497v2.pdf","comment":"work in progress"},{"id":"http://arxiv.org/abs/2403.03636v3","updated":"2025-03-03T06:56:29Z","published":"2024-03-06T11:48:08Z","title":"SheetAgent: Towards A Generalist Agent for Spreadsheet Reasoning and\n  Manipulation via Large Language Models","summary":"  Spreadsheets are ubiquitous across the World Wide Web, playing a critical\nrole in enhancing work efficiency across various domains. Large language model\n(LLM) has been recently attempted for automatic spreadsheet manipulation but\nhas not yet been investigated in complicated and realistic tasks where\nreasoning challenges exist (e.g., long horizon manipulation with multi-step\nreasoning and ambiguous requirements). To bridge the gap with the real-world\nrequirements, we introduce SheetRM, a benchmark featuring long-horizon and\nmulti-category tasks with reasoning-dependent manipulation caused by real-life\nchallenges. To mitigate the above challenges, we further propose SheetAgent, a\nnovel autonomous agent that utilizes the power of LLMs. SheetAgent consists of\nthree collaborative modules: Planner, Informer, and Retriever, achieving both\nadvanced reasoning and accurate manipulation over spreadsheets without human\ninteraction through iterative task reasoning and reflection. Extensive\nexperiments demonstrate that SheetAgent delivers 20--40\\% pass rate\nimprovements on multiple benchmarks over baselines, achieving enhanced\nprecision in spreadsheet manipulation and demonstrating superior table\nreasoning abilities. More details and visualizations are available at the\nproject website: https://sheetagent.github.io/. The datasets and source code\nare available at https://anonymous.4open.science/r/SheetAgent.\n","authors":["Yibin Chen","Yifu Yuan","Zeyu Zhang","Yan Zheng","Jinyi Liu","Fei Ni","Jianye Hao","Hangyu Mao","Fuzheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.03636v3.pdf","comment":"Accepted by International World Wide Web Conference (WWW) 2025 (oral)"},{"id":"http://arxiv.org/abs/2407.04752v2","updated":"2025-03-03T06:46:33Z","published":"2024-07-05T08:37:17Z","title":"SpikeLLM: Scaling up Spiking Neural Network to Large Language Models via\n  Saliency-based Spiking","summary":"  Recent advancements in large language models (LLMs) with billions of\nparameters have improved performance in various applications, but their\ninference processes demand significant energy and computational resources. In\ncontrast, the human brain, with approximately 86 billion neurons, is much more\nenergy-efficient than LLMs with similar parameters. Inspired by this, we\nredesign 7$\\sim$70 billion parameter LLMs using bio-plausible spiking\nmechanisms, emulating the efficient behavior of the human brain. We propose the\nfirst spiking large language model, SpikeLLM. Coupled with the proposed model,\ntwo essential approaches are proposed to improve spike training efficiency:\nGeneralized Integrate-and-Fire (GIF) neurons to compress spike length from $T$\nto $\\frac{T}{L} \\log_2 L$ bits, and an Optimal Brain Spiking framework to\ndivide outlier channels and allocate different $T$ for GIF neurons, which\nfurther compresses spike length to approximate $log_2T$ bits. The necessity of\nspike-driven LLM is proved by comparison with quantized LLMs with similar\noperations. In the OmniQuant pipeline, SpikeLLM reduces 11.01% WikiText2\nperplexity and improves 2.55% accuracy of common scene reasoning on a LLAMA-7B\nW4A4 model. In the GPTQ pipeline, SpikeLLM achieves direct additive in linear\nlayers, significantly exceeding PB-LLMs.\n","authors":["Xingrun Xing","Boyan Gao","Zheng Zhang","David A. Clifton","Shitao Xiao","Li Du","Guoqi Li","Jiajun Zhang"],"pdf_url":"https://arxiv.org/pdf/2407.04752v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.12949v2","updated":"2025-03-03T06:42:17Z","published":"2025-02-18T16:00:10Z","title":"Efficient Learning Under Density Shift in Incremental Settings Using\n  Cramér-Rao-Based Regularization","summary":"  The continuous surge in data volume and velocity is often dealt with using\ndata orchestration and distributed processing approaches, abstracting away the\nmachine learning challenges that exist at the algorithmic level. With growing\ninterest in automating the learning loop, training with data that arrive in a\nsequence rather than in the classical in-memory training data form will face a\nmachine learning challenge because of evolving feature distributions across\nbatches of training data biasing the cross-validation step\n(\\cite{sugiyama2012machine}). This work takes a distributed density estimation\nangle to the problem where data are temporally distributed. It processes data\nin batches and allows a neural network to treat a batch as training data. The\nmethod accumulates knowledge about the data density via posterior probability\nabsorption using the Fisher Information Matrix, which contains information\nabout the local optimization gradients for the batch. This is then used as a\nregularizer for the loss in the following batch, and therefore the density\nestimate for the entire dataset constructively gets more robust to the non-iid\ndistribution shift. This needs the presence of a pair of batches in memory at a\ntime, so the space cost is not a function of the size of the complete,\ndistributed dataset. We proposed a novel regularization-based approach\nCovariate Shift Correction $C^{2}A$ that leverages Fisher information and\nKullback-Leibler divergence to adapt to both natural and sequential covariate\nshift caused by dataset fragmentation. $C^{2}A$ achieves $19\\%$ accuracy at\nmaximum against state-of-the-art methods.\n","authors":["Behraj Khan","Behroz Mirza","Nouman Durrani","Tahir Syed"],"pdf_url":"https://arxiv.org/pdf/2502.12949v2.pdf","comment":"It is the older version of our this paper arXiv:2502.15756. So this\n  is the duplicate older version mistakenly uploaded. There are mistakes in the\n  method part of this paper"},{"id":"http://arxiv.org/abs/2412.15598v2","updated":"2025-03-03T06:39:17Z","published":"2024-12-20T06:42:58Z","title":"Long-Term EEG Partitioning for Seizure Onset Detection","summary":"  Deep learning models have recently shown great success in classifying\nepileptic patients using EEG recordings. Unfortunately, classification-based\nmethods lack a sound mechanism to detect the onset of seizure events. In this\nwork, we propose a two-stage framework, SODor, that explicitly models seizure\nonset through a novel task formulation of subsequence clustering. Given an EEG\nsequence, the framework first learns a set of second-level embeddings with\nlabel supervision. It then employs model-based clustering to explicitly capture\nlong-term temporal dependencies in EEG sequences and identify meaningful\nsubsequences. Epochs within a subsequence share a common cluster assignment\n(normal or seizure), with cluster or state transitions representing successful\nonset detections. Extensive experiments on three datasets demonstrate that our\nmethod can correct misclassifications, achieving 5\\%-11\\% classification\nimprovements over other baselines and accurately detecting seizure onsets.\n","authors":["Zheng Chen","Yasuko Matsubara","Yasushi Sakurai","Jimeng Sun"],"pdf_url":"https://arxiv.org/pdf/2412.15598v2.pdf","comment":"Accepted at AAAI 2025"},{"id":"http://arxiv.org/abs/2309.15531v3","updated":"2025-03-03T06:37:01Z","published":"2023-09-27T09:48:31Z","title":"Rethinking Channel Dimensions to Isolate Outliers for Low-bit Weight\n  Quantization of Large Language Models","summary":"  Large Language Models (LLMs) have recently demonstrated remarkable success\nacross various tasks. However, efficiently serving LLMs has been a challenge\ndue to the large memory bottleneck, specifically in small batch inference\nsettings (e.g. mobile devices). Weight-only quantization can be a promising\napproach, but sub-4 bit quantization remains a challenge due to large-magnitude\nactivation outliers. To mitigate the undesirable outlier effect, we first\npropose per-IC quantization, a simple yet effective method that creates\nquantization groups within each input channel (IC) rather than the conventional\nper-output-channel (per-OC). Our method is motivated by the observation that\nactivation outliers affect the input dimension of the weight matrix, so\nsimilarly grouping the weights in the IC direction can isolate outliers within\na group. We also find that activation outliers do not dictate quantization\ndifficulty, and inherent weight sensitivities also exist. With per-IC\nquantization as a new outlier-friendly scheme, we propose Adaptive Dimensions\n(AdaDim), a versatile quantization framework that can adapt to various weight\nsensitivity patterns. We demonstrate the effectiveness of AdaDim by augmenting\nprior methods such as Round-To-Nearest and GPTQ, showing significant\nimprovements across various language modeling benchmarks for both base (up to\n+4.7% on MMLU) and instruction-tuned (up to +10% on HumanEval) LLMs. Code is\navailable at https://github.com/johnheo/adadim-llm\n","authors":["Jung Hwan Heo","Jeonghoon Kim","Beomseok Kwon","Byeongwook Kim","Se Jung Kwon","Dongsoo Lee"],"pdf_url":"https://arxiv.org/pdf/2309.15531v3.pdf","comment":"ICLR 2024"},{"id":"http://arxiv.org/abs/2412.19160v2","updated":"2025-03-03T06:34:25Z","published":"2024-12-26T10:40:15Z","title":"Cross-Spectral Vision Transformer for Biometric Authentication using\n  Forehead Subcutaneous Vein Pattern and Periocular Pattern","summary":"  Traditional biometric systems have encountered significant setbacks due to\nvarious unavoidable factors, for example, face recognition-based biometrics\nfails due to the wearing of face masks and fingerprints create hygiene\nconcerns. This paper proposes a novel lightweight cross-spectral vision\ntransformer (CS-ViT) for biometric authentication using forehead subcutaneous\nvein patterns and periocular patterns, offering a promising alternative to\ntraditional methods, capable of performing well even with the face masks and\nwithout any physical touch. The proposed framework comprises a cross-spectral\ndual-channel architecture designed to handle two distinct biometric traits and\nto capture inter-dependencies in terms of relative spectral patterns. Each\nchannel consists of a Phase-Only Correlation Cross-Spectral Attention (POC-CSA)\nthat captures their individual as well as correlated patterns. The computation\nof cross-spectral attention using POC extracts the phase correlation in the\nspatial features. Therefore, it is robust against the resolution/intensity\nvariations and illumination of the input images, assuming both biometric traits\nare from the same person. The lightweight model is suitable for edge device\ndeployment. The performance of the proposed algorithm was rigorously evaluated\nusing the Forehead Subcutaneous Vein Pattern and Periocular Biometric Pattern\n(FSVP-PBP) database. The results demonstrated the superiority of the algorithm\nover state-of-the-art methods, achieving a remarkable classification accuracy\nof 98.8% with the combined vein and periocular patterns.\n","authors":["Arun K. Sharma","Shubhobrata Bhattacharya","Motahar Reza","Bishakh Bhattacharya"],"pdf_url":"https://arxiv.org/pdf/2412.19160v2.pdf","comment":"Submitted to IEEE TPAMI"},{"id":"http://arxiv.org/abs/2410.01746v2","updated":"2025-03-03T06:17:54Z","published":"2024-10-02T17:01:01Z","title":"Leray-Schauder Mappings for Operator Learning","summary":"  We present an algorithm for learning operators between Banach spaces, based\non the use of Leray-Schauder mappings to learn a finite-dimensional\napproximation of compact subspaces. We show that the resulting method is a\nuniversal approximator of (possibly nonlinear) operators. We demonstrate the\nefficiency of the approach on two benchmark datasets showing it achieves\nresults comparable to state of the art models.\n","authors":["Emanuele Zappala"],"pdf_url":"https://arxiv.org/pdf/2410.01746v2.pdf","comment":"13 pages, 2 figures, 1 table. Comments are welcome! v2: Theoretical\n  analysis expanded, several explanations regarding the experiments have been\n  added for improved clarity"},{"id":"http://arxiv.org/abs/2310.01405v4","updated":"2025-03-03T06:14:14Z","published":"2023-10-02T17:59:07Z","title":"Representation Engineering: A Top-Down Approach to AI Transparency","summary":"  In this paper, we identify and characterize the emerging area of\nrepresentation engineering (RepE), an approach to enhancing the transparency of\nAI systems that draws on insights from cognitive neuroscience. RepE places\npopulation-level representations, rather than neurons or circuits, at the\ncenter of analysis, equipping us with novel methods for monitoring and\nmanipulating high-level cognitive phenomena in deep neural networks (DNNs). We\nprovide baselines and an initial analysis of RepE techniques, showing that they\noffer simple yet effective solutions for improving our understanding and\ncontrol of large language models. We showcase how these methods can provide\ntraction on a wide range of safety-relevant problems, including honesty,\nharmlessness, power-seeking, and more, demonstrating the promise of top-down\ntransparency research. We hope that this work catalyzes further exploration of\nRepE and fosters advancements in the transparency and safety of AI systems.\n","authors":["Andy Zou","Long Phan","Sarah Chen","James Campbell","Phillip Guo","Richard Ren","Alexander Pan","Xuwang Yin","Mantas Mazeika","Ann-Kathrin Dombrowski","Shashwat Goel","Nathaniel Li","Michael J. Byun","Zifan Wang","Alex Mallen","Steven Basart","Sanmi Koyejo","Dawn Song","Matt Fredrikson","J. Zico Kolter","Dan Hendrycks"],"pdf_url":"https://arxiv.org/pdf/2310.01405v4.pdf","comment":"Code is available at\n  https://github.com/andyzoujm/representation-engineering"},{"id":"http://arxiv.org/abs/2306.14872v4","updated":"2025-03-03T06:05:48Z","published":"2023-06-26T17:38:45Z","title":"Geometry-Aware Approaches for Balancing Performance and Theoretical\n  Guarantees in Linear Bandits","summary":"  This paper is motivated by recent research in the $d$-dimensional stochastic\nlinear bandit literature, which has revealed an unsettling discrepancy:\nalgorithms like Thompson sampling and Greedy demonstrate promising empirical\nperformance, yet this contrasts with their pessimistic theoretical regret\nbounds. The challenge arises from the fact that while these algorithms may\nperform poorly in certain problem instances, they generally excel in typical\ninstances. To address this, we propose a new data-driven technique that tracks\nthe geometric properties of the uncertainty ellipsoid around the main problem\nparameter. This methodology enables us to formulate a data-driven frequentist\nregret bound, which incorporates the geometric information, for a broad class\nof base algorithms, including Greedy, OFUL, and Thompson sampling. This result\nallows us to identify and ``course-correct\" problem instances in which the base\nalgorithms perform poorly. The course-corrected algorithms achieve the minimax\noptimal regret of order $\\tilde{\\mathcal{O}}(d\\sqrt{T})$ for a $T$-period\ndecision-making scenario, effectively maintaining the desirable attributes of\nthe base algorithms, including their empirical efficacy. We present simulation\nresults to validate our findings using synthetic and real data.\n","authors":["Yuwei Luo","Mohsen Bayati"],"pdf_url":"https://arxiv.org/pdf/2306.14872v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02886v2","updated":"2025-03-03T05:49:41Z","published":"2024-11-05T07:56:24Z","title":"TokenSelect: Efficient Long-Context Inference and Length Extrapolation\n  for LLMs via Dynamic Token-Level KV Cache Selection","summary":"  The rapid advancement of Large Language Models (LLMs) has driven growing\ndemand for processing extended context sequences in contemporary applications.\nHowever, this progress faces two major challenges: performance degradation due\nto sequence lengths out-of-distribution, and excessively long inference times\ncaused by the quadratic computational complexity of attention. These issues\nhinder the application of LLMs in long-context scenarios. In this paper, we\npropose Dynamic Token-Level KV Cache Selection (TokenSelect), a training-free\nmethod for efficient and accurate long-context inference. TokenSelect builds\nupon the observation of non-contiguous attention sparsity, using Query-Key dot\nproducts to measure per-head KV Cache criticality at token-level. By per-head\nsoft voting mechanism, TokenSelect selectively involves a few critical KV cache\ntokens in attention calculation without sacrificing accuracy. To further\naccelerate TokenSelect, we design the Selection Cache based on observations of\nconsecutive Query similarity and implemented efficient dot product kernel,\nsignificantly reducing the overhead. A comprehensive evaluation of TokenSelect\ndemonstrates up to 23.84x speedup in attention computation and up to 2.28x\nacceleration in end-to-end latency, while providing superior performance\ncompared to state-of-the-art long-context inference methods.\n","authors":["Wei Wu","Zhuoshi Pan","Chao Wang","Liyi Chen","Yunchu Bai","Tianfu Wang","Kun Fu","Zheng Wang","Hui Xiong"],"pdf_url":"https://arxiv.org/pdf/2411.02886v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.04495v4","updated":"2025-03-03T05:38:10Z","published":"2024-07-05T13:35:14Z","title":"Speed-accuracy relations for the diffusion models: Wisdom from\n  nonequilibrium thermodynamics and optimal transport","summary":"  We discuss a connection between a generative model, called the diffusion\nmodel, and nonequilibrium thermodynamics for the Fokker-Planck equation, called\nstochastic thermodynamics. Based on the techniques of stochastic\nthermodynamics, we derive the speed-accuracy relations for the diffusion\nmodels, which are inequalities that relate the accuracy of data generation to\nthe entropy production rate, which can be interpreted as the speed of the\ndiffusion dynamics in the absence of the non-conservative force. From a\nstochastic thermodynamic perspective, our results provide a quantitative\ninsight into how best to generate data in diffusion models. The optimal\nlearning protocol is introduced by the geodesic of space of the 2-Wasserstein\ndistance in optimal transport theory. We numerically illustrate the validity of\nthe speed-accuracy relations for the diffusion models with different noise\nschedules and the different data. We numerically discuss our results for the\noptimal and suboptimal learning protocols. We also show the inaccurate data\ngeneration due to the non-conservative force, and the applicability of our\nresults to data generation from the real-world image datasets.\n","authors":["Kotaro Ikeda","Tomoya Uda","Daisuke Okanohara","Sosuke Ito"],"pdf_url":"https://arxiv.org/pdf/2407.04495v4.pdf","comment":"36 pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.02268v3","updated":"2025-03-03T05:32:47Z","published":"2024-10-03T07:40:14Z","title":"Structural-Entropy-Based Sample Selection for Efficient and Effective\n  Learning","summary":"  Sample selection improves the efficiency and effectiveness of machine\nlearning models by providing informative and representative samples. Typically,\nsamples can be modeled as a sample graph, where nodes are samples and edges\nrepresent their similarities. Most existing methods are based on local\ninformation, such as the training difficulty of samples, thereby overlooking\nglobal information, such as connectivity patterns. This oversight can result in\nsuboptimal selection because global information is crucial for ensuring that\nthe selected samples well represent the structural properties of the graph. To\naddress this issue, we employ structural entropy to quantify global information\nand losslessly decompose it from the whole graph to individual nodes using the\nShapley value. Based on the decomposition, we present\n$\\textbf{S}$tructural-$\\textbf{E}$ntropy-based sample $\\textbf{S}$election\n($\\textbf{SES}$), a method that integrates both global and local information to\nselect informative and representative samples. SES begins by constructing a\n$k$NN-graph among samples based on their similarities. It then measures sample\nimportance by combining structural entropy (global metric) with training\ndifficulty (local metric). Finally, SES applies importance-biased blue noise\nsampling to select a set of diverse and representative samples. Comprehensive\nexperiments on three learning scenarios -- supervised learning, active\nlearning, and continual learning -- clearly demonstrate the effectiveness of\nour method.\n","authors":["Tianchi Xie","Jiangning Zhu","Guozu Ma","Minzhi Lin","Wei Chen","Weikai Yang","Shixia Liu"],"pdf_url":"https://arxiv.org/pdf/2410.02268v3.pdf","comment":"Published as a conference paper at ICLR 2025"},{"id":"http://arxiv.org/abs/2502.01912v2","updated":"2025-03-03T05:25:43Z","published":"2025-02-04T01:05:12Z","title":"PATCH: a deep learning method to assess heterogeneity of artistic\n  practice in historical paintings","summary":"  The history of art has seen significant shifts in the manner in which\nartworks are created, making understanding of creative processes a central\nquestion in technical art history. In the Renaissance and Early Modern period,\npaintings were largely produced by master painters directing workshops of\napprentices who often contributed to projects. The masters varied significantly\nin artistic and managerial styles, meaning different combinations of artists\nand implements might be seen both between masters and within workshops or even\nindividual canvases. Information on how different workshops were managed and\nthe processes by which artworks were created remains elusive. Machine learning\nmethods have potential to unearth new information about artists' creative\nprocesses by extending the analysis of brushwork to a microscopic scale.\nAnalysis of workshop paintings, however, presents a challenge in that\ndocumentation of the artists and materials involved is sparse, meaning external\nexamples are not available to train networks to recognize their contributions.\nHere we present a novel machine learning approach we call pairwise assignment\ntraining for classifying heterogeneity (PATCH) that is capable of identifying\nindividual artistic practice regimes with no external training data, or \"ground\ntruth.\" The method achieves unsupervised results by supervised means, and\noutperforms both simple statistical procedures and unsupervised machine\nlearning methods. We apply this method to two historical paintings by the\nSpanish Renaissance master, El Greco: The Baptism of Christ and Christ on the\nCross with Landscape, and our findings regarding the former potentially\nchallenge previous work that has assigned the painting to workshop members.\nFurther, the results of our analyses create a measure of heterogeneity of\nartistic practice that can be used to characterize artworks across time and\nspace.\n","authors":["Andrew Van Horn","Lauryn Smith","Mahamad Mahmoud","Michael McMaster","Clara Pinchbeck","Ina Martin","Andrew Lininger","Anthony Ingrisano","Adam Lowe","Carlos Bayod","Elizabeth Bolman","Kenneth Singer","Michael Hinczewski"],"pdf_url":"https://arxiv.org/pdf/2502.01912v2.pdf","comment":"main text: 16 pages, 6 figures; SI: 7 pages, 3 figures; v2: minor\n  typo corrections, higher resolution figures"},{"id":"http://arxiv.org/abs/2405.13937v8","updated":"2025-03-03T05:10:46Z","published":"2024-05-22T19:10:24Z","title":"Node-Time Conditional Prompt Learning In Dynamic Graphs","summary":"  Dynamic graphs capture evolving interactions between entities, such as in\nsocial networks, online learning platforms, and crowdsourcing projects. For\ndynamic graph modeling, dynamic graph neural networks (DGNNs) have emerged as a\nmainstream technique. However, they are generally pre-trained on the link\nprediction task, leaving a significant gap from the objectives of downstream\ntasks such as node classification. To bridge the gap, prompt-based learning has\ngained traction on graphs, but most existing efforts focus on static graphs,\nneglecting the evolution of dynamic graphs. In this paper, we propose\nDYGPROMPT, a novel pre-training and prompt learning framework for dynamic graph\nmodeling. First, we design dual prompts to address the gap in both task\nobjectives and temporal variations across pre-training and downstream tasks.\nSecond, we recognize that node and time features mutually characterize each\nother, and propose dual condition-nets to model the evolving node-time patterns\nin downstream tasks. Finally, we thoroughly evaluate and analyze DYGPROMPT\nthrough extensive experiments on four public datasets.\n","authors":["Xingtong Yu","Zhenghao Liu","Xinming Zhang","Yuan Fang"],"pdf_url":"https://arxiv.org/pdf/2405.13937v8.pdf","comment":"Accepted by ICLR 2025"},{"id":"http://arxiv.org/abs/2409.07002v2","updated":"2025-03-03T04:32:29Z","published":"2024-09-11T04:30:45Z","title":"AdvLogo: Adversarial Patch Attack against Object Detectors based on\n  Diffusion Models","summary":"  With the rapid development of deep learning, object detectors have\ndemonstrated impressive performance; however, vulnerabilities still exist in\ncertain scenarios. Current research exploring the vulnerabilities using\nadversarial patches often struggles to balance the trade-off between attack\neffectiveness and visual quality. To address this problem, we propose a novel\nframework of patch attack from semantic perspective, which we refer to as\nAdvLogo. Based on the hypothesis that every semantic space contains an\nadversarial subspace where images can cause detectors to fail in recognizing\nobjects, we leverage the semantic understanding of the diffusion denoising\nprocess and drive the process to adversarial subareas by perturbing the latent\nand unconditional embeddings at the last timestep. To mitigate the distribution\nshift that exposes a negative impact on image quality, we apply perturbation to\nthe latent in frequency domain with the Fourier Transform. Experimental results\ndemonstrate that AdvLogo achieves strong attack performance while maintaining\nhigh visual quality.\n","authors":["Boming Miao","Chunxiao Li","Yao Zhu","Weixiang Sun","Zizhe Wang","Xiaoyi Wang","Chuanlong Xie"],"pdf_url":"https://arxiv.org/pdf/2409.07002v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.09906v3","updated":"2025-03-03T04:28:49Z","published":"2024-02-15T12:12:19Z","title":"Generative Representational Instruction Tuning","summary":"  All text-based language problems can be reduced to either generation or\nembedding. Current models only perform well at one or the other. We introduce\ngenerative representational instruction tuning (GRIT) whereby a large language\nmodel is trained to handle both generative and embedding tasks by\ndistinguishing between them through instructions. Compared to other open\nmodels, our resulting GritLM 7B sets a new state of the art on the Massive Text\nEmbedding Benchmark (MTEB) and outperforms all models up to its size on a range\nof generative tasks. By scaling up further, GritLM 8x7B outperforms all open\ngenerative language models that we tried while still being among the best\nembedding models. Notably, we find that GRIT matches training on only\ngenerative or embedding data, thus we can unify both at no performance loss.\nAmong other benefits, the unification via GRIT speeds up Retrieval-Augmented\nGeneration (RAG) by > 60% for long documents, by no longer requiring separate\nretrieval and generation models. Models, code, etc. are freely available at\nhttps://github.com/ContextualAI/gritlm.\n","authors":["Niklas Muennighoff","Hongjin Su","Liang Wang","Nan Yang","Furu Wei","Tao Yu","Amanpreet Singh","Douwe Kiela"],"pdf_url":"https://arxiv.org/pdf/2402.09906v3.pdf","comment":"67 pages (16 main), 25 figures, 34 tables"},{"id":"http://arxiv.org/abs/2403.17010v3","updated":"2025-03-03T04:22:19Z","published":"2024-03-25T17:59:59Z","title":"Calib3D: Calibrating Model Preferences for Reliable 3D Scene\n  Understanding","summary":"  Safety-critical 3D scene understanding tasks necessitate not only accurate\nbut also confident predictions from 3D perception models. This study introduces\nCalib3D, a pioneering effort to benchmark and scrutinize the reliability of 3D\nscene understanding models from an uncertainty estimation viewpoint. We\ncomprehensively evaluate 28 state-of-the-art models across 10 diverse 3D\ndatasets, uncovering insightful phenomena that cope with both the aleatoric and\nepistemic uncertainties in 3D scene understanding. We discover that despite\nachieving impressive levels of accuracy, existing models frequently fail to\nprovide reliable uncertainty estimates -- a pitfall that critically undermines\ntheir applicability in safety-sensitive contexts. Through extensive analysis of\nkey factors such as network capacity, LiDAR representations, rasterization\nresolutions, and 3D data augmentation techniques, we correlate these aspects\ndirectly with the model calibration efficacy. Furthermore, we introduce DeptS,\na novel depth-aware scaling approach aimed at enhancing 3D model calibration.\nExtensive experiments across a wide range of configurations validate the\nsuperiority of our method. We hope this work could serve as a cornerstone for\nfostering reliable 3D scene understanding. Code and benchmark toolkit are\npublicly available.\n","authors":["Lingdong Kong","Xiang Xu","Jun Cen","Wenwei Zhang","Liang Pan","Kai Chen","Ziwei Liu"],"pdf_url":"https://arxiv.org/pdf/2403.17010v3.pdf","comment":"WACV 2025 Oral; 26 pages, 8 figures, 12 tables; Code at\n  https://github.com/ldkong1205/Calib3D"},{"id":"http://arxiv.org/abs/2410.08892v2","updated":"2025-03-03T04:14:17Z","published":"2024-10-11T15:10:38Z","title":"Federated Learning in Practice: Reflections and Projections","summary":"  Federated Learning (FL) is a machine learning technique that enables multiple\nentities to collaboratively learn a shared model without exchanging their local\ndata. Over the past decade, FL systems have achieved substantial progress,\nscaling to millions of devices across various learning domains while offering\nmeaningful differential privacy (DP) guarantees. Production systems from\norganizations like Google, Apple, and Meta demonstrate the real-world\napplicability of FL. However, key challenges remain, including verifying\nserver-side DP guarantees and coordinating training across heterogeneous\ndevices, limiting broader adoption. Additionally, emerging trends such as large\n(multi-modal) models and blurred lines between training, inference, and\npersonalization challenge traditional FL frameworks. In response, we propose a\nredefined FL framework that prioritizes privacy principles rather than rigid\ndefinitions. We also chart a path forward by leveraging trusted execution\nenvironments and open-source ecosystems to address these challenges and\nfacilitate future advancements in FL.\n","authors":["Katharine Daly","Hubert Eichner","Peter Kairouz","H. Brendan McMahan","Daniel Ramage","Zheng Xu"],"pdf_url":"https://arxiv.org/pdf/2410.08892v2.pdf","comment":"Published at 2024 IEEE 6th International Conference on Trust, Privacy\n  and Security in Intelligent Systems, and Applications (TPS-ISA)"},{"id":"http://arxiv.org/abs/2411.02728v2","updated":"2025-03-03T04:04:30Z","published":"2024-11-05T01:55:07Z","title":"Compositional simulation-based inference for time series","summary":"  Amortized simulation-based inference (SBI) methods train neural networks on\nsimulated data to perform Bayesian inference. While this strategy avoids the\nneed for tractable likelihoods, it often requires a large number of simulations\nand has been challenging to scale to time series data. Scientific simulators\nfrequently emulate real-world dynamics through thousands of single-state\ntransitions over time. We propose an SBI approach that can exploit such\nMarkovian simulators by locally identifying parameters consistent with\nindividual state transitions. We then compose these local results to obtain a\nposterior over parameters that align with the entire time series observation.\nWe focus on applying this approach to neural posterior score estimation but\nalso show how it can be applied, e.g., to neural likelihood (ratio) estimation.\nWe demonstrate that our approach is more simulation-efficient than directly\nestimating the global posterior on several synthetic benchmark tasks and\nsimulators used in ecology and epidemiology. Finally, we validate scalability\nand simulation efficiency of our approach by applying it to a high-dimensional\nKolmogorov flow simulator with around one million data dimensions.\n","authors":["Manuel Gloeckler","Shoji Toyota","Kenji Fukumizu","Jakob H. Macke"],"pdf_url":"https://arxiv.org/pdf/2411.02728v2.pdf","comment":"To be published in the proceedings of the Thirteenth International\n  Conference on Learning Representations (ICLR 2025), Singapore, 2025"},{"id":"http://arxiv.org/abs/2502.02954v2","updated":"2025-03-03T03:56:38Z","published":"2025-02-05T07:35:15Z","title":"Direct Distributional Optimization for Provable Alignment of Diffusion\n  Models","summary":"  We introduce a novel alignment method for diffusion models from distribution\noptimization perspectives while providing rigorous convergence guarantees. We\nfirst formulate the problem as a generic regularized loss minimization over\nprobability distributions and directly optimize the distribution using the Dual\nAveraging method. Next, we enable sampling from the learned distribution by\napproximating its score function via Doob's $h$-transform technique. The\nproposed framework is supported by rigorous convergence guarantees and an\nend-to-end bound on the sampling error, which imply that when the original\ndistribution's score is known accurately, the complexity of sampling from\nshifted distributions is independent of isoperimetric conditions. This\nframework is broadly applicable to general distribution optimization problems,\nincluding alignment tasks in Reinforcement Learning with Human Feedback (RLHF),\nDirect Preference Optimization (DPO), and Kahneman-Tversky Optimization (KTO).\nWe empirically validate its performance on synthetic and image datasets using\nthe DPO objective.\n","authors":["Ryotaro Kawata","Kazusato Oko","Atsushi Nitanda","Taiji Suzuki"],"pdf_url":"https://arxiv.org/pdf/2502.02954v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.00617v4","updated":"2025-03-03T03:41:11Z","published":"2024-06-30T08:00:34Z","title":"Iterative Nash Policy Optimization: Aligning LLMs with General\n  Preferences via No-Regret Learning","summary":"  Reinforcement Learning with Human Feedback (RLHF) has achieved great success\nin aligning large language models (LLMs) with human preferences. Prevalent RLHF\napproaches are reward-based, following the Bradley-Terry (BT) model assumption,\nwhich may not fully capture the complexity of human preferences. In this paper,\nwe explore RLHF under a general preference framework and approach it from a\ngame-theoretic perspective. Specifically, we formulate the problem as a\ntwo-player game and propose a novel online algorithm, iterative Nash policy\noptimization (INPO). The key idea is to let the policy play against itself via\nno-regret learning, thereby approximating the Nash policy. Unlike previous\nmethods, INPO bypasses the need for estimating the expected win rate for\nindividual responses, which typically incurs high computational or annotation\ncosts. Instead, we introduce a new loss objective that is directly minimized\nover a preference dataset. We provide theoretical analysis for our approach and\ndemonstrate its effectiveness through experiments on various representative\nbenchmarks. With an LLaMA-3-8B-based SFT model, INPO achieves a 42.6%\nlength-controlled win rate on AlpacaEval 2.0 and a 37.8% win rate on\nArena-Hard, showing substantial improvement over the state-of-the-art online\nRLHF algorithms.\n","authors":["Yuheng Zhang","Dian Yu","Baolin Peng","Linfeng Song","Ye Tian","Mingyue Huo","Nan Jiang","Haitao Mi","Dong Yu"],"pdf_url":"https://arxiv.org/pdf/2407.00617v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.04405v3","updated":"2025-03-03T03:39:50Z","published":"2024-07-05T10:41:15Z","title":"Discovering physical laws with parallel combinatorial tree search","summary":"  Symbolic regression plays a crucial role in modern scientific research thanks\nto its capability of discovering concise and interpretable mathematical\nexpressions from data. A grand challenge lies in the arduous search for\nparsimonious and generalizable mathematical formulas, in an infinite search\nspace, while intending to fit the training data. Existing algorithms have faced\na critical bottleneck of accuracy and efficiency over a decade when handling\nproblems of complexity, which essentially hinders the pace of applying symbolic\nregression for scientific exploration across interdisciplinary domains. To this\nend, we introduce a parallel combinatorial tree search (PCTS) model to\nefficiently distill generic mathematical expressions from limited data. Through\na series of extensive experiments, we demonstrate the superior accuracy and\nefficiency of PCTS for equation discovery, which greatly outperforms the\nstate-of-the-art baseline models on over 200 synthetic and experimental\ndatasets (e.g., lifting its performance by up to 99% accuracy improvement and\none-order of magnitude speed up). PCTS represents a key advance in accurate and\nefficient data-driven discovery of symbolic, interpretable models (e.g.,\nunderlying physical laws) and marks a pivotal transition towards scalable\nsymbolic learning.\n","authors":["Kai Ruan","Yilong Xu","Ze-Feng Gao","Yike Guo","Hao Sun","Ji-Rong Wen","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2407.04405v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.01117v2","updated":"2025-03-03T03:35:00Z","published":"2025-02-03T07:13:59Z","title":"Learning to Learn Weight Generation via Trajectory Diffusion","summary":"  Diffusion-based algorithms have emerged as promising techniques for weight\ngeneration, particularly in scenarios like multi-task learning that require\nfrequent weight updates. However, existing solutions suffer from limited\ncross-task transferability. In addition, they only utilize optimal weights as\ntraining samples, ignoring the value of other weights in the optimization\nprocess. To address these issues, we propose Lt-Di, which integrates the\ndiffusion algorithm with meta-learning to generate weights for unseen tasks.\nFurthermore, we extend the vanilla diffusion algorithm into a trajectory\ndiffusion algorithm to utilize other weights along the optimization trajectory.\nTrajectory diffusion decomposes the entire diffusion chain into multiple\nshorter ones, improving training and inference efficiency. We analyze the\nconvergence properties of the weight generation paradigm and improve\nconvergence efficiency without additional time overhead. Our experiments\ndemonstrate Lt-Di's higher accuracy while reducing computational overhead\nacross various tasks, including zero-shot and few-shot learning, multi-domain\ngeneralization, and large-scale language model fine-tuning.Our code is released\nat https://anonymous.4open.science/r/Lt-Di-0E51.\n","authors":["Yunchuan Guan","Yu Liu","Ke Zhou","Zhiqi Shen","Serge Belongie","Jenq-Neng Hwang","Lei Li"],"pdf_url":"https://arxiv.org/pdf/2502.01117v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.17674v2","updated":"2025-03-03T03:24:09Z","published":"2024-07-24T23:47:05Z","title":"Struc2mapGAN: improving synthetic cryo-EM density maps with generative\n  adversarial networks","summary":"  Generating synthetic cryogenic electron microscopy 3D density maps from\nmolecular structures has potential important applications in structural\nbiology. Yet existing simulation-based methods cannot mimic all the complex\nfeatures present in experimental maps, such as secondary structure elements. As\nan alternative, we propose struc2mapGAN, a novel data-driven method that\nemploys a generative adversarial network to produce improved experimental-like\ndensity maps from molecular structures. More specifically, struc2mapGAN uses a\nnested U-Net architecture as the generator, with an additional L1 loss term and\nfurther processing of raw training experimental maps to enhance learning\nefficiency. While struc2mapGAN can promptly generate maps after training, we\ndemonstrate that it outperforms existing simulation-based methods for a wide\narray of tested maps and across various evaluation metrics.\n","authors":["Chenwei Zhang","Anne Condon","Khanh Dao Duc"],"pdf_url":"https://arxiv.org/pdf/2407.17674v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13213v2","updated":"2025-03-03T03:20:08Z","published":"2024-10-17T04:37:37Z","title":"LLMOPT: Learning to Define and Solve General Optimization Problems from\n  Scratch","summary":"  Optimization problems are prevalent across various scenarios. Formulating and\nthen solving optimization problems described by natural language often requires\nhighly specialized human expertise, which could block the widespread\napplication of optimization-based decision making. To automate problem\nformulation and solving, leveraging large language models (LLMs) has emerged as\na potential way. However, this kind of approach suffers from the issue of\noptimization generalization. Namely, the accuracy of most current LLM-based\nmethods and the generality of optimization problem types that they can model\nare still limited. In this paper, we propose a unified learning-based framework\ncalled LLMOPT to boost optimization generalization. Starting from the natural\nlanguage descriptions of optimization problems and a pre-trained LLM, LLMOPT\nconstructs the introduced five-element formulation as a universal model for\nlearning to define diverse optimization problem types. Then, LLMOPT employs the\nmulti-instruction tuning to enhance both problem formalization and solver code\ngeneration accuracy and generality. After that, to prevent hallucinations in\nLLMs, such as sacrificing solving accuracy to avoid execution errors, the model\nalignment and self-correction mechanism are adopted in LLMOPT. We evaluate the\noptimization generalization ability of LLMOPT and compared methods across six\nreal-world datasets covering roughly 20 fields such as health, environment,\nenergy and manufacturing, etc. Extensive experiment results show that LLMOPT is\nable to model various optimization problem types such as linear/nonlinear\nprogramming, mixed integer programming, and combinatorial optimization, and\nachieves a notable 11.08% average solving accuracy improvement compared with\nthe state-of-the-art methods. The code is available at\nhttps://github.com/caigaojiang/LLMOPT.\n","authors":["Caigao Jiang","Xiang Shu","Hong Qian","Xingyu Lu","Jun Zhou","Aimin Zhou","Yang Yu"],"pdf_url":"https://arxiv.org/pdf/2410.13213v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.00645v2","updated":"2025-03-03T03:19:08Z","published":"2024-10-01T12:58:37Z","title":"TSVD: Bridging Theory and Practice in Continual Learning with\n  Pre-trained Models","summary":"  The goal of continual learning (CL) is to train a model that can solve\nmultiple tasks presented sequentially. Recent CL approaches have achieved\nstrong performance by leveraging large pre-trained models that generalize well\nto downstream tasks. However, such methods lack theoretical guarantees, making\nthem prone to unexpected failures. Conversely, principled CL approaches often\nfail to achieve competitive performance. In this work, we aim to bridge this\ngap between theory and practice by designing a simple CL method that is\ntheoretically sound and highly performant. Specifically, we lift pre-trained\nfeatures into a higher dimensional space and formulate an over-parametrized\nminimum-norm least-squares problem. We find that the lifted features are highly\nill-conditioned, potentially leading to large training errors (numerical\ninstability) and increased generalization errors. We address these challenges\nby continually truncating the singular value decomposition (SVD) of the lifted\nfeatures. Our approach, termed TSVD, is stable with respect to the choice of\nhyperparameters, can handle hundreds of tasks, and outperforms state-of-the-art\nCL methods on multiple datasets. Importantly, our method satisfies a recurrence\nrelation throughout its continual learning process, which allows us to prove it\nmaintains small training and generalization errors by appropriately truncating\na fraction of SVD factors. This results in a stable continual learning method\nwith strong empirical performance and theoretical guarantees. Code available:\nhttps://github.com/liangzu/tsvd.\n","authors":["Liangzu Peng","Juan Elenter","Joshua Agterberg","Alejandro Ribeiro","René Vidal"],"pdf_url":"https://arxiv.org/pdf/2410.00645v2.pdf","comment":"47 pages, 18 figures, 16 tables (v2, accepted to ICLR 2025)"},{"id":"http://arxiv.org/abs/2410.13085v2","updated":"2025-03-03T03:08:28Z","published":"2024-10-16T23:03:27Z","title":"MMed-RAG: Versatile Multimodal RAG System for Medical Vision Language\n  Models","summary":"  Artificial Intelligence (AI) has demonstrated significant potential in\nhealthcare, particularly in disease diagnosis and treatment planning. Recent\nprogress in Medical Large Vision-Language Models (Med-LVLMs) has opened up new\npossibilities for interactive diagnostic tools. However, these models often\nsuffer from factual hallucination, which can lead to incorrect diagnoses.\nFine-tuning and retrieval-augmented generation (RAG) have emerged as methods to\naddress these issues. However, the amount of high-quality data and distribution\nshifts between training data and deployment data limit the application of\nfine-tuning methods. Although RAG is lightweight and effective, existing\nRAG-based approaches are not sufficiently general to different medical domains\nand can potentially cause misalignment issues, both between modalities and\nbetween the model and the ground truth. In this paper, we propose a versatile\nmultimodal RAG system, MMed-RAG, designed to enhance the factuality of\nMed-LVLMs. Our approach introduces a domain-aware retrieval mechanism, an\nadaptive retrieved contexts selection method, and a provable RAG-based\npreference fine-tuning strategy. These innovations make the RAG process\nsufficiently general and reliable, significantly improving alignment when\nintroducing retrieved contexts. Experimental results across five medical\ndatasets (involving radiology, ophthalmology, pathology) on medical VQA and\nreport generation demonstrate that MMed-RAG can achieve an average improvement\nof 43.8% in the factual accuracy of Med-LVLMs. Our data and code are available\nin https://github.com/richard-peng-xia/MMed-RAG.\n","authors":["Peng Xia","Kangyu Zhu","Haoran Li","Tianze Wang","Weijia Shi","Sheng Wang","Linjun Zhang","James Zou","Huaxiu Yao"],"pdf_url":"https://arxiv.org/pdf/2410.13085v2.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2406.06600v3","updated":"2025-03-03T03:05:30Z","published":"2024-06-06T13:44:57Z","title":"HORAE: A Domain-Agnostic Modeling Language for Automating Multimodal\n  Service Regulation","summary":"  Artificial intelligence is rapidly encroaching on the field of service\nregulation. This work-in-progress article presents the design principles behind\nHORAE, a unified specification language to model multimodal regulation rules\nacross a diverse set of domains. We show how HORAE facilitates an intelligent\nservice regulation pipeline by further exploiting a fine-tuned large language\nmodel named HORAE that automates the HORAE modeling process, thereby yielding\nan end-to-end framework for fully automated intelligent service regulation.\n","authors":["Yutao Sun","Mingshuai Chen","Kangjia Zhao","Jintao Chen"],"pdf_url":"https://arxiv.org/pdf/2406.06600v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.00564v3","updated":"2025-03-03T02:59:29Z","published":"2024-10-01T10:25:03Z","title":"Scaling Offline Model-Based RL via Jointly-Optimized World-Action Model\n  Pretraining","summary":"  A significant aspiration of offline reinforcement learning (RL) is to develop\na generalist agent with high capabilities from large and heterogeneous\ndatasets. However, prior approaches that scale offline RL either rely heavily\non expert trajectories or struggle to generalize to diverse unseen tasks.\nInspired by the excellent generalization of world model in conditional video\ngeneration, we explore the potential of image observation-based world model for\nscaling offline RL and enhancing generalization on novel tasks. In this paper,\nwe introduce JOWA: Jointly-Optimized World-Action model, an offline model-based\nRL agent pretrained on multiple Atari games with 6 billion tokens data to learn\ngeneral-purpose representation and decision-making ability. Our method jointly\noptimizes a world-action model through a shared transformer backbone, which\nstabilize temporal difference learning with large models during pretraining.\nMoreover, we propose a provably efficient and parallelizable planning algorithm\nto compensate for the Q-value estimation error and thus search out better\npolicies. Experimental results indicate that our largest agent, with 150\nmillion parameters, achieves 78.9% human-level performance on pretrained games\nusing only 10% subsampled offline data, outperforming existing state-of-the-art\nlarge-scale offline RL baselines by 31.6% on averange. Furthermore, JOWA scales\nfavorably with model capacity and can sample-efficiently transfer to novel\ngames using only 5k offline fine-tuning data (approximately 4 trajectories) per\ngame, demonstrating superior generalization. We will release codes and model\nweights at https://github.com/CJReinforce/JOWA\n","authors":["Jie Cheng","Ruixi Qiao","Yingwei Ma","Binhua Li","Gang Xiong","Qinghai Miao","Yongbin Li","Yisheng Lv"],"pdf_url":"https://arxiv.org/pdf/2410.00564v3.pdf","comment":"Accepted by ICLR 2025"},{"id":"http://arxiv.org/abs/2410.01337v3","updated":"2025-03-03T02:50:30Z","published":"2024-10-02T08:54:18Z","title":"PhyMPGN: Physics-encoded Message Passing Graph Network for\n  spatiotemporal PDE systems","summary":"  Solving partial differential equations (PDEs) serves as a cornerstone for\nmodeling complex dynamical systems. Recent progresses have demonstrated grand\nbenefits of data-driven neural-based models for predicting spatiotemporal\ndynamics (e.g., tremendous speedup gain compared with classical numerical\nmethods). However, most existing neural models rely on rich training data, have\nlimited extrapolation and generalization abilities, and suffer to produce\nprecise or reliable physical prediction under intricate conditions (e.g.,\nirregular mesh or geometry, complex boundary conditions, diverse PDE\nparameters, etc.). To this end, we propose a new graph learning approach,\nnamely, Physics-encoded Message Passing Graph Network (PhyMPGN), to model\nspatiotemporal PDE systems on irregular meshes given small training datasets.\nSpecifically, we incorporate a GNN into a numerical integrator to approximate\nthe temporal marching of spatiotemporal dynamics for a given PDE system.\nConsidering that many physical phenomena are governed by diffusion processes,\nwe further design a learnable Laplace block, which encodes the discrete\nLaplace-Beltrami operator, to aid and guide the GNN learning in a physically\nfeasible solution space. A boundary condition padding strategy is also designed\nto improve the model convergence and accuracy. Extensive experiments\ndemonstrate that PhyMPGN is capable of accurately predicting various types of\nspatiotemporal dynamics on coarse unstructured meshes, consistently achieves\nthe state-of-the-art results, and outperforms other baselines with considerable\ngains.\n","authors":["Bocheng Zeng","Qi Wang","Mengtao Yan","Yang Liu","Ruizhi Chengze","Yi Zhang","Hongsheng Liu","Zidong Wang","Hao Sun"],"pdf_url":"https://arxiv.org/pdf/2410.01337v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.08109v3","updated":"2025-03-03T02:45:58Z","published":"2024-10-10T16:56:05Z","title":"A Closer Look at Machine Unlearning for Large Language Models","summary":"  Large language models (LLMs) may memorize sensitive or copyrighted content,\nraising privacy and legal concerns. Due to the high cost of retraining from\nscratch, researchers attempt to employ machine unlearning to remove specific\ncontent from LLMs while preserving the overall performance. In this paper, we\ndiscuss several issues in machine unlearning for LLMs and provide our insights\non possible approaches. To address the issue of inadequate evaluation of model\noutputs after unlearning, we introduce three additional metrics to evaluate\ntoken diversity, sentence semantics, and factual correctness. We then\ncategorize unlearning methods into untargeted and targeted, and discuss their\nissues respectively. Specifically, the behavior that untargeted unlearning\nattempts to approximate is unpredictable and may involve hallucinations, and\nexisting regularization is insufficient for targeted unlearning. To alleviate\nthese issues, we propose using the objective of maximizing entropy (ME) for\nuntargeted unlearning and incorporate answer preservation (AP) loss as\nregularization for targeted unlearning. Experimental results across three\nscenarios, i.e., fictitious unlearning, continual unlearning, and real-world\nunlearning, demonstrate the effectiveness of our approaches. The code is\navailable at https://github.com/sail-sg/closer-look-LLM-unlearning.\n","authors":["Xiaojian Yuan","Tianyu Pang","Chao Du","Kejiang Chen","Weiming Zhang","Min Lin"],"pdf_url":"https://arxiv.org/pdf/2410.08109v3.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2411.18872v2","updated":"2025-03-03T02:41:10Z","published":"2024-11-28T02:50:42Z","title":"A Lean Dataset for International Math Olympiad: Small Steps towards\n  Writing Math Proofs for Hard Problems","summary":"  Using AI to write formal proofs for mathematical problems is a challenging\ntask that has seen some advancements in recent years. Automated systems such as\nLean can verify the correctness of proofs written in formal language, yet\nwriting the proofs in formal language can be challenging for humans and\nmachines. The miniF2F benchmark has 20 IMO problems in its test set, yet formal\nproofs are available only for 6 of these problems (3 of which are only written\nby mathematicians). The model with best accuracy can only prove 2 of these 20\nIMO problems, from 1950s and 60s, while its training set is a secret. In this\nwork, we write complete, original formal proofs for the remaining IMO problems\nin Lean along with 3 extra problems from IMO 2022 and 2023. This effort expands\nthe availability of proof currently in the public domain by creating 5,880\nlines of Lean proof. The goal of the paper is to pave the way for developing AI\nmodels that can automatically write the formal proofs for all the IMO problems\nin miniF2F and beyond by providing an evaluation benchmark. In this pursuit, we\ndevise a method to decompose the proofs of these problems into their building\nblocks, constructing a dataset of 1,329 lemmas with more than 40k lines of Lean\ncode. These lemmas are not trivial, yet they are approachable, providing the\nopportunity to evaluate and diagnose the failures and successes of AI models.\nWe evaluate the ability of the SOTA LLMs on our dataset and analyze their\nsuccess and failure modes from different perspectives. Our dataset and code is\navailable at: https://github.com/roozbeh-yz/IMO-Steps.\n","authors":["Roozbeh Yousefzadeh","Xuenan Cao","Azim Ospanov"],"pdf_url":"https://arxiv.org/pdf/2411.18872v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21186v2","updated":"2025-03-03T02:33:31Z","published":"2025-02-28T16:02:23Z","title":"Scalable Decision-Making in Stochastic Environments through Learned\n  Temporal Abstraction","summary":"  Sequential decision-making in high-dimensional continuous action spaces,\nparticularly in stochastic environments, faces significant computational\nchallenges. We explore this challenge in the traditional offline RL setting,\nwhere an agent must learn how to make decisions based on data collected through\na stochastic behavior policy. We present Latent Macro Action Planner (L-MAP),\nwhich addresses this challenge by learning a set of temporally extended\nmacro-actions through a state-conditional Vector Quantized Variational\nAutoencoder (VQ-VAE), effectively reducing action dimensionality. L-MAP employs\na (separate) learned prior model that acts as a latent transition model and\nallows efficient sampling of plausible actions. During planning, our approach\naccounts for stochasticity in both the environment and the behavior policy by\nusing Monte Carlo tree search (MCTS). In offline RL settings, including\nstochastic continuous control tasks, L-MAP efficiently searches over discrete\nlatent actions to yield high expected returns. Empirical results demonstrate\nthat L-MAP maintains low decision latency despite increased action\ndimensionality. Notably, across tasks ranging from continuous control with\ninherently stochastic dynamics to high-dimensional robotic hand manipulation,\nL-MAP significantly outperforms existing model-based methods and performs\non-par with strong model-free actor-critic baselines, highlighting the\neffectiveness of the proposed approach in planning in complex and stochastic\nenvironments with high-dimensional action spaces.\n","authors":["Baiting Luo","Ava Pettet","Aron Laszka","Abhishek Dubey","Ayan Mukhopadhyay"],"pdf_url":"https://arxiv.org/pdf/2502.21186v2.pdf","comment":"Accepted by ICLR2025. Code would be available at\n  https://github.com/BaitingLuo/L-MAP.git"},{"id":"http://arxiv.org/abs/2412.01021v2","updated":"2025-03-03T02:13:49Z","published":"2024-12-02T00:41:25Z","title":"On the Feature Learning in Diffusion Models","summary":"  The predominant success of diffusion models in generative modeling has\nspurred significant interest in understanding their theoretical foundations. In\nthis work, we propose a feature learning framework aimed at analyzing and\ncomparing the training dynamics of diffusion models with those of traditional\nclassification models. Our theoretical analysis demonstrates that diffusion\nmodels, due to the denoising objective, are encouraged to learn more balanced\nand comprehensive representations of the data. In contrast, neural networks\nwith a similar architecture trained for classification tend to prioritize\nlearning specific patterns in the data, often focusing on easy-to-learn\ncomponents. To support these theoretical insights, we conduct several\nexperiments on both synthetic and real-world datasets, which empirically\nvalidate our findings and highlight the distinct feature learning dynamics in\ndiffusion models compared to classification.\n","authors":["Andi Han","Wei Huang","Yuan Cao","Difan Zou"],"pdf_url":"https://arxiv.org/pdf/2412.01021v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.19228v3","updated":"2025-03-03T02:06:52Z","published":"2024-04-30T03:15:04Z","title":"Weighted Point Set Embedding for Multimodal Contrastive Learning Toward\n  Optimal Similarity Metric","summary":"  In typical multimodal contrastive learning, such as CLIP, encoders produce\none point in the latent representation space for each input. However, one-point\nrepresentation has difficulty in capturing the relationship and the similarity\nstructure of a huge amount of instances in the real world. For richer classes\nof the similarity, we propose the use of weighted point sets, namely, sets of\npairs of weight and vector, as representations of instances. In this work, we\ntheoretically show the benefit of our proposed method through a new\nunderstanding of the contrastive loss of CLIP, which we call symmetric InfoNCE.\nWe clarify that the optimal similarity that minimizes symmetric InfoNCE is the\npointwise mutual information, and show an upper bound of excess risk on\ndownstream classification tasks of representations that achieve the optimal\nsimilarity. In addition, we show that our proposed similarity based on weighted\npoint sets consistently achieves the optimal similarity. To verify the\neffectiveness of our proposed method, we demonstrate pretraining of text-image\nrepresentation models and classification tasks on common benchmarks.\n","authors":["Toshimitsu Uesaka","Taiji Suzuki","Yuhta Takida","Chieh-Hsin Lai","Naoki Murata","Yuki Mitsufuji"],"pdf_url":"https://arxiv.org/pdf/2404.19228v3.pdf","comment":"ICLR 2025 (Spotlight)"},{"id":"http://arxiv.org/abs/2309.13838v2","updated":"2025-03-03T01:47:00Z","published":"2023-09-25T02:50:22Z","title":"Penalized Principal Component Analysis Using Smoothing","summary":"  Principal components computed via PCA (principal component analysis) are\ntraditionally used to reduce dimensionality in genomic data or to correct for\npopulation stratification. In this paper, we explore the penalized eigenvalue\nproblem (PEP) which reformulates the computation of the first eigenvector as an\noptimization problem and adds an $L_1$ penalty constraint to enforce sparseness\nof the solution. The contribution of our article is threefold. First, we extend\nPEP by applying smoothing to the original LASSO-type $L_1$ penalty. This allows\none to compute analytical gradients which enable faster and more efficient\nminimization of the objective function associated with the optimization\nproblem. Second, we demonstrate how higher order eigenvectors can be calculated\nwith PEP using established results from singular value decomposition (SVD).\nThird, we present four experimental studies to demonstrate the usefulness of\nthe smoothed penalized eigenvectors. Using data from the 1000 Genomes Project\ndataset, we empirically demonstrate that our proposed smoothed PEP allows one\nto increase numerical stability and obtain meaningful eigenvectors. We also\nemploy the penalized eigenvector approach in two additional real data\napplications (computation of a polygenic risk score and clustering),\ndemonstrating that exchanging the penalized eigenvectors for their smoothed\ncounterparts can increase prediction accuracy in polygenic risk scores and\nenhance discernibility of clusterings. Moreover, we compare our proposed\nsmoothed PEP to seven state-of-the-art algorithms for sparse PCA and evaluate\nthe accuracy of the obtained eigenvectors, their support recovery, and their\nruntime.\n","authors":["Rebecca M. Hurwitz","Georg Hahn"],"pdf_url":"https://arxiv.org/pdf/2309.13838v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.02060v2","updated":"2025-03-03T01:25:46Z","published":"2024-09-03T17:08:20Z","title":"OLMoE: Open Mixture-of-Experts Language Models","summary":"  We introduce OLMoE, a fully open, state-of-the-art language model leveraging\nsparse Mixture-of-Experts (MoE). OLMoE-1B-7B has 7 billion (B) parameters but\nuses only 1B per input token. We pretrain it on 5 trillion tokens and further\nadapt it to create OLMoE-1B-7B-Instruct. Our models outperform all available\nmodels with similar active parameters, even surpassing larger ones like\nLlama2-13B-Chat and DeepSeekMoE-16B. We present various experiments on MoE\ntraining, analyze routing in our model showing high specialization, and\nopen-source all aspects of our work: model weights, training data, code, and\nlogs.\n","authors":["Niklas Muennighoff","Luca Soldaini","Dirk Groeneveld","Kyle Lo","Jacob Morrison","Sewon Min","Weijia Shi","Pete Walsh","Oyvind Tafjord","Nathan Lambert","Yuling Gu","Shane Arora","Akshita Bhagia","Dustin Schwenk","David Wadden","Alexander Wettig","Binyuan Hui","Tim Dettmers","Douwe Kiela","Ali Farhadi","Noah A. Smith","Pang Wei Koh","Amanpreet Singh","Hannaneh Hajishirzi"],"pdf_url":"https://arxiv.org/pdf/2409.02060v2.pdf","comment":"63 pages (24 main), 36 figures, 17 tables"},{"id":"http://arxiv.org/abs/2407.10223v2","updated":"2025-03-03T01:21:39Z","published":"2024-07-14T14:26:17Z","title":"On Large Language Model Continual Unlearning","summary":"  While large language models have demonstrated impressive performance across\nvarious domains and tasks, their security issues have become increasingly\nsevere. Machine unlearning has emerged as a representative approach for model\nsafety and security by removing the influence of undesired data on the target\nmodel. However, these methods do not sufficiently consider that unlearning\nrequests in real-world scenarios are continuously emerging, especially in the\ncontext of LLMs, which may lead to accumulated model utility loss that\neventually becomes unacceptable. Moreover, existing LLM unlearning methods\noften ignore previous data access limitations due to privacy concerns and\ncopyright protection. Without previous data, the utility preservation during\nunlearning is much harder. To overcome these challenges, we propose the OOO\nframework that includes an Orthogonal low-rank adapter (LoRA) for continually\nunlearning requested data and an Out-Of-Distribution (OOD) detector to measure\nthe similarity between input and unlearning data. The orthogonal LoRA achieves\nparameter disentanglement among continual unlearning requests. The OOD detector\nis trained with a novel contrastive entropy loss and utilizes a glocal-aware\nscoring mechanism. During inference, our OOO framework can decide whether and\nto what extent to load the unlearning LoRA based on the OOD detector's\npredicted similarity between the input and the unlearned knowledge. Notably,\nOOO's effectiveness does not rely on any retained data. We conducted extensive\nexperiments on OOO and state-of-the-art LLM unlearning methods across three\ntasks and seven datasets. The results indicate that OOO consistently achieves\nthe best unlearning effectiveness and utility preservation, especially when\nfacing continuous unlearning requests. The source codes can be found at\nhttps://github.com/GCYZSL/O3-LLM-UNLEARNING.\n","authors":["Chongyang Gao","Lixu Wang","Kaize Ding","Chenkai Weng","Xiao Wang","Qi Zhu"],"pdf_url":"https://arxiv.org/pdf/2407.10223v2.pdf","comment":"This paper has been accepted by ICLR 2025. The first two authors\n  contribute equally and they are ordered alphabetically"},{"id":"http://arxiv.org/abs/2407.10967v2","updated":"2025-03-03T01:19:23Z","published":"2024-07-15T17:59:23Z","title":"BECAUSE: Bilinear Causal Representation for Generalizable Offline\n  Model-based Reinforcement Learning","summary":"  Offline model-based reinforcement learning (MBRL) enhances data efficiency by\nutilizing pre-collected datasets to learn models and policies, especially in\nscenarios where exploration is costly or infeasible. Nevertheless, its\nperformance often suffers from the objective mismatch between model and policy\nlearning, resulting in inferior performance despite accurate model predictions.\nThis paper first identifies the primary source of this mismatch comes from the\nunderlying confounders present in offline data for MBRL. Subsequently, we\nintroduce \\textbf{B}ilin\\textbf{E}ar \\textbf{CAUS}al\nr\\textbf{E}presentation~(BECAUSE), an algorithm to capture causal\nrepresentation for both states and actions to reduce the influence of the\ndistribution shift, thus mitigating the objective mismatch problem.\nComprehensive evaluations on 18 tasks that vary in data quality and environment\ncontext demonstrate the superior performance of BECAUSE over existing offline\nRL algorithms. We show the generalizability and robustness of BECAUSE under\nfewer samples or larger numbers of confounders. Additionally, we offer\ntheoretical analysis of BECAUSE to prove its error bound and sample efficiency\nwhen integrating causal representation into offline MBRL.\n","authors":["Haohong Lin","Wenhao Ding","Jian Chen","Laixi Shi","Jiacheng Zhu","Bo Li","Ding Zhao"],"pdf_url":"https://arxiv.org/pdf/2407.10967v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.14519v2","updated":"2025-03-03T00:51:41Z","published":"2024-09-22T16:25:31Z","title":"RobotFingerPrint: Unified Gripper Coordinate Space for Multi-Gripper\n  Grasp Synthesis and Transfer","summary":"  We introduce a novel grasp representation named the Unified Gripper\nCoordinate Space (UGCS) for grasp synthesis and grasp transfer. Our\nrepresentation leverages spherical coordinates to create a shared coordinate\nspace across different robot grippers, enabling it to synthesize and transfer\ngrasps for both novel objects and previously unseen grippers. The strength of\nthis representation lies in the ability to map palm and fingers of a gripper\nand the unified coordinate space. Grasp synthesis is formulated as predicting\nthe unified spherical coordinates on object surface points via a conditional\nvariational autoencoder. The predicted unified gripper coordinates establish\nexact correspondences between the gripper and object points, which is used to\noptimize grasp pose and joint values. Grasp transfer is facilitated through the\npoint-to-point correspondence between any two (potentially unseen) grippers and\nsolved via a similar optimization. Extensive simulation and real-world\nexperiments showcase the efficacy of the unified grasp representation for grasp\nsynthesis in generating stable and diverse grasps. Similarly, we showcase\nreal-world grasp transfer from human demonstrations across different objects.\n","authors":["Ninad Khargonkar","Luis Felipe Casas","Balakrishnan Prabhakaran","Yu Xiang"],"pdf_url":"https://arxiv.org/pdf/2409.14519v2.pdf","comment":"8 pages, 11 figures, 3 tables. Project page available at\n  https://irvlutd.github.io/RobotFingerPrint"},{"id":"http://arxiv.org/abs/2410.01417v2","updated":"2025-03-03T00:41:36Z","published":"2024-10-02T10:58:54Z","title":"The Labyrinth of Links: Navigating the Associative Maze of Multi-modal\n  LLMs","summary":"  Multi-modal Large Language Models (MLLMs) have exhibited impressive\ncapability. However, recently many deficiencies of MLLMs have been found\ncompared to human intelligence, $\\textit{e.g.}$, hallucination. To drive the\nMLLMs study, the community dedicated efforts to building larger benchmarks with\ncomplex tasks. In this paper, we propose benchmarking an essential but usually\noverlooked intelligence: $\\textbf{association}$, a human's basic capability to\nlink observation and prior practice memory. To comprehensively investigate\nMLLM's performance on the association, we formulate the association task and\ndevise a standard benchmark based on adjective and verb semantic concepts.\nInstead of costly data annotation and curation, we propose a convenient\n$\\textbf{annotation-free}$ construction method transforming the general dataset\nfor our association tasks. Simultaneously, we devise a rigorous data refinement\nprocess to eliminate confusion in the raw dataset. Building on this database,\nwe establish three levels of association tasks: single-step, synchronous, and\nasynchronous associations. Moreover, we conduct a comprehensive investigation\ninto the MLLMs' zero-shot association capabilities, addressing multiple\ndimensions, including three distinct memory strategies, both open-source and\nclosed-source MLLMs, cutting-edge Mixture-of-Experts (MoE) models, and the\ninvolvement of human experts. Our systematic investigation shows that current\nopen-source MLLMs consistently exhibit poor capability in our association\ntasks, even the currently state-of-the-art GPT-4V(vision) also has a\nsignificant gap compared to humans. We believe our benchmark would pave the way\nfor future MLLM studies. $\\textit{Our data and code are available at:}$\nhttps://mvig-rhos.com/llm_inception.\n","authors":["Hong Li","Nanxi Li","Yuanjie Chen","Jianbin Zhu","Qinlu Guo","Cewu Lu","Yong-Lu Li"],"pdf_url":"https://arxiv.org/pdf/2410.01417v2.pdf","comment":"Accepted by ICLR 2025. Project page:\n  https://mvig-rhos.com/llm_inception"},{"id":"http://arxiv.org/abs/2405.02318v2","updated":"2025-03-03T00:38:48Z","published":"2024-04-18T00:20:48Z","title":"NL2FOL: Translating Natural Language to First-Order Logic for Logical\n  Fallacy Detection","summary":"  Translating natural language into formal language such as First-Order Logic\n(FOL) is a foundational challenge in NLP with wide-ranging applications in\nautomated reasoning, misinformation tracking, and knowledge validation. In this\npaper, we introduce Natural Language to First-Order Logic (NL2FOL), a framework\nto autoformalize natural language to FOL step by step using Large Language\nModels (LLMs). Our approach addresses key challenges in this translation\nprocess, including the integration of implicit background knowledge. By\nleveraging structured representations generated by NL2FOL, we use\nSatisfiability Modulo Theory (SMT) solvers to reason about the logical validity\nof natural language statements. We present logical fallacy detection as a case\nstudy to evaluate the efficacy of NL2FOL. Being neurosymbolic, our approach\nalso provides interpretable insights into the reasoning process and\ndemonstrates robustness without requiring model fine-tuning or labeled training\ndata. Our framework achieves strong performance on multiple datasets. On the\nLOGIC dataset, NL2FOL achieves an F1-score of 78%, while generalizing\neffectively to the LOGICCLIMATE dataset with an F1-score of 80%.\n","authors":["Abhinav Lalwani","Tasha Kim","Lovish Chopra","Christopher Hahn","Zhijing Jin","Mrinmaya Sachan"],"pdf_url":"https://arxiv.org/pdf/2405.02318v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.22729v2","updated":"2025-03-03T00:23:28Z","published":"2024-10-30T06:28:21Z","title":"Identifying Drift, Diffusion, and Causal Structure from Temporal\n  Snapshots","summary":"  Stochastic differential equations (SDEs) are a fundamental tool for modelling\ndynamic processes, including gene regulatory networks (GRNs), contaminant\ntransport, financial markets, and image generation. However, learning the\nunderlying SDE from data is a challenging task, especially if individual\ntrajectories are not observable. Motivated by burgeoning research in\nsingle-cell datasets, we present the first comprehensive approach for jointly\nidentifying the drift and diffusion of an SDE from its temporal marginals.\nAssuming linear drift and additive diffusion, we prove that these parameters\nare identifiable from marginals if and only if the initial distribution lacks\nany generalized rotational symmetries. We further prove that the causal graph\nof any SDE with additive diffusion can be recovered from the SDE parameters. To\ncomplement this theory, we adapt entropy-regularized optimal transport to\nhandle anisotropic diffusion, and introduce APPEX (Alternating Projection\nParameter Estimation from $X_0$), an iterative algorithm designed to estimate\nthe drift, diffusion, and causal graph of an additive noise SDE, solely from\ntemporal marginals. We show that APPEX iteratively decreases Kullback-Leibler\ndivergence to the true solution, and demonstrate its effectiveness on simulated\ndata from linear additive noise SDEs.\n","authors":["Vincent Guan","Joseph Janssen","Hossein Rahmani","Andrew Warren","Stephen Zhang","Elina Robeva","Geoffrey Schiebinger"],"pdf_url":"https://arxiv.org/pdf/2410.22729v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.16002v2","updated":"2025-03-03T00:11:11Z","published":"2024-05-25T01:44:35Z","title":"Does SGD really happen in tiny subspaces?","summary":"  Understanding the training dynamics of deep neural networks is challenging\ndue to their high-dimensional nature and intricate loss landscapes. Recent\nstudies have revealed that, along the training trajectory, the gradient\napproximately aligns with a low-rank top eigenspace of the training loss\nHessian, referred to as the dominant subspace. Given this alignment, this paper\nexplores whether neural networks can be trained within the dominant subspace,\nwhich, if feasible, could lead to more efficient training methods. Our primary\nobservation is that when the SGD update is projected onto the dominant\nsubspace, the training loss does not decrease further. This suggests that the\nobserved alignment between the gradient and the dominant subspace is spurious.\nSurprisingly, projecting out the dominant subspace proves to be just as\neffective as the original update, despite removing the majority of the original\nupdate component. We observe similar behavior across practical setups,\nincluding the large learning rate regime (also known as Edge of Stability),\nSharpness-Aware Minimization, momentum, and adaptive optimizers. We discuss the\nmain causes and implications of this spurious alignment, shedding light on the\ndynamics of neural network training.\n","authors":["Minhak Song","Kwangjun Ahn","Chulhee Yun"],"pdf_url":"https://arxiv.org/pdf/2405.16002v2.pdf","comment":"Published at ICLR 2025"},{"id":"http://arxiv.org/abs/2401.15262v2","updated":"2025-03-03T00:04:46Z","published":"2024-01-27T01:16:33Z","title":"Asymptotic Behavior of Adversarial Training Estimator under\n  $\\ell_\\infty$-Perturbation","summary":"  Adversarial training has been proposed to protect machine learning models\nagainst adversarial attacks. This paper focuses on adversarial training under\n$\\ell_\\infty$-perturbation, which has recently attracted much research\nattention. The asymptotic behavior of the adversarial training estimator is\ninvestigated in the generalized linear model. The results imply that the\nasymptotic distribution of the adversarial training estimator under\n$\\ell_\\infty$-perturbation could put a positive probability mass at $0$ when\nthe true parameter is $0$, providing a theoretical guarantee of the associated\nsparsity-recovery ability. Alternatively, a two-step procedure is proposed --\nadaptive adversarial training, which could further improve the performance of\nadversarial training under $\\ell_\\infty$-perturbation. Specifically, the\nproposed procedure could achieve asymptotic variable-selection consistency and\nunbiasedness. Numerical experiments are conducted to show the sparsity-recovery\nability of adversarial training under $\\ell_\\infty$-perturbation and to compare\nthe empirical performance between classic adversarial training and adaptive\nadversarial training.\n","authors":["Yiling Xie","Xiaoming Huo"],"pdf_url":"https://arxiv.org/pdf/2401.15262v2.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2409.18459v2","updated":"2025-03-03T15:04:18Z","published":"2024-09-27T05:43:22Z","title":"FoodMLLM-JP: Leveraging Multimodal Large Language Models for Japanese\n  Recipe Generation","summary":"  Research on food image understanding using recipe data has been a\nlong-standing focus due to the diversity and complexity of the data. Moreover,\nfood is inextricably linked to people's lives, making it a vital research area\nfor practical applications such as dietary management. Recent advancements in\nMultimodal Large Language Models (MLLMs) have demonstrated remarkable\ncapabilities, not only in their vast knowledge but also in their ability to\nhandle languages naturally. While English is predominantly used, they can also\nsupport multiple languages including Japanese. This suggests that MLLMs are\nexpected to significantly improve performance in food image understanding\ntasks. We fine-tuned open MLLMs LLaVA-1.5 and Phi-3 Vision on a Japanese recipe\ndataset and benchmarked their performance against the closed model GPT-4o. We\nthen evaluated the content of generated recipes, including ingredients and\ncooking procedures, using 5,000 evaluation samples that comprehensively cover\nJapanese food culture. Our evaluation demonstrates that the open models trained\non recipe data outperform GPT-4o, the current state-of-the-art model, in\ningredient generation. Our model achieved F1 score of 0.531, surpassing\nGPT-4o's F1 score of 0.481, indicating a higher level of accuracy. Furthermore,\nour model exhibited comparable performance to GPT-4o in generating cooking\nprocedure text.\n","authors":["Yuki Imajuku","Yoko Yamakata","Kiyoharu Aizawa"],"pdf_url":"https://arxiv.org/pdf/2409.18459v2.pdf","comment":"15 pages, 5 figures. We found errors in the calculation of evaluation\n  metrics, which were corrected in this version with\n  $\\color{blue}{\\text{modifications highlighted in blue}}$. Please also see the\n  Appendix"},{"id":"http://arxiv.org/abs/2503.01980v1","updated":"2025-03-03T19:01:17Z","published":"2025-03-03T19:01:17Z","title":"Recurrence-Enhanced Vision-and-Language Transformers for Robust\n  Multimodal Document Retrieval","summary":"  Cross-modal retrieval is gaining increasing efficacy and interest from the\nresearch community, thanks to large-scale training, novel architectural and\nlearning designs, and its application in LLMs and multimodal LLMs. In this\npaper, we move a step forward and design an approach that allows for multimodal\nqueries, composed of both an image and a text, and can search within\ncollections of multimodal documents, where images and text are interleaved. Our\nmodel, ReT, employs multi-level representations extracted from different layers\nof both visual and textual backbones, both at the query and document side. To\nallow for multi-level and cross-modal understanding and feature extraction, ReT\nemploys a novel Transformer-based recurrent cell that integrates both textual\nand visual features at different layers, and leverages sigmoidal gates inspired\nby the classical design of LSTMs. Extensive experiments on M2KR and M-BEIR\nbenchmarks show that ReT achieves state-of-the-art performance across diverse\nsettings. Our source code and trained models are publicly available at\nhttps://github.com/aimagelab/ReT.\n","authors":["Davide Caffagni","Sara Sarto","Marcella Cornia","Lorenzo Baraldi","Rita Cucchiara"],"pdf_url":"https://arxiv.org/pdf/2503.01980v1.pdf","comment":"CVPR 2025"},{"id":"http://arxiv.org/abs/2503.01415v1","updated":"2025-03-03T11:10:37Z","published":"2025-03-03T11:10:37Z","title":"Improving the Efficiency of VVC using Partitioning of Reference Frames","summary":"  In response to the growing demand for high-quality videos, Versatile Video\nCoding (VVC) was released in 2020, building on the hybrid coding architecture\nof its predecessor, HEVC, achieving about 50% bitrate reduction for the same\nvisual quality. It introduces more flexible block partitioning, enhancing\ncompression efficiency at the cost of increased encoding complexity. To make\nefficient use of VVC in practical applications, optimization is essential.\nVVenC, an optimized open-source VVC encoder, introduces multiple presets to\naddress the trade-off between compression efficiency and encoder complexity.\nAlthough an optimized set of encoding tools has been selected for each preset,\nthe rate-distortion (RD) search space in the encoder presets still poses a\nchallenge for efficient encoder implementations. In this paper, we propose\nEarly Termination using Reference Frames (ETRF), which improves the trade-off\nbetween encoding efficiency and time complexity and positions itself as a new\npreset between medium and fast presets. The CTU partitioning map of the\nreference frames in lower temporal layers is employed to accelerate the\nencoding of frames in higher temporal layers. The results show a reduction in\nthe encoding time of around 21% compared to the medium preset. Specifically,\nfor videos with high spatial and temporal complexities, which typically require\nlonger encoding times, the proposed method achieves a better trade-off between\nbitrate savings and encoding time compared to the fast preset.\n","authors":["Kamran Qureshi","Hadi Amirpour","Christian Timmerer"],"pdf_url":"https://arxiv.org/pdf/2503.01415v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01404v1","updated":"2025-03-03T10:58:50Z","published":"2025-03-03T10:58:50Z","title":"Multi-resolution Encoding for HTTP Adaptive Streaming using VVenC","summary":"  HTTP Adaptive Streaming (HAS) is a widely adopted method for delivering video\ncontent over the Internet, requiring each video to be encoded at multiple\nbitrates and resolution pairs, known as representations, to adapt to various\nnetwork conditions and device capabilities. This multi-bitrate encoding\nintroduces significant challenges due to the computational and time-intensive\nnature of encoding multiple representations. Conventional approaches often\nencode these videos independently without leveraging similarities between\ndifferent representations of the same input video. This paper proposes an\naccelerated multi-resolution encoding strategy that utilizes representations of\nlower resolutions as references to speed up the encoding of higher resolutions\nwhen using Versatile Video Coding (VVC); specifically in VVenC, an optimized\nopen-source software implementation. For multi-resolution encoding, a\nmid-bitrate representation serves as the reference, allowing interpolated\nencoded partition data to efficiently guide the partitioning process in higher\nresolutions. The proposed approach uses shared encoding information to reduce\nredundant calculations, optimizing partitioning decisions. Experimental results\ndemonstrate that the proposed technique achieves a reduction of up to 17%\ncompared to medium preset in encoding time across videos of varying\ncomplexities with minimal BDBR/BDT of 0.12 compared to the fast preset.\n","authors":["Kamran Qureshi","Hadi Amirpour","Christian Timmerer"],"pdf_url":"https://arxiv.org/pdf/2503.01404v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01396v1","updated":"2025-03-03T10:52:34Z","published":"2025-03-03T10:52:34Z","title":"CorrNetDroid: Android Malware Detector leveraging a Correlation-based\n  Feature Selection for Network Traffic features","summary":"  Copious mobile operating systems exist in the market, but Android remains the\nuser's choice. Meanwhile, its growing popularity has also attracted malware\ndevelopers. Researchers have proposed various static solutions for Android\nmalware detection. However, stealthier malware evade static analysis. This\nraises the need for a robust Android malware detection system capable of\ndealing with advanced threats and overcoming the shortcomings of static\nanalysis.\n  Hence, this work proposes a dynamic analysis-based Android malware detection\nsystem, CorrNetDroid, that works over network traffic flows. Many traffic\nfeatures exhibit overlapping ranges in normal and malware datasets. Therefore,\nwe first rank the features using two statistical measures, crRelevance and\nNormalized Mean Residue Similarity (NMRS), to assess feature-class and\nfeature-feature correlations. Thereafter, we introduce a novel\ncorrelation-based feature selection algorithm that applies NMRS on crRelevance\nrankings to identify the optimal feature subset for Android malware detection.\n  Experimental results highlight that our model effectively reduces the feature\nset while detecting Android malware with 99.50 percent accuracy when\nconsidering only two network traffic features. Furthermore, our experiments\ndemonstrate that the NMRS-based algorithm on crRelevance rankings outperforms\nstatistical tests such as chi-square, ANOVA, Mann-Whitney U test, and\nKruskal-Wallis test. In addition, our model surpasses various state-of-the-art\nAndroid malware detection techniques in terms of detection accuracy.\n","authors":["Yash Sharma","Anshul Arora"],"pdf_url":"https://arxiv.org/pdf/2503.01396v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01370v1","updated":"2025-03-03T10:07:19Z","published":"2025-03-03T10:07:19Z","title":"Kiss3DGen: Repurposing Image Diffusion Models for 3D Asset Generation","summary":"  Diffusion models have achieved great success in generating 2D images.\nHowever, the quality and generalizability of 3D content generation remain\nlimited. State-of-the-art methods often require large-scale 3D assets for\ntraining, which are challenging to collect. In this work, we introduce\nKiss3DGen (Keep It Simple and Straightforward in 3D Generation), an efficient\nframework for generating, editing, and enhancing 3D objects by repurposing a\nwell-trained 2D image diffusion model for 3D generation. Specifically, we\nfine-tune a diffusion model to generate ''3D Bundle Image'', a tiled\nrepresentation composed of multi-view images and their corresponding normal\nmaps. The normal maps are then used to reconstruct a 3D mesh, and the\nmulti-view images provide texture mapping, resulting in a complete 3D model.\nThis simple method effectively transforms the 3D generation problem into a 2D\nimage generation task, maximizing the utilization of knowledge in pretrained\ndiffusion models. Furthermore, we demonstrate that our Kiss3DGen model is\ncompatible with various diffusion model techniques, enabling advanced features\nsuch as 3D editing, mesh and texture enhancement, etc. Through extensive\nexperiments, we demonstrate the effectiveness of our approach, showcasing its\nability to produce high-quality 3D models efficiently.\n","authors":["Jiantao Lin","Xin Yang","Meixi Chen","Yingjie Xu","Dongyu Yan","Leyi Wu","Xinli Xu","Lie XU","Shunsi Zhang","Ying-Cong Chen"],"pdf_url":"https://arxiv.org/pdf/2503.01370v1.pdf","comment":"The first three authors contributed equally to this work"},{"id":"http://arxiv.org/abs/2503.01362v1","updated":"2025-03-03T09:55:54Z","published":"2025-03-03T09:55:54Z","title":"Streaming Piano Transcription Based on Consistent Onset and Offset\n  Decoding with Sustain Pedal Detection","summary":"  This paper describes a streaming audio-to-MIDI piano transcription approach\nthat aims to sequentially translate a music signal into a sequence of note\nonset and offset events. The sequence-to-sequence nature of this task may call\nfor the computationally-intensive transformer model for better performance,\nwhich has recently been used for offline transcription benchmarks and could be\nextended for streaming transcription with causal attention mechanisms. We\nassume that the performance limitation of this naive approach lies in the\ndecoder. Although time-frequency features useful for onset detection are\nconsiderably different from those for offset detection, the single decoder is\ntrained to output a mixed sequence of onset and offset events without guarantee\nof the correspondence between the onset and offset events of the same note. To\novercome this limitation, we propose a streaming encoder-decoder model that\nuses a convolutional encoder aggregating local acoustic features, followed by\nan autoregressive Transformer decoder detecting a variable number of onset\nevents and another decoder detecting the offset events for the active pitches\nwith validation of the sustain pedal at each time frame. Experiments using the\nMAESTRO dataset showed that the proposed streaming method performed comparably\nwith or even better than the state-of-the-art offline methods while\nsignificantly reducing the computational cost.\n","authors":["Weixing Wei","Jiahao Zhao","Yulun Wu","Kazuyoshi Yoshii"],"pdf_url":"https://arxiv.org/pdf/2503.01362v1.pdf","comment":"Accepted to ISMIR 2024"},{"id":"http://arxiv.org/abs/2503.01175v1","updated":"2025-03-03T04:47:39Z","published":"2025-03-03T04:47:39Z","title":"HOP: Heterogeneous Topology-based Multimodal Entanglement for Co-Speech\n  Gesture Generation","summary":"  Co-speech gestures are crucial non-verbal cues that enhance speech clarity\nand expressiveness in human communication, which have attracted increasing\nattention in multimodal research. While the existing methods have made strides\nin gesture accuracy, challenges remain in generating diverse and coherent\ngestures, as most approaches assume independence among multimodal inputs and\nlack explicit modeling of their interactions. In this work, we propose a novel\nmultimodal learning method named HOP for co-speech gesture generation that\ncaptures the heterogeneous entanglement between gesture motion, audio rhythm,\nand text semantics, enabling the generation of coordinated gestures. By\nleveraging spatiotemporal graph modeling, we achieve the alignment of audio and\naction. Moreover, to enhance modality coherence, we build the audio-text\nsemantic representation based on a reprogramming module, which is beneficial\nfor cross-modality adaptation. Our approach enables the trimodal system to\nlearn each other's features and represent them in the form of topological\nentanglement. Extensive experiments demonstrate that HOP achieves\nstate-of-the-art performance, offering more natural and expressive co-speech\ngesture generation. More information, codes, and demos are available here:\nhttps://star-uu-wang.github.io/HOP/\n","authors":["Hongye Cheng","Tianyu Wang","Guangsi Shi","Zexing Zhao","Yanwei Fu"],"pdf_url":"https://arxiv.org/pdf/2503.01175v1.pdf","comment":"Accepted by CVPR 2025. See https://star-uu-wang.github.io/HOP/"}]},"2025-03-02T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2502.12361v3","updated":"2025-03-02T22:19:39Z","published":"2025-02-17T22:56:42Z","title":"ConFit v2: Improving Resume-Job Matching using Hypothetical Resume\n  Embedding and Runner-Up Hard-Negative Mining","summary":"  A reliable resume-job matching system helps a company recommend suitable\ncandidates from a pool of resumes and helps a job seeker find relevant jobs\nfrom a list of job posts. However, since job seekers apply only to a few jobs,\ninteraction labels in resume-job datasets are sparse. We introduce ConFit v2,\nan improvement over ConFit to tackle this sparsity problem. We propose two\ntechniques to enhance the encoder's contrastive training process: augmenting\njob data with hypothetical reference resume generated by a large language\nmodel; and creating high-quality hard negatives from unlabeled resume/job pairs\nusing a novel hard-negative mining strategy. We evaluate ConFit v2 on two\nreal-world datasets and demonstrate that it outperforms ConFit and prior\nmethods (including BM25 and OpenAI text-embedding-003), achieving an average\nabsolute improvement of 13.8% in recall and 17.5% in nDCG across job-ranking\nand resume-ranking tasks.\n","authors":["Xiao Yu","Ruize Xu","Chengyuan Xue","Jinzhong Zhang","Xu Ma","Zhou Yu"],"pdf_url":"https://arxiv.org/pdf/2502.12361v3.pdf","comment":"arXiv admin note: text overlap with arXiv:2401.16349"},{"id":"http://arxiv.org/abs/2402.10767v2","updated":"2025-03-02T20:33:20Z","published":"2024-02-16T15:41:23Z","title":"Inference to the Best Explanation in Large Language Models","summary":"  While Large Language Models (LLMs) have found success in real-world\napplications, their underlying explanatory process is still poorly understood.\nThis paper proposes IBE-Eval, a framework inspired by philosophical accounts on\nInference to the Best Explanation (IBE) to advance the interpretation and\nevaluation of LLMs' explanations. IBE-Eval estimates the plausibility of\nnatural language explanations through a combination of explicit logical and\nlinguistic features including: consistency, parsimony, coherence, and\nuncertainty. Extensive experiments are conducted on Causal Question Answering\n(CQA), where \\textit{IBE-Eval} is tasked to select the most plausible causal\nexplanation amongst competing ones generated by LLMs (i.e., GPT 3.5 and Llama\n2). The experiments reveal that IBE-Eval can successfully identify the best\nexplanation with up to 77\\% accuracy ($\\approx 27\\%$ above random), improving\nupon a GPT 3.5-as-a-Judge baseline ($\\approx+17\\%$) while being intrinsically\nmore efficient and interpretable. Additional analyses suggest that, despite\nmodel-specific variances, LLM-generated explanations tend to conform to IBE\ncriteria and that IBE-Eval is significantly correlated with human judgment,\nopening up opportunities for future development of automated explanation\nverification tools.\n","authors":["Dhairya Dalal","Marco Valentino","André Freitas","Paul Buitelaar"],"pdf_url":"https://arxiv.org/pdf/2402.10767v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04343v2","updated":"2025-03-02T19:44:37Z","published":"2024-10-06T03:42:15Z","title":"Inference Scaling for Long-Context Retrieval Augmented Generation","summary":"  The scaling of inference computation has unlocked the potential of\nlong-context large language models (LLMs) across diverse settings. For\nknowledge-intensive tasks, the increased compute is often allocated to\nincorporate more external knowledge. However, without effectively utilizing\nsuch knowledge, solely expanding context does not always enhance performance.\nIn this work, we investigate inference scaling for retrieval augmented\ngeneration (RAG), exploring the combination of multiple strategies beyond\nsimply increasing the quantity of knowledge, including in-context learning and\niterative prompting. These strategies provide additional flexibility to scale\ntest-time computation (e.g., by increasing retrieved documents or generation\nsteps), thereby enhancing LLMs' ability to effectively acquire and utilize\ncontextual information. We address two key questions: (1) How does RAG\nperformance benefit from the scaling of inference computation when optimally\nconfigured? (2) Can we predict the optimal test-time compute allocation for a\ngiven budget by modeling the relationship between RAG performance and inference\nparameters? Our observations reveal that increasing inference computation leads\nto nearly linear gains in RAG performance when optimally allocated, a\nrelationship we describe as the inference scaling laws for RAG. Building on\nthis, we further develop the computation allocation model to estimate RAG\nperformance across different inference configurations. The model predicts\noptimal inference parameters under various computation constraints, which align\nclosely with the experimental results. By applying these optimal\nconfigurations, we demonstrate that scaling inference compute on long-context\nLLMs achieves up to 58.9% gains on benchmark datasets compared to standard RAG.\n","authors":["Zhenrui Yue","Honglei Zhuang","Aijun Bai","Kai Hui","Rolf Jagerman","Hansi Zeng","Zhen Qin","Dong Wang","Xuanhui Wang","Michael Bendersky"],"pdf_url":"https://arxiv.org/pdf/2410.04343v2.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2405.14105v4","updated":"2025-03-02T18:24:29Z","published":"2024-05-23T02:14:17Z","title":"Distributed Speculative Inference (DSI): Speculation Parallelism for\n  Provably Faster Lossless Language Model Inference","summary":"  This paper introduces distributed speculative inference (DSI), a novel\ninference algorithm that is provably faster than speculative inference (SI)\n[leviathan2023, chen2023, miao2024, sun2025, timor2025] and standard\nautoregressive inference (non-SI). Like other SI algorithms, DSI operates on\nfrozen language models (LMs), requiring no training or architectural\nmodifications, and it preserves the target distribution. Prior studies on SI\nhave demonstrated empirical speedups over non-SI--but rely on sufficiently fast\nand accurate drafters, which are often unavailable in practice. We identify a\ngap where SI can be slower than non-SI if drafters are too slow or inaccurate.\nWe close this gap by proving that DSI is faster than both SI and non-SI--given\nany drafters. DSI is therefore not only faster than SI, but also unlocks the\nacceleration of LMs for which SI fails. DSI leverages speculation parallelism\n(SP), a novel type of task parallelism, to orchestrate target and drafter\ninstances that overlap in time, establishing a new foundational tradeoff\nbetween computational resources and latency. Our simulations show that DSI is\n1.29-1.92x faster than SI in single-node setups for various off-the-shelf LMs\nand tasks. We open-source all our code.\n","authors":["Nadav Timor","Jonathan Mamou","Daniel Korat","Moshe Berchansky","Oren Pereg","Moshe Wasserblat","Tomer Galanti","Michal Gordon","David Harel"],"pdf_url":"https://arxiv.org/pdf/2405.14105v4.pdf","comment":"Published at ICLR 2025. (Link:\n  https://openreview.net/forum?id=cJd1BgZ9CS)"},{"id":"http://arxiv.org/abs/2403.08743v2","updated":"2025-03-02T17:33:03Z","published":"2024-03-13T17:46:28Z","title":"Prompting Fairness: Integrating Causality to Debias Large Language\n  Models","summary":"  Large language models (LLMs), despite their remarkable capabilities, are\nsusceptible to generating biased and discriminatory responses. As LLMs\nincreasingly influence high-stakes decision-making (e.g., hiring and\nhealthcare), mitigating these biases becomes critical. In this work, we propose\na causality-guided debiasing framework to tackle social biases, aiming to\nreduce the objectionable dependence between LLMs' decisions and the social\ninformation in the input. Our framework introduces a novel perspective to\nidentify how social information can affect an LLM's decision through different\ncausal pathways. Leveraging these causal insights, we outline principled\nprompting strategies that regulate these pathways through selection mechanisms.\nThis framework not only unifies existing prompting-based debiasing techniques,\nbut also opens up new directions for reducing bias by encouraging the model to\nprioritize fact-based reasoning over reliance on biased social cues. We\nvalidate our framework through extensive experiments on real-world datasets\nacross multiple domains, demonstrating its effectiveness in debiasing LLM\ndecisions, even with only black-box access to the model.\n","authors":["Jingling Li","Zeyu Tang","Xiaoyu Liu","Peter Spirtes","Kun Zhang","Liu Leqi","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2403.08743v2.pdf","comment":"24 pages, 10 figures"},{"id":"http://arxiv.org/abs/2502.11882v3","updated":"2025-03-02T17:15:11Z","published":"2025-02-17T15:09:45Z","title":"Leveraging Dual Process Theory in Language Agent Framework for Real-time\n  Simultaneous Human-AI Collaboration","summary":"  Agents built on large language models (LLMs) have excelled in turn-by-turn\nhuman-AI collaboration but struggle with simultaneous tasks requiring real-time\ninteraction. Latency issues and the challenge of inferring variable human\nstrategies hinder their ability to make autonomous decisions without explicit\ninstructions. Through experiments with current independent System 1 and System\n2 methods, we validate the necessity of using Dual Process Theory (DPT) in\nreal-time tasks. We propose DPT-Agent, a novel language agent framework that\nintegrates System 1 and System 2 for efficient real-time simultaneous human-AI\ncollaboration. DPT-Agent's System 1 uses a Finite-state Machine (FSM) and\ncode-as-policy for fast, intuitive, and controllable decision-making.\nDPT-Agent's System 2 integrates Theory of Mind (ToM) and asynchronous\nreflection to infer human intentions and perform reasoning-based autonomous\ndecisions. We demonstrate the effectiveness of DPT-Agent through further\nexperiments with rule-based agents and human collaborators, showing significant\nimprovements over mainstream LLM-based frameworks. DPT-Agent can effectively\nhelp LLMs convert correct slow thinking and reasoning into executable actions,\nthereby improving performance. To the best of our knowledge, DPT-Agent is the\nfirst language agent framework that achieves successful real-time simultaneous\nhuman-AI collaboration autonomously. Code of DPT-Agent can be found in\nhttps://github.com/sjtu-marl/DPT-Agent.\n","authors":["Shao Zhang","Xihuai Wang","Wenhao Zhang","Chaoran Li","Junru Song","Tingyu Li","Lin Qiu","Xuezhi Cao","Xunliang Cai","Wen Yao","Weinan Zhang","Xinbing Wang","Ying Wen"],"pdf_url":"https://arxiv.org/pdf/2502.11882v3.pdf","comment":"Preprint under review. Update the experimental results of the\n  DeepSeek-R1 series models, o3-mini-high and o3-mini-medium"},{"id":"http://arxiv.org/abs/2502.18036v2","updated":"2025-03-02T16:56:04Z","published":"2025-02-25T09:48:53Z","title":"Harnessing Multiple Large Language Models: A Survey on LLM Ensemble","summary":"  LLM Ensemble -- which involves the comprehensive use of multiple large\nlanguage models (LLMs), each aimed at handling user queries during downstream\ninference, to benefit from their individual strengths -- has gained substantial\nattention recently. The widespread availability of LLMs, coupled with their\nvarying strengths and out-of-the-box usability, has profoundly advanced the\nfield of LLM Ensemble. This paper presents the first systematic review of\nrecent developments in LLM Ensemble. First, we introduce our taxonomy of LLM\nEnsemble and discuss several related research problems. Then, we provide a more\nin-depth classification of the methods under the broad categories of\n\"ensemble-before-inference, ensemble-during-inference,\nensemble-after-inference'', and review all relevant methods. Finally, we\nintroduce related benchmarks and applications, summarize existing studies, and\nsuggest several future research directions. A curated list of papers on LLM\nEnsemble is available at https://github.com/junchenzhi/Awesome-LLM-Ensemble.\n","authors":["Zhijun Chen","Jingzheng Li","Pengpeng Chen","Zhuoran Li","Kai Sun","Yuankai Luo","Qianren Mao","Dingqi Yang","Hailong Sun","Philip S. Yu"],"pdf_url":"https://arxiv.org/pdf/2502.18036v2.pdf","comment":"9 pages, 2 figures, codebase:\n  https://github.com/junchenzhi/Awesome-LLM-Ensemble"},{"id":"http://arxiv.org/abs/2502.06563v2","updated":"2025-03-02T16:38:28Z","published":"2025-02-10T15:31:54Z","title":"Large Language Models Meet Symbolic Provers for Logical Reasoning\n  Evaluation","summary":"  First-order logic (FOL) reasoning, which involves sequential deduction, is\npivotal for intelligent systems and serves as a valuable task for evaluating\nreasoning capabilities, particularly in chain-of-thought (CoT) contexts.\nExisting benchmarks often rely on extensive human annotation or handcrafted\ntemplates, making it difficult to achieve the necessary complexity,\nscalability, and diversity for robust evaluation. To address these limitations,\nwe propose a novel framework called ProverGen that synergizes the generative\nstrengths of Large Language Models (LLMs) with the rigor and precision of\nsymbolic provers, enabling the creation of a scalable, diverse, and\nhigh-quality FOL reasoning dataset, ProverQA. ProverQA is also distinguished by\nits inclusion of accessible and logically coherent intermediate reasoning steps\nfor each problem. Our evaluation shows that state-of-the-art LLMs struggle to\nsolve ProverQA problems, even with CoT prompting, highlighting the dataset's\nchallenging nature. We also finetune Llama3.1-8B-Instruct on a separate\ntraining set generated by our framework. The finetuned model demonstrates\nconsistent improvements on both in-distribution and out-of-distribution test\nsets, suggesting the value of our proposed data generation framework. Code\navailable at: https://github.com/opendatalab/ProverGen\n","authors":["Chengwen Qi","Ren Ma","Bowen Li","He Du","Binyuan Hui","Jinwang Wu","Yuanjun Laili","Conghui He"],"pdf_url":"https://arxiv.org/pdf/2502.06563v2.pdf","comment":"Accepted by ICLR 2025"},{"id":"http://arxiv.org/abs/2410.00812v2","updated":"2025-03-02T16:32:24Z","published":"2024-10-01T15:57:48Z","title":"Generative causal testing to bridge data-driven models and scientific\n  theories in language neuroscience","summary":"  Representations from large language models are highly effective at predicting\nBOLD fMRI responses to language stimuli. However, these representations are\nlargely opaque: it is unclear what features of the language stimulus drive the\nresponse in each brain area. We present generative causal testing (GCT), a\nframework for generating concise explanations of language selectivity in the\nbrain from predictive models and then testing those explanations in follow-up\nexperiments using LLM-generated stimuli.This approach is successful at\nexplaining selectivity both in individual voxels and cortical regions of\ninterest (ROIs), including newly identified microROIs in prefrontal cortex. We\nshow that explanatory accuracy is closely related to the predictive power and\nstability of the underlying predictive models. Finally, we show that GCT can\ndissect fine-grained differences between brain areas with similar functional\nselectivity. These results demonstrate that LLMs can be used to bridge the\nwidening gap between data-driven models and formal scientific theories.\n","authors":["Richard Antonello","Chandan Singh","Shailee Jain","Aliyah Hsu","Sihang Guo","Jianfeng Gao","Bin Yu","Alexander Huth"],"pdf_url":"https://arxiv.org/pdf/2410.00812v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.19412v2","updated":"2025-03-02T16:16:39Z","published":"2025-02-26T18:56:38Z","title":"The Mighty ToRR: A Benchmark for Table Reasoning and Robustness","summary":"  Despite its real-world significance, model performance on tabular data\nremains underexplored, leaving uncertainty about which model to rely on and\nwhich prompt configuration to adopt. To address this gap, we create ToRR, a\nbenchmark for Table Reasoning and Robustness, measuring model performance and\nrobustness on table-related tasks. The benchmark includes 10 datasets that\ncover different types of table reasoning capabilities across varied domains.\nToRR goes beyond model performance rankings, and is designed to reflect whether\nmodels can handle tabular data consistently and robustly, across a variety of\ncommon table representation formats. We present a leaderboard as well as\ncomprehensive analyses of the results of leading models over ToRR. Our results\nreveal a striking pattern of brittle model behavior, where even strong models\nare unable to perform robustly on tabular data tasks. Although no specific\ntable format leads to consistently better performance, we show that testing\nover multiple formats is crucial for reliably estimating model capabilities.\nMoreover, we show that the reliability boost from testing multiple prompts can\nbe equivalent to adding more test examples. Overall, our findings show that\ntable understanding and reasoning tasks remain a significant challenge.\n","authors":["Shir Ashury-Tahan","Yifan Mai","Rajmohan C","Ariel Gera","Yotam Perlitz","Asaf Yehudai","Elron Bandel","Leshem Choshen","Eyal Shnarch","Percy Liang","Michal Shmueli-Scheuer"],"pdf_url":"https://arxiv.org/pdf/2502.19412v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.03895v2","updated":"2025-03-02T15:55:07Z","published":"2025-01-07T16:03:14Z","title":"LLaVA-Mini: Efficient Image and Video Large Multimodal Models with One\n  Vision Token","summary":"  The advent of real-time large multimodal models (LMMs) like GPT-4o has\nsparked considerable interest in efficient LMMs. LMM frameworks typically\nencode visual inputs into vision tokens (continuous representations) and\nintegrate them and textual instructions into the context of large language\nmodels (LLMs), where large-scale parameters and numerous context tokens\n(predominantly vision tokens) result in substantial computational overhead.\nPrevious efforts towards efficient LMMs always focus on replacing the LLM\nbackbone with smaller models, while neglecting the crucial issue of token\nquantity. In this paper, we introduce LLaVA-Mini, an efficient LMM with minimal\nvision tokens. To achieve a high compression ratio of vision tokens while\npreserving visual information, we first analyze how LMMs understand vision\ntokens and find that most vision tokens only play a crucial role in the early\nlayers of LLM backbone, where they mainly fuse visual information into text\ntokens. Building on this finding, LLaVA-Mini introduces modality pre-fusion to\nfuse visual information into text tokens in advance, thereby facilitating the\nextreme compression of vision tokens fed to LLM backbone into one token.\nLLaVA-Mini is a unified large multimodal model that can support the\nunderstanding of images, high-resolution images, and videos in an efficient\nmanner. Experiments across 11 image-based and 7 video-based benchmarks\ndemonstrate that LLaVA-Mini outperforms LLaVA-v1.5 with just 1 vision token\ninstead of 576. Efficiency analyses reveal that LLaVA-Mini can reduce FLOPs by\n77%, deliver low-latency responses within 40 milliseconds, and process over\n10,000 frames of video on the GPU hardware with 24GB of memory.\n","authors":["Shaolei Zhang","Qingkai Fang","Zhe Yang","Yang Feng"],"pdf_url":"https://arxiv.org/pdf/2501.03895v2.pdf","comment":"Accepted to ICLR 2025. Code: https://github.com/ictnlp/LLaVA-Mini\n  Model: https://huggingface.co/ICTNLP/llava-mini-llama-3.1-8b"},{"id":"http://arxiv.org/abs/2410.03524v2","updated":"2025-03-02T15:54:11Z","published":"2024-10-04T15:44:47Z","title":"Steering Large Language Models between Code Execution and Textual\n  Reasoning","summary":"  While a lot of recent research focuses on enhancing the textual reasoning\ncapabilities of Large Language Models (LLMs) by optimizing the multi-agent\nframework or reasoning chains, several benchmark tasks can be solved with 100\\%\nsuccess through direct coding, which is more scalable and avoids the\ncomputational overhead associated with textual iterating and searching. Textual\nreasoning has inherent limitations in solving tasks with challenges in math,\nlogics, optimization, and searching, which is unlikely to be solved by simply\nscaling up the model and data size. The recently released OpenAI GPT Code\nInterpreter and multi-agent frameworks such as AutoGen have demonstrated\nremarkable proficiency of integrating code generation and execution to solve\ncomplex tasks using LLMs. However, based on our experiments on 7 existing\npopular methods for steering code/text generation in both single- and\nmulti-turn settings with 14 tasks and 6 types of LLMs (including the new\nO1-preview), currently there is no optimal method to correctly steer LLMs to\nwrite code when needed. We discover some interesting patterns on when models\nuse code vs. textual reasoning with the evolution to task complexity and model\nsizes, which even result in an astonishingly inverse scaling behavior. We also\ndiscover that results from LLM written code are not always better than using\ntextual reasoning, even if the task could be solved through code. To mitigate\nthe above issues, we propose three methods to better steer LLM code/text\ngeneration and achieve a notable improvement. The costs of token lengths and\nruntime are thoroughly discussed for all the methods. We believe the problem of\nsteering LLM code/text generation is critical for future research and has much\nspace for further improvement. Project Page, Datasets, and Codes are available\nat https://yongchao98.github.io/CodeSteer/.\n","authors":["Yongchao Chen","Harsh Jhamtani","Srinagesh Sharma","Chuchu Fan","Chi Wang"],"pdf_url":"https://arxiv.org/pdf/2410.03524v2.pdf","comment":"32 pages, 12 figures, 12 tables"},{"id":"http://arxiv.org/abs/2410.10781v2","updated":"2025-03-02T14:37:53Z","published":"2024-10-14T17:50:28Z","title":"When Attention Sink Emerges in Language Models: An Empirical View","summary":"  Language Models (LMs) assign significant attention to the first token, even\nif it is not semantically important, which is known as attention sink. This\nphenomenon has been widely adopted in applications such as streaming/long\ncontext generation, KV cache optimization, inference acceleration, model\nquantization, and others. Despite its widespread use, a deep understanding of\nattention sink in LMs is still lacking. In this work, we first demonstrate that\nattention sinks exist universally in LMs with various inputs, even in small\nmodels. Furthermore, attention sink is observed to emerge during the LM\npre-training, motivating us to investigate how optimization, data distribution,\nloss function, and model architecture in LM pre-training influence its\nemergence. We highlight that attention sink emerges after effective\noptimization on sufficient training data. The sink position is highly\ncorrelated with the loss function and data distribution. Most importantly, we\nfind that attention sink acts more like key biases, storing extra attention\nscores, which could be non-informative and not contribute to the value\ncomputation. We also observe that this phenomenon (at least partially) stems\nfrom tokens' inner dependence on attention scores as a result of softmax\nnormalization. After relaxing such dependence by replacing softmax attention\nwith other attention operations, such as sigmoid attention without\nnormalization, attention sinks do not emerge in LMs up to 1B parameters. The\ncode is available at https://github.com/sail-sg/Attention-Sink.\n","authors":["Xiangming Gu","Tianyu Pang","Chao Du","Qian Liu","Fengzhuo Zhang","Cunxiao Du","Ye Wang","Min Lin"],"pdf_url":"https://arxiv.org/pdf/2410.10781v2.pdf","comment":"ICLR 2025 (Spotlight)"},{"id":"http://arxiv.org/abs/2409.13555v2","updated":"2025-03-02T14:36:29Z","published":"2024-09-20T14:56:33Z","title":"Generating Visual Stories with Grounded and Coreferent Characters","summary":"  Characters are important in narratives. They move the plot forward, create\nemotional connections, and embody the story's themes. Visual storytelling\nmethods focus more on the plot and events relating to it, without building the\nnarrative around specific characters. As a result, the generated stories feel\ngeneric, with character mentions being absent, vague, or incorrect. To mitigate\nthese issues, we introduce the new task of character-centric story generation\nand present the first model capable of predicting visual stories with\nconsistently grounded and coreferent character mentions. Our model is finetuned\non a new dataset which we build on top of the widely used VIST benchmark.\nSpecifically, we develop an automated pipeline to enrich VIST with visual and\ntextual character coreference chains. We also propose new evaluation metrics to\nmeasure the richness of characters and coreference in stories. Experimental\nresults show that our model generates stories with recurring characters which\nare consistent and coreferent to larger extent compared to baselines and\nstate-of-the-art systems.\n","authors":["Danyang Liu","Mirella Lapata","Frank Keller"],"pdf_url":"https://arxiv.org/pdf/2409.13555v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.07137v2","updated":"2025-03-02T14:28:33Z","published":"2024-10-09T17:53:06Z","title":"Cheating Automatic LLM Benchmarks: Null Models Achieve High Win Rates","summary":"  Automatic LLM benchmarks, such as AlpacaEval 2.0, Arena-Hard-Auto, and\nMT-Bench, have become popular for evaluating language models due to their\ncost-effectiveness and scalability compared to human evaluation. Achieving high\nwin rates on these benchmarks can significantly boost the promotional impact of\nnewly released language models. This promotional benefit may motivate tricks,\nsuch as manipulating model output length or style to game win rates, even\nthough several mechanisms have been developed to control length and disentangle\nstyle to reduce gameability. Nonetheless, we show that even a \"null model\" that\nalways outputs a constant response (irrelevant to input instructions) can cheat\nautomatic benchmarks and achieve top-ranked win rates: an 86.5% LC win rate on\nAlpacaEval 2.0; an 83.0 score on Arena-Hard-Auto; and a 9.55 score on MT-Bench.\nMoreover, the crafted cheating outputs are transferable because we assume that\nthe instructions of these benchmarks (e.g., 805 samples of AlpacaEval 2.0) are\nprivate and cannot be accessed. While our experiments are primarily\nproof-of-concept, an adversary could use LLMs to generate more imperceptible\ncheating responses, unethically benefiting from high win rates and promotional\nimpact. Our findings call for the development of anti-cheating mechanisms for\nreliable automatic benchmarks. The code is available at\nhttps://github.com/sail-sg/Cheating-LLM-Benchmarks.\n","authors":["Xiaosen Zheng","Tianyu Pang","Chao Du","Qian Liu","Jing Jiang","Min Lin"],"pdf_url":"https://arxiv.org/pdf/2410.07137v2.pdf","comment":"ICLR 2025 (Oral)"},{"id":"http://arxiv.org/abs/2411.03962v4","updated":"2025-03-02T13:52:25Z","published":"2024-11-06T14:51:02Z","title":"How Does A Text Preprocessing Pipeline Affect Ontology Syntactic\n  Matching?","summary":"  The generic text preprocessing pipeline, comprising Tokenisation,\nNormalisation, Stop Words Removal, and Stemming/Lemmatisation, has been\nimplemented in many systems for syntactic ontology matching (OM). However, the\nlack of standardisation in text preprocessing creates diversity in mapping\nresults. In this paper, we investigate the effect of the text preprocessing\npipeline on syntactic OM in 8 Ontology Alignment Evaluation Initiative (OAEI)\ntracks with 49 distinct alignments. We find that Phase 1 text preprocessing\n(Tokenisation and Normalisation) is currently more effective than Phase 2 text\npreprocessing (Stop Words Removal and Stemming/Lemmatisation). To repair the\nless effective Phase 2 text preprocessing caused by unwanted false mappings, we\npropose a novel context-based pipeline repair approach that employs an ad hoc\ncheck to find common words that cause false mappings. These words are stored in\na reserved word set and applied in text preprocessing. The experimental results\nshow that our approach improves the matching correctness and the overall\nmatching performance. We also discuss the integration of the classical text\npreprocessing pipeline with modern large language models (LLMs). We recommend\nthat LLMs inject the text preprocessing pipeline via function calling to avoid\nthe tendency towards unstable true mappings produced by prompt-based LLM\napproaches, and use LLMs to repair false mappings generated by the text\npreprocessing pipeline.\n","authors":["Zhangcheng Qiang","Kerry Taylor","Weiqing Wang"],"pdf_url":"https://arxiv.org/pdf/2411.03962v4.pdf","comment":"13 pages, 11 figures, 4 tables"},{"id":"http://arxiv.org/abs/2406.15812v2","updated":"2025-03-02T12:28:24Z","published":"2024-06-22T10:36:04Z","title":"Intrinsic Dimension Correlation: uncovering nonlinear connections in\n  multimodal representations","summary":"  To gain insight into the mechanisms behind machine learning methods, it is\ncrucial to establish connections among the features describing data points.\nHowever, these correlations often exhibit a high-dimensional and strongly\nnonlinear nature, which makes them challenging to detect using standard\nmethods. This paper exploits the entanglement between intrinsic dimensionality\nand correlation to propose a metric that quantifies the (potentially nonlinear)\ncorrelation between high-dimensional manifolds. We first validate our method on\nsynthetic data in controlled environments, showcasing its advantages and\ndrawbacks compared to existing techniques. Subsequently, we extend our analysis\nto large-scale applications in neural network representations. Specifically, we\nfocus on latent representations of multimodal data, uncovering clear\ncorrelations between paired visual and textual embeddings, whereas existing\nmethods struggle significantly in detecting similarity. Our results indicate\nthe presence of highly nonlinear correlation patterns between latent manifolds.\n","authors":["Lorenzo Basile","Santiago Acevedo","Luca Bortolussi","Fabio Anselmi","Alex Rodriguez"],"pdf_url":"https://arxiv.org/pdf/2406.15812v2.pdf","comment":"Accepted at ICLR 2025"},{"id":"http://arxiv.org/abs/2405.01229v2","updated":"2025-03-02T12:27:07Z","published":"2024-05-02T12:18:14Z","title":"Boosting Jailbreak Attack with Momentum","summary":"  Large Language Models (LLMs) have achieved remarkable success across diverse\ntasks, yet they remain vulnerable to adversarial attacks, notably the\nwell-known jailbreak attack. In particular, the Greedy Coordinate Gradient\n(GCG) attack has demonstrated efficacy in exploiting this vulnerability by\noptimizing adversarial prompts through a combination of gradient heuristics and\ngreedy search. However, the efficiency of this attack has become a bottleneck\nin the attacking process. To mitigate this limitation, in this paper we rethink\nthe generation of the adversarial prompts through an optimization lens, aiming\nto stabilize the optimization process and harness more heuristic insights from\nprevious optimization iterations. Specifically, we propose the\n\\textbf{M}omentum \\textbf{A}ccelerated G\\textbf{C}G (\\textbf{MAC}) attack,\nwhich integrates a momentum term into the gradient heuristic to boost and\nstabilize the random search for tokens in adversarial prompts. Experimental\nresults showcase the notable enhancement achieved by MAC over baselines in\nterms of attack success rate and optimization efficiency. Moreover, we\ndemonstrate that MAC can still exhibit superior performance for transfer\nattacks and models under defense mechanisms. Our code is available at\nhttps://github.com/weizeming/momentum-attack-llm.\n","authors":["Yihao Zhang","Zeming Wei"],"pdf_url":"https://arxiv.org/pdf/2405.01229v2.pdf","comment":"Accepted by ICASSP 2025"},{"id":"http://arxiv.org/abs/2310.17953v4","updated":"2025-03-02T12:17:06Z","published":"2023-10-27T08:01:55Z","title":"Developing a Multilingual Dataset and Evaluation Metrics for\n  Code-Switching: A Focus on Hong Kong's Polylingual Dynamics","summary":"  The existing audio datasets are predominantly tailored towards single\nlanguages, overlooking the complex linguistic behaviors of multilingual\ncommunities that engage in code-switching. This practice, where individuals\nfrequently mix two or more languages in their daily interactions, is\nparticularly prevalent in multilingual regions such as Hong Kong, China. To\nbridge this gap, we have developed a 34.8-hour dataset of Mixed Cantonese and\nEnglish (MCE) audio using our Multi-Agent Data Generation Framework (MADGF). We\nfine-tuned the open-source multilingual Automatic Speech Recognition (ASR)\nmodel, Whisper, with the MCE dataset, leading to impressive zero-shot\nperformance. The traditional metrics overlook important factors such as latency\nin real-world applications and code-switching scenarios. We have introduced a\nnovel evaluation metric called Fidelity to the Original Audio, Accuracy, and\nLatency (FAL). This metric aims to overcome the limitations of traditional\nmetrics used to assess ASR systems.\n","authors":["Peng Xie","Kani Chen"],"pdf_url":"https://arxiv.org/pdf/2310.17953v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.13940v3","updated":"2025-03-02T12:11:13Z","published":"2024-08-25T21:20:17Z","title":"Derailer-Rerailer: Adaptive Verification for Efficient and Reliable\n  Language Model Reasoning","summary":"  Large Language Models (LLMs) have shown impressive reasoning capabilities,\nyet existing prompting methods face a critical trade-off: simple approaches\noften struggle with complex tasks and reasoning stability, while more\nsophisticated methods require multiple inferences and substantial computational\nresources, limiting their practical deployment. To address this challenge, we\npropose Derailer-Rerailer, a novel framework that adaptively balances reasoning\naccuracy and computational efficiency. At its core, our framework employs a\nlightweight Derailer mechanism to assess reasoning stability and selectively\ntriggers an advanced Rerailer verification process only when necessary, thereby\noptimizing computational resource usage. Extensive evaluation across both open\nand closed-source models on more than 20 categories of mathematical, symbolic,\nand commonsense reasoning tasks demonstrates our framework's effectiveness:\nDerailer-Rerailer achieves significant accuracy improvements (8-11\\% across\nvarious reasoning tasks) while maintaining 2-3 times better efficiency than\nexisting verification methods, with particularly strong performance in\nmathematical and symbolic reasoning, offering a practical solution for\nenhancing LLM reasoning reliability while significantly reducing computational\noverhead.\n","authors":["Guangya Wan","Yuqi Wu","Hao Wang","Shengming Zhao","Jie Chen","Sheng Li"],"pdf_url":"https://arxiv.org/pdf/2408.13940v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.19649v2","updated":"2025-03-02T11:23:58Z","published":"2025-02-27T00:40:01Z","title":"Taxonomy, Opportunities, and Challenges of Representation Engineering\n  for Large Language Models","summary":"  Representation Engineering (RepE) is a novel paradigm for controlling the\nbehavior of LLMs. Unlike traditional approaches that modify inputs or fine-tune\nthe model, RepE directly manipulates the model's internal representations. As a\nresult, it may offer more effective, interpretable, data-efficient, and\nflexible control over models' behavior. We present the first comprehensive\nsurvey of RepE for LLMs, reviewing the rapidly growing literature to address\nkey questions: What RepE methods exist and how do they differ? For what\nconcepts and problems has RepE been applied? What are the strengths and\nweaknesses of RepE compared to other methods? To answer these, we propose a\nunified framework describing RepE as a pipeline comprising representation\nidentification, operationalization, and control. We posit that while RepE\nmethods offer significant potential, challenges remain, including managing\nmultiple concepts, ensuring reliability, and preserving models' performance.\nTowards improving RepE, we identify opportunities for experimental and\nmethodological improvements and construct a guide for best practices.\n","authors":["Jan Wehner","Sahar Abdelnabi","Daniel Tan","David Krueger","Mario Fritz"],"pdf_url":"https://arxiv.org/pdf/2502.19649v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14666v2","updated":"2025-03-02T10:38:32Z","published":"2024-10-18T17:56:11Z","title":"DiscoGraMS: Enhancing Movie Screen-Play Summarization using Movie\n  Character-Aware Discourse Graph","summary":"  Summarizing movie screenplays presents a unique set of challenges compared to\nstandard document summarization. Screenplays are not only lengthy, but also\nfeature a complex interplay of characters, dialogues, and scenes, with numerous\ndirect and subtle relationships and contextual nuances that are difficult for\nmachine learning models to accurately capture and comprehend. Recent attempts\nat screenplay summarization focus on fine-tuning transformer-based pre-trained\nmodels, but these models often fall short in capturing long-term dependencies\nand latent relationships, and frequently encounter the \"lost in the middle\"\nissue. To address these challenges, we introduce DiscoGraMS, a novel resource\nthat represents movie scripts as a movie character-aware discourse graph (CaD\nGraph). This approach is well-suited for various downstream tasks, such as\nsummarization, question-answering, and salience detection. The model aims to\npreserve all salient information, offering a more comprehensive and faithful\nrepresentation of the screenplay's content. We further explore a baseline\nmethod that combines the CaD Graph with the corresponding movie script through\na late fusion of graph and text modalities, and we present very initial\npromising results.\n","authors":["Maitreya Prafulla Chitale","Uday Bindal","Rajakrishnan Rajkumar","Rahul Mishra"],"pdf_url":"https://arxiv.org/pdf/2410.14666v2.pdf","comment":"Accepted at NAACL 2025 (Main)"},{"id":"http://arxiv.org/abs/2502.14897v2","updated":"2025-03-02T10:18:09Z","published":"2025-02-17T21:35:18Z","title":"Market-Derived Financial Sentiment Analysis: Context-Aware Language\n  Models for Crypto Forecasting","summary":"  Financial Sentiment Analysis (FSA) traditionally relies on human-annotated\nsentiment labels to infer investor sentiment and forecast market movements.\nHowever, inferring the potential market impact of words based on their\nhuman-perceived intentions is inherently challenging. We hypothesize that the\nhistorical market reactions to words, offer a more reliable indicator of their\npotential impact on markets than subjective sentiment interpretations by human\nannotators. To test this hypothesis, a market-derived labeling approach is\nproposed to assign tweet labels based on ensuing short-term price trends,\nenabling the language model to capture the relationship between textual signals\nand market dynamics directly. A domain-specific language model was fine-tuned\non these labels, achieving up to an 11% improvement in short-term trend\nprediction accuracy over traditional sentiment-based benchmarks. Moreover, by\nincorporating market and temporal context through prompt-tuning, the proposed\ncontext-aware language model demonstrated an accuracy of 89.6% on a curated\ndataset of 227 impactful Bitcoin-related news events with significant market\nimpacts. Aggregating daily tweet predictions into trading signals, our method\noutperformed traditional fusion models (which combine sentiment-based and\nprice-based predictions). It challenged the assumption that sentiment-based\nsignals are inferior to price-based predictions in forecasting market\nmovements. Backtesting these signals across three distinct market regimes\nyielded robust Sharpe ratios of up to 5.07 in trending markets and 3.73 in\nneutral markets. Our findings demonstrate that language models can serve as\neffective short-term market predictors. This paradigm shift underscores the\nuntapped capabilities of language models in financial decision-making and opens\nnew avenues for market prediction applications.\n","authors":["Hamid Moradi-Kamali","Mohammad-Hossein Rajabi-Ghozlou","Mahdi Ghazavi","Ali Soltani","Amirreza Sattarzadeh","Reza Entezari-Maleki"],"pdf_url":"https://arxiv.org/pdf/2502.14897v2.pdf","comment":"13 pages, 6 figures"},{"id":"http://arxiv.org/abs/2408.10557v2","updated":"2025-03-02T09:59:36Z","published":"2024-08-20T05:45:04Z","title":"Speech Representation Learning Revisited: The Necessity of Separate\n  Learnable Parameters and Robust Data Augmentation","summary":"  Speech modeling methods learn one embedding for a fixed segment of speech,\ntypically in between 10-25 ms. The information present in speech can be divided\ninto two categories: \"what is being said\" (content) and \"how it is expressed\"\n(other) and these two are orthogonal in nature causing the optimization\nalgorithm to find a sub-optimal solution if forced to optimize together. This\nleads to sub-optimal performance in one or all downstream tasks as shown by\nprevious studies. Current self-supervised learning (SSL) methods such as HuBERT\nare very good at modeling the content information present in speech. Data\naugmentation improves the performance on tasks which require effective modeling\nof other information but this leads to a divided capacity of the model. In this\nwork, we conduct a preliminary study to understand the importance of modeling\nother information using separate learnable parameters. We propose a modified\nversion of HuBERT, termed Other HuBERT (O-HuBERT), to test our hypothesis. Our\nfindings are twofold: first, the O-HuBERT method is able to utilize all layers\nto build complex features to encode other information; second, a robust data\naugmentation strategy is essential for learning the information required by\ntasks that depend on other information and to achieve state-of-the-art (SOTA)\nperformance on the SUPERB benchmark with a similarly sized model (100 million\nparameters) and pre-training data (960 hours).\n","authors":["Hemant Yadav","Sunayana Sitaram","Rajiv Ratn Shah"],"pdf_url":"https://arxiv.org/pdf/2408.10557v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.04236v3","updated":"2025-03-02T09:39:57Z","published":"2024-02-06T18:43:48Z","title":"CogCoM: A Visual Language Model with Chain-of-Manipulations Reasoning","summary":"  Vision-Language Models (VLMs) have demonstrated their broad effectiveness\nthanks to extensive training in aligning visual instructions to responses.\nHowever, such training of conclusive alignment leads models to ignore essential\nvisual reasoning, further resulting in failures in meticulous visual problems\nand unfaithful responses. Drawing inspiration from human cognition in solving\nvisual problems (e.g., marking, zoom in), this paper introduces Chain of\nManipulations, a mechanism that enables VLMs to solve problems step-by-step\nwith evidence. After training, models can solve various visual problems by\neliciting intrinsic manipulations (e.g., grounding, zoom in) with results\n(e.g., boxes, image) actively without involving external tools, while also\nallowing users to trace error causes. We study the roadmap to implement this\nmechanism, including (1) a flexible design of manipulations upon extensive\nanalysis, (2) an efficient automated data generation pipeline, (3) a compatible\nVLM architecture capable of multi-turn multi-image, and (4) a model training\nprocess for versatile capabilities. With the design, we also manually annotate\n6K high-quality samples for the challenging graphical mathematical problems.\nOur trained model, \\textbf{CogCoM}, equipped with this mechanism with 17B\nparameters achieves state-of-the-art performance across 9 benchmarks from 4\ncategories, demonstrating the effectiveness while preserving the\ninterpretability. Our code, model weights, and collected data are publicly\navailable at https://github.com/THUDM/CogCoM.\n","authors":["Ji Qi","Ming Ding","Weihan Wang","Yushi Bai","Qingsong Lv","Wenyi Hong","Bin Xu","Lei Hou","Juanzi Li","Yuxiao Dong","Jie Tang"],"pdf_url":"https://arxiv.org/pdf/2402.04236v3.pdf","comment":"21 pages, 10 figures"},{"id":"http://arxiv.org/abs/2412.02956v2","updated":"2025-03-02T09:35:28Z","published":"2024-12-04T02:05:21Z","title":"Curriculum-style Data Augmentation for LLM-based Metaphor Detection","summary":"  Recently, utilizing large language models (LLMs) for metaphor detection has\nachieved promising results. However, these methods heavily rely on the\ncapabilities of closed-source LLMs, which come with relatively high inference\ncosts and latency. To address this, we propose a method for metaphor detection\nby fine-tuning open-source LLMs, effectively reducing inference costs and\nlatency with a single inference step. Furthermore, metaphor detection suffers\nfrom a severe data scarcity problem, which hinders effective fine-tuning of\nLLMs. To tackle this, we introduce Curriculum-style Data Augmentation (CDA).\nSpecifically, before fine-tuning, we evaluate the training data to identify\ncorrectly predicted instances for fine-tuning, while incorrectly predicted\ninstances are used as seed data for data augmentation. This approach enables\nthe model to quickly learn simpler knowledge and progressively acquire more\ncomplex knowledge, thereby improving performance incrementally. Experimental\nresults demonstrate that our method achieves state-of-the-art performance\nacross all baselines. Additionally, we provide detailed ablation studies to\nvalidate the effectiveness of CDA.\n","authors":["Kaidi Jia","Yanxia Wu","Ming Liu","Rongsheng Li"],"pdf_url":"https://arxiv.org/pdf/2412.02956v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.23771v2","updated":"2025-03-02T09:23:18Z","published":"2024-10-31T09:39:28Z","title":"What is Wrong with Perplexity for Long-context Language Modeling?","summary":"  Handling long-context inputs is crucial for large language models (LLMs) in\ntasks such as extended conversations, document summarization, and many-shot\nin-context learning. While recent approaches have extended the context windows\nof LLMs and employed perplexity (PPL) as a standard evaluation metric, PPL has\nproven unreliable for assessing long-context capabilities. The underlying cause\nof this limitation has remained unclear. In this work, we provide a\ncomprehensive explanation for this issue. We find that PPL overlooks key\ntokens, which are essential for long-context understanding, by averaging across\nall tokens and thereby obscuring the true performance of models in long-context\nscenarios. To address this, we propose \\textbf{LongPPL}, a novel metric that\nfocuses on key tokens by employing a long-short context contrastive method to\nidentify them. Our experiments demonstrate that LongPPL strongly correlates\nwith performance on various long-context benchmarks (e.g., Pearson correlation\nof -0.96), significantly outperforming traditional PPL in predictive accuracy.\nAdditionally, we introduce \\textbf{LongCE} (Long-context Cross-Entropy) loss, a\nre-weighting strategy for fine-tuning that prioritizes key tokens, leading to\nconsistent improvements across diverse benchmarks. In summary, these\ncontributions offer deeper insights into the limitations of PPL and present\neffective solutions for accurately evaluating and enhancing the long-context\ncapabilities of LLMs. Code is available at https://github.com/PKU-ML/LongPPL.\n","authors":["Lizhe Fang","Yifei Wang","Zhaoyang Liu","Chenheng Zhang","Stefanie Jegelka","Jinyang Gao","Bolin Ding","Yisen Wang"],"pdf_url":"https://arxiv.org/pdf/2410.23771v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.07168v2","updated":"2025-03-02T09:16:05Z","published":"2024-10-09T17:59:04Z","title":"Sylber: Syllabic Embedding Representation of Speech from Raw Audio","summary":"  Syllables are compositional units of spoken language that efficiently\nstructure human speech perception and production. However, current neural\nspeech representations lack such structure, resulting in dense token sequences\nthat are costly to process. To bridge this gap, we propose a new model, Sylber,\nthat produces speech representations with clean and robust syllabic structure.\nSpecifically, we propose a self-supervised learning (SSL) framework that\nbootstraps syllabic embeddings by distilling from its own initial unsupervised\nsyllabic segmentation. This results in a highly structured representation of\nspeech features, offering three key benefits: 1) a fast, linear-time syllable\nsegmentation algorithm, 2) efficient syllabic tokenization with an average of\n4.27 tokens per second, and 3) novel phonological units suited for efficient\nspoken language modeling. Our proposed segmentation method is highly robust and\ngeneralizes to out-of-domain data and unseen languages without any tuning. By\ntraining token-to-speech generative models, fully intelligible speech can be\nreconstructed from Sylber tokens with a significantly lower bitrate than\nbaseline SSL tokens. This suggests that our model effectively compresses speech\ninto a compact sequence of tokens with minimal information loss. Lastly, we\ndemonstrate that categorical perception-a linguistic phenomenon in speech\nperception-emerges naturally in Sylber, making the embedding space more\ncategorical and sparse than previous speech features and thus supporting the\nhigh efficiency of our tokenization. Together, we present a novel SSL approach\nfor representing speech as syllables, with significant potential for efficient\nspeech tokenization and spoken language modeling.\n","authors":["Cheol Jun Cho","Nicholas Lee","Akshat Gupta","Dhruv Agarwal","Ethan Chen","Alan W Black","Gopala K. Anumanchipalli"],"pdf_url":"https://arxiv.org/pdf/2410.07168v2.pdf","comment":"Accepted at ICLR 2025"},{"id":"http://arxiv.org/abs/2409.01281v2","updated":"2025-03-02T09:13:56Z","published":"2024-08-25T01:45:53Z","title":"Path-Consistency: Prefix Enhancement for Efficient Inference in LLM","summary":"  To enhance the reasoning capabilities of large language models (LLMs),\nself-consistency has gained significant popularity by combining multiple\nsampling with majority voting. However, the state-of-the-art self-consistency\napproaches consume substantial computational resources and lead to significant\nadditional time costs due to the multiple sampling. This prevents its full\npotential from being realized in scenarios where computational resources are\ncritical. To improve the inference efficiency, this paper introduces\n\\textit{path-consistency}, a method that leverages the confidence of answers\ngenerated in earlier branches to identify the prefix of the most promising\npath. By dynamically guiding the generation of subsequent branches based on\nthis prefix, the \\textit{path-consistency} mitigates both the errors and\nredundancies from random or less useful sampling in self-consistency. As a\nresult, it can significantly accelerate the inference process by reducing the\nnumber of tokens generated. Our extensive empirical evaluation shows that the\n\\textit{path-consistency} achieves significant acceleration in inference\nlatency ranging from $7.8\\%$ to $40.5\\%$, while maintaining or even improving\ntask accuracy across different datasets, including mathematical reasoning,\ncommon sense reasoning, symbolic reasoning, and code generation.\n","authors":["Jiace Zhu","Yingtao Shen","Jie Zhao","An Zou"],"pdf_url":"https://arxiv.org/pdf/2409.01281v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.06751v2","updated":"2025-03-02T09:10:13Z","published":"2025-01-12T08:36:38Z","title":"Padding Tone: A Mechanistic Analysis of Padding Tokens in T2I Models","summary":"  Text-to-image (T2I) diffusion models rely on encoded prompts to guide the\nimage generation process. Typically, these prompts are extended to a fixed\nlength by adding padding tokens before text encoding. Despite being a default\npractice, the influence of padding tokens on the image generation process has\nnot been investigated. In this work, we conduct the first in-depth analysis of\nthe role padding tokens play in T2I models. We develop two causal techniques to\nanalyze how information is encoded in the representation of tokens across\ndifferent components of the T2I pipeline. Using these techniques, we\ninvestigate when and how padding tokens impact the image generation process.\nOur findings reveal three distinct scenarios: padding tokens may affect the\nmodel's output during text encoding, during the diffusion process, or be\neffectively ignored. Moreover, we identify key relationships between these\nscenarios and the model's architecture (cross or self-attention) and its\ntraining process (frozen or trained text encoder). These insights contribute to\na deeper understanding of the mechanisms of padding tokens, potentially\ninforming future model design and training practices in T2I systems.\n","authors":["Michael Toker","Ido Galil","Hadas Orgad","Rinon Gal","Yoad Tewel","Gal Chechik","Yonatan Belinkov"],"pdf_url":"https://arxiv.org/pdf/2501.06751v2.pdf","comment":"Published in: NAACL 2025. Project webpage:\n  https://padding-tone.github.io/"},{"id":"http://arxiv.org/abs/2408.02976v3","updated":"2025-03-02T08:30:58Z","published":"2024-08-06T06:16:00Z","title":"Empathy Level Alignment via Reinforcement Learning for Empathetic\n  Response Generation","summary":"  Empathetic response generation, aiming to understand the user's situation and\nfeelings and respond empathically, is crucial in building human-like dialogue\nsystems. Traditional approaches typically employ maximum likelihood estimation\nas the optimization objective during training, yet fail to align the empathy\nlevels between generated and target responses. To this end, we propose an\nempathetic response generation framework using reinforcement learning (EmpRL).\nThe framework develops an effective empathy reward function and generates\nempathetic responses by maximizing the expected reward through reinforcement\nlearning. EmpRL utilizes the pre-trained T5 model as the generator and further\nfine-tunes it to initialize the policy. To align the empathy levels between\ngenerated and target responses within a given context, an empathy reward\nfunction containing three empathy communication mechanisms -- emotional\nreaction, interpretation, and exploration -- is constructed using pre-designed\nand pre-trained empathy identifiers. During reinforcement learning training,\nthe proximal policy optimization algorithm is used to fine-tune the policy,\nenabling the generation of empathetic responses. Both automatic and human\nevaluations demonstrate that the proposed EmpRL framework significantly\nimproves the quality of generated responses, enhances the similarity in empathy\nlevels between generated and target responses, and produces empathetic\nresponses covering both affective and cognitive aspects.\n","authors":["Hui Ma","Bo Zhang","Bo Xu","Jian Wang","Hongfei Lin","Xiao Sun"],"pdf_url":"https://arxiv.org/pdf/2408.02976v3.pdf","comment":"Accepted by IEEE Transactions on Affective Computing"},{"id":"http://arxiv.org/abs/2407.00886v3","updated":"2025-03-02T08:26:23Z","published":"2024-07-01T01:12:20Z","title":"Efficient Automated Circuit Discovery in Transformers using Contextual\n  Decomposition","summary":"  Automated mechanistic interpretation research has attracted great interest\ndue to its potential to scale explanations of neural network internals to large\nmodels. Existing automated circuit discovery work relies on activation patching\nor its approximations to identify subgraphs in models for specific tasks\n(circuits). They often suffer from slow runtime, approximation errors, and\nspecific requirements of metrics, such as non-zero gradients. In this work, we\nintroduce contextual decomposition for transformers (CD-T) to build\ninterpretable circuits in large language models. CD-T can produce circuits of\narbitrary level of abstraction, and is the first able to produce circuits as\nfine-grained as attention heads at specific sequence positions efficiently.\nCD-T consists of a set of mathematical equations to isolate contribution of\nmodel features. Through recursively computing contribution of all nodes in a\ncomputational graph of a model using CD-T followed by pruning, we are able to\nreduce circuit discovery runtime from hours to seconds compared to\nstate-of-the-art baselines. On three standard circuit evaluation datasets\n(indirect object identification, greater-than comparisons, and docstring\ncompletion), we demonstrate that CD-T outperforms ACDC and EAP by better\nrecovering the manual circuits with an average of 97% ROC AUC under low\nruntimes. In addition, we provide evidence that faithfulness of CD-T circuits\nis not due to random chance by showing our circuits are 80% more faithful than\nrandom circuits of up to 60% of the original model size. Finally, we show CD-T\ncircuits are able to perfectly replicate original models' behavior\n(faithfulness $ = 1$) using fewer nodes than the baselines for all tasks. Our\nresults underscore the great promise of CD-T for efficient automated\nmechanistic interpretability, paving the way for new insights into the workings\nof large language models.\n","authors":["Aliyah R. Hsu","Georgia Zhou","Yeshwanth Cherapanamjeri","Yaxuan Huang","Anobel Y. Odisho","Peter R. Carroll","Bin Yu"],"pdf_url":"https://arxiv.org/pdf/2407.00886v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.09097v2","updated":"2025-03-02T07:58:08Z","published":"2025-02-13T09:13:23Z","title":"A Hybrid Transformer Model for Fake News Detection: Leveraging Bayesian\n  Optimization and Bidirectional Recurrent Unit","summary":"  In this paper, we propose an optimized Transformer model that integrates\nBayesian algorithms with a Bidirectional Gated Recurrent Unit (BiGRU), and\napply it to fake news classification for the first time. First, we employ the\nTF-IDF method to extract features from news texts and transform them into\nnumeric representations to facilitate subsequent machine learning tasks. Two\nsets of experiments are then conducted for fake news detection and\nclassification: one using a Transformer model optimized only with BiGRU, and\nthe other incorporating Bayesian algorithms into the BiGRU-based Transformer.\nExperimental results show that the BiGRU-optimized Transformer achieves 100%\naccuracy on the training set and 99.67% on the test set, while the addition of\nthe Bayesian algorithm maintains 100% accuracy on the training set and slightly\nimproves test-set accuracy to 99.73%. This indicates that the Bayesian\nalgorithm boosts model accuracy by 0.06%, further enhancing the detection\ncapability for fake news. Moreover, the proposed algorithm converges rapidly at\naround the 10th training epoch with accuracy nearing 100%, demonstrating both\nits effectiveness and its fast classification ability. Overall, the optimized\nTransformer model, enhanced by the Bayesian algorithm and BiGRU, exhibits\nexcellent continuous learning and detection performance, offering a robust\ntechnical means to combat the spread of fake news in the current era of\ninformation overload.\n","authors":["Tianyi Huang","Zeqiu Xu","Peiyang Yu","Jingyuan Yi","Xiaochuan Xu"],"pdf_url":"https://arxiv.org/pdf/2502.09097v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.13757v2","updated":"2025-03-02T07:34:35Z","published":"2024-10-17T16:53:50Z","title":"MobA: Multifaceted Memory-Enhanced Adaptive Planning for Efficient\n  Mobile Task Automation","summary":"  Existing Multimodal Large Language Model (MLLM)-based agents face significant\nchallenges in handling complex GUI (Graphical User Interface) interactions on\ndevices. These challenges arise from the dynamic and structured nature of GUI\nenvironments, which integrate text, images, and spatial relationships, as well\nas the variability in action spaces across different pages and tasks. To\naddress these limitations, we propose MobA, a novel MLLM-based mobile assistant\nsystem. MobA introduces an adaptive planning module that incorporates a\nreflection mechanism for error recovery and dynamically adjusts plans to align\nwith the real environment contexts and action module's execution capacity.\nAdditionally, a multifaceted memory module provides comprehensive memory\nsupport to enhance adaptability and efficiency. We also present MobBench, a\ndataset designed for complex mobile interactions. Experimental results on\nMobBench and AndroidArena demonstrate MobA's ability to handle dynamic GUI\nenvironments and perform complex mobile task.\n","authors":["Zichen Zhu","Hao Tang","Yansi Li","Dingye Liu","Hongshen Xu","Kunyao Lan","Danyang Zhang","Yixuan Jiang","Hao Zhou","Chenrun Wang","Situo Zhang","Liangtai Sun","Yixiao Wang","Yuheng Sun","Lu Chen","Kai Yu"],"pdf_url":"https://arxiv.org/pdf/2410.13757v2.pdf","comment":"NAACL 2025 Demo Track"},{"id":"http://arxiv.org/abs/2501.14294v3","updated":"2025-03-02T06:49:21Z","published":"2025-01-24T07:24:23Z","title":"Examining Alignment of Large Language Models through Representative\n  Heuristics: The Case of Political Stereotypes","summary":"  Examining the alignment of large language models (LLMs) has become\nincreasingly important, e.g., when LLMs fail to operate as intended. This study\nexamines the alignment of LLMs with human values for the domain of politics.\nPrior research has shown that LLM-generated outputs can include political\nleanings and mimic the stances of political parties on various issues. However,\nthe extent and conditions under which LLMs deviate from empirical positions are\ninsufficiently examined. To address this gap, we analyze the factors that\ncontribute to LLMs' deviations from empirical positions on political issues,\naiming to quantify these deviations and identify the conditions that cause\nthem.\n  Drawing on findings from cognitive science about representativeness\nheuristics, i.e., situations where humans lean on representative attributes of\na target group in a way that leads to exaggerated beliefs, we scrutinize LLM\nresponses through this heuristics' lens. We conduct experiments to determine\nhow LLMs inflate predictions about political parties, which results in\nstereotyping. We find that while LLMs can mimic certain political parties'\npositions, they often exaggerate these positions more than human survey\nrespondents do. Also, LLMs tend to overemphasize representativeness more than\nhumans. This study highlights the susceptibility of LLMs to representativeness\nheuristics, suggesting a potential vulnerability of LLMs that facilitates\npolitical stereotyping. We also test prompt-based mitigation strategies,\nfinding that strategies that can mitigate representative heuristics in humans\nare also effective in reducing the influence of representativeness on\nLLM-generated responses.\n","authors":["Sullam Jeoung","Yubin Ge","Haohan Wang","Jana Diesner"],"pdf_url":"https://arxiv.org/pdf/2501.14294v3.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2502.17924v2","updated":"2025-03-02T06:46:48Z","published":"2025-02-25T07:44:22Z","title":"FACT-AUDIT: An Adaptive Multi-Agent Framework for Dynamic Fact-Checking\n  Evaluation of Large Language Models","summary":"  Large Language Models (LLMs) have significantly advanced the fact-checking\nstudies. However, existing automated fact-checking evaluation methods rely on\nstatic datasets and classification metrics, which fail to automatically\nevaluate the justification production and uncover the nuanced limitations of\nLLMs in fact-checking. In this work, we introduce FACT-AUDIT, an agent-driven\nframework that adaptively and dynamically assesses LLMs' fact-checking\ncapabilities. Leveraging importance sampling principles and multi-agent\ncollaboration, FACT-AUDIT generates adaptive and scalable datasets, performs\niterative model-centric evaluations, and updates assessments based on\nmodel-specific responses. By incorporating justification production alongside\nverdict prediction, this framework provides a comprehensive and evolving audit\nof LLMs' factual reasoning capabilities, to investigate their trustworthiness.\nExtensive experiments demonstrate that FACT-AUDIT effectively differentiates\namong state-of-the-art LLMs, providing valuable insights into model strengths\nand limitations in model-centric fact-checking analysis.\n","authors":["Hongzhan Lin","Yang Deng","Yuxuan Gu","Wenxuan Zhang","Jing Ma","See-Kiong Ng","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2502.17924v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.19425v3","updated":"2025-03-02T06:36:57Z","published":"2024-05-29T18:08:37Z","title":"Adaptive In-conversation Team Building for Language Model Agents","summary":"  Leveraging multiple large language model (LLM) agents has shown to be a\npromising approach for tackling complex tasks, while the effective design of\nmultiple agents for a particular application remains an art. It is thus\nintriguing to answer a critical question: Given a task, how can we build a team\nof LLM agents to solve it effectively? Our new adaptive team-building paradigm\noffers a flexible solution, realized through a novel agent design named Captain\nAgent. It dynamically forms and manages teams for each step of a task-solving\nprocess, utilizing nested group conversations and reflection to ensure diverse\nexpertise and prevent stereotypical outputs, allowing for a flexible yet\nstructured approach to problem-solving. A comprehensive evaluation across six\nreal-world scenarios demonstrates that Captain Agent significantly outperforms\nexisting multi-agent methods with 21.94% improvement in average accuracy,\nproviding outstanding performance without requiring task-specific prompt\nengineering. Our exploration of different backbone LLM and cost analysis\nfurther shows that Captain Agent can improve the conversation quality of weak\nLLM and achieve competitive performance with extremely low cost, which\nilluminates the application of multi-agent systems.\n","authors":["Linxin Song","Jiale Liu","Jieyu Zhang","Shaokun Zhang","Ao Luo","Shijian Wang","Qingyun Wu","Chi Wang"],"pdf_url":"https://arxiv.org/pdf/2405.19425v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.01902v2","updated":"2025-03-02T06:28:59Z","published":"2024-07-02T02:58:29Z","title":"SeqAR: Jailbreak LLMs with Sequential Auto-Generated Characters","summary":"  The widespread applications of large language models (LLMs) have brought\nabout concerns regarding their potential misuse. Although aligned with human\npreference data before release, LLMs remain vulnerable to various malicious\nattacks. In this paper, we adopt a red-teaming strategy to enhance LLM safety\nand introduce SeqAR, a simple yet effective framework to design jailbreak\nprompts automatically. The SeqAR framework generates and optimizes multiple\njailbreak characters and then applies sequential jailbreak characters in a\nsingle query to bypass the guardrails of the target LLM. Different from\nprevious work which relies on proprietary LLMs or seed jailbreak templates\ncrafted by human expertise, SeqAR can generate and optimize the jailbreak\nprompt in a cold-start scenario using open-sourced LLMs without any seed\njailbreak templates. Experimental results show that SeqAR achieves attack\nsuccess rates of 88% and 60% in bypassing the safety alignment of GPT-3.5-1106\nand GPT-4, respectively. Furthermore, we extensively evaluate the\ntransferability of the generated templates across different LLMs and held-out\nmalicious requests, while also exploring defense strategies against the\njailbreak attack designed by SeqAR.\n","authors":["Yan Yang","Zeguan Xiao","Xin Lu","Hongru Wang","Xuetao Wei","Hailiang Huang","Guanhua Chen","Yun Chen"],"pdf_url":"https://arxiv.org/pdf/2407.01902v2.pdf","comment":"Accepted by NAACL 2025"},{"id":"http://arxiv.org/abs/2410.07672v2","updated":"2025-03-02T06:25:14Z","published":"2024-10-10T07:29:35Z","title":"MACPO: Weak-to-Strong Alignment via Multi-Agent Contrastive Preference\n  Optimization","summary":"  As large language models (LLMs) are rapidly advancing and achieving\nnear-human capabilities on specific tasks, aligning them with human values is\nbecoming more urgent. In scenarios where LLMs outperform humans, we face a\nweak-to-strong alignment problem where we need to effectively align strong\nstudent LLMs through weak supervision generated by weak teachers. Existing\nalignment methods mainly focus on strong-to-weak alignment and self-alignment\nsettings, and it is impractical to adapt them to the much harder weak-to-strong\nalignment setting. To fill this gap, we propose a multi-agent contrastive\npreference optimization (MACPO) framework. MACPO facilitates weak teachers and\nstrong students to learn from each other by iteratively reinforcing unfamiliar\npositive behaviors while penalizing familiar negative ones. To get this, we\ndevise a mutual positive behavior augmentation strategy to encourage weak\nteachers and strong students to learn from each other's positive behavior and\nfurther provide higher quality positive behavior for the next iteration.\nAdditionally, we propose a hard negative behavior construction strategy to\ninduce weak teachers and strong students to generate familiar negative behavior\nby fine-tuning on negative behavioral data. Experimental results on the HH-RLHF\nand PKU-SafeRLHF datasets, evaluated using both automatic metrics and human\njudgments, demonstrate that MACPO simultaneously improves the alignment\nperformance of strong students and weak teachers. Moreover, as the number of\nweak teachers increases, MACPO achieves better weak-to-strong alignment\nperformance through more iteration optimization rounds.\n","authors":["Yougang Lyu","Lingyong Yan","Zihan Wang","Dawei Yin","Pengjie Ren","Maarten de Rijke","Zhaochun Ren"],"pdf_url":"https://arxiv.org/pdf/2410.07672v2.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2410.03115v2","updated":"2025-03-02T05:16:38Z","published":"2024-10-04T03:17:27Z","title":"X-ALMA: Plug & Play Modules and Adaptive Rejection for Quality\n  Translation at Scale","summary":"  Large language models (LLMs) have achieved remarkable success across various\nNLP tasks with a focus on English due to English-centric pre-training and\nlimited multilingual data. In this work, we focus on the problem of\ntranslation, and while some multilingual LLMs claim to support for hundreds of\nlanguages, models often fail to provide high-quality responses for mid- and\nlow-resource languages, leading to imbalanced performance heavily skewed in\nfavor of high-resource languages. We introduce **X-ALMA**, a model designed to\nensure top-tier performance across 50 diverse languages, regardless of their\nresource levels. X-ALMA surpasses state-of-the-art open-source multilingual\nLLMs, such as Aya-101 and Aya-23, in every single translation direction on the\nFLORES-200 and WMT'23 test datasets according to COMET-22. This is achieved by\nplug-and-play language-specific module architecture to prevent language\nconflicts during training and a carefully designed training regimen with novel\noptimization methods to maximize the translation performance. After the final\nstage of training regimen, our proposed **A**daptive **R**ejection\n**P**reference **O**ptimization (**ARPO**) surpasses existing preference\noptimization methods in translation tasks.\n","authors":["Haoran Xu","Kenton Murray","Philipp Koehn","Hieu Hoang","Akiko Eriguchi","Huda Khayrallah"],"pdf_url":"https://arxiv.org/pdf/2410.03115v2.pdf","comment":"Published as a conference paper at ICLR 2025 (spotlight)"},{"id":"http://arxiv.org/abs/2406.09044v3","updated":"2025-03-02T04:45:56Z","published":"2024-06-13T12:30:02Z","title":"MiLoRA: Harnessing Minor Singular Components for Parameter-Efficient LLM\n  Finetuning","summary":"  Efficient finetuning of large language models (LLMs) aims to adapt the LLMs\nwith reduced computational and memory cost. Previous LoRA-based approaches\ninitialize the low-rank matrices with Gaussian distribution and zero values\nwhile keeping the original weight matrices frozen. However, the trainable model\nparameters optimized in an unguided subspace might interfere with the\nwell-learned subspace of the pretrained weight matrices. In this paper, we\npropose MiLoRA, a simple yet effective LLM finetuning approach that only\nupdates the minor singular components of the weight matrix while keeping the\nprincipal singular components frozen. It is observed that the minor matrix\ncorresponds to the noisy or long-tail information, while the principal matrix\ncontains important knowledge. The MiLoRA initializes the low-rank matrices\nwithin a subspace that is orthogonal to the principal matrix, thus the\npretrained knowledge is expected to be well preserved. During finetuning,\nMiLoRA makes the most use of the less-optimized subspace for learning the\nlabeled dataset. Extensive experiments on commonsense reasoning, math\nreasoning, instruction following and visual instruction following benchmarks\npresent the superior performance of our method.\n","authors":["Hanqing Wang","Yixia Li","Shuo Wang","Guanhua Chen","Yun Chen"],"pdf_url":"https://arxiv.org/pdf/2406.09044v3.pdf","comment":"This paper has been accepted at NAACL 2025. Code is available at:\n  https://github.com/sufenlp/MiLoRA"},{"id":"http://arxiv.org/abs/2410.21533v2","updated":"2025-03-02T04:39:42Z","published":"2024-10-28T21:02:13Z","title":"L3Ms -- Lagrange Large Language Models","summary":"  Supervised fine-tuning (SFT) and alignment of large language models (LLMs)\nare key steps in providing a good user experience. However, the concept of an\nappropriate alignment is inherently application-dependent, and current methods\noften rely on heuristic choices to drive optimization. In this work, we\nformulate SFT and alignment as a constrained optimization problem: the LLM is\nfine-tuned on a task while being required to meet application-specific\nrequirements, without resorting to heuristics. To solve this, we propose\nLagrange Large Language Models (L3Ms), which employ logarithmic barriers to\nenforce the constraints. This approach allows for the customization of L3Ms\nacross diverse applications while avoiding heuristic-driven processes. We\nexperimentally demonstrate the versatility and efficacy of L3Ms in achieving\ntailored alignments for various applications.\n","authors":["Guneet S. Dhillon","Xingjian Shi","Yee Whye Teh","Alex Smola"],"pdf_url":"https://arxiv.org/pdf/2410.21533v2.pdf","comment":"International Conference on Learning Representations (ICLR), 2025"},{"id":"http://arxiv.org/abs/2502.10709v2","updated":"2025-03-02T04:37:08Z","published":"2025-02-15T07:45:20Z","title":"An Empirical Analysis of Uncertainty in Large Language Model Evaluations","summary":"  As LLM-as-a-Judge emerges as a new paradigm for assessing large language\nmodels (LLMs), concerns have been raised regarding the alignment, bias, and\nstability of LLM evaluators. While substantial work has focused on alignment\nand bias, little research has concentrated on the stability of LLM evaluators.\nIn this paper, we conduct extensive experiments involving 9 widely used LLM\nevaluators across 2 different evaluation settings to investigate the\nuncertainty in model-based LLM evaluations. We pinpoint that LLM evaluators\nexhibit varying uncertainty based on model families and sizes. With careful\ncomparative analyses, we find that employing special prompting strategies,\nwhether during inference or post-training, can alleviate evaluation uncertainty\nto some extent. By utilizing uncertainty to enhance LLM's reliability and\ndetection capability in Out-Of-Distribution (OOD) data, we further fine-tune an\nuncertainty-aware LLM evaluator named ConfiLM using a human-annotated\nfine-tuning set and assess ConfiLM's OOD evaluation ability on a manually\ndesigned test set sourced from the 2024 Olympics. Experimental results\ndemonstrate that incorporating uncertainty as additional information during the\nfine-tuning phase can largely improve the model's evaluation performance in OOD\nscenarios. The code and data are released at:\nhttps://github.com/hasakiXie123/LLM-Evaluator-Uncertainty.\n","authors":["Qiujie Xie","Qingqiu Li","Zhuohao Yu","Yuejie Zhang","Yue Zhang","Linyi Yang"],"pdf_url":"https://arxiv.org/pdf/2502.10709v2.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2308.11432v7","updated":"2025-03-02T04:04:03Z","published":"2023-08-22T13:30:37Z","title":"A Survey on Large Language Model based Autonomous Agents","summary":"  Autonomous agents have long been a prominent research focus in both academic\nand industry communities. Previous research in this field often focuses on\ntraining agents with limited knowledge within isolated environments, which\ndiverges significantly from human learning processes, and thus makes the agents\nhard to achieve human-like decisions. Recently, through the acquisition of vast\namounts of web knowledge, large language models (LLMs) have demonstrated\nremarkable potential in achieving human-level intelligence. This has sparked an\nupsurge in studies investigating LLM-based autonomous agents. In this paper, we\npresent a comprehensive survey of these studies, delivering a systematic review\nof the field of LLM-based autonomous agents from a holistic perspective. More\nspecifically, we first discuss the construction of LLM-based autonomous agents,\nfor which we propose a unified framework that encompasses a majority of the\nprevious work. Then, we present a comprehensive overview of the diverse\napplications of LLM-based autonomous agents in the fields of social science,\nnatural science, and engineering. Finally, we delve into the evaluation\nstrategies commonly used for LLM-based autonomous agents. Based on the previous\nstudies, we also present several challenges and future directions in this\nfield. To keep track of this field and continuously update our survey, we\nmaintain a repository of relevant references at\nhttps://github.com/Paitesanshi/LLM-Agent-Survey.\n","authors":["Lei Wang","Chen Ma","Xueyang Feng","Zeyu Zhang","Hao Yang","Jingsen Zhang","Zhiyuan Chen","Jiakai Tang","Xu Chen","Yankai Lin","Wayne Xin Zhao","Zhewei Wei","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2308.11432v7.pdf","comment":"Correcting several typos, 35 pages, 5 figures, 3 tables"},{"id":"http://arxiv.org/abs/2407.14985v5","updated":"2025-03-02T03:27:58Z","published":"2024-07-20T21:24:40Z","title":"Generalization v.s. Memorization: Tracing Language Models' Capabilities\n  Back to Pretraining Data","summary":"  The impressive capabilities of large language models (LLMs) have sparked\ndebate over whether these models genuinely generalize to unseen tasks or\npredominantly rely on memorizing vast amounts of pretraining data. To explore\nthis issue, we introduce an extended concept of memorization, distributional\nmemorization, which measures the correlation between the LLM output\nprobabilities and the pretraining data frequency. To effectively capture\ntask-specific pretraining data frequency, we propose a novel task-gram language\nmodel, which is built by counting the co-occurrence of semantically related\n$n$-gram pairs from task inputs and outputs in the pretraining corpus. Using\nthe Pythia models trained on the Pile dataset, we evaluate four distinct tasks:\nmachine translation, factual question answering, world knowledge understanding,\nand math reasoning. Our findings reveal varying levels of memorization, with\nthe strongest effect observed in factual question answering. Furthermore, while\nmodel performance improves across all tasks as LLM size increases, only factual\nquestion answering shows an increase in memorization, whereas machine\ntranslation and reasoning tasks exhibit greater generalization, producing more\nnovel outputs. This study demonstrates that memorization plays a larger role in\nsimpler, knowledge-intensive tasks, while generalization is the key for harder,\nreasoning-based tasks, providing a scalable method for analyzing large\npretraining corpora in greater depth.\n","authors":["Xinyi Wang","Antonis Antoniades","Yanai Elazar","Alfonso Amayuelas","Alon Albalak","Kexun Zhang","William Yang Wang"],"pdf_url":"https://arxiv.org/pdf/2407.14985v5.pdf","comment":"Accepted to ICLR 2025"},{"id":"http://arxiv.org/abs/2401.06603v2","updated":"2025-03-02T01:46:57Z","published":"2024-01-12T14:35:57Z","title":"Mutual Enhancement of Large Language and Reinforcement Learning Models\n  through Bi-Directional Feedback Mechanisms: A Planning Case Study","summary":"  Large Language Models (LLMs) have demonstrated remarkable capabilities for\nreinforcement learning (RL) models, such as planning and reasoning\ncapabilities. However, the problems of LLMs and RL model collaboration still\nneed to be solved. In this study, we employ a teacher-student learning\nframework to tackle these problems, specifically by offering feedback for LLMs\nusing RL models and providing high-level information for RL models with LLMs in\na cooperative multi-agent setting. Within this framework, the LLM acts as a\nteacher, while the RL model acts as a student. The two agents cooperatively\nassist each other through a process of recursive help, such as \"I help you help\nI help.\" The LLM agent supplies abstract information to the RL agent, enabling\nefficient exploration and policy improvement. In turn, the RL agent offers\nfeedback to the LLM agent, providing valuable, real-time information that helps\ngenerate more useful tokens. This bi-directional feedback loop promotes\noptimization, exploration, and mutual improvement for both agents, enabling\nthem to accomplish increasingly challenging tasks. Remarkably, we propose a\npractical algorithm to address the problem and conduct empirical experiments to\nevaluate the effectiveness of our method.\n","authors":["Shangding Gu"],"pdf_url":"https://arxiv.org/pdf/2401.06603v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.10594v2","updated":"2025-03-02T01:19:51Z","published":"2024-10-14T15:04:18Z","title":"VisRAG: Vision-based Retrieval-augmented Generation on Multi-modality\n  Documents","summary":"  Retrieval-augmented generation (RAG) is an effective technique that enables\nlarge language models (LLMs) to utilize external knowledge sources for\ngeneration. However, current RAG systems are solely based on text, rendering it\nimpossible to utilize vision information like layout and images that play\ncrucial roles in real-world multi-modality documents. In this paper, we\nintroduce VisRAG, which tackles this issue by establishing a vision-language\nmodel (VLM)-based RAG pipeline. In this pipeline, instead of first parsing the\ndocument to obtain text, the document is directly embedded using a VLM as an\nimage and then retrieved to enhance the generation of a VLM. Compared to\ntraditional text-based RAG, VisRAG maximizes the retention and utilization of\nthe data information in the original documents, eliminating the information\nloss introduced during the parsing process. We collect both open-source and\nsynthetic data to train the retriever in VisRAG and explore a variety of\ngeneration methods. Experiments demonstrate that VisRAG outperforms traditional\nRAG in both the retrieval and generation stages, achieving a 20--40% end-to-end\nperformance gain over traditional text-based RAG pipeline. Further analysis\nreveals that VisRAG is efficient in utilizing training data and demonstrates\nstrong generalization capability, positioning it as a promising solution for\nRAG on multi-modality documents. Our code and data are available at\nhttps://github.com/openbmb/visrag.\n","authors":["Shi Yu","Chaoyue Tang","Bokai Xu","Junbo Cui","Junhao Ran","Yukun Yan","Zhenghao Liu","Shuo Wang","Xu Han","Zhiyuan Liu","Maosong Sun"],"pdf_url":"https://arxiv.org/pdf/2410.10594v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.13629v3","updated":"2025-03-02T00:46:31Z","published":"2024-06-19T15:25:29Z","title":"InstructRAG: Instructing Retrieval-Augmented Generation via\n  Self-Synthesized Rationales","summary":"  Retrieval-augmented generation (RAG) has shown promising potential to enhance\nthe accuracy and factuality of language models (LMs). However, imperfect\nretrievers or noisy corpora can introduce misleading or even erroneous\ninformation to the retrieved contents, posing a significant challenge to the\ngeneration quality. Existing RAG methods typically address this challenge by\ndirectly predicting final answers despite potentially noisy inputs, resulting\nin an implicit denoising process that is difficult to interpret and verify. On\nthe other hand, the acquisition of explicit denoising supervision is often\ncostly, involving significant human efforts. In this work, we propose\nInstructRAG, where LMs explicitly learn the denoising process through\nself-synthesized rationales -- First, we instruct the LM to explain how the\nground-truth answer is derived from retrieved documents. Then, these rationales\ncan be used either as demonstrations for in-context learning of explicit\ndenoising or as supervised fine-tuning data to train the model. Compared to\nstandard RAG approaches, InstructRAG requires no additional supervision, allows\nfor easier verification of the predicted answers, and effectively improves\ngeneration accuracy. Experiments show InstructRAG consistently outperforms\nexisting RAG methods in both training-free and trainable scenarios, achieving a\nrelative improvement of 8.3% over the best baseline method on average across\nfive knowledge-intensive benchmarks. Extensive analysis indicates that\nInstructRAG scales well with increased numbers of retrieved documents and\nconsistently exhibits robust denoising ability even in out-of-domain datasets,\ndemonstrating strong generalizability.\n","authors":["Zhepei Wei","Wei-Lin Chen","Yu Meng"],"pdf_url":"https://arxiv.org/pdf/2406.13629v3.pdf","comment":"ICLR 2025. Code: https://github.com/weizhepei/InstructRAG"},{"id":"http://arxiv.org/abs/2410.21533v2","updated":"2025-03-02T04:39:42Z","published":"2024-10-28T21:02:13Z","title":"L3Ms - Lagrange Large Language Models","summary":"  Supervised fine-tuning (SFT) and alignment of large language models (LLMs)\nare key steps in providing a good user experience. However, the concept of an\nappropriate alignment is inherently application-dependent, and current methods\noften rely on heuristic choices to drive optimization. In this work, we\nformulate SFT and alignment as a constrained optimization problem: the LLM is\nfine-tuned on a task while being required to meet application-specific\nrequirements, without resorting to heuristics. To solve this, we propose\nLagrange Large Language Models (L3Ms), which employ logarithmic barriers to\nenforce the constraints. This approach allows for the customization of L3Ms\nacross diverse applications while avoiding heuristic-driven processes. We\nexperimentally demonstrate the versatility and efficacy of L3Ms in achieving\ntailored alignments for various applications.\n","authors":["Guneet S. Dhillon","Xingjian Shi","Yee Whye Teh","Alex Smola"],"pdf_url":"https://arxiv.org/pdf/2410.21533v2.pdf","comment":"International Conference on Learning Representations (ICLR), 2025"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2310.07887v4","updated":"2025-03-02T23:48:32Z","published":"2023-10-11T20:48:20Z","title":"Unsupervised Denoising for Signal-Dependent and Row-Correlated Imaging\n  Noise","summary":"  Accurate analysis of microscopy images is hindered by the presence of noise.\nThis noise is usually signal-dependent and often additionally correlated along\nrows or columns of pixels. Current self- and unsupervised denoisers can address\nsignal-dependent noise, but none can reliably remove noise that is also row- or\ncolumn-correlated. Here, we present the first fully unsupervised deep\nlearning-based denoiser capable of handling imaging noise that is\nrow-correlated as well as signal-dependent. Our approach uses a Variational\nAutoencoder (VAE) with a specially designed autoregressive decoder. This\ndecoder is capable of modeling row-correlated and signal-dependent noise but is\nincapable of independently modeling underlying clean signal. The VAE therefore\nproduces latent variables containing only clean signal information, and these\nare mapped back into image space using a proposed second decoder network. Our\nmethod does not require a pre-trained noise model and can be trained from\nscratch using unpaired noisy data. We benchmark our approach on microscopy\ndatatsets from a range of imaging modalities and sensor types, each with row-\nor column-correlated, signal-dependent noise, and show that it outperforms\nexisting self- and unsupervised denoisers.\n","authors":["Benjamin Salmon","Alexander Krull"],"pdf_url":"https://arxiv.org/pdf/2310.07887v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.15998v2","updated":"2025-03-02T23:41:37Z","published":"2024-08-28T17:59:31Z","title":"Eagle: Exploring The Design Space for Multimodal LLMs with Mixture of\n  Encoders","summary":"  The ability to accurately interpret complex visual information is a crucial\ntopic of multimodal large language models (MLLMs). Recent work indicates that\nenhanced visual perception significantly reduces hallucinations and improves\nperformance on resolution-sensitive tasks, such as optical character\nrecognition and document analysis. A number of recent MLLMs achieve this goal\nusing a mixture of vision encoders. Despite their success, there is a lack of\nsystematic comparisons and detailed ablation studies addressing critical\naspects, such as expert selection and the integration of multiple vision\nexperts. This study provides an extensive exploration of the design space for\nMLLMs using a mixture of vision encoders and resolutions. Our findings reveal\nseveral underlying principles common to various existing strategies, leading to\na streamlined yet effective design approach. We discover that simply\nconcatenating visual tokens from a set of complementary vision encoders is as\neffective as more complex mixing architectures or strategies. We additionally\nintroduce Pre-Alignment to bridge the gap between vision-focused encoders and\nlanguage tokens, enhancing model coherence. The resulting family of MLLMs,\nEagle, surpasses other leading open-source models on major MLLM benchmarks.\n","authors":["Min Shi","Fuxiao Liu","Shihao Wang","Shijia Liao","Subhashree Radhakrishnan","Yilin Zhao","De-An Huang","Hongxu Yin","Karan Sapra","Yaser Yacoob","Humphrey Shi","Bryan Catanzaro","Andrew Tao","Jan Kautz","Zhiding Yu","Guilin Liu"],"pdf_url":"https://arxiv.org/pdf/2408.15998v2.pdf","comment":"Github: https://github.com/NVlabs/Eagle, HuggingFace:\n  https://huggingface.co/NVEagle"},{"id":"http://arxiv.org/abs/2411.01106v2","updated":"2025-03-02T22:41:37Z","published":"2024-11-02T02:09:01Z","title":"SV-RAG: LoRA-Contextualizing Adaptation of MLLMs for Long Document\n  Understanding","summary":"  Multimodal large language models (MLLMs) have recently shown great progress\nin text-rich image understanding, yet they still struggle with complex,\nmulti-page visually-rich documents. Traditional methods using document parsers\nfor retrieval-augmented generation suffer from performance and efficiency\nlimitations, while directly presenting all pages to MLLMs leads to\ninefficiencies, especially with lengthy ones. In this work, we present a novel\nframework named **S**elf-**V**isual **R**etrieval-**A**ugmented **G**eneration\n(SV-RAG), which can broaden horizons of any MLLM to support long-document\nunderstanding. We demonstrate that **MLLMs themselves can be an effective\nmultimodal retriever** to fetch relevant pages and then answer user questions\nbased on these pages. SV-RAG is implemented with two specific MLLM adapters,\none for evidence page retrieval and the other for question answering. Empirical\nresults show state-of-the-art performance on public benchmarks, demonstrating\nthe effectiveness of SV-RAG.\n","authors":["Jian Chen","Ruiyi Zhang","Yufan Zhou","Tong Yu","Franck Dernoncourt","Jiuxiang Gu","Ryan A. Rossi","Changyou Chen","Tong Sun"],"pdf_url":"https://arxiv.org/pdf/2411.01106v2.pdf","comment":"Accepted to ICLR 2025"},{"id":"http://arxiv.org/abs/2502.00156v2","updated":"2025-03-02T20:53:26Z","published":"2025-01-31T20:47:06Z","title":"ALBAR: Adversarial Learning approach to mitigate Biases in Action\n  Recognition","summary":"  Bias in machine learning models can lead to unfair decision making, and while\nit has been well-studied in the image and text domains, it remains\nunderexplored in action recognition. Action recognition models often suffer\nfrom background bias (i.e., inferring actions based on background cues) and\nforeground bias (i.e., relying on subject appearance), which can be detrimental\nto real-life applications such as autonomous vehicles or assisted living\nmonitoring. While prior approaches have mainly focused on mitigating background\nbias using specialized augmentations, we thoroughly study both foreground and\nbackground bias. We propose ALBAR, a novel adversarial training method that\nmitigates foreground and background biases without requiring specialized\nknowledge of the bias attributes. Our framework applies an adversarial\ncross-entropy loss to the sampled static clip (where all the frames are the\nsame) and aims to make its class probabilities uniform using a proposed entropy\nmaximization loss. Additionally, we introduce a gradient penalty loss for\nregularization against the debiasing process. We evaluate our method on\nestablished background and foreground bias protocols, setting a new\nstate-of-the-art and strongly improving combined debiasing performance by over\n12% absolute on HMDB51. Furthermore, we identify an issue of background leakage\nin the existing UCF101 protocol for bias evaluation which provides a shortcut\nto predict actions and does not provide an accurate measure of the debiasing\ncapability of a model. We address this issue by proposing more fine-grained\nsegmentation boundaries for the actor, where our method also outperforms\nexisting approaches. Project Page:\nhttps://joefioresi718.github.io/ALBAR_webpage/\n","authors":["Joseph Fioresi","Ishan Rajendrakumar Dave","Mubarak Shah"],"pdf_url":"https://arxiv.org/pdf/2502.00156v2.pdf","comment":"Accepted to ICLR 2025"},{"id":"http://arxiv.org/abs/2312.15289v3","updated":"2025-03-02T18:36:56Z","published":"2023-12-23T16:10:53Z","title":"Fréchet Wavelet Distance: A Domain-Agnostic Metric for Image\n  Generation","summary":"  Modern metrics for generative learning like Fr\\'echet Inception Distance\n(FID) and DINOv2-Fr\\'echet Distance (FD-DINOv2) demonstrate impressive\nperformance. However, they suffer from various shortcomings, like a bias\ntowards specific generators and datasets. To address this problem, we propose\nthe Fr\\'echet Wavelet Distance (FWD) as a domain-agnostic metric based on the\nWavelet Packet Transform ($W_p$). FWD provides a sight across a broad spectrum\nof frequencies in images with a high resolution, preserving both spatial and\ntextural aspects. Specifically, we use $W_p$ to project generated and real\nimages to the packet coefficient space. We then compute the Fr\\'echet distance\nwith the resultant coefficients to evaluate the quality of a generator. This\nmetric is general-purpose and dataset-domain agnostic, as it does not rely on\nany pre-trained network, while being more interpretable due to its ability to\ncompute Fr\\'echet distance per packet, enhancing transparency. We conclude with\nan extensive evaluation of a wide variety of generators across various datasets\nthat the proposed FWD can generalize and improve robustness to domain shifts\nand various corruptions compared to other metrics.\n","authors":["Lokesh Veeramacheneni","Moritz Wolter","Hildegard Kuehne","Juergen Gall"],"pdf_url":"https://arxiv.org/pdf/2312.15289v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.10509v2","updated":"2025-03-02T18:17:14Z","published":"2024-11-15T15:39:04Z","title":"TESGNN: Temporal Equivariant Scene Graph Neural Networks for Efficient\n  and Robust Multi-View 3D Scene Understanding","summary":"  Scene graphs have proven to be highly effective for various scene\nunderstanding tasks due to their compact and explicit representation of\nrelational information. However, current methods often overlook the critical\nimportance of preserving symmetry when generating scene graphs from 3D point\nclouds, which can lead to reduced accuracy and robustness, particularly when\ndealing with noisy, multi-view data. Furthermore, a major limitation of prior\napproaches is the lack of temporal modeling to capture time-dependent\nrelationships among dynamically evolving entities in a scene. To address these\nchallenges, we propose Temporal Equivariant Scene Graph Neural Network\n(TESGNN), consisting of two key components: (1) an Equivariant Scene Graph\nNeural Network (ESGNN), which extracts information from 3D point clouds to\ngenerate scene graph while preserving crucial symmetry properties, and (2) a\nTemporal Graph Matching Network, which fuses scene graphs generated by ESGNN\nacross multiple time sequences into a unified global representation using an\napproximate graph-matching algorithm. Our combined architecture TESGNN\noutperforms current state-of-the-art methods in scene graph generation,\nachieving higher accuracy and faster training convergence. Moreover, we show\nthat leveraging the symmetry-preserving property produces a more stable and\naccurate global scene representation compared to existing approaches. Last but\nnot least, it is computationally efficient and easily implementable using\nexisting frameworks, making it well-suited for real-time applications in\nrobotics and computer vision. This approach paves the way for more robust and\nscalable solutions to complex multi-view scene understanding challenges. Our\nsource code is publicly available at: https://github.com/HySonLab/TESGraph\n","authors":["Quang P. M. Pham","Khoi T. N. Nguyen","Lan C. Ngo","Truong Do","Dezhen Song","Truong-Son Hy"],"pdf_url":"https://arxiv.org/pdf/2411.10509v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2407.00609"},{"id":"http://arxiv.org/abs/2411.02372v2","updated":"2025-03-02T17:34:53Z","published":"2024-11-04T18:40:46Z","title":"Learning General-Purpose Biomedical Volume Representations using\n  Randomized Synthesis","summary":"  Current volumetric biomedical foundation models struggle to generalize as\npublic 3D datasets are small and do not cover the broad diversity of medical\nprocedures, conditions, anatomical regions, and imaging protocols. We address\nthis by creating a representation learning method that instead anticipates\nstrong domain shifts at training time itself. We first propose a data engine\nthat synthesizes highly variable training samples that would enable\ngeneralization to new biomedical contexts. To then train a single 3D network\nfor any voxel-level task, we develop a contrastive learning method that\npretrains the network to be stable against nuisance imaging variation simulated\nby the data engine, a key inductive bias for generalization. This network's\nfeatures can be used as robust representations of input images for downstream\ntasks and its weights provide a strong, dataset-agnostic initialization for\nfinetuning on new datasets. As a result, we set new standards across both\nmultimodality registration and few-shot segmentation, a first for any 3D\nbiomedical vision model, all without (pre-)training on any existing dataset of\nreal images.\n","authors":["Neel Dey","Benjamin Billot","Hallee E. Wong","Clinton J. Wang","Mengwei Ren","P. Ellen Grant","Adrian V. Dalca","Polina Golland"],"pdf_url":"https://arxiv.org/pdf/2411.02372v2.pdf","comment":"ICLR 2025: International Conference on Learning Representations. Code\n  and model weights available at https://github.com/neel-dey/anatomix.\n  Keywords: synthetic data, representation learning, medical image analysis,\n  image registration, image segmentation"},{"id":"http://arxiv.org/abs/2409.14876v3","updated":"2025-03-02T17:27:04Z","published":"2024-09-23T10:17:13Z","title":"Tri-Clustering: A Multi-views Tri-level Information Fusion Context\n  Clustering Framework for Localization and Classification in Mammography","summary":"  Breast cancer is a significant global health issue, and the diagnosis of\nbreast imaging has always been challenging. Mammography images typically have\nextremely high resolution, with lesions occupying only a very small area.\nDown-sampling in neural networks can easily lead to the loss of\nmicrocalcifications or subtle structures, making it difficult for traditional\nneural network architectures to address these issues. To tackle these\nchallenges, we propose a Context Clustering Network with triple information\nfusion. Firstly, compared to CNNs or transformers, we find that Context\nclustering methods (1) are more computationally efficient and (2) can more\neasily associate structural or pathological features, making them suitable for\nthe clinical tasks of mammography. Secondly, we propose a triple information\nfusion mechanism that integrates global information, feature-based local\ninformation, and patch-based local information. The proposed approach is\nrigorously evaluated on two public datasets, Vindr-Mammo and CBIS-DDSM, using\nfive independent splits to ensure statistical robustness. Our method achieves\nan AUC of 0.828 on Vindr-Mammo and 0.805 on CBIS-DDSM, outperforming the next\nbest method by 3.1% and 2.4%, respectively. These improvements are\nstatistically significant (p<0.05), underscoring the benefits of Context\nClustering Network with triple information fusion. Overall, our Context\nClustering framework demonstrates strong potential as a scalable and\ncost-effective solution for large-scale mammography screening, enabling more\nefficient and accurate breast cancer detection. Access to our method is\navailable at https://github.com/Sohyu1/Mammo_Clustering.\n","authors":["Shilong Yang","Chulong Zhang","Qi Zang","Juan Yu","Liang Zeng","Xiao Luo","Yexuan Xing","Xin Pan","Qi Li","Xiaokun Liang","Yaoqin Xie"],"pdf_url":"https://arxiv.org/pdf/2409.14876v3.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2410.04810v2","updated":"2025-03-02T17:18:04Z","published":"2024-10-07T07:45:18Z","title":"FedBiP: Heterogeneous One-Shot Federated Learning with Personalized\n  Latent Diffusion Models","summary":"  One-Shot Federated Learning (OSFL), a special decentralized machine learning\nparadigm, has recently gained significant attention. OSFL requires only a\nsingle round of client data or model upload, which reduces communication costs\nand mitigates privacy threats compared to traditional FL. Despite these\npromising prospects, existing methods face challenges due to client data\nheterogeneity and limited data quantity when applied to real-world OSFL\nsystems. Recently, Latent Diffusion Models (LDM) have shown remarkable\nadvancements in synthesizing high-quality images through pretraining on\nlarge-scale datasets, thereby presenting a potential solution to overcome these\nissues. However, directly applying pretrained LDM to heterogeneous OSFL results\nin significant distribution shifts in synthetic data, leading to performance\ndegradation in classification models trained on such data. This issue is\nparticularly pronounced in rare domains, such as medical imaging, which are\nunderrepresented in LDM's pretraining data. To address this challenge, we\npropose Federated Bi-Level Personalization (FedBiP), which personalizes the\npretrained LDM at both instance-level and concept-level. Hereby, FedBiP\nsynthesizes images following the client's local data distribution without\ncompromising the privacy regulations. FedBiP is also the first approach to\nsimultaneously address feature space heterogeneity and client data scarcity in\nOSFL. Our method is validated through extensive experiments on three OSFL\nbenchmarks with feature space heterogeneity, as well as on challenging medical\nand satellite image datasets with label heterogeneity. The results demonstrate\nthe effectiveness of FedBiP, which substantially outperforms other OSFL\nmethods.\n","authors":["Haokun Chen","Hang Li","Yao Zhang","Jinhe Bi","Gengyuan Zhang","Yueqi Zhang","Philip Torr","Jindong Gu","Denis Krompass","Volker Tresp"],"pdf_url":"https://arxiv.org/pdf/2410.04810v2.pdf","comment":"CVPR 2025"},{"id":"http://arxiv.org/abs/2308.09036v2","updated":"2025-03-02T17:15:30Z","published":"2023-08-17T15:17:49Z","title":"Synthesizing Physically Plausible Human Motions in 3D Scenes","summary":"  We present a physics-based character control framework for synthesizing\nhuman-scene interactions. Recent advances adopt physics simulation to mitigate\nartifacts produced by data-driven kinematic approaches. However, existing\nphysics-based methods mainly focus on single-object environments, resulting in\nlimited applicability in realistic 3D scenes with multi-objects. To address\nsuch challenges, we propose a framework that enables physically simulated\ncharacters to perform long-term interaction tasks in diverse, cluttered, and\nunseen 3D scenes. The key idea is to decouple human-scene interactions into two\nfundamental processes, Interacting and Navigating, which motivates us to\nconstruct two reusable Controllers, namely InterCon and NavCon. Specifically,\nInterCon uses two complementary policies to enable characters to enter or leave\nthe interacting state with a particular object (e.g., sitting on a chair or\ngetting up). To realize navigation in cluttered environments, we introduce\nNavCon, where a trajectory following policy enables characters to track\npre-planned collision-free paths. Benefiting from the divide and conquer\nstrategy, we can train all policies in simple environments and directly apply\nthem in complex multi-object scenes through coordination from a rule-based\nscheduler. Video and code are available at\nhttps://github.com/liangpan99/InterScene.\n","authors":["Liang Pan","Jingbo Wang","Buzhen Huang","Junyu Zhang","Haofan Wang","Xu Tang","Yangang Wang"],"pdf_url":"https://arxiv.org/pdf/2308.09036v2.pdf","comment":"3DV 2024 version"},{"id":"http://arxiv.org/abs/2410.15744v2","updated":"2025-03-02T16:58:17Z","published":"2024-10-21T08:01:58Z","title":"Unleashing the Potential of Vision-Language Pre-Training for 3D\n  Zero-Shot Lesion Segmentation via Mask-Attribute Alignment","summary":"  Recent advancements in medical vision-language pre-training models have\ndriven significant progress in zero-shot disease recognition. However,\ntransferring image-level knowledge to pixel-level tasks, such as lesion\nsegmentation in 3D CT scans, remains a critical challenge. Due to the\ncomplexity and variability of pathological visual characteristics, existing\nmethods struggle to align fine-grained lesion features not encountered during\ntraining with disease-related textual representations. In this paper, we\npresent Malenia, a novel multi-scale lesion-level mask-attribute alignment\nframework, specifically designed for 3D zero-shot lesion segmentation. Malenia\nimproves the compatibility between mask representations and their associated\nelemental attributes, explicitly linking the visual features of unseen lesions\nwith the extensible knowledge learned from previously seen ones. Furthermore,\nwe design a Cross-Modal Knowledge Injection module to enhance both visual and\ntextual features with mutually beneficial information, effectively guiding the\ngeneration of segmentation results. Comprehensive experiments across three\ndatasets and 12 lesion categories validate the superior performance of Malenia.\n","authors":["Yankai Jiang","Wenhui Lei","Xiaofan Zhang","Shaoting Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.15744v2.pdf","comment":"Accepted as ICLR 2025 conference paper"},{"id":"http://arxiv.org/abs/2403.18035v4","updated":"2025-03-02T16:41:49Z","published":"2024-03-26T18:40:36Z","title":"Bidirectional Consistency Models","summary":"  Diffusion models (DMs) are capable of generating remarkably high-quality\nsamples by iteratively denoising a random vector, a process that corresponds to\nmoving along the probability flow ordinary differential equation (PF ODE).\nInterestingly, DMs can also invert an input image to noise by moving backward\nalong the PF ODE, a key operation for downstream tasks such as interpolation\nand image editing. However, the iterative nature of this process restricts its\nspeed, hindering its broader application. Recently, Consistency Models (CMs)\nhave emerged to address this challenge by approximating the integral of the PF\nODE, largely reducing the number of iterations. Yet, the absence of an explicit\nODE solver complicates the inversion process. To resolve this, we introduce\nBidirectional Consistency Model (BCM), which learns a single neural network\nthat enables both forward and backward traversal along the PF ODE, efficiently\nunifying generation and inversion tasks within one framework. We can train BCM\nfrom scratch or tune it using a pretrained consistency model, which reduces the\ntraining cost and increases scalability. We demonstrate that BCM enables\none-step generation and inversion while also allowing the use of additional\nsteps to enhance generation quality or reduce reconstruction error. We further\nshowcase BCM's capability in downstream tasks, such as interpolation and\ninpainting. Our code and weights are available at\nhttps://github.com/Mosasaur5526/BCM-iCT-torch.\n","authors":["Liangchen Li","Jiajun He"],"pdf_url":"https://arxiv.org/pdf/2403.18035v4.pdf","comment":"39 pages, 27 figures; a shorter version of this paper was acceppted\n  at the ICML 2024 Workshop on Structured Probabilistic Inference & Generative\n  Modeling"},{"id":"http://arxiv.org/abs/2408.11915v2","updated":"2025-03-02T15:55:14Z","published":"2024-08-21T18:06:15Z","title":"Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event\n  Condition For Foley Sound","summary":"  Foley sound synthesis is crucial for multimedia production, enhancing user\nexperience by synchronizing audio and video both temporally and semantically.\nRecent studies on automating this labor-intensive process through\nvideo-to-sound generation face significant challenges. Systems lacking explicit\ntemporal features suffer from poor alignment and controllability, while\ntimestamp-based models require costly and subjective human annotation. We\npropose Video-Foley, a video-to-sound system using Root Mean Square (RMS) as an\nintuitive condition with semantic timbre prompts (audio or text). RMS, a\nframe-level intensity envelope closely related to audio semantics, acts as a\ntemporal event feature to guide audio generation from video. The\nannotation-free self-supervised learning framework consists of two stages,\nVideo2RMS and RMS2Sound, incorporating novel ideas including RMS discretization\nand RMS-ControlNet with a pretrained text-to-audio model. Our extensive\nevaluation shows that Video-Foley achieves state-of-the-art performance in\naudio-visual alignment and controllability for sound timing, intensity, timbre,\nand nuance. Source code, model weights and demos are available on our companion\nwebsite. (https://jnwnlee.github.io/video-foley-demo)\n","authors":["Junwon Lee","Jaekwon Im","Dabin Kim","Juhan Nam"],"pdf_url":"https://arxiv.org/pdf/2408.11915v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.03895v2","updated":"2025-03-02T15:55:07Z","published":"2025-01-07T16:03:14Z","title":"LLaVA-Mini: Efficient Image and Video Large Multimodal Models with One\n  Vision Token","summary":"  The advent of real-time large multimodal models (LMMs) like GPT-4o has\nsparked considerable interest in efficient LMMs. LMM frameworks typically\nencode visual inputs into vision tokens (continuous representations) and\nintegrate them and textual instructions into the context of large language\nmodels (LLMs), where large-scale parameters and numerous context tokens\n(predominantly vision tokens) result in substantial computational overhead.\nPrevious efforts towards efficient LMMs always focus on replacing the LLM\nbackbone with smaller models, while neglecting the crucial issue of token\nquantity. In this paper, we introduce LLaVA-Mini, an efficient LMM with minimal\nvision tokens. To achieve a high compression ratio of vision tokens while\npreserving visual information, we first analyze how LMMs understand vision\ntokens and find that most vision tokens only play a crucial role in the early\nlayers of LLM backbone, where they mainly fuse visual information into text\ntokens. Building on this finding, LLaVA-Mini introduces modality pre-fusion to\nfuse visual information into text tokens in advance, thereby facilitating the\nextreme compression of vision tokens fed to LLM backbone into one token.\nLLaVA-Mini is a unified large multimodal model that can support the\nunderstanding of images, high-resolution images, and videos in an efficient\nmanner. Experiments across 11 image-based and 7 video-based benchmarks\ndemonstrate that LLaVA-Mini outperforms LLaVA-v1.5 with just 1 vision token\ninstead of 576. Efficiency analyses reveal that LLaVA-Mini can reduce FLOPs by\n77%, deliver low-latency responses within 40 milliseconds, and process over\n10,000 frames of video on the GPU hardware with 24GB of memory.\n","authors":["Shaolei Zhang","Qingkai Fang","Zhe Yang","Yang Feng"],"pdf_url":"https://arxiv.org/pdf/2501.03895v2.pdf","comment":"Accepted to ICLR 2025. Code: https://github.com/ictnlp/LLaVA-Mini\n  Model: https://huggingface.co/ICTNLP/llava-mini-llama-3.1-8b"},{"id":"http://arxiv.org/abs/2501.18672v3","updated":"2025-03-02T15:43:39Z","published":"2025-01-30T18:51:54Z","title":"Drag Your Gaussian: Effective Drag-Based Editing with Score Distillation\n  for 3D Gaussian Splatting","summary":"  Recent advancements in 3D scene editing have been propelled by the rapid\ndevelopment of generative models. Existing methods typically utilize generative\nmodels to perform text-guided editing on 3D representations, such as 3D\nGaussian Splatting (3DGS). However, these methods are often limited to texture\nmodifications and fail when addressing geometric changes, such as editing a\ncharacter's head to turn around. Moreover, such methods lack accurate control\nover the spatial position of editing results, as language struggles to\nprecisely describe the extent of edits. To overcome these limitations, we\nintroduce DYG, an effective 3D drag-based editing method for 3D Gaussian\nSplatting. It enables users to conveniently specify the desired editing region\nand the desired dragging direction through the input of 3D masks and pairs of\ncontrol points, thereby enabling precise control over the extent of editing.\nDYG integrates the strengths of the implicit triplane representation to\nestablish the geometric scaffold of the editing results, effectively overcoming\nsuboptimal editing outcomes caused by the sparsity of 3DGS in the desired\nediting regions. Additionally, we incorporate a drag-based Latent Diffusion\nModel into our method through the proposed Drag-SDS loss function, enabling\nflexible, multi-view consistent, and fine-grained editing. Extensive\nexperiments demonstrate that DYG conducts effective drag-based editing guided\nby control point prompts, surpassing other baselines in terms of editing effect\nand quality, both qualitatively and quantitatively. Visit our project page at\nhttps://quyans.github.io/Drag-Your-Gaussian.\n","authors":["Yansong Qu","Dian Chen","Xinyang Li","Xiaofan Li","Shengchuan Zhang","Liujuan Cao","Rongrong Ji"],"pdf_url":"https://arxiv.org/pdf/2501.18672v3.pdf","comment":"Visit our project page at https://quyans.github.io/Drag-Your-Gaussian"},{"id":"http://arxiv.org/abs/2310.18709v4","updated":"2025-03-02T15:37:39Z","published":"2023-10-28T13:37:52Z","title":"Audio-Visual Instance Segmentation","summary":"  In this paper, we propose a new multi-modal task, termed audio-visual\ninstance segmentation (AVIS), which aims to simultaneously identify, segment\nand track individual sounding object instances in audible videos. To facilitate\nthis research, we introduce a high-quality benchmark named AVISeg, containing\nover 90K instance masks from 26 semantic categories in 926 long videos.\nAdditionally, we propose a strong baseline model for this task. Our model first\nlocalizes sound source within each frame, and condenses object-specific\ncontexts into concise tokens. Then it builds long-range audio-visual\ndependencies between these tokens using window-based attention, and tracks\nsounding objects among the entire video sequences. Extensive experiments reveal\nthat our method performs best on AVISeg, surpassing the existing methods from\nrelated tasks. We further conduct the evaluation on several multi-modal large\nmodels. Unfortunately, they exhibits subpar performance on instance-level sound\nsource localization and temporal perception. We expect that AVIS will inspire\nthe community towards a more comprehensive multi-modal understanding. Dataset\nand code is available at https://github.com/ruohaoguo/avis.\n","authors":["Ruohao Guo","Xianghua Ying","Yaru Chen","Dantong Niu","Guangyao Li","Liao Qu","Yanyu Qi","Jinxing Zhou","Bowei Xing","Wenzhen Yue","Ji Shi","Qixun Wang","Peiliang Zhang","Buwen Liang"],"pdf_url":"https://arxiv.org/pdf/2310.18709v4.pdf","comment":"Accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2409.03114v2","updated":"2025-03-02T15:30:06Z","published":"2024-09-04T22:39:02Z","title":"Evaluating Low-Resource Lane Following Algorithms for\n  Compute-Constrained Automated Vehicles","summary":"  Reliable lane-following is essential for automated and assisted driving, yet\nexisting solutions often rely on models that require extensive computational\nresources, limiting their deployment in compute-constrained vehicles. We\nevaluate five low-resource lane-following algorithms designed for real-time\noperation on vehicles with limited computing resources. Performance was\nassessed through simulation and deployment on real drive-by-wire electric\nvehicles, with evaluation metrics including reliability, comfort, speed, and\nadaptability. The top-performing methods used unsupervised learning to detect\nand separate lane lines with processing time under 10 ms per frame,\noutperforming compute-intensive and poor generalizing deep learning approaches.\nThese approaches demonstrated robustness across lighting conditions, road\ntextures, and lane geometries. The findings highlight the potential for\nefficient lane detection approaches to enhance the accessibility and\nreliability of autonomous vehicle technologies. Reducing computing requirements\nenables lane keeping to be widely deployed in vehicles as part of lower-level\nautomation, including active safety systems.\n","authors":["Beñat Froemming-Aldanondo","Tatiana Rastoskueva","Michael Evans","Marcial Machado","Anna Vadella","Rickey Johnson","Luis Escamilla","Milan Jostes","Devson Butani","Ryan Kaddis","Chan-Jin Chung","Joshua Siegel"],"pdf_url":"https://arxiv.org/pdf/2409.03114v2.pdf","comment":"Supported by the National Science Foundation under Grants No. 2150292\n  and 2150096"},{"id":"http://arxiv.org/abs/2410.03878v2","updated":"2025-03-02T15:22:12Z","published":"2024-10-04T19:22:20Z","title":"SPARTUN3D: Situated Spatial Understanding of 3D World in Large Language\n  Models","summary":"  Integrating the 3D world into large language models (3D-based LLMs) has been\na promising research direction for 3D scene understanding. However, current\n3D-based LLMs fall short in situated understanding due to two key limitations:\n1) existing 3D datasets are constructed from a global perspective of the 3D\nscenes and lack situated context. 2) the architectures of existing 3D-based\nLLMs lack explicit alignment between the spatial representations of 3D scenes\nand natural language, limiting their performance in tasks requiring precise\nspatial reasoning. We address these issues by introducing a scalable situated\n3D dataset, named Spartun3D, that incorporates various situated spatial\nreasoning tasks. Furthermore, we propose Spartun3D-LLM, built on an existing\n3D-based LLM but integrated with a novel situated spatial alignment module,\naiming to enhance the alignment between 3D visual representations and their\ncorresponding textual descriptions. Experimental results demonstrate that both\nour proposed dataset and alignment module significantly enhance the situated\nspatial understanding of 3D-based LLMs.\n","authors":["Yue Zhang","Zhiyang Xu","Ying Shen","Parisa Kordjamshidi","Lifu Huang"],"pdf_url":"https://arxiv.org/pdf/2410.03878v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.13426v2","updated":"2025-03-02T15:06:51Z","published":"2024-09-20T11:46:48Z","title":"HMD^2: Environment-aware Motion Generation from Single Egocentric\n  Head-Mounted Device","summary":"  This paper investigates the generation of realistic full-body human motion\nusing a single head-mounted device with an outward-facing color camera and the\nability to perform visual SLAM. To address the ambiguity of this setup, we\npresent HMD^2, a novel system that balances motion reconstruction and\ngeneration. From a reconstruction standpoint, it aims to maximally utilize the\ncamera streams to produce both analytical and learned features, including head\nmotion, SLAM point cloud, and image embeddings. On the generative front, HMD^2\nemploys a multi-modal conditional motion diffusion model with a Transformer\nbackbone to maintain temporal coherence of generated motions, and utilizes\nautoregressive inpainting to facilitate online motion inference with minimal\nlatency (0.17 seconds). We show that our system provides an effective and\nrobust solution that scales to a diverse dataset of over 200 hours of motion in\ncomplex indoor and outdoor environments.\n","authors":["Vladimir Guzov","Yifeng Jiang","Fangzhou Hong","Gerard Pons-Moll","Richard Newcombe","C. Karen Liu","Yuting Ye","Lingni Ma"],"pdf_url":"https://arxiv.org/pdf/2409.13426v2.pdf","comment":"International Conference on 3D Vision 2025 (3DV 2025)"},{"id":"http://arxiv.org/abs/2502.11858v3","updated":"2025-03-02T14:14:07Z","published":"2025-02-17T14:50:34Z","title":"Rethinking Audio-Visual Adversarial Vulnerability from Temporal and\n  Modality Perspectives","summary":"  While audio-visual learning equips models with a richer understanding of the\nreal world by leveraging multiple sensory modalities, this integration also\nintroduces new vulnerabilities to adversarial attacks.\n  In this paper, we present a comprehensive study of the adversarial robustness\nof audio-visual models, considering both temporal and modality-specific\nvulnerabilities. We propose two powerful adversarial attacks: 1) a temporal\ninvariance attack that exploits the inherent temporal redundancy across\nconsecutive time segments and 2) a modality misalignment attack that introduces\nincongruence between the audio and visual modalities. These attacks are\ndesigned to thoroughly assess the robustness of audio-visual models against\ndiverse threats. Furthermore, to defend against such attacks, we introduce a\nnovel audio-visual adversarial training framework. This framework addresses key\nchallenges in vanilla adversarial training by incorporating efficient\nadversarial perturbation crafting tailored to multi-modal data and an\nadversarial curriculum strategy. Extensive experiments in the Kinetics-Sounds\ndataset demonstrate that our proposed temporal and modality-based attacks in\ndegrading model performance can achieve state-of-the-art performance, while our\nadversarial training defense largely improves the adversarial robustness as\nwell as the adversarial training efficiency.\n","authors":["Zeliang Zhang","Susan Liang","Daiki Shimada","Chenliang Xu"],"pdf_url":"https://arxiv.org/pdf/2502.11858v3.pdf","comment":"Accepted by ICLR 2025"},{"id":"http://arxiv.org/abs/2410.02094v3","updated":"2025-03-02T14:04:22Z","published":"2024-10-02T23:30:05Z","title":"Tracking objects that change in appearance with phase synchrony","summary":"  Objects we encounter often change appearance as we interact with them.\nChanges in illumination (shadows), object pose, or the movement of non-rigid\nobjects can drastically alter available image features. How do biological\nvisual systems track objects as they change? One plausible mechanism involves\nattentional mechanisms for reasoning about the locations of objects\nindependently of their appearances -- a capability that prominent neuroscience\ntheories have associated with computing through neural synchrony. Here, we\ndescribe a novel deep learning circuit that can learn to precisely control\nattention to features separately from their location in the world through\nneural synchrony: the complex-valued recurrent neural network (CV-RNN). Next,\nwe compare object tracking in humans, the CV-RNN, and other deep neural\nnetworks (DNNs), using FeatureTracker: a large-scale challenge that asks\nobservers to track objects as their locations and appearances change in\nprecisely controlled ways. While humans effortlessly solved FeatureTracker,\nstate-of-the-art DNNs did not. In contrast, our CV-RNN behaved similarly to\nhumans on the challenge, providing a computational proof-of-concept for the\nrole of phase synchronization as a neural substrate for tracking\nappearance-morphing objects as they move about.\n","authors":["Sabine Muzellec","Drew Linsley","Alekh K. Ashok","Ennio Mingolla","Girik Malik","Rufin VanRullen","Thomas Serre"],"pdf_url":"https://arxiv.org/pdf/2410.02094v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.19047v2","updated":"2025-03-02T13:52:23Z","published":"2025-02-26T11:01:43Z","title":"A Dual-Purpose Framework for Backdoor Defense and Backdoor Amplification\n  in Diffusion Models","summary":"  Diffusion models have emerged as state-of-the-art generative frameworks,\nexcelling in producing high-quality multi-modal samples. However, recent\nstudies have revealed their vulnerability to backdoor attacks, where backdoored\nmodels generate specific, undesirable outputs called backdoor target (e.g.,\nharmful images) when a pre-defined trigger is embedded to their inputs. In this\npaper, we propose PureDiffusion, a dual-purpose framework that simultaneously\nserves two contrasting roles: backdoor defense and backdoor attack\namplification. For defense, we introduce two novel loss functions to invert\nbackdoor triggers embedded in diffusion models. The first leverages\ntrigger-induced distribution shifts across multiple timesteps of the diffusion\nprocess, while the second exploits the denoising consistency effect when a\nbackdoor is activated. Once an accurate trigger inversion is achieved, we\ndevelop a backdoor detection method that analyzes both the inverted trigger and\nthe generated backdoor targets to identify backdoor attacks. In terms of attack\namplification with the role of an attacker, we describe how our trigger\ninversion algorithm can be used to reinforce the original trigger embedded in\nthe backdoored diffusion model. This significantly boosts attack performance\nwhile reducing the required backdoor training time. Experimental results\ndemonstrate that PureDiffusion achieves near-perfect detection accuracy,\noutperforming existing defenses by a large margin, particularly against complex\ntrigger patterns. Additionally, in an attack scenario, our attack amplification\napproach elevates the attack success rate (ASR) of existing backdoor attacks to\nnearly 100\\% while reducing training time by up to 20x.\n","authors":["Vu Tuan Truong","Long Bao Le"],"pdf_url":"https://arxiv.org/pdf/2502.19047v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.15161v2","updated":"2025-03-02T13:49:21Z","published":"2024-04-23T16:01:33Z","title":"Test-Time Adaptation for Combating Missing Modalities in Egocentric\n  Videos","summary":"  Understanding videos that contain multiple modalities is crucial, especially\nin egocentric videos, where combining various sensory inputs significantly\nimproves tasks like action recognition and moment localization. However,\nreal-world applications often face challenges with incomplete modalities due to\nprivacy concerns, efficiency needs, or hardware issues. Current methods, while\neffective, often necessitate retraining the model entirely to handle missing\nmodalities, making them computationally intensive, particularly with large\ntraining datasets. In this study, we propose a novel approach to address this\nissue at test time without requiring retraining. We frame the problem as a\ntest-time adaptation task, where the model adjusts to the available unlabeled\ndata at test time. Our method, MiDl~(Mutual information with\nself-Distillation), encourages the model to be insensitive to the specific\nmodality source present during testing by minimizing the mutual information\nbetween the prediction and the available modality. Additionally, we incorporate\nself-distillation to maintain the model's original performance when both\nmodalities are available. MiDl represents the first self-supervised, online\nsolution for handling missing modalities exclusively at test time. Through\nexperiments with various pretrained models and datasets, MiDl demonstrates\nsubstantial performance improvement without the need for retraining.\n","authors":["Merey Ramazanova","Alejandro Pardo","Bernard Ghanem","Motasem Alfarra"],"pdf_url":"https://arxiv.org/pdf/2404.15161v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20209v2","updated":"2025-03-02T13:36:57Z","published":"2025-02-27T15:50:21Z","title":"DIPSER: A Dataset for In-Person Student Engagement Recognition in the\n  Wild","summary":"  In this paper, a novel dataset is introduced, designed to assess student\nattention within in-person classroom settings. This dataset encompasses RGB\ncamera data, featuring multiple cameras per student to capture both posture and\nfacial expressions, in addition to smartwatch sensor data for each individual.\nThis dataset allows machine learning algorithms to be trained to predict\nattention and correlate it with emotion. A comprehensive suite of attention and\nemotion labels for each student is provided, generated through self-reporting\nas well as evaluations by four different experts. Our dataset uniquely combines\nfacial and environmental camera data, smartwatch metrics, and includes\nunderrepresented ethnicities in similar datasets, all within in-the-wild,\nin-person settings, making it the most comprehensive dataset of its kind\ncurrently available.\n  The dataset presented offers an extensive and diverse collection of data\npertaining to student interactions across different educational contexts,\naugmented with additional metadata from other tools. This initiative addresses\nexisting deficiencies by offering a valuable resource for the analysis of\nstudent attention and emotion in face-to-face lessons.\n","authors":["Luis Marquez-Carpintero","Sergio Suescun-Ferrandiz","Carolina Lorenzo Álvarez","Jorge Fernandez-Herrero","Diego Viejo","Rosabel Roig-Vila","Miguel Cazorla"],"pdf_url":"https://arxiv.org/pdf/2502.20209v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.02820v2","updated":"2025-03-02T13:14:11Z","published":"2022-08-04T02:22:29Z","title":"MOVE: Effective and Harmless Ownership Verification via Embedded\n  External Features","summary":"  Currently, deep neural networks (DNNs) are widely adopted in different\napplications. Despite its commercial values, training a well-performing DNN is\nresource-consuming. Accordingly, the well-trained model is valuable\nintellectual property for its owner. However, recent studies revealed the\nthreats of model stealing, where the adversaries can obtain a function-similar\ncopy of the victim model, even when they can only query the model. In this\npaper, we propose an effective and harmless model ownership verification (MOVE)\nto defend against different types of model stealing simultaneously, without\nintroducing new security risks. In general, we conduct the ownership\nverification by verifying whether a suspicious model contains the knowledge of\ndefender-specified external features. Specifically, we embed the external\nfeatures by modifying a few training samples with style transfer. We then train\na meta-classifier to determine whether a model is stolen from the victim. This\napproach is inspired by the understanding that the stolen models should contain\nthe knowledge of features learned by the victim model. In particular,\n\\revision{we develop our MOVE method under both white-box and black-box\nsettings and analyze its theoretical foundation to provide comprehensive model\nprotection.} Extensive experiments on benchmark datasets verify the\neffectiveness of our method and its resistance to potential adaptive attacks.\nThe codes for reproducing the main experiments of our method are available at\nhttps://github.com/THUYimingLi/MOVE.\n","authors":["Yiming Li","Linghui Zhu","Xiaojun Jia","Yang Bai","Yong Jiang","Shu-Tao Xia","Xiaochun Cao","Kui Ren"],"pdf_url":"https://arxiv.org/pdf/2208.02820v2.pdf","comment":"This paper has been accepted by IEEE TPAMI 2025. It is the journal\n  extension of our conference paper in AAAI 2022\n  (https://ojs.aaai.org/index.php/AAAI/article/view/20036). 18 pages"},{"id":"http://arxiv.org/abs/2502.18461v2","updated":"2025-03-02T12:44:06Z","published":"2025-02-25T18:59:12Z","title":"K-LoRA: Unlocking Training-Free Fusion of Any Subject and Style LoRAs","summary":"  Recent studies have explored combining different LoRAs to jointly generate\nlearned style and content. However, existing methods either fail to effectively\npreserve both the original subject and style simultaneously or require\nadditional training. In this paper, we argue that the intrinsic properties of\nLoRA can effectively guide diffusion models in merging learned subject and\nstyle. Building on this insight, we propose K-LoRA, a simple yet effective\ntraining-free LoRA fusion approach. In each attention layer, K-LoRA compares\nthe Top-K elements in each LoRA to be fused, determining which LoRA to select\nfor optimal fusion. This selection mechanism ensures that the most\nrepresentative features of both subject and style are retained during the\nfusion process, effectively balancing their contributions. Experimental results\ndemonstrate that the proposed method effectively integrates the subject and\nstyle information learned by the original LoRAs, outperforming state-of-the-art\ntraining-based approaches in both qualitative and quantitative results.\n","authors":["Ziheng Ouyang","Zhen Li","Qibin Hou"],"pdf_url":"https://arxiv.org/pdf/2502.18461v2.pdf","comment":"CVPR 2025, Project page: https://k-lora.github.io/K-LoRA.io/"},{"id":"http://arxiv.org/abs/2406.15812v2","updated":"2025-03-02T12:28:24Z","published":"2024-06-22T10:36:04Z","title":"Intrinsic Dimension Correlation: uncovering nonlinear connections in\n  multimodal representations","summary":"  To gain insight into the mechanisms behind machine learning methods, it is\ncrucial to establish connections among the features describing data points.\nHowever, these correlations often exhibit a high-dimensional and strongly\nnonlinear nature, which makes them challenging to detect using standard\nmethods. This paper exploits the entanglement between intrinsic dimensionality\nand correlation to propose a metric that quantifies the (potentially nonlinear)\ncorrelation between high-dimensional manifolds. We first validate our method on\nsynthetic data in controlled environments, showcasing its advantages and\ndrawbacks compared to existing techniques. Subsequently, we extend our analysis\nto large-scale applications in neural network representations. Specifically, we\nfocus on latent representations of multimodal data, uncovering clear\ncorrelations between paired visual and textual embeddings, whereas existing\nmethods struggle significantly in detecting similarity. Our results indicate\nthe presence of highly nonlinear correlation patterns between latent manifolds.\n","authors":["Lorenzo Basile","Santiago Acevedo","Luca Bortolussi","Fabio Anselmi","Alex Rodriguez"],"pdf_url":"https://arxiv.org/pdf/2406.15812v2.pdf","comment":"Accepted at ICLR 2025"},{"id":"http://arxiv.org/abs/2409.20063v2","updated":"2025-03-02T12:17:51Z","published":"2024-09-30T08:05:00Z","title":"Q-Bench-Video: Benchmarking the Video Quality Understanding of LMMs","summary":"  With the rising interest in research on Large Multi-modal Models (LMMs) for\nvideo understanding, many studies have emphasized general video comprehension\ncapabilities, neglecting the systematic exploration into video quality\nunderstanding. To address this oversight, we introduce Q-Bench-Video in this\npaper, a new benchmark specifically designed to evaluate LMMs' proficiency in\ndiscerning video quality. a) To ensure video source diversity, Q-Bench-Video\nencompasses videos from natural scenes, AI-generated Content (AIGC), and\nComputer Graphics (CG). b) Building on the traditional multiple-choice\nquestions format with the Yes-or-No and What-How categories, we include\nOpen-ended questions to better evaluate complex scenarios. Additionally, we\nincorporate the video pair quality comparison question to enhance\ncomprehensiveness. c) Beyond the traditional Technical, Aesthetic, and Temporal\ndistortions, we have expanded our evaluation aspects to include the dimension\nof AIGC distortions, which addresses the increasing demand for video\ngeneration. Finally, we collect a total of 2,378 question-answer pairs and test\nthem on 12 open-source & 5 proprietary LMMs. Our findings indicate that while\nLMMs have a foundational understanding of video quality, their performance\nremains incomplete and imprecise, with a notable discrepancy compared to human\nperformance. Through Q-Bench-Video, we seek to catalyze community interest,\nstimulate further research, and unlock the untapped potential of LMMs to close\nthe gap in video quality understanding.\n","authors":["Zicheng Zhang","Ziheng Jia","Haoning Wu","Chunyi Li","Zijian Chen","Yingjie Zhou","Wei Sun","Xiaohong Liu","Xiongkuo Min","Weisi Lin","Guangtao Zhai"],"pdf_url":"https://arxiv.org/pdf/2409.20063v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08470v2","updated":"2025-03-02T11:52:31Z","published":"2024-11-13T09:42:12Z","title":"HyperFace: Generating Synthetic Face Recognition Datasets by Exploring\n  Face Embedding Hypersphere","summary":"  Face recognition datasets are often collected by crawling Internet and\nwithout individuals' consents, raising ethical and privacy concerns. Generating\nsynthetic datasets for training face recognition models has emerged as a\npromising alternative. However, the generation of synthetic datasets remains\nchallenging as it entails adequate inter-class and intra-class variations.\nWhile advances in generative models have made it easier to increase intra-class\nvariations in face datasets (such as pose, illumination, etc.), generating\nsufficient inter-class variation is still a difficult task. In this paper, we\nformulate the dataset generation as a packing problem on the embedding space\n(represented on a hypersphere) of a face recognition model and propose a new\nsynthetic dataset generation approach, called HyperFace. We formalize our\npacking problem as an optimization problem and solve it with a gradient\ndescent-based approach. Then, we use a conditional face generator model to\nsynthesize face images from the optimized embeddings. We use our generated\ndatasets to train face recognition models and evaluate the trained models on\nseveral benchmarking real datasets. Our experimental results show that models\ntrained with HyperFace achieve state-of-the-art performance in training face\nrecognition using synthetic datasets.\n","authors":["Hatef Otroshi Shahreza","Sébastien Marcel"],"pdf_url":"https://arxiv.org/pdf/2411.08470v2.pdf","comment":"Accepted in ICLR 2025"},{"id":"http://arxiv.org/abs/2408.09886v3","updated":"2025-03-02T11:32:04Z","published":"2024-08-19T11:01:00Z","title":"Improved Baselines with Synchronized Encoding for Universal Medical\n  Image Segmentation","summary":"  Large foundation models, known for their strong zero-shot generalization\ncapabilities, can be applied to a wide range of downstream tasks. However,\ndeveloping foundation models for medical image segmentation poses a significant\nchallenge due to the domain gap between natural and medical images. While\nfine-tuning techniques based on the Segment Anything Model (SAM) have been\nexplored, they primarily focus on scaling up data or refining inference\nstrategies without incorporating domain-specific architectural designs,\nlimiting their zero-shot performance. To optimize segmentation performance\nunder standard inference settings and provide a strong baseline for future\nresearch, we introduce SyncSAM, which employs a synchronized dual-branch\nencoder that integrates convolution and Transformer features in a synchronized\nmanner to enhance medical image encoding, and a multi-scale dual-branch decoder\nto preserve image details. SyncSAM is trained on two of the largest medical\nimage segmentation datasets, SA-Med2D-20M and IMed-361M, resulting in a series\nof pre-trained models for universal medical image segmentation. Experimental\nresults demonstrate that SyncSAM not only achieves state-of-the-art performance\non test sets but also exhibits strong zero-shot capabilities on unseen\ndatasets. The code and model weights are available at\nhttps://github.com/Hhankyangg/SyncSAM.\n","authors":["Sihan Yang","Xuande Mi","Jiadong Feng","Haixia Bi","Hai Zhang","Jian Sun"],"pdf_url":"https://arxiv.org/pdf/2408.09886v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.15445v2","updated":"2025-03-02T11:16:08Z","published":"2025-01-26T08:22:44Z","title":"StochSync: Stochastic Diffusion Synchronization for Image Generation in\n  Arbitrary Spaces","summary":"  We propose a zero-shot method for generating images in arbitrary spaces\n(e.g., a sphere for 360{\\deg} panoramas and a mesh surface for texture) using a\npretrained image diffusion model. The zero-shot generation of various visual\ncontent using a pretrained image diffusion model has been explored mainly in\ntwo directions. First, Diffusion Synchronization-performing reverse diffusion\nprocesses jointly across different projected spaces while synchronizing them in\nthe target space-generates high-quality outputs when enough conditioning is\nprovided, but it struggles in its absence. Second, Score Distillation\nSampling-gradually updating the target space data through gradient\ndescent-results in better coherence but often lacks detail. In this paper, we\nreveal for the first time the interconnection between these two methods while\nhighlighting their differences. To this end, we propose StochSync, a novel\napproach that combines the strengths of both, enabling effective performance\nwith weak conditioning. Our experiments demonstrate that StochSync provides the\nbest performance in 360{\\deg} panorama generation (where image conditioning is\nnot given), outperforming previous finetuning-based methods, and also delivers\ncomparable results in 3D mesh texturing (where depth conditioning is provided)\nwith previous methods.\n","authors":["Kyeongmin Yeo","Jaihoon Kim","Minhyuk Sung"],"pdf_url":"https://arxiv.org/pdf/2501.15445v2.pdf","comment":"Project page: https://stochsync.github.io/ (ICLR 2025)"},{"id":"http://arxiv.org/abs/2410.05260v2","updated":"2025-03-02T10:58:06Z","published":"2024-10-07T17:58:22Z","title":"DartControl: A Diffusion-Based Autoregressive Motion Model for Real-Time\n  Text-Driven Motion Control","summary":"  Text-conditioned human motion generation, which allows for user interaction\nthrough natural language, has become increasingly popular. Existing methods\ntypically generate short, isolated motions based on a single input sentence.\nHowever, human motions are continuous and can extend over long periods,\ncarrying rich semantics. Creating long, complex motions that precisely respond\nto streams of text descriptions, particularly in an online and real-time\nsetting, remains a significant challenge. Furthermore, incorporating spatial\nconstraints into text-conditioned motion generation presents additional\nchallenges, as it requires aligning the motion semantics specified by text\ndescriptions with geometric information, such as goal locations and 3D scene\ngeometry. To address these limitations, we propose DartControl, in short DART,\na Diffusion-based Autoregressive motion primitive model for Real-time\nText-driven motion control. Our model effectively learns a compact motion\nprimitive space jointly conditioned on motion history and text inputs using\nlatent diffusion models. By autoregressively generating motion primitives based\non the preceding history and current text input, DART enables real-time,\nsequential motion generation driven by natural language descriptions.\nAdditionally, the learned motion primitive space allows for precise spatial\nmotion control, which we formulate either as a latent noise optimization\nproblem or as a Markov decision process addressed through reinforcement\nlearning. We present effective algorithms for both approaches, demonstrating\nour model's versatility and superior performance in various motion synthesis\ntasks. Experiments show our method outperforms existing baselines in motion\nrealism, efficiency, and controllability. Video results are available on the\nproject page: https://zkf1997.github.io/DART/.\n","authors":["Kaifeng Zhao","Gen Li","Siyu Tang"],"pdf_url":"https://arxiv.org/pdf/2410.05260v2.pdf","comment":"Updated ICLR camera ready version"},{"id":"http://arxiv.org/abs/2402.04236v3","updated":"2025-03-02T09:39:57Z","published":"2024-02-06T18:43:48Z","title":"CogCoM: A Visual Language Model with Chain-of-Manipulations Reasoning","summary":"  Vision-Language Models (VLMs) have demonstrated their broad effectiveness\nthanks to extensive training in aligning visual instructions to responses.\nHowever, such training of conclusive alignment leads models to ignore essential\nvisual reasoning, further resulting in failures in meticulous visual problems\nand unfaithful responses. Drawing inspiration from human cognition in solving\nvisual problems (e.g., marking, zoom in), this paper introduces Chain of\nManipulations, a mechanism that enables VLMs to solve problems step-by-step\nwith evidence. After training, models can solve various visual problems by\neliciting intrinsic manipulations (e.g., grounding, zoom in) with results\n(e.g., boxes, image) actively without involving external tools, while also\nallowing users to trace error causes. We study the roadmap to implement this\nmechanism, including (1) a flexible design of manipulations upon extensive\nanalysis, (2) an efficient automated data generation pipeline, (3) a compatible\nVLM architecture capable of multi-turn multi-image, and (4) a model training\nprocess for versatile capabilities. With the design, we also manually annotate\n6K high-quality samples for the challenging graphical mathematical problems.\nOur trained model, \\textbf{CogCoM}, equipped with this mechanism with 17B\nparameters achieves state-of-the-art performance across 9 benchmarks from 4\ncategories, demonstrating the effectiveness while preserving the\ninterpretability. Our code, model weights, and collected data are publicly\navailable at https://github.com/THUDM/CogCoM.\n","authors":["Ji Qi","Ming Ding","Weihan Wang","Yushi Bai","Qingsong Lv","Wenyi Hong","Bin Xu","Lei Hou","Juanzi Li","Yuxiao Dong","Jie Tang"],"pdf_url":"https://arxiv.org/pdf/2402.04236v3.pdf","comment":"21 pages, 10 figures"},{"id":"http://arxiv.org/abs/2502.18176v2","updated":"2025-03-02T09:22:47Z","published":"2025-02-25T13:09:34Z","title":"CLIPure: Purification in Latent Space via CLIP for Adversarially Robust\n  Zero-Shot Classification","summary":"  In this paper, we aim to build an adversarially robust zero-shot image\nclassifier. We ground our work on CLIP, a vision-language pre-trained encoder\nmodel that can perform zero-shot classification by matching an image with text\nprompts ``a photo of a <class-name>.''. Purification is the path we choose\nsince it does not require adversarial training on specific attack types and\nthus can cope with any foreseen attacks. We then formulate purification risk as\nthe KL divergence between the joint distributions of the purification process\nof denoising the adversarial samples and the attack process of adding\nperturbations to benign samples, through bidirectional Stochastic Differential\nEquations (SDEs). The final derived results inspire us to explore purification\nin the multi-modal latent space of CLIP. We propose two variants for our\nCLIPure approach: CLIPure-Diff which models the likelihood of images' latent\nvectors with the DiffusionPrior module in DaLLE-2 (modeling the generation\nprocess of CLIP's latent vectors), and CLIPure-Cos which models the likelihood\nwith the cosine similarity between the embeddings of an image and ``a photo of\na.''. As far as we know, CLIPure is the first purification method in\nmulti-modal latent space and CLIPure-Cos is the first purification method that\nis not based on generative models, which substantially improves defense\nefficiency. We conducted extensive experiments on CIFAR-10, ImageNet, and 13\ndatasets that previous CLIP-based defense methods used for evaluating zero-shot\nclassification robustness. Results show that CLIPure boosts the SOTA robustness\nby a large margin, e.g., from 71.7% to 91.1% on CIFAR10, from 59.6% to 72.6% on\nImageNet, and 108% relative improvements of average robustness on the 13\ndatasets over previous SOTA. The code is available at\nhttps://github.com/TMLResearchGroup-CAS/CLIPure.\n","authors":["Mingkun Zhang","Keping Bi","Wei Chen","Jiafeng Guo","Xueqi Cheng"],"pdf_url":"https://arxiv.org/pdf/2502.18176v2.pdf","comment":"accepted by ICLR 2025"},{"id":"http://arxiv.org/abs/2412.09765v2","updated":"2025-03-02T09:21:27Z","published":"2024-12-12T23:57:01Z","title":"L-WISE: Boosting Human Visual Category Learning Through Model-Based\n  Image Selection And Enhancement","summary":"  The currently leading artificial neural network models of the visual ventral\nstream - which are derived from a combination of performance optimization and\nrobustification methods - have demonstrated a remarkable degree of behavioral\nalignment with humans on visual categorization tasks. We show that image\nperturbations generated by these models can enhance the ability of humans to\naccurately report the ground truth class. Furthermore, we find that the same\nmodels can also be used out-of-the-box to predict the proportion of correct\nhuman responses to individual images, providing a simple, human-aligned\nestimator of the relative difficulty of each image. Motivated by these\nobservations, we propose to augment visual learning in humans in a way that\nimproves human categorization accuracy at test time. Our learning augmentation\napproach consists of (i) selecting images based on their model-estimated\nrecognition difficulty, and (ii) applying image perturbations that aid\nrecognition for novice learners. We find that combining these model-based\nstrategies leads to categorization accuracy gains of 33-72% relative to control\nsubjects without these interventions, on unmodified, randomly selected held-out\ntest images. Beyond the accuracy gain, the training time for the augmented\nlearning group was also shortened by 20-23%, despite both groups completing the\nsame number of training trials. We demonstrate the efficacy of our approach in\na fine-grained categorization task with natural images, as well as two tasks in\nclinically relevant image domains - histology and dermoscopy - where visual\nlearning is notoriously challenging. To the best of our knowledge, our work is\nthe first application of artificial neural networks to increase visual learning\nperformance in humans by enhancing category-specific image features.\n","authors":["Morgan B. Talbot","Gabriel Kreiman","James J. DiCarlo","Guy Gaziv"],"pdf_url":"https://arxiv.org/pdf/2412.09765v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.06751v2","updated":"2025-03-02T09:10:13Z","published":"2025-01-12T08:36:38Z","title":"Padding Tone: A Mechanistic Analysis of Padding Tokens in T2I Models","summary":"  Text-to-image (T2I) diffusion models rely on encoded prompts to guide the\nimage generation process. Typically, these prompts are extended to a fixed\nlength by adding padding tokens before text encoding. Despite being a default\npractice, the influence of padding tokens on the image generation process has\nnot been investigated. In this work, we conduct the first in-depth analysis of\nthe role padding tokens play in T2I models. We develop two causal techniques to\nanalyze how information is encoded in the representation of tokens across\ndifferent components of the T2I pipeline. Using these techniques, we\ninvestigate when and how padding tokens impact the image generation process.\nOur findings reveal three distinct scenarios: padding tokens may affect the\nmodel's output during text encoding, during the diffusion process, or be\neffectively ignored. Moreover, we identify key relationships between these\nscenarios and the model's architecture (cross or self-attention) and its\ntraining process (frozen or trained text encoder). These insights contribute to\na deeper understanding of the mechanisms of padding tokens, potentially\ninforming future model design and training practices in T2I systems.\n","authors":["Michael Toker","Ido Galil","Hadas Orgad","Rinon Gal","Yoad Tewel","Gal Chechik","Yonatan Belinkov"],"pdf_url":"https://arxiv.org/pdf/2501.06751v2.pdf","comment":"Published in: NAACL 2025. Project webpage:\n  https://padding-tone.github.io/"},{"id":"http://arxiv.org/abs/2410.06614v2","updated":"2025-03-02T08:59:29Z","published":"2024-10-09T07:09:46Z","title":"Pair-VPR: Place-Aware Pre-training and Contrastive Pair Classification\n  for Visual Place Recognition with Vision Transformers","summary":"  In this work we propose a novel joint training method for Visual Place\nRecognition (VPR), which simultaneously learns a global descriptor and a pair\nclassifier for re-ranking. The pair classifier can predict whether a given pair\nof images are from the same place or not. The network only comprises Vision\nTransformer components for both the encoder and the pair classifier, and both\ncomponents are trained using their respective class tokens. In existing VPR\nmethods, typically the network is initialized using pre-trained weights from a\ngeneric image dataset such as ImageNet. In this work we propose an alternative\npre-training strategy, by using Siamese Masked Image Modelling as a\npre-training task. We propose a Place-aware image sampling procedure from a\ncollection of large VPR datasets for pre-training our model, to learn visual\nfeatures tuned specifically for VPR. By re-using the Mask Image Modelling\nencoder and decoder weights in the second stage of training, Pair-VPR can\nachieve state-of-the-art VPR performance across five benchmark datasets with a\nViT-B encoder, along with further improvements in localization recall with\nlarger encoders. The Pair-VPR website is:\nhttps://csiro-robotics.github.io/Pair-VPR.\n","authors":["Stephen Hausler","Peyman Moghadam"],"pdf_url":"https://arxiv.org/pdf/2410.06614v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20092v2","updated":"2025-03-02T08:56:15Z","published":"2025-02-27T13:51:56Z","title":"WalnutData: A UAV Remote Sensing Dataset of Green Walnuts and Model\n  Evaluation","summary":"  The UAV technology is gradually maturing and can provide extremely powerful\nsupport for smart agriculture and precise monitoring. Currently, there is no\ndataset related to green walnuts in the field of agricultural computer vision.\nThus, in order to promote the algorithm design in the field of agricultural\ncomputer vision, we used UAV to collect remote-sensing data from 8 walnut\nsample plots. Considering that green walnuts are subject to various lighting\nconditions and occlusion, we constructed a large-scale dataset with a\nhigher-granularity of target features - WalnutData. This dataset contains a\ntotal of 30,240 images and 706,208 instances, and there are 4 target\ncategories: being illuminated by frontal light and unoccluded (A1), being\nbacklit and unoccluded (A2), being illuminated by frontal light and occluded\n(B1), and being backlit and occluded (B2). Subsequently, we evaluated many\nmainstream algorithms on WalnutData and used these evaluation results as the\nbaseline standard. The dataset and all evaluation results can be obtained at\nhttps://github.com/1wuming/WalnutData.\n","authors":["Mingjie Wu","Chenggui Yang","Huihua Wang","Chen Xue","Yibo Wang","Haoyu Wang","Yansong Wang","Can Peng","Yuqi Han","Ruoyu Li","Lijun Yun","Zaiqing Chen","Songfan Shi","Luhao Fang","Shuyi Wan","Tingfeng Li","Shuangyao Liu","Haotian Feng"],"pdf_url":"https://arxiv.org/pdf/2502.20092v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.14808v2","updated":"2025-03-02T08:53:47Z","published":"2024-11-22T09:08:58Z","title":"High-Resolution Image Synthesis via Next-Token Prediction","summary":"  Recently, autoregressive models have demonstrated remarkable performance in\nclass-conditional image generation. However, the application of next-token\nprediction to high-resolution text-to-image generation remains largely\nunexplored. In this paper, we introduce \\textbf{D-JEPA$\\cdot$T2I}, an\nautoregressive model based on continuous tokens that incorporates innovations\nin both architecture and training strategy to generate high-quality,\nphotorealistic images at arbitrary resolutions, up to 4K. Architecturally, we\nadopt the denoising joint embedding predictive architecture (D-JEPA) while\nleveraging a multimodal visual transformer to effectively integrate textual and\nvisual features. Additionally, we introduce flow matching loss alongside the\nproposed Visual Rotary Positional Embedding (VoPE) to enable continuous\nresolution learning. In terms of training strategy, we propose a data feedback\nmechanism that dynamically adjusts the sampling procedure based on statistical\nanalysis and an online learning critic model. This encourages the model to move\nbeyond its comfort zone, reducing redundant training on well-mastered scenarios\nand compelling it to address more challenging cases with suboptimal generation\nquality. For the first time, we achieve state-of-the-art high-resolution image\nsynthesis via next-token prediction.\n","authors":["Dengsheng Chen","Jie Hu","Tiezhu Yue","Xiaoming Wei","Enhua Wu"],"pdf_url":"https://arxiv.org/pdf/2411.14808v2.pdf","comment":"31 pages"},{"id":"http://arxiv.org/abs/2411.03990v2","updated":"2025-03-02T08:11:34Z","published":"2024-11-06T15:30:42Z","title":"ET-SEED: Efficient Trajectory-Level SE(3) Equivariant Diffusion Policy","summary":"  Imitation learning, e.g., diffusion policy, has been proven effective in\nvarious robotic manipulation tasks. However, extensive demonstrations are\nrequired for policy robustness and generalization. To reduce the demonstration\nreliance, we leverage spatial symmetry and propose ET-SEED, an efficient\ntrajectory-level SE(3) equivariant diffusion model for generating action\nsequences in complex robot manipulation tasks. Further, previous equivariant\ndiffusion models require the per-step equivariance in the Markov process,\nmaking it difficult to learn policy under such strong constraints. We\ntheoretically extend equivariant Markov kernels and simplify the condition of\nequivariant diffusion process, thereby significantly improving training\nefficiency for trajectory-level SE(3) equivariant diffusion policy in an\nend-to-end manner. We evaluate ET-SEED on representative robotic manipulation\ntasks, involving rigid body, articulated and deformable object. Experiments\ndemonstrate superior data efficiency and manipulation proficiency of our\nproposed method, as well as its ability to generalize to unseen configurations\nwith only a few demonstrations. Website: https://et-seed.github.io/\n","authors":["Chenrui Tie","Yue Chen","Ruihai Wu","Boxuan Dong","Zeyi Li","Chongkai Gao","Hao Dong"],"pdf_url":"https://arxiv.org/pdf/2411.03990v2.pdf","comment":"Accept to ICLR 2025"},{"id":"http://arxiv.org/abs/2412.14169v2","updated":"2025-03-02T08:09:39Z","published":"2024-12-18T18:59:53Z","title":"Autoregressive Video Generation without Vector Quantization","summary":"  This paper presents a novel approach that enables autoregressive video\ngeneration with high efficiency. We propose to reformulate the video generation\nproblem as a non-quantized autoregressive modeling of temporal frame-by-frame\nprediction and spatial set-by-set prediction. Unlike raster-scan prediction in\nprior autoregressive models or joint distribution modeling of fixed-length\ntokens in diffusion models, our approach maintains the causal property of\nGPT-style models for flexible in-context capabilities, while leveraging\nbidirectional modeling within individual frames for efficiency. With the\nproposed approach, we train a novel video autoregressive model without vector\nquantization, termed NOVA. Our results demonstrate that NOVA surpasses prior\nautoregressive video models in data efficiency, inference speed, visual\nfidelity, and video fluency, even with a much smaller model capacity, i.e.,\n0.6B parameters. NOVA also outperforms state-of-the-art image diffusion models\nin text-to-image generation tasks, with a significantly lower training cost.\nAdditionally, NOVA generalizes well across extended video durations and enables\ndiverse zero-shot applications in one unified model. Code and models are\npublicly available at https://github.com/baaivision/NOVA.\n","authors":["Haoge Deng","Ting Pan","Haiwen Diao","Zhengxiong Luo","Yufeng Cui","Huchuan Lu","Shiguang Shan","Yonggang Qi","Xinlong Wang"],"pdf_url":"https://arxiv.org/pdf/2412.14169v2.pdf","comment":"Accepted to ICLR 2025. Project page at\n  https://github.com/baaivision/NOVA"},{"id":"http://arxiv.org/abs/2404.14396v2","updated":"2025-03-02T07:53:44Z","published":"2024-04-22T17:56:09Z","title":"SEED-X: Multimodal Models with Unified Multi-granularity Comprehension\n  and Generation","summary":"  The rapid evolution of multimodal foundation model has demonstrated\nsignificant progresses in vision-language understanding and generation, e.g.,\nour previous work SEED-LLaMA. However, there remains a gap between its\ncapability and the real-world applicability, primarily due to the model's\nlimited capacity to effectively respond to various user instructions and\ninteract with diverse visual data. In this work, we focus on bridging this gap\nthrough integrating two enhanced features: (1) comprehending images of\narbitrary sizes and ratios, and (2) enabling multi-granularity image\ngeneration. We present a unified and versatile foundation model, namely,\nSEED-X, which is able to model multi-granularity visual semantics for\ncomprehension and generation tasks. Besides the competitive results on public\nbenchmarks, SEED-X demonstrates its effectiveness in handling real-world\napplications across various domains after instruction tuning. We hope that our\nwork will inspire future research into what can be achieved by versatile\nmultimodal foundation models in real-world applications. The models, codes, and\ndatasets are released in https://github.com/AILab-CVC/SEED-X.\n","authors":["Yuying Ge","Sijie Zhao","Jinguo Zhu","Yixiao Ge","Kun Yi","Lin Song","Chen Li","Xiaohan Ding","Ying Shan"],"pdf_url":"https://arxiv.org/pdf/2404.14396v2.pdf","comment":"We added benchmark results (without updating models) and ablation\n  study in this version. Project released at:\n  https://github.com/AILab-CVC/SEED-X"},{"id":"http://arxiv.org/abs/2405.20986v2","updated":"2025-03-02T07:46:05Z","published":"2024-05-31T16:32:46Z","title":"Predictive Uncertainty Quantification for Bird's Eye View Segmentation:\n  A Benchmark and Novel Loss Function","summary":"  The fusion of raw sensor data to create a Bird's Eye View (BEV)\nrepresentation is critical for autonomous vehicle planning and control. Despite\nthe growing interest in using deep learning models for BEV semantic\nsegmentation, anticipating segmentation errors and enhancing the explainability\nof these models remain underexplored. This paper introduces a comprehensive\nbenchmark for predictive uncertainty quantification in BEV segmentation,\nevaluating multiple uncertainty quantification methods across three popular\ndatasets with three representative network architectures. Our study focuses on\nthe effectiveness of quantified uncertainty in detecting misclassified and\nout-of-distribution (OOD) pixels while also improving model calibration.\nThrough empirical analysis, we uncover challenges in existing uncertainty\nquantification methods and demonstrate the potential of evidential deep\nlearning techniques, which capture both aleatoric and epistemic uncertainty. To\naddress these challenges, we propose a novel loss function,\nUncertainty-Focal-Cross-Entropy (UFCE), specifically designed for highly\nimbalanced data, along with a simple uncertainty-scaling regularization term\nthat improves both uncertainty quantification and model calibration for BEV\nsegmentation.\n","authors":["Linlin Yu","Bowen Yang","Tianhao Wang","Kangshuo Li","Feng Chen"],"pdf_url":"https://arxiv.org/pdf/2405.20986v2.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2410.03355v3","updated":"2025-03-02T07:45:09Z","published":"2024-10-04T12:21:03Z","title":"LANTERN: Accelerating Visual Autoregressive Models with Relaxed\n  Speculative Decoding","summary":"  Auto-Regressive (AR) models have recently gained prominence in image\ngeneration, often matching or even surpassing the performance of diffusion\nmodels. However, one major limitation of AR models is their sequential nature,\nwhich processes tokens one at a time, slowing down generation compared to\nmodels like GANs or diffusion-based methods that operate more efficiently.\nWhile speculative decoding has proven effective for accelerating LLMs by\ngenerating multiple tokens in a single forward, its application in visual AR\nmodels remains largely unexplored. In this work, we identify a challenge in\nthis setting, which we term \\textit{token selection ambiguity}, wherein visual\nAR models frequently assign uniformly low probabilities to tokens, hampering\nthe performance of speculative decoding. To overcome this challenge, we propose\na relaxed acceptance condition referred to as LANTERN that leverages the\ninterchangeability of tokens in latent space. This relaxation restores the\neffectiveness of speculative decoding in visual AR models by enabling more\nflexible use of candidate tokens that would otherwise be prematurely rejected.\nFurthermore, by incorporating a total variation distance bound, we ensure that\nthese speed gains are achieved without significantly compromising image quality\nor semantic coherence. Experimental results demonstrate the efficacy of our\nmethod in providing a substantial speed-up over speculative decoding. In\nspecific, compared to a na\\\"ive application of the state-of-the-art speculative\ndecoding, LANTERN increases speed-ups by $\\mathbf{1.75}\\times$ and\n$\\mathbf{1.82}\\times$, as compared to greedy decoding and random sampling,\nrespectively, when applied to LlamaGen, a contemporary visual AR model. The\ncode is publicly available at https://github.com/jadohu/LANTERN.\n","authors":["Doohyuk Jang","Sihwan Park","June Yong Yang","Yeonsung Jung","Jihun Yun","Souvik Kundu","Sung-Yub Kim","Eunho Yang"],"pdf_url":"https://arxiv.org/pdf/2410.03355v3.pdf","comment":"30 pages, 13 figures, Accepted to ICLR 2025 (poster)"},{"id":"http://arxiv.org/abs/2410.10010v3","updated":"2025-03-02T07:42:20Z","published":"2024-10-13T21:11:04Z","title":"InterMask: 3D Human Interaction Generation via Collaborative Masked\n  Modeling","summary":"  Generating realistic 3D human-human interactions from textual descriptions\nremains a challenging task. Existing approaches, typically based on diffusion\nmodels, often produce results lacking realism and fidelity. In this work, we\nintroduce InterMask, a novel framework for generating human interactions using\ncollaborative masked modeling in discrete space. InterMask first employs a\nVQ-VAE to transform each motion sequence into a 2D discrete motion token map.\nUnlike traditional 1D VQ token maps, it better preserves fine-grained\nspatio-temporal details and promotes spatial awareness within each token.\nBuilding on this representation, InterMask utilizes a generative masked\nmodeling framework to collaboratively model the tokens of two interacting\nindividuals. This is achieved by employing a transformer architecture\nspecifically designed to capture complex spatio-temporal inter-dependencies.\nDuring training, it randomly masks the motion tokens of both individuals and\nlearns to predict them. For inference, starting from fully masked sequences, it\nprogressively fills in the tokens for both individuals. With its enhanced\nmotion representation, dedicated architecture, and effective learning strategy,\nInterMask achieves state-of-the-art results, producing high-fidelity and\ndiverse human interactions. It outperforms previous methods, achieving an FID\nof $5.154$ (vs $5.535$ of in2IN) on the InterHuman dataset and $0.399$ (vs\n$5.207$ of InterGen) on the InterX dataset. Additionally, InterMask seamlessly\nsupports reaction generation without the need for model redesign or\nfine-tuning.\n","authors":["Muhammad Gohar Javed","Chuan Guo","Li Cheng","Xingyu Li"],"pdf_url":"https://arxiv.org/pdf/2410.10010v3.pdf","comment":"Project webpage: https://gohar-malik.github.io/intermask"},{"id":"http://arxiv.org/abs/2409.19835v2","updated":"2025-03-02T07:32:50Z","published":"2024-09-30T00:17:00Z","title":"MoCoLSK: Modality Conditioned High-Resolution Downscaling for Land\n  Surface Temperature","summary":"  Land Surface Temperature (LST) is a critical parameter for environmental\nstudies, but directly obtaining high spatial resolution LST data remains\nchallenging due to the spatio-temporal trade-off in satellite remote sensing.\nGuided LST downscaling has emerged as an alternative solution to overcome these\nlimitations, but current methods often neglect spatial non-stationarity, and\nthere is a lack of an open-source ecosystem for deep learning methods. In this\npaper, we propose the Modality-Conditional Large Selective Kernel (MoCoLSK)\nNetwork, a novel architecture that dynamically fuses multi-modal data through\nmodality-conditioned projections. MoCoLSK achieves a confluence of dynamic\nreceptive field adjustment and multi-modal feature fusion, leading to enhanced\nLST prediction accuracy. Furthermore, we establish the GrokLST project, a\ncomprehensive open-source ecosystem featuring the GrokLST dataset, a\nhigh-resolution benchmark, and the GrokLST toolkit, an open-source\nPyTorch-based toolkit encapsulating MoCoLSK alongside 40+ state-of-the-art\napproaches. Extensive experimental results validate MoCoLSK's effectiveness in\ncapturing complex dependencies and subtle variations within multispectral data,\noutperforming existing methods in LST downscaling. Our code, dataset, and\ntoolkit are available at https://github.com/GrokCV/GrokLST.\n","authors":["Qun Dai","Chunyang Yuan","Yimian Dai","Yuxuan Li","Xiang Li","Kang Ni","Jianhui Xu","Xiangbo Shu","Jian Yang"],"pdf_url":"https://arxiv.org/pdf/2409.19835v2.pdf","comment":"Accepted by IEEE TGRS"},{"id":"http://arxiv.org/abs/2502.10982v3","updated":"2025-03-02T07:31:57Z","published":"2025-02-16T04:00:06Z","title":"TEASER: Token Enhanced Spatial Modeling for Expressions Reconstruction","summary":"  3D facial reconstruction from a single in-the-wild image is a crucial task in\nhuman-centered computer vision tasks. While existing methods can recover\naccurate facial shapes, there remains significant space for improvement in\nfine-grained expression capture. Current approaches struggle with irregular\nmouth shapes, exaggerated expressions, and asymmetrical facial movements. We\npresent TEASER (Token EnhAnced Spatial modeling for Expressions\nReconstruction), which addresses these challenges and enhances 3D facial\ngeometry performance. TEASER tackles two main limitations of existing methods:\ninsufficient photometric loss for self-reconstruction and inaccurate\nlocalization of subtle expressions. We introduce a multi-scale tokenizer to\nextract facial appearance information. Combined with a neural renderer, these\ntokens provide precise geometric guidance for expression reconstruction.\nFurthermore, TEASER incorporates a pose-dependent landmark loss to further\nimprove geometric performances. Our approach not only significantly enhances\nexpression reconstruction quality but also offers interpretable tokens suitable\nfor various downstream applications, such as photorealistic facial video\ndriving, expression transfer, and identity swapping. Quantitative and\nqualitative experimental results across multiple datasets demonstrate that\nTEASER achieves state-of-the-art performance in precise expression\nreconstruction.\n","authors":["Yunfei Liu","Lei Zhu","Lijian Lin","Ye Zhu","Ailing Zhang","Yu Li"],"pdf_url":"https://arxiv.org/pdf/2502.10982v3.pdf","comment":"Accepted by ICLR 2025, code and demos are available at\n  https://tinyurl.com/TEASER-project"},{"id":"http://arxiv.org/abs/2501.19069v2","updated":"2025-03-02T07:22:57Z","published":"2025-01-31T11:55:17Z","title":"Improving vision-language alignment with graph spiking hybrid Networks","summary":"  To bridge the semantic gap between vision and language (VL), it is necessary\nto develop a good alignment strategy, which includes handling semantic\ndiversity, abstract representation of visual information, and generalization\nability of models. Recent works use detector-based bounding boxes or patches\nwith regular partitions to represent visual semantics. While current paradigms\nhave made strides, they are still insufficient for fully capturing the nuanced\ncontextual relations among various objects. This paper proposes a comprehensive\nvisual semantic representation module, necessitating the utilization of\npanoptic segmentation to generate coherent fine-grained semantic features.\nFurthermore, we propose a novel Graph Spiking Hybrid Network (GSHN) that\nintegrates the complementary advantages of Spiking Neural Networks (SNNs) and\nGraph Attention Networks (GATs) to encode visual semantic information.\nIntriguingly, the model not only encodes the discrete and continuous latent\nvariables of instances but also adeptly captures both local and global\ncontextual features, thereby significantly enhancing the richness and diversity\nof semantic representations. Leveraging the spatiotemporal properties inherent\nin SNNs, we employ contrastive learning (CL) to enhance the similarity-based\nrepresentation of embeddings. This strategy alleviates the computational\noverhead of the model and enriches meaningful visual representations by\nconstructing positive and negative sample pairs. We design an innovative\npre-training method, Spiked Text Learning (STL), which uses text features to\nimprove the encoding ability of discrete semantics. Experiments show that the\nproposed GSHN exhibits promising results on multiple VL downstream tasks.\n","authors":["Siyu Zhang","Wenzhe Liu","Yeming Chen","Yiming Wu","Heming Zheng","Cheng Cheng"],"pdf_url":"https://arxiv.org/pdf/2501.19069v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.11817v2","updated":"2025-03-02T07:05:19Z","published":"2024-10-15T17:46:31Z","title":"Improving Long-Text Alignment for Text-to-Image Diffusion Models","summary":"  The rapid advancement of text-to-image (T2I) diffusion models has enabled\nthem to generate unprecedented results from given texts. However, as text\ninputs become longer, existing encoding methods like CLIP face limitations, and\naligning the generated images with long texts becomes challenging. To tackle\nthese issues, we propose LongAlign, which includes a segment-level encoding\nmethod for processing long texts and a decomposed preference optimization\nmethod for effective alignment training. For segment-level encoding, long texts\nare divided into multiple segments and processed separately. This method\novercomes the maximum input length limits of pretrained encoding models. For\npreference optimization, we provide decomposed CLIP-based preference models to\nfine-tune diffusion models. Specifically, to utilize CLIP-based preference\nmodels for T2I alignment, we delve into their scoring mechanisms and find that\nthe preference scores can be decomposed into two components: a text-relevant\npart that measures T2I alignment and a text-irrelevant part that assesses other\nvisual aspects of human preference. Additionally, we find that the\ntext-irrelevant part contributes to a common overfitting problem during\nfine-tuning. To address this, we propose a reweighting strategy that assigns\ndifferent weights to these two components, thereby reducing overfitting and\nenhancing alignment. After fine-tuning $512 \\times 512$ Stable Diffusion (SD)\nv1.5 for about 20 hours using our method, the fine-tuned SD outperforms\nstronger foundation models in T2I alignment, such as PixArt-$\\alpha$ and\nKandinsky v2.2. The code is available at\nhttps://github.com/luping-liu/LongAlign.\n","authors":["Luping Liu","Chao Du","Tianyu Pang","Zehan Wang","Chongxuan Li","Dong Xu"],"pdf_url":"https://arxiv.org/pdf/2410.11817v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.03836v3","updated":"2025-03-02T06:41:56Z","published":"2025-01-07T14:45:39Z","title":"SCC-YOLO: An Improved Object Detector for Assisting in Brain Tumor\n  Diagnosis","summary":"  Brain tumors can lead to neurological dysfunction, cognitive and\npsychological changes, increased intracranial pressure, and seizures, posing\nsignificant risks to health. The You Only Look Once (YOLO) series has shown\nsuperior accuracy in medical imaging object detection. This paper presents a\nnovel SCC-YOLO architecture that integrates the SCConv module into YOLOv9. The\nSCConv module optimizes convolutional efficiency by reducing spatial and\nchannel redundancy, enhancing image feature learning. We examine the effects of\ndifferent attention mechanisms with YOLOv9 for brain tumor detection using the\nBr35H dataset and our custom dataset (Brain_Tumor_Dataset). Results indicate\nthat SCC-YOLO improved mAP50 by 0.3% on the Br35H dataset and by 0.5% on our\ncustom dataset compared to YOLOv9. SCC-YOLO achieves state-of-the-art\nperformance in brain tumor detection.\n","authors":["Runci Bai","Guibao Xu","Yanze Shi"],"pdf_url":"https://arxiv.org/pdf/2501.03836v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.03173v2","updated":"2025-03-02T06:24:05Z","published":"2024-12-04T09:53:09Z","title":"IRisPath: Enhancing Costmap for Off-Road Navigation with Robust IR-RGB\n  Fusion for Improved Day and Night Traversability","summary":"  Autonomous off-road navigation is required for applications in agriculture,\nconstruction, search and rescue and defence. Traditional on-road autonomous\nmethods struggle with dynamic terrains, leading to poor vehicle control in\noff-road conditions. Recent deep-learning models have used perception sensors\nalong with kinesthetic feedback for navigation on such terrains. However, this\napproach has out-of-domain uncertainty. Factors like change in time of day and\nweather impacts the performance of the model. We propose a multi modal fusion\nnetwork \"IRisPath\" capable of using Thermal and RGB images to provide\nrobustness against dynamic weather and light conditions. To aid further works\nin this domain, we also open-source a day-night dataset with Thermal and RGB\nimages along with pseudo-labels for traversability. In order to co-register for\nfusion model we also develop a novel method for targetless extrinsic\ncalibration of Thermal, LiDAR and RGB cameras with translation accuracy of\n+/-1.7cm and rotation accuracy of +/-0.827degrees.\n","authors":["Saksham Sharma","Akshit Raizada","Suresh Sundaram"],"pdf_url":"https://arxiv.org/pdf/2412.03173v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.12033v2","updated":"2025-03-02T06:19:58Z","published":"2023-06-21T05:48:51Z","title":"End-to-End Augmentation Hyperparameter Tuning for Self-Supervised\n  Anomaly Detection","summary":"  Self-supervised learning (SSL) has emerged as a promising paradigm that\npresents supervisory signals to real-world problems, bypassing the extensive\ncost of manual labeling. Consequently, self-supervised anomaly detection (SSAD)\nhas seen a recent surge of interest, since SSL is especially attractive for\nunsupervised tasks. However, recent works have reported that the choice of a\ndata augmentation function has significant impact on the accuracy of SSAD,\nposing augmentation search as an essential but nontrivial problem with the lack\nof labeled validation data. In this paper, we introduce ST-SSAD, the first\nsystematic approach for rigorous augmentation tuning on SSAD. To this end, our\nwork presents two key contributions. The first is a new unsupervised validation\nloss that quantifies the alignment between augmented training data and\nunlabeled validation data. The second is new differentiable augmentation\nfunctions, allowing data augmentation hyperparameter(s) to be tuned in an\nend-to-end manner. Experiments on two testbeds with semantic class anomalies\nand subtle industrial defects show that ST-SSAD gives significant performance\ngains over existing works.\n","authors":["Jaemin Yoo","Lingxiao Zhao","Leman Akoglu"],"pdf_url":"https://arxiv.org/pdf/2306.12033v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03051v3","updated":"2025-03-02T06:17:12Z","published":"2024-10-04T00:13:54Z","title":"AuroraCap: Efficient, Performant Video Detailed Captioning and a New\n  Benchmark","summary":"  Video detailed captioning is a key task which aims to generate comprehensive\nand coherent textual descriptions of video content, benefiting both video\nunderstanding and generation. In this paper, we propose AuroraCap, a video\ncaptioner based on a large multimodal model. We follow the simplest\narchitecture design without additional parameters for temporal modeling. To\naddress the overhead caused by lengthy video sequences, we implement the token\nmerging strategy, reducing the number of input visual tokens. Surprisingly, we\nfound that this strategy results in little performance loss. AuroraCap shows\nsuperior performance on various video and image captioning benchmarks, for\nexample, obtaining a CIDEr of 88.9 on Flickr30k, beating GPT-4V (55.3) and\nGemini-1.5 Pro (82.2). However, existing video caption benchmarks only include\nsimple descriptions, consisting of a few dozen words, which limits research in\nthis field. Therefore, we develop VDC, a video detailed captioning benchmark\nwith over one thousand carefully annotated structured captions. In addition, we\npropose a new LLM-assisted metric VDCscore for bettering evaluation, which\nadopts a divide-and-conquer strategy to transform long caption evaluation into\nmultiple short question-answer pairs. With the help of human Elo ranking, our\nexperiments show that this benchmark better correlates with human judgments of\nvideo detailed captioning quality.\n","authors":["Wenhao Chai","Enxin Song","Yilun Du","Chenlin Meng","Vashisht Madhavan","Omer Bar-Tal","Jenq-Neng Hwang","Saining Xie","Christopher D. Manning"],"pdf_url":"https://arxiv.org/pdf/2410.03051v3.pdf","comment":"Accepted to ICLR 2025. Code, docs, weight, benchmark and training\n  data are all avaliable at https://rese1f.github.io/aurora-web/"},{"id":"http://arxiv.org/abs/2502.19260v2","updated":"2025-03-02T06:08:34Z","published":"2025-02-26T16:06:35Z","title":"EMT: A Visual Multi-Task Benchmark Dataset for Autonomous Driving in the\n  Arab Gulf Region","summary":"  This paper introduces the Emirates Multi-Task (EMT) dataset - the first\npublicly available dataset for autonomous driving collected in the Arab Gulf\nregion. The EMT dataset captures the unique road topology, high traffic\ncongestion, and distinctive characteristics of the Gulf region, including\nvariations in pedestrian clothing and weather conditions. It contains over\n30,000 frames from a dash-camera perspective, along with 570,000 annotated\nbounding boxes, covering approximately 150 kilometers of driving routes. The\nEMT dataset supports three primary tasks: tracking, trajectory forecasting and\nintention prediction. Each benchmark dataset is complemented with corresponding\nevaluations: (1) multi-agent tracking experiments, focusing on multi-class\nscenarios and occlusion handling; (2) trajectory forecasting evaluation using\ndeep sequential and interaction-aware models; and (3) intention benchmark\nexperiments conducted for predicting agents intentions from observed\ntrajectories. The dataset is publicly available at avlab.io/emt-dataset, and\npre-processing scripts along with evaluation models can be accessed at\ngithub.com/AV-Lab/emt-dataset.\n","authors":["Nadya Abdel Madjid","Murad Mebrahtu","Abdelmoamen Nasser","Bilal Hassan","Naoufel Werghi","Jorge Dias","Majid Khonji"],"pdf_url":"https://arxiv.org/pdf/2502.19260v2.pdf","comment":"19 pages, 6 figures"},{"id":"http://arxiv.org/abs/2502.08813v2","updated":"2025-03-02T05:50:08Z","published":"2025-02-12T21:55:26Z","title":"Measuring Anxiety Levels with Head Motion Patterns in Severe Depression\n  Population","summary":"  Depression and anxiety are prevalent mental health disorders that frequently\ncooccur, with anxiety significantly influencing both the manifestation and\ntreatment of depression. An accurate assessment of anxiety levels in\nindividuals with depression is crucial to develop effective and personalized\ntreatment plans. This study proposes a new noninvasive method for quantifying\nanxiety severity by analyzing head movements -- specifically speed,\nacceleration, and angular displacement -- during video-recorded interviews with\npatients suffering from severe depression. Using data from a new CALYPSO\nDepression Dataset, we extracted head motion characteristics and applied\nregression analysis to predict clinically evaluated anxiety levels. Our results\ndemonstrate a high level of precision, achieving a mean absolute error (MAE) of\n0.35 in predicting the severity of psychological anxiety based on head movement\npatterns. This indicates that our approach can enhance the understanding of\nanxiety's role in depression and assist psychiatrists in refining treatment\nstrategies for individuals.\n","authors":["Fouad Boutaleb","Emery Pierson","Nicolas Doudeau","Clémence Nineuil","Ali Amad","Mohamed Daoudi"],"pdf_url":"https://arxiv.org/pdf/2502.08813v2.pdf","comment":"19th IEEE International Conference on Automatic Face and Gesture\n  Recognition (FG), 2025"},{"id":"http://arxiv.org/abs/2411.01099v2","updated":"2025-03-02T05:33:33Z","published":"2024-11-02T01:31:47Z","title":"Few-Class Arena: A Benchmark for Efficient Selection of Vision Models\n  and Dataset Difficulty Measurement","summary":"  We propose Few-Class Arena (FCA), as a unified benchmark with focus on\ntesting efficient image classification models for few classes. A wide variety\nof benchmark datasets with many classes (80-1000) have been created to assist\nComputer Vision architectural evolution. An increasing number of vision models\nare evaluated with these many-class datasets. However, real-world applications\noften involve substantially fewer classes of interest (2-10). This gap between\nmany and few classes makes it difficult to predict performance of the few-class\napplications using models trained on the available many-class datasets. To\ndate, little has been offered to evaluate models in this Few-Class Regime. We\nconduct a systematic evaluation of the ResNet family trained on ImageNet\nsubsets from 2 to 1000 classes, and test a wide spectrum of Convolutional\nNeural Networks and Transformer architectures over ten datasets by using our\nnewly proposed FCA tool. Furthermore, to aid an up-front assessment of dataset\ndifficulty and a more efficient selection of models, we incorporate a\ndifficulty measure as a function of class similarity. FCA offers a new tool for\nefficient machine learning in the Few-Class Regime, with goals ranging from a\nnew efficient class similarity proposal, to lightweight model architecture\ndesign, to a new scaling law. FCA is user-friendly and can be easily extended\nto new models and datasets, facilitating future research work. Our benchmark is\navailable at https://github.com/bryanbocao/fca.\n","authors":["Bryan Bo Cao","Lawrence O'Gorman","Michael Coss","Shubham Jain"],"pdf_url":"https://arxiv.org/pdf/2411.01099v2.pdf","comment":"10 pages, 32 pages including References and Appendix, 19 figures, 8\n  tables"},{"id":"http://arxiv.org/abs/2410.03816v2","updated":"2025-03-02T05:29:42Z","published":"2024-10-04T18:47:49Z","title":"Modeling and Analysis of Spatial and Temporal Land Clutter Statistics in\n  SAR Imaging Based on MSTAR Data","summary":"  The statistical analysis of land clutter for Synthetic Aperture Radar (SAR)\nimaging has become an increasingly important subject for research and\ninvestigation. It is also absolutely necessary for designing robust algorithms\ncapable of performing the task of target detection in the background clutter.\nAny attempt to extract the energy of the desired targets from the land clutter\nrequires complete knowledge of the statistical properties of the background\nclutter. In this paper, the spatial as well as the temporal characteristics of\nthe land clutter are studied. Since the data for each image has been collected\nbased on a different aspect angle; therefore, the temporal analysis contains\nvariation in the aspect angle. Consequently, the temporal analysis includes the\ncharacteristics of the radar cross section with respect to the aspect angle\nbased on which the data has been collected. In order to perform the statistical\nanalysis, several well-known and relevant distributions, namely, Weibull,\nLog-normal, Gamma, and Rayleigh are considered as prime candidates to model the\nland clutter. The goodness-of-fit test is based on the Kullback-Leibler (KL)\nDivergence metric. The detailed analysis presented in this paper demonstrates\nthat the Weibull distribution is a more accurate fit for the\ntemporal-aspect-angle statistical analysis while the Rayleigh distribution\nmodels the spatial characteristics of the background clutter with higher\naccuracy. Finally, based on the aforementioned statistical analyses and by\nutilizing the Constant False Alarm Rate (CFAR) algorithm, we perform target\ndetection in land clutter. The overall verification of the analysis is\nperformed by exploiting the Moving and Stationary Target Acquisition and\nRecognition (MSTAR) data-set, which has been collected in spotlight mode at\nX-band, and the results are presented.\n","authors":["Shahrokh Hamidi"],"pdf_url":"https://arxiv.org/pdf/2410.03816v2.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2409.02155"},{"id":"http://arxiv.org/abs/2408.08258v3","updated":"2025-03-02T04:25:12Z","published":"2024-08-15T16:59:15Z","title":"Snuffy: Efficient Whole Slide Image Classifier","summary":"  Whole Slide Image (WSI) classification with multiple instance learning (MIL)\nin digital pathology faces significant computational challenges. Current\nmethods mostly rely on extensive self-supervised learning (SSL) for\nsatisfactory performance, requiring long training periods and considerable\ncomputational resources. At the same time, no pre-training affects performance\ndue to domain shifts from natural images to WSIs. We introduce Snuffy\narchitecture, a novel MIL-pooling method based on sparse transformers that\nmitigates performance loss with limited pre-training and enables continual\nfew-shot pre-training as a competitive option. Our sparsity pattern is tailored\nfor pathology and is theoretically proven to be a universal approximator with\nthe tightest probabilistic sharp bound on the number of layers for sparse\ntransformers, to date. We demonstrate Snuffy's effectiveness on CAMELYON16 and\nTCGA Lung cancer datasets, achieving superior WSI and patch-level accuracies.\nThe code is available on https://github.com/jafarinia/snuffy.\n","authors":["Hossein Jafarinia","Alireza Alipanah","Danial Hamdi","Saeed Razavi","Nahal Mirzaie","Mohammad Hossein Rohban"],"pdf_url":"https://arxiv.org/pdf/2408.08258v3.pdf","comment":"Accepted for ECCV 2024"},{"id":"http://arxiv.org/abs/2405.16071v2","updated":"2025-03-02T04:18:55Z","published":"2024-05-25T05:44:55Z","title":"DynRefer: Delving into Region-level Multimodal Tasks via Dynamic\n  Resolution","summary":"  One fundamental task of multimodal models is to translate referred image\nregions to human preferred language descriptions. Existing methods, however,\nignore the resolution adaptability needs of different tasks, which hinders them\nto find out precise language descriptions. In this study, we propose a DynRefer\napproach, to pursue high-accuracy region-level referring through mimicking the\nresolution adaptability of human visual cognition. During training, DynRefer\nstochastically aligns language descriptions of multimodal tasks with images of\nmultiple resolutions, which are constructed by nesting a set of random views\naround the referred region. During inference, DynRefer performs selectively\nmultimodal referring by sampling proper region representations for tasks from\nthe nested views based on image and task priors. This allows the visual\ninformation for referring to better match human preferences, thereby improving\nthe representational adaptability of region-level multimodal models.\nExperiments show that DynRefer brings mutual improvement upon broad tasks\nincluding region-level captioning, open-vocabulary region recognition and\nattribute detection. Furthermore, DynRefer achieves state-of-the-art results on\nmultiple region-level multimodal tasks using a single model. Code is available\nat https://github.com/callsys/DynRefer.\n","authors":["Yuzhong Zhao","Feng Liu","Yue Liu","Mingxiang Liao","Chen Gong","Qixiang Ye","Fang Wan"],"pdf_url":"https://arxiv.org/pdf/2405.16071v2.pdf","comment":"Accepted in CVPR 2025. Code is available at\n  https://github.com/callsys/DynRefer"},{"id":"http://arxiv.org/abs/2411.18018v2","updated":"2025-03-02T04:05:24Z","published":"2024-11-27T03:21:57Z","title":"Neural Finite-State Machines for Surgical Phase Recognition","summary":"  Surgical phase recognition (SPR) is crucial for applications in workflow\noptimization, performance evaluation, and real-time intervention guidance.\nHowever, current deep learning models often struggle with fragmented\npredictions, failing to capture the sequential nature of surgical workflows. We\npropose the Neural Finite-State Machine (NFSM), a novel approach that enforces\ntemporal coherence by integrating classical state-transition priors with modern\nneural networks. NFSM leverages learnable global state embeddings as unique\nphase identifiers and dynamic transition tables to model phase-to-phase\nprogressions. Additionally, a future phase forecasting mechanism employs\nrepeated frame padding to anticipate upcoming transitions. Implemented as a\nplug-and-play module, NFSM can be integrated into existing SPR pipelines\nwithout changing their core architectures. We demonstrate state-of-the-art\nperformance across multiple benchmarks, including a significant improvement on\nthe BernBypass70 dataset - raising video-level accuracy by 0.9 points and\nphase-level precision, recall, F1-score, and mAP by 3.8, 3.1, 3.3, and 4.1,\nrespectively. Ablation studies confirm each component's effectiveness and the\nmodule's adaptability to various architectures. By unifying finite-state\nprinciples with deep learning, NFSM offers a robust path toward consistent,\nlong-term surgical video analysis.\n","authors":["Hao Ding","Zhongpai Gao","Benjamin Planche","Tianyu Luan","Abhishek Sharma","Meng Zheng","Ange Lou","Terrence Chen","Mathias Unberath","Ziyan Wu"],"pdf_url":"https://arxiv.org/pdf/2411.18018v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.11069v3","updated":"2025-03-02T03:01:19Z","published":"2025-01-19T15:05:15Z","title":"Refinement Module based on Parse Graph of Feature Map for Human Pose\n  Estimation","summary":"  Parse graphs of the human body can be obtained in the human brain to help\nhumans complete the human Pose Estimation better (HPE). It contains a\nhierarchical structure, like a tree structure, and context relations among\nnodes. To equip models with such capabilities, many researchers predefine the\nparse graph of body structure to design HPE frameworks. However, these\nframeworks struggle to adapt to instances that deviate from the predefined\nparse graph and are often parameter-heavy. Unlike them, we view the feature map\nholistically, much like the human body. It can be optimized using parse graphs,\nwhere each node's feature is an implicit expression rather than a fixed one.\nThis allows it to adapt to more instances, unconstrained by rigid structural\nfeatures. In this paper, we design the Refinement Module based on the Parse\nGraph of feature map (RMPG), which includes two stages: top-down decomposition\nand bottom-up combination. In the first stage, the feature map is decomposed\ninto multiple sub-feature maps along the channel. In the second stage, the\ncontext relations of sub-feature maps are calculated to obtain their respective\ncontext information and the sub-feature maps with context information are\nconcatenated along channels to obtain the refined feature map. Additionally, we\ndesign a hierarchical network with fewer parameters using multiple RMPG modules\nto model the context relations and hierarchies in the parse graph of body\nstructure for HPE, some of which are supervised to obtain context relations\namong body parts. Our network achieves excellent results on multiple mainstream\nhuman pose datasets. More importantly, the effectiveness of RMPG is proven on\ndifferent methods. The code of RMPG will be open.\n","authors":["Shibang Liu","Xuemei Xie","Guangming Shi"],"pdf_url":"https://arxiv.org/pdf/2501.11069v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.20026v2","updated":"2025-03-02T02:45:56Z","published":"2024-10-26T00:49:06Z","title":"Towards Robust Algorithms for Surgical Phase Recognition via Digital\n  Twin Representation","summary":"  Surgical phase recognition (SPR) is an integral component of surgical data\nscience, enabling high-level surgical analysis. End-to-end trained neural\nnetworks that predict surgical phase directly from videos have shown excellent\nperformance on benchmarks. However, these models struggle with robustness due\nto non-causal associations in the training set. Our goal is to improve model\nrobustness to variations in the surgical videos by leveraging the digital twin\n(DT) paradigm -- an intermediary layer to separate high-level analysis (SPR)\nfrom low-level processing. As a proof of concept, we present a DT\nrepresentation-based framework for SPR from videos. The framework employs\nvision foundation models with reliable low-level scene understanding to craft\nDT representation. We embed the DT representation in place of raw video inputs\nin the state-of-the-art SPR model. The framework is trained on the Cholec80\ndataset and evaluated on out-of-distribution (OOD) and corrupted test samples.\nContrary to the vulnerability of the baseline model, our framework demonstrates\nstrong robustness on both OOD and corrupted samples, with a video-level\naccuracy of 80.3 on a highly corrupted Cholec80 test set, 67.9 on the\nchallenging CRCD dataset, and 99.8 on an internal robotic surgery dataset,\noutperforming the baseline by 3.9, 16.8, and 90.9 respectively. We also find\nthat using DT representation as an augmentation to the raw input can\nsignificantly improve model robustness. Our findings lend support to the thesis\nthat DT representations are effective in enhancing model robustness. Future\nwork will seek to improve the feature informativeness and incorporate\ninterpretability for a more comprehensive framework.\n","authors":["Hao Ding","Yuqian Zhang","Wenzheng Cheng","Xinyu Wang","Xu Lian","Chenhao Yu","Hongchao Shu","Ji Woong Kim","Axel Krieger","Mathias Unberath"],"pdf_url":"https://arxiv.org/pdf/2410.20026v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.04364v4","updated":"2025-03-02T02:32:25Z","published":"2024-01-09T05:32:22Z","title":"SoK: Systematization and Benchmarking of Deepfake Detectors in a Unified\n  Framework","summary":"  Deepfakes have rapidly emerged as a serious threat to society due to their\nease of creation and dissemination, triggering the accelerated development of\ndetection technologies. However, many existing detectors rely on labgenerated\ndatasets for validation, which may not prepare them for novel, real-world\ndeepfakes. This paper extensively reviews and analyzes state-of-the-art\ndeepfake detectors, evaluating them against several critical criteria. These\ncriteria categorize detectors into 4 high-level groups and 13 finegrained\nsub-groups, aligned with a unified conceptual framework we propose. This\nclassification offers practical insights into the factors affecting detector\nefficacy. We evaluate the generalizability of 16 leading detectors across\ncomprehensive attack scenarios, including black-box, white-box, and graybox\nsettings. Our systematized analysis and experiments provide a deeper\nunderstanding of deepfake detectors and their generalizability, paving the way\nfor future research and the development of more proactive defenses against\ndeepfakes.\n","authors":["Binh M. Le","Jiwon Kim","Simon S. Woo","Kristen Moore","Alsharif Abuadbba","Shahroz Tariq"],"pdf_url":"https://arxiv.org/pdf/2401.04364v4.pdf","comment":"20 pages, 6 figures, 7 table, Accepted at IEEE European Symposium on\n  security and privacy 2025 (EuroS&P '25)"},{"id":"http://arxiv.org/abs/2410.05470v2","updated":"2025-03-02T02:07:21Z","published":"2024-10-07T20:04:29Z","title":"Image Watermarks are Removable Using Controllable Regeneration from\n  Clean Noise","summary":"  Image watermark techniques provide an effective way to assert ownership,\ndeter misuse, and trace content sources, which has become increasingly\nessential in the era of large generative models. A critical attribute of\nwatermark techniques is their robustness against various manipulations. In this\npaper, we introduce a watermark removal approach capable of effectively\nnullifying state-of-the-art watermarking techniques. Our primary insight\ninvolves regenerating the watermarked image starting from a clean Gaussian\nnoise via a controllable diffusion model, utilizing the extracted semantic and\nspatial features from the watermarked image. The semantic control adapter and\nthe spatial control network are specifically trained to control the denoising\nprocess towards ensuring image quality and enhancing consistency between the\ncleaned image and the original watermarked image. To achieve a smooth trade-off\nbetween watermark removal performance and image consistency, we further propose\nan adjustable and controllable regeneration scheme. This scheme adds varying\nnumbers of noise steps to the latent representation of the watermarked image,\nfollowed by a controlled denoising process starting from this noisy latent\nrepresentation. As the number of noise steps increases, the latent\nrepresentation progressively approaches clean Gaussian noise, facilitating the\ndesired trade-off. We apply our watermark removal methods across various\nwatermarking techniques, and the results demonstrate that our methods offer\nsuperior visual consistency/quality and enhanced watermark removal performance\ncompared to existing regeneration approaches. Our code is available at\nhttps://github.com/yepengliu/CtrlRegen.\n","authors":["Yepeng Liu","Yiren Song","Hai Ci","Yu Zhang","Haofan Wang","Mike Zheng Shou","Yuheng Bu"],"pdf_url":"https://arxiv.org/pdf/2410.05470v2.pdf","comment":"ICLR2025"},{"id":"http://arxiv.org/abs/2502.10603v2","updated":"2025-03-02T01:50:22Z","published":"2025-02-14T23:18:54Z","title":"Adaptive Neural Networks for Intelligent Data-Driven Development","summary":"  Advances in machine learning methods for computer vision tasks have led to\ntheir consideration for safety-critical applications like autonomous driving.\nHowever, effectively integrating these methods into the automotive development\nlifecycle remains challenging. Since the performance of machine learning\nalgorithms relies heavily on the training data provided, the data and model\ndevelopment lifecycle play a key role in successfully integrating these\ncomponents into the product development lifecycle. Existing models frequently\nencounter difficulties recognizing or adapting to novel instances not present\nin the original training dataset. This poses a significant risk for reliable\ndeployment in dynamic environments. To address this challenge, we propose an\nadaptive neural network architecture and an iterative development framework\nthat enables users to efficiently incorporate previously unknown objects into\nthe current perception system. Our approach builds on continuous learning,\nemphasizing the necessity of dynamic updates to reflect real-world deployment\nconditions. Specifically, we introduce a pipeline with three key components:\n(1) a scalable network extension strategy to integrate new classes while\npreserving existing performance, (2) a dynamic OoD detection component that\nrequires no additional retraining for newly added classes, and (3) a\nretrieval-based data augmentation process tailored for safety-critical\ndeployments. The integration of these components establishes a pragmatic and\nadaptive pipeline for the continuous evolution of perception systems in the\ncontext of autonomous driving.\n","authors":["Youssef Shoeb","Azarm Nowzad","Hanno Gottschalk"],"pdf_url":"https://arxiv.org/pdf/2502.10603v2.pdf","comment":"8 pages, 3 figures, and 3 tables"},{"id":"http://arxiv.org/abs/2412.05707v3","updated":"2025-03-02T01:46:15Z","published":"2024-12-07T17:40:20Z","title":"Segment-Level Road Obstacle Detection Using Visual Foundation Model\n  Priors and Likelihood Ratios","summary":"  Detecting road obstacles is essential for autonomous vehicles to navigate\ndynamic and complex traffic environments safely. Current road obstacle\ndetection methods typically assign a score to each pixel and apply a threshold\nto generate final predictions. However, selecting an appropriate threshold is\nchallenging, and the per-pixel classification approach often leads to\nfragmented predictions with numerous false positives. In this work, we propose\na novel method that leverages segment-level features from visual foundation\nmodels and likelihood ratios to predict road obstacles directly. By focusing on\nsegments rather than individual pixels, our approach enhances detection\naccuracy, reduces false positives, and offers increased robustness to scene\nvariability. We benchmark our approach against existing methods on the\nRoadObstacle and LostAndFound datasets, achieving state-of-the-art performance\nwithout needing a predefined threshold.\n","authors":["Youssef Shoeb","Nazir Nayal","Azarm Nowzad","Fatma Güney","Hanno Gottschalk"],"pdf_url":"https://arxiv.org/pdf/2412.05707v3.pdf","comment":"10 pages, 4 figures, and 1 table, to be published in VISAPP 2025"},{"id":"http://arxiv.org/abs/2410.10594v2","updated":"2025-03-02T01:19:51Z","published":"2024-10-14T15:04:18Z","title":"VisRAG: Vision-based Retrieval-augmented Generation on Multi-modality\n  Documents","summary":"  Retrieval-augmented generation (RAG) is an effective technique that enables\nlarge language models (LLMs) to utilize external knowledge sources for\ngeneration. However, current RAG systems are solely based on text, rendering it\nimpossible to utilize vision information like layout and images that play\ncrucial roles in real-world multi-modality documents. In this paper, we\nintroduce VisRAG, which tackles this issue by establishing a vision-language\nmodel (VLM)-based RAG pipeline. In this pipeline, instead of first parsing the\ndocument to obtain text, the document is directly embedded using a VLM as an\nimage and then retrieved to enhance the generation of a VLM. Compared to\ntraditional text-based RAG, VisRAG maximizes the retention and utilization of\nthe data information in the original documents, eliminating the information\nloss introduced during the parsing process. We collect both open-source and\nsynthetic data to train the retriever in VisRAG and explore a variety of\ngeneration methods. Experiments demonstrate that VisRAG outperforms traditional\nRAG in both the retrieval and generation stages, achieving a 20--40% end-to-end\nperformance gain over traditional text-based RAG pipeline. Further analysis\nreveals that VisRAG is efficient in utilizing training data and demonstrates\nstrong generalization capability, positioning it as a promising solution for\nRAG on multi-modality documents. Our code and data are available at\nhttps://github.com/openbmb/visrag.\n","authors":["Shi Yu","Chaoyue Tang","Bokai Xu","Junbo Cui","Junhao Ran","Yukun Yan","Zhenghao Liu","Shuo Wang","Xu Han","Zhiyuan Liu","Maosong Sun"],"pdf_url":"https://arxiv.org/pdf/2410.10594v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.11219v3","updated":"2025-03-02T01:07:41Z","published":"2024-09-17T14:12:50Z","title":"Score Forgetting Distillation: A Swift, Data-Free Method for Machine\n  Unlearning in Diffusion Models","summary":"  The machine learning community is increasingly recognizing the importance of\nfostering trust and safety in modern generative AI (GenAI) models. We posit\nmachine unlearning (MU) as a crucial foundation for developing safe, secure,\nand trustworthy GenAI models. Traditional MU methods often rely on stringent\nassumptions and require access to real data. This paper introduces Score\nForgetting Distillation (SFD), an innovative MU approach that promotes the\nforgetting of undesirable information in diffusion models by aligning the\nconditional scores of \"unsafe\" classes or concepts with those of \"safe\" ones.\nTo eliminate the need for real data, our SFD framework incorporates a\nscore-based MU loss into the score distillation objective of a pretrained\ndiffusion model. This serves as a regularization term that preserves desired\ngeneration capabilities while enabling the production of synthetic data through\na one-step generator. Our experiments on pretrained label-conditional and\ntext-to-image diffusion models demonstrate that our method effectively\naccelerates the forgetting of target classes or concepts during generation,\nwhile preserving the quality of other classes or concepts. This unlearned and\ndistilled diffusion not only pioneers a novel concept in MU but also\naccelerates the generation speed of diffusion models. Our experiments and\nstudies on a range of diffusion models and datasets confirm that our approach\nis generalizable, effective, and advantageous for MU in diffusion models. Code\nis available at https://github.com/tqch/score-forgetting-distillation.\n($\\textbf{Warning:}$ This paper contains sexually explicit imagery, discussions\nof pornography, racially-charged terminology, and other content that some\nreaders may find disturbing, distressing, and/or offensive.)\n","authors":["Tianqi Chen","Shujian Zhang","Mingyuan Zhou"],"pdf_url":"https://arxiv.org/pdf/2409.11219v3.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2502.02283v3","updated":"2025-03-02T00:25:45Z","published":"2025-02-04T12:50:16Z","title":"GP-GS: Gaussian Processes for Enhanced Gaussian Splatting","summary":"  3D Gaussian Splatting has emerged as an efficient photorealistic novel view\nsynthesis method. However, its reliance on sparse Structure-from-Motion (SfM)\npoint clouds consistently compromises the scene reconstruction quality. To\naddress these limitations, this paper proposes a novel 3D reconstruction\nframework Gaussian Processes Gaussian Splatting (GP-GS), where a multi-output\nGaussian Process model is developed to achieve adaptive and uncertainty-guided\ndensification of sparse SfM point clouds. Specifically, we propose a dynamic\nsampling and filtering pipeline that adaptively expands the SfM point clouds by\nleveraging GP-based predictions to infer new candidate points from the input 2D\npixels and depth maps. The pipeline utilizes uncertainty estimates to guide the\npruning of high-variance predictions, ensuring geometric consistency and\nenabling the generation of dense point clouds. The densified point clouds\nprovide high-quality initial 3D Gaussians to enhance reconstruction\nperformance. Extensive experiments conducted on synthetic and real-world\ndatasets across various scales validate the effectiveness and practicality of\nthe proposed framework.\n","authors":["Zhihao Guo","Jingxuan Su","Shenglin Wang","Jinlong Fan","Jing Zhang","Liangxiu Han","Peng Wang"],"pdf_url":"https://arxiv.org/pdf/2502.02283v3.pdf","comment":"14 pages,11 figures"},{"id":"http://arxiv.org/abs/2411.18810v4","updated":"2025-03-02T00:15:11Z","published":"2024-11-27T23:32:54Z","title":"All Seeds Are Not Equal: Enhancing Compositional Text-to-Image\n  Generation with Reliable Random Seeds","summary":"  Text-to-image diffusion models have demonstrated remarkable capability in\ngenerating realistic images from arbitrary text prompts. However, they often\nproduce inconsistent results for compositional prompts such as \"two dogs\" or \"a\npenguin on the right of a bowl\". Understanding these inconsistencies is crucial\nfor reliable image generation. In this paper, we highlight the significant role\nof initial noise in these inconsistencies, where certain noise patterns are\nmore reliable for compositional prompts than others. Our analyses reveal that\ndifferent initial random seeds tend to guide the model to place objects in\ndistinct image areas, potentially adhering to specific patterns of camera\nangles and image composition associated with the seed. To improve the model's\ncompositional ability, we propose a method for mining these reliable cases,\nresulting in a curated training set of generated images without requiring any\nmanual annotation. By fine-tuning text-to-image models on these generated\nimages, we significantly enhance their compositional capabilities. For\nnumerical composition, we observe relative increases of 29.3% and 19.5% for\nStable Diffusion and PixArt-{\\alpha}, respectively. Spatial composition sees\neven larger gains, with 60.7% for Stable Diffusion and 21.1% for\nPixArt-{\\alpha}.\n","authors":["Shuangqi Li","Hieu Le","Jingyi Xu","Mathieu Salzmann"],"pdf_url":"https://arxiv.org/pdf/2411.18810v4.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2410.10594v2","updated":"2025-03-02T01:19:51Z","published":"2024-10-14T15:04:18Z","title":"VisRAG: Vision-based Retrieval-augmented Generation on Multi-modality\n  Documents","summary":"  Retrieval-augmented generation (RAG) is an effective technique that enables\nlarge language models (LLMs) to utilize external knowledge sources for\ngeneration. However, current RAG systems are solely based on text, rendering it\nimpossible to utilize vision information like layout and images that play\ncrucial roles in real-world multi-modality documents. In this paper, we\nintroduce VisRAG, which tackles this issue by establishing a vision-language\nmodel (VLM)-based RAG pipeline. In this pipeline, instead of first parsing the\ndocument to obtain text, the document is directly embedded using a VLM as an\nimage and then retrieved to enhance the generation of a VLM. Compared to\ntraditional text-based RAG, VisRAG maximizes the retention and utilization of\nthe data information in the original documents, eliminating the information\nloss introduced during the parsing process. We collect both open-source and\nsynthetic data to train the retriever in VisRAG and explore a variety of\ngeneration methods. Experiments demonstrate that VisRAG outperforms traditional\nRAG in both the retrieval and generation stages, achieving a 20--40% end-to-end\nperformance gain over traditional text-based RAG pipeline. Further analysis\nreveals that VisRAG is efficient in utilizing training data and demonstrates\nstrong generalization capability, positioning it as a promising solution for\nRAG on multi-modality documents. Our code and data are available at\nhttps://github.com/openbmb/visrag.\n","authors":["Shi Yu","Chaoyue Tang","Bokai Xu","Junbo Cui","Junhao Ran","Yukun Yan","Zhenghao Liu","Shuo Wang","Xu Han","Zhiyuan Liu","Maosong Sun"],"pdf_url":"https://arxiv.org/pdf/2410.10594v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01031v1","updated":"2025-03-02T21:33:49Z","published":"2025-03-02T21:33:49Z","title":"Can We Find the Code? An Empirical Study of Google Scholar's Code\n  Retrieval","summary":"  Academic codes associated with research papers are valuable resources for\nscholars. In specialized fields outside computer science, code availability is\noften limited, making effective code retrieval essential. Google Scholar is a\ncrucial academic search tool. If a code published in the paper is not\nretrievable via Google Scholar, its accessibility and impact are significantly\nreduced. This study takes the term \"accelerated degradation\" combined with\n\"reliability\" as an example, and finds that, for papers published by Elsevier,\nonly GitHub links included in abstracts are comprehensively retrieved by Google\nScholar. When such links appear within the main body of a paper, even in the\n\"Data Availability\" section, they may be ignored and become unsearchable. These\nfindings highlight the importance of strategically placing GitHub links in\nabstracts to enhance code discoverability on Google Scholar.\n","authors":["Shi-Shun Chen"],"pdf_url":"https://arxiv.org/pdf/2503.01031v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01003v1","updated":"2025-03-02T19:59:41Z","published":"2025-03-02T19:59:41Z","title":"A Semantic Search Pipeline for Causality-driven Adhoc Information\n  Retrieval","summary":"  We present a unsupervised semantic search pipeline for the Causality-driven\nAdhoc Information Retrieval (CAIR-2021) shared task. The CAIR shared task\nexpands traditional information retrieval to support the retrieval of documents\ncontaining the likely causes of a query event. A successful system must be able\nto distinguish between topical documents and documents containing causal\ndescriptions of events that are causally related to the query event. Our\napproach involves aggregating results from multiple query strategies over a\nsemantic and lexical index. The proposed approach leads the CAIR-2021\nleaderboard and outperformed both traditional IR and pure semantic\nembedding-based approaches.\n","authors":["Dhairya Dalal","Sharmi Dev Gupta","Bentolhoda Binaei"],"pdf_url":"https://arxiv.org/pdf/2503.01003v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01001v1","updated":"2025-03-02T19:43:35Z","published":"2025-03-02T19:43:35Z","title":"Towards An Efficient LLM Training Paradigm for CTR Prediction","summary":"  Large Language Models (LLMs) have demonstrated tremendous potential as the\nnext-generation ranking-based recommendation system. Many recent works have\nshown that LLMs can significantly outperform conventional click-through-rate\n(CTR) prediction approaches. Despite such promising results, the computational\ninefficiency inherent in the current training paradigm makes it particularly\nchallenging to train LLMs for ranking-based recommendation tasks on large\ndatasets. To train LLMs for CTR prediction, most existing studies adopt the\nprevalent ''sliding-window'' paradigm. Given a sequence of $m$ user\ninteractions, a unique training prompt is constructed for each interaction by\ndesignating it as the prediction target along with its preceding $n$\ninteractions serving as context. In turn, the sliding-window paradigm results\nin an overall complexity of $O(mn^2)$ that scales linearly with the length of\nuser interactions. Consequently, a direct adoption to train LLMs with such\nstrategy can result in prohibitively high training costs as the length of\ninteractions grows. To alleviate the computational inefficiency, we propose a\nnovel training paradigm, namely Dynamic Target Isolation (DTI), that\nstructurally parallelizes the training of $k$ (where $k >> 1$) target\ninteractions. Furthermore, we identify two major bottlenecks - hidden-state\nleakage and positional bias overfitting - that limit DTI to only scale up to a\nsmall value of $k$ (e.g., 5) then propose a computationally light solution to\neffectively tackle each. Through extensive experiments on three widely adopted\npublic CTR datasets, we empirically show that DTI reduces training time by an\naverage of $\\textbf{92%}$ (e.g., from $70.5$ hrs to $5.31$ hrs), without\ncompromising CTR prediction performance.\n","authors":["Allen Lin","Renqin Cai","Yun He","Hanchao Yu","Jing Qian","Rui Li","Qifan Wang","James Caverlee"],"pdf_url":"https://arxiv.org/pdf/2503.01001v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.00999v1","updated":"2025-03-02T19:39:29Z","published":"2025-03-02T19:39:29Z","title":"Federated Conversational Recommender System","summary":"  Conversational Recommender Systems (CRSs) have become increasingly popular as\na powerful tool for providing personalized recommendation experiences. By\ndirectly engaging with users in a conversational manner to learn their current\nand fine-grained preferences, a CRS can quickly derive recommendations that are\nrelevant and justifiable. However, existing conversational recommendation\nsystems (CRSs) typically rely on a centralized training and deployment process,\nwhich involves collecting and storing explicitly-communicated user preferences\nin a centralized repository. These fine-grained user preferences are completely\nhuman-interpretable and can easily be used to infer sensitive information\n(e.g., financial status, political stands, and health information) about the\nuser, if leaked or breached. To address the user privacy concerns in CRS, we\nfirst define a set of privacy protection guidelines for preserving user privacy\nunder the conversational recommendation setting. Based on these guidelines, we\npropose a novel federated conversational recommendation framework that\neffectively reduces the risk of exposing user privacy by (i) de-centralizing\nboth the historical interests estimation stage and the interactive preference\nelicitation stage and (ii) strictly bounding privacy leakage by enforcing\nuser-level differential privacy with meticulously selected privacy budgets.\nThrough extensive experiments, we show that the proposed framework not only\nsatisfies these user privacy protection guidelines, but also enables the system\nto achieve competitive recommendation performance even when compared to the\nstate-of-the-art non-private conversational recommendation approach.\n","authors":["Allen Lin","Jianling Wang","Ziwei Zhu","James Caverlee"],"pdf_url":"https://arxiv.org/pdf/2503.00999v1.pdf","comment":"ECIR 2024"},{"id":"http://arxiv.org/abs/2503.00863v1","updated":"2025-03-02T11:45:50Z","published":"2025-03-02T11:45:50Z","title":"Systematic Literature Review on Clinical Trial Eligibility Matching","summary":"  Clinical trial eligibility matching is a critical yet often labor-intensive\nand error-prone step in medical research, as it ensures that participants meet\nprecise criteria for safe and reliable study outcomes. Recent advances in\nNatural Language Processing (NLP) have shown promise in automating and\nimproving this process by rapidly analyzing large volumes of unstructured\nclinical text and structured electronic health record (EHR) data. In this\npaper, we present a systematic overview of current NLP methodologies applied to\nclinical trial eligibility screening, focusing on data sources, annotation\npractices, machine learning approaches, and real-world implementation\nchallenges. A comprehensive literature search (spanning Google Scholar,\nMendeley, and PubMed from 2015 to 2024) yielded high-quality studies, each\ndemonstrating the potential of techniques such as rule-based systems, named\nentity recognition, contextual embeddings, and ontology-based normalization to\nenhance patient matching accuracy. While results indicate substantial\nimprovements in screening efficiency and precision, limitations persist\nregarding data completeness, annotation consistency, and model scalability\nacross diverse clinical domains. The review highlights how explainable AI and\nstandardized ontologies can bolster clinician trust and broaden adoption.\nLooking ahead, further research into advanced semantic and temporal\nrepresentations, expanded data integration, and rigorous prospective\nevaluations is necessary to fully realize the transformative potential of NLP\nin clinical trial recruitment.\n","authors":["Muhammad Talha Sharif","Abdul Rehman"],"pdf_url":"https://arxiv.org/pdf/2503.00863v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.00781v1","updated":"2025-03-02T08:11:07Z","published":"2025-03-02T08:11:07Z","title":"Towards Efficient Educational Chatbots: Benchmarking RAG Frameworks","summary":"  Large Language Models (LLMs) have proven immensely beneficial in education by\ncapturing vast amounts of literature-based information, allowing them to\ngenerate context without relying on external sources. In this paper, we propose\na generative AI-powered GATE question-answering framework (GATE stands for\nGraduate Aptitude Test in Engineering) that leverages LLMs to explain GATE\nsolutions and support students in their exam preparation. We conducted\nextensive benchmarking to select the optimal embedding model and LLM,\nevaluating our framework based on criteria such as latency, faithfulness, and\nrelevance, with additional validation through human evaluation. Our chatbot\nintegrates state-of-the-art embedding models and LLMs to deliver accurate,\ncontext-aware responses. Through rigorous experimentation, we identified\nconfigurations that balance performance and computational efficiency, ensuring\na reliable chatbot to serve students' needs. Additionally, we discuss the\nchallenges faced in data processing and modeling and implemented solutions. Our\nwork explores the application of Retrieval-Augmented Generation (RAG) for GATE\nQ/A explanation tasks, and our findings demonstrate significant improvements in\nretrieval accuracy and response quality. This research offers practical\ninsights for developing effective AI-driven educational tools while\nhighlighting areas for future enhancement in usability and scalability.\n","authors":["Umar Ali Khan","Ekram Khan","Fiza Khan","Athar Ali Moinuddin"],"pdf_url":"https://arxiv.org/pdf/2503.00781v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.00674v1","updated":"2025-03-02T00:28:55Z","published":"2025-03-02T00:28:55Z","title":"OrdRankBen: A Novel Ranking Benchmark for Ordinal Relevance in NLP","summary":"  The evaluation of ranking tasks remains a significant challenge in natural\nlanguage processing (NLP), particularly due to the lack of direct labels for\nresults in real-world scenarios. Benchmark datasets play a crucial role in\nproviding standardized testbeds that ensure fair comparisons, enhance\nreproducibility, and enable progress tracking, facilitating rigorous assessment\nand continuous improvement of ranking models. Existing NLP ranking benchmarks\ntypically use binary relevance labels or continuous relevance scores,\nneglecting ordinal relevance scores. However, binary labels oversimplify\nrelevance distinctions, while continuous scores lack a clear ordinal structure,\nmaking it challenging to capture nuanced ranking differences effectively. To\naddress these challenges, we introduce OrdRankBen, a novel benchmark designed\nto capture multi-granularity relevance distinctions. Unlike conventional\nbenchmarks, OrdRankBen incorporates structured ordinal labels, enabling more\nprecise ranking evaluations. Given the absence of suitable datasets for ordinal\nrelevance ranking in NLP, we constructed two datasets with distinct ordinal\nlabel distributions. We further evaluate various models for three model types,\nranking-based language models, general large language models, and\nranking-focused large language models on these datasets. Experimental results\nshow that ordinal relevance modeling provides a more precise evaluation of\nranking models, improving their ability to distinguish multi-granularity\ndifferences among ranked items-crucial for tasks that demand fine-grained\nrelevance differentiation.\n","authors":["Yan Wang","Lingfei Qian","Xueqing Peng","Jimin Huang","Dongji Feng"],"pdf_url":"https://arxiv.org/pdf/2503.00674v1.pdf","comment":"6 pages"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2408.15998v2","updated":"2025-03-02T23:41:37Z","published":"2024-08-28T17:59:31Z","title":"Eagle: Exploring The Design Space for Multimodal LLMs with Mixture of\n  Encoders","summary":"  The ability to accurately interpret complex visual information is a crucial\ntopic of multimodal large language models (MLLMs). Recent work indicates that\nenhanced visual perception significantly reduces hallucinations and improves\nperformance on resolution-sensitive tasks, such as optical character\nrecognition and document analysis. A number of recent MLLMs achieve this goal\nusing a mixture of vision encoders. Despite their success, there is a lack of\nsystematic comparisons and detailed ablation studies addressing critical\naspects, such as expert selection and the integration of multiple vision\nexperts. This study provides an extensive exploration of the design space for\nMLLMs using a mixture of vision encoders and resolutions. Our findings reveal\nseveral underlying principles common to various existing strategies, leading to\na streamlined yet effective design approach. We discover that simply\nconcatenating visual tokens from a set of complementary vision encoders is as\neffective as more complex mixing architectures or strategies. We additionally\nintroduce Pre-Alignment to bridge the gap between vision-focused encoders and\nlanguage tokens, enhancing model coherence. The resulting family of MLLMs,\nEagle, surpasses other leading open-source models on major MLLM benchmarks.\n","authors":["Min Shi","Fuxiao Liu","Shihao Wang","Shijia Liao","Subhashree Radhakrishnan","Yilin Zhao","De-An Huang","Hongxu Yin","Karan Sapra","Yaser Yacoob","Humphrey Shi","Bryan Catanzaro","Andrew Tao","Jan Kautz","Zhiding Yu","Guilin Liu"],"pdf_url":"https://arxiv.org/pdf/2408.15998v2.pdf","comment":"Github: https://github.com/NVlabs/Eagle, HuggingFace:\n  https://huggingface.co/NVEagle"},{"id":"http://arxiv.org/abs/2411.09851v3","updated":"2025-03-02T23:29:50Z","published":"2024-11-15T00:09:37Z","title":"SymbolFit: Automatic Parametric Modeling with Symbolic Regression","summary":"  We introduce SymbolFit, a framework that automates parametric modeling by\nusing symbolic regression to perform a machine-search for functions that fit\nthe data while simultaneously providing uncertainty estimates in a single run.\nTraditionally, constructing a parametric model to accurately describe binned\ndata has been a manual and iterative process, requiring an adequate functional\nform to be determined before the fit can be performed. The main challenge\narises when the appropriate functional forms cannot be derived from first\nprinciples, especially when there is no underlying true closed-form function\nfor the distribution. In this work, we develop a framework that automates and\nstreamlines the process by utilizing symbolic regression, a machine learning\ntechnique that explores a vast space of candidate functions without requiring a\npredefined functional form because the functional form itself is treated as a\ntrainable parameter, making the process far more efficient and effortless than\ntraditional regression methods. We demonstrate the framework in high-energy\nphysics experiments at the CERN Large Hadron Collider (LHC) using five real\nproton-proton collision datasets from new physics searches, including\nbackground modeling in resonance searches for high-mass dijet, trijet,\npaired-dijet, diphoton, and dimuon events. We show that our framework can\nflexibly and efficiently generate a wide range of candidate functions that fit\na nontrivial distribution well using a simple fit configuration that varies\nonly by random seed, and that the same fit configuration, which defines a vast\nfunction space, can also be applied to distributions of different shapes,\nwhereas achieving a comparable result with traditional methods would have\nrequired extensive manual effort.\n","authors":["Ho Fung Tsoi","Dylan Rankin","Cecile Caillol","Miles Cranmer","Sridhara Dasu","Javier Duarte","Philip Harris","Elliot Lipeles","Vladimir Loncar"],"pdf_url":"https://arxiv.org/pdf/2411.09851v3.pdf","comment":"50 pages, 35 figures. Under review. The API can be used\n  out-of-the-box and is available at https://github.com/hftsoi/symbolfit"},{"id":"http://arxiv.org/abs/2401.17116v2","updated":"2025-03-02T23:04:57Z","published":"2024-01-30T15:50:06Z","title":"Quantum time dynamics mediated by the Yang-Baxter equation and\n  artificial neural networks","summary":"  Quantum computing shows great potential, but errors pose a significant\nchallenge. This study explores new strategies for mitigating quantum errors\nusing artificial neural networks (ANN) and the Yang-Baxter equation (YBE).\nUnlike traditional error mitigation methods, which are computationally\nintensive, we investigate artificial error mitigation. We developed a novel\nmethod that combines ANN for noise mitigation combined with the YBE to generate\nnoisy data. This approach effectively reduces noise in quantum simulations,\nenhancing the accuracy of the results. The YBE rigorously preserves quantum\ncorrelations and symmetries in spin chain simulations in certain classes of\nintegrable lattice models, enabling effective compression of quantum circuits\nwhile retaining linear scalability with the number of qubits. This compression\nfacilitates both full and partial implementations, allowing the generation of\nnoisy quantum data on hardware alongside noiseless simulations using classical\nplatforms. By introducing controlled noise through the YBE, we enhance the\ndataset for error mitigation. We train an ANN model on partial data from\nquantum simulations, demonstrating its effectiveness in mitigating errors in\ntime-evolving quantum states, providing a scalable framework to enhance quantum\ncomputation fidelity, particularly in noisy intermediate-scale quantum (NISQ)\nsystems. We demonstrate the efficacy of this approach by performing quantum\ntime dynamics simulations using the Heisenberg XY Hamiltonian on real quantum\ndevices.\n","authors":["Sahil Gulania","Yuri Alexeev","Stephen K. Gray","Bo Peng","Niranjan Govind"],"pdf_url":"https://arxiv.org/pdf/2401.17116v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.13496v2","updated":"2025-03-02T22:34:01Z","published":"2024-02-21T03:14:45Z","title":"Heterogeneous Graph Neural Network on Semantic Tree","summary":"  The recent past has seen an increasing interest in Heterogeneous Graph Neural\nNetworks (HGNNs), since many real-world graphs are heterogeneous in nature,\nfrom citation graphs to email graphs. However, existing methods ignore a tree\nhierarchy among metapaths, naturally constituted by different node types and\nrelation types. In this paper, we present HetTree, a novel HGNN that models\nboth the graph structure and heterogeneous aspects in a scalable and effective\nmanner. Specifically, HetTree builds a semantic tree data structure to capture\nthe hierarchy among metapaths. To effectively encode the semantic tree, HetTree\nuses a novel subtree attention mechanism to emphasize metapaths that are more\nhelpful in encoding parent-child relationships. Moreover, HetTree proposes\ncarefully matching pre-computed features and labels correspondingly,\nconstituting a complete metapath representation. Our evaluation of HetTree on a\nvariety of real-world datasets demonstrates that it outperforms all existing\nbaselines on open benchmarks and efficiently scales to large real-world graphs\nwith millions of nodes and edges.\n","authors":["Mingyu Guan","Jack W. Stokes","Qinlong Luo","Fuchen Liu","Purvanshi Mehta","Elnaz Nouri","Taesoo Kim"],"pdf_url":"https://arxiv.org/pdf/2402.13496v2.pdf","comment":"Accepted at AAAI 2025"},{"id":"http://arxiv.org/abs/2407.11249v3","updated":"2025-03-02T22:12:01Z","published":"2024-07-15T21:32:58Z","title":"Disentangling Representations through Multi-task Learning","summary":"  Intelligent perception and interaction with the world hinges on internal\nrepresentations that capture its underlying structure (''disentangled'' or\n''abstract'' representations). Disentangled representations serve as world\nmodels, isolating latent factors of variation in the world along approximately\northogonal directions, thus facilitating feature-based generalization. We\nprovide experimental and theoretical results guaranteeing the emergence of\ndisentangled representations in agents that optimally solve multi-task evidence\naccumulation classification tasks, canonical in the neuroscience literature.\nThe key conceptual finding is that, by producing accurate multi-task\nclassification estimates, a system implicitly represents a set of coordinates\nspecifying a disentangled representation of the underlying latent state of the\ndata it receives. The theory provides conditions for the emergence of these\nrepresentations in terms of noise, number of tasks, and evidence accumulation\ntime. We experimentally validate these predictions in RNNs trained to\nmulti-task, which learn disentangled representations in the form of continuous\nattractors, leading to zero-shot out-of-distribution (OOD) generalization in\npredicting latent factors. We demonstrate the robustness of our framework\nacross autoregressive architectures, decision boundary geometries and in tasks\nrequiring classification confidence estimation. We find that transformers are\nparticularly suited for disentangling representations, which might explain\ntheir unique world understanding abilities. Overall, our framework establishes\na formal link between competence at multiple tasks and the formation of\ndisentangled, interpretable world models in both biological and artificial\nsystems, and helps explain why ANNs often arrive at human-interpretable\nconcepts, and how they both may acquire exceptional zero-shot generalization\ncapabilities.\n","authors":["Pantelis Vafidis","Aman Bhargava","Antonio Rangel"],"pdf_url":"https://arxiv.org/pdf/2407.11249v3.pdf","comment":"43 pages, 17 figures"},{"id":"http://arxiv.org/abs/2406.10279v3","updated":"2025-03-02T21:03:52Z","published":"2024-06-12T03:29:06Z","title":"We Have a Package for You! A Comprehensive Analysis of Package\n  Hallucinations by Code Generating LLMs","summary":"  The reliance of popular programming languages such as Python and JavaScript\non centralized package repositories and open-source software, combined with the\nemergence of code-generating Large Language Models (LLMs), has created a new\ntype of threat to the software supply chain: package hallucinations. These\nhallucinations, which arise from fact-conflicting errors when generating code\nusing LLMs, represent a novel form of package confusion attack that poses a\ncritical threat to the integrity of the software supply chain. This paper\nconducts a rigorous and comprehensive evaluation of package hallucinations\nacross different programming languages, settings, and parameters, exploring how\na diverse set of models and configurations affect the likelihood of generating\nerroneous package recommendations and identifying the root causes of this\nphenomenon. Using 16 popular LLMs for code generation and two unique prompt\ndatasets, we generate 576,000 code samples in two programming languages that we\nanalyze for package hallucinations. Our findings reveal that that the average\npercentage of hallucinated packages is at least 5.2% for commercial models and\n21.7% for open-source models, including a staggering 205,474 unique examples of\nhallucinated package names, further underscoring the severity and pervasiveness\nof this threat. To overcome this problem, we implement several hallucination\nmitigation strategies and show that they are able to significantly reduce the\nnumber of package hallucinations while maintaining code quality. Our\nexperiments and findings highlight package hallucinations as a persistent and\nsystemic phenomenon while using state-of-the-art LLMs for code generation, and\na significant challenge which deserves the research community's urgent\nattention.\n","authors":["Joseph Spracklen","Raveen Wijewickrama","A H M Nazmus Sakib","Anindya Maiti","Bimal Viswanath","Murtuza Jadliwala"],"pdf_url":"https://arxiv.org/pdf/2406.10279v3.pdf","comment":"To appear in the 2025 USENIX Security Symposium. 22 pages, 14\n  figures, 8 tables. Edited from original version for submission to a different\n  conference. No change to original results or findings"},{"id":"http://arxiv.org/abs/2410.06232v3","updated":"2025-03-02T20:40:21Z","published":"2024-10-08T17:41:37Z","title":"Range, not Independence, Drives Modularity in Biologically Inspired\n  Representations","summary":"  Why do biological and artificial neurons sometimes modularise, each encoding\na single meaningful variable, and sometimes entangle their representation of\nmany variables? In this work, we develop a theory of when biologically inspired\nnetworks -- those that are nonnegative and energy efficient -- modularise their\nrepresentation of source variables (sources). We derive necessary and\nsufficient conditions on a sample of sources that determine whether the neurons\nin an optimal biologically-inspired linear autoencoder modularise. Our theory\napplies to any dataset, extending far beyond the case of statistical\nindependence studied in previous work. Rather we show that sources modularise\nif their support is ``sufficiently spread''. From this theory, we extract and\nvalidate predictions in a variety of empirical studies on how data distribution\naffects modularisation in nonlinear feedforward and recurrent neural networks\ntrained on supervised and unsupervised tasks. Furthermore, we apply these ideas\nto neuroscience data, showing that range independence can be used to understand\nthe mixing or modularising of spatial and reward information in entorhinal\nrecordings in seemingly conflicting experiments. Further, we use these results\nto suggest alternate origins of mixed-selectivity, beyond the predominant\ntheory of flexible nonlinear classification. In sum, our theory prescribes\nprecise conditions on when neural activities modularise, providing tools for\ninducing and elucidating modular representations in brains and machines.\n","authors":["Will Dorrell","Kyle Hsu","Luke Hollingsworth","Jin Hwa Lee","Jiajun Wu","Chelsea Finn","Peter E Latham","Tim EJ Behrens","James CR Whittington"],"pdf_url":"https://arxiv.org/pdf/2410.06232v3.pdf","comment":"47 pages, 17 figures. WD and KH contributed equally; LH and JHL\n  contributed equally"},{"id":"http://arxiv.org/abs/2408.15905v2","updated":"2025-03-02T20:30:28Z","published":"2024-08-28T16:19:35Z","title":"MetaGFN: Exploring Distant Modes with Adapted Metadynamics for\n  Continuous GFlowNets","summary":"  Generative Flow Networks (GFlowNets) are a class of generative models that\nsample objects in proportion to a specified reward function through a learned\npolicy. They can be trained either on-policy or off-policy, needing a balance\nbetween exploration and exploitation for fast convergence to a target\ndistribution. While exploration strategies for discrete GFlowNets have been\nstudied, exploration in the continuous case remains to be investigated, despite\nthe potential for novel exploration algorithms due to the local connectedness\nof continuous domains. Here, we introduce Adapted Metadynamics, a variant of\nmetadynamics that can be applied to arbitrary black-box reward functions on\ncontinuous domains. We use Adapted Metadynamics as an exploration strategy for\ncontinuous GFlowNets. We show several continuous domains where the resulting\nalgorithm, MetaGFN, accelerates convergence to the target distribution and\ndiscovers more distant reward modes than previous off-policy exploration\nstrategies used for GFlowNets.\n","authors":["Dominic Phillips","Flaviu Cipcigan"],"pdf_url":"https://arxiv.org/pdf/2408.15905v2.pdf","comment":"22 pages"},{"id":"http://arxiv.org/abs/2502.12381v3","updated":"2025-03-02T20:17:56Z","published":"2025-02-17T23:40:27Z","title":"Linear Diffusion Networks","summary":"  Diffusion kernels capture global dependencies. We present Linear Diffusion\nNetworks (LDNs), a novel architecture that reinterprets sequential data\nprocessing as a unified diffusion process. Our model integrates adaptive\ndiffusion modules with localized nonlinear updates and a diffusion-inspired\nattention mechanism. This design enables efficient global information\npropagation while preserving fine-grained temporal details. LDN overcomes the\nlimitations of conventional recurrent and transformer models by allowing full\nparallelization across time steps and supporting robust multi-scale temporal\nrepresentations. Experiments on benchmark sequence modeling tasks demonstrate\nthat LDN delivers competitive performance across ImageNet and GLUE tasks.\n","authors":["Jacob Fein-Ashley"],"pdf_url":"https://arxiv.org/pdf/2502.12381v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.05967v2","updated":"2025-03-02T20:16:43Z","published":"2025-02-09T17:31:09Z","title":"$μ$nit Scaling: Simple and Scalable FP8 LLM Training","summary":"  Large Language Model training with 8-bit floating point (FP8) formats\npromises significant efficiency improvements, but reduced numerical precision\nmakes training challenging. It is currently possible to train in FP8 only if\none is willing to tune various hyperparameters, reduce model scale, or accept\nthe overhead of computing dynamic scale factors. We demonstrate simple,\nscalable FP8 training that requires no dynamic scaling factors or special\nhyperparameters, even at large model sizes. Our method, $\\mu$nit Scaling\n($\\mu$S), also enables simple hyperparameter transfer across model widths,\nmatched numerics across training and inference, and other desirable properties.\n$\\mu$nit Scaling is straightforward to implement, consisting of a set of\nminimal interventions based on a first-principles analysis of common\ntransformer operations. We validate our method by training models from 1B to\n13B parameters, performing all hidden linear layer computations in FP8. We\nachieve quality equal to higher precision baselines while also training up to\n33% faster.\n","authors":["Saaketh Narayan","Abhay Gupta","Mansheej Paul","Davis Blalock"],"pdf_url":"https://arxiv.org/pdf/2502.05967v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.12534v2","updated":"2025-03-02T20:13:11Z","published":"2024-04-18T22:54:08Z","title":"Lean Copilot: Large Language Models as Copilots for Theorem Proving in\n  Lean","summary":"  Neural theorem proving combines large language models (LLMs) with proof\nassistants such as Lean, where the correctness of formal proofs can be\nrigorously verified, leaving no room for hallucination. With existing neural\ntheorem provers pretrained on a fixed collection of data and offering valuable\nsuggestions at times, it is challenging for them to continually prove novel\ntheorems in a fully autonomous mode, where human insights may be critical. In\nthis paper, we explore LLMs as copilots that assist humans in proving theorems.\nWe introduce Lean Copilot, an general framework for running LLM inference\nnatively in Lean. It enables programmers to build various LLM-based proof\nautomation tools that integrate seamlessly into the workflow of Lean users.\nLean users can use our pretrained models or bring their own ones that run\neither locally (with or without GPUs) or on the cloud. Using Lean Copilot, we\nbuild LLM-based tools that suggest proof steps, complete proof goals, and\nselect relevant premises. Experimental results on the Mathematics in Lean\ntextbook demonstrate the effectiveness of our method compared to existing\nrule-based proof automation in Lean (aesop). When assisting humans, Lean\nCopilot requires only 2.08 manually-entered proof steps on average (3.86\nrequired by aesop); when automating the theorem proving process, Lean Copilot\nautomates 74.2% proof steps on average, 85% better than aesop (40.1%). We open\nsource all code and artifacts under a permissive MIT license to facilitate\nfurther research.\n","authors":["Peiyang Song","Kaiyu Yang","Anima Anandkumar"],"pdf_url":"https://arxiv.org/pdf/2404.12534v2.pdf","comment":"All code and artifacts open-sourced at\n  https://github.com/lean-dojo/LeanCopilot"},{"id":"http://arxiv.org/abs/2405.09660v3","updated":"2025-03-02T19:51:43Z","published":"2024-05-15T19:03:08Z","title":"Fast Two-Time-Scale Stochastic Gradient Method with Applications in\n  Reinforcement Learning","summary":"  Two-time-scale optimization is a framework introduced in Zeng et al. (2024)\nthat abstracts a range of policy evaluation and policy optimization problems in\nreinforcement learning (RL). Akin to bi-level optimization under a particular\ntype of stochastic oracle, the two-time-scale optimization framework has an\nupper level objective whose gradient evaluation depends on the solution of a\nlower level problem, which is to find the root of a strongly monotone operator.\nIn this work, we propose a new method for solving two-time-scale optimization\nthat achieves significantly faster convergence than the prior arts. The key\nidea of our approach is to leverage an averaging step to improve the estimates\nof the operators in both lower and upper levels before using them to update the\ndecision variables. These additional averaging steps eliminate the direct\ncoupling between the main variables, enabling the accelerated performance of\nour algorithm. We characterize the finite-time convergence rates of the\nproposed algorithm under various conditions of the underlying objective\nfunction, including strong convexity, Polyak-Lojasiewicz condition, and general\nnon-convexity. These rates significantly improve over the best-known complexity\nof the standard two-time-scale stochastic approximation algorithm. When applied\nto RL, we show how the proposed algorithm specializes to novel online\nsample-based methods that surpass or match the performance of the existing\nstate of the art. Finally, we support our theoretical results with numerical\nsimulations in RL.\n","authors":["Sihan Zeng","Thinh T. Doan"],"pdf_url":"https://arxiv.org/pdf/2405.09660v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16103v4","updated":"2025-03-02T18:38:37Z","published":"2024-10-21T15:31:06Z","title":"LDAdam: Adaptive Optimization from Low-Dimensional Gradient Statistics","summary":"  We introduce LDAdam, a memory-efficient optimizer for training large models,\nthat performs adaptive optimization steps within lower dimensional subspaces,\nwhile consistently exploring the full parameter space during training. This\nstrategy keeps the optimizer's memory footprint to a fraction of the model\nsize. LDAdam relies on a new projection-aware update rule for the optimizer\nstates that allows for transitioning between subspaces, i.e., estimation of the\nstatistics of the projected gradients. To mitigate the errors due to low-rank\nprojection, LDAdam integrates a new generalized error feedback mechanism, which\nexplicitly accounts for both gradient and optimizer state compression. We prove\nthe convergence of LDAdam under standard assumptions, and show that LDAdam\nallows for accurate and efficient fine-tuning and pre-training of language\nmodels. Code is available at https://github.com/IST-DASLab/LDAdam\n","authors":["Thomas Robert","Mher Safaryan","Ionut-Vlad Modoranu","Dan Alistarh"],"pdf_url":"https://arxiv.org/pdf/2410.16103v4.pdf","comment":"39 pages, ICLR 2025"},{"id":"http://arxiv.org/abs/2312.15289v3","updated":"2025-03-02T18:36:56Z","published":"2023-12-23T16:10:53Z","title":"Fréchet Wavelet Distance: A Domain-Agnostic Metric for Image\n  Generation","summary":"  Modern metrics for generative learning like Fr\\'echet Inception Distance\n(FID) and DINOv2-Fr\\'echet Distance (FD-DINOv2) demonstrate impressive\nperformance. However, they suffer from various shortcomings, like a bias\ntowards specific generators and datasets. To address this problem, we propose\nthe Fr\\'echet Wavelet Distance (FWD) as a domain-agnostic metric based on the\nWavelet Packet Transform ($W_p$). FWD provides a sight across a broad spectrum\nof frequencies in images with a high resolution, preserving both spatial and\ntextural aspects. Specifically, we use $W_p$ to project generated and real\nimages to the packet coefficient space. We then compute the Fr\\'echet distance\nwith the resultant coefficients to evaluate the quality of a generator. This\nmetric is general-purpose and dataset-domain agnostic, as it does not rely on\nany pre-trained network, while being more interpretable due to its ability to\ncompute Fr\\'echet distance per packet, enhancing transparency. We conclude with\nan extensive evaluation of a wide variety of generators across various datasets\nthat the proposed FWD can generalize and improve robustness to domain shifts\nand various corruptions compared to other metrics.\n","authors":["Lokesh Veeramacheneni","Moritz Wolter","Hildegard Kuehne","Juergen Gall"],"pdf_url":"https://arxiv.org/pdf/2312.15289v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02950v2","updated":"2025-03-02T18:31:59Z","published":"2024-08-06T04:28:16Z","title":"Kolmogorov-Arnold PointNet: Deep learning for prediction of fluid fields\n  on irregular geometries","summary":"  Kolmogorov-Arnold Networks (KANs) have emerged as a promising alternative to\ntraditional Multilayer Perceptrons (MLPs) in deep learning. KANs have already\nbeen integrated into various architectures, such as convolutional neural\nnetworks, graph neural networks, and transformers, and their potential has been\nassessed for predicting physical quantities. However, the combination of KANs\nwith point-cloud-based neural networks (e.g., PointNet) for computational\nphysics has not yet been explored. To address this, we present\nKolmogorov-Arnold PointNet (KA-PointNet) as a novel supervised deep learning\nframework for the prediction of incompressible steady-state fluid flow fields\nin irregular domains, where the predicted fields are a function of the geometry\nof the domains. In KA-PointNet, we implement shared KANs in the segmentation\nbranch of the PointNet architecture. We utilize Jacobi polynomials to construct\nshared KANs. As a benchmark test case, we consider incompressible laminar\nsteady-state flow over a cylinder, where the geometry of its cross-section\nvaries over the data set. We investigate the performance of Jacobi polynomials\nwith different degrees as well as special cases of Jacobi polynomials such as\nLegendre polynomials, Chebyshev polynomials of the first and second kinds, and\nGegenbauer polynomials, in terms of the computational cost of training and\naccuracy of prediction of the test set. Additionally, we compare the\nperformance of PointNet with shared KANs (i.e., KA-PointNet) and PointNet with\nshared MLPs. It is observed that when the number of trainable parameters is\napproximately equal, PointNet with shared KANs (i.e., KA-PointNet) outperforms\nPointNet with shared MLPs. Moreover, KA-PointNet predicts the pressure and\nvelocity distributions along the surface of cylinders more accurately,\nresulting in more precise computations of lift and drag.\n","authors":["Ali Kashefi"],"pdf_url":"https://arxiv.org/pdf/2408.02950v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.14105v4","updated":"2025-03-02T18:24:29Z","published":"2024-05-23T02:14:17Z","title":"Distributed Speculative Inference (DSI): Speculation Parallelism for\n  Provably Faster Lossless Language Model Inference","summary":"  This paper introduces distributed speculative inference (DSI), a novel\ninference algorithm that is provably faster than speculative inference (SI)\n[leviathan2023, chen2023, miao2024, sun2025, timor2025] and standard\nautoregressive inference (non-SI). Like other SI algorithms, DSI operates on\nfrozen language models (LMs), requiring no training or architectural\nmodifications, and it preserves the target distribution. Prior studies on SI\nhave demonstrated empirical speedups over non-SI--but rely on sufficiently fast\nand accurate drafters, which are often unavailable in practice. We identify a\ngap where SI can be slower than non-SI if drafters are too slow or inaccurate.\nWe close this gap by proving that DSI is faster than both SI and non-SI--given\nany drafters. DSI is therefore not only faster than SI, but also unlocks the\nacceleration of LMs for which SI fails. DSI leverages speculation parallelism\n(SP), a novel type of task parallelism, to orchestrate target and drafter\ninstances that overlap in time, establishing a new foundational tradeoff\nbetween computational resources and latency. Our simulations show that DSI is\n1.29-1.92x faster than SI in single-node setups for various off-the-shelf LMs\nand tasks. We open-source all our code.\n","authors":["Nadav Timor","Jonathan Mamou","Daniel Korat","Moshe Berchansky","Oren Pereg","Moshe Wasserblat","Tomer Galanti","Michal Gordon","David Harel"],"pdf_url":"https://arxiv.org/pdf/2405.14105v4.pdf","comment":"Published at ICLR 2025. (Link:\n  https://openreview.net/forum?id=cJd1BgZ9CS)"},{"id":"http://arxiv.org/abs/2411.10509v2","updated":"2025-03-02T18:17:14Z","published":"2024-11-15T15:39:04Z","title":"TESGNN: Temporal Equivariant Scene Graph Neural Networks for Efficient\n  and Robust Multi-View 3D Scene Understanding","summary":"  Scene graphs have proven to be highly effective for various scene\nunderstanding tasks due to their compact and explicit representation of\nrelational information. However, current methods often overlook the critical\nimportance of preserving symmetry when generating scene graphs from 3D point\nclouds, which can lead to reduced accuracy and robustness, particularly when\ndealing with noisy, multi-view data. Furthermore, a major limitation of prior\napproaches is the lack of temporal modeling to capture time-dependent\nrelationships among dynamically evolving entities in a scene. To address these\nchallenges, we propose Temporal Equivariant Scene Graph Neural Network\n(TESGNN), consisting of two key components: (1) an Equivariant Scene Graph\nNeural Network (ESGNN), which extracts information from 3D point clouds to\ngenerate scene graph while preserving crucial symmetry properties, and (2) a\nTemporal Graph Matching Network, which fuses scene graphs generated by ESGNN\nacross multiple time sequences into a unified global representation using an\napproximate graph-matching algorithm. Our combined architecture TESGNN\noutperforms current state-of-the-art methods in scene graph generation,\nachieving higher accuracy and faster training convergence. Moreover, we show\nthat leveraging the symmetry-preserving property produces a more stable and\naccurate global scene representation compared to existing approaches. Last but\nnot least, it is computationally efficient and easily implementable using\nexisting frameworks, making it well-suited for real-time applications in\nrobotics and computer vision. This approach paves the way for more robust and\nscalable solutions to complex multi-view scene understanding challenges. Our\nsource code is publicly available at: https://github.com/HySonLab/TESGraph\n","authors":["Quang P. M. Pham","Khoi T. N. Nguyen","Lan C. Ngo","Truong Do","Dezhen Song","Truong-Son Hy"],"pdf_url":"https://arxiv.org/pdf/2411.10509v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2407.00609"},{"id":"http://arxiv.org/abs/2407.13929v2","updated":"2025-03-02T18:17:11Z","published":"2024-07-18T22:33:52Z","title":"Unmasking Social Bots: How Confident Are We?","summary":"  Social bots remain a major vector for spreading disinformation on social\nmedia and a menace to the public. Despite the progress made in developing\nmultiple sophisticated social bot detection algorithms and tools, bot detection\nremains a challenging, unsolved problem that is fraught with uncertainty due to\nthe heterogeneity of bot behaviors, training data, and detection algorithms.\nDetection models often disagree on whether to label the same account as bot or\nhuman-controlled. However, they do not provide any measure of uncertainty to\nindicate how much we should trust their results. We propose to address both bot\ndetection and the quantification of uncertainty at the account level - a novel\nfeature of this research. This dual focus is crucial as it allows us to\nleverage additional information related to the quantified uncertainty of each\nprediction, thereby enhancing decision-making and improving the reliability of\nbot classifications. Specifically, our approach facilitates targeted\ninterventions for bots when predictions are made with high confidence and\nsuggests caution (e.g., gathering more data) when predictions are uncertain.\n","authors":["James Giroux","Ariyarathne Gangani","Alexander C. Nwala","Cristiano Fanelli"],"pdf_url":"https://arxiv.org/pdf/2407.13929v2.pdf","comment":"15 pages, 6 figures, 6 tables"},{"id":"http://arxiv.org/abs/2410.04642v3","updated":"2025-03-02T18:16:48Z","published":"2024-10-06T22:30:14Z","title":"The Optimization Landscape of SGD Across the Feature Learning Strength","summary":"  We consider neural networks (NNs) where the final layer is down-scaled by a\nfixed hyperparameter $\\gamma$. Recent work has identified $\\gamma$ as\ncontrolling the strength of feature learning. As $\\gamma$ increases, network\nevolution changes from \"lazy\" kernel dynamics to \"rich\" feature-learning\ndynamics, with a host of associated benefits including improved performance on\ncommon tasks. In this work, we conduct a thorough empirical investigation of\nthe effect of scaling $\\gamma$ across a variety of models and datasets in the\nonline training setting. We first examine the interaction of $\\gamma$ with the\nlearning rate $\\eta$, identifying several scaling regimes in the\n$\\gamma$-$\\eta$ plane which we explain theoretically using a simple model. We\nfind that the optimal learning rate $\\eta^*$ scales non-trivially with\n$\\gamma$. In particular, $\\eta^* \\propto \\gamma^2$ when $\\gamma \\ll 1$ and\n$\\eta^* \\propto \\gamma^{2/L}$ when $\\gamma \\gg 1$ for a feed-forward network of\ndepth $L$. Using this optimal learning rate scaling, we proceed with an\nempirical study of the under-explored \"ultra-rich\" $\\gamma \\gg 1$ regime. We\nfind that networks in this regime display characteristic loss curves, starting\nwith a long plateau followed by a drop-off, sometimes followed by one or more\nadditional staircase steps. We find networks of different large $\\gamma$ values\noptimize along similar trajectories up to a reparameterization of time. We\nfurther find that optimal online performance is often found at large $\\gamma$\nand could be missed if this hyperparameter is not tuned. Our findings indicate\nthat analytical study of the large-$\\gamma$ limit may yield useful insights\ninto the dynamics of representation learning in performant models.\n","authors":["Alexander Atanasov","Alexandru Meterez","James B. Simon","Cengiz Pehlevan"],"pdf_url":"https://arxiv.org/pdf/2410.04642v3.pdf","comment":"ICLR 2025 Final Copy, 40 Pages, 45 figures"},{"id":"http://arxiv.org/abs/2408.08531v2","updated":"2025-03-02T18:15:48Z","published":"2024-08-16T04:57:54Z","title":"Detecting Unsuccessful Students in Cybersecurity Exercises in Two\n  Different Learning Environments","summary":"  This full paper in the research track evaluates the usage of data logged from\ncybersecurity exercises in order to predict students who are potentially at\nrisk of performing poorly. Hands-on exercises are essential for learning since\nthey enable students to practice their skills. In cybersecurity, hands-on\nexercises are often complex and require knowledge of many topics. Therefore,\nstudents may miss solutions due to gaps in their knowledge and become\nfrustrated, which impedes their learning. Targeted aid by the instructor helps,\nbut since the instructor's time is limited, efficient ways to detect struggling\nstudents are needed. This paper develops automated tools to predict when a\nstudent is having difficulty. We formed a dataset with the actions of 313\nstudents from two countries and two learning environments: KYPO CRP and\nEDURange. These data are used in machine learning algorithms to predict the\nsuccess of students in exercises deployed in these environments. After\nextracting features from the data, we trained and cross-validated eight\nclassifiers for predicting the exercise outcome and evaluated their predictive\npower. The contribution of this paper is comparing two approaches to feature\nengineering, modeling, and classification performance on data from two learning\nenvironments. Using the features from either learning environment, we were able\nto detect and distinguish between successful and struggling students. A\ndecision tree classifier achieved the highest balanced accuracy and sensitivity\nwith data from both learning environments. The results show that activity data\nfrom cybersecurity exercises are suitable for predicting student success. In a\npotential application, such models can aid instructors in detecting struggling\nstudents and providing targeted help. We publish data and code for building\nthese models so that others can adopt or adapt them.\n","authors":["Valdemar Švábenský","Kristián Tkáčik","Aubrey Birdwell","Richard Weiss","Ryan S. Baker","Pavel Čeleda","Jan Vykopal","Jens Mache","Ankur Chattopadhyay"],"pdf_url":"https://arxiv.org/pdf/2408.08531v2.pdf","comment":"Published in the FIE 2024 conference proceedings, see\n  https://doi.org/10.1109/FIE61694.2024.10893135"},{"id":"http://arxiv.org/abs/2410.11112v5","updated":"2025-03-02T17:48:06Z","published":"2024-10-14T21:43:48Z","title":"Differentiable Weightless Neural Networks","summary":"  We introduce the Differentiable Weightless Neural Network (DWN), a model\nbased on interconnected lookup tables. Training of DWNs is enabled by a novel\nExtended Finite Difference technique for approximate differentiation of binary\nvalues. We propose Learnable Mapping, Learnable Reduction, and Spectral\nRegularization to further improve the accuracy and efficiency of these models.\nWe evaluate DWNs in three edge computing contexts: (1) an FPGA-based hardware\naccelerator, where they demonstrate superior latency, throughput, energy\nefficiency, and model area compared to state-of-the-art solutions, (2) a\nlow-power microcontroller, where they achieve preferable accuracy to XGBoost\nwhile subject to stringent memory constraints, and (3) ultra-low-cost chips,\nwhere they consistently outperform small models in both accuracy and projected\nhardware area. DWNs also compare favorably against leading approaches for\ntabular datasets, with higher average rank. Overall, our work positions DWNs as\na pioneering solution for edge-compatible high-throughput neural networks.\n","authors":["Alan T. L. Bacellar","Zachary Susskind","Mauricio Breternitz Jr.","Eugene John","Lizy K. John","Priscila M. V. Lima","Felipe M. G. França"],"pdf_url":"https://arxiv.org/pdf/2410.11112v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02372v2","updated":"2025-03-02T17:34:53Z","published":"2024-11-04T18:40:46Z","title":"Learning General-Purpose Biomedical Volume Representations using\n  Randomized Synthesis","summary":"  Current volumetric biomedical foundation models struggle to generalize as\npublic 3D datasets are small and do not cover the broad diversity of medical\nprocedures, conditions, anatomical regions, and imaging protocols. We address\nthis by creating a representation learning method that instead anticipates\nstrong domain shifts at training time itself. We first propose a data engine\nthat synthesizes highly variable training samples that would enable\ngeneralization to new biomedical contexts. To then train a single 3D network\nfor any voxel-level task, we develop a contrastive learning method that\npretrains the network to be stable against nuisance imaging variation simulated\nby the data engine, a key inductive bias for generalization. This network's\nfeatures can be used as robust representations of input images for downstream\ntasks and its weights provide a strong, dataset-agnostic initialization for\nfinetuning on new datasets. As a result, we set new standards across both\nmultimodality registration and few-shot segmentation, a first for any 3D\nbiomedical vision model, all without (pre-)training on any existing dataset of\nreal images.\n","authors":["Neel Dey","Benjamin Billot","Hallee E. Wong","Clinton J. Wang","Mengwei Ren","P. Ellen Grant","Adrian V. Dalca","Polina Golland"],"pdf_url":"https://arxiv.org/pdf/2411.02372v2.pdf","comment":"ICLR 2025: International Conference on Learning Representations. Code\n  and model weights available at https://github.com/neel-dey/anatomix.\n  Keywords: synthetic data, representation learning, medical image analysis,\n  image registration, image segmentation"},{"id":"http://arxiv.org/abs/2403.08743v2","updated":"2025-03-02T17:33:03Z","published":"2024-03-13T17:46:28Z","title":"Prompting Fairness: Integrating Causality to Debias Large Language\n  Models","summary":"  Large language models (LLMs), despite their remarkable capabilities, are\nsusceptible to generating biased and discriminatory responses. As LLMs\nincreasingly influence high-stakes decision-making (e.g., hiring and\nhealthcare), mitigating these biases becomes critical. In this work, we propose\na causality-guided debiasing framework to tackle social biases, aiming to\nreduce the objectionable dependence between LLMs' decisions and the social\ninformation in the input. Our framework introduces a novel perspective to\nidentify how social information can affect an LLM's decision through different\ncausal pathways. Leveraging these causal insights, we outline principled\nprompting strategies that regulate these pathways through selection mechanisms.\nThis framework not only unifies existing prompting-based debiasing techniques,\nbut also opens up new directions for reducing bias by encouraging the model to\nprioritize fact-based reasoning over reliance on biased social cues. We\nvalidate our framework through extensive experiments on real-world datasets\nacross multiple domains, demonstrating its effectiveness in debiasing LLM\ndecisions, even with only black-box access to the model.\n","authors":["Jingling Li","Zeyu Tang","Xiaoyu Liu","Peter Spirtes","Kun Zhang","Liu Leqi","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2403.08743v2.pdf","comment":"24 pages, 10 figures"},{"id":"http://arxiv.org/abs/2502.03391v3","updated":"2025-03-02T17:32:48Z","published":"2025-02-05T17:29:12Z","title":"Explain Yourself, Briefly! Self-Explaining Neural Networks with Concise\n  Sufficient Reasons","summary":"  *Minimal sufficient reasons* represent a prevalent form of explanation - the\nsmallest subset of input features which, when held constant at their\ncorresponding values, ensure that the prediction remains unchanged. Previous\n*post-hoc* methods attempt to obtain such explanations but face two main\nlimitations: (1) Obtaining these subsets poses a computational challenge,\nleading most scalable methods to converge towards suboptimal, less meaningful\nsubsets; (2) These methods heavily rely on sampling out-of-distribution input\nassignments, potentially resulting in counterintuitive behaviors. To tackle\nthese limitations, we propose in this work a self-supervised training approach,\nwhich we term *sufficient subset training* (SST). Using SST, we train models to\ngenerate concise sufficient reasons for their predictions as an integral part\nof their output. Our results indicate that our framework produces succinct and\nfaithful subsets substantially more efficiently than competing post-hoc\nmethods, while maintaining comparable predictive performance.\n","authors":["Shahaf Bassan","Ron Eliav","Shlomit Gur"],"pdf_url":"https://arxiv.org/pdf/2502.03391v3.pdf","comment":"To appear in ICLR 2025"},{"id":"http://arxiv.org/abs/2410.06262v2","updated":"2025-03-02T17:20:26Z","published":"2024-10-08T18:02:29Z","title":"SymDiff: Equivariant Diffusion via Stochastic Symmetrisation","summary":"  We propose SymDiff, a method for constructing equivariant diffusion models\nusing the framework of stochastic symmetrisation. SymDiff resembles a learned\ndata augmentation that is deployed at sampling time, and is lightweight,\ncomputationally efficient, and easy to implement on top of arbitrary\noff-the-shelf models. In contrast to previous work, SymDiff typically does not\nrequire any neural network components that are intrinsically equivariant,\navoiding the need for complex parameterisations or the use of higher-order\ngeometric features. Instead, our method can leverage highly scalable modern\narchitectures as drop-in replacements for these more constrained alternatives.\nWe show that this additional flexibility yields significant empirical benefit\nfor $\\mathrm{E}(3)$-equivariant molecular generation. To the best of our\nknowledge, this is the first application of symmetrisation to generative\nmodelling, suggesting its potential in this domain more generally.\n","authors":["Leo Zhang","Kianoosh Ashouritaklimi","Yee Whye Teh","Rob Cornish"],"pdf_url":"https://arxiv.org/pdf/2410.06262v2.pdf","comment":"Camera-ready version for ICLR 2025"},{"id":"http://arxiv.org/abs/2410.04810v2","updated":"2025-03-02T17:18:04Z","published":"2024-10-07T07:45:18Z","title":"FedBiP: Heterogeneous One-Shot Federated Learning with Personalized\n  Latent Diffusion Models","summary":"  One-Shot Federated Learning (OSFL), a special decentralized machine learning\nparadigm, has recently gained significant attention. OSFL requires only a\nsingle round of client data or model upload, which reduces communication costs\nand mitigates privacy threats compared to traditional FL. Despite these\npromising prospects, existing methods face challenges due to client data\nheterogeneity and limited data quantity when applied to real-world OSFL\nsystems. Recently, Latent Diffusion Models (LDM) have shown remarkable\nadvancements in synthesizing high-quality images through pretraining on\nlarge-scale datasets, thereby presenting a potential solution to overcome these\nissues. However, directly applying pretrained LDM to heterogeneous OSFL results\nin significant distribution shifts in synthetic data, leading to performance\ndegradation in classification models trained on such data. This issue is\nparticularly pronounced in rare domains, such as medical imaging, which are\nunderrepresented in LDM's pretraining data. To address this challenge, we\npropose Federated Bi-Level Personalization (FedBiP), which personalizes the\npretrained LDM at both instance-level and concept-level. Hereby, FedBiP\nsynthesizes images following the client's local data distribution without\ncompromising the privacy regulations. FedBiP is also the first approach to\nsimultaneously address feature space heterogeneity and client data scarcity in\nOSFL. Our method is validated through extensive experiments on three OSFL\nbenchmarks with feature space heterogeneity, as well as on challenging medical\nand satellite image datasets with label heterogeneity. The results demonstrate\nthe effectiveness of FedBiP, which substantially outperforms other OSFL\nmethods.\n","authors":["Haokun Chen","Hang Li","Yao Zhang","Jinhe Bi","Gengyuan Zhang","Yueqi Zhang","Philip Torr","Jindong Gu","Denis Krompass","Volker Tresp"],"pdf_url":"https://arxiv.org/pdf/2410.04810v2.pdf","comment":"CVPR 2025"},{"id":"http://arxiv.org/abs/2410.03011v2","updated":"2025-03-02T17:17:22Z","published":"2024-10-03T21:42:21Z","title":"Towards Understanding the Universality of Transformers for Next-Token\n  Prediction","summary":"  Causal Transformers are trained to predict the next token for a given\ncontext. While it is widely accepted that self-attention is crucial for\nencoding the causal structure of sequences, the precise underlying mechanism\nbehind this in-context autoregressive learning ability remains unclear. In this\npaper, we take a step towards understanding this phenomenon by studying the\napproximation ability of Transformers for next-token prediction. Specifically,\nwe explore the capacity of causal Transformers to predict the next token\n$x_{t+1}$ given an autoregressive sequence $(x_1, \\dots, x_t)$ as a prompt,\nwhere $ x_{t+1} = f(x_t) $, and $ f $ is a context-dependent function that\nvaries with each sequence. On the theoretical side, we focus on specific\ninstances, namely when $ f $ is linear or when $ (x_t)_{t \\geq 1} $ is\nperiodic. We explicitly construct a Transformer (with linear, exponential, or\nsoftmax attention) that learns the mapping $f$ in-context through a causal\nkernel descent method. The causal kernel descent method we propose provably\nestimates $x_{t+1} $ based solely on past and current observations $ (x_1,\n\\dots, x_t) $, with connections to the Kaczmarz algorithm in Hilbert spaces. We\npresent experimental results that validate our theoretical findings and suggest\ntheir applicability to more general mappings $f$.\n","authors":["Michael E. Sander","Gabriel Peyré"],"pdf_url":"https://arxiv.org/pdf/2410.03011v2.pdf","comment":"ICLR 2025, 20 pages"},{"id":"http://arxiv.org/abs/2502.11882v3","updated":"2025-03-02T17:15:11Z","published":"2025-02-17T15:09:45Z","title":"Leveraging Dual Process Theory in Language Agent Framework for Real-time\n  Simultaneous Human-AI Collaboration","summary":"  Agents built on large language models (LLMs) have excelled in turn-by-turn\nhuman-AI collaboration but struggle with simultaneous tasks requiring real-time\ninteraction. Latency issues and the challenge of inferring variable human\nstrategies hinder their ability to make autonomous decisions without explicit\ninstructions. Through experiments with current independent System 1 and System\n2 methods, we validate the necessity of using Dual Process Theory (DPT) in\nreal-time tasks. We propose DPT-Agent, a novel language agent framework that\nintegrates System 1 and System 2 for efficient real-time simultaneous human-AI\ncollaboration. DPT-Agent's System 1 uses a Finite-state Machine (FSM) and\ncode-as-policy for fast, intuitive, and controllable decision-making.\nDPT-Agent's System 2 integrates Theory of Mind (ToM) and asynchronous\nreflection to infer human intentions and perform reasoning-based autonomous\ndecisions. We demonstrate the effectiveness of DPT-Agent through further\nexperiments with rule-based agents and human collaborators, showing significant\nimprovements over mainstream LLM-based frameworks. DPT-Agent can effectively\nhelp LLMs convert correct slow thinking and reasoning into executable actions,\nthereby improving performance. To the best of our knowledge, DPT-Agent is the\nfirst language agent framework that achieves successful real-time simultaneous\nhuman-AI collaboration autonomously. Code of DPT-Agent can be found in\nhttps://github.com/sjtu-marl/DPT-Agent.\n","authors":["Shao Zhang","Xihuai Wang","Wenhao Zhang","Chaoran Li","Junru Song","Tingyu Li","Lin Qiu","Xuezhi Cao","Xunliang Cai","Wen Yao","Weinan Zhang","Xinbing Wang","Ying Wen"],"pdf_url":"https://arxiv.org/pdf/2502.11882v3.pdf","comment":"Preprint under review. Update the experimental results of the\n  DeepSeek-R1 series models, o3-mini-high and o3-mini-medium"},{"id":"http://arxiv.org/abs/2403.18035v4","updated":"2025-03-02T16:41:49Z","published":"2024-03-26T18:40:36Z","title":"Bidirectional Consistency Models","summary":"  Diffusion models (DMs) are capable of generating remarkably high-quality\nsamples by iteratively denoising a random vector, a process that corresponds to\nmoving along the probability flow ordinary differential equation (PF ODE).\nInterestingly, DMs can also invert an input image to noise by moving backward\nalong the PF ODE, a key operation for downstream tasks such as interpolation\nand image editing. However, the iterative nature of this process restricts its\nspeed, hindering its broader application. Recently, Consistency Models (CMs)\nhave emerged to address this challenge by approximating the integral of the PF\nODE, largely reducing the number of iterations. Yet, the absence of an explicit\nODE solver complicates the inversion process. To resolve this, we introduce\nBidirectional Consistency Model (BCM), which learns a single neural network\nthat enables both forward and backward traversal along the PF ODE, efficiently\nunifying generation and inversion tasks within one framework. We can train BCM\nfrom scratch or tune it using a pretrained consistency model, which reduces the\ntraining cost and increases scalability. We demonstrate that BCM enables\none-step generation and inversion while also allowing the use of additional\nsteps to enhance generation quality or reduce reconstruction error. We further\nshowcase BCM's capability in downstream tasks, such as interpolation and\ninpainting. Our code and weights are available at\nhttps://github.com/Mosasaur5526/BCM-iCT-torch.\n","authors":["Liangchen Li","Jiajun He"],"pdf_url":"https://arxiv.org/pdf/2403.18035v4.pdf","comment":"39 pages, 27 figures; a shorter version of this paper was acceppted\n  at the ICML 2024 Workshop on Structured Probabilistic Inference & Generative\n  Modeling"},{"id":"http://arxiv.org/abs/2412.07067v3","updated":"2025-03-02T16:40:03Z","published":"2024-12-10T00:19:28Z","title":"MoE-CAP: Benchmarking Cost, Accuracy and Performance of Sparse\n  Mixture-of-Experts Systems","summary":"  The Mixture-of-Experts (MoE) architecture is increasingly favored for scaling\nLarge Language Models (LLMs). Its key feature, sparse activation, selectively\nactivates only a subset of parameters (experts) per token, reducing memory\nbandwidth and compute FLOPs compared to dense models. To capitalize on this,\nMoE designers leverage heterogeneous compute and memory hardware to lower\nsystem costs. However, the interaction between model sparsity and hardware\nheterogeneity introduces trade-offs in Cost, Accuracy, and Performance (CAP).\nTo address this, we introduce MoE-CAP, a benchmarking method for evaluating\nsparse MoE systems across these three dimensions. Its key innovation is a\nsparsity-aware CAP analysis model, the first to integrate cost, performance,\nand accuracy metrics into a single diagram while estimating the impact of\nsparsity on system performance. MoE-CAP helps practitioners optimize hardware\nprovisioning for an MoE model-or vice versa. MoE-CAP supports various MoE\nmodels and provides more accurate metrics than existing methods.\n","authors":["Yao Fu","Yinsicheng Jiang","Yeqi Huang","Ping Nie","Zhan Lu","Leyang Xue","Congjie He","Man-Kit Sit","Jilong Xue","Li Dong","Ziming Miao","Kai Zou","Edoardo Ponti","Luo Mai"],"pdf_url":"https://arxiv.org/pdf/2412.07067v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.16471v4","updated":"2025-03-02T16:36:29Z","published":"2023-08-31T05:26:14Z","title":"Foundational Policy Acquisition via Multitask Learning for Motor Skill\n  Generation","summary":"  In this study, we propose a multitask reinforcement learning algorithm for\nfoundational policy acquisition to generate novel motor skills.\n\\textcolor{\\hcolor}{Learning the rich representation of the multitask policy is\na challenge in dynamic movement generation tasks because the policy needs to\ncope with changes in goals or environments with different reward functions or\nphysical parameters. Inspired by human sensorimotor adaptation mechanisms, we\ndeveloped the learning pipeline to construct the encoder-decoder networks and\nnetwork selection to facilitate foundational policy acquisition under multiple\nsituations. First, we compared the proposed method with previous multitask\nreinforcement learning methods in the standard multi-locomotion tasks. The\nresults showed that the proposed approach outperformed the baseline methods.\nThen, we applied the proposed method to the ball heading task using a monopod\nrobot model to evaluate skill generation performance. The results showed that\nthe proposed method was able to adapt to novel target positions or\ninexperienced ball restitution coefficients but to acquire a foundational\npolicy network, originally learned for heading motion, which can generate an\nentirely new overhead kicking skill.\n","authors":["Satoshi Yamamori","Jun Morimoto"],"pdf_url":"https://arxiv.org/pdf/2308.16471v4.pdf","comment":"11 pages, 9 figures"},{"id":"http://arxiv.org/abs/2406.03735v2","updated":"2025-03-02T16:21:37Z","published":"2024-06-06T04:19:55Z","title":"Phase-Amplitude Reduction-Based Imitation Learning","summary":"  In this study, we propose the use of the phase-amplitude reduction method to\nconstruct an imitation learning framework. Imitating human movement\ntrajectories is recognized as a promising strategy for generating a range of\nhuman-like robot movements. Unlike previous dynamical system-based imitation\nlearning approaches, our proposed method allows the robot not only to imitate a\nlimit cycle trajectory but also to replicate the transient movement from the\ninitial or disturbed state to the limit cycle. Consequently, our method offers\na safer imitation learning approach that avoids generating unpredictable\nmotions immediately after disturbances or from a specified initial state. We\nfirst validated our proposed method by reconstructing a simple limit-cycle\nattractor. We then compared the proposed approach with a conventional method on\na lemniscate trajectory tracking task with a simulated robot arm. Our findings\nconfirm that our proposed method can more accurately generate transient\nmovements to converge on a target periodic attractor compared to the previous\nstandard approach. Subsequently, we applied our method to a real robot arm to\nimitate periodic human movements.\n","authors":["Satoshi Yamamori","Jun Morimoto"],"pdf_url":"https://arxiv.org/pdf/2406.03735v2.pdf","comment":"21 pages, 8 figures"},{"id":"http://arxiv.org/abs/2502.18960v2","updated":"2025-03-02T16:14:51Z","published":"2025-02-26T09:17:04Z","title":"Nonparametric Heterogeneous Long-term Causal Effect Estimation via Data\n  Combination","summary":"  Long-term causal inference has drawn increasing attention in many scientific\ndomains. Existing methods mainly focus on estimating average long-term causal\neffects by combining long-term observational data and short-term experimental\ndata. However, it is still understudied how to robustly and effectively\nestimate heterogeneous long-term causal effects, significantly limiting\npractical applications. In this paper, we propose several two-stage style\nnonparametric estimators for heterogeneous long-term causal effect estimation,\nincluding propensity-based, regression-based, and multiple robust estimators.\nWe conduct a comprehensive theoretical analysis of their asymptotic properties\nunder mild assumptions, with the ultimate goal of building a better\nunderstanding of the conditions under which some estimators can be expected to\nperform better. Extensive experiments across several semi-synthetic and\nreal-world datasets validate the theoretical results and demonstrate the\neffectiveness of the proposed estimators.\n","authors":["Weilin Chen","Ruichu Cai","Junjie Wan","Zeqin Yang","José Miguel Hernández-Lobato"],"pdf_url":"https://arxiv.org/pdf/2502.18960v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.20138v5","updated":"2025-03-02T15:57:39Z","published":"2024-12-28T12:54:06Z","title":"TradingAgents: Multi-Agents LLM Financial Trading Framework","summary":"  Significant progress has been made in automated problem-solving using\nsocieties of agents powered by large language models (LLMs). In finance,\nefforts have largely focused on single-agent systems handling specific tasks or\nmulti-agent frameworks independently gathering data. However, multi-agent\nsystems' potential to replicate real-world trading firms' collaborative\ndynamics remains underexplored. TradingAgents proposes a novel stock trading\nframework inspired by trading firms, featuring LLM-powered agents in\nspecialized roles such as fundamental analysts, sentiment analysts, technical\nanalysts, and traders with varied risk profiles. The framework includes Bull\nand Bear researcher agents assessing market conditions, a risk management team\nmonitoring exposure, and traders synthesizing insights from debates and\nhistorical data to make informed decisions. By simulating a dynamic,\ncollaborative trading environment, this framework aims to improve trading\nperformance. Detailed architecture and extensive experiments reveal its\nsuperiority over baseline models, with notable improvements in cumulative\nreturns, Sharpe ratio, and maximum drawdown, highlighting the potential of\nmulti-agent LLM frameworks in financial trading. TradingAgents is available at\nhttps://github.com/PioneerFintech.\n","authors":["Yijia Xiao","Edward Sun","Di Luo","Wei Wang"],"pdf_url":"https://arxiv.org/pdf/2412.20138v5.pdf","comment":"Multi-Agent AI in the Real World @ AAAI 2025"},{"id":"http://arxiv.org/abs/2408.11915v2","updated":"2025-03-02T15:55:14Z","published":"2024-08-21T18:06:15Z","title":"Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event\n  Condition For Foley Sound","summary":"  Foley sound synthesis is crucial for multimedia production, enhancing user\nexperience by synchronizing audio and video both temporally and semantically.\nRecent studies on automating this labor-intensive process through\nvideo-to-sound generation face significant challenges. Systems lacking explicit\ntemporal features suffer from poor alignment and controllability, while\ntimestamp-based models require costly and subjective human annotation. We\npropose Video-Foley, a video-to-sound system using Root Mean Square (RMS) as an\nintuitive condition with semantic timbre prompts (audio or text). RMS, a\nframe-level intensity envelope closely related to audio semantics, acts as a\ntemporal event feature to guide audio generation from video. The\nannotation-free self-supervised learning framework consists of two stages,\nVideo2RMS and RMS2Sound, incorporating novel ideas including RMS discretization\nand RMS-ControlNet with a pretrained text-to-audio model. Our extensive\nevaluation shows that Video-Foley achieves state-of-the-art performance in\naudio-visual alignment and controllability for sound timing, intensity, timbre,\nand nuance. Source code, model weights and demos are available on our companion\nwebsite. (https://jnwnlee.github.io/video-foley-demo)\n","authors":["Junwon Lee","Jaekwon Im","Dabin Kim","Juhan Nam"],"pdf_url":"https://arxiv.org/pdf/2408.11915v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.18709v4","updated":"2025-03-02T15:37:39Z","published":"2023-10-28T13:37:52Z","title":"Audio-Visual Instance Segmentation","summary":"  In this paper, we propose a new multi-modal task, termed audio-visual\ninstance segmentation (AVIS), which aims to simultaneously identify, segment\nand track individual sounding object instances in audible videos. To facilitate\nthis research, we introduce a high-quality benchmark named AVISeg, containing\nover 90K instance masks from 26 semantic categories in 926 long videos.\nAdditionally, we propose a strong baseline model for this task. Our model first\nlocalizes sound source within each frame, and condenses object-specific\ncontexts into concise tokens. Then it builds long-range audio-visual\ndependencies between these tokens using window-based attention, and tracks\nsounding objects among the entire video sequences. Extensive experiments reveal\nthat our method performs best on AVISeg, surpassing the existing methods from\nrelated tasks. We further conduct the evaluation on several multi-modal large\nmodels. Unfortunately, they exhibits subpar performance on instance-level sound\nsource localization and temporal perception. We expect that AVIS will inspire\nthe community towards a more comprehensive multi-modal understanding. Dataset\nand code is available at https://github.com/ruohaoguo/avis.\n","authors":["Ruohao Guo","Xianghua Ying","Yaru Chen","Dantong Niu","Guangyao Li","Liao Qu","Yanyu Qi","Jinxing Zhou","Bowei Xing","Wenzhen Yue","Ji Shi","Qixun Wang","Peiliang Zhang","Buwen Liang"],"pdf_url":"https://arxiv.org/pdf/2310.18709v4.pdf","comment":"Accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2412.12164v2","updated":"2025-03-02T15:12:38Z","published":"2024-12-11T19:12:22Z","title":"GAMED: Knowledge Adaptive Multi-Experts Decoupling for Multimodal Fake\n  News Detection","summary":"  Multimodal fake news detection often involves modelling heterogeneous data\nsources, such as vision and language. Existing detection methods typically rely\non fusion effectiveness and cross-modal consistency to model the content,\ncomplicating understanding how each modality affects prediction accuracy.\nAdditionally, these methods are primarily based on static feature modelling,\nmaking it difficult to adapt to the dynamic changes and relationships between\ndifferent data modalities. This paper develops a significantly novel approach,\nGAMED, for multimodal modelling, which focuses on generating distinctive and\ndiscriminative features through modal decoupling to enhance cross-modal\nsynergies, thereby optimizing overall performance in the detection process.\nGAMED leverages multiple parallel expert networks to refine features and\npre-embed semantic knowledge to improve the experts' ability in information\nselection and viewpoint sharing. Subsequently, the feature distribution of each\nmodality is adaptively adjusted based on the respective experts' opinions.\nGAMED also introduces a novel classification technique to dynamically manage\ncontributions from different modalities, while improving the explainability of\ndecisions. Experimental results on the Fakeddit and Yang datasets demonstrate\nthat GAMED performs better than recently developed state-of-the-art models. The\nsource code can be accessed at https://github.com/slz0925/GAMED.\n","authors":["Lingzhi Shen","Yunfei Long","Xiaohao Cai","Imran Razzak","Guanming Chen","Kang Liu","Shoaib Jameel"],"pdf_url":"https://arxiv.org/pdf/2412.12164v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.07189v2","updated":"2025-03-02T15:05:58Z","published":"2024-02-11T12:54:07Z","title":"Improving LSH via Tensorized Random Projection","summary":"  Locality sensitive hashing (LSH) is a fundamental algorithmic toolkit used by\ndata scientists for approximate nearest neighbour search problems that have\nbeen used extensively in many large scale data processing applications such as\nnear duplicate detection, nearest neighbour search, clustering, etc. In this\nwork, we aim to propose faster and space efficient locality sensitive hash\nfunctions for Euclidean distance and cosine similarity for tensor data.\nTypically, the naive approach for obtaining LSH for tensor data involves first\nreshaping the tensor into vectors, followed by applying existing LSH methods\nfor vector data $E2LSH$ and $SRP$. However, this approach becomes impractical\nfor higher order tensors because the size of the reshaped vector becomes\nexponential in the order of the tensor. Consequently, the size of LSH\nparameters increases exponentially. To address this problem, we suggest two\nmethods for LSH for Euclidean distance and cosine similarity, namely\n$CP-E2LSH$, $TT-E2LSH$, and $CP-SRP$, $TT-SRP$, respectively, building on $CP$\nand tensor train $(TT)$ decompositions techniques. Our approaches are space\nefficient and can be efficiently applied to low rank $CP$ or $TT$ tensors. We\nprovide a rigorous theoretical analysis of our proposal on their correctness\nand efficacy.\n","authors":["Bhisham Dev Verma","Rameshwar Pratap"],"pdf_url":"https://arxiv.org/pdf/2402.07189v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.14154v2","updated":"2025-03-02T14:41:12Z","published":"2024-07-19T09:34:04Z","title":"Where is the Testbed for my Federated Learning Research?","summary":"  Progressing beyond centralized AI is of paramount importance, yet,\ndistributed AI solutions, in particular various federated learning (FL)\nalgorithms, are often not comprehensively assessed, which prevents the research\ncommunity from identifying the most promising approaches and practitioners from\nbeing convinced that a certain solution is deployment-ready. The largest hurdle\ntowards FL algorithm evaluation is the difficulty of conducting real-world\nexperiments over a variety of FL client devices and different platforms, with\ndifferent datasets and data distribution, all while assessing various\ndimensions of algorithm performance, such as inference accuracy, energy\nconsumption, and time to convergence, to name a few. In this paper, we present\nCoLExT, a real-world testbed for FL research. CoLExT is designed to streamline\nexperimentation with custom FL algorithms in a rich testbed configuration\nspace, with a large number of heterogeneous edge devices, ranging from\nsingle-board computers to smartphones, and provides real-time collection and\nvisualization of a variety of metrics through automatic instrumentation.\nAccording to our evaluation, porting FL algorithms to CoLExT requires minimal\ninvolvement from the developer, and the instrumentation introduces minimal\nresource usage overhead. Furthermore, through an initial investigation\ninvolving popular FL algorithms running on CoLExT, we reveal previously unknown\ntrade-offs, inefficiencies, and programming bugs.\n","authors":["Janez Božič","Amândio R. Faustino","Boris Radovič","Marco Canini","Veljko Pejović"],"pdf_url":"https://arxiv.org/pdf/2407.14154v2.pdf","comment":"SEC 2024"},{"id":"http://arxiv.org/abs/2410.10781v2","updated":"2025-03-02T14:37:53Z","published":"2024-10-14T17:50:28Z","title":"When Attention Sink Emerges in Language Models: An Empirical View","summary":"  Language Models (LMs) assign significant attention to the first token, even\nif it is not semantically important, which is known as attention sink. This\nphenomenon has been widely adopted in applications such as streaming/long\ncontext generation, KV cache optimization, inference acceleration, model\nquantization, and others. Despite its widespread use, a deep understanding of\nattention sink in LMs is still lacking. In this work, we first demonstrate that\nattention sinks exist universally in LMs with various inputs, even in small\nmodels. Furthermore, attention sink is observed to emerge during the LM\npre-training, motivating us to investigate how optimization, data distribution,\nloss function, and model architecture in LM pre-training influence its\nemergence. We highlight that attention sink emerges after effective\noptimization on sufficient training data. The sink position is highly\ncorrelated with the loss function and data distribution. Most importantly, we\nfind that attention sink acts more like key biases, storing extra attention\nscores, which could be non-informative and not contribute to the value\ncomputation. We also observe that this phenomenon (at least partially) stems\nfrom tokens' inner dependence on attention scores as a result of softmax\nnormalization. After relaxing such dependence by replacing softmax attention\nwith other attention operations, such as sigmoid attention without\nnormalization, attention sinks do not emerge in LMs up to 1B parameters. The\ncode is available at https://github.com/sail-sg/Attention-Sink.\n","authors":["Xiangming Gu","Tianyu Pang","Chao Du","Qian Liu","Fengzhuo Zhang","Cunxiao Du","Ye Wang","Min Lin"],"pdf_url":"https://arxiv.org/pdf/2410.10781v2.pdf","comment":"ICLR 2025 (Spotlight)"},{"id":"http://arxiv.org/abs/2410.07137v2","updated":"2025-03-02T14:28:33Z","published":"2024-10-09T17:53:06Z","title":"Cheating Automatic LLM Benchmarks: Null Models Achieve High Win Rates","summary":"  Automatic LLM benchmarks, such as AlpacaEval 2.0, Arena-Hard-Auto, and\nMT-Bench, have become popular for evaluating language models due to their\ncost-effectiveness and scalability compared to human evaluation. Achieving high\nwin rates on these benchmarks can significantly boost the promotional impact of\nnewly released language models. This promotional benefit may motivate tricks,\nsuch as manipulating model output length or style to game win rates, even\nthough several mechanisms have been developed to control length and disentangle\nstyle to reduce gameability. Nonetheless, we show that even a \"null model\" that\nalways outputs a constant response (irrelevant to input instructions) can cheat\nautomatic benchmarks and achieve top-ranked win rates: an 86.5% LC win rate on\nAlpacaEval 2.0; an 83.0 score on Arena-Hard-Auto; and a 9.55 score on MT-Bench.\nMoreover, the crafted cheating outputs are transferable because we assume that\nthe instructions of these benchmarks (e.g., 805 samples of AlpacaEval 2.0) are\nprivate and cannot be accessed. While our experiments are primarily\nproof-of-concept, an adversary could use LLMs to generate more imperceptible\ncheating responses, unethically benefiting from high win rates and promotional\nimpact. Our findings call for the development of anti-cheating mechanisms for\nreliable automatic benchmarks. The code is available at\nhttps://github.com/sail-sg/Cheating-LLM-Benchmarks.\n","authors":["Xiaosen Zheng","Tianyu Pang","Chao Du","Qian Liu","Jing Jiang","Min Lin"],"pdf_url":"https://arxiv.org/pdf/2410.07137v2.pdf","comment":"ICLR 2025 (Oral)"},{"id":"http://arxiv.org/abs/2410.16699v2","updated":"2025-03-02T14:18:13Z","published":"2024-10-22T05:11:45Z","title":"Graph Transformers Dream of Electric Flow","summary":"  We show theoretically and empirically that the linear Transformer, when\napplied to graph data, can implement algorithms that solve canonical problems\nsuch as electric flow and eigenvector decomposition. The Transformer has access\nto information on the input graph only via the graph's incidence matrix. We\npresent explicit weight configurations for implementing each algorithm, and we\nbound the constructed Transformers' errors by the errors of the underlying\nalgorithms. Our theoretical findings are corroborated by experiments on\nsynthetic data. Additionally, on a real-world molecular regression task, we\nobserve that the linear Transformer is capable of learning a more effective\npositional encoding than the default one based on Laplacian eigenvectors. Our\nwork is an initial step towards elucidating the inner-workings of the\nTransformer for graph data. Code is available at\nhttps://github.com/chengxiang/LinearGraphTransformer\n","authors":["Xiang Cheng","Lawrence Carin","Suvrit Sra"],"pdf_url":"https://arxiv.org/pdf/2410.16699v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.15252v2","updated":"2025-03-02T14:10:09Z","published":"2024-05-24T06:22:01Z","title":"Accelerating 3D Molecule Generation via Jointly Geometric Optimal\n  Transport","summary":"  This paper proposes a new 3D molecule generation framework, called GOAT, for\nfast and effective 3D molecule generation based on the flow-matching optimal\ntransport objective. Specifically, we formulate a geometric transport formula\nfor measuring the cost of mapping multi-modal features (e.g., continuous atom\ncoordinates and categorical atom types) between a base distribution and a\ntarget data distribution. Our formula is solved within a joint, equivariant,\nand smooth representation space. This is achieved by transforming the\nmulti-modal features into a continuous latent space with equivariant networks.\nIn addition, we find that identifying optimal distributional coupling is\nnecessary for fast and effective transport between any two distributions. We\nfurther propose a mechanism for estimating and purifying optimal coupling to\ntrain the flow model with optimal transport. By doing so, GOAT can turn\narbitrary distribution couplings into new deterministic couplings, leading to\nan estimated optimal transport plan for fast 3D molecule generation. The\npurification filters out the subpar molecules to ensure the ultimate generation\nquality. We theoretically and empirically prove that the proposed optimal\ncoupling estimation and purification yield transport plan with non-increasing\ncost. Finally, extensive experiments show that GOAT enjoys the efficiency of\nsolving geometric optimal transport, leading to a double speedup compared to\nthe sub-optimal method while achieving the best generation quality regarding\nvalidity, uniqueness, and novelty. The code is available at\nhttps://github.com/WanyuGroup/ICLR2025-GOAT.\n","authors":["Haokai Hong","Wanyu Lin","Kay Chen Tan"],"pdf_url":"https://arxiv.org/pdf/2405.15252v2.pdf","comment":"Published as a conference paper at ICLR 2025"},{"id":"http://arxiv.org/abs/2302.01310v3","updated":"2025-03-02T13:29:19Z","published":"2023-02-02T18:33:34Z","title":"Knowledge Gradient for Multi-Objective Bayesian Optimization with\n  Decoupled Evaluations","summary":"  Multi-objective Bayesian optimization aims to find the Pareto front of\ntrade-offs between a set of expensive objectives while collecting as few\nsamples as possible. In some cases, it is possible to evaluate the objectives\nseparately, and a different latency or evaluation cost can be associated with\neach objective. This decoupling of the objectives presents an opportunity to\nlearn the Pareto front faster by avoiding unnecessary, expensive evaluations.\nWe propose a scalarization based knowledge gradient acquisition function which\naccounts for the different evaluation costs of the objectives. We prove\nasymptotic consistency of the estimator of the optimum for an arbitrary,\nD-dimensional, real compact search space and show empirically that the\nalgorithm performs comparably with the state of the art and significantly\noutperforms versions which always evaluate both objectives.\n","authors":["Jack M. Buckingham","Sebastian Rojas Gonzalez","Juergen Branke"],"pdf_url":"https://arxiv.org/pdf/2302.01310v3.pdf","comment":"36 pages. This preprint has not undergone peer review (when\n  applicable) or any post-submission improvements or corrections. The Version\n  of Record of this contribution is published in 'Evolutionary Multi-Criterion\n  Optimization', LNCS 15513, and is available online at\n  https://doi.org/10.1007/978-981-96-3538-2_9"},{"id":"http://arxiv.org/abs/2411.12556v2","updated":"2025-03-02T13:29:03Z","published":"2024-11-19T15:15:45Z","title":"UMGAD: Unsupervised Multiplex Graph Anomaly Detection","summary":"  Graph anomaly detection (GAD) is a critical task in graph machine learning,\nwith the primary objective of identifying anomalous nodes that deviate\nsignificantly from the majority. This task is widely applied in various\nreal-world scenarios, including fraud detection and social network analysis.\nHowever, existing GAD methods still face two major challenges: (1) They are\noften limited to detecting anomalies in single-type interaction graphs and\nstruggle with multiple interaction types in multiplex heterogeneous graphs. (2)\nIn unsupervised scenarios, selecting appropriate anomaly score thresholds\nremains a significant challenge for accurate anomaly detection. To address the\nabove challenges, we propose a novel Unsupervised Multiplex Graph Anomaly\nDetection method, named UMGAD. We first learn multi-relational correlations\namong nodes in multiplex heterogeneous graphs and capture anomaly information\nduring node attribute and structure reconstruction through graph-masked\nautoencoder (GMAE). Then, to further extract abnormal information, we generate\nattribute-level and subgraph-level augmented-view graphs respectively, and\nperform attribute and structure reconstruction through GMAE. Finally, we learn\nto optimize node attributes and structural features through contrastive\nlearning between original-view and augmented-view graphs to improve the model's\nability to capture anomalies. Meanwhile, we also propose a new anomaly score\nthreshold selection strategy, which allows the model to be independent of\nground truth information in real unsupervised scenarios. Extensive experiments\non four datasets show that our UMGAD significantly outperforms state-of-the-art\nmethods, achieving average improvements of 13.48% in AUC and 11.68% in Macro-F1\nacross all datasets.\n","authors":["Xiang Li","Jianpeng Qi","Zhongying Zhao","Guanjie Zheng","Lei Cao","Junyu Dong","Yanwei Yu"],"pdf_url":"https://arxiv.org/pdf/2411.12556v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.02820v2","updated":"2025-03-02T13:14:11Z","published":"2022-08-04T02:22:29Z","title":"MOVE: Effective and Harmless Ownership Verification via Embedded\n  External Features","summary":"  Currently, deep neural networks (DNNs) are widely adopted in different\napplications. Despite its commercial values, training a well-performing DNN is\nresource-consuming. Accordingly, the well-trained model is valuable\nintellectual property for its owner. However, recent studies revealed the\nthreats of model stealing, where the adversaries can obtain a function-similar\ncopy of the victim model, even when they can only query the model. In this\npaper, we propose an effective and harmless model ownership verification (MOVE)\nto defend against different types of model stealing simultaneously, without\nintroducing new security risks. In general, we conduct the ownership\nverification by verifying whether a suspicious model contains the knowledge of\ndefender-specified external features. Specifically, we embed the external\nfeatures by modifying a few training samples with style transfer. We then train\na meta-classifier to determine whether a model is stolen from the victim. This\napproach is inspired by the understanding that the stolen models should contain\nthe knowledge of features learned by the victim model. In particular,\n\\revision{we develop our MOVE method under both white-box and black-box\nsettings and analyze its theoretical foundation to provide comprehensive model\nprotection.} Extensive experiments on benchmark datasets verify the\neffectiveness of our method and its resistance to potential adaptive attacks.\nThe codes for reproducing the main experiments of our method are available at\nhttps://github.com/THUYimingLi/MOVE.\n","authors":["Yiming Li","Linghui Zhu","Xiaojun Jia","Yang Bai","Yong Jiang","Shu-Tao Xia","Xiaochun Cao","Kui Ren"],"pdf_url":"https://arxiv.org/pdf/2208.02820v2.pdf","comment":"This paper has been accepted by IEEE TPAMI 2025. It is the journal\n  extension of our conference paper in AAAI 2022\n  (https://ojs.aaai.org/index.php/AAAI/article/view/20036). 18 pages"},{"id":"http://arxiv.org/abs/2312.08671v2","updated":"2025-03-02T13:13:42Z","published":"2023-12-14T06:08:35Z","title":"Permutation-Invariant Graph Partitioning:How Graph Neural Networks\n  Capture Structural Interactions?","summary":"  Graph Neural Networks (GNNs) have paved the way for being a cornerstone in\ngraph-related learning tasks. Yet, the ability of GNNs to capture structural\ninteractions within graphs remains under-explored. In this work, we address\nthis gap by drawing on the insight that permutation invariant graph\npartitioning enables a powerful way of exploring structural interactions. We\nestablish theoretical connections between permutation invariant graph\npartitioning and graph isomorphism, and then propose Graph Partitioning Neural\nNetworks (GPNNs), a novel architecture that efficiently enhances the expressive\npower of GNNs in learning structural interactions. We analyze how partitioning\nschemes and structural interactions contribute to GNN expressivity and their\ntrade-offs with complexity. Empirically, we demonstrate that GPNNs outperform\nexisting GNN models in capturing structural interactions across diverse graph\nbenchmark tasks.\n","authors":["Asela Hevapathige","Qing Wang"],"pdf_url":"https://arxiv.org/pdf/2312.08671v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.15812v2","updated":"2025-03-02T12:28:24Z","published":"2024-06-22T10:36:04Z","title":"Intrinsic Dimension Correlation: uncovering nonlinear connections in\n  multimodal representations","summary":"  To gain insight into the mechanisms behind machine learning methods, it is\ncrucial to establish connections among the features describing data points.\nHowever, these correlations often exhibit a high-dimensional and strongly\nnonlinear nature, which makes them challenging to detect using standard\nmethods. This paper exploits the entanglement between intrinsic dimensionality\nand correlation to propose a metric that quantifies the (potentially nonlinear)\ncorrelation between high-dimensional manifolds. We first validate our method on\nsynthetic data in controlled environments, showcasing its advantages and\ndrawbacks compared to existing techniques. Subsequently, we extend our analysis\nto large-scale applications in neural network representations. Specifically, we\nfocus on latent representations of multimodal data, uncovering clear\ncorrelations between paired visual and textual embeddings, whereas existing\nmethods struggle significantly in detecting similarity. Our results indicate\nthe presence of highly nonlinear correlation patterns between latent manifolds.\n","authors":["Lorenzo Basile","Santiago Acevedo","Luca Bortolussi","Fabio Anselmi","Alex Rodriguez"],"pdf_url":"https://arxiv.org/pdf/2406.15812v2.pdf","comment":"Accepted at ICLR 2025"},{"id":"http://arxiv.org/abs/2405.01229v2","updated":"2025-03-02T12:27:07Z","published":"2024-05-02T12:18:14Z","title":"Boosting Jailbreak Attack with Momentum","summary":"  Large Language Models (LLMs) have achieved remarkable success across diverse\ntasks, yet they remain vulnerable to adversarial attacks, notably the\nwell-known jailbreak attack. In particular, the Greedy Coordinate Gradient\n(GCG) attack has demonstrated efficacy in exploiting this vulnerability by\noptimizing adversarial prompts through a combination of gradient heuristics and\ngreedy search. However, the efficiency of this attack has become a bottleneck\nin the attacking process. To mitigate this limitation, in this paper we rethink\nthe generation of the adversarial prompts through an optimization lens, aiming\nto stabilize the optimization process and harness more heuristic insights from\nprevious optimization iterations. Specifically, we propose the\n\\textbf{M}omentum \\textbf{A}ccelerated G\\textbf{C}G (\\textbf{MAC}) attack,\nwhich integrates a momentum term into the gradient heuristic to boost and\nstabilize the random search for tokens in adversarial prompts. Experimental\nresults showcase the notable enhancement achieved by MAC over baselines in\nterms of attack success rate and optimization efficiency. Moreover, we\ndemonstrate that MAC can still exhibit superior performance for transfer\nattacks and models under defense mechanisms. Our code is available at\nhttps://github.com/weizeming/momentum-attack-llm.\n","authors":["Yihao Zhang","Zeming Wei"],"pdf_url":"https://arxiv.org/pdf/2405.01229v2.pdf","comment":"Accepted by ICASSP 2025"},{"id":"http://arxiv.org/abs/2412.05994v2","updated":"2025-03-02T12:21:49Z","published":"2024-12-08T16:58:29Z","title":"PIG: Physics-Informed Gaussians as Adaptive Parametric Mesh\n  Representations","summary":"  The numerical approximation of partial differential equations (PDEs) using\nneural networks has seen significant advancements through Physics-Informed\nNeural Networks (PINNs). Despite their straightforward optimization framework\nand flexibility in implementing various PDEs, PINNs often suffer from limited\naccuracy due to the spectral bias of Multi-Layer Perceptrons (MLPs), which\nstruggle to effectively learn high-frequency and nonlinear components.\nRecently, parametric mesh representations in combination with neural networks\nhave been investigated as a promising approach to eliminate the inductive bias\nof MLPs. However, they usually require high-resolution grids and a large number\nof collocation points to achieve high accuracy while avoiding overfitting. In\naddition, the fixed positions of the mesh parameters restrict their\nflexibility, making accurate approximation of complex PDEs challenging. To\novercome these limitations, we propose Physics-Informed Gaussians (PIGs), which\ncombine feature embeddings using Gaussian functions with a lightweight neural\nnetwork. Our approach uses trainable parameters for the mean and variance of\neach Gaussian, allowing for dynamic adjustment of their positions and shapes\nduring training. This adaptability enables our model to optimally approximate\nPDE solutions, unlike models with fixed parameter positions. Furthermore, the\nproposed approach maintains the same optimization framework used in PINNs,\nallowing us to benefit from their excellent properties. Experimental results\nshow the competitive performance of our model across various PDEs,\ndemonstrating its potential as a robust tool for solving complex PDEs. Our\nproject page is available at\nhttps://namgyukang.github.io/Physics-Informed-Gaussians/\n","authors":["Namgyu Kang","Jaemin Oh","Youngjoon Hong","Eunbyung Park"],"pdf_url":"https://arxiv.org/pdf/2412.05994v2.pdf","comment":"Project page:\n  https://namgyukang.github.io/Physics-Informed-Gaussians/"},{"id":"http://arxiv.org/abs/2410.12025v2","updated":"2025-03-02T12:20:56Z","published":"2024-10-15T19:46:09Z","title":"Geometric Inductive Biases of Deep Networks: The Role of Data and\n  Architecture","summary":"  In this paper, we propose the $\\textit{geometric invariance hypothesis\n(GIH)}$, which argues that the input space curvature of a neural network\nremains invariant under transformation in certain architecture-dependent\ndirections during training. We investigate a simple, non-linear binary\nclassification problem residing on a plane in a high dimensional space and\nobserve that$\\unicode{x2014}$unlike MPLs$\\unicode{x2014}$ResNets fail to\ngeneralize depending on the orientation of the plane. Motivated by this\nexample, we define a neural network's $\\textbf{average geometry}$ and\n$\\textbf{average geometry evolution}$ as compact\n$\\textit{architecture-dependent}$ summaries of the model's input-output\ngeometry and its evolution during training. By investigating the average\ngeometry evolution at initialization, we discover that the geometry of a neural\nnetwork evolves according to the data covariance projected onto its average\ngeometry. This means that the geometry only changes in a subset of the input\nspace when the average geometry is low-rank, such as in ResNets. This causes an\narchitecture-dependent invariance property in the input space curvature, which\nwe dub GIH. Finally, we present extensive experimental results to observe the\nconsequences of GIH and how it relates to generalization in neural networks.\n","authors":["Sajad Movahedi","Antonio Orvieto","Seyed-Mohsen Moosavi-Dezfooli"],"pdf_url":"https://arxiv.org/pdf/2410.12025v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.14309v2","updated":"2025-03-02T12:04:35Z","published":"2025-02-20T06:51:42Z","title":"On Theoretical Limits of Learning with Label Differential Privacy","summary":"  Label differential privacy (DP) is designed for learning problems involving\nprivate labels and public features. While various methods have been proposed\nfor learning under label DP, the theoretical limits remain largely unexplored.\nIn this paper, we investigate the fundamental limits of learning with label DP\nin both local and central models for both classification and regression tasks,\ncharacterized by minimax convergence rates. We establish lower bounds by\nconverting each task into a multiple hypothesis testing problem and bounding\nthe test error. Additionally, we develop algorithms that yield matching upper\nbounds. Our results demonstrate that under label local DP (LDP), the risk has a\nsignificantly faster convergence rate than that under full LDP, i.e. protecting\nboth features and labels, indicating the advantages of relaxing the DP\ndefinition to focus solely on labels. In contrast, under the label central DP\n(CDP), the risk is only reduced by a constant factor compared to full DP,\nindicating that the relaxation of CDP only has limited benefits on the\nperformance.\n","authors":["Puning Zhao","Chuan Ma","Li Shen","Shaowei Wang","Rongfei Fan"],"pdf_url":"https://arxiv.org/pdf/2502.14309v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.04942v2","updated":"2025-03-02T11:55:15Z","published":"2024-07-06T03:22:57Z","title":"FOSP: Fine-tuning Offline Safe Policy through World Models","summary":"  Offline Safe Reinforcement Learning (RL) seeks to address safety constraints\nby learning from static datasets and restricting exploration. However, these\napproaches heavily rely on the dataset and struggle to generalize to unseen\nscenarios safely. In this paper, we aim to improve safety during the deployment\nof vision-based robotic tasks through online fine-tuning an offline pretrained\npolicy. To facilitate effective fine-tuning, we introduce model-based RL, which\nis known for its data efficiency. Specifically, our method employs in-sample\noptimization to improve offline training efficiency while incorporating\nreachability guidance to ensure safety. After obtaining an offline safe policy,\na safe policy expansion approach is leveraged for online fine-tuning. The\nperformance of our method is validated on simulation benchmarks with five\nvision-only tasks and through real-world robot deployment using limited data.\nIt demonstrates that our approach significantly improves the generalization of\noffline policies to unseen safety-constrained scenarios. To the best of our\nknowledge, this is the first work to explore offline-to-online RL for safe\ngeneralization tasks.\n","authors":["Chenyang Cao","Yucheng Xin","Silang Wu","Longxiang He","Zichen Yan","Junbo Tan","Xueqian Wang"],"pdf_url":"https://arxiv.org/pdf/2407.04942v2.pdf","comment":"32 pages, ICLR2025"},{"id":"http://arxiv.org/abs/2411.02275v2","updated":"2025-03-02T11:48:40Z","published":"2024-11-04T17:05:37Z","title":"Breaking the Reclustering Barrier in Centroid-based Deep Clustering","summary":"  This work investigates an important phenomenon in centroid-based deep\nclustering (DC) algorithms: Performance quickly saturates after a period of\nrapid early gains. Practitioners commonly address early saturation with\nperiodic reclustering, which we demonstrate to be insufficient to address\nperformance plateaus. We call this phenomenon the \"reclustering barrier\" and\nempirically show when the reclustering barrier occurs, what its underlying\nmechanisms are, and how it is possible to Break the Reclustering Barrier with\nour algorithm BRB. BRB avoids early over-commitment to initial clusterings and\nenables continuous adaptation to reinitialized clustering targets while\nremaining conceptually simple. Applying our algorithm to widely-used\ncentroid-based DC algorithms, we show that (1) BRB consistently improves\nperformance across a wide range of clustering benchmarks, (2) BRB enables\ntraining from scratch, and (3) BRB performs competitively against\nstate-of-the-art DC algorithms when combined with a contrastive loss. We\nrelease our code and pre-trained models at\nhttps://github.com/Probabilistic-and-Interactive-ML/breaking-the-reclustering-barrier .\n","authors":["Lukas Miklautz","Timo Klein","Kevin Sidak","Collin Leiber","Thomas Lang","Andrii Shkabrii","Sebastian Tschiatschek","Claudia Plant"],"pdf_url":"https://arxiv.org/pdf/2411.02275v2.pdf","comment":"Accepted at ICLR 2025 (Camera-ready version)"},{"id":"http://arxiv.org/abs/2407.05649v4","updated":"2025-03-02T11:37:49Z","published":"2024-07-08T06:21:56Z","title":"Greener GRASS: Enhancing GNNs with Encoding, Rewiring, and Attention","summary":"  Graph Neural Networks (GNNs) have become important tools for machine learning\non graph-structured data. In this paper, we explore the synergistic combination\nof graph encoding, graph rewiring, and graph attention, by introducing Graph\nAttention with Stochastic Structures (GRASS), a novel GNN architecture. GRASS\nutilizes relative random walk probabilities (RRWP) encoding and a novel\ndecomposed variant (D-RRWP) to efficiently capture structural information. It\nrewires the input graph by superimposing a random regular graph to enhance\nlong-range information propagation. It also employs a novel additive attention\nmechanism tailored for graph-structured data. Our empirical evaluations\ndemonstrate that GRASS achieves state-of-the-art performance on multiple\nbenchmark datasets, including a 20.3% reduction in mean absolute error on the\nZINC dataset.\n","authors":["Tongzhou Liao","Barnabás Póczos"],"pdf_url":"https://arxiv.org/pdf/2407.05649v4.pdf","comment":"Published as a conference paper at ICLR 2025"},{"id":"http://arxiv.org/abs/2410.02242v2","updated":"2025-03-02T11:32:27Z","published":"2024-10-03T06:30:27Z","title":"Robust Weight Initialization for Tanh Neural Networks with Fixed Point\n  Analysis","summary":"  As a neural network's depth increases, it can improve generalization\nperformance. However, training deep networks is challenging due to gradient and\nsignal propagation issues. To address these challenges, extensive theoretical\nresearch and various methods have been introduced. Despite these advances,\neffective weight initialization methods for tanh neural networks remain\ninsufficiently investigated. This paper presents a novel weight initialization\nmethod for neural networks with tanh activation function. Based on an analysis\nof the fixed points of the function $\\tanh(ax)$, the proposed method aims to\ndetermine values of $a$ that mitigate activation saturation. A series of\nexperiments on various classification datasets and physics-informed neural\nnetworks demonstrates that the proposed method outperforms Xavier\ninitialization methods~(with or without normalization) in terms of robustness\nacross different network sizes, data efficiency, and convergence speed. Code is\navailable at https://github.com/1HyunwooLee/Tanh-Init\n","authors":["Hyunwoo Lee","Hayoung Choi","Hyunju Kim"],"pdf_url":"https://arxiv.org/pdf/2410.02242v2.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2502.19649v2","updated":"2025-03-02T11:23:58Z","published":"2025-02-27T00:40:01Z","title":"Taxonomy, Opportunities, and Challenges of Representation Engineering\n  for Large Language Models","summary":"  Representation Engineering (RepE) is a novel paradigm for controlling the\nbehavior of LLMs. Unlike traditional approaches that modify inputs or fine-tune\nthe model, RepE directly manipulates the model's internal representations. As a\nresult, it may offer more effective, interpretable, data-efficient, and\nflexible control over models' behavior. We present the first comprehensive\nsurvey of RepE for LLMs, reviewing the rapidly growing literature to address\nkey questions: What RepE methods exist and how do they differ? For what\nconcepts and problems has RepE been applied? What are the strengths and\nweaknesses of RepE compared to other methods? To answer these, we propose a\nunified framework describing RepE as a pipeline comprising representation\nidentification, operationalization, and control. We posit that while RepE\nmethods offer significant potential, challenges remain, including managing\nmultiple concepts, ensuring reliability, and preserving models' performance.\nTowards improving RepE, we identify opportunities for experimental and\nmethodological improvements and construct a guide for best practices.\n","authors":["Jan Wehner","Sahar Abdelnabi","Daniel Tan","David Krueger","Mario Fritz"],"pdf_url":"https://arxiv.org/pdf/2502.19649v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04803v4","updated":"2025-03-02T11:22:35Z","published":"2024-10-07T07:27:39Z","title":"Timer-XL: Long-Context Transformers for Unified Time Series Forecasting","summary":"  We present Timer-XL, a causal Transformer for unified time series\nforecasting. To uniformly predict multidimensional time series, we generalize\nnext token prediction, predominantly adopted for 1D token sequences, to\nmultivariate next token prediction. The paradigm formulates various forecasting\ntasks as a long-context prediction problem. We opt for decoder-only\nTransformers that capture causal dependencies from varying-length contexts for\nunified forecasting, making predictions on non-stationary univariate time\nseries, multivariate series with complicated dynamics and correlations, as well\nas covariate-informed contexts that include exogenous variables. Technically,\nwe propose a universal TimeAttention to capture fine-grained intra- and\ninter-series dependencies of flattened time series tokens (patches), which is\nfurther enhanced by deft position embedding for temporal causality and variable\nequivalence. Timer-XL achieves state-of-the-art performance across\ntask-specific forecasting benchmarks through a unified approach. Based on\nlarge-scale pre-training, Timer-XL achieves state-of-the-art zero-shot\nperformance, making it a promising architecture for pre-trained time series\nmodels. Code is available at this repository:\nhttps://github.com/thuml/Timer-XL.\n","authors":["Yong Liu","Guo Qin","Xiangdong Huang","Jianmin Wang","Mingsheng Long"],"pdf_url":"https://arxiv.org/pdf/2410.04803v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.02957v4","updated":"2025-03-02T10:59:52Z","published":"2024-03-05T13:25:44Z","title":"On the Asymptotic Mean Square Error Optimality of Diffusion Models","summary":"  Diffusion models (DMs) as generative priors have recently shown great\npotential for denoising tasks but lack theoretical understanding with respect\nto their mean square error (MSE) optimality. This paper proposes a novel\ndenoising strategy inspired by the structure of the MSE-optimal conditional\nmean estimator (CME). The resulting DM-based denoiser can be conveniently\nemployed using a pre-trained DM, being particularly fast by truncating reverse\ndiffusion steps and not requiring stochastic re-sampling. We present a\ncomprehensive (non-)asymptotic optimality analysis of the proposed\ndiffusion-based denoiser, demonstrating polynomial-time convergence to the CME\nunder mild conditions. Our analysis also derives a novel Lipschitz constant\nthat depends solely on the DM's hyperparameters. Further, we offer a new\nperspective on DMs, showing that they inherently combine an asymptotically\noptimal denoiser with a powerful generator, modifiable by switching re-sampling\nin the reverse process on or off. The theoretical findings are thoroughly\nvalidated with experiments based on various benchmark datasets\n","authors":["Benedikt Fesl","Benedikt Böck","Florian Strasser","Michael Baur","Michael Joham","Wolfgang Utschick"],"pdf_url":"https://arxiv.org/pdf/2403.02957v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.13706v3","updated":"2025-03-02T10:52:11Z","published":"2022-12-28T05:43:57Z","title":"End-to-End Modeling Hierarchical Time Series Using Autoregressive\n  Transformer and Conditional Normalizing Flow based Reconciliation","summary":"  Multivariate time series forecasting with hierarchical structure is pervasive\nin real-world applications, demanding not only predicting each level of the\nhierarchy, but also reconciling all forecasts to ensure coherency, i.e., the\nforecasts should satisfy the hierarchical aggregation constraints. Moreover,\nthe disparities of statistical characteristics between levels can be huge,\nworsened by non-Gaussian distributions and non-linear correlations. To this\nextent, we propose a novel end-to-end hierarchical time series forecasting\nmodel, based on conditioned normalizing flow-based autoregressive transformer\nreconciliation, to represent complex data distribution while simultaneously\nreconciling the forecasts to ensure coherency. Unlike other state-of-the-art\nmethods, we achieve the forecasting and reconciliation simultaneously without\nrequiring any explicit post-processing step. In addition, by harnessing the\npower of deep model, we do not rely on any assumption such as unbiased\nestimates or Gaussian distribution. Our evaluation experiments are conducted on\nfour real-world hierarchical datasets from different industrial domains (three\npublic ones and a dataset from the application servers of Alipay's data center)\nand the preliminary results demonstrate efficacy of our proposed method.\n","authors":["Shiyu Wang","Fan Zhou","Yinbo Sun","Lintao Ma","James Zhang","Yangfei Zheng"],"pdf_url":"https://arxiv.org/pdf/2212.13706v3.pdf","comment":"Accepted by the 22nd IEEE International Conference on Data Mining\n  (ICDM2022)"},{"id":"http://arxiv.org/abs/2402.05569v5","updated":"2025-03-02T10:48:32Z","published":"2024-02-08T11:10:39Z","title":"Training-Free Message Passing for Learning on Hypergraphs","summary":"  Hypergraphs are crucial for modelling higher-order interactions in real-world\ndata. Hypergraph neural networks (HNNs) effectively utilise these structures by\nmessage passing to generate informative node features for various downstream\ntasks like node classification. However, the message passing module in existing\nHNNs typically requires a computationally intensive training process, which\nlimits their practical use. To tackle this challenge, we propose an alternative\napproach by decoupling the usage of hypergraph structural information from the\nmodel learning stage. This leads to a novel training-free message passing\nmodule, named TF-MP-Module, which can be precomputed in the data preprocessing\nstage, thereby reducing the computational burden. We refer to the hypergraph\nneural network equipped with our TF-MP-Module as TF-HNN. We theoretically\nsupport the efficiency and effectiveness of TF-HNN by showing that: 1) It is\nmore training-efficient compared to existing HNNs; 2) It utilises as much\ninformation as existing HNNs for node feature generation; and 3) It is robust\nagainst the oversmoothing issue while using long-range interactions.\nExperiments based on seven real-world hypergraph benchmarks in node\nclassification and hyperlink prediction show that, compared to state-of-the-art\nHNNs, TF-HNN exhibits both competitive performance and superior training\nefficiency. Specifically, on the large-scale benchmark, Trivago, TF-HNN\noutperforms the node classification accuracy of the best baseline by 10% with\njust 1% of the training time of that baseline.\n","authors":["Bohan Tang","Zexi Liu","Keyue Jiang","Siheng Chen","Xiaowen Dong"],"pdf_url":"https://arxiv.org/pdf/2402.05569v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14666v2","updated":"2025-03-02T10:38:32Z","published":"2024-10-18T17:56:11Z","title":"DiscoGraMS: Enhancing Movie Screen-Play Summarization using Movie\n  Character-Aware Discourse Graph","summary":"  Summarizing movie screenplays presents a unique set of challenges compared to\nstandard document summarization. Screenplays are not only lengthy, but also\nfeature a complex interplay of characters, dialogues, and scenes, with numerous\ndirect and subtle relationships and contextual nuances that are difficult for\nmachine learning models to accurately capture and comprehend. Recent attempts\nat screenplay summarization focus on fine-tuning transformer-based pre-trained\nmodels, but these models often fall short in capturing long-term dependencies\nand latent relationships, and frequently encounter the \"lost in the middle\"\nissue. To address these challenges, we introduce DiscoGraMS, a novel resource\nthat represents movie scripts as a movie character-aware discourse graph (CaD\nGraph). This approach is well-suited for various downstream tasks, such as\nsummarization, question-answering, and salience detection. The model aims to\npreserve all salient information, offering a more comprehensive and faithful\nrepresentation of the screenplay's content. We further explore a baseline\nmethod that combines the CaD Graph with the corresponding movie script through\na late fusion of graph and text modalities, and we present very initial\npromising results.\n","authors":["Maitreya Prafulla Chitale","Uday Bindal","Rajakrishnan Rajkumar","Rahul Mishra"],"pdf_url":"https://arxiv.org/pdf/2410.14666v2.pdf","comment":"Accepted at NAACL 2025 (Main)"},{"id":"http://arxiv.org/abs/2411.15216v2","updated":"2025-03-02T10:23:51Z","published":"2024-11-20T16:17:40Z","title":"Dist Loss: Enhancing Regression in Few-Shot Region through Distribution\n  Distance Constraint","summary":"  Imbalanced data distributions are prevalent in real-world scenarios, posing\nsignificant challenges in both imbalanced classification and imbalanced\nregression tasks. They often cause deep learning models to overfit in areas of\nhigh sample density (many-shot regions) while underperforming in areas of low\nsample density (few-shot regions). This characteristic restricts the utility of\ndeep learning models in various sectors, notably healthcare, where areas with\nfew-shot data hold greater clinical relevance. While recent studies have shown\nthe benefits of incorporating distribution information in imbalanced\nclassification tasks, such strategies are rarely explored in imbalanced\nregression. In this paper, we address this issue by introducing a novel loss\nfunction, termed Dist Loss, designed to minimize the distribution distance\nbetween the model's predictions and the target labels in a differentiable\nmanner, effectively integrating distribution information into model training.\nDist Loss enables deep learning models to regularize their output distribution\nduring training, effectively enhancing their focus on few-shot regions. We have\nconducted extensive experiments across three datasets spanning computer vision\nand healthcare: IMDB-WIKI-DIR, AgeDB-DIR, and ECG-Ka-DIR. The results\ndemonstrate that Dist Loss effectively mitigates the negative impact of\nimbalanced data distribution on model performance, achieving state-of-the-art\nresults in sparse data regions. Furthermore, Dist Loss is easy to integrate,\ncomplementing existing methods.\n","authors":["Guangkun Nie","Gongzheng Tang","Shenda Hong"],"pdf_url":"https://arxiv.org/pdf/2411.15216v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.14897v2","updated":"2025-03-02T10:18:09Z","published":"2025-02-17T21:35:18Z","title":"Market-Derived Financial Sentiment Analysis: Context-Aware Language\n  Models for Crypto Forecasting","summary":"  Financial Sentiment Analysis (FSA) traditionally relies on human-annotated\nsentiment labels to infer investor sentiment and forecast market movements.\nHowever, inferring the potential market impact of words based on their\nhuman-perceived intentions is inherently challenging. We hypothesize that the\nhistorical market reactions to words, offer a more reliable indicator of their\npotential impact on markets than subjective sentiment interpretations by human\nannotators. To test this hypothesis, a market-derived labeling approach is\nproposed to assign tweet labels based on ensuing short-term price trends,\nenabling the language model to capture the relationship between textual signals\nand market dynamics directly. A domain-specific language model was fine-tuned\non these labels, achieving up to an 11% improvement in short-term trend\nprediction accuracy over traditional sentiment-based benchmarks. Moreover, by\nincorporating market and temporal context through prompt-tuning, the proposed\ncontext-aware language model demonstrated an accuracy of 89.6% on a curated\ndataset of 227 impactful Bitcoin-related news events with significant market\nimpacts. Aggregating daily tweet predictions into trading signals, our method\noutperformed traditional fusion models (which combine sentiment-based and\nprice-based predictions). It challenged the assumption that sentiment-based\nsignals are inferior to price-based predictions in forecasting market\nmovements. Backtesting these signals across three distinct market regimes\nyielded robust Sharpe ratios of up to 5.07 in trending markets and 3.73 in\nneutral markets. Our findings demonstrate that language models can serve as\neffective short-term market predictors. This paradigm shift underscores the\nuntapped capabilities of language models in financial decision-making and opens\nnew avenues for market prediction applications.\n","authors":["Hamid Moradi-Kamali","Mohammad-Hossein Rajabi-Ghozlou","Mahdi Ghazavi","Ali Soltani","Amirreza Sattarzadeh","Reza Entezari-Maleki"],"pdf_url":"https://arxiv.org/pdf/2502.14897v2.pdf","comment":"13 pages, 6 figures"}],"Multimedia":[{"id":"http://arxiv.org/abs/2410.04810v2","updated":"2025-03-02T17:18:04Z","published":"2024-10-07T07:45:18Z","title":"FedBiP: Heterogeneous One-Shot Federated Learning with Personalized\n  Latent Diffusion Models","summary":"  One-Shot Federated Learning (OSFL), a special decentralized machine learning\nparadigm, has recently gained significant attention. OSFL requires only a\nsingle round of client data or model upload, which reduces communication costs\nand mitigates privacy threats compared to traditional FL. Despite these\npromising prospects, existing methods face challenges due to client data\nheterogeneity and limited data quantity when applied to real-world OSFL\nsystems. Recently, Latent Diffusion Models (LDM) have shown remarkable\nadvancements in synthesizing high-quality images through pretraining on\nlarge-scale datasets, thereby presenting a potential solution to overcome these\nissues. However, directly applying pretrained LDM to heterogeneous OSFL results\nin significant distribution shifts in synthetic data, leading to performance\ndegradation in classification models trained on such data. This issue is\nparticularly pronounced in rare domains, such as medical imaging, which are\nunderrepresented in LDM's pretraining data. To address this challenge, we\npropose Federated Bi-Level Personalization (FedBiP), which personalizes the\npretrained LDM at both instance-level and concept-level. Hereby, FedBiP\nsynthesizes images following the client's local data distribution without\ncompromising the privacy regulations. FedBiP is also the first approach to\nsimultaneously address feature space heterogeneity and client data scarcity in\nOSFL. Our method is validated through extensive experiments on three OSFL\nbenchmarks with feature space heterogeneity, as well as on challenging medical\nand satellite image datasets with label heterogeneity. The results demonstrate\nthe effectiveness of FedBiP, which substantially outperforms other OSFL\nmethods.\n","authors":["Haokun Chen","Hang Li","Yao Zhang","Jinhe Bi","Gengyuan Zhang","Yueqi Zhang","Philip Torr","Jindong Gu","Denis Krompass","Volker Tresp"],"pdf_url":"https://arxiv.org/pdf/2410.04810v2.pdf","comment":"CVPR 2025"},{"id":"http://arxiv.org/abs/2408.11915v2","updated":"2025-03-02T15:55:14Z","published":"2024-08-21T18:06:15Z","title":"Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event\n  Condition For Foley Sound","summary":"  Foley sound synthesis is crucial for multimedia production, enhancing user\nexperience by synchronizing audio and video both temporally and semantically.\nRecent studies on automating this labor-intensive process through\nvideo-to-sound generation face significant challenges. Systems lacking explicit\ntemporal features suffer from poor alignment and controllability, while\ntimestamp-based models require costly and subjective human annotation. We\npropose Video-Foley, a video-to-sound system using Root Mean Square (RMS) as an\nintuitive condition with semantic timbre prompts (audio or text). RMS, a\nframe-level intensity envelope closely related to audio semantics, acts as a\ntemporal event feature to guide audio generation from video. The\nannotation-free self-supervised learning framework consists of two stages,\nVideo2RMS and RMS2Sound, incorporating novel ideas including RMS discretization\nand RMS-ControlNet with a pretrained text-to-audio model. Our extensive\nevaluation shows that Video-Foley achieves state-of-the-art performance in\naudio-visual alignment and controllability for sound timing, intensity, timbre,\nand nuance. Source code, model weights and demos are available on our companion\nwebsite. (https://jnwnlee.github.io/video-foley-demo)\n","authors":["Junwon Lee","Jaekwon Im","Dabin Kim","Juhan Nam"],"pdf_url":"https://arxiv.org/pdf/2408.11915v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.18709v4","updated":"2025-03-02T15:37:39Z","published":"2023-10-28T13:37:52Z","title":"Audio-Visual Instance Segmentation","summary":"  In this paper, we propose a new multi-modal task, termed audio-visual\ninstance segmentation (AVIS), which aims to simultaneously identify, segment\nand track individual sounding object instances in audible videos. To facilitate\nthis research, we introduce a high-quality benchmark named AVISeg, containing\nover 90K instance masks from 26 semantic categories in 926 long videos.\nAdditionally, we propose a strong baseline model for this task. Our model first\nlocalizes sound source within each frame, and condenses object-specific\ncontexts into concise tokens. Then it builds long-range audio-visual\ndependencies between these tokens using window-based attention, and tracks\nsounding objects among the entire video sequences. Extensive experiments reveal\nthat our method performs best on AVISeg, surpassing the existing methods from\nrelated tasks. We further conduct the evaluation on several multi-modal large\nmodels. Unfortunately, they exhibits subpar performance on instance-level sound\nsource localization and temporal perception. We expect that AVIS will inspire\nthe community towards a more comprehensive multi-modal understanding. Dataset\nand code is available at https://github.com/ruohaoguo/avis.\n","authors":["Ruohao Guo","Xianghua Ying","Yaru Chen","Dantong Niu","Guangyao Li","Liao Qu","Yanyu Qi","Jinxing Zhou","Bowei Xing","Wenzhen Yue","Ji Shi","Qixun Wang","Peiliang Zhang","Buwen Liang"],"pdf_url":"https://arxiv.org/pdf/2310.18709v4.pdf","comment":"Accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2410.11817v2","updated":"2025-03-02T07:05:19Z","published":"2024-10-15T17:46:31Z","title":"Improving Long-Text Alignment for Text-to-Image Diffusion Models","summary":"  The rapid advancement of text-to-image (T2I) diffusion models has enabled\nthem to generate unprecedented results from given texts. However, as text\ninputs become longer, existing encoding methods like CLIP face limitations, and\naligning the generated images with long texts becomes challenging. To tackle\nthese issues, we propose LongAlign, which includes a segment-level encoding\nmethod for processing long texts and a decomposed preference optimization\nmethod for effective alignment training. For segment-level encoding, long texts\nare divided into multiple segments and processed separately. This method\novercomes the maximum input length limits of pretrained encoding models. For\npreference optimization, we provide decomposed CLIP-based preference models to\nfine-tune diffusion models. Specifically, to utilize CLIP-based preference\nmodels for T2I alignment, we delve into their scoring mechanisms and find that\nthe preference scores can be decomposed into two components: a text-relevant\npart that measures T2I alignment and a text-irrelevant part that assesses other\nvisual aspects of human preference. Additionally, we find that the\ntext-irrelevant part contributes to a common overfitting problem during\nfine-tuning. To address this, we propose a reweighting strategy that assigns\ndifferent weights to these two components, thereby reducing overfitting and\nenhancing alignment. After fine-tuning $512 \\times 512$ Stable Diffusion (SD)\nv1.5 for about 20 hours using our method, the fine-tuned SD outperforms\nstronger foundation models in T2I alignment, such as PixArt-$\\alpha$ and\nKandinsky v2.2. The code is available at\nhttps://github.com/luping-liu/LongAlign.\n","authors":["Luping Liu","Chao Du","Tianyu Pang","Zehan Wang","Chongxuan Li","Dong Xu"],"pdf_url":"https://arxiv.org/pdf/2410.11817v2.pdf","comment":null}]},"2025-03-01T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2409.01482v2","updated":"2025-03-01T23:34:06Z","published":"2024-09-02T22:17:18Z","title":"Masked Mixers for Language Generation and Retrieval","summary":"  Attention mechanisms that confer selective focus on a strict subset of input\nelements are nearly ubiquitous in language models today. We posit there to be\ndownside to the use of attention: most input information is lost. In support of\nthis idea we observe poor input representation accuracy in transformers and\nmore accurate representation in what we term masked mixers, which replace\nself-attention with masked convolutions. The masked mixer learns causal\nlanguage modeling more efficiently than early transformer implementations and\neven outperforms optimized, current transformers when training on small (<512)\nbut not larger context windows. Evidence is presented for the hypothesis that\ndifferences in transformer and masked mixer training efficiencies for various\ntasks are best predicted by input representation accuracy, or equivalently\nglobal invertibility. We hypothesize that the information loss exhibited by\ntransformers would be more detrimental to retrieval than generation, as the\nformer is more closely approximated by a bijective and thus invertible\nfunction. We find that masked mixers are more effective retrieval models both\nwhen the pretrained embedding model is unchanged as well as when the embedding\nmodel is modified via cosine similarity-based InfoNCE loss minimization. A\nsmall masked mixer is shown to outperform a large and near state-of-the-art\ntransformer-based retrieval model, despite the latter being trained with many\norders of magnitude more data and compute.\n","authors":["Benjamin L. Badger"],"pdf_url":"https://arxiv.org/pdf/2409.01482v2.pdf","comment":"31 pages, 8 figures, 3 tables, 9 supplementary figures, 13\n  supplementary tables"},{"id":"http://arxiv.org/abs/2410.14853v2","updated":"2025-03-01T23:22:15Z","published":"2024-10-18T20:35:28Z","title":"DFlow: Diverse Dialogue Flow Simulation with Large Language Models","summary":"  Developing language model-based dialogue agents requires effective data to\ntrain models that can follow specific task logic. However, most existing data\nsimulation methods focus on increasing diversity in language, topics, or\ndialogue acts at the utterance level, largely neglecting a critical aspect of\ntask logic diversity at the dialogue level. This paper proposes a novel data\nsimulation method designed to enhance the diversity of synthetic dialogues by\nfocusing on task execution logic. Our method uses LLMs to generate decision\ntree-structured task plans, which enables the derivation of diverse dialogue\ntrajectories for a given task. Each trajectory, referred to as a \"dialog flow\",\nguides the generation of a multi-turn dialogue that follows a unique\ntrajectory. We apply this method to generate a task-oriented dialogue dataset\ncomprising 3,886 dialogue flows across 15 different domains. We validate the\neffectiveness of this dataset using the next action prediction task, where\nmodels fine-tuned on our dataset outperform strong baselines, including GPT-4.\nUpon acceptance of this paper, we plan to release the code and data publicly.\n","authors":["Wanyu Du","Song Feng","James Gung","Lijia Sun","Yi Zhang","Saab Mansour","Yanjun Qi"],"pdf_url":"https://arxiv.org/pdf/2410.14853v2.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2408.09632v4","updated":"2025-03-01T23:19:07Z","published":"2024-08-19T01:30:14Z","title":"MoDeGPT: Modular Decomposition for Large Language Model Compression","summary":"  Large Language Models (LLMs) have reshaped the landscape of artificial\nintelligence by demonstrating exceptional performance across various tasks.\nHowever, substantial computational requirements make their deployment\nchallenging on devices with limited resources. Recently, compression methods\nusing low-rank matrix techniques have shown promise, yet these often lead to\ndegraded accuracy or introduce significant overhead in parameters and inference\nlatency. This paper introduces \\textbf{Mo}dular \\textbf{De}composition\n(MoDeGPT), a novel structured compression framework that does not need recovery\nfine-tuning while resolving the above drawbacks. MoDeGPT partitions the\nTransformer block into modules comprised of matrix pairs and reduces the hidden\ndimensions via reconstructing the module-level outputs. MoDeGPT is developed\nbased on a theoretical framework that utilizes three well-established matrix\ndecomposition algorithms -- Nystr\\\"om approximation, CR decomposition, and SVD\n-- and applies them to our redefined transformer modules. Our comprehensive\nexperiments show MoDeGPT, without backward propagation, matches or surpasses\nprevious structured compression methods that rely on gradient information, and\nsaves 98% of compute costs on compressing a 13B model. On \\textsc{Llama}-2/3\nand OPT models, MoDeGPT maintains 90-95% zero-shot performance with 25-30%\ncompression rates. Moreover, the compression can be done on a single GPU within\na few hours and increases the inference throughput by up to 46%.\n","authors":["Chi-Heng Lin","Shangqian Gao","James Seale Smith","Abhishek Patel","Shikhar Tuli","Yilin Shen","Hongxia Jin","Yen-Chang Hsu"],"pdf_url":"https://arxiv.org/pdf/2408.09632v4.pdf","comment":"31 pages, 9 figures"},{"id":"http://arxiv.org/abs/2410.12735v3","updated":"2025-03-01T23:03:21Z","published":"2024-10-16T16:51:01Z","title":"CREAM: Consistency Regularized Self-Rewarding Language Models","summary":"  Recent self-rewarding large language models (LLM) have successfully applied\nLLM-as-a-Judge to iteratively improve the alignment performance without the\nneed of human annotations for preference data. These methods commonly utilize\nthe same LLM to act as both the policy model (which generates responses) and\nthe reward model (which scores and ranks those responses). The ranked responses\nare then used as preference pairs to train the LLM via direct alignment\ntechnologies (e.g. DPO). However, it is noteworthy that throughout this\nprocess, there is no guarantee of accuracy in the rewarding and ranking, which\nis critical for ensuring accurate rewards and high-quality preference data.\nEmpirical results from relatively small LLMs (e.g., 7B parameters) also\nindicate that improvements from self-rewarding may diminish after several\niterations in certain situations, which we hypothesize is due to accumulated\nbias in the reward system. This bias can lead to unreliable preference data for\ntraining the LLM. To address this issue, we first formulate and analyze the\ngeneralized iterative preference fine-tuning framework for self-rewarding\nlanguage model. We then introduce the regularization to this generalized\nframework to mitigate the overconfident preference labeling in the\nself-rewarding process. Based on this theoretical insight, we propose a\nConsistency Regularized sElf-rewarding lAnguage Model (CREAM) that leverages\nthe consistency of rewards across different iterations to regularize the\nself-rewarding training, helping the model to learn from more reliable\npreference data. With this explicit regularization, our empirical results\ndemonstrate the superiority of CREAM in improving both reward consistency and\nalignment performance. The code is publicly available at\nhttps://github.com/Raibows/CREAM.\n","authors":["Zhaoyang Wang","Weilei He","Zhiyuan Liang","Xuchao Zhang","Chetan Bansal","Ying Wei","Weitong Zhang","Huaxiu Yao"],"pdf_url":"https://arxiv.org/pdf/2410.12735v3.pdf","comment":"To appear at ICLR 2025"},{"id":"http://arxiv.org/abs/2406.04604v4","updated":"2025-03-01T20:47:54Z","published":"2024-06-07T03:27:51Z","title":"Learning Task Decomposition to Assist Humans in Competitive Programming","summary":"  When using language models (LMs) to solve complex problems, humans might\nstruggle to understand the LM-generated solutions and repair the flawed ones.\nTo assist humans in repairing them, we propose to automatically decompose\ncomplex solutions into multiple simpler pieces that correspond to specific\nsubtasks. We introduce a novel objective for learning task decomposition,\ntermed assistive value (AssistV), which measures the feasibility and speed for\nhumans to repair the decomposed solution. We collect a dataset of human repair\nexperiences on different decomposed solutions. Utilizing the collected data as\nin-context examples, we then learn to critique, refine, and rank decomposed\nsolutions to improve AssistV. We validate our method under competitive\nprogramming problems: under 177 hours of human study, our method enables\nnon-experts to solve 33.3\\% more problems, speeds them up by 3.3x, and empowers\nthem to match unassisted experts.\n","authors":["Jiaxin Wen","Ruiqi Zhong","Pei Ke","Zhihong Shao","Hongning Wang","Minlie Huang"],"pdf_url":"https://arxiv.org/pdf/2406.04604v4.pdf","comment":"ACL 2024 Main Conference"},{"id":"http://arxiv.org/abs/2407.13193v3","updated":"2025-03-01T20:23:07Z","published":"2024-07-18T06:06:53Z","title":"Retrieval-Augmented Generation for Natural Language Processing: A Survey","summary":"  Large language models (LLMs) have demonstrated great success in various\nfields, benefiting from their huge amount of parameters that store knowledge.\nHowever, LLMs still suffer from several key issues, such as hallucination\nproblems, knowledge update issues, and lacking domain-specific expertise. The\nappearance of retrieval-augmented generation (RAG), which leverages an external\nknowledge database to augment LLMs, makes up those drawbacks of LLMs. This\npaper reviews all significant techniques of RAG, especially in the retriever\nand the retrieval fusions. Besides, tutorial codes are provided for\nimplementing the representative techniques in RAG. This paper further discusses\nthe RAG update, including RAG with/without knowledge update. Then, we introduce\nRAG evaluation and benchmarking, as well as the application of RAG in\nrepresentative NLP tasks and industrial scenarios. Finally, this paper\ndiscusses RAG's future directions and challenges for promoting this field's\ndevelopment.\n","authors":["Shangyu Wu","Ying Xiong","Yufei Cui","Haolun Wu","Can Chen","Ye Yuan","Lianming Huang","Xue Liu","Tei-Wei Kuo","Nan Guan","Chun Jason Xue"],"pdf_url":"https://arxiv.org/pdf/2407.13193v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.19607v2","updated":"2025-03-01T19:33:15Z","published":"2025-02-26T22:45:08Z","title":"Revisiting Word Embeddings in the LLM Era","summary":"  Large Language Models (LLMs) have recently shown remarkable advancement in\nvarious NLP tasks. As such, a popular trend has emerged lately where NLP\nresearchers extract word/sentence/document embeddings from these large\ndecoder-only models and use them for various inference tasks with promising\nresults. However, it is still unclear whether the performance improvement of\nLLM-induced embeddings is merely because of scale or whether underlying\nembeddings they produce significantly differ from classical encoding models\nlike Word2Vec, GloVe, Sentence-BERT (SBERT) or Universal Sentence Encoder\n(USE). This is the central question we investigate in the paper by\nsystematically comparing classical decontextualized and contextualized word\nembeddings with the same for LLM-induced embeddings. Our results show that LLMs\ncluster semantically related words more tightly and perform better on analogy\ntasks in decontextualized settings. However, in contextualized settings,\nclassical models like SimCSE often outperform LLMs in sentence-level similarity\nassessment tasks, highlighting their continued relevance for fine-grained\nsemantics.\n","authors":["Yash Mahajan","Matthew Freestone","Sathyanarayanan Aakur","Santu Karmaker"],"pdf_url":"https://arxiv.org/pdf/2502.19607v2.pdf","comment":"This work was intended as a replacement of the older version,\n  arXiv:2402.11094, and any subsequent updates will appear there"},{"id":"http://arxiv.org/abs/2402.11094v3","updated":"2025-03-01T19:27:41Z","published":"2024-02-16T21:47:30Z","title":"Revisiting Word Embeddings in the LLM Era","summary":"  Large Language Models (LLMs) have recently shown remarkable advancement in\nvarious NLP tasks. As such, a popular trend has emerged lately where NLP\nresearchers extract word/sentence/document embeddings from these large\ndecoder-only models and use them for various inference tasks with promising\nresults. However, it is still unclear whether the performance improvement of\nLLM-induced embeddings is merely because of scale or whether underlying\nembeddings they produce significantly differ from classical encoding models\nlike Word2Vec, GloVe, Sentence-BERT (SBERT) or Universal Sentence Encoder\n(USE). This is the central question we investigate in the paper by\nsystematically comparing classical decontextualized and contextualized word\nembeddings with the same for LLM-induced embeddings. Our results show that LLMs\ncluster semantically related words more tightly and perform better on analogy\ntasks in decontextualized settings. However, in contextualized settings,\nclassical models like SimCSE often outperform LLMs in sentence-level similarity\nassessment tasks, highlighting their continued relevance for fine-grained\nsemantics.\n","authors":["Yash Mahajan","Matthew Freestone","Naman Bansal","Sathyanarayanan Aakur","Shubhra Kanti Karmaker Santu"],"pdf_url":"https://arxiv.org/pdf/2402.11094v3.pdf","comment":"This is an updated version of the older version: 2402.11094. We\n  accidentally submitted this article as a new submission (2502.19607), which\n  we have requested to withdraw. This version has 30 pages and 22 figures"},{"id":"http://arxiv.org/abs/2403.08694v4","updated":"2025-03-01T19:25:49Z","published":"2024-03-13T16:57:57Z","title":"TeaMs-RL: Teaching LLMs to Generate Better Instruction Datasets via\n  Reinforcement Learning","summary":"  The development of Large Language Models (LLMs) often confronts challenges\nstemming from the heavy reliance on human annotators in the reinforcement\nlearning with human feedback (RLHF) framework, or the frequent and costly\nexternal queries tied to the self-instruct paradigm. In this work, we pivot to\nReinforcement Learning (RL) -- but with a twist. Diverging from the typical\nRLHF, which refines LLMs following instruction data training, we use RL to\ndirectly generate the foundational instruction dataset that alone suffices for\nfine-tuning. Our method, TeaMs-RL, uses a suite of textual operations and\nrules, prioritizing the diversification of training datasets. It facilitates\nthe generation of high-quality data without excessive reliance on external\nadvanced models, paving the way for a single fine-tuning step and negating the\nneed for subsequent RLHF stages. Our findings highlight key advantages of our\napproach: reduced need for human involvement and fewer model queries (only\n5.73% of the strong baseline's total), along with enhanced capabilities of LLMs\nin crafting and comprehending complex instructions compared to strong\nbaselines, and substantially improved model privacy protection. Code is\navailable at the link: https://github.com/SafeRL-Lab/TeaMs-RL\n","authors":["Shangding Gu","Alois Knoll","Ming Jin"],"pdf_url":"https://arxiv.org/pdf/2403.08694v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.09102v2","updated":"2025-03-01T19:06:35Z","published":"2024-10-09T12:52:41Z","title":"Instructional Segment Embedding: Improving LLM Safety with Instruction\n  Hierarchy","summary":"  Large Language Models (LLMs) are susceptible to security and safety threats,\nsuch as prompt injection, prompt extraction, and harmful requests. One major\ncause of these vulnerabilities is the lack of an instruction hierarchy. Modern\nLLM architectures treat all inputs equally, failing to distinguish between and\nprioritize various types of instructions, such as system messages, user\nprompts, and data. As a result, lower-priority user prompts may override more\ncritical system instructions, including safety protocols. Existing approaches\nto achieving instruction hierarchy, such as delimiters and instruction-based\ntraining, do not address this issue at the architectural level. We introduce\nthe Instructional Segment Embedding (ISE) technique, inspired by BERT, to\nmodern large language models, which embeds instruction priority information\ndirectly into the model. This approach enables models to explicitly\ndifferentiate and prioritize various instruction types, significantly improving\nsafety against malicious prompts that attempt to override priority rules. Our\nexperiments on the Structured Query and Instruction Hierarchy benchmarks\ndemonstrate an average robust accuracy increase of up to 15.75% and 18.68%,\nrespectively. Furthermore, we observe an improvement in instruction-following\ncapability of up to 4.1% evaluated on AlpacaEval. Overall, our approach offers\na promising direction for enhancing the safety and effectiveness of LLM\narchitectures.\n","authors":["Tong Wu","Shujian Zhang","Kaiqiang Song","Silei Xu","Sanqiang Zhao","Ravi Agrawal","Sathish Reddy Indurthi","Chong Xiang","Prateek Mittal","Wenxuan Zhou"],"pdf_url":"https://arxiv.org/pdf/2410.09102v2.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2410.20513v4","updated":"2025-03-01T18:58:42Z","published":"2024-10-27T16:52:21Z","title":"Self-correction is Not An Innate Capability in Large Language Models: A\n  Case Study of Moral Self-correction","summary":"  Though there has been intensive attention to the self-correction capability\nof Large Language Models (LLMs), conclusions regarding its effectiveness remain\nvaried. In this paper, we investigate a fundamental question: is moral\nself-correction an innate capability in LLMs? To explore this, we conduct (1) a\nmechanistic analysis of how key components of self-correction, such as\nChain-of-Thought (CoT) reasoning and external feedback, interact to enable\nmoral self-correction; and (2) a behavioral analysis of LLMs' ability to\ndistinguish between desired and undesired outputs, introducing a\nself-distinguish framework. Our mechanistic analysis reveals that LLMs struggle\nto effectively leverage helpful feedback, and conflicts can arise between\nfeedback and CoT reasoning. These limitations suggest that LLMs fail to\nidentify useful contextual information, instead prioritizing their own internal\nknowledge. Additionally, our behavioral analysis indicates that LLMs struggle\nto differentiate among their own outputs. Based on these empirical findings\nacross two analytical dimensions, mechanism and behavior, we argue that moral\nself-correction is not an innate capability of LLMs.\n","authors":["Zimo Qi","Guangliang Liu","Kristen Marie Johnson","Lu Cheng"],"pdf_url":"https://arxiv.org/pdf/2410.20513v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.00053v3","updated":"2025-03-01T18:42:10Z","published":"2024-05-28T21:38:20Z","title":"Dual Process Learning: Controlling Use of In-Context vs. In-Weights\n  Strategies with Weight Forgetting","summary":"  Language models have the ability to perform in-context learning (ICL),\nallowing them to flexibly adapt their behavior based on context. This contrasts\nwith in-weights learning (IWL), where memorized information is encoded in model\nparameters after iterated observations of data. An ideal model should be able\nto flexibly deploy both of these abilities. Despite their apparent ability to\nlearn in-context, language models are known to struggle when faced with unseen\nor rarely seen tokens (Land & Bartolo, 2024). Hence, we study\n$\\textbf{structural in-context learning}$, which we define as the ability of a\nmodel to execute in-context learning on arbitrary novel tokens -- so called\nbecause the model must generalize on the basis of e.g. sentence structure or\ntask structure, rather than content encoded in token embeddings. We study\nstructural in-context algorithms on both synthetic and naturalistic tasks using\ntoy models, masked language models, and autoregressive language models. We find\nthat structural ICL appears before quickly disappearing early in LM\npretraining. While it has been shown that ICL can diminish during training\n(Singh et al., 2023), we find that prior work does not account for structural\nICL. Building on Chen et al. (2024) 's active forgetting method, we introduce\npretraining and finetuning methods that can modulate the preference for\nstructural ICL and IWL. Importantly, this allows us to induce a $\\textit{dual\nprocess strategy}$ where in-context and in-weights solutions coexist within a\nsingle model.\n","authors":["Suraj Anand","Michael A. Lepori","Jack Merullo","Ellie Pavlick"],"pdf_url":"https://arxiv.org/pdf/2406.00053v3.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2405.01649v4","updated":"2025-03-01T17:24:49Z","published":"2024-05-02T18:12:08Z","title":"Improving Complex Reasoning over Knowledge Graph with Logic-Aware\n  Curriculum Tuning","summary":"  Answering complex queries over incomplete knowledge graphs (KGs) is a\nchallenging job. Most previous works have focused on learning entity/relation\nembeddings and simulating first-order logic operators with various neural\nnetworks. However, they are bottlenecked by the inability to share world\nknowledge to improve logical reasoning, thus resulting in suboptimal\nperformance. In this paper, we propose a complex reasoning schema over KG upon\nlarge language models (LLMs), containing a curriculum-based logical-aware\ninstruction tuning framework, named LACT. Specifically, we augment the\narbitrary first-order logical queries via binary tree decomposition, to\nstimulate the reasoning capability of LLMs. To address the difficulty gap among\ndifferent types of complex queries, we design a simple and flexible logic-aware\ncurriculum learning framework. Experiments across widely used datasets\ndemonstrate that LACT has substantial improvements~(brings an average +5.5% MRR\nscore) over advanced methods, achieving the new state-of-the-art.\n","authors":["Tianle Xia","Liang Ding","Guojia Wan","Yibing Zhan","Bo Du","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2405.01649v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.17173v2","updated":"2025-03-01T17:23:31Z","published":"2025-02-24T14:09:45Z","title":"Cheems: A Practical Guidance for Building and Evaluating Chinese Reward\n  Models from Scratch","summary":"  Reward models (RMs) are crucial for aligning large language models (LLMs)\nwith human preferences. However, most RM research is centered on English and\nrelies heavily on synthetic resources, which leads to limited and less reliable\ndatasets and benchmarks for Chinese. To address this gap, we introduce\nCheemsBench, a fully human-annotated RM evaluation benchmark within Chinese\ncontexts, and CheemsPreference, a large-scale and diverse preference dataset\nannotated through human-machine collaboration to support Chinese RM training.\nWe systematically evaluate open-source discriminative and generative RMs on\nCheemsBench and observe significant limitations in their ability to capture\nhuman preferences in Chinese scenarios. Additionally, based on\nCheemsPreference, we construct an RM that achieves state-of-the-art performance\non CheemsBench, demonstrating the necessity of human supervision in RM\ntraining. Our findings reveal that scaled AI-generated data struggles to fully\ncapture human preferences, emphasizing the importance of high-quality human\nsupervision in RM development.\n","authors":["Xueru Wen","Jie Lou","Zichao Li","Yaojie Lu","Xing Yu","Yuqiu Ji","Guohai Xu","Hongyu Lin","Ben He","Xianpei Han","Le Sun","Debing Zhang"],"pdf_url":"https://arxiv.org/pdf/2502.17173v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.17631v2","updated":"2025-03-01T17:06:43Z","published":"2023-10-26T17:48:58Z","title":"JudgeLM: Fine-tuned Large Language Models are Scalable Judges","summary":"  Evaluating Large Language Models (LLMs) in open-ended scenarios is\nchallenging because existing benchmarks and metrics can not measure them\ncomprehensively. To address this problem, we propose to fine-tune LLMs as\nscalable judges (JudgeLM) to evaluate LLMs efficiently and effectively in\nopen-ended benchmarks. We first propose a comprehensive, large-scale,\nhigh-quality dataset containing task seeds, LLMs-generated answers, and\nGPT-4-generated judgments for fine-tuning high-performance judges, as well as a\nnew benchmark for evaluating the judges. We train JudgeLM at different scales\nfrom 7B, 13B, to 33B parameters, and conduct a systematic analysis of its\ncapabilities and behaviors. We then analyze the key biases in fine-tuning LLM\nas a judge and consider them as position bias, knowledge bias, and format bias.\nTo address these issues, JudgeLM introduces a bag of techniques including swap\naugmentation, reference support, and reference drop, which clearly enhance the\njudge's performance. JudgeLM obtains the state-of-the-art judge performance on\nboth the existing PandaLM benchmark and our proposed new benchmark. Our JudgeLM\nis efficient and the JudgeLM-7B only needs 3 minutes to judge 5K samples with 8\nA100 GPUs. JudgeLM obtains high agreement with the teacher judge, achieving an\nagreement exceeding 90% that even surpasses human-to-human agreement. JudgeLM\nalso demonstrates extended capabilities in being judges of the single answer,\nmultimodal models, multiple answers, multi-turn chat, etc. Code is available at\nhttps://github.com/baaivision/JudgeLM.\n","authors":["Lianghui Zhu","Xinggang Wang","Xinlong Wang"],"pdf_url":"https://arxiv.org/pdf/2310.17631v2.pdf","comment":"JudgeLM is accepted by ICLR2025. Code is available at\n  https://github.com/baaivision/JudgeLM"},{"id":"http://arxiv.org/abs/2411.17637v2","updated":"2025-03-01T16:07:45Z","published":"2024-11-26T17:55:37Z","title":"On Limitations of LLM as Annotator for Low Resource Languages","summary":"  Low-resource languages face significant challenges due to the lack of\nsufficient linguistic data, resources, and tools for tasks such as supervised\nlearning, annotation, and classification. This shortage hinders the development\nof accurate models and datasets, making it difficult to perform critical NLP\ntasks like sentiment analysis or hate speech detection. To bridge this gap,\nLarge Language Models (LLMs) present an opportunity for potential annotators,\ncapable of generating datasets and resources for these underrepresented\nlanguages. In this paper, we focus on Marathi, a low-resource language, and\nevaluate the performance of both closed-source and open-source LLMs as\nannotators, while also comparing these results with fine-tuned BERT models. We\nassess models such as GPT-4o and Gemini 1.0 Pro, Gemma 2 (2B and 9B), and Llama\n3.1 (8B and 405B) on classification tasks including sentiment analysis, news\nclassification, and hate speech detection. Our findings reveal that while LLMs\nexcel in annotation tasks for high-resource languages like English, they still\nfall short when applied to Marathi. Even advanced models like GPT-4o and Llama\n3.1 405B underperform compared to fine-tuned BERT-based baselines, with GPT-4o\nand Llama 3.1 405B trailing fine-tuned BERT by accuracy margins of 10.2% and\n14.1%, respectively. This highlights the limitations of LLMs as annotators for\nlow-resource languages.\n","authors":["Suramya Jadhav","Abhay Shanbhag","Amogh Thakurdesai","Ridhima Sinare","Raviraj Joshi"],"pdf_url":"https://arxiv.org/pdf/2411.17637v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.16806v3","updated":"2025-03-01T15:17:50Z","published":"2025-02-24T03:30:29Z","title":"CoT2Align: Cross-Chain of Thought Distillation via Optimal Transport\n  Alignment for Language Models with Different Tokenizers","summary":"  Large Language Models (LLMs) achieve state-of-the-art performance across\nvarious NLP tasks but face deployment challenges due to high computational\ncosts and memory constraints. Knowledge distillation (KD) is a promising\nsolution, transferring knowledge from large teacher models to smaller student\nmodels. However, existing KD methods often assume shared vocabularies and\ntokenizers, limiting their flexibility. While approaches like Universal Logit\nDistillation (ULD) and Dual-Space Knowledge Distillation (DSKD) address\nvocabulary mismatches, they overlook the critical \\textbf{reasoning-aware\ndistillation} aspect. To bridge this gap, we propose CoT2Align a universal KD\nframework that integrates Chain-of-Thought (CoT) augmentation and introduces\nCross-CoT Alignment to enhance reasoning transfer. Additionally, we extend\nOptimal Transport beyond token-wise alignment to a sequence-level and\nlayer-wise alignment approach that adapts to varying sequence lengths while\npreserving contextual integrity. Comprehensive experiments demonstrate that\nCoT2Align outperforms existing KD methods across different vocabulary settings,\nimproving reasoning capabilities and robustness in domain-specific tasks.\n","authors":["Anh Duc Le","Tu Vu","Nam Le Hai","Nguyen Thi Ngoc Diep","Linh Ngo Van","Trung Le","Thien Huu Nguyen"],"pdf_url":"https://arxiv.org/pdf/2502.16806v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.20207v2","updated":"2025-03-01T14:39:33Z","published":"2024-07-29T17:39:08Z","title":"QAEA-DR: A Unified Text Augmentation Framework for Dense Retrieval","summary":"  In dense retrieval, embedding long texts into dense vectors can result in\ninformation loss, leading to inaccurate query-text matching. Additionally,\nlow-quality texts with excessive noise or sparse key information are unlikely\nto align well with relevant queries. Recent studies mainly focus on improving\nthe sentence embedding model or retrieval process. In this work, we introduce a\nnovel text augmentation framework for dense retrieval. This framework\ntransforms raw documents into information-dense text formats, which supplement\nthe original texts to effectively address the aforementioned issues without\nmodifying embedding or retrieval methodologies. Two text representations are\ngenerated via large language models (LLMs) zero-shot prompting: question-answer\npairs and element-driven events. We term this approach QAEA-DR: unifying\nquestion-answer generation and event extraction in a text augmentation\nframework for dense retrieval. To further enhance the quality of generated\ntexts, a scoring-based evaluation and regeneration mechanism is introduced in\nLLM prompting. Our QAEA-DR model has a positive impact on dense retrieval,\nsupported by both theoretical analysis and empirical experiments.\n","authors":["Hongming Tan","Shaoxiong Zhan","Hai Lin","Hai-Tao Zheng","Wai Kin Chan"],"pdf_url":"https://arxiv.org/pdf/2407.20207v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.16406v2","updated":"2025-03-01T14:22:20Z","published":"2024-02-26T08:59:05Z","title":"From RAGs to riches: Utilizing large language models to write documents\n  for clinical trials","summary":"  This manuscript has now been published: - Link to article on journal website:\nhttps://journals.sagepub.com/doi/10.1177/17407745251320806 - Pubmed link:\nhttps://pubmed.ncbi.nlm.nih.gov/40013826/\n","authors":["Nigel Markey","Ilyass El-Mansouri","Gaetan Rensonnet","Casper van Langen","Christoph Meier"],"pdf_url":"https://arxiv.org/pdf/2402.16406v2.pdf","comment":"6 pages, 2 figures"},{"id":"http://arxiv.org/abs/2409.06666v2","updated":"2025-03-01T12:59:49Z","published":"2024-09-10T17:34:34Z","title":"LLaMA-Omni: Seamless Speech Interaction with Large Language Models","summary":"  Models like GPT-4o enable real-time interaction with large language models\n(LLMs) through speech, significantly enhancing user experience compared to\ntraditional text-based interaction. However, there is still a lack of\nexploration on how to build speech interaction models based on open-source\nLLMs. To address this, we propose LLaMA-Omni, a novel model architecture\ndesigned for low-latency and high-quality speech interaction with LLMs.\nLLaMA-Omni integrates a pretrained speech encoder, a speech adaptor, an LLM,\nand a streaming speech decoder. It eliminates the need for speech\ntranscription, and can simultaneously generate text and speech responses\ndirectly from speech instructions with extremely low latency. We build our\nmodel based on the latest Llama-3.1-8B-Instruct model. To align the model with\nspeech interaction scenarios, we construct a dataset named InstructS2S-200K,\nwhich includes 200K speech instructions and corresponding speech responses.\nExperimental results show that compared to previous speech-language models,\nLLaMA-Omni provides better responses in both content and style, with a response\nlatency as low as 226ms. Additionally, training LLaMA-Omni takes less than 3\ndays on just 4 GPUs, paving the way for the efficient development of\nspeech-language models in the future.\n","authors":["Qingkai Fang","Shoutao Guo","Yan Zhou","Zhengrui Ma","Shaolei Zhang","Yang Feng"],"pdf_url":"https://arxiv.org/pdf/2409.06666v2.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2402.02611v3","updated":"2025-03-01T12:46:25Z","published":"2024-02-04T20:56:09Z","title":"FCoReBench: Can Large Language Models Solve Challenging First-Order\n  Combinatorial Reasoning Problems?","summary":"  Can the large language models (LLMs) solve challenging first-order\ncombinatorial reasoning problems such as graph coloring, knapsack, and\ncryptarithmetic? By first-order, we mean these problems can be instantiated\nwith potentially an infinite number of problem instances of varying sizes. They\nare also challenging being NP-hard and requiring several reasoning steps to\nreach a solution. While existing work has focused on coming up with datasets\nwith hard benchmarks, there is limited work which exploits the first-order\nnature of the problem structure. To address this challenge, we present\nFCoReBench, a dataset of 40 such challenging problems, along with scripts to\ngenerate problem instances of varying sizes and automatically verify and\ngenerate their solutions. We first observe that LLMs, even when aided by\nsymbolic solvers, perform rather poorly on our dataset, being unable to\nleverage the underlying structure of these problems. We specifically observe a\ndrop in performance with increasing problem size. In response, we propose a new\napproach, SymPro-LM, which combines LLMs with both symbolic solvers and program\ninterpreters, along with feedback from a few solved examples, to achieve huge\nperformance gains. Our proposed approach is robust to changes in the problem\nsize, and has the unique characteristic of not requiring any LLM call during\ninference time, unlike earlier approaches. As an additional experiment, we also\ndemonstrate SymPro-LM's effectiveness on other logical reasoning benchmarks.\n","authors":["Chinmay Mittal","Krishna Kartik"," Mausam","Parag Singla"],"pdf_url":"https://arxiv.org/pdf/2402.02611v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.04909v2","updated":"2025-03-01T12:40:09Z","published":"2024-08-09T07:31:06Z","title":"Surveying the Landscape of Image Captioning Evaluation: A Comprehensive\n  Taxonomy, Trends and Metrics Analysis","summary":"  The task of image captioning has recently been gaining popularity, and with\nit the complex task of evaluating the quality of image captioning models. In\nthis work, we present the first survey and taxonomy of over 70 different image\ncaptioning metrics and their usage in hundreds of papers, specifically designed\nto help users select the most suitable metric for their needs. We find that\ndespite the diversity of proposed metrics, the vast majority of studies rely on\nonly five popular metrics, which we show to be weakly correlated with human\nratings. We hypothesize that combining a diverse set of metrics can enhance\ncorrelation with human ratings. As an initial step, we demonstrate that a\nlinear regression-based ensemble method, which we call EnsembEval, trained on\none human ratings dataset, achieves improved correlation across five additional\ndatasets, showing there is a lot of room for improvement by leveraging a\ndiverse set of metrics.\n","authors":["Uri Berger","Gabriel Stanovsky","Omri Abend","Lea Frermann"],"pdf_url":"https://arxiv.org/pdf/2408.04909v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.04286v2","updated":"2025-03-01T11:19:12Z","published":"2024-05-07T12:57:01Z","title":"Who Wrote This? The Key to Zero-Shot LLM-Generated Text Detection Is\n  GECScore","summary":"  The efficacy of detectors for texts generated by large language models (LLMs)\nsubstantially depends on the availability of large-scale training data.\nHowever, white-box zero-shot detectors, which require no such data, are limited\nby the accessibility of the source model of the LLM-generated text. In this\npaper, we propose a simple yet effective black-box zero-shot detection approach\nbased on the observation that, from the perspective of LLMs, human-written\ntexts typically contain more grammatical errors than LLM-generated texts. This\napproach involves calculating the Grammar Error Correction Score (GECScore) for\nthe given text to differentiate between human-written and LLM-generated text.\nExperimental results show that our method outperforms current state-of-the-art\n(SOTA) zero-shot and supervised methods, achieving an average AUROC of 98.62%\nacross XSum and Writing Prompts dataset. Additionally, our approach\ndemonstrates strong reliability in the wild, exhibiting robust generalization\nand resistance to paraphrasing attacks. Data and code are available at:\nhttps://github.com/NLP2CT/GECScore.\n","authors":["Junchao Wu","Runzhe Zhan","Derek F. Wong","Shu Yang","Xuebo Liu","Lidia S. Chao","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2405.04286v2.pdf","comment":"COLING 2025"},{"id":"http://arxiv.org/abs/2502.17810v2","updated":"2025-03-01T11:14:44Z","published":"2025-02-25T03:31:48Z","title":"URO-Bench: A Comprehensive Benchmark for End-to-End Spoken Dialogue\n  Models","summary":"  In recent years, with advances in large language models (LLMs), end-to-end\nspoken dialogue models (SDMs) have made significant strides. Compared to\ntext-based LLMs, the evaluation of SDMs needs to take speech-related aspects\ninto account, such as paralinguistic information and speech quality. However,\nthere is still a lack of comprehensive evaluations for SDMs in speech-to-speech\n(S2S) scenarios. To address this gap, we propose URO-Bench, an extensive\nbenchmark for SDMs. Notably, URO-Bench is the first S2S benchmark that covers\nevaluations about multilingualism, multi-round dialogues, and paralinguistics.\nOur benchmark is divided into two difficulty levels: basic track and pro track,\nconsisting of 16 and 20 datasets respectively, evaluating the model's abilities\nin Understanding, Reasoning, and Oral conversation. Evaluations on our proposed\nbenchmark reveal that current open-source SDMs perform rather well in daily QA\ntasks, but lag behind their backbone LLMs in terms of instruction-following\nability and also suffer from catastrophic forgetting. Their performance in\nadvanced evaluations of paralinguistic information and audio understanding\nremains subpar, highlighting the need for further research in this direction.\nWe hope that URO-Bench can effectively facilitate the development of spoken\ndialogue models by providing a multifaceted evaluation of existing models and\nhelping to track progress in this area.\n","authors":["Ruiqi Yan","Xiquan Li","Wenxi Chen","Zhikang Niu","Chen Yang","Ziyang Ma","Kai Yu","Xie Chen"],"pdf_url":"https://arxiv.org/pdf/2502.17810v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.18448v3","updated":"2025-03-01T09:48:15Z","published":"2024-05-28T01:15:21Z","title":"Multi-objective Representation for Numbers in Clinical Narratives: A\n  CamemBERT-Bio-Based Alternative to Large-Scale LLMs","summary":"  The processing of numerical values is a rapidly developing area in the field\nof Language Models (LLMs). Despite numerous advancements achieved by previous\nresearch, significant challenges persist, particularly within the healthcare\ndomain. This paper investigates the limitations of Transformer models in\nunderstanding numerical values. \\textit{Objective:} this research aims to\ncategorize numerical values extracted from medical documents into eight\nspecific physiological categories using CamemBERT-bio. \\textit{Methods:} In a\ncontext where scalable methods and Large Language Models (LLMs) are emphasized,\nwe explore lifting the limitations of transformer-based models. We examine two\nstrategies: fine-tuning CamemBERT-bio on a small medical dataset, integrating\nLabel Embedding for Self-Attention (LESA), and combining LESA with additional\nenhancement techniques such as Xval. Given that CamemBERT-bio is already\npre-trained on a large medical dataset, the first approach aims to update its\nencoder with the newly added label embeddings technique. In contrast, the\nsecond approach seeks to develop multiple representations of numbers\n(contextual and magnitude-based) to achieve more robust number embeddings.\n\\textit{Results:} As anticipated, fine-tuning the standard CamemBERT-bio on our\nsmall medical dataset did not improve F1 scores. However, significant\nimprovements were observed with CamemBERT-bio + LESA, resulting in an over 13\\%\nincrease. Similar enhancements were noted when combining LESA with Xval,\noutperforming conventional methods and giving comparable results to GPT-4\n\\textit{Conclusions and Novelty:} This study introduces two innovative\ntechniques for handling numerical data, which are also applicable to other\nmodalities. We illustrate how these techniques can improve the performance of\nTransformer-based models, achieving more reliable classification results even\nwith small datasets.\n","authors":["Boammani Aser Lompo","Thanh-Dung Le"],"pdf_url":"https://arxiv.org/pdf/2405.18448v3.pdf","comment":"Under the revision. arXiv admin note: substantial text overlap with\n  arXiv:2404.10171"},{"id":"http://arxiv.org/abs/2410.06615v2","updated":"2025-03-01T08:32:14Z","published":"2024-10-09T07:12:24Z","title":"QA-Calibration of Language Model Confidence Scores","summary":"  To use generative question-and-answering (QA) systems for decision-making and\nin any critical application, these systems need to provide well-calibrated\nconfidence scores that reflect the correctness of their answers. Existing\ncalibration methods aim to ensure that the confidence score is, *on average*,\nindicative of the likelihood that the answer is correct. We argue, however,\nthat this standard (average-case) notion of calibration is difficult to\ninterpret for decision-making in generative QA. To address this, we generalize\nthe standard notion of average calibration and introduce QA-calibration, which\nensures calibration holds across different question-and-answer groups. We then\npropose discretized posthoc calibration schemes for achieving QA-calibration.\nWe establish distribution-free guarantees on the performance of this method and\nvalidate our method on confidence scores returned by elicitation prompts across\nmultiple QA benchmarks and large language models (LLMs).\n","authors":["Putra Manggala","Atalanti Mastakouri","Elke Kirschbaum","Shiva Prasad Kasiviswanathan","Aaditya Ramdas"],"pdf_url":"https://arxiv.org/pdf/2410.06615v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.19870v2","updated":"2025-03-01T08:16:00Z","published":"2025-02-27T08:21:28Z","title":"MMKE-Bench: A Multimodal Editing Benchmark for Diverse Visual Knowledge","summary":"  Knowledge editing techniques have emerged as essential tools for updating the\nfactual knowledge of large language models (LLMs) and multimodal models (LMMs),\nallowing them to correct outdated or inaccurate information without retraining\nfrom scratch. However, existing benchmarks for multimodal knowledge editing\nprimarily focus on entity-level knowledge represented as simple triplets, which\nfail to capture the complexity of real-world multimodal information. To address\nthis issue, we introduce MMKE-Bench, a comprehensive MultiModal Knowledge\nEditing Benchmark, designed to evaluate the ability of LMMs to edit diverse\nvisual knowledge in real-world scenarios. MMKE-Bench addresses these\nlimitations by incorporating three types of editing tasks: visual entity\nediting, visual semantic editing, and user-specific editing. Besides,\nMMKE-Bench uses free-form natural language to represent and edit knowledge,\noffering a more flexible and effective format. The benchmark consists of 2,940\npieces of knowledge and 8,363 images across 33 broad categories, with\nevaluation questions automatically generated and human-verified. We assess five\nstate-of-the-art knowledge editing methods on three prominent LMMs, revealing\nthat no method excels across all criteria, and that visual and user-specific\nedits are particularly challenging. MMKE-Bench sets a new standard for\nevaluating the robustness of multimodal knowledge editing techniques, driving\nprogress in this rapidly evolving field.\n","authors":["Yuntao Du","Kailin Jiang","Zhi Gao","Chenrui Shi","Zilong Zheng","Siyuan Qi","Qing Li"],"pdf_url":"https://arxiv.org/pdf/2502.19870v2.pdf","comment":"Accept to ICLR2025. Project Page: https://mmke-bench-iclr.github.io/"},{"id":"http://arxiv.org/abs/2502.13922v3","updated":"2025-03-01T08:02:07Z","published":"2025-02-19T17:59:03Z","title":"LongPO: Long Context Self-Evolution of Large Language Models through\n  Short-to-Long Preference Optimization","summary":"  Large Language Models (LLMs) have demonstrated remarkable capabilities\nthrough pretraining and alignment. However, superior short-context LLMs may\nunderperform in long-context scenarios due to insufficient long-context\nalignment. This alignment process remains challenging due to the impracticality\nof human annotation for extended contexts and the difficulty in balancing\nshort- and long-context performance. To address these challenges, we introduce\nLongPO, that enables short-context LLMs to self-evolve to excel on long-context\ntasks by internally transferring short-context capabilities. LongPO harnesses\nLLMs to learn from self-generated short-to-long preference data, comprising\npaired responses generated for identical instructions with long-context inputs\nand their compressed short-context counterparts, respectively. This preference\nreveals capabilities and potentials of LLMs cultivated during short-context\nalignment that may be diminished in under-aligned long-context scenarios.\nAdditionally, LongPO incorporates a short-to-long KL constraint to mitigate\nshort-context performance decline during long-context alignment. When applied\nto Mistral-7B-Instruct-v0.2 from 128K to 512K context lengths, LongPO fully\nretains short-context performance and largely outperforms naive SFT and DPO in\nboth long- and short-context tasks. Specifically, LongPO-trained models can\nachieve results on long-context benchmarks comparable to, or even surpassing,\nthose of superior LLMs (e.g., GPT-4-128K) that involve extensive long-context\nannotation and larger parameter scales. Our code is available at\nhttps://github.com/DAMO-NLP-SG/LongPO.\n","authors":["Guanzheng Chen","Xin Li","Michael Qizhe Shieh","Lidong Bing"],"pdf_url":"https://arxiv.org/pdf/2502.13922v3.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2502.10596v2","updated":"2025-03-01T06:33:01Z","published":"2025-02-14T23:00:49Z","title":"Post-training an LLM for RAG? Train on Self-Generated Demonstrations","summary":"  Large language models (LLMs) often struggle with knowledge intensive NLP\ntasks, such as answering \"Who won the latest World Cup?\" because the knowledge\nthey learn during training may be insufficient or outdated. Conditioning\ngeneration on retrieved documents -- a technique known as retrieval augmented\ngeneration (RAG) -- mitigates these shortcomings by allowing the model to\nleverage in-context information. Practitioners can improve LLM RAG performance\nby fine-tuning on retrieval-augmented instructions, but must beware that this\ncan cause undesirable model behaviors like hallucinations. We attribute this\ndegradation to the fact that the training data is likely to be\nout-of-distribution for the model and may suffer from quality issues, such as\nmisalignment between retrievals and target responses (since retrievals are\nfrequently added post-hoc). We propose a recipe for training RAG-enabled LLMs\nusing self-generated demonstrations, thereby avoiding training on\nout-of-distribution text and integrating retrievals into the LLM responses. We\nevaluate our method on knowledge intensive question answering (QA) tasks and\nshow that our method teaches LLMs to properly handle in-context retrievals and\nabstain from questions it will likely get wrong. Compared to conventional RA-IT\nmethods, our method prevents model degradation in non-RAG settings while\nexhibiting superior QA performance.\n","authors":["Matthew Finlayson","Ilia Kulikov","Daniel M. Bikel","Barlas Oguz","Xilun Chen","Aasish Pappu"],"pdf_url":"https://arxiv.org/pdf/2502.10596v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.21368v2","updated":"2025-03-01T06:14:00Z","published":"2024-07-31T06:34:38Z","title":"Prompting Medical Large Vision-Language Models to Diagnose Pathologies\n  by Visual Question Answering","summary":"  Large Vision-Language Models (LVLMs) have achieved significant success in\nrecent years, and they have been extended to the medical domain. Although\ndemonstrating satisfactory performance on medical Visual Question Answering\n(VQA) tasks, Medical LVLMs (MLVLMs) suffer from the hallucination problem,\nwhich makes them fail to diagnose complex pathologies. Moreover, they readily\nfail to learn minority pathologies due to imbalanced training data. We propose\ntwo prompting strategies for MLVLMs that reduce hallucination and improve VQA\nperformance. In the first strategy, we provide a detailed explanation of the\nqueried pathology. In the second strategy, we fine-tune a cheap, weak learner\nto achieve high performance on a specific metric, and textually provide its\njudgment to the MLVLM. Tested on the MIMIC-CXR-JPG and Chexpert datasets, our\nmethods significantly improve the diagnostic F1 score, with the highest\nincrease being 0.27. We also demonstrate that our prompting strategies can be\nextended to general LVLM domains. Based on POPE metrics, it effectively\nsuppresses the false negative predictions of existing LVLMs and improves Recall\nby approximately 0.07.\n","authors":["Danfeng Guo","Demetri Terzopoulos"],"pdf_url":"https://arxiv.org/pdf/2407.21368v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.16880v2","updated":"2025-03-01T06:13:45Z","published":"2025-02-24T06:28:26Z","title":"CORAL: Learning Consistent Representations across Multi-step Training\n  with Lighter Speculative Drafter","summary":"  Speculative decoding is a powerful technique that accelerates Large Language\nModel (LLM) inference by leveraging a lightweight speculative draft model.\nHowever, existing designs suffers in performance due to misalignment between\ntraining and inference. Recent methods have tried to solve this issue by\nadopting a multi-step training strategy, but the complex inputs of different\ntraining steps make it harder for the draft model to converge. To address this,\nwe propose CORAL, a novel framework that improves both accuracy and efficiency\nin speculative drafting. CORAL introduces Cross-Step Representation Alignment,\na method that enhances consistency across multiple training steps,\nsignificantly improving speculative drafting performance. Additionally, we\nidentify the LM head as a major bottleneck in the inference speed of the draft\nmodel. We introduce a weight-grouping mechanism that selectively activates a\nsubset of LM head parameters during inference, substantially reducing the\nlatency of the draft model. We evaluate CORAL on three LLM families and three\nbenchmark datasets, achieving speedup ratios of 2.50x-4.07x, outperforming\nstate-of-the-art methods such as EAGLE-2 and HASS. Our results demonstrate that\nCORAL effectively mitigates training-inference misalignment and delivers\nsignificant speedup for modern LLMs with large vocabularies.\n","authors":["Yepeng Weng","Dianwen Mei","Huishi Qiu","Xujie Chen","Li Liu","Jiang Tian","Zhongchao Shi"],"pdf_url":"https://arxiv.org/pdf/2502.16880v2.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2501.19393v3","updated":"2025-03-01T06:07:39Z","published":"2025-01-31T18:48:08Z","title":"s1: Simple test-time scaling","summary":"  Test-time scaling is a promising new approach to language modeling that uses\nextra test-time compute to improve performance. Recently, OpenAI's o1 model\nshowed this capability but did not publicly share its methodology, leading to\nmany replication efforts. We seek the simplest approach to achieve test-time\nscaling and strong reasoning performance. First, we curate a small dataset s1K\nof 1,000 questions paired with reasoning traces relying on three criteria we\nvalidate through ablations: difficulty, diversity, and quality. Second, we\ndevelop budget forcing to control test-time compute by forcefully terminating\nthe model's thinking process or lengthening it by appending \"Wait\" multiple\ntimes to the model's generation when it tries to end. This can lead the model\nto double-check its answer, often fixing incorrect reasoning steps. After\nsupervised finetuning the Qwen2.5-32B-Instruct language model on s1K and\nequipping it with budget forcing, our model s1-32B exceeds o1-preview on\ncompetition math questions by up to 27% (MATH and AIME24). Further, scaling\ns1-32B with budget forcing allows extrapolating beyond its performance without\ntest-time intervention: from 50% to 57% on AIME24. Our model, data, and code\nare open-source at https://github.com/simplescaling/s1\n","authors":["Niklas Muennighoff","Zitong Yang","Weijia Shi","Xiang Lisa Li","Li Fei-Fei","Hannaneh Hajishirzi","Luke Zettlemoyer","Percy Liang","Emmanuel Candès","Tatsunori Hashimoto"],"pdf_url":"https://arxiv.org/pdf/2501.19393v3.pdf","comment":"46 pages (9 main), 10 figures, 15 tables"},{"id":"http://arxiv.org/abs/2406.17972v3","updated":"2025-03-01T04:10:03Z","published":"2024-06-25T23:07:18Z","title":"LABOR-LLM: Language-Based Occupational Representations with Large\n  Language Models","summary":"  Vafa et al. (2024) introduced a transformer-based econometric model, CAREER,\nthat predicts a worker's next job as a function of career history (an\n\"occupation model\"). CAREER was initially estimated (\"pre-trained\") using a\nlarge, unrepresentative resume dataset, which served as a \"foundation model,\"\nand parameter estimation was continued (\"fine-tuned\") using data from a\nrepresentative survey. CAREER had better predictive performance than\nbenchmarks. This paper considers an alternative where the resume-based\nfoundation model is replaced by a large language model (LLM). We convert\ntabular data from the survey into text files that resemble resumes and\nfine-tune the LLMs using these text files with the objective to predict the\nnext token (word). The resulting fine-tuned LLM is used as an input to an\noccupation model. Its predictive performance surpasses all prior models. We\ndemonstrate the value of fine-tuning and further show that by adding more\ncareer data from a different population, fine-tuning smaller LLMs surpasses the\nperformance of fine-tuning larger models.\n","authors":["Susan Athey","Herman Brunborg","Tianyu Du","Ayush Kanodia","Keyon Vafa"],"pdf_url":"https://arxiv.org/pdf/2406.17972v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.06615v2","updated":"2025-03-01T03:07:31Z","published":"2024-06-07T04:25:38Z","title":"Language Guided Skill Discovery","summary":"  Skill discovery methods enable agents to learn diverse emergent behaviors\nwithout explicit rewards. To make learned skills useful for unknown downstream\ntasks, obtaining a semantically diverse repertoire of skills is essential.\nWhile some approaches introduce a discriminator to distinguish skills and\nothers aim to increase state coverage, no existing work directly addresses the\n\"semantic diversity\" of skills. We hypothesize that leveraging the semantic\nknowledge of large language models (LLMs) can lead us to improve semantic\ndiversity of resulting behaviors. In this sense, we introduce Language Guided\nSkill Discovery (LGSD), a skill discovery framework that aims to directly\nmaximize the semantic diversity between skills. LGSD takes user prompts as\ninput and outputs a set of semantically distinctive skills. The prompts serve\nas a means to constrain the search space into a semantically desired subspace,\nand the generated LLM outputs guide the agent to visit semantically diverse\nstates within the subspace. We demonstrate that LGSD enables legged robots to\nvisit different user-intended areas on a plane by simply changing the prompt.\nFurthermore, we show that language guidance aids in discovering more diverse\nskills compared to five existing skill discovery methods in robot-arm\nmanipulation environments. Lastly, LGSD provides a simple way of utilizing\nlearned skills via natural language.\n","authors":["Seungeun Rho","Laura Smith","Tianyu Li","Sergey Levine","Xue Bin Peng","Sehoon Ha"],"pdf_url":"https://arxiv.org/pdf/2406.06615v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.11418v3","updated":"2025-03-01T01:47:51Z","published":"2024-07-16T06:19:14Z","title":"Semantic Operators: A Declarative Model for Rich, AI-based Data\n  Processing","summary":"  The semantic capabilities of large language models (LLMs) have the potential\nto enable rich analytics and reasoning over vast knowledge corpora.\nUnfortunately, existing systems either empirically optimize expensive\nLLM-powered operations with no performance guarantees, or serve a limited set\nof row-wise LLM operations, providing limited robustness, expressiveness and\nusability. We introduce semantic operators, the first formalism for declarative\nand general-purpose AI-based transformations based on natural language\nspecifications (e.g., filtering, sorting, joining or aggregating records using\nnatural language criteria). Each operator opens a rich space for execution\nplans, similar to relational operators. Our model specifies the expected\nbehavior of each operator with a high-quality gold algorithm, and we develop an\noptimization framework that reduces cost, while providing accuracy guarantees\nwith respect to a gold algorithm. Using this approach, we propose several novel\noptimizations to accelerate semantic filtering, joining, group-by and top-k\noperations by up to $1,000\\times$. We implement semantic operators in the LOTUS\nsystem and demonstrate LOTUS' effectiveness on real, bulk-semantic processing\napplications, including fact-checking, biomedical multi-label classification,\nsearch, and topic analysis. We show that the semantic operator model is\nexpressive, capturing state-of-the-art AI pipelines in a few operator calls,\nand making it easy to express new pipelines that match or exceed quality of\nrecent LLM-based analytic systems by up to $170\\%$, while offering accuracy\nguarantees. Overall, LOTUS programs match or exceed the accuracy of\nstate-of-the-art AI pipelines for each task while running up to $3.6\\times$\nfaster than the highest-quality baselines. LOTUS is publicly available at\nhttps://github.com/lotus-data/lotus.\n","authors":["Liana Patel","Siddharth Jha","Melissa Pan","Harshit Gupta","Parth Asawa","Carlos Guestrin","Matei Zaharia"],"pdf_url":"https://arxiv.org/pdf/2407.11418v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.17514v3","updated":"2025-03-01T01:39:28Z","published":"2024-01-31T00:15:34Z","title":"How Useful is Continued Pre-Training for Generative Unsupervised Domain\n  Adaptation?","summary":"  Recent breakthroughs in scale have enabled the emergence of powerful\ngenerative language models, and the ability to fine-tune these models on\nvarious tasks by casting them into prompts or instructions. In this landscape,\nthe problem of Unsupervised Domain Adaptation (UDA), or the problem of\nleveraging knowledge from a labeled source domain to an unlabeled target\ndomain, has been left behind, with recent UDA methods still addressing\ndiscriminative classification. In particular, two popular UDA approaches,\ninvolving Continued Pre-Training (CPT) and learning domain invariant\nrepresentations, have been under-explored in the generative setting, signaling\na gap. In this work, we evaluate the utility of CPT for generative UDA. We\nfirst perform an empirical evaluation to measure the trade-offs between CPT and\nstrong methods promoting domain invariance. We further evaluate how well the\nbenefits of CPT extend to different architectures, tuning methods and data\nregimes. We then motivate the use of CPT by studying to what degree it benefits\nclassification performance on the target domain. Finally, we attempt to\nunderstand the mechanism behind which CPT improves classification performance\non the unlabeled target domain. Our findings suggest that a implicitly learns\nthe downstream task while predicting masked words informative to that task. Our\nwork connects the body of UDA research with that of instruction tuning,\nenabling an initial step towards a wider applicability of modern language\nmodels.\n","authors":["Rheeya Uppaal","Yixuan Li","Junjie Hu"],"pdf_url":"https://arxiv.org/pdf/2401.17514v3.pdf","comment":"Accepted to RepL4NLP at ACL 2024"},{"id":"http://arxiv.org/abs/2405.13967v5","updated":"2025-03-01T01:35:47Z","published":"2024-05-22T20:08:48Z","title":"Model Editing as a Robust and Denoised variant of DPO: A Case Study on\n  Toxicity","summary":"  Recent alignment algorithms such as direct preference optimization (DPO) have\nbeen developed to improve the safety of large language models (LLMs) by\ntraining these models to match human behaviors exemplified by preference data.\nHowever, these methods are both computationally intensive and lacking in\ncontrollability and transparency, inhibiting their widespread use. Furthermore,\nthese tuning-based methods require large-scale preference data for training and\nare susceptible to noisy preference data. In this paper, we introduce a\ntuning-free alignment alternative, ProFS (Projection Filter for Subspaces), and\ndemonstrate its effectiveness under the use case of toxicity reduction.\nGrounded on theory from factor analysis, ProFS is a sample-efficient model\nediting approach that identifies a toxic subspace in the model parameter space\nand reduces model toxicity by projecting away the detected subspace. The toxic\nsubspace is identified by extracting preference data embeddings from the\nlanguage model, and removing non-toxic information from these embeddings. We\nshow that ProFS is more sample-efficient than DPO, further showcasing greater\nrobustness to noisy data. Finally, we attempt to connect tuning based alignment\nwith editing, by establishing both theoretical and empirical connections\nbetween ProFS and DPO, showing that ProFS can be interpreted as a denoised\nversion of a single DPO step.\n","authors":["Rheeya Uppaal","Apratim Dey","Yiting He","Yiqiao Zhong","Junjie Hu"],"pdf_url":"https://arxiv.org/pdf/2405.13967v5.pdf","comment":"Accepted to ICLR 2025"},{"id":"http://arxiv.org/abs/2408.04650v2","updated":"2025-03-01T00:49:53Z","published":"2024-08-03T19:57:49Z","title":"Building Trust in Mental Health Chatbots: Safety Metrics and LLM-Based\n  Evaluation Tools","summary":"  Objective: This study aims to develop and validate an evaluation framework to\nensure the safety and reliability of mental health chatbots, which are\nincreasingly popular due to their accessibility, human-like interactions, and\ncontext-aware support. Materials and Methods: We created an evaluation\nframework with 100 benchmark questions and ideal responses, and five guideline\nquestions for chatbot responses. This framework, validated by mental health\nexperts, was tested on a GPT-3.5-turbo-based chatbot. Automated evaluation\nmethods explored included large language model (LLM)-based scoring, an agentic\napproach using real-time data, and embedding models to compare chatbot\nresponses against ground truth standards. Results: The results highlight the\nimportance of guidelines and ground truth for improving LLM evaluation\naccuracy. The agentic method, dynamically accessing reliable information,\ndemonstrated the best alignment with human assessments. Adherence to a\nstandardized, expert-validated framework significantly enhanced chatbot\nresponse safety and reliability. Discussion: Our findings emphasize the need\nfor comprehensive, expert-tailored safety evaluation metrics for mental health\nchatbots. While LLMs have significant potential, careful implementation is\nnecessary to mitigate risks. The superior performance of the agentic approach\nunderscores the importance of real-time data access in enhancing chatbot\nreliability. Conclusion: The study validated an evaluation framework for mental\nhealth chatbots, proving its effectiveness in improving safety and reliability.\nFuture work should extend evaluations to accuracy, bias, empathy, and privacy\nto ensure holistic assessment and responsible integration into healthcare.\nStandardized evaluations will build trust among users and professionals,\nfacilitating broader adoption and improved mental health support through\ntechnology.\n","authors":["Jung In Park","Mahyar Abbasian","Iman Azimi","Dawn T. Bounds","Angela Jun","Jaesu Han","Robert M. McCarron","Jessica Borelli","Parmida Safavi","Sanaz Mirbaha","Jia Li","Mona Mahmoudi","Carmen Wiedenhoeft","Amir M. Rahmani"],"pdf_url":"https://arxiv.org/pdf/2408.04650v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.21637v2","updated":"2025-03-01T00:12:48Z","published":"2024-10-29T00:46:24Z","title":"Mitigating Paraphrase Attacks on Machine-Text Detectors via Paraphrase\n  Inversion","summary":"  High-quality paraphrases are easy to produce using instruction-tuned language\nmodels or specialized paraphrasing models. Although this capability has a\nvariety of benign applications, paraphrasing\nattacks$\\unicode{x2013}$paraphrases applied to machine-generated\ntexts$\\unicode{x2013}$are known to significantly degrade the performance of\nmachine-text detectors. This motivates us to consider the novel problem of\nparaphrase inversion, where, given paraphrased text, the objective is to\nrecover an approximation of the original text. The closer the approximation is\nto the original text, the better machine-text detectors will perform. We\npropose an approach which frames the problem as translation from paraphrased\ntext back to the original text, which requires examples of texts and\ncorresponding paraphrases to train the inversion model. Fortunately, such\ntraining data can easily be generated, given a corpus of original texts and one\nor more paraphrasing models. We find that language models such as GPT-4 and\nLlama-3 exhibit biases when paraphrasing which an inversion model can learn\nwith a modest amount of data. Perhaps surprisingly, we also find that such\nmodels generalize well, including to paraphrase models unseen at training time.\nFinally, we show that when combined with a paraphrased-text detector, our\ninversion models provide an effective defense against paraphrasing attacks, and\noverall our approach yields an average improvement of +22% AUROC across seven\nmachine-text detectors and three different domains.\n","authors":["Rafael Rivera Soto","Barry Chen","Nicholas Andrews"],"pdf_url":"https://arxiv.org/pdf/2410.21637v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.11094v3","updated":"2025-03-01T19:27:41Z","published":"2024-02-16T21:47:30Z","title":"Revisiting Word Embeddings in the LLM Era","summary":"  Large Language Models (LLMs) have recently shown remarkable advancement in\nvarious NLP tasks. As such, a popular trend has emerged lately where NLP\nresearchers extract word/sentence/document embeddings from these large\ndecoder-only models and use them for various inference tasks with promising\nresults. However, it is still unclear whether the performance improvement of\nLLM-induced embeddings is merely because of scale or whether underlying\nembeddings they produce significantly differ from classical encoding models\nlike Word2Vec, GloVe, Sentence-BERT (SBERT) or Universal Sentence Encoder\n(USE). This is the central question we investigate in the paper by\nsystematically comparing classical decontextualized and contextualized word\nembeddings with the same for LLM-induced embeddings. Our results show that LLMs\ncluster semantically related words more tightly and perform better on analogy\ntasks in decontextualized settings. However, in contextualized settings,\nclassical models like SimCSE often outperform LLMs in sentence-level similarity\nassessment tasks, highlighting their continued relevance for fine-grained\nsemantics.\n","authors":["Yash Mahajan","Matthew Freestone","Naman Bansal","Sathyanarayanan Aakur","Shubhra Kanti Karmaker Santu"],"pdf_url":"https://arxiv.org/pdf/2402.11094v3.pdf","comment":"This is an updated version of the older version: arXiv:2402.11094. We\n  accidentally submitted this article as a new submission (arXiv:2502.19607),\n  which we have requested to withdraw. This version has 30 pages and 22 figures"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2303.15263v5","updated":"2025-03-01T23:43:08Z","published":"2023-03-27T14:52:08Z","title":"Joint Person Identity, Gender and Age Estimation from Hand Images using\n  Deep Multi-Task Representation Learning","summary":"  In this paper, we propose a multi-task representation learning framework to\njointly estimate the identity, gender and age of individuals from their hand\nimages for the purpose of criminal investigations since the hand images are\noften the only available information in cases of serious crime such as sexual\nabuse. We investigate different up-to-date deep learning architectures and\ncompare their performance for joint estimation of identity, gender and age from\nhand images of perpetrators of serious crime. To simplify the age prediction,\nwe create age groups for the age estimation. We make extensive evaluations and\ncomparisons of both convolution-based and transformer-based deep learning\narchitectures on a publicly available 11k hands dataset. Our experimental\nanalysis shows that it is possible to efficiently estimate not only identity\nbut also other attributes such as gender and age of suspects jointly from hand\nimages for criminal investigations, which is crucial in assisting international\npolice forces in the court to identify and convict abusers.\n","authors":["Nathanael L. Baisa"],"pdf_url":"https://arxiv.org/pdf/2303.15263v5.pdf","comment":"arXiv admin note: text overlap with arXiv:2209.04821"},{"id":"http://arxiv.org/abs/2404.15709v3","updated":"2025-03-01T23:26:22Z","published":"2024-04-24T07:58:28Z","title":"ViViDex: Learning Vision-based Dexterous Manipulation from Human Videos","summary":"  In this work, we aim to learn a unified vision-based policy for\nmulti-fingered robot hands to manipulate a variety of objects in diverse poses.\nThough prior work has shown benefits of using human videos for policy learning,\nperformance gains have been limited by the noise in estimated trajectories.\nMoreover, reliance on privileged object information such as ground-truth object\nstates further limits the applicability in realistic scenarios. To address\nthese limitations, we propose a new framework ViViDex to improve vision-based\npolicy learning from human videos. It first uses reinforcement learning with\ntrajectory guided rewards to train state-based policies for each video,\nobtaining both visually natural and physically plausible trajectories from the\nvideo. We then rollout successful episodes from state-based policies and train\na unified visual policy without using any privileged information. We propose\ncoordinate transformation to further enhance the visual point cloud\nrepresentation, and compare behavior cloning and diffusion policy for the\nvisual policy training. Experiments both in simulation and on the real robot\ndemonstrate that ViViDex outperforms state-of-the-art approaches on three\ndexterous manipulation tasks.\n","authors":["Zerui Chen","Shizhe Chen","Etienne Arlaud","Ivan Laptev","Cordelia Schmid"],"pdf_url":"https://arxiv.org/pdf/2404.15709v3.pdf","comment":"Accepted by ICRA 2025. Project Page:\n  https://zerchen.github.io/projects/vividex.html"},{"id":"http://arxiv.org/abs/2502.20108v2","updated":"2025-03-01T23:17:26Z","published":"2025-02-27T14:02:14Z","title":"VDT-Auto: End-to-end Autonomous Driving with VLM-Guided Diffusion\n  Transformers","summary":"  In autonomous driving, dynamic environment and corner cases pose significant\nchallenges to the robustness of ego vehicle's decision-making. To address these\nchallenges, commencing with the representation of state-action mapping in the\nend-to-end autonomous driving paradigm, we introduce a novel pipeline,\nVDT-Auto. Leveraging the advancement of the state understanding of Visual\nLanguage Model (VLM), incorporating with diffusion Transformer-based action\ngeneration, our VDT-Auto parses the environment geometrically and contextually\nfor the conditioning of the diffusion process. Geometrically, we use a\nbird's-eye view (BEV) encoder to extract feature grids from the surrounding\nimages. Contextually, the structured output of our fine-tuned VLM is processed\ninto textual embeddings and noisy paths. During our diffusion process, the\nadded noise for the forward process is sampled from the noisy path output of\nthe fine-tuned VLM, while the extracted BEV feature grids and embedded texts\ncondition the reverse process of our diffusion Transformers. Our VDT-Auto\nachieved 0.52m on average L2 errors and 21% on average collision rate in the\nnuScenes open-loop planning evaluation. Moreover, the real-world demonstration\nexhibited prominent generalizability of our VDT-Auto. The code and dataset will\nbe released after acceptance.\n","authors":["Ziang Guo","Konstantin Gubernatorov","Selamawit Asfaw","Zakhar Yagudin","Dzmitry Tsetserukou"],"pdf_url":"https://arxiv.org/pdf/2502.20108v2.pdf","comment":"Submitted paper"},{"id":"http://arxiv.org/abs/2407.07516v2","updated":"2025-03-01T23:17:11Z","published":"2024-07-10T10:09:12Z","title":"HDKD: Hybrid Data-Efficient Knowledge Distillation Network for Medical\n  Image Classification","summary":"  Vision Transformers (ViTs) have achieved significant advancement in computer\nvision tasks due to their powerful modeling capacity. However, their\nperformance notably degrades when trained with insufficient data due to lack of\ninherent inductive biases. Distilling knowledge and inductive biases from a\nConvolutional Neural Network (CNN) teacher has emerged as an effective strategy\nfor enhancing the generalization of ViTs on limited datasets. Previous\napproaches to Knowledge Distillation (KD) have pursued two primary paths: some\nfocused solely on distilling the logit distribution from CNN teacher to ViT\nstudent, neglecting the rich semantic information present in intermediate\nfeatures due to the structural differences between them. Others integrated\nfeature distillation along with logit distillation, yet this introduced\nalignment operations that limits the amount of knowledge transferred due to\nmismatched architectures and increased the computational overhead. To this end,\nthis paper presents Hybrid Data-efficient Knowledge Distillation (HDKD)\nparadigm which employs a CNN teacher and a hybrid student. The choice of hybrid\nstudent serves two main aspects. First, it leverages the strengths of both\nconvolutions and transformers while sharing the convolutional structure with\nthe teacher model. Second, this shared structure enables the direct application\nof feature distillation without any information loss or additional\ncomputational overhead. Additionally, we propose an efficient light-weight\nconvolutional block named Mobile Channel-Spatial Attention (MBCSA), which\nserves as the primary convolutional block in both teacher and student models.\nExtensive experiments on two medical public datasets showcase the superiority\nof HDKD over other state-of-the-art models and its computational efficiency.\nSource code at: https://github.com/omarsherif200/HDKD\n","authors":["Omar S. EL-Assiouti","Ghada Hamed","Dina Khattab","Hala M. Ebied"],"pdf_url":"https://arxiv.org/pdf/2407.07516v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.16820v3","updated":"2025-03-01T22:41:18Z","published":"2024-04-25T17:58:43Z","title":"Revisiting Text-to-Image Evaluation with Gecko: On Metrics, Prompts, and\n  Human Ratings","summary":"  While text-to-image (T2I) generative models have become ubiquitous, they do\nnot necessarily generate images that align with a given prompt. While previous\nwork has evaluated T2I alignment by proposing metrics, benchmarks, and\ntemplates for collecting human judgements, the quality of these components is\nnot systematically measured. Human-rated prompt sets are generally small and\nthe reliability of the ratings -- and thereby the prompt set used to compare\nmodels -- is not evaluated. We address this gap by performing an extensive\nstudy evaluating auto-eval metrics and human templates. We provide three main\ncontributions: (1) We introduce a comprehensive skills-based benchmark that can\ndiscriminate models across different human templates. This skills-based\nbenchmark categorises prompts into sub-skills, allowing a practitioner to\npinpoint not only which skills are challenging, but at what level of complexity\na skill becomes challenging. (2) We gather human ratings across four templates\nand four T2I models for a total of >100K annotations. This allows us to\nunderstand where differences arise due to inherent ambiguity in the prompt and\nwhere they arise due to differences in metric and model quality. (3) Finally,\nwe introduce a new QA-based auto-eval metric that is better correlated with\nhuman ratings than existing metrics for our new dataset, across different human\ntemplates, and on TIFA160.\n","authors":["Olivia Wiles","Chuhan Zhang","Isabela Albuquerque","Ivana Kajić","Su Wang","Emanuele Bugliarello","Yasumasa Onoe","Chris Knutsen","Cyrus Rashtchian","Jordi Pont-Tuset","Aida Nematzadeh"],"pdf_url":"https://arxiv.org/pdf/2404.16820v3.pdf","comment":"Accepted to ICLR 2025 (Spotlight)"},{"id":"http://arxiv.org/abs/2312.04465v3","updated":"2025-03-01T22:24:56Z","published":"2023-12-07T17:35:49Z","title":"FitDiff: Robust monocular 3D facial shape and reflectance estimation\n  using Diffusion Models","summary":"  The remarkable progress in 3D face reconstruction has resulted in high-detail\nand photorealistic facial representations. Recently, Diffusion Models have\nrevolutionized the capabilities of generative methods by surpassing the\nperformance of GANs. In this work, we present FitDiff, a diffusion-based 3D\nfacial avatar generative model. Leveraging diffusion principles, our model\naccurately generates relightable facial avatars, utilizing an identity\nembedding extracted from an \"in-the-wild\" 2D facial image. The introduced\nmulti-modal diffusion model is the first to concurrently output facial\nreflectance maps (diffuse and specular albedo and normals) and shapes,\nshowcasing great generalization capabilities. It is solely trained on an\nannotated subset of a public facial dataset, paired with 3D reconstructions. We\nrevisit the typical 3D facial fitting approach by guiding a reverse diffusion\nprocess using perceptual and face recognition losses. Being the first 3D LDM\nconditioned on face recognition embeddings, FitDiff reconstructs relightable\nhuman avatars, that can be used as-is in common rendering engines, starting\nonly from an unconstrained facial image, and achieving state-of-the-art\nperformance.\n","authors":["Stathis Galanakis","Alexandros Lattas","Stylianos Moschoglou","Stefanos Zafeiriou"],"pdf_url":"https://arxiv.org/pdf/2312.04465v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01345v2","updated":"2025-03-01T22:11:10Z","published":"2024-10-02T09:02:34Z","title":"Towards Generalizable Vision-Language Robotic Manipulation: A Benchmark\n  and LLM-guided 3D Policy","summary":"  Generalizing language-conditioned robotic policies to new tasks remains a\nsignificant challenge, hampered by the lack of suitable simulation benchmarks.\nIn this paper, we address this gap by introducing GemBench, a novel benchmark\nto assess generalization capabilities of vision-language robotic manipulation\npolicies. GemBench incorporates seven general action primitives and four levels\nof generalization, spanning novel placements, rigid and articulated objects,\nand complex long-horizon tasks. We evaluate state-of-the-art approaches on\nGemBench and also introduce a new method. Our approach 3D-LOTUS leverages rich\n3D information for action prediction conditioned on language. While 3D-LOTUS\nexcels in both efficiency and performance on seen tasks, it struggles with\nnovel tasks. To address this, we present 3D-LOTUS++, a framework that\nintegrates 3D-LOTUS's motion planning capabilities with the task planning\ncapabilities of LLMs and the object grounding accuracy of VLMs. 3D-LOTUS++\nachieves state-of-the-art performance on novel tasks of GemBench, setting a new\nstandard for generalization in robotic manipulation. The benchmark, codes and\ntrained models are available at\nhttps://www.di.ens.fr/willow/research/gembench/.\n","authors":["Ricardo Garcia","Shizhe Chen","Cordelia Schmid"],"pdf_url":"https://arxiv.org/pdf/2410.01345v2.pdf","comment":"ICRA 2025"},{"id":"http://arxiv.org/abs/2407.19617v2","updated":"2025-03-01T19:16:08Z","published":"2024-07-29T00:39:51Z","title":"Leveraging Vision Language Models for Specialized Agricultural Tasks","summary":"  As Vision Language Models (VLMs) become increasingly accessible to farmers\nand agricultural experts, there is a growing need to evaluate their potential\nin specialized tasks. We present AgEval, a comprehensive benchmark for\nassessing VLMs' capabilities in plant stress phenotyping, offering a solution\nto the challenge of limited annotated data in agriculture. Our study explores\nhow general-purpose VLMs can be leveraged for domain-specific tasks with only a\nfew annotated examples, providing insights into their behavior and\nadaptability. AgEval encompasses 12 diverse plant stress phenotyping tasks,\nevaluating zero-shot and few-shot in-context learning performance of\nstate-of-the-art models including Claude, GPT, Gemini, and LLaVA. Our results\ndemonstrate VLMs' rapid adaptability to specialized tasks, with the\nbest-performing model showing an increase in F1 scores from 46.24% to 73.37% in\n8-shot identification. To quantify performance disparities across classes, we\nintroduce metrics such as the coefficient of variation (CV), revealing that\nVLMs' training impacts classes differently, with CV ranging from 26.02% to\n58.03%. We also find that strategic example selection enhances model\nreliability, with exact category examples improving F1 scores by 15.38% on\naverage. AgEval establishes a framework for assessing VLMs in agricultural\napplications, offering valuable benchmarks for future evaluations. Our findings\nsuggest that VLMs, with minimal few-shot examples, show promise as a viable\nalternative to traditional specialized models in plant stress phenotyping,\nwhile also highlighting areas for further refinement. Results and benchmark\ndetails are available at: https://github.com/arbab-ml/AgEval\n","authors":["Muhammad Arbab Arshad","Talukder Zaki Jubery","Tirtho Roy","Rim Nassiri","Asheesh K. Singh","Arti Singh","Chinmay Hegde","Baskar Ganapathysubramanian","Aditya Balu","Adarsh Krishnamurthy","Soumik Sarkar"],"pdf_url":"https://arxiv.org/pdf/2407.19617v2.pdf","comment":"Published at WACV 2025"},{"id":"http://arxiv.org/abs/2410.11019v2","updated":"2025-03-01T18:48:48Z","published":"2024-10-14T19:14:49Z","title":"ET-Former: Efficient Triplane Deformable Attention for 3D Semantic Scene\n  Completion From Monocular Camera","summary":"  We introduce ET-Former, a novel end-to-end algorithm for semantic scene\ncompletion using a single monocular camera. Our approach generates a semantic\noccupancy map from single RGB observation while simultaneously providing\nuncertainty estimates for semantic predictions. By designing a triplane-based\ndeformable attention mechanism, our approach improves geometric understanding\nof the scene than other SOTA approaches and reduces noise in semantic\npredictions. Additionally, through the use of a Conditional Variational\nAutoEncoder (CVAE), we estimate the uncertainties of these predictions. The\ngenerated semantic and uncertainty maps will help formulate navigation\nstrategies that facilitate safe and permissible decision making in the future.\nEvaluated on the Semantic-KITTI dataset, ET-Former achieves the highest\nIntersection over Union (IoU) and mean IoU (mIoU) scores while maintaining the\nlowest GPU memory usage, surpassing state-of-the-art (SOTA) methods. It\nimproves the SOTA scores of IoU from 44.71 to 51.49 and mIoU from 15.04 to\n16.30 on SeamnticKITTI test, with a notably low training memory consumption of\n10.9 GB. Project page: https://github.com/jingGM/ET-Former.git.\n","authors":["Jing Liang","He Yin","Xuewei Qi","Jong Jin Park","Min Sun","Rajasimman Madhivanan","Dinesh Manocha"],"pdf_url":"https://arxiv.org/pdf/2410.11019v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.17436v2","updated":"2025-03-01T18:48:22Z","published":"2025-02-24T18:59:55Z","title":"Towards Hierarchical Rectified Flow","summary":"  We formulate a hierarchical rectified flow to model data distributions. It\nhierarchically couples multiple ordinary differential equations (ODEs) and\ndefines a time-differentiable stochastic process that generates a data\ndistribution from a known source distribution. Each ODE resembles the ODE that\nis solved in a classic rectified flow, but differs in its domain, i.e.,\nlocation, velocity, acceleration, etc. Unlike the classic rectified flow\nformulation, which formulates a single ODE in the location domain and only\ncaptures the expected velocity field (sufficient to capture a multi-modal data\ndistribution), the hierarchical rectified flow formulation models the\nmulti-modal random velocity field, acceleration field, etc., in their entirety.\nThis more faithful modeling of the random velocity field enables integration\npaths to intersect when the underlying ODE is solved during data generation.\nIntersecting paths in turn lead to integration trajectories that are more\nstraight than those obtained in the classic rectified flow formulation, where\nintegration paths cannot intersect. This leads to modeling of data\ndistributions with fewer neural function evaluations. We empirically verify\nthis on synthetic 1D and 2D data as well as MNIST, CIFAR-10, and ImageNet-32\ndata. Our code is available at: https://riccizz.github.io/HRF/.\n","authors":["Yichi Zhang","Yici Yan","Alex Schwing","Zhizhen Zhao"],"pdf_url":"https://arxiv.org/pdf/2502.17436v2.pdf","comment":"ICLR 2025; Project Page: https://riccizz.github.io/HRF/"},{"id":"http://arxiv.org/abs/2409.19599v4","updated":"2025-03-01T17:31:31Z","published":"2024-09-29T07:32:14Z","title":"DATransNet: Dynamic Attention Transformer Network for Infrared Small\n  Target Detection","summary":"  Infrared small target detection (ISTD) is widely used in civilian and\nmilitary applications. However, ISTD encounters several challenges, including\nthe tendency for small and dim targets to be obscured by complex backgrounds.\nTo address this issue, we propose the Dynamic Attention Transformer Network\n(DATransNet), which aims to extract and preserve detailed information vital for\nsmall targets. DATransNet employs the Dynamic Attention Transformer (DATrans),\nsimulating central difference convolutions (CDC) to extract gradient features.\nFurthermore, we propose a global feature extraction module (GFEM) that offers a\ncomprehensive perspective to prevent the network from focusing solely on\ndetails while neglecting the global information. We compare the network with\nstate-of-the-art (SOTA) approaches and demonstrate that our method performs\neffectively. Our source code is available at\nhttps://github.com/greekinRoma/DATransNet.\n","authors":["Chen Hu","Yian Huang","Kexuan Li","Luping Zhang","Chang Long","Yiming Zhu","Tian Pu","Zhenming Peng"],"pdf_url":"https://arxiv.org/pdf/2409.19599v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09484v3","updated":"2025-03-01T17:29:09Z","published":"2024-11-14T14:37:50Z","title":"Image Matching Filtering and Refinement by Planes and Beyond","summary":"  This paper introduces a modular, non-deep learning method for filtering and\nrefining sparse correspondences in image matching. Assuming that motion flow\nwithin the scene can be approximated by local homography transformations,\nmatches are aggregated into overlapping clusters corresponding to virtual\nplanes using an iterative RANSAC-based approach, with non-conforming\ncorrespondences discarded. Moreover, the underlying planar structural design\nprovides an explicit map between local patches associated with the matches,\nenabling optional refinement of keypoint positions through cross-correlation\ntemplate matching after patch reprojection. Finally, to enhance robustness and\nfault-tolerance against violations of the piece-wise planar approximation\nassumption, a further strategy is designed for minimizing relative patch\ndistortion in the plane reprojection by introducing an intermediate homography\nthat projects both patches into a common plane. The proposed method is\nextensively evaluated on standard datasets and image matching pipelines, and\ncompared with state-of-the-art approaches. Unlike other current comparisons,\nthe proposed benchmark also takes into account the more general, real, and\npractical cases where camera intrinsics are unavailable. Experimental results\ndemonstrate that our proposed non-deep learning, geometry-based approach\nachieves performances that are either superior to or on par with recent\nstate-of-the-art deep learning methods. Finally, this study suggests that there\nare still development potential in actual image matching solutions in the\nconsidered research direction, which could be in the future incorporated in\nnovel deep image matching architectures.\n","authors":["Fabio Bellavia","Zhenjun Zhao","Luca Morelli","Fabio Remondino"],"pdf_url":"https://arxiv.org/pdf/2411.09484v3.pdf","comment":"project page: https://github.com/fb82/MiHo"},{"id":"http://arxiv.org/abs/2410.08208v3","updated":"2025-03-01T15:51:38Z","published":"2024-10-10T17:59:51Z","title":"SPA: 3D Spatial-Awareness Enables Effective Embodied Representation","summary":"  In this paper, we introduce SPA, a novel representation learning framework\nthat emphasizes the importance of 3D spatial awareness in embodied AI. Our\napproach leverages differentiable neural rendering on multi-view images to\nendow a vanilla Vision Transformer (ViT) with intrinsic spatial understanding.\nWe present the most comprehensive evaluation of embodied representation\nlearning to date, covering 268 tasks across 8 simulators with diverse policies\nin both single-task and language-conditioned multi-task scenarios. The results\nare compelling: SPA consistently outperforms more than 10 state-of-the-art\nrepresentation methods, including those specifically designed for embodied AI,\nvision-centric tasks, and multi-modal applications, while using less training\ndata. Furthermore, we conduct a series of real-world experiments to confirm its\neffectiveness in practical scenarios. These results highlight the critical role\nof 3D spatial awareness for embodied representation learning. Our strongest\nmodel takes more than 6000 GPU hours to train and we are committed to\nopen-sourcing all code and model weights to foster future research in embodied\nrepresentation learning. Project Page: https://haoyizhu.github.io/spa/.\n","authors":["Haoyi Zhu","Honghui Yang","Yating Wang","Jiange Yang","Limin Wang","Tong He"],"pdf_url":"https://arxiv.org/pdf/2410.08208v3.pdf","comment":"Project Page: https://haoyizhu.github.io/spa/"},{"id":"http://arxiv.org/abs/2501.03775v4","updated":"2025-03-01T15:41:19Z","published":"2025-01-07T13:30:54Z","title":"Strip R-CNN: Large Strip Convolution for Remote Sensing Object Detection","summary":"  While witnessed with rapid development, remote sensing object detection\nremains challenging for detecting high aspect ratio objects. This paper shows\nthat large strip convolutions are good feature representation learners for\nremote sensing object detection and can detect objects of various aspect ratios\nwell. Based on large strip convolutions, we build a new network architecture\ncalled Strip R-CNN, which is simple, efficient, and powerful. Unlike recent\nremote sensing object detectors that leverage large-kernel convolutions with\nsquare shapes, our Strip R-CNN takes advantage of sequential orthogonal large\nstrip convolutions in our backbone network StripNet to capture spatial\ninformation. In addition, we improve the localization capability of\nremote-sensing object detectors by decoupling the detection heads and equipping\nthe localization branch with strip convolutions in our strip head. Extensive\nexperiments on several benchmarks, for example DOTA, FAIR1M, HRSC2016, and\nDIOR, show that our Strip R-CNN can greatly improve previous work. In\nparticular, our 30M model achieves 82.75% mAP on DOTA-v1.0, setting a new\nstate-of-the-art record. Our code will be made publicly available.Code is\navailable at https://github.com/YXB-NKU/Strip-R-CNN.\n","authors":["Xinbin Yuan","Zhaohui Zheng","Yuxuan Li","Xialei Liu","Li Liu","Xiang Li","Qibin Hou","Ming-Ming Cheng"],"pdf_url":"https://arxiv.org/pdf/2501.03775v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.13524v2","updated":"2025-03-01T14:42:44Z","published":"2025-02-19T08:21:59Z","title":"MobileViM: A Light-weight and Dimension-independent Vision Mamba for 3D\n  Medical Image Analysis","summary":"  Efficient evaluation of three-dimensional (3D) medical images is crucial for\ndiagnostic and therapeutic practices in healthcare. Recent years have seen a\nsubstantial uptake in applying deep learning and computer vision to analyse and\ninterpret medical images. Traditional approaches, such as convolutional neural\nnetworks (CNNs) and vision transformers (ViTs), face significant computational\nchallenges, prompting the need for architectural advancements. Recent efforts\nhave led to the introduction of novel architectures like the ``Mamba'' model as\nalternative solutions to traditional CNNs or ViTs. The Mamba model excels in\nthe linear processing of one-dimensional data with low computational demands.\nHowever, Mamba's potential for 3D medical image analysis remains underexplored\nand could face significant computational challenges as the dimension increases.\nThis manuscript presents MobileViM, a streamlined architecture for efficient\nsegmentation of 3D medical images. In the MobileViM network, we invent a new\ndimension-independent mechanism and a dual-direction traversing approach to\nincorporate with a vision-Mamba-based framework. MobileViM also features a\ncross-scale bridging technique to improve efficiency and accuracy across\nvarious medical imaging modalities. With these enhancements, MobileViM achieves\nsegmentation speeds exceeding 90 frames per second (FPS) on a single graphics\nprocessing unit (i.e., NVIDIA RTX 4090). This performance is over 24 FPS faster\nthan the state-of-the-art deep learning models for processing 3D images with\nthe same computational resources. In addition, experimental evaluations\ndemonstrate that MobileViM delivers superior performance, with Dice similarity\nscores reaching 92.72%, 86.69%, 80.46%, and 77.43% for PENGWIN, BraTS2024,\nATLAS, and Toothfairy2 datasets, respectively, which significantly surpasses\nexisting models.\n","authors":["Wei Dai","Steven Wang","Jun Liu"],"pdf_url":"https://arxiv.org/pdf/2502.13524v2.pdf","comment":"The co-authors have not approved its submission to arXiv"},{"id":"http://arxiv.org/abs/2501.01791v2","updated":"2025-03-01T14:17:25Z","published":"2025-01-03T12:48:01Z","title":"Balancing Accuracy and Efficiency for Large-Scale SLAM: A Minimal Subset\n  Approach for Scalable Loop Closures","summary":"  Typical LiDAR SLAM architectures feature a front-end for odometry estimation\nand a back-end for refining and optimizing the trajectory and map, commonly\nthrough loop closures. However, loop closure detection in large-scale missions\npresents significant computational challenges due to the need to identify,\nverify, and process numerous candidate pairs for pose graph optimization.\nKeyframe sampling bridges the front-end and back-end by selecting frames for\nstoring and processing during global optimization. This article proposes an\nonline keyframe sampling approach that constructs the pose graph using the most\nimpactful keyframes for loop closure. We introduce the Minimal Subset Approach\n(MSA), which optimizes two key objectives: redundancy minimization and\ninformation preservation, implemented within a sliding window framework. By\noperating in the feature space rather than 3-D space, MSA efficiently reduces\nredundant keyframes while retaining essential information. In sum, evaluations\non diverse public datasets show that the proposed approach outperforms naive\nmethods in reducing false positive rates in place recognition, while delivering\nsuperior ATE and RPE in metric localization, without the need for manual\nparameter tuning. Additionally, MSA demonstrates efficiency and scalability by\nreducing memory usage and computational overhead during loop closure detection\nand pose graph optimization.\n","authors":["Nikolaos Stathoulopoulos","Christoforos Kanellakis","George Nikolakopoulos"],"pdf_url":"https://arxiv.org/pdf/2501.01791v2.pdf","comment":"8 pages, 7 Figures, 2 Tables. Submitted"},{"id":"http://arxiv.org/abs/2410.06912v2","updated":"2025-03-01T13:43:36Z","published":"2024-10-09T14:12:50Z","title":"Compositional Entailment Learning for Hyperbolic Vision-Language Models","summary":"  Image-text representation learning forms a cornerstone in vision-language\nmodels, where pairs of images and textual descriptions are contrastively\naligned in a shared embedding space. Since visual and textual concepts are\nnaturally hierarchical, recent work has shown that hyperbolic space can serve\nas a high-potential manifold to learn vision-language representation with\nstrong downstream performance. In this work, for the first time we show how to\nfully leverage the innate hierarchical nature of hyperbolic embeddings by\nlooking beyond individual image-text pairs. We propose Compositional Entailment\nLearning for hyperbolic vision-language models. The idea is that an image is\nnot only described by a sentence but is itself a composition of multiple object\nboxes, each with their own textual description. Such information can be\nobtained freely by extracting nouns from sentences and using openly available\nlocalized grounding models. We show how to hierarchically organize images,\nimage boxes, and their textual descriptions through contrastive and\nentailment-based objectives. Empirical evaluation on a hyperbolic\nvision-language model trained with millions of image-text pairs shows that the\nproposed compositional learning approach outperforms conventional Euclidean\nCLIP learning, as well as recent hyperbolic alternatives, with better zero-shot\nand retrieval generalization and clearly stronger hierarchical performance.\n","authors":["Avik Pal","Max van Spengler","Guido Maria D'Amely di Melendugno","Alessandro Flaborea","Fabio Galasso","Pascal Mettes"],"pdf_url":"https://arxiv.org/pdf/2410.06912v2.pdf","comment":"Accepted as oral paper at ICLR 2025"},{"id":"http://arxiv.org/abs/2412.09945v3","updated":"2025-03-01T13:24:41Z","published":"2024-12-13T08:10:47Z","title":"Going Beyond Feature Similarity: Effective Dataset distillation based on\n  Class-aware Conditional Mutual Information","summary":"  Dataset distillation (DD) aims to minimize the time and memory consumption\nneeded for training deep neural networks on large datasets, by creating a\nsmaller synthetic dataset that has similar performance to that of the full real\ndataset. However, current dataset distillation methods often result in\nsynthetic datasets that are excessively difficult for networks to learn from,\ndue to the compression of a substantial amount of information from the original\ndata through metrics measuring feature similarity, e,g., distribution matching\n(DM). In this work, we introduce conditional mutual information (CMI) to assess\nthe class-aware complexity of a dataset and propose a novel method by\nminimizing CMI. Specifically, we minimize the distillation loss while\nconstraining the class-aware complexity of the synthetic dataset by minimizing\nits empirical CMI from the feature space of pre-trained networks,\nsimultaneously. Conducting on a thorough set of experiments, we show that our\nmethod can serve as a general regularization method to existing DD methods and\nimprove the performance and training efficiency.\n","authors":["Xinhao Zhong","Bin Chen","Hao Fang","Xulin Gu","Shu-Tao Xia","En-Hui Yang"],"pdf_url":"https://arxiv.org/pdf/2412.09945v3.pdf","comment":"Accepted to ICLR 2025"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2502.20317v2","updated":"2025-03-01T23:21:58Z","published":"2025-02-27T17:42:52Z","title":"Mixture of Structural-and-Textual Retrieval over Text-rich Graph\n  Knowledge Bases","summary":"  Text-rich Graph Knowledge Bases (TG-KBs) have become increasingly crucial for\nanswering queries by providing textual and structural knowledge. However,\ncurrent retrieval methods often retrieve these two types of knowledge in\nisolation without considering their mutual reinforcement and some hybrid\nmethods even bypass structural retrieval entirely after neighboring\naggregation. To fill in this gap, we propose a Mixture of\nStructural-and-Textual Retrieval (MoR) to retrieve these two types of knowledge\nvia a Planning-Reasoning-Organizing framework. In the Planning stage, MoR\ngenerates textual planning graphs delineating the logic for answering queries.\nFollowing planning graphs, in the Reasoning stage, MoR interweaves structural\ntraversal and textual matching to obtain candidates from TG-KBs. In the\nOrganizing stage, MoR further reranks fetched candidates based on their\nstructural trajectory. Extensive experiments demonstrate the superiority of MoR\nin harmonizing structural and textual retrieval with insights, including uneven\nretrieving performance across different query logics and the benefits of\nintegrating structural trajectories for candidate reranking. Our code is\navailable at https://github.com/Yoega/MoR.\n","authors":["Yongjia Lei","Haoyu Han","Ryan A. Rossi","Franck Dernoncourt","Nedim Lipka","Mahantesh M Halappanavar","Jiliang Tang","Yu Wang"],"pdf_url":"https://arxiv.org/pdf/2502.20317v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2109.12887v5","updated":"2025-03-01T22:46:43Z","published":"2021-09-27T09:17:53Z","title":"ICPE: An Item Cluster-Wise Pareto-Efficient Framework for Recommendation\n  Debiasing","summary":"  Recommender system based on historical user-item interactions is of vital\nimportance for web-based services. However, the observed data used to train the\nrecommender model suffers from severe bias issues. Practically, the item\nfrequency distribution of the dataset is a highly skewed power-law\ndistribution. Interactions of a small fraction of head items account for almost\nthe whole training data. The normal training paradigm from such biased data\ntends to repetitively generate recommendations from the head items, which\nfurther exacerbates the biases and affects the exploration of potentially\ninteresting items from the niche set. In this work, we innovatively explore the\ncentral theme of recommendation debiasing from an item cluster-wise\nmulti-objective optimization perspective. Aiming to balance the learning on\nvarious item clusters that differ in popularity during the training process, we\npropose a model-agnostic framework namely Item Cluster-Wise Pareto-Efficient\nRecommendation (ICPE). In detail, we define our item cluster-wise optimization\ntarget as the recommender model should balance all item clusters that differ in\npopularity, thus we set the model learning on each item cluster as a unique\noptimization objective. To achieve this goal, we first explore items'\npopularity levels from a novel causal reasoning perspective. Then, we devise\npopularity discrepancy-based bisecting clustering to separate the item\nclusters. Next, we adaptively find the overall harmonious gradient direction\nfor cluster-wise optimization objectives from a Pareto-efficient solver.\nFinally, in the prediction stage, we perform counterfactual inference to\nfurther eliminate the impact of global propensity. Extensive experimental\nresults verify the superiorities of ICPE on overall recommendation performance\nand biases elimination.\n","authors":["Yule Wang","Xin Xin","Yue Ding","Yunzhe Li","Dong Wang"],"pdf_url":"https://arxiv.org/pdf/2109.12887v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.20207v2","updated":"2025-03-01T14:39:33Z","published":"2024-07-29T17:39:08Z","title":"QAEA-DR: A Unified Text Augmentation Framework for Dense Retrieval","summary":"  In dense retrieval, embedding long texts into dense vectors can result in\ninformation loss, leading to inaccurate query-text matching. Additionally,\nlow-quality texts with excessive noise or sparse key information are unlikely\nto align well with relevant queries. Recent studies mainly focus on improving\nthe sentence embedding model or retrieval process. In this work, we introduce a\nnovel text augmentation framework for dense retrieval. This framework\ntransforms raw documents into information-dense text formats, which supplement\nthe original texts to effectively address the aforementioned issues without\nmodifying embedding or retrieval methodologies. Two text representations are\ngenerated via large language models (LLMs) zero-shot prompting: question-answer\npairs and element-driven events. We term this approach QAEA-DR: unifying\nquestion-answer generation and event extraction in a text augmentation\nframework for dense retrieval. To further enhance the quality of generated\ntexts, a scoring-based evaluation and regeneration mechanism is introduced in\nLLM prompting. Our QAEA-DR model has a positive impact on dense retrieval,\nsupported by both theoretical analysis and empirical experiments.\n","authors":["Hongming Tan","Shaoxiong Zhan","Hai Lin","Hai-Tao Zheng","Wai Kin Chan"],"pdf_url":"https://arxiv.org/pdf/2407.20207v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17901v3","updated":"2025-03-01T00:49:44Z","published":"2024-03-26T17:43:08Z","title":"Search and Society: Reimagining Information Access for Radical Futures","summary":"  Information retrieval (IR) research must understand and contend with the\nsocial implications of the technology it produces. Instead of adopting a\nreactionary strategy of trying to mitigate potential social harms from emerging\ntechnologies, the community should aim to proactively set the research agenda\nfor the kinds of systems we should build inspired by diverse explicitly stated\nsociotechnical imaginaries. The sociotechnical imaginaries that underpin the\ndesign and development of information access technologies needs to be\nexplicitly articulated, and we need to develop theories of change in context of\nthese diverse perspectives. Our guiding future imaginaries must be informed by\nother academic fields, such as human-computer interaction, information\nsciences, media studies, design, science and technology studies, social\nsciences, humanities, democratic theory, and critical theory, as well as legal\nand policy experts, civil rights and social justice activists, and artists,\namong others. In this perspective paper, we motivate why the community must\nconsider this radical shift in how we do research and what we work on, and\nsketch a path forward towards this transformation.\n","authors":["Bhaskar Mitra"],"pdf_url":"https://arxiv.org/pdf/2403.17901v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.00619v1","updated":"2025-03-01T20:55:28Z","published":"2025-03-01T20:55:28Z","title":"PinLanding: Content-First Keyword Landing Page Generation via\n  Multi-Modal AI for Web-Scale Discovery","summary":"  Online platforms like Pinterest hosting vast content collections\ntraditionally rely on manual curation or user-generated search logs to create\nkeyword landing pages (KLPs) -- topic-centered collection pages that serve as\nentry points for content discovery. While manual curation ensures quality, it\ndoesn't scale to millions of collections, and search log approaches result in\nlimited topic coverage and imprecise content matching. In this paper, we\npresent PinLanding, a novel content-first architecture that transforms the way\nplatforms create topical collections. Instead of deriving topics from user\nbehavior, our system employs a multi-stage pipeline combining vision-language\nmodel (VLM) for attribute extraction, large language model (LLM) for topic\ngeneration, and a CLIP-based dual-encoder architecture for precise content\nmatching. Our model achieves 99.7% Recall@10 on Fashion200K benchmark,\ndemonstrating strong attribute understanding capabilities. In production\ndeployment for search engine optimization with 4.2 million shopping landing\npages, the system achieves a 4X increase in topic coverage and 14.29%\nimprovement in collection attribute precision over the traditional search\nlog-based approach via human evaluation. The architecture can be generalized\nbeyond search traffic to power various user experiences, including content\ndiscovery and recommendations, providing a scalable solution to transform\nunstructured content into curated topical collections across any content\ndomain.\n","authors":["Faye Zhang","Jasmine Wan","Qianyu Cheng","Jinfeng Rao"],"pdf_url":"https://arxiv.org/pdf/2503.00619v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.00501v1","updated":"2025-03-01T14:15:00Z","published":"2025-03-01T14:15:00Z","title":"Qilin: A Multimodal Information Retrieval Dataset with APP-level User\n  Sessions","summary":"  User-generated content (UGC) communities, especially those featuring\nmultimodal content, improve user experiences by integrating visual and textual\ninformation into results (or items). The challenge of improving user\nexperiences in complex systems with search and recommendation (S\\&R) services\nhas drawn significant attention from both academia and industry these years.\nHowever, the lack of high-quality datasets has limited the research progress on\nmultimodal S\\&R. To address the growing need for developing better S\\&R\nservices, we present a novel multimodal information retrieval dataset in this\npaper, namely Qilin. The dataset is collected from Xiaohongshu, a popular\nsocial platform with over 300 million monthly active users and an average\nsearch penetration rate of over 70\\%. In contrast to existing datasets,\n\\textsf{Qilin} offers a comprehensive collection of user sessions with\nheterogeneous results like image-text notes, video notes, commercial notes, and\ndirect answers, facilitating the development of advanced multimodal neural\nretrieval models across diverse task settings. To better model user\nsatisfaction and support the analysis of heterogeneous user behaviors, we also\ncollect extensive APP-level contextual signals and genuine user feedback.\nNotably, Qilin contains user-favored answers and their referred results for\nsearch requests triggering the Deep Query Answering (DQA) module. This allows\nnot only the training \\& evaluation of a Retrieval-augmented Generation (RAG)\npipeline, but also the exploration of how such a module would affect users'\nsearch behavior. Through comprehensive analysis and experiments, we provide\ninteresting findings and insights for further improving S\\&R systems. We hope\nthat \\textsf{Qilin} will significantly contribute to the advancement of\nmultimodal content platforms with S\\&R services in the future.\n","authors":["Jia Chen","Qian Dong","Haitao Li","Xiaohui He","Yan Gao","Shaosheng Cao","Yi Wu","Ping Yang","Chen Xu","Yao Hu","Qingyao Ai","Yiqun Liu"],"pdf_url":"https://arxiv.org/pdf/2503.00501v1.pdf","comment":"11 pages"},{"id":"http://arxiv.org/abs/2503.00479v1","updated":"2025-03-01T13:12:41Z","published":"2025-03-01T13:12:41Z","title":"Bayesian Active Learning for Multi-Criteria Comparative Judgement in\n  Educational Assessment","summary":"  Comparative Judgement (CJ) provides an alternative assessment approach by\nevaluating work holistically rather than breaking it into discrete criteria.\nThis method leverages human ability to make nuanced comparisons, yielding more\nreliable and valid assessments. CJ aligns with real-world evaluations, where\noverall quality emerges from the interplay of various elements. However,\nrubrics remain widely used in education, offering structured criteria for\ngrading and detailed feedback. This creates a gap between CJ's holistic ranking\nand the need for criterion-based performance breakdowns.\n  This paper addresses this gap using a Bayesian approach. We build on Bayesian\nCJ (BCJ) by Gray et al., which directly models preferences instead of using\nlikelihoods over total scores, allowing for expected ranks with uncertainty\nestimation. Their entropy-based active learning method selects the most\ninformative pairwise comparisons for assessors. We extend BCJ to handle\nmultiple independent learning outcome (LO) components, defined by a rubric,\nenabling both holistic and component-wise predictive rankings with uncertainty\nestimates. Additionally, we propose a method to aggregate entropies and\nidentify the most informative comparison for assessors. Experiments on\nsynthetic and real data demonstrate our method's effectiveness. Finally, we\naddress a key limitation of BCJ, which is the inability to quantify assessor\nagreement. We show how to derive agreement levels, enhancing transparency in\nassessment.\n","authors":["Andy Gray","Alma Rahat","Tom Crick","Stephen Lindsay"],"pdf_url":"https://arxiv.org/pdf/2503.00479v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.00353v1","updated":"2025-03-01T05:05:24Z","published":"2025-03-01T05:05:24Z","title":"U-NIAH: Unified RAG and LLM Evaluation for Long Context\n  Needle-In-A-Haystack","summary":"  Recent advancements in Large Language Models (LLMs) have expanded their\ncontext windows to unprecedented lengths, sparking debates about the necessity\nof Retrieval-Augmented Generation (RAG). To address the fragmented evaluation\nparadigms and limited cases in existing Needle-in-a-Haystack (NIAH), this paper\nintroduces U-NIAH, a unified framework that systematically compares LLMs and\nRAG methods in controlled long context settings. Our framework extends beyond\ntraditional NIAH by incorporating multi-needle, long-needle, and\nneedle-in-needle configurations, along with different retrieval settings, while\nleveraging the synthetic Starlight Academy dataset-a fictional magical\nuniverse-to eliminate biases from pre-trained knowledge. Through extensive\nexperiments, we investigate three research questions: (1) performance\ntrade-offs between LLMs and RAG, (2) error patterns in RAG, and (3) RAG's\nlimitations in complex settings. Our findings show that RAG significantly\nenhances smaller LLMs by mitigating the \"lost-in-the-middle\" effect and\nimproving robustness, achieving an 82.58% win-rate over LLMs. However, we\nobserve that retrieval noise and reverse chunk ordering degrade performance,\nwhile surprisingly, advanced reasoning LLMs exhibit reduced RAG compatibility\ndue to sensitivity to semantic distractors. We identify typical error patterns\nincluding omission due to noise, hallucination under high noise critical\ncondition, and self-doubt behaviors. Our work not only highlights the\ncomplementary roles of RAG and LLMs, but also provides actionable insights for\noptimizing deployments. Code: https://github.com/Tongji-KGLLM/U-NIAH.\n","authors":["Yunfan Gao","Yun Xiong","Wenlong Wu","Zijing Huang","Bohan Li","Haofen Wang"],"pdf_url":"https://arxiv.org/pdf/2503.00353v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.00309v1","updated":"2025-03-01T02:39:37Z","published":"2025-03-01T02:39:37Z","title":"Pseudo-Knowledge Graph: Meta-Path Guided Retrieval and In-Graph Text for\n  RAG-Equipped LLM","summary":"  The advent of Large Language Models (LLMs) has revolutionized natural\nlanguage processing. However, these models face challenges in retrieving\nprecise information from vast datasets. Retrieval-Augmented Generation (RAG)\nwas developed to combining LLMs with external information retrieval systems to\nenhance the accuracy and context of responses. Despite improvements, RAG still\nstruggles with comprehensive retrieval in high-volume, low-information-density\ndatabases and lacks relational awareness, leading to fragmented answers.\n  To address this, this paper introduces the Pseudo-Knowledge Graph (PKG)\nframework, designed to overcome these limitations by integrating Meta-path\nRetrieval, In-graph Text and Vector Retrieval into LLMs. By preserving natural\nlanguage text and leveraging various retrieval techniques, the PKG offers a\nricher knowledge representation and improves accuracy in information retrieval.\nExtensive evaluations using Open Compass and MultiHop-RAG benchmarks\ndemonstrate the framework's effectiveness in managing large volumes of data and\ncomplex relationships.\n","authors":["Yuxin Yang","Haoyang Wu","Tao Wang","Jia Yang","Hao Ma","Guojie Luo"],"pdf_url":"https://arxiv.org/pdf/2503.00309v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.00278v1","updated":"2025-03-01T01:11:24Z","published":"2025-03-01T01:11:24Z","title":"NeuroLit Navigator: A Neurosymbolic Approach to Scholarly Article\n  Searches for Systematic Reviews","summary":"  The introduction of Large Language Models (LLMs) has significantly impacted\nvarious fields, including education, for example, by enabling the creation of\npersonalized learning materials. However, their use in Systematic Reviews (SRs)\nreveals limitations such as restricted access to specialized vocabularies, lack\nof domain-specific reasoning, and a tendency to generate inaccurate\ninformation. Existing SR tools often rely on traditional NLP methods and fail\nto address these issues adequately. To overcome these challenges, we developed\nthe ``NeuroLit Navigator,'' a system that combines domain-specific LLMs with\nstructured knowledge sources like Medical Subject Headings (MeSH) and the\nUnified Medical Language System (UMLS). This integration enhances query\nformulation, expands search vocabularies, and deepens search scopes, enabling\nmore precise searches. Deployed in multiple universities and tested by over a\ndozen librarians, the NeuroLit Navigator has reduced the time required for\ninitial literature searches by 90\\%. Despite this efficiency, the initial set\nof articles retrieved can vary in relevance and quality. Nonetheless, the\nsystem has greatly improved the reproducibility of search results,\ndemonstrating its potential to support librarians in the SR process.\n","authors":["Vedant Khandelwal","Kaushik Roy","Valerie Lookingbill","Ritvik Garimella","Harshul Surana","Heather Heckman","Amit Sheth"],"pdf_url":"https://arxiv.org/pdf/2503.00278v1.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2503.00625v1","updated":"2025-03-01T21:28:12Z","published":"2025-03-01T21:28:12Z","title":"Perceptual Visual Quality Assessment: Principles, Methods, and Future\n  Directions","summary":"  As multimedia services such as video streaming, video conferencing, virtual\nreality (VR), and online gaming continue to expand, ensuring high perceptual\nvisual quality becomes a priority to maintain user satisfaction and\ncompetitiveness. However, multimedia content undergoes various distortions\nduring acquisition, compression, transmission, and storage, resulting in the\ndegradation of experienced quality. Thus, perceptual visual quality assessment\n(PVQA), which focuses on evaluating the quality of multimedia content based on\nhuman perception, is essential for optimizing user experiences in advanced\ncommunication systems. Several challenges are involved in the PVQA process,\nincluding diverse characteristics of multimedia content such as image, video,\nVR, point cloud, mesh, multimodality, etc., and complex distortion scenarios as\nwell as viewing conditions. In this paper, we first present an overview of PVQA\nprinciples and methods. This includes both subjective methods, where users\ndirectly rate their experiences, and objective methods, where algorithms\npredict human perception based on measurable factors such as bitrate, frame\nrate, and compression levels. Based on the basics of PVQA, quality predictors\nfor different multimedia data are then introduced. In addition to traditional\nimages and videos, immersive multimedia and generative artificial intelligence\n(GenAI) content are also discussed. Finally, the paper concludes with a\ndiscussion on the future directions of PVQA research.\n","authors":["Wei Zhou","Hadi Amirpour","Christian Timmerer","Guangtao Zhai","Patrick Le Callet","Alan C. Bovik"],"pdf_url":"https://arxiv.org/pdf/2503.00625v1.pdf","comment":"A tutorial and review"},{"id":"http://arxiv.org/abs/2503.00548v1","updated":"2025-03-01T16:31:02Z","published":"2025-03-01T16:31:02Z","title":"Unbiased Video Scene Graph Generation via Visual and Semantic Dual\n  Debiasing","summary":"  Video Scene Graph Generation (VidSGG) aims to capture dynamic relationships\namong entities by sequentially analyzing video frames and integrating visual\nand semantic information. However, VidSGG is challenged by significant biases\nthat skew predictions. To mitigate these biases, we propose a VIsual and\nSemantic Awareness (VISA) framework for unbiased VidSGG. VISA addresses visual\nbias through memory-enhanced temporal integration that enhances object\nrepresentations and concurrently reduces semantic bias by iteratively\nintegrating object features with comprehensive semantic information derived\nfrom triplet relationships. This visual-semantics dual debiasing approach\nresults in more unbiased representations of complex scene dynamics. Extensive\nexperiments demonstrate the effectiveness of our method, where VISA outperforms\nexisting unbiased VidSGG approaches by a substantial margin (e.g., +13.1%\nimprovement in mR@20 and mR@50 for the SGCLS task under Semi Constraint).\n","authors":["Yanjun Li","Zhaoyang Li","Honghui Chen","Lizhi Xu"],"pdf_url":"https://arxiv.org/pdf/2503.00548v1.pdf","comment":"17 pages, 8 figures, CVPR 2025"},{"id":"http://arxiv.org/abs/2503.00455v1","updated":"2025-03-01T11:35:17Z","published":"2025-03-01T11:35:17Z","title":"PodAgent: A Comprehensive Framework for Podcast Generation","summary":"  Existing Existing automatic audio generation methods struggle to generate\npodcast-like audio programs effectively. The key challenges lie in in-depth\ncontent generation, appropriate and expressive voice production. This paper\nproposed PodAgent, a comprehensive framework for creating audio programs.\nPodAgent 1) generates informative topic-discussion content by designing a\nHost-Guest-Writer multi-agent collaboration system, 2) builds a voice pool for\nsuitable voice-role matching and 3) utilizes LLM-enhanced speech synthesis\nmethod to generate expressive conversational speech. Given the absence of\nstandardized evaluation criteria for podcast-like audio generation, we\ndeveloped comprehensive assessment guidelines to effectively evaluate the\nmodel's performance. Experimental results demonstrate PodAgent's effectiveness,\nsignificantly surpassing direct GPT-4 generation in topic-discussion dialogue\ncontent, achieving an 87.4% voice-matching accuracy, and producing more\nexpressive speech through LLM-guided synthesis. Demo page:\nhttps://podcast-agent.github.io/demo/. Source code:\nhttps://github.com/yujxx/PodAgent.\n","authors":["Yujia Xiao","Lei He","Haohan Guo","Fenglong Xie","Tan Lee"],"pdf_url":"https://arxiv.org/pdf/2503.00455v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.00374v1","updated":"2025-03-01T07:02:30Z","published":"2025-03-01T07:02:30Z","title":"MIRROR: Multi-Modal Pathological Self-Supervised Representation Learning\n  via Modality Alignment and Retention","summary":"  Histopathology and transcriptomics are fundamental modalities in oncology,\nencapsulating the morphological and molecular aspects of the disease.\nMulti-modal self-supervised learning has demonstrated remarkable potential in\nlearning pathological representations by integrating diverse data sources.\nConventional multi-modal integration methods primarily emphasize modality\nalignment, while paying insufficient attention to retaining the\nmodality-specific structures. However, unlike conventional scenarios where\nmulti-modal inputs share highly overlapping features, histopathology and\ntranscriptomics exhibit pronounced heterogeneity, offering orthogonal yet\ncomplementary insights. Histopathology provides morphological and spatial\ncontext, elucidating tissue architecture and cellular topology, whereas\ntranscriptomics delineates molecular signatures through gene expression\npatterns. This inherent disparity introduces a major challenge in aligning them\nwhile maintaining modality-specific fidelity. To address these challenges, we\npresent MIRROR, a novel multi-modal representation learning method designed to\nfoster both modality alignment and retention. MIRROR employs dedicated encoders\nto extract comprehensive features for each modality, which is further\ncomplemented by a modality alignment module to achieve seamless integration\nbetween phenotype patterns and molecular profiles. Furthermore, a modality\nretention module safeguards unique attributes from each modality, while a style\nclustering module mitigates redundancy and enhances disease-relevant\ninformation by modeling and aligning consistent pathological signatures within\na clustering space. Extensive evaluations on TCGA cohorts for cancer subtyping\nand survival analysis highlight MIRROR's superior performance, demonstrating\nits effectiveness in constructing comprehensive oncological feature\nrepresentations and benefiting the cancer diagnosis.\n","authors":["Tianyi Wang","Jianan Fan","Dingxin Zhang","Dongnan Liu","Yong Xia","Heng Huang","Weidong Cai"],"pdf_url":"https://arxiv.org/pdf/2503.00374v1.pdf","comment":"10 pages, 5 figures, 3 tables"}]},"2025-03-04T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2502.19732v3","updated":"2025-03-04T03:46:23Z","published":"2025-02-27T03:53:45Z","title":"Speculative Decoding and Beyond: An In-Depth Survey of Techniques","summary":"  Sequential dependencies present a fundamental bottleneck in deploying\nlarge-scale autoregressive models, particularly for real-time applications.\nWhile traditional optimization approaches like pruning and quantization often\ncompromise model quality, recent advances in generation-refinement frameworks\ndemonstrate that this trade-off can be significantly mitigated.\n  This survey presents a comprehensive taxonomy of generation-refinement\nframeworks, analyzing methods across autoregressive sequence tasks. We\ncategorize methods based on their generation strategies (from simple n-gram\nprediction to sophisticated draft models) and refinement mechanisms (including\nsingle-pass verification and iterative approaches). Through systematic analysis\nof both algorithmic innovations and system-level implementations, we examine\ndeployment strategies across computing environments and explore applications\nspanning text, images, and speech generation. This systematic examination of\nboth theoretical frameworks and practical implementations provides a foundation\nfor future research in efficient autoregressive decoding.\n","authors":["Yunhai Hu","Zining Liu","Zhenyuan Dong","Tianfan Peng","Bradley McDanel","Sai Qian Zhang"],"pdf_url":"https://arxiv.org/pdf/2502.19732v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.06057v3","updated":"2025-03-04T14:33:50Z","published":"2024-07-08T15:59:44Z","title":"Variational Best-of-N Alignment","summary":"  Best-of-N (BoN) is a popular and effective algorithm for aligning language\nmodels to human preferences. The algorithm works as follows: at inference time,\nN samples are drawn from the language model, and the sample with the highest\nreward, as judged by a reward model, is returned as the output. Despite its\neffectiveness, BoN is computationally expensive; it reduces sampling throughput\nby a factor of N. To make BoN more efficient at inference time, one strategy is\nto fine-tune the language model to mimic what BoN does during inference. To\nachieve this, we derive the distribution induced by the BoN algorithm. We then\npropose to fine-tune the language model to minimize backward KL divergence to\nthe BoN distribution. Our approach is analogous to mean-field variational\ninference and, thus, we term it variational BoN (vBoN). To the extent this\nfine-tuning is successful and we end up with a good approximation, we have\nreduced the inference cost by a factor of N. Our experiments on controlled\ngeneration and summarization tasks show that BoN is the most effective\nalignment method, and our variational approximation to BoN achieves the closest\nperformance to BoN and surpasses models fine-tuned using the standard\nKL-constrained RL objective. In the controlled generation task, vBoN appears\nmore frequently on the Pareto frontier of reward and KL divergence compared to\nother alignment methods. In the summarization task, vBoN achieves high reward\nvalues across various sampling temperatures.\n","authors":["Afra Amini","Tim Vieira","Elliott Ash","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2407.06057v3.pdf","comment":"Accepted at ICLR 2025"},{"id":"http://arxiv.org/abs/2502.12110v3","updated":"2025-03-04T15:09:10Z","published":"2025-02-17T18:36:14Z","title":"A-MEM: Agentic Memory for LLM Agents","summary":"  While large language model (LLM) agents can effectively use external tools\nfor complex real-world tasks, they require memory systems to leverage\nhistorical experiences. Current memory systems enable basic storage and\nretrieval but lack sophisticated memory organization, despite recent attempts\nto incorporate graph databases. Moreover, these systems' fixed operations and\nstructures limit their adaptability across diverse tasks. To address this\nlimitation, this paper proposes a novel agentic memory system for LLM agents\nthat can dynamically organize memories in an agentic way. Following the basic\nprinciples of the Zettelkasten method, we designed our memory system to create\ninterconnected knowledge networks through dynamic indexing and linking. When a\nnew memory is added, we generate a comprehensive note containing multiple\nstructured attributes, including contextual descriptions, keywords, and tags.\nThe system then analyzes historical memories to identify relevant connections,\nestablishing links where meaningful similarities exist. Additionally, this\nprocess enables memory evolution - as new memories are integrated, they can\ntrigger updates to the contextual representations and attributes of existing\nhistorical memories, allowing the memory network to continuously refine its\nunderstanding. Our approach combines the structured organization principles of\nZettelkasten with the flexibility of agent-driven decision making, allowing for\nmore adaptive and context-aware memory management. Empirical experiments on six\nfoundation models show superior improvement against existing SOTA baselines.\nThe source code for evaluating performance is available at\nhttps://github.com/WujiangXu/AgenticMemory, while the source code of agentic\nmemory system is available at https://github.com/agiresearch/A-mem.\n","authors":["Wujiang Xu","Zujie Liang","Kai Mei","Hang Gao","Juntao Tan","Yongfeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2502.12110v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.14093v4","updated":"2025-03-04T08:24:20Z","published":"2024-05-23T01:43:54Z","title":"A Survey on Vision-Language-Action Models for Embodied AI","summary":"  Embodied AI is widely recognized as a key element of artificial general\nintelligence because it involves controlling embodied agents to perform tasks\nin the physical world. Building on the success of large language models and\nvision-language models, a new category of multimodal models -- referred to as\nvision-language-action models (VLAs) -- has emerged to address\nlanguage-conditioned robotic tasks in embodied AI by leveraging their distinct\nability to generate actions. In recent years, a myriad of VLAs have been\ndeveloped, making it imperative to capture the rapidly evolving landscape\nthrough a comprehensive survey. To this end, we present the first survey on\nVLAs for embodied AI. This work provides a detailed taxonomy of VLAs, organized\ninto three major lines of research. The first line focuses on individual\ncomponents of VLAs. The second line is dedicated to developing control policies\nadept at predicting low-level actions. The third line comprises high-level task\nplanners capable of decomposing long-horizon tasks into a sequence of subtasks,\nthereby guiding VLAs to follow more general user instructions. Furthermore, we\nprovide an extensive summary of relevant resources, including datasets,\nsimulators, and benchmarks. Finally, we discuss the challenges faced by VLAs\nand outline promising future directions in embodied AI. We have created a\nproject associated with this survey, which is available at\nhttps://github.com/yueen-ma/Awesome-VLA.\n","authors":["Yueen Ma","Zixing Song","Yuzheng Zhuang","Jianye Hao","Irwin King"],"pdf_url":"https://arxiv.org/pdf/2405.14093v4.pdf","comment":"Project page: https://github.com/yueen-ma/Awesome-VLA"},{"id":"http://arxiv.org/abs/2410.23771v3","updated":"2025-03-04T04:07:01Z","published":"2024-10-31T09:39:28Z","title":"What is Wrong with Perplexity for Long-context Language Modeling?","summary":"  Handling long-context inputs is crucial for large language models (LLMs) in\ntasks such as extended conversations, document summarization, and many-shot\nin-context learning. While recent approaches have extended the context windows\nof LLMs and employed perplexity (PPL) as a standard evaluation metric, PPL has\nproven unreliable for assessing long-context capabilities. The underlying cause\nof this limitation has remained unclear. In this work, we provide a\ncomprehensive explanation for this issue. We find that PPL overlooks key\ntokens, which are essential for long-context understanding, by averaging across\nall tokens and thereby obscuring the true performance of models in long-context\nscenarios. To address this, we propose \\textbf{LongPPL}, a novel metric that\nfocuses on key tokens by employing a long-short context contrastive method to\nidentify them. Our experiments demonstrate that LongPPL strongly correlates\nwith performance on various long-context benchmarks (e.g., Pearson correlation\nof -0.96), significantly outperforming traditional PPL in predictive accuracy.\nAdditionally, we introduce \\textbf{LongCE} (Long-context Cross-Entropy) loss, a\nre-weighting strategy for fine-tuning that prioritizes key tokens, leading to\nconsistent improvements across diverse benchmarks. In summary, these\ncontributions offer deeper insights into the limitations of PPL and present\neffective solutions for accurately evaluating and enhancing the long-context\ncapabilities of LLMs. Code is available at https://github.com/PKU-ML/LongPPL.\n","authors":["Lizhe Fang","Yifei Wang","Zhaoyang Liu","Chenheng Zhang","Stefanie Jegelka","Jinyang Gao","Bolin Ding","Yisen Wang"],"pdf_url":"https://arxiv.org/pdf/2410.23771v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02316v4","updated":"2025-03-04T09:10:59Z","published":"2024-11-04T17:40:39Z","title":"Evaluating Creative Short Story Generation in Humans and Large Language\n  Models","summary":"  Story-writing is a fundamental aspect of human imagination, relying heavily\non creativity to produce narratives that are novel, effective, and surprising.\nWhile large language models (LLMs) have demonstrated the ability to generate\nhigh-quality stories, their creative story-writing capabilities remain\nunder-explored. In this work, we conduct a systematic analysis of creativity in\nshort story generation across 60 LLMs and 60 people using a five-sentence\ncreative story-writing task. We use measures to automatically evaluate model-\nand human-generated stories across several dimensions of creativity, including\nnovelty, surprise, diversity, and linguistic complexity. We also collect\ncreativity ratings and Turing Test classifications from non-expert and expert\nhuman raters and LLMs. Automated metrics show that LLMs generate stylistically\ncomplex stories, but tend to fall short in terms of novelty, surprise and\ndiversity when compared to average human writers. Expert ratings generally\ncoincide with automated metrics. However, LLMs and non-experts rate LLM stories\nto be more creative than human-generated stories. We discuss why and how these\ndifferences in ratings occur, and their implications for both human and\nartificial creativity.\n","authors":["Mete Ismayilzada","Claire Stevenson","Lonneke van der Plas"],"pdf_url":"https://arxiv.org/pdf/2411.02316v4.pdf","comment":"Submitted to ICCC 2025"},{"id":"http://arxiv.org/abs/2503.03064v1","updated":"2025-03-04T23:59:08Z","published":"2025-03-04T23:59:08Z","title":"Improving LLM-as-a-Judge Inference with the Judgment Distribution","summary":"  Using language models to scalably approximate human preferences on text\nquality (LLM-as-a-judge) has become a standard practice applicable to many\ntasks. A judgment is often extracted from the judge's textual output alone,\ntypically with greedy decoding. However, LLM judges naturally provide\ndistributions over judgment tokens, inviting a breadth of inference methods for\nextracting fine-grained preferences. We find that taking the mean of the\njudgment distribution consistently outperforms taking the mode (i.e. greedy\ndecoding) in all evaluation settings (i.e. pointwise, pairwise, and listwise).\nWe further explore novel methods of deriving preferences from judgment\ndistributions, and find that methods incorporating risk aversion often improve\nperformance. Lastly, we analyze LLM-as-a-judge paired with chain-of-thought\n(CoT) prompting, showing that CoT can collapse the spread of the judgment\ndistribution, often harming performance. Our findings suggest leveraging\ndistributional output can improve LLM-as-a-judge, as opposed to using the text\ninterface alone.\n","authors":["Victor Wang","Michael J. Q. Zhang","Eunsol Choi"],"pdf_url":"https://arxiv.org/pdf/2503.03064v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03062v1","updated":"2025-03-04T23:52:49Z","published":"2025-03-04T23:52:49Z","title":"Semi-Supervised In-Context Learning: A Baseline Study","summary":"  Most existing work in data selection for In-Context Learning (ICL) has\nfocused on constructing demonstrations from ground truth annotations, with\nlimited attention given to selecting reliable self-generated annotations. In\nthis work, we propose a three-step semi-supervised ICL framework: annotation\ngeneration, demonstration selection, and semi-supervised inference. Our\nbaseline, Naive-SemiICL, which prompts select high-confidence self-generated\ndemonstrations for ICL prompting, outperforms a 16-shot baseline by an average\nof 9.94% across 16 datasets. We further introduce IterPSD, an annotation\napproach that refines pseudo-demonstrations iteratively, achieving up to 6.8%\nadditional gains in classification tasks. Lastly, we reveal a scaling law for\nsemi-supervised ICL, where models achieve optimal performance with over 1,000\ndemonstrations.\n","authors":["Zhengyao Gu","Henry Peng Zou","Yankai Chen","Aiwei Liu","Weizhi Zhang","Philip S. Yu"],"pdf_url":"https://arxiv.org/pdf/2503.03062v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.14338v2","updated":"2025-03-04T23:24:09Z","published":"2025-02-20T07:47:03Z","title":"English Please: Evaluating Machine Translation for Multilingual Bug\n  Reports","summary":"  Accurate translation of bug reports is critical for efficient collaboration\nin global software development. In this study, we conduct the first\ncomprehensive evaluation of machine translation (MT) performance on bug\nreports, analyzing the capabilities of DeepL, AWS Translate, and ChatGPT using\ndata from the Visual Studio Code GitHub repository, specifically focusing on\nreports labeled with the english-please tag. To thoroughly assess the accuracy\nand effectiveness of each system, we employ multiple machine translation\nmetrics, including BLEU, BERTScore, COMET, METEOR, and ROUGE. Our findings\nindicate that DeepL consistently outperforms the other systems across most\nautomatic metrics, demonstrating strong lexical and semantic alignment. AWS\nTranslate performs competitively, particularly in METEOR, while ChatGPT lags in\nkey metrics. This study underscores the importance of domain adaptation for\ntranslating technical texts and offers guidance for integrating automated\ntranslation into bug-triaging workflows. Moreover, our results establish a\nfoundation for future research to refine machine translation solutions for\nspecialized engineering contexts. The code and dataset for this paper are\navailable at GitHub: https://github.com/av9ash/gitbugs/tree/main/multilingual.\n","authors":["Avinash Patil","Aryan Jadon"],"pdf_url":"https://arxiv.org/pdf/2502.14338v2.pdf","comment":"8 Pages, 4 Figures, 3 Tables"},{"id":"http://arxiv.org/abs/2503.03044v1","updated":"2025-03-04T22:50:17Z","published":"2025-03-04T22:50:17Z","title":"QE4PE: Word-level Quality Estimation for Human Post-Editing","summary":"  Word-level quality estimation (QE) detects erroneous spans in machine\ntranslations, which can direct and facilitate human post-editing. While the\naccuracy of word-level QE systems has been assessed extensively, their\nusability and downstream influence on the speed, quality and editing choices of\nhuman post-editing remain understudied. Our QE4PE study investigates the impact\nof word-level QE on machine translation (MT) post-editing in a realistic\nsetting involving 42 professional post-editors across two translation\ndirections. We compare four error-span highlight modalities, including\nsupervised and uncertainty-based word-level QE methods, for identifying\npotential errors in the outputs of a state-of-the-art neural MT model.\nPost-editing effort and productivity are estimated by behavioral logs, while\nquality improvements are assessed by word- and segment-level human annotation.\nWe find that domain, language and editors' speed are critical factors in\ndetermining highlights' effectiveness, with modest differences between\nhuman-made and automated QE highlights underlining a gap between accuracy and\nusability in professional workflows.\n","authors":["Gabriele Sarti","Vilém Zouhar","Grzegorz Chrupała","Ana Guerberof-Arenas","Malvina Nissim","Arianna Bisazza"],"pdf_url":"https://arxiv.org/pdf/2503.03044v1.pdf","comment":"Code: https://github.com/gsarti/qe4pe. Dataset:\n  https://huggingface.co/datasets/gsarti/qe4pe"},{"id":"http://arxiv.org/abs/2503.03040v1","updated":"2025-03-04T22:45:24Z","published":"2025-03-04T22:45:24Z","title":"SAGE: Steering and Refining Dialog Generation with State-Action\n  Augmentation","summary":"  Recent advances in large language models have demonstrated impressive\ncapabilities in task-oriented applications, yet building emotionally\nintelligent chatbots that can engage in natural, strategic conversations\nremains a challenge. We present a novel approach called SAGE that uses latent\nvariables to control long-horizon behavior in dialogue generation. At the core\nof our method is the State-Action Chain (SAC), which augments standard language\nmodel fine-tuning by introducing latent variables that encapsulate emotional\nstates and conversational strategies between dialogue turns. During inference,\nthese variables are generated before each response, enabling coarse-grained\ncontrol over dialogue progression while maintaining natural interaction\npatterns. We also introduce a self-improvement pipeline that leverages dialogue\ntree search, LLM-based reward modeling, and targeted fine-tuning to optimize\nconversational trajectories. Our experimental results show that models trained\nwith this approach demonstrate improved performance in emotional intelligence\nmetrics while maintaining strong capabilities on LLM benchmarks. The discrete\nnature of our latent variables facilitates search-based strategies and provides\na foundation for future applications of reinforcement learning to dialogue\nsystems, where learning can occur at the state level rather than the token\nlevel.\n","authors":["Yizhe Zhang","Navdeep Jaitly"],"pdf_url":"https://arxiv.org/pdf/2503.03040v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03032v1","updated":"2025-03-04T22:19:52Z","published":"2025-03-04T22:19:52Z","title":"SAFE: A Sparse Autoencoder-Based Framework for Robust Query Enrichment\n  and Hallucination Mitigation in LLMs","summary":"  Despite the state-of-the-art performance of Large Language Models (LLMs),\nthese models often suffer from hallucinations, which can undermine their\nperformance in critical applications. In this work, we propose SAFE, a novel\nmethod for detecting and mitigating hallucinations by leveraging Sparse\nAutoencoders (SAEs). While hallucination detection techniques and SAEs have\nbeen explored independently, their synergistic application in a comprehensive\nsystem, particularly for hallucination-aware query enrichment, has not been\nfully investigated. To validate the effectiveness of SAFE, we evaluate it on\ntwo models with available SAEs across three diverse cross-domain datasets\ndesigned to assess hallucination problems. Empirical results demonstrate that\nSAFE consistently improves query generation accuracy and mitigates\nhallucinations across all datasets, achieving accuracy improvements of up to\n29.45%.\n","authors":["Samir Abdaljalil","Filippo Pallucchini","Andrea Seveso","Hasan Kurban","Fabio Mercorio","Erchin Serpedin"],"pdf_url":"https://arxiv.org/pdf/2503.03032v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.10813v2","updated":"2025-03-04T22:19:41Z","published":"2024-10-14T17:59:44Z","title":"LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive\n  Memory","summary":"  Recent large language model (LLM)-driven chat assistant systems have\nintegrated memory components to track user-assistant chat histories, enabling\nmore accurate and personalized responses. However, their long-term memory\ncapabilities in sustained interactions remain underexplored. We introduce\nLongMemEval, a comprehensive benchmark designed to evaluate five core long-term\nmemory abilities of chat assistants: information extraction, multi-session\nreasoning, temporal reasoning, knowledge updates, and abstention. With 500\nmeticulously curated questions embedded within freely scalable user-assistant\nchat histories, LongMemEval presents a significant challenge to existing\nlong-term memory systems, with commercial chat assistants and long-context LLMs\nshowing a 30% accuracy drop on memorizing information across sustained\ninteractions. We then present a unified framework that breaks down the\nlong-term memory design into three stages: indexing, retrieval, and reading.\nBuilt upon key experimental insights, we propose several memory design\noptimizations including session decomposition for value granularity,\nfact-augmented key expansion for indexing, and time-aware query expansion for\nrefining the search scope. Extensive experiments show that these optimizations\ngreatly improve both memory recall and downstream question answering on\nLongMemEval. Overall, our study provides valuable resources and guidance for\nadvancing the long-term memory capabilities of LLM-based chat assistants,\npaving the way toward more personalized and reliable conversational AI. Our\nbenchmark and code are publicly available at\nhttps://github.com/xiaowu0162/LongMemEval.\n","authors":["Di Wu","Hongwei Wang","Wenhao Yu","Yuwei Zhang","Kai-Wei Chang","Dong Yu"],"pdf_url":"https://arxiv.org/pdf/2410.10813v2.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2503.03008v1","updated":"2025-03-04T21:08:17Z","published":"2025-03-04T21:08:17Z","title":"One Model to Train them All: Hierarchical Self-Distillation for Enhanced\n  Early Layer Embeddings","summary":"  Deploying language models often requires handling model size vs. performance\ntrade-offs to satisfy downstream latency constraints while preserving the\nmodel's usefulness. Model distillation is commonly employed to reduce model\nsize while maintaining acceptable performance. However, distillation can be\ninefficient since it involves multiple training steps. In this work, we\nintroduce MODULARSTARENCODER, a modular multi-exit encoder with 1B parameters,\nuseful for multiple tasks within the scope of code retrieval.\nMODULARSTARENCODER is trained with a novel self-distillation mechanism that\nsignificantly improves lower-layer representations-allowing different portions\nof the model to be used while still maintaining a good trade-off in terms of\nperformance. Our architecture focuses on enhancing text-to-code and\ncode-to-code search by systematically capturing syntactic and semantic\nstructures across multiple levels of representation. Specific encoder layers\nare targeted as exit heads, allowing higher layers to guide earlier layers\nduring training. This self-distillation effect improves intermediate\nrepresentations, increasing retrieval recall at no extra training cost. In\naddition to the multi-exit scheme, our approach integrates a repository-level\ncontextual loss that maximally utilizes the training context window, further\nenhancing the learned representations. We also release a new dataset\nconstructed via code translation, seamlessly expanding traditional text-to-code\nbenchmarks with code-to-code pairs across diverse programming languages.\nExperimental results highlight the benefits of self-distillation through\nmulti-exit supervision.\n","authors":["Andrea Gurioli","Federico Pennino","João Monteiro","Maurizio Gabbrielli"],"pdf_url":"https://arxiv.org/pdf/2503.03008v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03005v1","updated":"2025-03-04T21:04:21Z","published":"2025-03-04T21:04:21Z","title":"Will I Get Hate Speech Predicting the Volume of Abusive Replies before\n  Posting in Social Media","summary":"  Despite the growing body of research tackling offensive language in social\nmedia, this research is predominantly reactive, determining if content already\nposted in social media is abusive. There is a gap in predictive approaches,\nwhich we address in our study by enabling to predict the volume of abusive\nreplies a tweet will receive after being posted. We formulate the problem from\nthe perspective of a social media user asking: ``if I post a certain message on\nsocial media, is it possible to predict the volume of abusive replies it might\nreceive?'' We look at four types of features, namely text, text metadata, tweet\nmetadata, and account features, which also help us understand the extent to\nwhich the user or the content helps predict the number of abusive replies.\nThis, in turn, helps us develop a model to support social media users in\nfinding the best way to post content. One of our objectives is also to\ndetermine the extent to which the volume of abusive replies that a tweet will\nget are motivated by the content of the tweet or by the identity of the user\nposting it. Our study finds that one can build a model that performs\ncompetitively by developing a comprehensive set of features derived from the\ncontent of the message that is going to be posted. In addition, our study\nsuggests that features derived from the user's identity do not impact model\nperformance, hence suggesting that it is especially the content of a post that\ntriggers abusive replies rather than who the user is.\n","authors":["Raneem Alharthia","Rajwa Alharthib","Ravi Shekharc","Aiqi Jiangd","Arkaitz Zubiagaa"],"pdf_url":"https://arxiv.org/pdf/2503.03005v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02993v1","updated":"2025-03-04T20:39:07Z","published":"2025-03-04T20:39:07Z","title":"Zero-Shot Multi-Label Classification of Bangla Documents: Large Decoders\n  Vs. Classic Encoders","summary":"  Bangla, a language spoken by over 300 million native speakers and ranked as\nthe sixth most spoken language worldwide, presents unique challenges in natural\nlanguage processing (NLP) due to its complex morphological characteristics and\nlimited resources. While recent Large Decoder Based models (LLMs), such as GPT,\nLLaMA, and DeepSeek, have demonstrated excellent performance across many NLP\ntasks, their effectiveness in Bangla remains largely unexplored. In this paper,\nwe establish the first benchmark comparing decoder-based LLMs with classic\nencoder-based models for Zero-Shot Multi-Label Classification (Zero-Shot-MLC)\ntask in Bangla. Our evaluation of 32 state-of-the-art models reveals that,\nexisting so-called powerful encoders and decoders still struggle to achieve\nhigh accuracy on the Bangla Zero-Shot-MLC task, suggesting a need for more\nresearch and resources for Bangla NLP.\n","authors":["Souvika Sarkar","Md. Najib Hasan","Santu Karmaker"],"pdf_url":"https://arxiv.org/pdf/2503.02993v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02989v1","updated":"2025-03-04T20:32:27Z","published":"2025-03-04T20:32:27Z","title":"Effectively Steer LLM To Follow Preference via Building Confident\n  Directions","summary":"  Having an LLM that aligns with human preferences is essential for\naccommodating individual needs, such as maintaining writing style or generating\nspecific topics of interest. The majority of current alignment methods rely on\nfine-tuning or prompting, which can be either costly or difficult to control.\nModel steering algorithms, which modify the model output by constructing\nspecific steering directions, are typically easy to implement and\noptimization-free. However, their capabilities are typically limited to\nsteering the model into one of the two directions (i.e., bidirectional\nsteering), and there has been no theoretical understanding to guarantee their\nperformance. In this work, we propose a theoretical framework to understand and\nquantify the model steering methods. Inspired by the framework, we propose a\nconfident direction steering method (CONFST) that steers LLMs via modifying\ntheir activations at inference time. More specifically, CONFST builds a\nconfident direction that is closely aligned with users' preferences, and this\ndirection is then added to the activations of the LLMs to effectively steer the\nmodel output. Our approach offers three key advantages over popular\nbidirectional model steering methods: 1) It is more powerful, since multiple\n(i.e. more than two) users' preferences can be aligned simultaneously; 2) It is\nsimple to implement, since there is no need to determine which layer to add the\nsteering vector to; 3) No explicit user instruction is required. We validate\nour method on GPT-2 XL (1.5B), Mistral (7B) and Gemma-it (9B) models for tasks\nthat require shifting the output of LLMs across various topics and styles,\nachieving superior performance over competing methods.\n","authors":["Bingqing Song","Boran Han","Shuai Zhang","Hao Wang","Haoyang Fang","Bonan Min","Yuyang Wang","Mingyi Hong"],"pdf_url":"https://arxiv.org/pdf/2503.02989v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02972v1","updated":"2025-03-04T19:57:47Z","published":"2025-03-04T19:57:47Z","title":"LINGOLY-TOO: Disentangling Memorisation from Reasoning with Linguistic\n  Templatisation and Orthographic Obfuscation","summary":"  Effective evaluation of the reasoning capabilities of large language models\n(LLMs) are susceptible to overestimation due to data exposure of evaluation\nbenchmarks. We introduce a framework for producing linguistic reasoning\nproblems that reduces the effect of memorisation in model performance estimates\nand apply this framework to develop LINGOLY-TOO, a challenging evaluation\nbenchmark for linguistic reasoning. By developing orthographic templates, we\ndynamically obfuscate the writing systems of real languages to generate\nnumerous question variations. These variations preserve the reasoning steps\nrequired for each solution while reducing the likelihood of specific problem\ninstances appearing in model training data. Our experiments demonstrate that\nfrontier models, including OpenAI o1-preview and DeepSeem R1, struggle with\nadvanced reasoning. Our analysis also shows that LLMs exhibit noticeable\nvariance in accuracy across permutations of the same problem, and on average\nperform better on questions appearing in their original orthography. Our\nfindings highlight the opaque nature of response generation in LLMs and provide\nevidence that prior data exposure contributes to overestimating the reasoning\ncapabilities of frontier models.\n","authors":["Jude Khouja","Karolina Korgul","Simi Hellsten","Lingyi Yang","Vlad Neacs","Harry Mayne","Ryan Kearns","Andrew Bean","Adam Mahdi"],"pdf_url":"https://arxiv.org/pdf/2503.02972v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02971v1","updated":"2025-03-04T19:56:56Z","published":"2025-03-04T19:56:56Z","title":"Multilingual Relative Clause Attachment Ambiguity Resolution in Large\n  Language Models","summary":"  This study examines how large language models (LLMs) resolve relative clause\n(RC) attachment ambiguities and compares their performance to human sentence\nprocessing. Focusing on two linguistic factors, namely the length of RCs and\nthe syntactic position of complex determiner phrases (DPs), we assess whether\nLLMs can achieve human-like interpretations amid the complexities of language.\nIn this study, we evaluated several LLMs, including Claude, Gemini and Llama,\nin multiple languages: English, Spanish, French, German, Japanese, and Korean.\nWhile these models performed well in Indo-European languages (English, Spanish,\nFrench, and German), they encountered difficulties in Asian languages (Japanese\nand Korean), often defaulting to incorrect English translations. The findings\nunderscore the variability in LLMs' handling of linguistic ambiguities and\nhighlight the need for model improvements, particularly for non-European\nlanguages. This research informs future enhancements in LLM design to improve\naccuracy and human-like processing in diverse linguistic environments.\n","authors":["So Young Lee","Russell Scheinberg","Amber Shore","Ameeta Agrawal"],"pdf_url":"https://arxiv.org/pdf/2503.02971v1.pdf","comment":"Accepted at PACLIC 2024"},{"id":"http://arxiv.org/abs/2503.02969v1","updated":"2025-03-04T19:51:29Z","published":"2025-03-04T19:51:29Z","title":"InfiniSST: Simultaneous Translation of Unbounded Speech with Large\n  Language Model","summary":"  Simultaneous translation of unbounded streaming speech remains a challenging\nproblem due to the need for effectively processing the history speech context\nand past translations so that quality and latency, including computation\noverhead, can be balanced. Most prior works assume pre-segmented speech,\nlimiting their real-world applicability. In this paper, we propose InfiniSST, a\nnovel approach that formulates SST as a multi-turn dialogue task, enabling\nseamless translation of unbounded speech. We construct translation trajectories\nand robust segments from MuST-C with multi-latency augmentation during training\nand develop a key-value (KV) cache management strategy to facilitate efficient\ninference. Experiments on MuST-C En-Es, En-De, and En-Zh demonstrate that\nInfiniSST reduces computation-aware latency by 0.5 to 1 second while\nmaintaining the same translation quality compared to baselines. Ablation\nstudies further validate the contributions of our data construction and cache\nmanagement strategy. We release the code at\nhttps://github.com/LeiLiLab/InfiniSST\n","authors":["Siqi Ouyang","Xi Xu","Lei Li"],"pdf_url":"https://arxiv.org/pdf/2503.02969v1.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2503.02951v1","updated":"2025-03-04T19:17:36Z","published":"2025-03-04T19:17:36Z","title":"KodCode: A Diverse, Challenging, and Verifiable Synthetic Dataset for\n  Coding","summary":"  We introduce KodCode, a synthetic dataset that addresses the persistent\nchallenge of acquiring high-quality, verifiable training data across diverse\ndifficulties and domains for training Large Language Models for coding.\nExisting code-focused resources typically fail to ensure either the breadth of\ncoverage (e.g., spanning simple coding tasks to advanced algorithmic problems)\nor verifiable correctness (e.g., unit tests). In contrast, KodCode comprises\nquestion-solution-test triplets that are systematically validated via a\nself-verification procedure. Our pipeline begins by synthesizing a broad range\nof coding questions, then generates solutions and test cases with additional\nattempts allocated to challenging problems. Finally, post-training data\nsynthesis is done by rewriting questions into diverse formats and generating\nresponses under a test-based reject sampling procedure from a reasoning model\n(DeepSeek R1). This pipeline yields a large-scale, robust and diverse coding\ndataset. KodCode is suitable for supervised fine-tuning and the paired unit\ntests also provide great potential for RL tuning. Fine-tuning experiments on\ncoding benchmarks (HumanEval(+), MBPP(+), BigCodeBench, and LiveCodeBench)\ndemonstrate that KodCode-tuned models achieve state-of-the-art performance,\nsurpassing models like Qwen2.5-Coder-32B-Instruct and\nDeepSeek-R1-Distill-Llama-70B.\n","authors":["Zhangchen Xu","Yang Liu","Yueqin Yin","Mingyuan Zhou","Radha Poovendran"],"pdf_url":"https://arxiv.org/pdf/2503.02951v1.pdf","comment":"Codes and Data: https://kodcode-ai.github.io/"},{"id":"http://arxiv.org/abs/2409.13744v2","updated":"2025-03-04T19:15:49Z","published":"2024-09-11T00:16:17Z","title":"A Simplified Retriever to Improve Accuracy of Phenotype Normalizations\n  by Large Language Models","summary":"  Large language models (LLMs) have shown improved accuracy in phenotype term\nnormalization tasks when augmented with retrievers that suggest candidate\nnormalizations based on term definitions. In this work, we introduce a\nsimplified retriever that enhances LLM accuracy by searching the Human\nPhenotype Ontology (HPO) for candidate matches using contextual word embeddings\nfrom BioBERT without the need for explicit term definitions. Testing this\nmethod on terms derived from the clinical synopses of Online Mendelian\nInheritance in Man (OMIM), we demonstrate that the normalization accuracy of a\nstate-of-the-art LLM increases from a baseline of 62.3% without augmentation to\n90.3% with retriever augmentation. This approach is potentially generalizable\nto other biomedical term normalization tasks and offers an efficient\nalternative to more complex retrieval methods.\n","authors":["Daniel B. Hier","Thanh Son Do","Tayo Obafemi-Ajayi"],"pdf_url":"https://arxiv.org/pdf/2409.13744v2.pdf","comment":"Published by Frontiers in Digital Health"},{"id":"http://arxiv.org/abs/2503.02950v1","updated":"2025-03-04T19:13:10Z","published":"2025-03-04T19:13:10Z","title":"LiteWebAgent: The Open-Source Suite for VLM-Based Web-Agent Applications","summary":"  We introduce LiteWebAgent, an open-source suite for VLM-based web agent\napplications. Our framework addresses a critical gap in the web agent ecosystem\nwith a production-ready solution that combines minimal serverless backend\nconfiguration, intuitive user and browser interfaces, and extensible research\ncapabilities in agent planning, memory, and tree search. For the core\nLiteWebAgent agent framework, we implemented a simple yet effective baseline\nusing recursive function calling, providing with decoupled action generation\nand action grounding. In addition, we integrate advanced research components\nsuch as agent planning, agent workflow memory, and tree search in a modular and\nextensible manner. We then integrate the LiteWebAgent agent framework with\nfrontend and backend as deployed systems in two formats: (1) a production\nVercel-based web application, which provides users with an agent-controlled\nremote browser, (2) a Chrome extension leveraging LiteWebAgent's API to control\nan existing Chrome browser via CDP (Chrome DevTools Protocol). The LiteWebAgent\nframework is available at https://github.com/PathOnAI/LiteWebAgent, with\ndeployed frontend at https://lite-web-agent.vercel.app/.\n","authors":["Danqing Zhang","Balaji Rama","Jingyi Ni","Shiying He","Fu Zhao","Kunyu Chen","Arnold Chen","Junyu Cao"],"pdf_url":"https://arxiv.org/pdf/2503.02950v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02948v1","updated":"2025-03-04T19:09:48Z","published":"2025-03-04T19:09:48Z","title":"ExpertGenQA: Open-ended QA generation in Specialized Domains","summary":"  Generating high-quality question-answer pairs for specialized technical\ndomains remains challenging, with existing approaches facing a tradeoff between\nleveraging expert examples and achieving topical diversity. We present\nExpertGenQA, a protocol that combines few-shot learning with structured topic\nand style categorization to generate comprehensive domain-specific QA pairs.\nUsing U.S. Federal Railroad Administration documents as a test bed, we\ndemonstrate that ExpertGenQA achieves twice the efficiency of baseline few-shot\napproaches while maintaining $94.4\\%$ topic coverage. Through systematic\nevaluation, we show that current LLM-based judges and reward models exhibit\nstrong bias toward superficial writing styles rather than content quality. Our\nanalysis using Bloom's Taxonomy reveals that ExpertGenQA better preserves the\ncognitive complexity distribution of expert-written questions compared to\ntemplate-based approaches. When used to train retrieval models, our generated\nqueries improve top-1 accuracy by $13.02\\%$ over baseline performance,\ndemonstrating their effectiveness for downstream applications in technical\ndomains.\n","authors":["Haz Sameen Shahgir","Chansong Lim","Jia Chen","Evangelos E. Papalexakis","Yue Dong"],"pdf_url":"https://arxiv.org/pdf/2503.02948v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.18282v2","updated":"2025-03-04T19:06:06Z","published":"2025-02-25T15:16:17Z","title":"Better Aligned with Survey Respondents or Training Data? Unveiling\n  Political Leanings of LLMs on U.S. Supreme Court Cases","summary":"  The increased adoption of Large Language Models (LLMs) and their potential to\nshape public opinion have sparked interest in assessing these models' political\nleanings. Building on previous research that compared LLMs and human opinions\nand observed political bias in system responses, we take a step further to\ninvestigate the underlying causes of such biases by empirically examining how\nthe values and biases embedded in training corpora shape model outputs.\nSpecifically, we propose a method to quantitatively evaluate political leanings\nembedded in the large pretraining corpora. Subsequently we investigate to whom\nare the LLMs' political leanings more aligned with, their pretrainig corpora or\nthe surveyed human opinions. As a case study, we focus on probing the political\nleanings of LLMs in 32 U.S. Supreme Court cases, addressing contentious topics\nsuch as abortion and voting rights. Our findings reveal that LLMs strongly\nreflect the political leanings in their training data, and no strong\ncorrelation is observed with their alignment to human opinions as expressed in\nsurveys. These results underscore the importance of responsible curation of\ntraining data and the need for robust evaluation metrics to ensure LLMs'\nalignment with human-centered values.\n","authors":["Shanshan Xu","T. Y. S. S Santosh","Yanai Elazar","Quirin Vogel","Barbara Plank","Matthias Grabmair"],"pdf_url":"https://arxiv.org/pdf/2502.18282v2.pdf","comment":"under review"},{"id":"http://arxiv.org/abs/2503.02879v1","updated":"2025-03-04T18:58:13Z","published":"2025-03-04T18:58:13Z","title":"Wikipedia in the Era of LLMs: Evolution and Risks","summary":"  In this paper, we present a thorough analysis of the impact of Large Language\nModels (LLMs) on Wikipedia, examining the evolution of Wikipedia through\nexisting data and using simulations to explore potential risks. We begin by\nanalyzing page views and article content to study Wikipedia's recent changes\nand assess the impact of LLMs. Subsequently, we evaluate how LLMs affect\nvarious Natural Language Processing (NLP) tasks related to Wikipedia, including\nmachine translation and retrieval-augmented generation (RAG). Our findings and\nsimulation results reveal that Wikipedia articles have been influenced by LLMs,\nwith an impact of approximately 1%-2% in certain categories. If the machine\ntranslation benchmark based on Wikipedia is influenced by LLMs, the scores of\nthe models may become inflated, and the comparative results among models might\nshift as well. Moreover, the effectiveness of RAG might decrease if the\nknowledge base becomes polluted by LLM-generated content. While LLMs have not\nyet fully changed Wikipedia's language and knowledge structures, we believe\nthat our empirical findings signal the need for careful consideration of\npotential future risks.\n","authors":["Siming Huang","Yuliang Xu","Mingmeng Geng","Yao Wan","Dongping Chen"],"pdf_url":"https://arxiv.org/pdf/2503.02879v1.pdf","comment":"We release all the experimental dataset and source code at:\n  https://github.com/HSM316/LLM_Wikipedia"},{"id":"http://arxiv.org/abs/2503.02878v1","updated":"2025-03-04T18:58:11Z","published":"2025-03-04T18:58:11Z","title":"Language Models can Self-Improve at State-Value Estimation for Better\n  Search","summary":"  Collecting ground truth task completion rewards or human demonstrations for\nmulti-step reasoning tasks is often cost-prohibitive and time-consuming,\nespecially in interactive domains like web tasks. To address this bottleneck,\nwe present self-taught lookahead, a self-supervised method that leverages\nstate-transition dynamics to train a value model capable of effectively guiding\nlanguage model-controlled search. We find that moderately sized (8 billion\nparameters) open-weight value models improved with self-taught lookahead can\nmatch the performance of using a frontier LLM such as gpt-4o as the value\nmodel. Furthermore, we find that self-taught lookahead improves performance by\n20% while reducing costs 37x compared to previous LLM-based tree search,\nwithout relying on ground truth rewards.\n","authors":["Ethan Mendes","Alan Ritter"],"pdf_url":"https://arxiv.org/pdf/2503.02878v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02875v1","updated":"2025-03-04T18:56:03Z","published":"2025-03-04T18:56:03Z","title":"The First Few Tokens Are All You Need: An Efficient and Effective\n  Unsupervised Prefix Fine-Tuning Method for Reasoning Models","summary":"  Improving the reasoning capabilities of large language models (LLMs)\ntypically requires supervised fine-tuning with labeled data or computationally\nexpensive sampling. We introduce Unsupervised Prefix Fine-Tuning (UPFT), which\nleverages the observation of Prefix Self-Consistency -- the shared initial\nreasoning steps across diverse solution trajectories -- to enhance LLM\nreasoning efficiency. By training exclusively on the initial prefix substrings\n(as few as 8 tokens), UPFT removes the need for labeled data or exhaustive\nsampling. Experiments on reasoning benchmarks show that UPFT matches the\nperformance of supervised methods such as Rejection Sampling Fine-Tuning, while\nreducing training time by 75% and sampling cost by 99%. Further analysis\nreveals that errors tend to appear in later stages of the reasoning process and\nthat prefix-based training preserves the model's structural knowledge. This\nwork demonstrates how minimal unsupervised fine-tuning can unlock substantial\nreasoning gains in LLMs, offering a scalable and resource-efficient alternative\nto conventional approaches.\n","authors":["Ke Ji","Jiahao Xu","Tian Liang","Qiuzhi Liu","Zhiwei He","Xingyu Chen","Xiaoyuan Liu","Zhijie Wang","Junying Chen","Benyou Wang","Zhaopeng Tu","Haitao Mi","Dong Yu"],"pdf_url":"https://arxiv.org/pdf/2503.02875v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.14509v5","updated":"2025-03-04T18:55:27Z","published":"2024-09-22T16:13:00Z","title":"Can AI writing be salvaged? Mitigating Idiosyncrasies and Improving\n  Human-AI Alignment in the Writing Process through Edits","summary":"  LLM-based applications are helping people write, and LLM-generated text is\nmaking its way into social media, journalism, and our classrooms. However, the\ndifferences between LLM-generated and human written text remain unclear. To\nexplore this, we hired professional writers to edit paragraphs in several\ncreative domains. We first found these writers agree on undesirable\nidiosyncrasies in LLM generated text, formalizing it into a seven-category\ntaxonomy (e.g. clich\\'es, unnecessary exposition). Second, we curated the LAMP\ncorpus: 1,057 LLM-generated paragraphs edited by professional writers according\nto our taxonomy. Analysis of LAMP reveals that none of the LLMs used in our\nstudy (GPT4o, Claude-3.5-Sonnet, Llama-3.1-70b) outperform each other in terms\nof writing quality, revealing common limitations across model families. Third,\nbuilding on existing work in automatic editing we evaluated methods to improve\nLLM-generated text. A large-scale preference annotation confirms that although\nexperts largely prefer text edited by other experts, automatic editing methods\nshow promise in improving alignment between LLM-generated and human-written\ntext.\n","authors":["Tuhin Chakrabarty","Philippe Laban","Chien-Sheng Wu"],"pdf_url":"https://arxiv.org/pdf/2409.14509v5.pdf","comment":"ACM CHI 2025"},{"id":"http://arxiv.org/abs/2503.00043v2","updated":"2025-03-04T18:47:38Z","published":"2025-02-25T23:36:19Z","title":"VOILA: Evaluation of MLLMs For Perceptual Understanding and Analogical\n  Reasoning","summary":"  Multimodal Large Language Models (MLLMs) have become a powerful tool for\nintegrating visual and textual information. Despite their exceptional\nperformance on visual understanding benchmarks, measuring their ability to\nreason abstractly across multiple images remains a significant challenge. To\naddress this, we introduce VOILA, a large-scale, open-ended, dynamic benchmark\ndesigned to evaluate MLLMs' perceptual understanding and abstract relational\nreasoning. VOILA employs an analogical mapping approach in the visual domain,\nrequiring models to generate an image that completes an analogy between two\ngiven image pairs, reference and application, without relying on predefined\nchoices. Our experiments demonstrate that the analogical reasoning tasks in\nVOILA present a challenge to MLLMs. Through multi-step analysis, we reveal that\ncurrent MLLMs struggle to comprehend inter-image relationships and exhibit\nlimited capabilities in high-level relational reasoning. Notably, we observe\nthat performance improves when following a multi-step strategy of least-to-most\nprompting. Comprehensive evaluations on open-source models and GPT-4o show that\non text-based answers, the best accuracy for challenging scenarios is 13%\n(LLaMa 3.2) and even for simpler tasks is only 29% (GPT-4o), while human\nperformance is significantly higher at 70% across both difficulty levels.\n","authors":["Nilay Yilmaz","Maitreya Patel","Yiran Lawrence Luo","Tejas Gokhale","Chitta Baral","Suren Jayasuriya","Yezhou Yang"],"pdf_url":"https://arxiv.org/pdf/2503.00043v2.pdf","comment":"Accepted at ICLR 2025. Code and data: https://github.com/nlylmz/Voila"},{"id":"http://arxiv.org/abs/2503.02863v1","updated":"2025-03-04T18:40:49Z","published":"2025-03-04T18:40:49Z","title":"Calibrating LLM Confidence with Semantic Steering: A Multi-Prompt\n  Aggregation Framework","summary":"  Large Language Models (LLMs) often exhibit misaligned confidence scores,\nusually overestimating the reliability of their predictions. While verbalized\nconfidence in Large Language Models (LLMs) has gained attention, prior work\nremains divided on whether confidence scores can be systematically steered\nthrough prompting. Recent studies even argue that such prompt-induced\nconfidence shifts are negligible, suggesting LLMs' confidence calibration is\nrigid to linguistic interventions. Contrary to these claims, we first\nrigorously confirm the existence of directional confidence shifts by probing\nthree models (including GPT3.5, LLAMA3-70b, GPT4) across 7 benchmarks,\ndemonstrating that explicit instructions can inflate or deflate confidence\nscores in a regulated manner. Based on this observation, we propose a novel\nframework containing three components: confidence steering, steered confidence\naggregation and steered answers selection, named SteeringConf. Our method,\nSteeringConf, leverages a confidence manipulation mechanism to steer the\nconfidence scores of LLMs in several desired directions, followed by a\nsummarization module that aggregates the steered confidence scores to produce a\nfinal prediction. We evaluate our method on 7 benchmarks and it consistently\noutperforms the baselines in terms of calibration metrics in task of confidence\ncalibration and failure detection.\n","authors":["Ziang Zhou","Tianyuan Jin","Jieming Shi","Qing Li"],"pdf_url":"https://arxiv.org/pdf/2503.02863v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02854v1","updated":"2025-03-04T18:31:02Z","published":"2025-03-04T18:31:02Z","title":"(How) Do Language Models Track State?","summary":"  Transformer language models (LMs) exhibit behaviors -- from storytelling to\ncode generation -- that appear to require tracking the unobserved state of an\nevolving world. How do they do so? We study state tracking in LMs trained or\nfine-tuned to compose permutations (i.e., to compute the order of a set of\nobjects after a sequence of swaps). Despite the simple algebraic structure of\nthis problem, many other tasks (e.g., simulation of finite automata and\nevaluation of boolean expressions) can be reduced to permutation composition,\nmaking it a natural model for state tracking in general. We show that LMs\nconsistently learn one of two state tracking mechanisms for this task. The\nfirst closely resembles the \"associative scan\" construction used in recent\ntheoretical work by Liu et al. (2023) and Merrill et al. (2024). The second\nuses an easy-to-compute feature (permutation parity) to partially prune the\nspace of outputs, then refines this with an associative scan. The two\nmechanisms exhibit markedly different robustness properties, and we show how to\nsteer LMs toward one or the other with intermediate training tasks that\nencourage or suppress the heuristics. Our results demonstrate that transformer\nLMs, whether pretrained or fine-tuned, can learn to implement efficient and\ninterpretable state tracking mechanisms, and the emergence of these mechanisms\ncan be predicted and controlled.\n","authors":["Belinda Z. Li","Zifan Carl Guo","Jacob Andreas"],"pdf_url":"https://arxiv.org/pdf/2503.02854v1.pdf","comment":"21 pages, 17 figures, 1 table"},{"id":"http://arxiv.org/abs/2503.02851v1","updated":"2025-03-04T18:27:00Z","published":"2025-03-04T18:27:00Z","title":"Shakespearean Sparks: The Dance of Hallucination and Creativity in LLMs'\n  Decoding Layers","summary":"  Large language models (LLMs) are known to hallucinate, a phenomenon often\nlinked to creativity. While previous research has primarily explored this\nconnection through theoretical or qualitative lenses, our work takes a\nquantitative approach to systematically examine the relationship between\nhallucination and creativity in LLMs. Given the complex nature of creativity,\nwe propose a narrow definition tailored to LLMs and introduce an evaluation\nframework, HCL, which quantifies Hallucination and Creativity across different\nLayers of LLMs during decoding. Our empirical analysis reveals a tradeoff\nbetween hallucination and creativity that is consistent across layer depth,\nmodel type, and model size. Notably, across different model architectures, we\nidentify a specific layer at each model size that optimally balances this\ntradeoff. Additionally, the optimal layer tends to appear in the early layers\nof larger models, and the confidence of the model is also significantly higher\nat this layer. These findings provide a quantitative perspective that offers\nnew insights into the interplay between LLM creativity and hallucination. The\ncode and data for our experiments are available at\nhttps://github.com/ZicongHe2002/HCL-Spark.\n","authors":["Zicong He","Boxuan Zhang","Lu Cheng"],"pdf_url":"https://arxiv.org/pdf/2503.02851v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02846v1","updated":"2025-03-04T18:20:24Z","published":"2025-03-04T18:20:24Z","title":"Mask-DPO: Generalizable Fine-grained Factuality Alignment of LLMs","summary":"  Large language models (LLMs) exhibit hallucinations (i.e., unfaithful or\nnonsensical information) when serving as AI assistants in various domains.\nSince hallucinations always come with truthful content in the LLM responses,\nprevious factuality alignment methods that conduct response-level preference\nlearning inevitably introduced noises during training. Therefore, this paper\nproposes a fine-grained factuality alignment method based on Direct Preference\nOptimization (DPO), called Mask-DPO. Incorporating sentence-level factuality as\nmask signals, Mask-DPO only learns from factually correct sentences in the\npreferred samples and prevents the penalty on factual contents in the not\npreferred samples, which resolves the ambiguity in the preference learning.\nExtensive experimental results demonstrate that Mask-DPO can significantly\nimprove the factuality of LLMs responses to questions from both in-domain and\nout-of-domain datasets, although these questions and their corresponding topics\nare unseen during training. Only trained on the ANAH train set, the score of\nLlama3.1-8B-Instruct on the ANAH test set is improved from 49.19% to 77.53%,\neven surpassing the score of Llama3.1-70B-Instruct (53.44%), while its\nFactScore on the out-of-domain Biography dataset is also improved from 30.29%\nto 39.39%. We further study the generalization property of Mask-DPO using\ndifferent training sample scaling strategies and find that scaling the number\nof topics in the dataset is more effective than the number of questions. We\nprovide a hypothesis of what factual alignment is doing with LLMs, on the\nimplication of this phenomenon, and conduct proof-of-concept experiments to\nverify it. We hope the method and the findings pave the way for future research\non scaling factuality alignment.\n","authors":["Yuzhe Gu","Wenwei Zhang","Chengqi Lyu","Dahua Lin","Kai Chen"],"pdf_url":"https://arxiv.org/pdf/2503.02846v1.pdf","comment":"Accepted by ICLR 2025. Code is available at\n  https://github.com/open-compass/ANAH"},{"id":"http://arxiv.org/abs/2412.16172v2","updated":"2025-03-04T18:15:36Z","published":"2024-12-07T00:15:24Z","title":"LABIIUM: AI-Enhanced Zero-configuration Measurement Automation System","summary":"  The complexity of laboratory environments requires solutions that simplify\ninstrument interaction and enhance measurement automation. Traditional tools\noften require configuration, software, and programming skills, creating\nbarriers to productivity. Previous approaches, including dedicated software\nsuites and custom scripts, frequently fall short in providing user-friendly\nsolutions that align with programming practices. We present LABIIUM, an\nAI-enhanced, zero-configuration measurement automation system designed to\nstreamline experimental workflows and improve user productivity. LABIIUM\nintegrates an AI assistant powered by Large Language Models (LLMs) to generate\ncode. LABIIUM's Lab-Automation-Measurement Bridges (LAMBs) enable seamless\ninstrument connectivity using standard tools such as VSCode and Python,\neliminating setup overhead. To demonstrate its capabilities, we conducted\nexperiments involving the measurement of the parametric transfer curve of a\nsimple two-transistor inverting amplifier with a current source load. The AI\nassistant was evaluated using different prompt scenarios and compared with\nmultiple models, including Claude Sonnet 3.5, Gemini Pro 1.5, and GPT-4o. An\nexpert solution implementing the Gradient-Weighted Adaptive Stochastic Sampling\n(GWASS) method was used as a baseline. The solutions generated by the AI\nassistant were compared with the expert solution and a uniform linear sweep\nbaseline with 10,000 points. The graph results show that the LLMs were able to\nsuccessfully complete the most basic uniform sweep, but LLMs were unable to\ndevelop adaptive sweeping algorithms to compete with GWASS. The evaluation\nunderscores LABIIUM's ability to enhance laboratory productivity and support\ndigital transformation in research and industry, and emphasizes the future work\nrequired to improve LLM performance in Electronic Measurement Science Tasks.\n","authors":["Emmanuel A. Olowe","Danial Chitnis"],"pdf_url":"https://arxiv.org/pdf/2412.16172v2.pdf","comment":"accepted for IEEE I2MTC 2025"},{"id":"http://arxiv.org/abs/2410.01335v2","updated":"2025-03-04T18:15:16Z","published":"2024-10-02T08:53:07Z","title":"Layer Swapping for Zero-Shot Cross-Lingual Transfer in Large Language\n  Models","summary":"  Model merging, such as model souping, is the practice of combining different\nmodels with the same architecture together without further training. In this\nwork, we present a model merging methodology that addresses the difficulty of\nfine-tuning Large Language Models (LLMs) for target tasks in non-English\nlanguages, where task-specific data is often unavailable. We focus on\nmathematical reasoning and without in-language math data, facilitate\ncross-lingual transfer by composing language and math capabilities. Starting\nfrom the same pretrained model, we fine-tune separate \"experts\" on math\ninstruction data in English and on generic instruction data in the target\nlanguage. We then replace the top and bottom transformer layers of the math\nexpert directly with layers from the language expert, which consequently\nenhances math performance in the target language. The resulting merged models\noutperform the individual experts and other merging methods on the math\nbenchmark, MGSM, by 10% across four major languages where math instruction data\nis scarce. In addition, this layer swapping is simple, inexpensive, and\nintuitive, as it is based on an interpretative analysis of the most important\nparameter changes during the fine-tuning of each expert. The ability to\nsuccessfully re-compose LLMs for cross-lingual transfer in this manner opens up\nfuture possibilities to combine model expertise, create modular solutions, and\ntransfer reasoning capabilities across languages all post hoc.\n","authors":["Lucas Bandarkar","Benjamin Muller","Pritish Yuvraj","Rui Hou","Nayan Singhal","Hongjiang Lv","Bing Liu"],"pdf_url":"https://arxiv.org/pdf/2410.01335v2.pdf","comment":"ICLR 2025, Spotlight Paper, In The Thirteenth International\n  Conference on Learning Representations, 2025"},{"id":"http://arxiv.org/abs/2406.05516v3","updated":"2025-03-04T18:07:34Z","published":"2024-06-08T16:35:31Z","title":"Verbalized Probabilistic Graphical Modeling","summary":"  Human cognition excels at transcending sensory input and forming latent\nrepresentations that structure our understanding of the world. Although Large\nLanguage Models (LLMs) can produce chain-of-thought reasoning, they lack a\nprincipled framework to capture latent structures and model uncertainty,\nespecially in compositional reasoning tasks. We propose Verbalized\nProbabilistic Graphical Modeling (vPGM), a Bayesian prompting framework that\nguides LLMs to simulate key principles of Probabilistic Graphical Models (PGMs)\nin natural language. Unlike many traditional probabilistic methods requiring\nsubstantial domain expertise or specialized training, vPGM bypasses\nexpert-driven model design, making it well-suited for scenarios with limited\nassumptions or scarce data. We evaluated our model on several compositional\nreasoning tasks, both close-ended and open-ended. Our results indicate that the\nmodel effectively enhances confidence calibration and text generation quality.\n","authors":["Hengguan Huang","Xing Shen","Songtao Wang","Lingfa Meng","Dianbo Liu","Hao Wang","Samir Bhatt"],"pdf_url":"https://arxiv.org/pdf/2406.05516v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01773v2","updated":"2025-03-04T18:01:19Z","published":"2025-03-03T17:57:03Z","title":"Why Is Spatial Reasoning Hard for VLMs? An Attention Mechanism\n  Perspective on Focus Areas","summary":"  Large Vision Language Models (VLMs) have long struggled with spatial\nreasoning tasks. Surprisingly, even simple spatial reasoning tasks, such as\nrecognizing \"under\" or \"behind\" relationships between only two objects, pose\nsignificant challenges for current VLMs. In this work, we study the spatial\nreasoning challenge from the lens of mechanistic interpretability, diving into\nthe model's internal states to examine the interactions between image and text\ntokens. By tracing attention distribution over the image through out\nintermediate layers, we observe that successful spatial reasoning correlates\nstrongly with the model's ability to align its attention distribution with\nactual object locations, particularly differing between familiar and unfamiliar\nspatial relationships. Motivated by these findings, we propose ADAPTVIS based\non inference-time confidence scores to sharpen the attention on highly relevant\nregions when confident, while smoothing and broadening the attention window to\nconsider a wider context when confidence is lower. This training-free decoding\nmethod shows significant improvement (e.g., up to a 50 absolute point\nimprovement) on spatial reasoning benchmarks such as WhatsUp and VSR with\nnegligible cost. We make code and data publicly available for research purposes\nat https://github.com/shiqichen17/AdaptVis.\n","authors":["Shiqi Chen","Tongyao Zhu","Ruochen Zhou","Jinghan Zhang","Siyang Gao","Juan Carlos Niebles","Mor Geva","Junxian He","Jiajun Wu","Manling Li"],"pdf_url":"https://arxiv.org/pdf/2503.01773v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02832v1","updated":"2025-03-04T17:57:09Z","published":"2025-03-04T17:57:09Z","title":"AlignDistil: Token-Level Language Model Alignment as Adaptive Policy\n  Distillation","summary":"  In modern large language models (LLMs), LLM alignment is of crucial\nimportance and is typically achieved through methods such as reinforcement\nlearning from human feedback (RLHF) and direct preference optimization (DPO).\nHowever, in most existing methods for LLM alignment, all tokens in the response\nare optimized using a sparse, response-level reward or preference annotation.\nThe ignorance of token-level rewards may erroneously punish high-quality tokens\nor encourage low-quality tokens, resulting in suboptimal performance and slow\nconvergence speed. To address this issue, we propose AlignDistil, an\nRLHF-equivalent distillation method for token-level reward optimization.\nSpecifically, we introduce the reward learned by DPO into the RLHF objective\nand theoretically prove the equivalence between this objective and a\ntoken-level distillation process, where the teacher distribution linearly\ncombines the logits from the DPO model and a reference model. On this basis, we\nfurther bridge the accuracy gap between the reward from the DPO model and the\npure reward model, by building a contrastive DPO reward with a normal and a\nreverse DPO model. Moreover, to avoid under- and over-optimization on different\ntokens, we design a token adaptive logit extrapolation mechanism to construct\nan appropriate teacher distribution for each token. Experimental results\ndemonstrate the superiority of our AlignDistil over existing methods and\nshowcase fast convergence due to its token-level distributional reward\noptimization.\n","authors":["Songming Zhang","Xue Zhang","Tong Zhang","Bojie Hu","Yufeng Chen","Jinan Xu"],"pdf_url":"https://arxiv.org/pdf/2503.02832v1.pdf","comment":"15 pages, 2 figures"},{"id":"http://arxiv.org/abs/2503.02812v1","updated":"2025-03-04T17:37:49Z","published":"2025-03-04T17:37:49Z","title":"Q-Filters: Leveraging QK Geometry for Efficient KV Cache Compression","summary":"  Autoregressive language models rely on a Key-Value (KV) Cache, which avoids\nre-computing past hidden states during generation, making it faster. As model\nsizes and context lengths grow, the KV Cache becomes a significant memory\nbottleneck, which calls for compression methods that limit its size during\ngeneration. In this paper, we discover surprising properties of Query (Q) and\nKey (K) vectors that allow us to efficiently approximate attention scores\nwithout computing the attention maps. We propose Q-Filters, a training-free KV\nCache compression method that filters out less crucial Key-Value pairs based on\na single context-agnostic projection. Contrarily to many alternatives,\nQ-Filters is compatible with FlashAttention, as it does not require direct\naccess to attention weights. Experimental results in long-context settings\ndemonstrate that Q-Filters is competitive with attention-based compression\nmethods such as SnapKV in retrieval tasks while consistently outperforming\nefficient compression schemes such as Streaming-LLM in generation setups.\nNotably, Q-Filters achieves a 99% accuracy in the needle-in-a-haystack task\nwith a x32 compression level while reducing the generation perplexity drop by\nup to 65% in text generation compared to Streaming-LLM.\n","authors":["Nathan Godey","Alessio Devoto","Yu Zhao","Simone Scardapane","Pasquale Minervini","Éric de la Clergerie","Benoît Sagot"],"pdf_url":"https://arxiv.org/pdf/2503.02812v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.21239v2","updated":"2025-03-04T17:31:25Z","published":"2025-02-28T17:09:08Z","title":"Semantic Volume: Quantifying and Detecting both External and Internal\n  Uncertainty in LLMs","summary":"  Large language models (LLMs) have demonstrated remarkable performance across\ndiverse tasks by encoding vast amounts of factual knowledge. However, they are\nstill prone to hallucinations, generating incorrect or misleading information,\noften accompanied by high uncertainty. Existing methods for hallucination\ndetection primarily focus on quantifying internal uncertainty, which arises\nfrom missing or conflicting knowledge within the model. However, hallucinations\ncan also stem from external uncertainty, where ambiguous user queries lead to\nmultiple possible interpretations. In this work, we introduce Semantic Volume,\na novel mathematical measure for quantifying both external and internal\nuncertainty in LLMs. Our approach perturbs queries and responses, embeds them\nin a semantic space, and computes the determinant of the Gram matrix of the\nembedding vectors, capturing their dispersion as a measure of uncertainty. Our\nframework provides a generalizable and unsupervised uncertainty detection\nmethod without requiring white-box access to LLMs. We conduct extensive\nexperiments on both external and internal uncertainty detection, demonstrating\nthat our Semantic Volume method consistently outperforms existing baselines in\nboth tasks. Additionally, we provide theoretical insights linking our measure\nto differential entropy, unifying and extending previous sampling-based\nuncertainty measures such as the semantic entropy. Semantic Volume is shown to\nbe a robust and interpretable approach to improving the reliability of LLMs by\nsystematically detecting uncertainty in both user queries and model responses.\n","authors":["Xiaomin Li","Zhou Yu","Ziji Zhang","Yingying Zhuang","Swair Shah","Anurag Beniwal"],"pdf_url":"https://arxiv.org/pdf/2502.21239v2.pdf","comment":"This paper needs approval from Amazon for open resource release"},{"id":"http://arxiv.org/abs/2502.16600v3","updated":"2025-03-04T17:23:23Z","published":"2025-02-23T15:00:53Z","title":"Revealing the Pragmatic Dilemma for Moral Reasoning Acquisition in\n  Language Models","summary":"  Ensuring that Large Language Models (LLMs) return just responses which adhere\nto societal values is crucial for their broader application. Prior research has\nshown that LLMs often fail to perform satisfactorily on tasks requiring moral\ncognizance, such as ethics-based judgments. While current approaches have\nfocused on fine-tuning LLMs with curated datasets to improve their capabilities\non such tasks, choosing the optimal learning paradigm to enhance the ethical\nresponses of LLMs remains an open research debate. In this work, we aim to\naddress this fundamental question: can current learning paradigms enable LLMs\nto acquire sufficient moral reasoning capabilities? Drawing from distributional\nsemantics theory and the pragmatic nature of moral discourse, our analysis\nindicates that performance improvements follow a mechanism similar to that of\nsemantic-level tasks, and therefore remain affected by the pragmatic nature of\nmorals latent in discourse, a phenomenon we name the pragmatic dilemma. We\nconclude that this pragmatic dilemma imposes significant limitations on the\ngeneralization ability of current learning paradigms, making it the primary\nbottleneck for moral reasoning acquisition in LLMs.\n","authors":["Guangliang Liu","Lei Jiang","Xitong Zhang","Kristen Marie Johnson"],"pdf_url":"https://arxiv.org/pdf/2502.16600v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02783v1","updated":"2025-03-04T16:56:34Z","published":"2025-03-04T16:56:34Z","title":"IterPref: Focal Preference Learning for Code Generation via Iterative\n  Debugging","summary":"  Preference learning enhances Code LLMs beyond supervised fine-tuning by\nleveraging relative quality comparisons. Existing methods construct preference\npairs from\n  candidates based on test case success, treating the higher pass rate sample\nas positive and the lower as negative. However, this approach does not pinpoint\nspecific errors in the code, which prevents the model from learning more\ninformative error correction patterns, as aligning failing code as a whole\nlacks the granularity needed to capture meaningful error-resolution\nrelationships. To address these issues, we propose IterPref, a new preference\nalignment framework that mimics human iterative debugging to refine Code LLMs.\nIterPref explicitly locates error regions and aligns the corresponding tokens\nvia a tailored DPO algorithm. To generate informative pairs, we introduce the\nCodeFlow dataset, where samples are iteratively refined until passing tests,\nwith modifications capturing error corrections. Extensive experiments show that\na diverse suite of Code LLMs equipped with IterPref achieves significant\nperformance gains in code generation and improves on challenging tasks like\nBigCodeBench. In-depth analysis reveals that IterPref yields fewer errors. Our\ncode and data will be made publicaly available.\n","authors":["Jie Wu","Haoling Li","Xin Zhang","Jianwen Luo","Yangyu Huang","Ruihang Chu","Yujiu Yang","Scarlett Li"],"pdf_url":"https://arxiv.org/pdf/2503.02783v1.pdf","comment":"The code and data will be released soon"},{"id":"http://arxiv.org/abs/2503.02776v1","updated":"2025-03-04T16:49:37Z","published":"2025-03-04T16:49:37Z","title":"Implicit Bias in LLMs: A Survey","summary":"  Due to the implement of guardrails by developers, Large language models\n(LLMs) have demonstrated exceptional performance in explicit bias tests.\nHowever, bias in LLMs may occur not only explicitly, but also implicitly, much\nlike humans who consciously strive for impartiality yet still harbor implicit\nbias. The unconscious and automatic nature of implicit bias makes it\nparticularly challenging to study. This paper provides a comprehensive review\nof the existing literature on implicit bias in LLMs. We begin by introducing\nkey concepts, theories and methods related to implicit bias in psychology,\nextending them from humans to LLMs. Drawing on the Implicit Association Test\n(IAT) and other psychological frameworks, we categorize detection methods into\nthree primary approaches: word association, task-oriented text generation and\ndecision-making. We divide our taxonomy of evaluation metrics for implicit bias\ninto two categories: single-value-based metrics and comparison-value-based\nmetrics. We classify datasets into two types: sentences with masked tokens and\ncomplete sentences, incorporating datasets from various domains to reflect the\nbroad application of LLMs. Although research on mitigating implicit bias in\nLLMs is still limited, we summarize existing efforts and offer insights on\nfuture challenges. We aim for this work to serve as a clear guide for\nresearchers and inspire innovative ideas to advance exploration in this task.\n","authors":["Xinru Lin","Luyang Li"],"pdf_url":"https://arxiv.org/pdf/2503.02776v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.17403v2","updated":"2025-03-04T16:36:52Z","published":"2025-02-24T18:30:36Z","title":"Large Language Models are Powerful EHR Encoders","summary":"  Electronic Health Records (EHRs) offer rich potential for clinical\nprediction, yet their inherent complexity and heterogeneity pose significant\nchallenges for traditional machine learning approaches. Domain-specific EHR\nfoundation models trained on large collections of unlabeled EHR data have\ndemonstrated promising improvements in predictive accuracy and generalization;\nhowever, their training is constrained by limited access to diverse,\nhigh-quality datasets and inconsistencies in coding standards and healthcare\npractices. In this study, we explore the possibility of using general-purpose\nLarge Language Models (LLMs) based embedding methods as EHR encoders. By\nserializing patient records into structured Markdown text, transforming codes\ninto human-readable descriptors, we leverage the extensive generalization\ncapabilities of LLMs pretrained on vast public corpora, thereby bypassing the\nneed for proprietary medical datasets. We systematically evaluate two\nstate-of-the-art LLM-embedding models, GTE-Qwen2-7B-Instruct and\nLLM2Vec-Llama3.1-8B-Instruct, across 15 diverse clinical prediction tasks from\nthe EHRSHOT benchmark, comparing their performance to an EHRspecific foundation\nmodel, CLIMBR-T-Base, and traditional machine learning baselines. Our results\ndemonstrate that LLM-based embeddings frequently match or exceed the\nperformance of specialized models, even in few-shot settings, and that their\neffectiveness scales with the size of the underlying LLM and the available\ncontext window. Overall, our findings demonstrate that repurposing LLMs for EHR\nencoding offers a scalable and effective approach for clinical prediction,\ncapable of overcoming the limitations of traditional EHR modeling and\nfacilitating more interoperable and generalizable healthcare applications.\n","authors":["Stefan Hegselmann","Georg von Arnim","Tillmann Rheude","Noel Kronenberg","David Sontag","Gerhard Hindricks","Roland Eils","Benjamin Wild"],"pdf_url":"https://arxiv.org/pdf/2502.17403v2.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2502.20041v3","updated":"2025-03-04T07:37:57Z","published":"2025-02-27T12:29:44Z","title":"3D-AffordanceLLM: Harnessing Large Language Models for Open-Vocabulary\n  Affordance Detection in 3D Worlds","summary":"  3D Affordance detection is a challenging problem with broad applications on\nvarious robotic tasks. Existing methods typically formulate the detection\nparadigm as a label-based semantic segmentation task. This paradigm relies on\npredefined labels and lacks the ability to comprehend complex natural language,\nresulting in limited generalization in open-world scene. To address these\nlimitations, we reformulate the traditional affordance detection paradigm into\n\\textit{Instruction Reasoning Affordance Segmentation} (IRAS) task. This task\nis designed to output a affordance mask region given a query reasoning text,\nwhich avoids fixed categories of input labels. We accordingly propose the\n\\textit{3D-AffordanceLLM} (3D-ADLLM), a framework designed for reasoning\naffordance detection in 3D open-scene. Specifically, 3D-ADLLM introduces large\nlanguage models (LLMs) to 3D affordance perception with a custom-designed\ndecoder for generating affordance masks, thus achieving open-world reasoning\naffordance detection. In addition, given the scarcity of 3D affordance datasets\nfor training large models, we seek to extract knowledge from general\nsegmentation data and transfer it to affordance detection. Thus, we propose a\nmulti-stage training strategy that begins with a novel pre-training task, i.e.,\n\\textit{Referring Object Part Segmentation}~(ROPS). This stage is designed to\nequip the model with general recognition and segmentation capabilities at the\nobject-part level. Then followed by fine-tuning with the IRAS task, 3D-ADLLM\nobtains the reasoning ability for affordance detection. In summary, 3D-ADLLM\nleverages the rich world knowledge and human-object interaction reasoning\nability of LLMs, achieving approximately an 8\\% improvement in mIoU on\nopen-vocabulary affordance detection tasks.\n","authors":["Hengshuo Chu","Xiang Deng","Qi Lv","Xiaoyang Chen","Yinchuan Li","Jianye Hao","Liqiang Nie"],"pdf_url":"https://arxiv.org/pdf/2502.20041v3.pdf","comment":"ICLR"},{"id":"http://arxiv.org/abs/2405.14093v4","updated":"2025-03-04T08:24:20Z","published":"2024-05-23T01:43:54Z","title":"A Survey on Vision-Language-Action Models for Embodied AI","summary":"  Embodied AI is widely recognized as a key element of artificial general\nintelligence because it involves controlling embodied agents to perform tasks\nin the physical world. Building on the success of large language models and\nvision-language models, a new category of multimodal models -- referred to as\nvision-language-action models (VLAs) -- has emerged to address\nlanguage-conditioned robotic tasks in embodied AI by leveraging their distinct\nability to generate actions. In recent years, a myriad of VLAs have been\ndeveloped, making it imperative to capture the rapidly evolving landscape\nthrough a comprehensive survey. To this end, we present the first survey on\nVLAs for embodied AI. This work provides a detailed taxonomy of VLAs, organized\ninto three major lines of research. The first line focuses on individual\ncomponents of VLAs. The second line is dedicated to developing control policies\nadept at predicting low-level actions. The third line comprises high-level task\nplanners capable of decomposing long-horizon tasks into a sequence of subtasks,\nthereby guiding VLAs to follow more general user instructions. Furthermore, we\nprovide an extensive summary of relevant resources, including datasets,\nsimulators, and benchmarks. Finally, we discuss the challenges faced by VLAs\nand outline promising future directions in embodied AI. We have created a\nproject associated with this survey, which is available at\nhttps://github.com/yueen-ma/Awesome-VLA.\n","authors":["Yueen Ma","Zixing Song","Yuzheng Zhuang","Jianye Hao","Irwin King"],"pdf_url":"https://arxiv.org/pdf/2405.14093v4.pdf","comment":"Project page: https://github.com/yueen-ma/Awesome-VLA"},{"id":"http://arxiv.org/abs/2502.20092v3","updated":"2025-03-04T14:00:03Z","published":"2025-02-27T13:51:56Z","title":"WalnutData: A UAV Remote Sensing Dataset of Green Walnuts and Model\n  Evaluation","summary":"  The UAV technology is gradually maturing and can provide extremely powerful\nsupport for smart agriculture and precise monitoring. Currently, there is no\ndataset related to green walnuts in the field of agricultural computer vision.\nThus, in order to promote the algorithm design in the field of agricultural\ncomputer vision, we used UAV to collect remote-sensing data from 8 walnut\nsample plots. Considering that green walnuts are subject to various lighting\nconditions and occlusion, we constructed a large-scale dataset with a\nhigher-granularity of target features - WalnutData. This dataset contains a\ntotal of 30,240 images and 706,208 instances, and there are 4 target\ncategories: being illuminated by frontal light and unoccluded (A1), being\nbacklit and unoccluded (A2), being illuminated by frontal light and occluded\n(B1), and being backlit and occluded (B2). Subsequently, we evaluated many\nmainstream algorithms on WalnutData and used these evaluation results as the\nbaseline standard. The dataset and all evaluation results can be obtained at\nhttps://github.com/1wuming/WalnutData.\n","authors":["Mingjie Wu","Chenggui Yang","Huihua Wang","Chen Xue","Yibo Wang","Haoyu Wang","Yansong Wang","Can Peng","Yuqi Han","Ruoyu Li","Lijun Yun","Zaiqing Chen","Yuelong Xia"],"pdf_url":"https://arxiv.org/pdf/2502.20092v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.06437v2","updated":"2025-03-04T23:49:01Z","published":"2024-10-09T00:45:02Z","title":"LocoVR: Multiuser Indoor Locomotion Dataset in Virtual Reality","summary":"  Understanding human locomotion is crucial for AI agents such as robots,\nparticularly in complex indoor home environments. Modeling human trajectories\nin these spaces requires insight into how individuals maneuver around physical\nobstacles and manage social navigation dynamics. These dynamics include subtle\nbehaviors influenced by proxemics - the social use of space, such as stepping\naside to allow others to pass or choosing longer routes to avoid collisions.\nPrevious research has developed datasets of human motion in indoor scenes, but\nthese are often limited in scale and lack the nuanced social navigation\ndynamics common in home environments. To address this, we present LocoVR, a\ndataset of 7000+ two-person trajectories captured in virtual reality from over\n130 different indoor home environments. LocoVR provides accurate trajectory\ndata and precise spatial information, along with rich examples of\nsocially-motivated movement behaviors. For example, the dataset captures\ninstances of individuals navigating around each other in narrow spaces,\nadjusting paths to respect personal boundaries in living areas, and\ncoordinating movements in high-traffic zones like entryways and kitchens. Our\nevaluation shows that LocoVR significantly enhances model performance in three\npractical indoor tasks utilizing human trajectories, and demonstrates\npredicting socially-aware navigation patterns in home environments.\n","authors":["Kojiro Takeyama","Yimeng Liu","Misha Sra"],"pdf_url":"https://arxiv.org/pdf/2410.06437v2.pdf","comment":"This paper has been accepted to ICLR2025"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2407.06057v3","updated":"2025-03-04T14:33:50Z","published":"2024-07-08T15:59:44Z","title":"Variational Best-of-N Alignment","summary":"  Best-of-N (BoN) is a popular and effective algorithm for aligning language\nmodels to human preferences. The algorithm works as follows: at inference time,\nN samples are drawn from the language model, and the sample with the highest\nreward, as judged by a reward model, is returned as the output. Despite its\neffectiveness, BoN is computationally expensive; it reduces sampling throughput\nby a factor of N. To make BoN more efficient at inference time, one strategy is\nto fine-tune the language model to mimic what BoN does during inference. To\nachieve this, we derive the distribution induced by the BoN algorithm. We then\npropose to fine-tune the language model to minimize backward KL divergence to\nthe BoN distribution. Our approach is analogous to mean-field variational\ninference and, thus, we term it variational BoN (vBoN). To the extent this\nfine-tuning is successful and we end up with a good approximation, we have\nreduced the inference cost by a factor of N. Our experiments on controlled\ngeneration and summarization tasks show that BoN is the most effective\nalignment method, and our variational approximation to BoN achieves the closest\nperformance to BoN and surpasses models fine-tuned using the standard\nKL-constrained RL objective. In the controlled generation task, vBoN appears\nmore frequently on the Pareto frontier of reward and KL divergence compared to\nother alignment methods. In the summarization task, vBoN achieves high reward\nvalues across various sampling temperatures.\n","authors":["Afra Amini","Tim Vieira","Elliott Ash","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2407.06057v3.pdf","comment":"Accepted at ICLR 2025"},{"id":"http://arxiv.org/abs/2411.12556v3","updated":"2025-03-04T09:56:09Z","published":"2024-11-19T15:15:45Z","title":"UMGAD: Unsupervised Multiplex Graph Anomaly Detection","summary":"  Graph anomaly detection (GAD) is a critical task in graph machine learning,\nwith the primary objective of identifying anomalous nodes that deviate\nsignificantly from the majority. This task is widely applied in various\nreal-world scenarios, including fraud detection and social network analysis.\nHowever, existing GAD methods still face two major challenges: (1) They are\noften limited to detecting anomalies in single-type interaction graphs and\nstruggle with multiple interaction types in multiplex heterogeneous graphs. (2)\nIn unsupervised scenarios, selecting appropriate anomaly score thresholds\nremains a significant challenge for accurate anomaly detection. To address the\nabove challenges, we propose a novel Unsupervised Multiplex Graph Anomaly\nDetection method, named UMGAD. We first learn multi-relational correlations\namong nodes in multiplex heterogeneous graphs and capture anomaly information\nduring node attribute and structure reconstruction through graph-masked\nautoencoder (GMAE). Then, to further extract abnormal information, we generate\nattribute-level and subgraph-level augmented-view graphs respectively, and\nperform attribute and structure reconstruction through GMAE. Finally, we learn\nto optimize node attributes and structural features through contrastive\nlearning between original-view and augmented-view graphs to improve the model's\nability to capture anomalies. Meanwhile, we also propose a new anomaly score\nthreshold selection strategy, which allows the model to be independent of\nground truth information in real unsupervised scenarios. Extensive experiments\non four datasets show that our UMGAD significantly outperforms state-of-the-art\nmethods, achieving average improvements of 13.48% in AUC and 11.68% in Macro-F1\nacross all datasets.\n","authors":["Xiang Li","Jianpeng Qi","Zhongying Zhao","Guanjie Zheng","Lei Cao","Junyu Dong","Yanwei Yu"],"pdf_url":"https://arxiv.org/pdf/2411.12556v3.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2502.18495v2","updated":"2025-03-04T15:16:52Z","published":"2025-02-19T01:37:24Z","title":"A Comprehensive Survey on Composed Image Retrieval","summary":"  Composed Image Retrieval (CIR) is an emerging yet challenging task that\nallows users to search for target images using a multimodal query, comprising a\nreference image and a modification text specifying the user's desired changes\nto the reference image. Given its significant academic and practical value, CIR\nhas become a rapidly growing area of interest in the computer vision and\nmachine learning communities, particularly with the advances in deep learning.\nTo the best of our knowledge, there is currently no comprehensive review of CIR\nto provide a timely overview of this field. Therefore, we synthesize insights\nfrom over 120 publications in top conferences and journals, including ACM TOIS,\nSIGIR, and CVPR In particular, we systematically categorize existing supervised\nCIR and zero-shot CIR models using a fine-grained taxonomy. For a comprehensive\nreview, we also briefly discuss approaches for tasks closely related to CIR,\nsuch as attribute-based CIR and dialog-based CIR. Additionally, we summarize\nbenchmark datasets for evaluation and analyze existing supervised and zero-shot\nCIR methods by comparing experimental results across multiple datasets.\nFurthermore, we present promising future directions in this field, offering\npractical insights for researchers interested in further exploration. The\ncurated collection of related works is maintained and continuously updated in\nhttps://github.com/haokunwen/Awesome-Composed-Image-Retrieval.\n","authors":["Xuemeng Song","Haoqiang Lin","Haokun Wen","Bohan Hou","Mingzhu Xu","Liqiang Nie"],"pdf_url":"https://arxiv.org/pdf/2502.18495v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02823v1","updated":"2025-03-04T17:48:48Z","published":"2025-03-04T17:48:48Z","title":"A Multimodal Symphony: Integrating Taste and Sound through Generative AI","summary":"  In recent decades, neuroscientific and psychological research has traced\ndirect relationships between taste and auditory perceptions. This article\nexplores multimodal generative models capable of converting taste information\ninto music, building on this foundational research. We provide a brief review\nof the state of the art in this field, highlighting key findings and\nmethodologies. We present an experiment in which a fine-tuned version of a\ngenerative music model (MusicGEN) is used to generate music based on detailed\ntaste descriptions provided for each musical piece. The results are promising:\naccording the participants' ($n=111$) evaluation, the fine-tuned model produces\nmusic that more coherently reflects the input taste descriptions compared to\nthe non-fine-tuned model. This study represents a significant step towards\nunderstanding and developing embodied interactions between AI, sound, and\ntaste, opening new possibilities in the field of generative AI. We release our\ndataset, code and pre-trained model at: https://osf.io/xs5jy/.\n","authors":["Matteo Spanio","Massimiliano Zampini","Antonio Rodà","Franco Pierucci"],"pdf_url":"https://arxiv.org/pdf/2503.02823v1.pdf","comment":"17 pages, 6 figures (2 + 2 figures with 2 subfigures each)"},{"id":"http://arxiv.org/abs/2503.02452v1","updated":"2025-03-04T09:57:24Z","published":"2025-03-04T09:57:24Z","title":"2DGS-Avatar: Animatable High-fidelity Clothed Avatar via 2D Gaussian\n  Splatting","summary":"  Real-time rendering of high-fidelity and animatable avatars from monocular\nvideos remains a challenging problem in computer vision and graphics. Over the\npast few years, the Neural Radiance Field (NeRF) has made significant progress\nin rendering quality but behaves poorly in run-time performance due to the low\nefficiency of volumetric rendering. Recently, methods based on 3D Gaussian\nSplatting (3DGS) have shown great potential in fast training and real-time\nrendering. However, they still suffer from artifacts caused by inaccurate\ngeometry. To address these problems, we propose 2DGS-Avatar, a novel approach\nbased on 2D Gaussian Splatting (2DGS) for modeling animatable clothed avatars\nwith high-fidelity and fast training performance. Given monocular RGB videos as\ninput, our method generates an avatar that can be driven by poses and rendered\nin real-time. Compared to 3DGS-based methods, our 2DGS-Avatar retains the\nadvantages of fast training and rendering while also capturing detailed,\ndynamic, and photo-realistic appearances. We conduct abundant experiments on\npopular datasets such as AvatarRex and THuman4.0, demonstrating impressive\nperformance in both qualitative and quantitative metrics.\n","authors":["Qipeng Yan","Mingyang Sun","Lihua Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.02452v1.pdf","comment":"ICVRV 2024"},{"id":"http://arxiv.org/abs/2503.02318v1","updated":"2025-03-04T06:18:34Z","published":"2025-03-04T06:18:34Z","title":"Audio-Reasoner: Improving Reasoning Capability in Large Audio Language\n  Models","summary":"  Recent advancements in multimodal reasoning have largely overlooked the audio\nmodality. We introduce Audio-Reasoner, a large-scale audio language model for\ndeep reasoning in audio tasks. We meticulously curated a large-scale and\ndiverse multi-task audio dataset with simple annotations. Then, we leverage\nclosed-source models to conduct secondary labeling, QA generation, along with\nstructured COT process. These datasets together form a high-quality reasoning\ndataset with 1.2 million reasoning-rich samples, which we name CoTA. Following\ninference scaling principles, we train Audio-Reasoner on CoTA, enabling it to\nachieve great logical capabilities in audio reasoning. Experiments show\nstate-of-the-art performance across key benchmarks, including MMAU-mini\n(+25.42%), AIR-Bench chat/foundation(+14.57%/+10.13%), and MELD (+8.01%). Our\nfindings stress the core of structured CoT training in advancing audio\nreasoning.\n","authors":["Zhifei Xie","Mingbao Lin","Zihang Liu","Pengcheng Wu","Shuicheng Yan","Chunyan Miao"],"pdf_url":"https://arxiv.org/pdf/2503.02318v1.pdf","comment":"Technical report, in process"},{"id":"http://arxiv.org/abs/2310.07236v4","updated":"2025-03-04T03:47:04Z","published":"2023-10-11T06:56:08Z","title":"AdaMesh: Personalized Facial Expressions and Head Poses for Adaptive\n  Speech-Driven 3D Facial Animation","summary":"  Speech-driven 3D facial animation aims at generating facial movements that\nare synchronized with the driving speech, which has been widely explored\nrecently. Existing works mostly neglect the person-specific talking style in\ngeneration, including facial expression and head pose styles. Several works\nintend to capture the personalities by fine-tuning modules. However, limited\ntraining data leads to the lack of vividness. In this work, we propose AdaMesh,\na novel adaptive speech-driven facial animation approach, which learns the\npersonalized talking style from a reference video of about 10 seconds and\ngenerates vivid facial expressions and head poses. Specifically, we propose\nmixture-of-low-rank adaptation (MoLoRA) to fine-tune the expression adapter,\nwhich efficiently captures the facial expression style. For the personalized\npose style, we propose a pose adapter by building a discrete pose prior and\nretrieving the appropriate style embedding with a semantic-aware pose style\nmatrix without fine-tuning. Extensive experimental results show that our\napproach outperforms state-of-the-art methods, preserves the talking style in\nthe reference video, and generates vivid facial animation. The supplementary\nvideo and code will be available at https://adamesh.github.io.\n","authors":["Liyang Chen","Weihong Bao","Shun Lei","Boshi Tang","Zhiyong Wu","Shiyin Kang","Haozhi Huang","Helen Meng"],"pdf_url":"https://arxiv.org/pdf/2310.07236v4.pdf","comment":"Accepted by IEEE Transactions on Multimedia"},{"id":"http://arxiv.org/abs/2503.02199v1","updated":"2025-03-04T02:21:07Z","published":"2025-03-04T02:21:07Z","title":"Words or Vision: Do Vision-Language Models Have Blind Faith in Text?","summary":"  Vision-Language Models (VLMs) excel in integrating visual and textual\ninformation for vision-centric tasks, but their handling of inconsistencies\nbetween modalities is underexplored. We investigate VLMs' modality preferences\nwhen faced with visual data and varied textual inputs in vision-centered\nsettings. By introducing textual variations to four vision-centric tasks and\nevaluating ten Vision-Language Models (VLMs), we discover a \\emph{``blind faith\nin text''} phenomenon: VLMs disproportionately trust textual data over visual\ndata when inconsistencies arise, leading to significant performance drops under\ncorrupted text and raising safety concerns. We analyze factors influencing this\ntext bias, including instruction prompts, language model size, text relevance,\ntoken order, and the interplay between visual and textual certainty. While\ncertain factors, such as scaling up the language model size, slightly mitigate\ntext bias, others like token order can exacerbate it due to positional biases\ninherited from language models. To address this issue, we explore supervised\nfine-tuning with text augmentation and demonstrate its effectiveness in\nreducing text bias. Additionally, we provide a theoretical analysis suggesting\nthat the blind faith in text phenomenon may stem from an imbalance of pure text\nand multi-modal data during training. Our findings highlight the need for\nbalanced training and careful consideration of modality interactions in VLMs to\nenhance their robustness and reliability in handling multi-modal data\ninconsistencies.\n","authors":["Ailin Deng","Tri Cao","Zhirui Chen","Bryan Hooi"],"pdf_url":"https://arxiv.org/pdf/2503.02199v1.pdf","comment":"Accepted to CVPR 2025"},{"id":"http://arxiv.org/abs/2412.17049v2","updated":"2025-03-04T02:14:35Z","published":"2024-12-22T15:00:16Z","title":"Modular Conversational Agents for Surveys and Interviews","summary":"  Surveys and interviews are widely used for collecting insights on emerging or\nhypothetical scenarios. Traditional human-led methods often face challenges\nrelated to cost, scalability, and consistency. Recently, various domains have\nbegun to explore the use of conversational agents (chatbots) powered by\ngenerative artificial intelligence (AI) technologies. However, considering\ndecisions in transportation investments and policies often carry significant\npublic and environmental stakes, surveys and interviews face unique challenges\nin integrating AI agents, underscoring the need for a rigorous,\nresource-efficient approach that enhances participant engagement and ensures\nprivacy. This paper addresses this gap by introducing a modular approach and\nits resulting parameterized process for designing AI agents. We detail the\nsystem architecture, integrating engineered prompts, specialized knowledge\nbases, and customizable, goal-oriented conversational logic. We demonstrate the\nadaptability, generalizability, and efficacy of our modular approach through\nthree empirical studies: (1) travel preference surveys, highlighting\nconditional logic and multimodal (voice, text, and image generation)\ncapabilities; (2) public opinion elicitation on a newly constructed, novel\ninfrastructure project, showcasing question customization and multilingual\n(English and French) capabilities; and (3) expert consultation about the impact\nof technologies on future transportation systems, highlighting real-time,\nclarification request capabilities for open-ended questions, resilience in\nhandling erratic inputs, and efficient transcript postprocessing. The results\nsuggest that the AI agent increases completion rates and response quality.\nFurthermore, the modular approach demonstrates controllability, flexibility,\nand robustness while addressing key ethical, privacy, security, and token\nconsumption concerns.\n","authors":["Jiangbo Yu","Jinhua Zhao","Luis Miranda-Moreno","Matthew Korp"],"pdf_url":"https://arxiv.org/pdf/2412.17049v2.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2503.03062v1","updated":"2025-03-04T23:52:49Z","published":"2025-03-04T23:52:49Z","title":"Semi-Supervised In-Context Learning: A Baseline Study","summary":"  Most existing work in data selection for In-Context Learning (ICL) has\nfocused on constructing demonstrations from ground truth annotations, with\nlimited attention given to selecting reliable self-generated annotations. In\nthis work, we propose a three-step semi-supervised ICL framework: annotation\ngeneration, demonstration selection, and semi-supervised inference. Our\nbaseline, Naive-SemiICL, which prompts select high-confidence self-generated\ndemonstrations for ICL prompting, outperforms a 16-shot baseline by an average\nof 9.94% across 16 datasets. We further introduce IterPSD, an annotation\napproach that refines pseudo-demonstrations iteratively, achieving up to 6.8%\nadditional gains in classification tasks. Lastly, we reveal a scaling law for\nsemi-supervised ICL, where models achieve optimal performance with over 1,000\ndemonstrations.\n","authors":["Zhengyao Gu","Henry Peng Zou","Yankai Chen","Aiwei Liu","Weizhi Zhang","Philip S. Yu"],"pdf_url":"https://arxiv.org/pdf/2503.03062v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02993v1","updated":"2025-03-04T20:39:07Z","published":"2025-03-04T20:39:07Z","title":"Zero-Shot Multi-Label Classification of Bangla Documents: Large Decoders\n  Vs. Classic Encoders","summary":"  Bangla, a language spoken by over 300 million native speakers and ranked as\nthe sixth most spoken language worldwide, presents unique challenges in natural\nlanguage processing (NLP) due to its complex morphological characteristics and\nlimited resources. While recent Large Decoder Based models (LLMs), such as GPT,\nLLaMA, and DeepSeek, have demonstrated excellent performance across many NLP\ntasks, their effectiveness in Bangla remains largely unexplored. In this paper,\nwe establish the first benchmark comparing decoder-based LLMs with classic\nencoder-based models for Zero-Shot Multi-Label Classification (Zero-Shot-MLC)\ntask in Bangla. Our evaluation of 32 state-of-the-art models reveals that,\nexisting so-called powerful encoders and decoders still struggle to achieve\nhigh accuracy on the Bangla Zero-Shot-MLC task, suggesting a need for more\nresearch and resources for Bangla NLP.\n","authors":["Souvika Sarkar","Md. Najib Hasan","Santu Karmaker"],"pdf_url":"https://arxiv.org/pdf/2503.02993v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.13744v2","updated":"2025-03-04T19:15:49Z","published":"2024-09-11T00:16:17Z","title":"A Simplified Retriever to Improve Accuracy of Phenotype Normalizations\n  by Large Language Models","summary":"  Large language models (LLMs) have shown improved accuracy in phenotype term\nnormalization tasks when augmented with retrievers that suggest candidate\nnormalizations based on term definitions. In this work, we introduce a\nsimplified retriever that enhances LLM accuracy by searching the Human\nPhenotype Ontology (HPO) for candidate matches using contextual word embeddings\nfrom BioBERT without the need for explicit term definitions. Testing this\nmethod on terms derived from the clinical synopses of Online Mendelian\nInheritance in Man (OMIM), we demonstrate that the normalization accuracy of a\nstate-of-the-art LLM increases from a baseline of 62.3% without augmentation to\n90.3% with retriever augmentation. This approach is potentially generalizable\nto other biomedical term normalization tasks and offers an efficient\nalternative to more complex retrieval methods.\n","authors":["Daniel B. Hier","Thanh Son Do","Tayo Obafemi-Ajayi"],"pdf_url":"https://arxiv.org/pdf/2409.13744v2.pdf","comment":"Published by Frontiers in Digital Health"},{"id":"http://arxiv.org/abs/2503.02948v1","updated":"2025-03-04T19:09:48Z","published":"2025-03-04T19:09:48Z","title":"ExpertGenQA: Open-ended QA generation in Specialized Domains","summary":"  Generating high-quality question-answer pairs for specialized technical\ndomains remains challenging, with existing approaches facing a tradeoff between\nleveraging expert examples and achieving topical diversity. We present\nExpertGenQA, a protocol that combines few-shot learning with structured topic\nand style categorization to generate comprehensive domain-specific QA pairs.\nUsing U.S. Federal Railroad Administration documents as a test bed, we\ndemonstrate that ExpertGenQA achieves twice the efficiency of baseline few-shot\napproaches while maintaining $94.4\\%$ topic coverage. Through systematic\nevaluation, we show that current LLM-based judges and reward models exhibit\nstrong bias toward superficial writing styles rather than content quality. Our\nanalysis using Bloom's Taxonomy reveals that ExpertGenQA better preserves the\ncognitive complexity distribution of expert-written questions compared to\ntemplate-based approaches. When used to train retrieval models, our generated\nqueries improve top-1 accuracy by $13.02\\%$ over baseline performance,\ndemonstrating their effectiveness for downstream applications in technical\ndomains.\n","authors":["Haz Sameen Shahgir","Chansong Lim","Jia Chen","Evangelos E. Papalexakis","Yue Dong"],"pdf_url":"https://arxiv.org/pdf/2503.02948v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02922v1","updated":"2025-03-04T18:47:17Z","published":"2025-03-04T18:47:17Z","title":"Optimizing open-domain question answering with graph-based retrieval\n  augmented generation","summary":"  In this work, we benchmark various graph-based retrieval-augmented generation\n(RAG) systems across a broad spectrum of query types, including OLTP-style\n(fact-based) and OLAP-style (thematic) queries, to address the complex demands\nof open-domain question answering (QA). Traditional RAG methods often fall\nshort in handling nuanced, multi-document synthesis tasks. By structuring\nknowledge as graphs, we can facilitate the retrieval of context that captures\ngreater semantic depth and enhances language model operations. We explore\ngraph-based RAG methodologies and introduce TREX, a novel, cost-effective\nalternative that combines graph-based and vector-based retrieval techniques.\nOur benchmarking across four diverse datasets highlights the strengths of\ndifferent RAG methodologies, demonstrates TREX's ability to handle multiple\nopen-domain QA types, and reveals the limitations of current evaluation\nmethods.\n  In a real-world technical support case study, we demonstrate how TREX\nsolutions can surpass conventional vector-based RAG in efficiently synthesizing\ndata from heterogeneous sources. Our findings underscore the potential of\naugmenting large language models with advanced retrieval and orchestration\ncapabilities, advancing scalable, graph-based AI solutions.\n","authors":["Joyce Cahoon","Prerna Singh","Nick Litombe","Jonathan Larson","Ha Trinh","Yiwen Zhu","Andreas Mueller","Fotis Psallidas","Carlo Curino"],"pdf_url":"https://arxiv.org/pdf/2503.02922v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2103.03223v5","updated":"2025-03-04T15:20:55Z","published":"2021-03-04T18:51:06Z","title":"A Comparative Evaluation of Quantification Methods","summary":"  Quantification represents the problem of estimating the distribution of class\nlabels on unseen data. It also represents a growing research field in\nsupervised machine learning, for which a large variety of different algorithms\nhas been proposed in recent years. However, a comprehensive empirical\ncomparison of quantification methods that supports algorithm selection is not\navailable yet. In this work, we close this research gap by conducting a\nthorough empirical performance comparison of 24 different quantification\nmethods on overall more than 40 data sets, considering binary as well as\nmulticlass quantification settings. We observe that no single algorithm\ngenerally outperforms all competitors, but identify a group of methods\nincluding the threshold selection-based Median Sweep and TSMax methods, the DyS\nframework including the HDy method, Forman's mixture model, and Friedman's\nmethod that performs best in the binary setting. For the multiclass setting, we\nobserve that a different, broad group of algorithms yields good performance,\nincluding the HDx method, the Generalized Probabilistic Adjusted Count, the\nreadme method, the energy distance minimization method, the EM algorithm for\nquantification, and Friedman's method. We also find that tuning the underlying\nclassifiers has in most cases only a limited impact on the quantification\nperformance. More generally, we find that the performance on multiclass\nquantification is inferior to the results obtained in the binary setting. Our\nresults can guide practitioners who intend to apply quantification algorithms\nand help researchers to identify opportunities for future research.\n","authors":["Tobias Schumacher","Markus Strohmaier","Florian Lemmerich"],"pdf_url":"https://arxiv.org/pdf/2103.03223v5.pdf","comment":"41 pages, 18 figures, 9 tables"},{"id":"http://arxiv.org/abs/2502.18495v2","updated":"2025-03-04T15:16:52Z","published":"2025-02-19T01:37:24Z","title":"A Comprehensive Survey on Composed Image Retrieval","summary":"  Composed Image Retrieval (CIR) is an emerging yet challenging task that\nallows users to search for target images using a multimodal query, comprising a\nreference image and a modification text specifying the user's desired changes\nto the reference image. Given its significant academic and practical value, CIR\nhas become a rapidly growing area of interest in the computer vision and\nmachine learning communities, particularly with the advances in deep learning.\nTo the best of our knowledge, there is currently no comprehensive review of CIR\nto provide a timely overview of this field. Therefore, we synthesize insights\nfrom over 120 publications in top conferences and journals, including ACM TOIS,\nSIGIR, and CVPR In particular, we systematically categorize existing supervised\nCIR and zero-shot CIR models using a fine-grained taxonomy. For a comprehensive\nreview, we also briefly discuss approaches for tasks closely related to CIR,\nsuch as attribute-based CIR and dialog-based CIR. Additionally, we summarize\nbenchmark datasets for evaluation and analyze existing supervised and zero-shot\nCIR methods by comparing experimental results across multiple datasets.\nFurthermore, we present promising future directions in this field, offering\npractical insights for researchers interested in further exploration. The\ncurated collection of related works is maintained and continuously updated in\nhttps://github.com/haokunwen/Awesome-Composed-Image-Retrieval.\n","authors":["Xuemeng Song","Haoqiang Lin","Haokun Wen","Bohan Hou","Mingzhu Xu","Liqiang Nie"],"pdf_url":"https://arxiv.org/pdf/2502.18495v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02695v1","updated":"2025-03-04T15:12:18Z","published":"2025-03-04T15:12:18Z","title":"Zero-Shot Complex Question-Answering on Long Scientific Documents","summary":"  With the rapid development in Transformer-based language models, the reading\ncomprehension tasks on short documents and simple questions have been largely\naddressed. Long documents, specifically the scientific documents that are\ndensely packed with knowledge discovered and developed by humans, remain\nrelatively unexplored. These documents often come with a set of complex and\nmore realistic questions, adding to their complexity. We present a zero-shot\npipeline framework that enables social science researchers to perform\nquestion-answering tasks that are complex yet of predetermined question formats\non full-length research papers without requiring machine learning expertise.\nOur approach integrates pre-trained language models to handle challenging\nscenarios including multi-span extraction, multi-hop reasoning, and long-answer\ngeneration. Evaluating on MLPsych, a novel dataset of social psychology papers\nwith annotated complex questions, we demonstrate that our framework achieves\nstrong performance through combination of extractive and generative models.\nThis work advances document understanding capabilities for social sciences\nwhile providing practical tools for researchers.\n","authors":["Wanting Wang"],"pdf_url":"https://arxiv.org/pdf/2503.02695v1.pdf","comment":"AAAI 2025 Workshop on Document Understanding and Intelligence"},{"id":"http://arxiv.org/abs/2503.02674v1","updated":"2025-03-04T14:46:01Z","published":"2025-03-04T14:46:01Z","title":"Towards Robust Expert Finding in Community Question Answering Platforms","summary":"  This paper introduces TUEF, a topic-oriented user-interaction model for fair\nExpert Finding in Community Question Answering (CQA) platforms. The Expert\nFinding task in CQA platforms involves identifying proficient users capable of\nproviding accurate answers to questions from the community. To this aim, TUEF\nimproves the robustness and credibility of the CQA platform through a more\nprecise Expert Finding component. The key idea of TUEF is to exploit diverse\ntypes of information, specifically, content and social information, to identify\nmore precisely experts thus improving the robustness of the task. We assess\nTUEF through reproducible experiments conducted on a large-scale dataset from\nStackOverflow. The results consistently demonstrate that TUEF outperforms\nstate-of-the-art competitors while promoting transparent expert identification.\n","authors":["Maddalena Amendola","Andrea Passarella","Raffaele Perego"],"pdf_url":"https://arxiv.org/pdf/2503.02674v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02671v1","updated":"2025-03-04T14:43:43Z","published":"2025-03-04T14:43:43Z","title":"Are some books better than others?","summary":"  Scholars, awards committees, and laypeople frequently discuss the merit of\nwritten works. Literary professionals and journalists differ in how much\nperspectivism they concede in their book reviews. Here, we quantify how\nstrongly book reviews are determined by the actual book contents vs.\nidiosyncratic reader tendencies. In our analysis of 624,320 numerical and\ntextual book reviews, we find that the contents of professionally published\nbooks are not predictive of a random reader's reading enjoyment. Online reviews\nof popular fiction and non-fiction books carry up to ten times more information\nabout the reviewer than about the book. For books of a preferred genre, readers\nmight be less likely to give low ratings, but still struggle to converge in\ntheir relative assessments. We find that book evaluations generalize more\nacross experienced review writers than casual readers. When discussing specific\nissues with a book, one review text had poor predictability of issues brought\nup in another review of the same book. We conclude that extreme perspectivism\nis a justifiable position when researching literary quality, bestowing literary\nawards, and designing recommendation systems.\n","authors":["Hannes Rosenbusch","Luke Korthals"],"pdf_url":"https://arxiv.org/pdf/2503.02671v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02614v1","updated":"2025-03-04T13:34:19Z","published":"2025-03-04T13:34:19Z","title":"Personalized Generation In Large Model Era: A Survey","summary":"  In the era of large models, content generation is gradually shifting to\nPersonalized Generation (PGen), tailoring content to individual preferences and\nneeds. This paper presents the first comprehensive survey on PGen,\ninvestigating existing research in this rapidly growing field. We conceptualize\nPGen from a unified perspective, systematically formalizing its key components,\ncore objectives, and abstract workflows. Based on this unified perspective, we\npropose a multi-level taxonomy, offering an in-depth review of technical\nadvancements, commonly used datasets, and evaluation metrics across multiple\nmodalities, personalized contexts, and tasks. Moreover, we envision the\npotential applications of PGen and highlight open challenges and promising\ndirections for future exploration. By bridging PGen research across multiple\nmodalities, this survey serves as a valuable resource for fostering knowledge\nsharing and interdisciplinary collaboration, ultimately contributing to a more\npersonalized digital landscape.\n","authors":["Yiyan Xu","Jinghao Zhang","Alireza Salemi","Xinting Hu","Wenjie Wang","Fuli Feng","Hamed Zamani","Xiangnan He","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2503.02614v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.13121v2","updated":"2025-03-04T12:17:16Z","published":"2023-11-22T02:49:14Z","title":"GENET: Unleashing the Power of Side Information for Recommendation via\n  Hypergraph Pre-training","summary":"  Recommendation with side information has drawn significant research interest\ndue to its potential to mitigate user feedback sparsity. However, existing\nmodels struggle with generalization across diverse domains and types of side\ninformation. In particular, three challenges have not been addressed, and they\nare (1) the diverse formats of side information, including text sequences. (2)\nThe diverse semantics of side information that describes items and users from\nmulti-level in a context different from recommendation systems. (3) The diverse\ncorrelations in side information to measure similarity over multiple objects\nbeyond pairwise relations. In this paper, we introduce GENET (Generalized\nhypErgraph pretraiNing on sidE informaTion), which pre-trains user and item\nrepresentations on feedback-irrelevant side information and fine-tunes the\nrepresentations on user feedback data. GENET leverages pre-training as a means\nto prevent side information from overshadowing critical ID features and\nfeedback signals. It employs a hypergraph framework to accommodate various\ntypes of diverse side information. During pre-training, GENET integrates tasks\nfor hyperlink prediction and self-supervised contrast to capture fine-grained\nsemantics at both local and global levels. Additionally, it introduces a unique\nstrategy to enhance pre-training robustness by perturbing positive samples\nwhile maintaining high-order relations. Extensive experiments demonstrate that\nGENET exhibits strong generalization capabilities, outperforming the SOTA\nmethod by up to 38% in TOP-N recommendation and Sequential recommendation tasks\non various datasets with different side information.\n","authors":["Yang Li","Qi'ao Zhao","Chen Lin","Zhenjie Zhang","Xiaomin Zhu","Jinsong Su"],"pdf_url":"https://arxiv.org/pdf/2311.13121v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02542v1","updated":"2025-03-04T12:12:37Z","published":"2025-03-04T12:12:37Z","title":"Efficient Long Sequential Low-rank Adaptive Attention for Click-through\n  rate Prediction","summary":"  In the context of burgeoning user historical behavior data, Accurate\nclick-through rate(CTR) prediction requires effective modeling of lengthy user\nbehavior sequences. As the volume of such data keeps swelling, the focus of\nresearch has shifted towards developing effective long-term behavior modeling\nmethods to capture latent user interests. Nevertheless, the complexity\nintroduced by large scale data brings about computational hurdles. There is a\npressing need to strike a balance between achieving high model performance and\nmeeting the strict response time requirements of online services. While\nexisting retrieval-based methods (e.g., similarity filtering or attention\napproximation) achieve practical runtime efficiency, they inherently compromise\ninformation fidelity through aggressive sequence truncation or attention\nsparsification. This paper presents a novel attention mechanism. It overcomes\nthe shortcomings of existing methods while ensuring computational efficiency.\nThis mechanism learn compressed representation of sequence with length $L$ via\nlow-rank projection matrices (rank $r \\ll L$), reducing attention complexity\nfrom $O(L)$ to $O(r)$. It also integrates a uniquely designed loss function to\npreserve nonlinearity of attention. In the inference stage, the mechanism\nadopts matrix absorption and prestorage strategies. These strategies enable it\nto effectively satisfy online constraints. Comprehensive offline and online\nexperiments demonstrate that the proposed method outperforms current\nstate-of-the-art solutions.\n","authors":["Xin Song","Xiaochen Li","Jinxin Hu","Hong Wen","Zulong Chen","Yu Zhang","Xiaoyi Zeng","Zhang Jing"],"pdf_url":"https://arxiv.org/pdf/2503.02542v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02453v1","updated":"2025-03-04T10:00:05Z","published":"2025-03-04T10:00:05Z","title":"Sparse Meets Dense: Unified Generative Recommendations with Cascaded\n  Sparse-Dense Representations","summary":"  Generative models have recently gained attention in recommendation systems by\ndirectly predicting item identifiers from user interaction sequences. However,\nexisting methods suffer from significant information loss due to the separation\nof stages such as quantization and sequence modeling, hindering their ability\nto achieve the modeling precision and accuracy of sequential dense retrieval\ntechniques. Integrating generative and dense retrieval methods remains a\ncritical challenge. To address this, we introduce the Cascaded Organized\nBi-Represented generAtive retrieval (COBRA) framework, which innovatively\nintegrates sparse semantic IDs and dense vectors through a cascading process.\nOur method alternates between generating these representations by first\ngenerating sparse IDs, which serve as conditions to aid in the generation of\ndense vectors. End-to-end training enables dynamic refinement of dense\nrepresentations, capturing both semantic insights and collaborative signals\nfrom user-item interactions. During inference, COBRA employs a coarse-to-fine\nstrategy, starting with sparse ID generation and refining them into dense\nvectors via the generative model. We further propose BeamFusion, an innovative\napproach combining beam search with nearest neighbor scores to enhance\ninference flexibility and recommendation diversity. Extensive experiments on\npublic datasets and offline tests validate our method's robustness. Online A/B\ntests on a real-world advertising platform with over 200 million daily users\ndemonstrate substantial improvements in key metrics, highlighting COBRA's\npractical advantages.\n","authors":["Yuhao Yang","Zhi Ji","Zhaopeng Li","Yi Li","Zhonglin Mo","Yue Ding","Kai Chen","Zijian Zhang","Jie Li","Shuanglong Li","Lin Liu"],"pdf_url":"https://arxiv.org/pdf/2503.02453v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02401v1","updated":"2025-03-04T08:43:19Z","published":"2025-03-04T08:43:19Z","title":"Hierarchical Re-ranker Retriever (HRR)","summary":"  Retrieving the right level of context for a given query is a perennial\nchallenge in information retrieval - too large a chunk dilutes semantic\nspecificity, while chunks that are too small lack broader context. This paper\nintroduces the Hierarchical Re-ranker Retriever (HRR), a framework designed to\nachieve both fine-grained and high-level context retrieval for large language\nmodel (LLM) applications. In HRR, documents are split into sentence-level and\nintermediate-level (512 tokens) chunks to maximize vector-search quality for\nboth short and broad queries. We then employ a reranker that operates on these\n512-token chunks, ensuring an optimal balance neither too coarse nor too fine\nfor robust relevance scoring. Finally, top-ranked intermediate chunks are\nmapped to parent chunks (2048 tokens) to provide an LLM with sufficiently large\ncontext.\n","authors":["Ashish Singh","Priti Mohapatra"],"pdf_url":"https://arxiv.org/pdf/2503.02401v1.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2503.02398v1","updated":"2025-03-04T08:41:40Z","published":"2025-03-04T08:41:40Z","title":"PersonaX: A Recommendation Agent Oriented User Modeling Framework for\n  Long Behavior Sequence","summary":"  Recommendation agents leverage large language models for user modeling LLM UM\nto construct textual personas guiding alignment with real users. However\nexisting LLM UM methods struggle with long user generated content UGC due to\ncontext limitations and performance degradation. To address this sampling\nstrategies prioritize relevance or recency are often applied yet they\ninevitably neglect the diverse user interests embedded within the discarded\nbehaviors resulting in incomplete modeling and degraded profiling quality.\nFurthermore relevance based sampling requires real time retrieval forcing the\nuser modeling process to operate online which introduces significant latency\noverhead. In this paper we propose PersonaX an agent agnostic LLM UM framework\nthat tackles these challenges through sub behavior sequence SBS selection and\noffline multi persona construction. PersonaX extracts compact SBS segments\noffline to capture diverse user interests generating fine grained textual\npersonas that are cached for efficient online retrieval. This approach ensures\nthat the user persona used for prompting remains highly relevant to the current\ncontext while eliminating the need for online user modeling. For SBS selection\nwe ensure both efficiency length less than five and high representational\nquality by balancing prototypicality and diversity within the sampled data.\nExtensive experiments validate the effectiveness and versatility of PersonaX in\nhigh quality user profiling. Utilizing only 30 to 50 percent of the behavioral\ndata with a sequence length of 480 integrating PersonaX with AgentCF yields an\nabsolute performance improvement of 3 to 11 percent while integration with\nAgent4Rec results in a gain of 10 to 50 percent. PersonaX as an agent agnostic\nframework sets a new benchmark for scalable user modeling paving the way for\nmore accurate and efficient LLM driven recommendation agents.\n","authors":["Yunxiao Shi","Wujiang Xu","Zeqi Zhang","Xing Zi","Qiang Wu","Min Xu"],"pdf_url":"https://arxiv.org/pdf/2503.02398v1.pdf","comment":"draft paper"},{"id":"http://arxiv.org/abs/2404.14851v4","updated":"2025-03-04T08:38:34Z","published":"2024-04-23T09:05:37Z","title":"From Matching to Generation: A Survey on Generative Information\n  Retrieval","summary":"  Information Retrieval (IR) systems are crucial tools for users to access\ninformation, which have long been dominated by traditional methods relying on\nsimilarity matching. With the advancement of pre-trained language models,\ngenerative information retrieval (GenIR) emerges as a novel paradigm,\nattracting increasing attention. Based on the form of information provided to\nusers, current research in GenIR can be categorized into two aspects:\n\\textbf{(1) Generative Document Retrieval} (GR) leverages the generative\nmodel's parameters for memorizing documents, enabling retrieval by directly\ngenerating relevant document identifiers without explicit indexing. \\textbf{(2)\nReliable Response Generation} employs language models to directly generate\ninformation users seek, breaking the limitations of traditional IR in terms of\ndocument granularity and relevance matching while offering flexibility,\nefficiency, and creativity to meet practical needs. This paper aims to\nsystematically review the latest research progress in GenIR. We will summarize\nthe advancements in GR regarding model training and structure, document\nidentifier, incremental learning, etc., as well as progress in reliable\nresponse generation in aspects of internal knowledge memorization, external\nknowledge augmentation, etc. We also review the evaluation, challenges and\nfuture developments in GenIR systems. This review aims to offer a comprehensive\nreference for researchers, encouraging further development in the GenIR field.\nGithub Repository: https://github.com/RUC-NLPIR/GenIR-Survey\n","authors":["Xiaoxi Li","Jiajie Jin","Yujia Zhou","Yuyao Zhang","Peitian Zhang","Yutao Zhu","Zhicheng Dou"],"pdf_url":"https://arxiv.org/pdf/2404.14851v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.11480v5","updated":"2025-03-04T07:56:04Z","published":"2024-02-18T07:06:17Z","title":"Pattern-wise Transparent Sequential Recommendation","summary":"  A transparent decision-making process is essential for developing reliable\nand trustworthy recommender systems. For sequential recommendation, it means\nthat the model can identify key items that account for its recommendation\nresults. However, achieving both interpretability and recommendation\nperformance simultaneously is challenging, especially for models that take the\nentire sequence of items as input without screening. In this paper, we propose\nan interpretable framework (named PTSR) that enables a pattern-wise transparent\ndecision-making process without extra features. It breaks the sequence of items\ninto multi-level patterns that serve as atomic units throughout the\nrecommendation process. The contribution of each pattern to the outcome is\nquantified in the probability space. With a carefully designed score correction\nmechanism, the pattern contribution can be implicitly learned in the absence of\nground-truth key patterns. The final recommended items are those that most key\npatterns strongly endorse. Extensive experiments on five public datasets\ndemonstrate remarkable recommendation performance, while statistical analysis\nand case studies validate the model interpretability.\n","authors":["Kun Ma","Cong Xu","Zeyuan Chen","Wei Zhang"],"pdf_url":"https://arxiv.org/pdf/2402.11480v5.pdf","comment":"This paper has been accepted by IEEE TKDE"},{"id":"http://arxiv.org/abs/2501.05874v2","updated":"2025-03-04T07:29:52Z","published":"2025-01-10T11:17:15Z","title":"VideoRAG: Retrieval-Augmented Generation over Video Corpus","summary":"  Retrieval-Augmented Generation (RAG) is a powerful strategy for improving the\nfactual accuracy of models by retrieving external knowledge relevant to queries\nand incorporating it into the generation process. However, existing approaches\nprimarily focus on text, with some recent advancements considering images, and\nthey largely overlook videos, a rich source of multimodal knowledge capable of\nrepresenting contextual details more effectively than any other modality. While\nvery recent studies explore the use of videos in response generation, they\neither predefine query-associated videos without retrieval or convert videos\ninto textual descriptions losing multimodal richness. To tackle these, we\nintroduce VideoRAG, a framework that not only dynamically retrieves videos\nbased on their relevance with queries but also utilizes both visual and textual\ninformation. The operation of VideoRAG is powered by recent Large Video\nLanguage Models (LVLMs), which enable the direct processing of video content to\nrepresent it for retrieval and the seamless integration of retrieved videos\njointly with queries for response generation. Also, inspired by that the\ncontext size of LVLMs may not be sufficient to process all frames in extremely\nlong videos and not all frames are equally important, we introduce a video\nframe selection mechanism to extract the most informative subset of frames,\nalong with a strategy to extract textual information from videos (as it can aid\nthe understanding of video content) when their subtitles are not available. We\nexperimentally validate the effectiveness of VideoRAG, showcasing that it is\nsuperior to relevant baselines. Code is available at\nhttps://github.com/starsuzi/VideoRAG.\n","authors":["Soyeong Jeong","Kangsan Kim","Jinheon Baek","Sung Ju Hwang"],"pdf_url":"https://arxiv.org/pdf/2501.05874v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.17102v2","updated":"2025-03-04T07:04:59Z","published":"2024-11-26T04:39:46Z","title":"Scholar Name Disambiguation with Search-enhanced LLM Across Language","summary":"  The task of scholar name disambiguation is crucial in various real-world\nscenarios, including bibliometric-based candidate evaluation for awards,\napplication material anti-fraud measures, and more. Despite significant\nadvancements, current methods face limitations due to the complexity of\nheterogeneous data, often necessitating extensive human intervention. This\npaper proposes a novel approach by leveraging search-enhanced language models\nacross multiple languages to improve name disambiguation. By utilizing the\npowerful query rewriting, intent recognition, and data indexing capabilities of\nsearch engines, our method can gather richer information for distinguishing\nbetween entities and extracting profiles, resulting in a more comprehensive\ndata dimension. Given the strong cross-language capabilities of large language\nmodels(LLMs), optimizing enhanced retrieval methods with this technology offers\nsubstantial potential for high-efficiency information retrieval and\nutilization. Our experiments demonstrate that incorporating local languages\nsignificantly enhances disambiguation performance, particularly for scholars\nfrom diverse geographic regions. This multi-lingual, search-enhanced\nmethodology offers a promising direction for more efficient and accurate active\nscholar name disambiguation.\n","authors":["Renyu Zhao","Yunxin Chen"],"pdf_url":"https://arxiv.org/pdf/2411.17102v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01469v2","updated":"2025-03-04T06:37:59Z","published":"2025-03-03T12:23:54Z","title":"Hierarchical Causal Transformer with Heterogeneous Information for\n  Expandable Sequential Recommendation","summary":"  Sequential recommendation systems leveraging transformer architectures have\ndemonstrated exceptional capabilities in capturing user behavior patterns. At\nthe core of these systems lies the critical challenge of constructing effective\nitem representations. Traditional approaches employ feature fusion through\nsimple concatenation or basic neural architectures to create uniform\nrepresentation sequences. However, these conventional methods fail to address\nthe intrinsic diversity of item attributes, thereby constraining the\ntransformer's capacity to discern fine-grained patterns and hindering model\nextensibility. Although recent research has begun incorporating user-related\nheterogeneous features into item sequences, the equally crucial item-side\nheterogeneous feature continue to be neglected. To bridge this methodological\ngap, we present HeterRec - an innovative framework featuring two novel\ncomponents: the Heterogeneous Token Flattening Layer (HTFL) and Hierarchical\nCausal Transformer (HCT). HTFL pioneers a sophisticated tokenization mechanism\nthat decomposes items into multi-dimensional token sets and structures them\ninto heterogeneous sequences, enabling scalable performance enhancement through\nmodel expansion. The HCT architecture further enhances pattern discovery\nthrough token-level and item-level attention mechanisms. furthermore, we\ndevelop a Listwise Multi-step Prediction (LMP) objective function to optimize\nlearning process. Rigorous validation, including real-world industrial\nplatforms, confirms HeterRec's state-of-the-art performance in both effective\nand efficiency.\n","authors":["Hao Deng","Haibo Xing","Kanefumi Matsuyama","Yulei Huang","Jinxin Hu","Hong Wen","Jia Xu","Zulong Chen","Yu Zhang","Xiaoyi Zeng","Jing Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.01469v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.11610v2","updated":"2025-03-04T06:28:50Z","published":"2025-02-17T09:54:46Z","title":"Accuracy Assessment of OpenAlex and Clarivate Scholar ID with an\n  LLM-Assisted Benchmark","summary":"  In quantitative SciSci (science of science) studies, accurately identifying\nindividual scholars is paramount for scientific data analysis. However, the\nvariability in how names are represented-due to commonality, abbreviations, and\ndifferent spelling conventions-complicates this task. While identifier systems\nlike ORCID are being developed, many scholars remain unregistered, and numerous\npublications are not included. Scholarly databases such as Clarivate and\nOpenAlex have introduced their own ID systems as preliminary name\ndisambiguation solutions. This study evaluates the effectiveness of these\nsystems across different groups to determine their suitability for various\napplication scenarios. We sampled authors from the top quartile (Q1) of Web of\nScience (WOS) journals based on country, discipline, and number of\ncorresponding author papers. For each group, we selected 100 scholars and\nmeticulously annotated all their papers using a Search-enhanced Large Language\nModel method. Using these annotations, we identified the corresponding IDs in\nOpenAlex and Clarivate, extracted all associated papers, filtered for Q1 WOS\njournals, and calculated precision and recall by comparing against the\nannotated dataset.\n","authors":["Renyu Zhao","Yunxin Chen"],"pdf_url":"https://arxiv.org/pdf/2502.11610v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02298v1","updated":"2025-03-04T05:48:07Z","published":"2025-03-04T05:48:07Z","title":"Towards Explainable Doctor Recommendation with Large Language Models","summary":"  The advent of internet medicine provides patients with unprecedented\nconvenience in searching and communicating with doctors relevant to their\ndiseases and desired treatments online. However, the current doctor\nrecommendation systems fail to fully ensure the professionalism and\ninterpretability of the recommended results. In this work, we formulate doctor\nrecommendation as a ranking task and develop a large language model (LLM)-based\npointwise ranking framework. Our framework ranks doctors according to their\nrelevance regarding specific diseases-treatment pairs in a zero-shot setting.\nThe advantage of our framework lies in its ability to generate precise and\nexplainable doctor ranking results. Additionally, we construct DrRank, a new\nexpertise-driven doctor ranking dataset comprising over 38 disease-treatment\npairs. Experiment results on the DrRank dataset demonstrate that our framework\nsignificantly outperforms the strongest cross-encoder baseline, achieving a\nnotable gain of +5.45 in the NDCG@10 score while maintaining affordable latency\nconsumption. Furthermore, we comprehensively present the fairness analysis\nresults of our framework from three perspectives of different diseases, patient\ngender, and geographical regions. Meanwhile, the interpretability of our\nframework is rigorously verified by three human experts, providing further\nevidence of the reliability of our proposed framework for doctor\nrecommendation.\n","authors":["Ziyang Zeng","Dongyuan Li","Yuqing Yang"],"pdf_url":"https://arxiv.org/pdf/2503.02298v1.pdf","comment":"12 pages, 6 figures, Journal of Biomedical and Health Informatics\n  (JBHI) under review"},{"id":"http://arxiv.org/abs/2501.18210v2","updated":"2025-03-04T04:07:39Z","published":"2025-01-30T08:55:32Z","title":"Hashtag Re-Appropriation for Audience Control on Recommendation-Driven\n  Social Media Xiaohongshu (rednote)","summary":"  Algorithms have played a central role in personalized recommendations on\nsocial media. However, they also present significant obstacles for content\ncreators trying to predict and manage their audience reach. This issue is\nparticularly challenging for marginalized groups seeking to maintain safe\nspaces. Our study explores how women on Xiaohongshu (rednote), a\nrecommendation-driven social platform, proactively re-appropriate hashtags\n(e.g., #Baby Supplemental Food) by using them in posts unrelated to their\nliteral meaning. The hashtags were strategically chosen from topics that would\nbe uninteresting to the male audience they wanted to block. Through a\nmixed-methods approach, we analyzed the practice of hashtag re-appropriation\nbased on 5,800 collected posts and interviewed 24 active users from diverse\nbackgrounds to uncover users' motivations and reactions towards the\nre-appropriation. This practice highlights how users can reclaim agency over\ncontent distribution on recommendation-driven platforms, offering insights into\nself-governance within algorithmic-centered power structures.\n","authors":["Ruyuan Wan","Lingbo Tong","Tiffany Knearem","Toby Jia-Jun Li","Ting-Hao 'Kenneth' Huang","Qunfang Wu"],"pdf_url":"https://arxiv.org/pdf/2501.18210v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02251v1","updated":"2025-03-04T03:57:10Z","published":"2025-03-04T03:57:10Z","title":"Tailoring Table Retrieval from a Field-aware Hybrid Matching Perspective","summary":"  Table retrieval, essential for accessing information through tabular data, is\nless explored compared to text retrieval. The row/column structure and distinct\nfields of tables (including titles, headers, and cells) present unique\nchallenges. For example, different table fields have varying matching\npreferences: cells may favor finer-grained (word/phrase level) matching over\nbroader (sentence/passage level) matching due to their fragmented and detailed\nnature, unlike titles. This necessitates a table-specific retriever to\naccommodate the various matching needs of each table field. Therefore, we\nintroduce a Table-tailored HYbrid Matching rEtriever (THYME), which approaches\ntable retrieval from a field-aware hybrid matching perspective. Empirical\nresults on two table retrieval benchmarks, NQ-TABLES and OTT-QA, show that\nTHYME significantly outperforms state-of-the-art baselines. Comprehensive\nanalyses confirm the differing matching preferences across table fields and\nvalidate the design of THYME.\n","authors":["Da Li","Keping Bi","Jiafeng Guo","Xueqi Cheng"],"pdf_url":"https://arxiv.org/pdf/2503.02251v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.15331v2","updated":"2025-03-04T02:18:36Z","published":"2025-02-21T09:34:31Z","title":"Lightweight yet Efficient: An External Attentive Graph Convolutional\n  Network with Positional Prompts for Sequential Recommendation","summary":"  Graph-based Sequential Recommender systems (GSRs) have gained significant\nresearch attention due to their ability to simultaneously handle user-item\ninteractions and sequential relationships between items. Current GSRs often\nutilize composite or in-depth structures for graph encoding (e.g., the Graph\nTransformer). Nevertheless, they have high computational complexity, hindering\nthe deployment on resource-constrained edge devices. Moreover, the relative\nposition encoding in Graph Transformer has difficulty in considering the\ncomplicated positional dependencies within sequence. To this end, we propose an\nExternal Attentive Graph convolutional network with Positional prompts for\nSequential recommendation, namely EA-GPS. Specifically, we first introduce an\nexternal attentive graph convolutional network that linearly measures the\nglobal associations among nodes via two external memory units. Then, we present\na positional prompt-based decoder that explicitly treats the absolute item\npositions as external prompts. By introducing length-adaptive sequential\nmasking and a soft attention network, such a decoder facilitates the model to\ncapture the long-term positional dependencies and contextual relationships\nwithin sequences. Extensive experimental results on five real-world datasets\ndemonstrate that the proposed EA-GPS outperforms the state-of-the-art methods.\nRemarkably, it achieves the superior performance while maintaining a smaller\nparameter size and lower training overhead. The implementation of this work is\npublicly available at https://github.com/ZZY-GraphMiningLab/EA-GPS.\n","authors":["Jinyu Zhang","Chao Li","Zhongying Zhao"],"pdf_url":"https://arxiv.org/pdf/2502.15331v2.pdf","comment":"26 pages, 8 figures, journal paper, accepted by TOIS at 20th\n  February, 2025"},{"id":"http://arxiv.org/abs/2410.11841v2","updated":"2025-03-04T01:02:11Z","published":"2024-10-15T17:59:30Z","title":"GaVaMoE: Gaussian-Variational Gated Mixture of Experts for Explainable\n  Recommendation","summary":"  Large language model-based explainable recommendation (LLM-based ER) systems\nshow promise in generating human-like explanations for recommendations.\nHowever, they face challenges in modeling user-item collaborative preferences,\npersonalizing explanations, and handling sparse user-item interactions. To\naddress these issues, we propose GaVaMoE, a novel Gaussian-Variational Gated\nMixture of Experts framework for explainable recommendation. GaVaMoE introduces\ntwo key components: (1) a rating reconstruction module that employs Variational\nAutoencoder (VAE) with a Gaussian Mixture Model (GMM) to capture complex\nuser-item collaborative preferences, serving as a pre-trained multi-gating\nmechanism; and (2) a set of fine-grained expert models coupled with the\nmulti-gating mechanism for generating highly personalized explanations. The VAE\ncomponent models latent factors in user-item interactions, while the GMM\nclusters users with similar behaviors. Each cluster corresponds to a gate in\nthe multi-gating mechanism, routing user-item pairs to appropriate expert\nmodels. This architecture enables GaVaMoE to generate tailored explanations for\nspecific user types and preferences, mitigating data sparsity by leveraging\nuser similarities. Extensive experiments on three real-world datasets\ndemonstrate that GaVaMoE significantly outperforms existing methods in\nexplanation quality, personalization, and consistency. Notably, GaVaMoE\nexhibits robust performance in scenarios with sparse user-item interactions,\nmaintaining high-quality explanations even for users with limited historical\ndata.\n","authors":["Fei Tang","Yongliang Shen","Hang Zhang","Zeqi Tan","Wenqi Zhang","Zhibiao Huang","Kaitao Song","Weiming Lu","Yueting Zhuang"],"pdf_url":"https://arxiv.org/pdf/2410.11841v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.01007v3","updated":"2025-03-04T00:36:44Z","published":"2024-12-01T23:54:12Z","title":"CoRNStack: High-Quality Contrastive Data for Better Code Retrieval and\n  Reranking","summary":"  Effective code retrieval plays a crucial role in advancing code generation,\nbug fixing, and software maintenance, particularly as software systems increase\nin complexity. While current code embedding models have demonstrated promise in\nretrieving code snippets for small-scale, well-defined tasks, they often\nunderperform in more demanding real-world applications such as bug localization\nwithin GitHub repositories. We hypothesize that a key issue is their reliance\non noisy and inconsistent datasets for training, which impedes their ability to\ngeneralize to more complex retrieval scenarios. To address these limitations,\nwe introduce CoRNStack, a large-scale, high-quality contrastive training\ndataset for code that spans multiple programming languages. This dataset is\ncurated using consistency filtering to eliminate noisy positives and is further\nenriched with mined hard negatives, thereby facilitating more effective\nlearning. We demonstrate that contrastive training of embedding models using\nCoRNStack leads to state-of-the-art performance across a variety of code\nretrieval tasks. Furthermore, the dataset can be leveraged for training code\nreranking models, a largely underexplored area compared to text reranking. Our\nfinetuned code reranking model significantly improves the ranking quality over\nthe retrieved results. Finally, by employing our code retriever and reranker\ntogether, we demonstrate significant improvements in function localization for\nGitHub issues, an important component of real-world software development.\n","authors":["Tarun Suresh","Revanth Gangi Reddy","Yifei Xu","Zach Nussbaum","Andriy Mulyar","Brandon Duderstadt","Heng Ji"],"pdf_url":"https://arxiv.org/pdf/2412.01007v3.pdf","comment":"Published as a conference paper at ICLR 2025. First and second author\n  had equal contribution"}]},"2025-03-05T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2503.03750v1","updated":"2025-03-05T18:59:23Z","published":"2025-03-05T18:59:23Z","title":"The MASK Benchmark: Disentangling Honesty From Accuracy in AI Systems","summary":"  As large language models (LLMs) become more capable and agentic, the\nrequirement for trust in their outputs grows significantly, yet at the same\ntime concerns have been mounting that models may learn to lie in pursuit of\ntheir goals. To address these concerns, a body of work has emerged around the\nnotion of \"honesty\" in LLMs, along with interventions aimed at mitigating\ndeceptive behaviors. However, evaluations of honesty are currently highly\nlimited, with no benchmark combining large scale and applicability to all\nmodels. Moreover, many benchmarks claiming to measure honesty in fact simply\nmeasure accuracy--the correctness of a model's beliefs--in disguise. In this\nwork, we introduce a large-scale human-collected dataset for measuring honesty\ndirectly, allowing us to disentangle accuracy from honesty for the first time.\nAcross a diverse set of LLMs, we find that while larger models obtain higher\naccuracy on our benchmark, they do not become more honest. Surprisingly, while\nmost frontier LLMs obtain high scores on truthfulness benchmarks, we find a\nsubstantial propensity in frontier LLMs to lie when pressured to do so,\nresulting in low honesty scores on our benchmark. We find that simple methods,\nsuch as representation engineering interventions, can improve honesty. These\nresults underscore the growing need for robust evaluations and effective\ninterventions to ensure LLMs remain trustworthy.\n","authors":["Richard Ren","Arunim Agarwal","Mantas Mazeika","Cristina Menghini","Robert Vacareanu","Brad Kenstler","Mick Yang","Isabelle Barrass","Alice Gatti","Xuwang Yin","Eduardo Trevino","Matias Geralnik","Adam Khoja","Dean Lee","Summer Yue","Dan Hendrycks"],"pdf_url":"https://arxiv.org/pdf/2503.03750v1.pdf","comment":"Website: https://www.mask-benchmark.ai"},{"id":"http://arxiv.org/abs/2503.03746v1","updated":"2025-03-05T18:58:44Z","published":"2025-03-05T18:58:44Z","title":"Process-based Self-Rewarding Language Models","summary":"  Large Language Models have demonstrated outstanding performance across\nvarious downstream tasks and have been widely applied in multiple scenarios.\nHuman-annotated preference data is used for training to further improve LLMs'\nperformance, which is constrained by the upper limit of human performance.\nTherefore, Self-Rewarding method has been proposed, where LLMs generate\ntraining data by rewarding their own outputs. However, the existing\nself-rewarding paradigm is not effective in mathematical reasoning scenarios\nand may even lead to a decline in performance. In this work, we propose the\nProcess-based Self-Rewarding pipeline for language models, which introduces\nlong-thought reasoning, step-wise LLM-as-a-Judge, and step-wise preference\noptimization within the self-rewarding paradigm. Our new paradigm successfully\nenhances the performance of LLMs on multiple mathematical reasoning benchmarks\nthrough iterative Process-based Self-Rewarding, demonstrating the immense\npotential of self-rewarding to achieve LLM reasoning that may surpass human\ncapabilities.\n","authors":["Shimao Zhang","Xiao Liu","Xin Zhang","Junxiao Liu","Zheheng Luo","Shujian Huang","Yeyun Gong"],"pdf_url":"https://arxiv.org/pdf/2503.03746v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.14395v2","updated":"2025-03-05T18:17:28Z","published":"2024-04-22T17:55:56Z","title":"PARAMANU-GANITA: Can Small Math Language Models Rival with Large\n  Language Models on Mathematical Reasoning?","summary":"  In this paper, we study whether domain specific pretraining of small\ngenerative language models (SLM) from scratch with domain specialized tokenizer\nand Chain-of-Thought (CoT) instruction fine-tuning results in competitive\nperformance on mathematical reasoning compared to LLMs? Secondly, whether this\napproach is environmentally sustainable, highly cost efficient? To address\nthese research questions, we present Paramanu-Ganita, a 208 million-parameter\nnovel decoder-only Auto Regressive SLM on mathematics. We performed pretraining\nfrom scratch on 31.5 billion tokens for 170 A100 hours using a context size of\n4096 on a mixed mathematical corpus consisting of web pages, source code,\ntextbooks, CoT templatised StackOverflow QA pairs, and mathematical lecture\nnotes in LaTeX curated by us. We also trained a math and code specialised BPE\ntokenizer. We proposed and performed CoT instruction fine-tuning of\nParamanu-Ganita on the MetaMathQA dataset. Our model Paramanu-Ganita, despite\nbeing 34 times smaller than the 7B LLMs, outperforms generalist LLMs by\napproximately 30% points, and even math-specialised LLMs by 3-23% points in\nGSM8K test accuracy metric. On MATH benchmark, Paramanu-Ganita outperformed the\nvarious models by 6-8% points. On benchmarks like LogiQA, MMLU (high school,\ncollege level), and competitive exams level, AGIEVAL (AQuA-RAT, SAT-Math),\nParamanu-Ganita outperformed others by 1-4%. Our model is available at\nhttps://huggingface.co/gyanai/paramanu-ganita-208M-hf .\n","authors":["Mitodru Niyogi","Arnab Bhattacharya"],"pdf_url":"https://arxiv.org/pdf/2404.14395v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03710v1","updated":"2025-03-05T18:01:05Z","published":"2025-03-05T18:01:05Z","title":"Improving LLM Safety Alignment with Dual-Objective Optimization","summary":"  Existing training-time safety alignment techniques for large language models\n(LLMs) remain vulnerable to jailbreak attacks. Direct preference optimization\n(DPO), a widely deployed alignment method, exhibits limitations in both\nexperimental and theoretical contexts as its loss function proves suboptimal\nfor refusal learning. Through gradient-based analysis, we identify these\nshortcomings and propose an improved safety alignment that disentangles DPO\nobjectives into two components: (1) robust refusal training, which encourages\nrefusal even when partial unsafe generations are produced, and (2) targeted\nunlearning of harmful knowledge. This approach significantly increases LLM\nrobustness against a wide range of jailbreak attacks, including prefilling,\nsuffix, and multi-turn attacks across both in-distribution and\nout-of-distribution scenarios. Furthermore, we introduce a method to emphasize\ncritical refusal tokens by incorporating a reward-based token-level weighting\nmechanism for refusal learning, which further improves the robustness against\nadversarial exploits. Our research also suggests that robustness to jailbreak\nattacks is correlated with token distribution shifts in the training process\nand internal representations of refusal and harmful tokens, offering valuable\ndirections for future research in LLM safety alignment. The code is available\nat https://github.com/wicai24/DOOR-Alignment\n","authors":["Xuandong Zhao","Will Cai","Tianneng Shi","David Huang","Licong Lin","Song Mei","Dawn Song"],"pdf_url":"https://arxiv.org/pdf/2503.03710v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03705v1","updated":"2025-03-05T17:56:20Z","published":"2025-03-05T17:56:20Z","title":"Effective LLM Knowledge Learning via Model Generalization","summary":"  Large language models (LLMs) are trained on enormous documents that contain\nextensive world knowledge. However, it is still not well-understood how\nknowledge is acquired via autoregressive pre-training. This lack of\nunderstanding greatly hinders effective knowledge learning, especially for\ncontinued pretraining on up-to-date information, as this evolving information\noften lacks diverse repetitions like foundational knowledge. In this paper, we\nfocus on understanding and improving LLM knowledge learning. We found and\nverified that knowledge learning for LLMs can be deemed as an implicit\nsupervised task hidden in the autoregressive pre-training objective. Our\nfindings suggest that knowledge learning for LLMs would benefit from methods\ndesigned to improve generalization ability for supervised tasks. Based on our\nanalysis, we propose the formatting-based data augmentation to grow\nin-distribution samples, which does not present the risk of altering the facts\nembedded in documents as text paraphrasing. We also introduce sharpness-aware\nminimization as an effective optimization algorithm to better improve\ngeneralization. Moreover, our analysis and method can be readily extended to\ninstruction tuning. Extensive experiment results validate our findings and\ndemonstrate our methods' effectiveness in both continued pre-training and\ninstruction tuning. This paper offers new perspectives and insights to\ninterpret and design effective strategies for LLM knowledge learning.\n","authors":["Mingkang Zhu","Xi Chen","Zhongdao Wang","Bei Yu","Hengshuang Zhao","Jiaya Jia"],"pdf_url":"https://arxiv.org/pdf/2503.03705v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03703v1","updated":"2025-03-05T17:53:11Z","published":"2025-03-05T17:53:11Z","title":"SoftMatcha: A Soft and Fast Pattern Matcher for Billion-Scale Corpus\n  Searches","summary":"  Researchers and practitioners in natural language processing and\ncomputational linguistics frequently observe and analyze the real language\nusage in large-scale corpora. For that purpose, they often employ off-the-shelf\npattern-matching tools, such as grep, and keyword-in-context concordancers,\nwhich is widely used in corpus linguistics for gathering examples. Nonetheless,\nthese existing techniques rely on surface-level string matching, and thus they\nsuffer from the major limitation of not being able to handle orthographic\nvariations and paraphrasing -- notable and common phenomena in any natural\nlanguage. In addition, existing continuous approaches such as dense vector\nsearch tend to be overly coarse, often retrieving texts that are unrelated but\nshare similar topics. Given these challenges, we propose a novel algorithm that\nachieves \\emph{soft} (or semantic) yet efficient pattern matching by relaxing a\nsurface-level matching with word embeddings. Our algorithm is highly scalable\nwith respect to the size of the corpus text utilizing inverted indexes. We have\nprepared an efficient implementation, and we provide an accessible web tool.\nOur experiments demonstrate that the proposed method (i) can execute searches\non billion-scale corpora in less than a second, which is comparable in speed to\nsurface-level string matching and dense vector search; (ii) can extract harmful\ninstances that semantically match queries from a large set of English and\nJapanese Wikipedia articles; and (iii) can be effectively applied to\ncorpus-linguistic analyses of Latin, a language with highly diverse\ninflections.\n","authors":["Hiroyuki Deguchi","Go Kamoda","Yusuke Matsushita","Chihiro Taguchi","Kohei Suenaga","Masaki Waga","Sho Yokoi"],"pdf_url":"https://arxiv.org/pdf/2503.03703v1.pdf","comment":"Accepted at ICLR2025"},{"id":"http://arxiv.org/abs/2503.03702v1","updated":"2025-03-05T17:53:07Z","published":"2025-03-05T17:53:07Z","title":"Developing and Utilizing a Large-Scale Cantonese Dataset for\n  Multi-Tasking in Large Language Models","summary":"  High-quality data resources play a crucial role in learning large language\nmodels (LLMs), particularly for low-resource languages like Cantonese. Despite\nhaving more than 85 million native speakers, Cantonese is still considered a\nlow-resource language in the field of natural language processing (NLP) due to\nfactors such as the dominance of Mandarin, lack of cohesion within the\nCantonese-speaking community, diversity in character encoding and input\nmethods, and the tendency of overseas Cantonese speakers to prefer using\nEnglish. In addition, rich colloquial vocabulary of Cantonese, English\nloanwords, and code-switching characteristics add to the complexity of corpus\ncollection and processing. To address these challenges, we collect Cantonese\ntexts from a variety of sources, including open source corpora, Hong\nKong-specific forums, Wikipedia, and Common Crawl data. We conduct rigorous\ndata processing through language filtering, quality filtering, content\nfiltering, and de-duplication steps, successfully constructing a high-quality\nCantonese corpus of over 2 billion tokens for training large language models.\nWe further refined the model through supervised fine-tuning (SFT) on curated\nCantonese tasks, enhancing its ability to handle specific applications. Upon\ncompletion of the training, the model achieves state-of-the-art (SOTA)\nperformance on four Cantonese benchmarks. After training on our dataset, the\nmodel also exhibits improved performance on other mainstream language tasks.\n","authors":["Jiyue Jiang","Alfred Kar Yin Truong","Yanyu Chen","Qinghang Bao","Sheng Wang","Pengan Chen","Jiuming Wang","Lingpeng Kong","Yu Li","Chuan Wu"],"pdf_url":"https://arxiv.org/pdf/2503.03702v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.08143v2","updated":"2025-03-05T17:50:44Z","published":"2024-10-10T17:30:09Z","title":"DelTA: An Online Document-Level Translation Agent Based on Multi-Level\n  Memory","summary":"  Large language models (LLMs) have achieved reasonable quality improvements in\nmachine translation (MT). However, most current research on MT-LLMs still faces\nsignificant challenges in maintaining translation consistency and accuracy when\nprocessing entire documents. In this paper, we introduce DelTA, a\nDocument-levEL Translation Agent designed to overcome these limitations. DelTA\nfeatures a multi-level memory structure that stores information across various\ngranularities and spans, including Proper Noun Records, Bilingual Summary,\nLong-Term Memory, and Short-Term Memory, which are continuously retrieved and\nupdated by auxiliary LLM-based components. Experimental results indicate that\nDelTA significantly outperforms strong baselines in terms of translation\nconsistency and quality across four open/closed-source LLMs and two\nrepresentative document translation datasets, achieving an increase in\nconsistency scores by up to 4.58 percentage points and in COMET scores by up to\n3.16 points on average. DelTA employs a sentence-by-sentence translation\nstrategy, ensuring no sentence omissions and offering a memory-efficient\nsolution compared to the mainstream method. Furthermore, DelTA improves pronoun\nand context-dependent translation accuracy, and the summary component of the\nagent also shows promise as a tool for query-based summarization tasks. The\ncode and data of our approach are released at\nhttps://github.com/YutongWang1216/DocMTAgent.\n","authors":["Yutong Wang","Jiali Zeng","Xuebo Liu","Derek F. Wong","Fandong Meng","Jie Zhou","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.08143v2.pdf","comment":"Accepted as a conference paper at ICLR 2025"},{"id":"http://arxiv.org/abs/2503.03686v1","updated":"2025-03-05T17:27:59Z","published":"2025-03-05T17:27:59Z","title":"MAS-GPT: Training LLMs to Build LLM-based Multi-Agent Systems","summary":"  LLM-based multi-agent systems (MAS) have shown significant potential in\ntackling diverse tasks. However, to design effective MAS, existing approaches\nheavily rely on manual configurations or multiple calls of advanced LLMs,\nresulting in inadaptability and high inference costs. In this paper, we\nsimplify the process of building an MAS by reframing it as a generative\nlanguage task, where the input is a user query and the output is a\ncorresponding MAS. To address this novel task, we unify the representation of\nMAS as executable code and propose a consistency-oriented data construction\npipeline to create a high-quality dataset comprising coherent and consistent\nquery-MAS pairs. Using this dataset, we train MAS-GPT, an open-source\nmedium-sized LLM that is capable of generating query-adaptive MAS within a\nsingle LLM inference. The generated MAS can be seamlessly applied to process\nuser queries and deliver high-quality responses. Extensive experiments on 9\nbenchmarks and 5 LLMs show that the proposed MAS-GPT consistently outperforms\n10+ baseline MAS methods on diverse settings, indicating MAS-GPT's high\neffectiveness, efficiency and strong generalization ability. Code will be\navailable at https://github.com/rui-ye/MAS-GPT.\n","authors":["Rui Ye","Shuo Tang","Rui Ge","Yaxin Du","Zhenfei Yin","Siheng Chen","Jing Shao"],"pdf_url":"https://arxiv.org/pdf/2503.03686v1.pdf","comment":"26 pages, 7 figures"},{"id":"http://arxiv.org/abs/2502.01777v2","updated":"2025-03-05T17:25:07Z","published":"2025-02-03T19:29:42Z","title":"CTC-DRO: Robust Optimization for Reducing Language Disparities in Speech\n  Recognition","summary":"  Modern deep learning models often achieve high overall performance, but\nconsistently fail on specific subgroups. Group distributionally robust\noptimization (group DRO) addresses this problem by minimizing the worst-group\nloss, but it fails when group losses misrepresent performance differences\nbetween groups. This is common in domains like speech, where the widely used\nconnectionist temporal classification (CTC) loss scales with input length and\nvaries with linguistic and acoustic properties, leading to spurious differences\nbetween group losses. We present CTC-DRO, which addresses the shortcomings of\nthe group DRO objective by smoothing the group weight update to prevent\noveremphasis on consistently high-loss groups, while using input length-matched\nbatching to mitigate CTC's scaling issues. We evaluate CTC-DRO on the task of\nmultilingual automatic speech recognition (ASR) across five language sets from\nthe ML-SUPERB 2.0 benchmark. CTC-DRO consistently outperforms group DRO and\nCTC-based baseline models, reducing the worst-language error by up to 47.1% and\nthe average error by up to 32.9%. CTC-DRO can be applied to ASR with minimal\ncomputational costs, and offers the potential for reducing group disparities in\nother domains with similar challenges.\n","authors":["Martijn Bartelds","Ananjan Nandi","Moussa Koulako Bala Doumbouya","Dan Jurafsky","Tatsunori Hashimoto","Karen Livescu"],"pdf_url":"https://arxiv.org/pdf/2502.01777v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03681v1","updated":"2025-03-05T17:22:33Z","published":"2025-03-05T17:22:33Z","title":"Quantification of Tenseness in English and Japanese Tense-Lax Vowels: A\n  Lagrangian Model with Indicator $θ_1$ and Force of Tenseness Ftense(t)","summary":"  The concept of vowel tenseness has traditionally been examined through the\nbinary distinction of tense and lax vowels. However, no universally accepted\nquantitative definition of tenseness has been established in any language.\nPrevious studies, including those by Jakobson, Fant, and Halle (1951) and\nChomsky and Halle (1968), have explored the relationship between vowel\ntenseness and the vocal tract. Building on these foundations, Ishizaki (2019,\n2022) proposed an indirect quantification of vowel tenseness using formant\nangles $\\theta_1$ and $\\theta_{F1}$ and their first and second derivatives,\n$d^Z_1(t)/dt = \\lim \\tan \\theta_1(t$) and $d^2 Z_1(t)/dt^2 = d/dt \\lim \\tan\n\\theta_1(t)$. This study extends this approach by investigating the potential\nrole of a force-related parameter in determining vowel quality. Specifically,\nwe introduce a simplified model based on the Lagrangian equation to describe\nthe dynamic interaction of the tongue and jaw within the oral cavity during the\narticulation of close vowels. This model provides a theoretical framework for\nestimating the forces involved in vowel production across different languages,\noffering new insights into the physical mechanisms underlying vowel\narticulation. The findings suggest that this force-based perspective warrants\nfurther exploration as a key factor in phonetic and phonological studies.\n","authors":["Tatsuya Ishizaki"],"pdf_url":"https://arxiv.org/pdf/2503.03681v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03669v1","updated":"2025-03-05T17:03:48Z","published":"2025-03-05T17:03:48Z","title":"Attentive Reasoning Queries: A Systematic Method for Optimizing\n  Instruction-Following in Large Language Models","summary":"  We present Attentive Reasoning Queries (ARQs), a novel structured reasoning\napproach that significantly improves instruction-following in Large Language\nModels through domain-specialized reasoning blueprints. While LLMs demonstrate\nremarkable capabilities across diverse tasks, they often fail to maintain\nadherence to complex, use-case-specific instructions during multi-turn\nconversations, presenting challenges for business-critical applications. ARQs\naddress this limitation by guiding LLMs through systematic reasoning steps with\ntargeted queries that reinstate critical instructions and facilitate\nintermediate reasoning throughout the completion process. In extensive testing\nwithin Parlant, our framework for reliable customer-facing agents in which ARQs\nwere born out of necessity, they achieved a 90.2% success rate across 87 test\nscenarios, outperforming both Chain-of-Thought reasoning (86.1%) and direct\nresponse generation (81.5%). ARQs showed particular strength in addressing\npersistent failure modes like guideline re-application and hallucination\nprevention. Our analysis also revealed that ARQs can potentially be more\ncomputationally efficient than free-form reasoning when carefully designed.\nThese findings demonstrate that structured reasoning approaches provide\neffective mechanisms for controlling how LLMs process information and make\ndecisions in complex scenarios.\n","authors":["Bar Karov","Dor Zohar","Yam Marcovitz"],"pdf_url":"https://arxiv.org/pdf/2503.03669v1.pdf","comment":"Supplementary materials, including code, is available on our GitHub:\n  https://github.com/emcie-co/parlant/tree/arqs-a-systematic-method-for-optimizing-instruction-following-in-llms"},{"id":"http://arxiv.org/abs/2503.03666v1","updated":"2025-03-05T16:59:08Z","published":"2025-03-05T16:59:08Z","title":"Analogical Reasoning Inside Large Language Models: Concept Vectors and\n  the Limits of Abstraction","summary":"  Analogical reasoning relies on conceptual abstractions, but it is unclear\nwhether Large Language Models (LLMs) harbor such internal representations. We\nexplore distilled representations from LLM activations and find that function\nvectors (FVs; Todd et al., 2024) - compact representations for in-context\nlearning (ICL) tasks - are not invariant to simple input changes (e.g.,\nopen-ended vs. multiple-choice), suggesting they capture more than pure\nconcepts. Using representational similarity analysis (RSA), we localize a small\nset of attention heads that encode invariant concept vectors (CVs) for verbal\nconcepts like \"antonym\". These CVs function as feature detectors that operate\nindependently of the final output - meaning that a model may form a correct\ninternal representation yet still produce an incorrect output. Furthermore, CVs\ncan be used to causally guide model behaviour. However, for more abstract\nconcepts like \"previous\" and \"next\", we do not observe invariant linear\nrepresentations, a finding we link to generalizability issues LLMs display\nwithin these domains.\n","authors":["Gustaw Opiełka","Hannes Rosenbusch","Claire E. Stevenson"],"pdf_url":"https://arxiv.org/pdf/2503.03666v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2409.07402v2","updated":"2025-03-05T16:48:23Z","published":"2024-09-11T16:42:22Z","title":"What to align in multimodal contrastive learning?","summary":"  Humans perceive the world through multisensory integration, blending the\ninformation of different modalities to adapt their behavior. Contrastive\nlearning offers an appealing solution for multimodal self-supervised learning.\nIndeed, by considering each modality as a different view of the same entity, it\nlearns to align features of different modalities in a shared representation\nspace. However, this approach is intrinsically limited as it only learns shared\nor redundant information between modalities, while multimodal interactions can\narise in other ways. In this work, we introduce CoMM, a Contrastive MultiModal\nlearning strategy that enables the communication between modalities in a single\nmultimodal space. Instead of imposing cross- or intra- modality constraints, we\npropose to align multimodal representations by maximizing the mutual\ninformation between augmented versions of these multimodal features. Our\ntheoretical analysis shows that shared, synergistic and unique terms of\ninformation naturally emerge from this formulation, allowing us to estimate\nmultimodal interactions beyond redundancy. We test CoMM both in a controlled\nand in a series of real-world settings: in the former, we demonstrate that CoMM\neffectively captures redundant, unique and synergistic information between\nmodalities. In the latter, CoMM learns complex multimodal interactions and\nachieves state-of-the-art results on the seven multimodal benchmarks. Code is\navailable at https://github.com/Duplums/CoMM\n","authors":["Benoit Dufumier","Javiera Castillo-Navarro","Devis Tuia","Jean-Philippe Thiran"],"pdf_url":"https://arxiv.org/pdf/2409.07402v2.pdf","comment":"ICLR 2025, 25 pages"},{"id":"http://arxiv.org/abs/2411.00816v2","updated":"2025-03-05T16:36:05Z","published":"2024-10-28T08:10:21Z","title":"CycleResearcher: Improving Automated Research via Automated Review","summary":"  The automation of scientific discovery has been a long-standing goal within\nthe research community, driven by the potential to accelerate knowledge\ncreation. While significant progress has been made using commercial large\nlanguage models (LLMs) as research assistants or idea generators, the\npossibility of automating the entire research process with open-source LLMs\nremains largely unexplored. This paper explores the feasibility of using\nopen-source post-trained LLMs as autonomous agents capable of performing the\nfull cycle of automated research and review, from literature review and\nmanuscript preparation to peer review and paper refinement. Our iterative\npreference training framework consists of CycleResearcher, which conducts\nresearch tasks, and CycleReviewer, which simulates the peer review process,\nproviding iterative feedback via reinforcement learning. To train these models,\nwe develop two new datasets, Review-5k and Research-14k, reflecting real-world\nmachine learning research and peer review dynamics. Our results demonstrate\nthat CycleReviewer achieves promising performance with a 26.89\\% reduction in\nmean absolute error (MAE) compared to individual human reviewers in predicting\npaper scores, indicating the potential of LLMs to effectively assist\nexpert-level research evaluation. In research, the papers generated by the\nCycleResearcher model achieved a score of 5.36 in simulated peer reviews,\nshowing some competitiveness in terms of simulated review scores compared to\nthe preprint level of 5.24 from human experts, while still having room for\nimprovement compared to the accepted paper level of 5.69. This work represents\na significant step toward fully automated scientific inquiry, providing ethical\nsafeguards and exploring AI-driven research capabilities. The code, dataset and\nmodel weight are released at https://wengsyx.github.io/Researcher/\n","authors":["Yixuan Weng","Minjun Zhu","Guangsheng Bao","Hongbo Zhang","Jindong Wang","Yue Zhang","Linyi Yang"],"pdf_url":"https://arxiv.org/pdf/2411.00816v2.pdf","comment":"Accept in ICLR 2025"},{"id":"http://arxiv.org/abs/2503.03654v1","updated":"2025-03-05T16:32:47Z","published":"2025-03-05T16:32:47Z","title":"Improving Neutral Point of View Text Generation through\n  Parameter-Efficient Reinforcement Learning and a Small-Scale High-Quality\n  Dataset","summary":"  This paper describes the construction of a dataset and the evaluation of\ntraining methods to improve generative large language models' (LLMs) ability to\nanswer queries on sensitive topics with a Neutral Point of View (NPOV), i.e.,\nto provide significantly more informative, diverse and impartial answers. The\ndataset, the SHQ-NPOV dataset, comprises 300 high-quality, human-written\nquadruplets: a query on a sensitive topic, an answer, an NPOV rating, and a set\nof links to source texts elaborating the various points of view. The first key\ncontribution of this paper is a new methodology to create such datasets through\niterative rounds of human peer-critique and annotator training, which we\nrelease alongside the dataset. The second key contribution is the\nidentification of a highly effective training regime for parameter-efficient\nreinforcement learning (PE-RL) to improve NPOV generation. We compare and\nextensively evaluate PE-RL and multiple baselines-including LoRA finetuning (a\nstrong baseline), SFT and RLHF.\n  PE-RL not only improves on overall NPOV quality compared to the strongest\nbaseline ($97.06\\%\\rightarrow 99.08\\%$), but also scores much higher on\nfeatures linguists identify as key to separating good answers from the best\nanswers ($60.25\\%\\rightarrow 85.21\\%$ for presence of supportive details,\n$68.74\\%\\rightarrow 91.43\\%$ for absence of oversimplification). A qualitative\nanalysis corroborates this. Finally, our evaluation finds no statistical\ndifferences between results on topics that appear in the training dataset and\nthose on separated evaluation topics, which provides strong evidence that our\napproach to training PE-RL exhibits very effective out of topic generalization.\n","authors":["Jessica Hoffmann","Christiane Ahlheim","Zac Yu","Aria Walfrand","Jarvis Jin","Marie Tano","Ahmad Beirami","Erin van Liemt","Nithum Thain","Hakim Sidahmed","Lucas Dixon"],"pdf_url":"https://arxiv.org/pdf/2503.03654v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20581v2","updated":"2025-03-05T16:32:35Z","published":"2025-02-27T22:47:03Z","title":"The Noisy Path from Source to Citation: Measuring How Scholars Engage\n  with Past Research","summary":"  Academic citations are widely used for evaluating research and tracing\nknowledge flows. Such uses typically rely on raw citation counts and neglect\nvariability in citation types. In particular, citations can vary in their\nfidelity as original knowledge from cited studies may be paraphrased,\nsummarized, or reinterpreted, possibly wrongly, leading to variation in how\nmuch information changes from cited to citing paper. In this study, we\nintroduce a computational pipeline to quantify citation fidelity at scale.\nUsing full texts of papers, the pipeline identifies citations in citing papers\nand the corresponding claims in cited papers, and applies supervised models to\nmeasure fidelity at the sentence level. Analyzing a large-scale\nmulti-disciplinary dataset of approximately 13 million citation sentence pairs,\nwe find that citation fidelity is higher when authors cite papers that are 1)\nmore recent and intellectually close, 2) more accessible, and 3) the first\nauthor has a lower H-index and the author team is medium-sized. Using a\nquasi-experiment, we establish the \"telephone effect\" - when citing papers have\nlow fidelity to the original claim, future papers that cite the citing paper\nand the original have lower fidelity to the original. Our work reveals\nsystematic differences in citation fidelity, underscoring the limitations of\nanalyses that rely on citation quantity alone and the potential for distortion\nof evidence.\n","authors":["Hong Chen","Misha Teplitskiy","David Jurgens"],"pdf_url":"https://arxiv.org/pdf/2502.20581v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.01863v2","updated":"2025-03-05T16:27:57Z","published":"2024-06-04T00:30:37Z","title":"Towards Effective Time-Aware Language Representation: Exploring Enhanced\n  Temporal Understanding in Language Models","summary":"  In the evolving field of Natural Language Processing (NLP), understanding the\ntemporal context of text is increasingly critical for applications requiring\nadvanced temporal reasoning. Traditional pre-trained language models like BERT,\nwhich rely on synchronic document collections such as BookCorpus and Wikipedia,\noften fall short in effectively capturing and leveraging temporal information.\nTo address this limitation, we introduce BiTimeBERT 2.0, a novel time-aware\nlanguage model pre-trained on a temporal news article collection. BiTimeBERT\n2.0 incorporates temporal information through three innovative pre-training\nobjectives: Extended Time-Aware Masked Language Modeling (ETAMLM), Document\nDating (DD), and Time-Sensitive Entity Replacement (TSER). Each objective is\nspecifically designed to target a distinct dimension of temporal information:\nETAMLM enhances the model's understanding of temporal contexts and relations,\nDD integrates document timestamps as explicit chronological markers, and TSER\nfocuses on the temporal dynamics of \"Person\" entities. Moreover, our refined\ncorpus preprocessing strategy reduces training time by nearly 53\\%, making\nBiTimeBERT 2.0 significantly more efficient while maintaining high performance.\nExperimental results show that BiTimeBERT 2.0 achieves substantial improvements\nacross a broad range of time-related tasks and excels on datasets spanning\nextensive temporal ranges. These findings underscore BiTimeBERT 2.0's potential\nas a powerful tool for advancing temporal reasoning in NLP.\n","authors":["Jiexin Wang","Adam Jatowt","Yi Cai"],"pdf_url":"https://arxiv.org/pdf/2406.01863v2.pdf","comment":"This paper has been accepted for publication in ACM Transactions on\n  the Web. Final publication details (volume, issue, page range) will be\n  updated once they are finalized"},{"id":"http://arxiv.org/abs/2503.03652v1","updated":"2025-03-05T16:27:25Z","published":"2025-03-05T16:27:25Z","title":"Token-Level Privacy in Large Language Models","summary":"  The use of language models as remote services requires transmitting private\ninformation to external providers, raising significant privacy concerns. This\nprocess not only risks exposing sensitive data to untrusted service providers\nbut also leaves it vulnerable to interception by eavesdroppers. Existing\nprivacy-preserving methods for natural language processing (NLP) interactions\nprimarily rely on semantic similarity, overlooking the role of contextual\ninformation. In this work, we introduce dchi-stencil, a novel token-level\nprivacy-preserving mechanism that integrates contextual and semantic\ninformation while ensuring strong privacy guarantees under the dchi\ndifferential privacy framework, achieving 2epsilon-dchi-privacy. By\nincorporating both semantic and contextual nuances, dchi-stencil achieves a\nrobust balance between privacy and utility. We evaluate dchi-stencil using\nstate-of-the-art language models and diverse datasets, achieving comparable and\neven better trade-off between utility and privacy compared to existing methods.\nThis work highlights the potential of dchi-stencil to set a new standard for\nprivacy-preserving NLP in modern, high-risk applications.\n","authors":["Re'em Harel","Niv Gilboa","Yuval Pinter"],"pdf_url":"https://arxiv.org/pdf/2503.03652v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02865v2","updated":"2025-03-05T16:24:43Z","published":"2025-03-04T18:43:57Z","title":"FairSense-AI: Responsible AI Meets Sustainability","summary":"  In this paper, we introduce FairSense-AI: a multimodal framework designed to\ndetect and mitigate bias in both text and images. By leveraging Large Language\nModels (LLMs) and Vision-Language Models (VLMs), FairSense-AI uncovers subtle\nforms of prejudice or stereotyping that can appear in content, providing users\nwith bias scores, explanatory highlights, and automated recommendations for\nfairness enhancements. In addition, FairSense-AI integrates an AI risk\nassessment component that aligns with frameworks like the MIT AI Risk\nRepository and NIST AI Risk Management Framework, enabling structured\nidentification of ethical and safety concerns. The platform is optimized for\nenergy efficiency via techniques such as model pruning and mixed-precision\ncomputation, thereby reducing its environmental footprint. Through a series of\ncase studies and applications, we demonstrate how FairSense-AI promotes\nresponsible AI use by addressing both the social dimension of fairness and the\npressing need for sustainability in large-scale AI deployments.\nhttps://vectorinstitute.github.io/FairSense-AI,\nhttps://pypi.org/project/fair-sense-ai/ (Sustainability , Responsible AI ,\nLarge Language Models , Vision Language Models , Ethical AI , Green AI)\n","authors":["Shaina Raza","Mukund Sayeeganesh Chettiar","Matin Yousefabadi","Tahniat Khan","Marcelo Lotif"],"pdf_url":"https://arxiv.org/pdf/2503.02865v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03645v1","updated":"2025-03-05T16:23:15Z","published":"2025-03-05T16:23:15Z","title":"Psy-Copilot: Visual Chain of Thought for Counseling","summary":"  Large language models (LLMs) are becoming increasingly popular in the field\nof psychological counseling. However, when human therapists work with LLMs in\ntherapy sessions, it is hard to understand how the model gives the answers. To\naddress this, we have constructed Psy-COT, a graph designed to visualize the\nthought processes of LLMs during therapy sessions. The Psy-COT graph presents\nsemi-structured counseling conversations alongside step-by-step annotations\nthat capture the reasoning and insights of therapists. Moreover, we have\ndeveloped Psy-Copilot, which is a conversational AI assistant designed to\nassist human psychological therapists in their consultations. It can offer\ntraceable psycho-information based on retrieval, including response candidates,\nsimilar dialogue sessions, related strategies, and visual traces of results. We\nhave also built an interactive platform for AI-assisted counseling. It has an\ninterface that displays the relevant parts of the retrieval sub-graph. The\nPsy-Copilot is designed not to replace psychotherapists but to foster\ncollaboration between AI and human therapists, thereby promoting mental health\ndevelopment. Our code and demo are both open-sourced and available for use.\n","authors":["Keqi Chen","Zekai Sun","Huijun Lian","Yingming Gao","Ya Li"],"pdf_url":"https://arxiv.org/pdf/2503.03645v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02102v2","updated":"2025-03-05T16:18:33Z","published":"2025-03-03T22:37:03Z","title":"Provable Benefits of Task-Specific Prompts for In-context Learning","summary":"  The in-context learning capabilities of modern language models have motivated\na deeper mathematical understanding of sequence models. A line of recent work\nhas shown that linear attention models can emulate projected gradient descent\niterations to implicitly learn the task vector from the data provided in the\ncontext window. In this work, we consider a novel setting where the global task\ndistribution can be partitioned into a union of conditional task distributions.\nWe then examine the use of task-specific prompts and prediction heads for\nlearning the prior information associated with the conditional task\ndistribution using a one-layer attention model. Our results on loss landscape\nshow that task-specific prompts facilitate a covariance-mean decoupling where\nprompt-tuning explains the conditional mean of the distribution whereas the\nvariance is learned/explained through in-context learning. Incorporating\ntask-specific head further aids this process by entirely decoupling estimation\nof mean and variance components. This covariance-mean perspective similarly\nexplains how jointly training prompt and attention weights can provably help\nover fine-tuning after pretraining.\n","authors":["Xiangyu Chang","Yingcong Li","Muti Kara","Samet Oymak","Amit K. Roy-Chowdhury"],"pdf_url":"https://arxiv.org/pdf/2503.02102v2.pdf","comment":"Proceedings of the 28th International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2025"},{"id":"http://arxiv.org/abs/2410.12893v2","updated":"2025-03-05T16:16:01Z","published":"2024-10-16T12:24:42Z","title":"MIRROR: A Novel Approach for the Automated Evaluation of Open-Ended\n  Question Generation","summary":"  Automatic question generation is a critical task that involves evaluating\nquestion quality by considering factors such as engagement, pedagogical value,\nand the ability to stimulate critical thinking. These aspects require\nhuman-like understanding and judgment, which automated systems currently lack.\nHowever, human evaluations are costly and impractical for large-scale samples\nof generated questions. Therefore, we propose a novel system, MIRROR (Multi-LLM\nIterative Review and Response for Optimized Rating), which leverages large\nlanguage models (LLMs) to automate the evaluation process for questions\ngenerated by automated question generation systems. We experimented with\nseveral state-of-the-art LLMs, such as GPT-4, Gemini, and Llama2-70b. We\nobserved that the scores of human evaluation metrics, namely relevance,\nappropriateness, novelty, complexity, and grammaticality, improved when using\nthe feedback-based approach called MIRROR, tending to be closer to the human\nbaseline scores. Furthermore, we observed that Pearson's correlation\ncoefficient between GPT-4 and human experts improved when using our proposed\nfeedback-based approach, MIRROR, compared to direct prompting for evaluation.\nError analysis shows that our proposed approach, MIRROR, significantly helps to\nimprove relevance and appropriateness.\n","authors":["Aniket Deroy","Subhankar Maity","Sudeshna Sarkar"],"pdf_url":"https://arxiv.org/pdf/2410.12893v2.pdf","comment":"NeurIPS'24 Workshop on Large Foundation Models for Educational\n  Assessment (FM-EduAssess)"},{"id":"http://arxiv.org/abs/2502.09647v2","updated":"2025-03-05T16:14:16Z","published":"2025-02-11T00:04:32Z","title":"Unveiling Simplicities of Attention: Adaptive Long-Context Head\n  Identification","summary":"  The ability to process long contexts is crucial for many natural language\nprocessing tasks, yet it remains a significant challenge. While substantial\nprogress has been made in enhancing the efficiency of attention mechanisms,\nthere is still a gap in understanding how attention heads function in\nlong-context settings. In this paper, we observe that while certain heads\nconsistently attend to local information only, others swing between attending\nto local and long-context information depending on the query. This raises the\nquestion: can we identify which heads require long-context information to\npredict the next token accurately? We demonstrate that it's possible to predict\nwhich heads are crucial for long-context processing using only local keys. The\ncore idea here is to exploit a simple model for the long-context scores via\nsecond moment approximations. These findings unveil simple properties of\nattention in the context of long sequences, and open the door to potentially\nsignificant gains in efficiency.\n","authors":["Konstantin Donhauser","Charles Arnal","Mohammad Pezeshki","Vivien Cabannes","David Lopez-Paz","Kartik Ahuja"],"pdf_url":"https://arxiv.org/pdf/2502.09647v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.08642v2","updated":"2025-03-05T15:55:52Z","published":"2024-10-11T09:10:26Z","title":"More than Memes: A Multimodal Topic Modeling Approach to Conspiracy\n  Theories on Telegram","summary":"  To address the increasing prevalence of (audio-)visual data on social media,\nand to capture the evolving and dynamic nature of this communication,\nresearchers have begun to explore the potential of unsupervised approaches for\nanalyzing multimodal online content. However, existing research often neglects\nvisual content beyond memes, and in addition lacks methods to compare topic\nmodels across modalities. Our study addresses these gaps by applying multimodal\ntopic modeling for analyzing conspiracy theories in German-language Telegram\nchannels. We use BERTopic with CLIP for the analysis of textual and visual data\nin a corpus of ~40, 000 Telegram messages posted in October 2023 in 571\nGerman-language Telegram channels known for disseminating conspiracy theories.\nThrough this dataset, we provide insights into unimodal and multimodal topic\nmodels by analyzing symmetry and intersections of topics across modalities. We\ndemonstrate the variety of textual and visual content shared in the channels\ndiscovered through the topic modeling, and propose a conceptual framework for\nthe analysis of textual and visual discursive strategies in the communication\nof conspiracy theories. We apply the framework in a case study of the topic\ngroup Israel Gaza.\n","authors":["Elisabeth Steffen"],"pdf_url":"https://arxiv.org/pdf/2410.08642v2.pdf","comment":"12 pages, 10 figures"},{"id":"http://arxiv.org/abs/2411.07527v2","updated":"2025-03-05T15:52:25Z","published":"2024-11-12T03:55:27Z","title":"Prompt-enhanced Network for Hateful Meme Classification","summary":"  The dynamic expansion of social media has led to an inundation of hateful\nmemes on media platforms, accentuating the growing need for efficient\nidentification and removal. Acknowledging the constraints of conventional\nmultimodal hateful meme classification, which heavily depends on external\nknowledge and poses the risk of including irrelevant or redundant content, we\ndeveloped Pen -- a prompt-enhanced network framework based on the prompt\nlearning approach. Specifically, after constructing the sequence through the\nprompt method and encoding it with a language model, we performed region\ninformation global extraction on the encoded sequence for multi-view\nperception. By capturing global information about inference instances and\ndemonstrations, Pen facilitates category selection by fully leveraging sequence\ninformation. This approach significantly improves model classification\naccuracy. Additionally, to bolster the model's reasoning capabilities in the\nfeature space, we introduced prompt-aware contrastive learning into the\nframework to improve the quality of sample feature distributions. Through\nextensive ablation experiments on two public datasets, we evaluate the\neffectiveness of the Pen framework, concurrently comparing it with\nstate-of-the-art model baselines. Our research findings highlight that Pen\nsurpasses manual prompt methods, showcasing superior generalization and\nclassification accuracy in hateful meme classification tasks. Our code is\navailable at https://github.com/juszzi/Pen.\n","authors":["Junxi Liu","Yanyan Feng","Jiehai Chen","Yun Xue","Fenghuan Li"],"pdf_url":"https://arxiv.org/pdf/2411.07527v2.pdf","comment":"Published in Proceedings of the Thirty-Third International Joint\n  Conference on Artificial Intelligence Main Track. Pages 6397-6405"},{"id":"http://arxiv.org/abs/2503.03607v1","updated":"2025-03-05T15:44:21Z","published":"2025-03-05T15:44:21Z","title":"Psy-Insight: Explainable Multi-turn Bilingual Dataset for Mental Health\n  Counseling","summary":"  The in-context learning capabilities of large language models (LLMs) show\ngreat potential in mental health support. However, the lack of counseling\ndatasets, particularly in Chinese corpora, restricts their application in this\nfield. To address this, we constructed Psy-Insight, the first mental\nhealth-oriented explainable multi-task bilingual dataset. We collected\nface-to-face multi-turn counseling dialogues, which are annotated with\nmulti-task labels and conversation process explanations. Our annotations\ninclude psychotherapy, emotion, strategy, and topic labels, as well as\nturn-level reasoning and session-level guidance. Psy-Insight is not only\nsuitable for tasks such as label recognition but also meets the need for\ntraining LLMs to act as empathetic counselors through logical reasoning.\nExperiments show that training LLMs on Psy-Insight enables the models to not\nonly mimic the conversation style but also understand the underlying strategies\nand reasoning of counseling.\n","authors":["Keqi Chen","Zekai Sun","Yuhua Wen","Huijun Lian","Yingming Gao","Ya Li"],"pdf_url":"https://arxiv.org/pdf/2503.03607v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03601v1","updated":"2025-03-05T15:33:52Z","published":"2025-03-05T15:33:52Z","title":"Feature-Level Insights into Artificial Text Detection with Sparse\n  Autoencoders","summary":"  Artificial Text Detection (ATD) is becoming increasingly important with the\nrise of advanced Large Language Models (LLMs). Despite numerous efforts, no\nsingle algorithm performs consistently well across different types of unseen\ntext or guarantees effective generalization to new LLMs. Interpretability plays\na crucial role in achieving this goal. In this study, we enhance ATD\ninterpretability by using Sparse Autoencoders (SAE) to extract features from\nGemma-2-2b residual stream. We identify both interpretable and efficient\nfeatures, analyzing their semantics and relevance through domain- and\nmodel-specific statistics, a steering approach, and manual or LLM-based\ninterpretation. Our methods offer valuable insights into how texts from various\nmodels differ from human-written content. We show that modern LLMs have a\ndistinct writing style, especially in information-dense domains, even though\nthey can produce human-like outputs with personalized prompts.\n","authors":["Kristian Kuznetsov","Laida Kushnareva","Polina Druzhinina","Anton Razzhigaev","Anastasia Voznyuk","Irina Piontkovskaya","Evgeny Burnaev","Serguei Barannikov"],"pdf_url":"https://arxiv.org/pdf/2503.03601v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03594v1","updated":"2025-03-05T15:27:36Z","published":"2025-03-05T15:27:36Z","title":"Small but Mighty: Enhancing Time Series Forecasting with Lightweight\n  LLMs","summary":"  While LLMs have demonstrated remarkable potential in time series forecasting,\ntheir practical deployment remains constrained by excessive computational\ndemands and memory footprints. Existing LLM-based approaches typically suffer\nfrom three critical limitations: Inefficient parameter utilization in handling\nnumerical time series patterns; Modality misalignment between continuous\ntemporal signals and discrete text embeddings; and Inflexibility for real-time\nexpert knowledge integration. We present SMETimes, the first systematic\ninvestigation of sub-3B parameter SLMs for efficient and accurate time series\nforecasting. Our approach centers on three key innovations: A\nstatistically-enhanced prompting mechanism that bridges numerical time series\nwith textual semantics through descriptive statistical features; A adaptive\nfusion embedding architecture that aligns temporal patterns with language model\ntoken spaces through learnable parameters; And a dynamic mixture-of-experts\nframework enabled by SLMs' computational efficiency, adaptively combining base\npredictions with domain-specific models. Extensive evaluations across seven\nbenchmark datasets demonstrate that our 3B-parameter SLM achieves\nstate-of-the-art performance on five primary datasets while maintaining 3.8x\nfaster training and 5.2x lower memory consumption compared to 7B-parameter LLM\nbaselines. Notably, the proposed model exhibits better learning capabilities,\nachieving 12.3% lower MSE than conventional LLM. Ablation studies validate that\nour statistical prompting and cross-modal fusion modules respectively\ncontribute 15.7% and 18.2% error reduction in long-horizon forecasting tasks.\nBy redefining the efficiency-accuracy trade-off landscape, this work\nestablishes SLMs as viable alternatives to resource-intensive LLMs for\npractical time series forecasting. Code and models are available at\nhttps://github.com/xiyan1234567/SMETimes.\n","authors":["Haoran Fan","Bin Li","Yixuan Weng","Shoujun Zhou"],"pdf_url":"https://arxiv.org/pdf/2503.03594v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2503.03592v1","updated":"2025-03-05T15:26:59Z","published":"2025-03-05T15:26:59Z","title":"English K_Quantization of LLMs Does Not Disproportionately Diminish\n  Multilingual Performance","summary":"  For consumer usage of locally deployed LLMs, the GGUF format and\nk_quantization are invaluable tools for maintaining the performance of the\noriginal model while reducing it to sizes deployable with consumer-grade\nhardware. The number of bits dedicated to each weight from the original model\nis reduced based on how important they are thought to be during model\ninference. This importance is arrived at through the application of an\n'importance matrix'-a relatively small text document meant to be representative\nof the LLM's standard use-cases. In the vast majority of quants available\nonline, this document is primarily written in English. It was therefore an open\nquestion whether performance on English language tasks was preserved through\nthe sacrifice of multilingual performance and whether it can be preserved with\nalternate importance matrices. This article investigates these hypotheses by\nquantizing Llama3.3 70B on importance matrices written in three languages\n(English, Norwegian, and Malayalam) and evaluating them on the MixEval dataset\nin both English and Norwegian. All experiments related to k_quantization\nyielded non-significant results (In all cases p > 0.237) indicating that\ncurrent quantization practices do not disproportionately harm multilingual\nperformance.\n","authors":["Karl Audun Borgersen"],"pdf_url":"https://arxiv.org/pdf/2503.03592v1.pdf","comment":"8 pages, 6 figures"},{"id":"http://arxiv.org/abs/2501.16207v3","updated":"2025-03-05T15:26:49Z","published":"2025-01-27T17:00:56Z","title":"From Informal to Formal -- Incorporating and Evaluating LLMs on Natural\n  Language Requirements to Verifiable Formal Proofs","summary":"  The research in AI-based formal mathematical reasoning has shown an\nunstoppable growth trend. These studies have excelled in mathematical\ncompetitions like IMO and have made significant progress. This paper focuses on\nformal verification, an immediate application scenario of formal reasoning, and\nbreaks it down into sub-tasks. We constructed 18k high-quality\ninstruction-response pairs across five formal specification languages (Coq,\nLean4, Dafny, ACSL, and TLA+) by distilling gpt-4o and evaluated against ten\nopen-sourced LLMs, including recent popular DeepSeek-R1. We also fine-tuned\nseveral 7~8B small models to achieve comparable performance with\nDeepseek-R1-671B. Interestingly, we observed that fine-tuning with formal data\nalso enhances mathematics, reasoning, and coding capabilities. Fine-tuned\nmodels are released at https: //huggingface.co/fm-universe.\n","authors":["Jialun Cao","Yaojie Lu","Meiziniu Li","Haoyang Ma","Haokun Li","Mengda He","Cheng Wen","Le Sun","Hongyu Zhang","Shengchao Qin","Shing-Chi Cheung","Cong Tian"],"pdf_url":"https://arxiv.org/pdf/2501.16207v3.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2502.20503v2","updated":"2025-03-05T15:26:45Z","published":"2025-02-27T20:22:34Z","title":"Protecting multimodal large language models against misleading\n  visualizations","summary":"  We assess the vulnerability of multimodal large language models to misleading\nvisualizations - charts that distort the underlying data using techniques such\nas truncated or inverted axes, leading readers to draw inaccurate conclusions\nthat may support misinformation or conspiracy theories. Our analysis shows that\nthese distortions severely harm multimodal large language models, reducing\ntheir question-answering accuracy to the level of the random baseline. To\nmitigate this vulnerability, we introduce six inference-time methods to improve\nperformance of MLLMs on misleading visualizations while preserving their\naccuracy on non-misleading ones. The most effective approach involves (1)\nextracting the underlying data table and (2) using a text-only large language\nmodel to answer questions based on the table. This method improves performance\non misleading visualizations by 15.4 to 19.6 percentage points.\n","authors":["Jonathan Tonglet","Tinne Tuytelaars","Marie-Francine Moens","Iryna Gurevych"],"pdf_url":"https://arxiv.org/pdf/2502.20503v2.pdf","comment":"Preprint. Code and data available at\n  https://github.com/UKPLab/arxiv2025-misleading-visualizations"},{"id":"http://arxiv.org/abs/2503.03588v1","updated":"2025-03-05T15:24:11Z","published":"2025-03-05T15:24:11Z","title":"PowerAttention: Exponentially Scaling of Receptive Fields for Effective\n  Sparse Attention","summary":"  Large Language Models (LLMs) face efficiency bottlenecks due to the quadratic\ncomplexity of the attention mechanism when processing long contexts. Sparse\nattention methods offer a promising solution, but existing approaches often\nsuffer from incomplete effective context and/or require complex implementation\nof pipeline. We present a comprehensive analysis of sparse attention for\nautoregressive LLMs from the respective of receptive field, recognize the\nsuboptimal nature of existing methods for expanding the receptive field, and\nintroduce PowerAttention, a novel sparse attention design that facilitates\neffective and complete context extension through the theoretical analysis.\nPowerAttention achieves exponential receptive field growth in $d$-layer LLMs,\nallowing each output token to attend to $2^d$ tokens, ensuring completeness and\ncontinuity of the receptive field. Experiments demonstrate that PowerAttention\noutperforms existing static sparse attention methods by $5\\sim 40\\%$,\nespecially on tasks demanding long-range dependencies like Passkey Retrieval\nand RULER, while maintaining a comparable time complexity to sliding window\nattention. Efficiency evaluations further highlight PowerAttention's superior\nspeedup in both prefilling and decoding phases compared with dynamic sparse\nattentions and full attention ($3.0\\times$ faster on 128K context), making it a\nhighly effective and user-friendly solution for processing long sequences in\nLLMs.\n","authors":["Lida Chen","Dong Xu","Chenxin An","Xintao Wang","Yikai Zhang","Jiangjie Chen","Zujie Liang","Feng Wei","Jiaqing Liang","Yanghua Xiao","Wei Wang"],"pdf_url":"https://arxiv.org/pdf/2503.03588v1.pdf","comment":"for associated code, see https://github.com/w568w/PowerAttention"},{"id":"http://arxiv.org/abs/2503.02623v2","updated":"2025-03-05T15:23:16Z","published":"2025-03-04T13:48:50Z","title":"Rewarding Doubt: A Reinforcement Learning Approach to Confidence\n  Calibration of Large Language Models","summary":"  A safe and trustworthy use of Large Language Models (LLMs) requires an\naccurate expression of confidence in their answers. We introduce a novel\nReinforcement Learning (RL) approach for LLM calibration that fine-tunes LLMs\nto elicit calibrated confidence estimations in their answers to factual\nquestions. We model the problem as a betting game where the model predicts a\nconfidence score together with every answer, and design a reward function that\npenalizes both over and under-confidence. We prove that under our reward design\nan optimal policy would result in a perfectly calibrated confidence estimation.\nOur experiments demonstrate significantly improved confidence calibration and\ngeneralization to new tasks without re-training, indicating that our approach\nteaches a general confidence awareness. This approach enables the training of\ninherently calibrated LLMs.\n","authors":["Paul Stangel","David Bani-Harouni","Chantal Pellegrini","Ege Özsoy","Kamilia Zaripova","Matthias Keicher","Nassir Navab"],"pdf_url":"https://arxiv.org/pdf/2503.02623v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03582v1","updated":"2025-03-05T15:17:18Z","published":"2025-03-05T15:17:18Z","title":"Scaling Crowdsourced Election Monitoring: Construction and Evaluation of\n  Classification Models for Multilingual and Cross-Domain Classification\n  Settings","summary":"  The adoption of crowdsourced election monitoring as a complementary\nalternative to traditional election monitoring is on the rise. Yet, its\nreliance on digital response volunteers to manually process incoming election\nreports poses a significant scaling bottleneck. In this paper, we address the\nchallenge of scaling crowdsourced election monitoring by advancing the task of\nautomated classification of crowdsourced election reports to multilingual and\ncross-domain classification settings. We propose a two-step classification\napproach of first identifying informative reports and then categorising them\ninto distinct information types. We conduct classification experiments using\nmultilingual transformer models such as XLM-RoBERTa and multilingual embeddings\nsuch as SBERT, augmented with linguistically motivated features. Our approach\nachieves F1-Scores of 77\\% for informativeness detection and 75\\% for\ninformation type classification. We conduct cross-domain experiments, applying\nmodels trained in a source electoral domain to a new target electoral domain in\nzero-shot and few-shot classification settings. Our results show promising\npotential for model transfer across electoral domains, with F1-Scores of 59\\%\nin zero-shot and 63\\% in few-shot settings. However, our analysis also reveals\na performance bias in detecting informative English reports over Swahili,\nlikely due to imbalances in the training data, indicating a need for caution\nwhen deploying classification models in real-world election scenarios.\n","authors":["Jabez Magomere","Scott Hale"],"pdf_url":"https://arxiv.org/pdf/2503.03582v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.16205v5","updated":"2025-03-05T14:43:33Z","published":"2024-07-23T06:14:41Z","title":"LLMs can be Dangerous Reasoners: Analyzing-based Jailbreak Attack on\n  Large Language Models","summary":"  The rapid development of Large Language Models (LLMs) has brought significant\nadvancements across various tasks. However, despite these achievements, LLMs\nstill exhibit inherent safety vulnerabilities, especially when confronted with\njailbreak attacks. Existing jailbreak methods suffer from two main limitations:\nreliance on complicated prompt engineering and iterative optimization, which\nlead to low attack success rate (ASR) and attack efficiency (AE). In this work,\nwe propose an efficient jailbreak attack method, Analyzing-based Jailbreak\n(ABJ), which leverages the advanced reasoning capability of LLMs to\nautonomously generate harmful content, revealing their underlying safety\nvulnerabilities during complex reasoning process. We conduct comprehensive\nexperiments on ABJ across various open-source and closed-source LLMs. In\nparticular, ABJ achieves high ASR (82.1% on GPT-4o-2024-11-20) with exceptional\nAE among all target LLMs, showcasing its remarkable attack effectiveness,\ntransferability, and efficiency. Our findings underscore the urgent need to\nprioritize and improve the safety of LLMs to mitigate the risks of misuse.\n","authors":["Shi Lin","Hongming Yang","Dingyang Lin","Rongchang Li","Xun Wang","Changting Lin","Wenpeng Xing","Meng Han"],"pdf_url":"https://arxiv.org/pdf/2407.16205v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01742v2","updated":"2025-03-05T14:41:38Z","published":"2025-03-03T17:04:22Z","title":"Building Safe GenAI Applications: An End-to-End Overview of Red Teaming\n  for Large Language Models","summary":"  The rapid growth of Large Language Models (LLMs) presents significant\nprivacy, security, and ethical concerns. While much research has proposed\nmethods for defending LLM systems against misuse by malicious actors,\nresearchers have recently complemented these efforts with an offensive approach\nthat involves red teaming, i.e., proactively attacking LLMs with the purpose of\nidentifying their vulnerabilities. This paper provides a concise and practical\noverview of the LLM red teaming literature, structured so as to describe a\nmulti-component system end-to-end. To motivate red teaming we survey the\ninitial safety needs of some high-profile LLMs, and then dive into the\ndifferent components of a red teaming system as well as software packages for\nimplementing them. We cover various attack methods, strategies for\nattack-success evaluation, metrics for assessing experiment outcomes, as well\nas a host of other considerations. Our survey will be useful for any reader who\nwants to rapidly obtain a grasp of the major red teaming concepts for their own\nuse in practical applications.\n","authors":["Alberto Purpura","Sahil Wadhwa","Jesse Zymet","Akshay Gupta","Andy Luo","Melissa Kazemi Rad","Swapnil Shinde","Mohammad Shahed Sorower"],"pdf_url":"https://arxiv.org/pdf/2503.01742v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.11681v4","updated":"2025-03-05T14:38:19Z","published":"2025-02-17T11:16:19Z","title":"RIDE: Enhancing Large Language Model Alignment through Restyled\n  In-Context Learning Demonstration Exemplars","summary":"  Alignment tuning is crucial for ensuring large language models (LLMs) behave\nethically and helpfully. Current alignment approaches require high-quality\nannotations and significant training resources. This paper proposes a low-cost,\ntuning-free method using in-context learning (ICL) to enhance LLM alignment.\nThrough an analysis of high-quality ICL demos, we identified style as a key\nfactor influencing LLM alignment capabilities and explicitly restyled ICL\nexemplars based on this stylistic framework. Additionally, we combined the\nrestyled demos to achieve a balance between the two conflicting aspects of LLM\nalignment--factuality and safety. We packaged the restyled examples as prompts\nto trigger few-shot learning, improving LLM alignment. Compared to the best\nbaseline approach, with an average score of 5.00 as the maximum, our method\nachieves a maximum 0.10 increase on the Alpaca task (from 4.50 to 4.60), a 0.22\nenhancement on the Just-eval benchmark (from 4.34 to 4.56), and a maximum\nimprovement of 0.32 (from 3.53 to 3.85) on the MT-Bench dataset. We release the\ncode and data at https://github.com/AnonymousCode-ComputerScience/RIDE.\n","authors":["Yuncheng Hua","Lizhen Qu","Zhuang Li","Hao Xue","Flora D. Salim","Gholamreza Haffari"],"pdf_url":"https://arxiv.org/pdf/2502.11681v4.pdf","comment":"38 pages, 2 figures, 20 tables; The paper is under review in ARR"},{"id":"http://arxiv.org/abs/2409.19005v3","updated":"2025-03-05T14:04:24Z","published":"2024-09-21T09:19:29Z","title":"What is a Digital Twin Anyway? Deriving the Definition for the Built\n  Environment from over 15,000 Scientific Publications","summary":"  The concept of digital twins has attracted significant attention across\nvarious domains, particularly within the built environment. However, there is a\nsheer volume of definitions and the terminological consensus remains out of\nreach. The lack of a universally accepted definition leads to ambiguities in\ntheir conceptualization and implementation, and may cause miscommunication for\nboth researchers and practitioners. We employed Natural Language Processing\n(NLP) techniques to systematically extract and analyze definitions of digital\ntwins from a corpus of more than 15,000 full-text articles spanning diverse\ndisciplines. The study compares these findings with insights from an expert\nsurvey that included 52 experts. The study identifies concurrence on the\ncomponents that comprise a ``Digital Twin'' from a practical perspective across\nvarious domains, contrasting them with those that do not, to identify\ndeviations. We investigate the evolution of digital twin definitions over time\nand across different scales, including manufacturing, building, and\nurban/geospatial perspectives. We extracted the main components of Digital\nTwins using Text Frequency Analysis and N-gram analysis. Subsequently, we\nidentified components that appeared in the literature and conducted a\nChi-square test to assess the significance of each component in different\ndomains. Our analysis identified key components of digital twins and revealed\nsignificant variations in definitions based on application domains, such as\nmanufacturing, building, and urban contexts. The analysis of DT components\nreveal two major groups of DT types: High-Performance Real-Time (HPRT) DTs, and\nLong-Term Decision Support (LTDS) DTs. Contrary to common assumptions, we found\nthat components such as simulation, AI/ML, real-time capabilities, and\nbi-directional data flow are not yet fully mature in the digital twins of the\nbuilt environment.\n","authors":["Mahmoud Abdelrahman","Edgardo Macatulad","Binyu Lei","Matias Quintana","Clayton Miller","Filip Biljecki"],"pdf_url":"https://arxiv.org/pdf/2409.19005v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05459v2","updated":"2025-03-05T13:57:56Z","published":"2024-10-07T19:45:09Z","title":"From Sparse Dependence to Sparse Attention: Unveiling How\n  Chain-of-Thought Enhances Transformer Sample Efficiency","summary":"  Chain-of-thought (CoT) significantly enhances the reasoning performance of\nlarge language models (LLM). While current theoretical studies often attribute\nthis improvement to increased expressiveness and computational capacity, we\nargue that expressiveness is not the primary limitation in the LLM regime, as\ncurrent large models will fail on simple tasks. Using a parity-learning setup,\nwe demonstrate that CoT can substantially improve sample efficiency even when\nthe representation power is sufficient. Specifically, with CoT, a transformer\ncan learn the function within polynomial samples, whereas without CoT, the\nrequired sample size is exponential. Additionally, we show that CoT simplifies\nthe learning process by introducing sparse sequential dependencies among input\ntokens, and leads to a sparse and interpretable attention. We validate our\ntheoretical analysis with both synthetic and real-world experiments, confirming\nthat sparsity in attention layers is a key factor of the improvement induced by\nCoT.\n","authors":["Kaiyue Wen","Huaqing Zhang","Hongzhou Lin","Jingzhao Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.05459v2.pdf","comment":"43 pages,11 figures"},{"id":"http://arxiv.org/abs/2503.03512v1","updated":"2025-03-05T13:57:48Z","published":"2025-03-05T13:57:48Z","title":"An Aspect Extraction Framework using Different Embedding Types, Learning\n  Models, and Dependency Structure","summary":"  Aspect-based sentiment analysis has gained significant attention in recent\nyears due to its ability to provide fine-grained insights for sentiment\nexpressions related to specific features of entities. An important component of\naspect-based sentiment analysis is aspect extraction, which involves\nidentifying and extracting aspect terms from text. Effective aspect extraction\nserves as the foundation for accurate sentiment analysis at the aspect level.\nIn this paper, we propose aspect extraction models that use different types of\nembeddings for words and part-of-speech tags and that combine several learning\nmodels. We also propose tree positional encoding that is based on dependency\nparsing output to capture better the aspect positions in sentences. In\naddition, a new aspect extraction dataset is built for Turkish by machine\ntranslating an English dataset in a controlled setting. The experiments\nconducted on two Turkish datasets showed that the proposed models mostly\noutperform the studies that use the same datasets, and incorporating tree\npositional encoding increases the performance of the models.\n","authors":["Ali Erkan","Tunga Güngör"],"pdf_url":"https://arxiv.org/pdf/2503.03512v1.pdf","comment":"Aspect-based Sentiment Analysis, Aspect Extraction, Natural Language\n  Processing, Machine Learning, Deep Neural Networks, Turkish"},{"id":"http://arxiv.org/abs/2503.03502v1","updated":"2025-03-05T13:47:53Z","published":"2025-03-05T13:47:53Z","title":"CURVALID: Geometrically-guided Adversarial Prompt Detection","summary":"  Adversarial prompts capable of jailbreaking large language models (LLMs) and\ninducing undesirable behaviours pose a significant obstacle to their safe\ndeployment. Current mitigation strategies rely on activating built-in defence\nmechanisms or fine-tuning the LLMs, but the fundamental distinctions between\nadversarial and benign prompts are yet to be understood. In this work, we\nintroduce CurvaLID, a novel defense framework that efficiently detects\nadversarial prompts by leveraging their geometric properties. It is agnostic to\nthe type of LLM, offering a unified detection framework across diverse\nadversarial prompts and LLM architectures. CurvaLID builds on the geometric\nanalysis of text prompts to uncover their underlying differences. We\ntheoretically extend the concept of curvature via the Whewell equation into an\n$n$-dimensional word embedding space, enabling us to quantify local geometric\nproperties, including semantic shifts and curvature in the underlying\nmanifolds. Additionally, we employ Local Intrinsic Dimensionality (LID) to\ncapture geometric features of text prompts within adversarial subspaces. Our\nfindings reveal that adversarial prompts differ fundamentally from benign\nprompts in terms of their geometric characteristics. Our results demonstrate\nthat CurvaLID delivers superior detection and rejection of adversarial queries,\npaving the way for safer LLM deployment. The source code can be found at\nhttps://github.com/Cancanxxx/CurvaLID\n","authors":["Canaan Yung","Hanxun Huang","Sarah Monazam Erfani","Christopher Leckie"],"pdf_url":"https://arxiv.org/pdf/2503.03502v1.pdf","comment":"29 Pages, 5 figues"},{"id":"http://arxiv.org/abs/2503.03495v1","updated":"2025-03-05T13:34:49Z","published":"2025-03-05T13:34:49Z","title":"Deictic Codes, Demonstratives, and Reference: A Step Toward Solving the\n  Grounding Problem","summary":"  In this paper we address the issue of grounding for experiential concepts.\nGiven that perceptual demonstratives are a basic form of such concepts, we\nexamine ways of fixing the referents of such demonstratives. To avoid\n'encodingism', that is, relating representations to representations, we\npostulate that the process of reference fixing must be bottom-up and\nnonconceptual, so that it can break the circle of conceptual content and touch\nthe world. For that purpose, an appropriate causal relation between\nrepresentations and the world is needed. We claim that this relation is\nprovided by spatial and object-centered attention that leads to the formation\nof object files through the function of deictic acts. This entire causal\nprocess takes place at a pre-conceptual level, meeting the requirement for a\nsolution to the grounding problem. Finally we claim that our account captures\nfundamental insights in Putnam's and Kripke's work on \"new\" reference.\n","authors":["Athanassios Raftopoulos","Vincent C. Müller"],"pdf_url":"https://arxiv.org/pdf/2503.03495v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20475v2","updated":"2025-03-05T13:22:47Z","published":"2025-02-27T19:23:15Z","title":"Promote, Suppress, Iterate: How Language Models Answer One-to-Many\n  Factual Queries","summary":"  To answer one-to-many factual queries (e.g., listing cities of a country), a\nlanguage model (LM) must simultaneously recall knowledge and avoid repeating\nprevious answers. How are these two subtasks implemented and integrated\ninternally? Across multiple datasets and models, we identify a\npromote-then-suppress mechanism: the model first recalls all answers, and then\nsuppresses previously generated ones. Specifically, LMs use both the subject\nand previous answer tokens to perform knowledge recall, with attention\npropagating subject information and MLPs promoting the answers. Then, attention\nattends to and suppresses previous answer tokens, while MLPs amplify the\nsuppression signal. Our mechanism is corroborated by extensive experimental\nevidence: in addition to using early decoding and causal tracing, we analyze\nhow components use different tokens by introducing both Token Lens, which\ndecodes aggregated attention updates from specified tokens, and a knockout\nmethod that analyzes changes in MLP outputs after removing attention to\nspecified tokens. Overall, we provide new insights into how LMs' internal\ncomponents interact with different input tokens to support complex factual\nrecall. Code is available at\nhttps://github.com/Lorenayannnnn/how-lms-answer-one-to-many-factual-queries.\n","authors":["Tianyi Lorena Yan","Robin Jia"],"pdf_url":"https://arxiv.org/pdf/2502.20475v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.02393v3","updated":"2025-03-05T13:19:16Z","published":"2025-01-04T22:30:21Z","title":"Graph-Aware Isomorphic Attention for Adaptive Dynamics in Transformers","summary":"  We present an approach to modifying Transformer architectures by integrating\ngraph-aware relational reasoning into the attention mechanism, merging concepts\nfrom graph neural networks and language modeling. Building on the inherent\nconnection between attention and graph theory, we reformulate the Transformer's\nattention mechanism as a graph operation and propose Graph-Aware Isomorphic\nAttention. This method leverages advanced graph modeling strategies, including\nGraph Isomorphism Networks (GIN) and Principal Neighborhood Aggregation (PNA),\nto enrich the representation of relational structures. Our approach captures\ncomplex dependencies and generalizes across tasks, as evidenced by a reduced\ngeneralization gap and improved learning performance. Additionally, we expand\nthe concept of graph-aware attention to introduce Sparse GIN-Attention, a\nfine-tuning approach that employs sparse GINs. By interpreting attention\nmatrices as sparse adjacency graphs, this technique enhances the adaptability\nof pre-trained foundational models with minimal computational overhead,\nendowing them with graph-aware capabilities. Sparse GIN-Attention fine-tuning\nachieves improved training dynamics and better generalization compared to\nalternative methods like low-rank adaption (LoRA). We discuss latent graph-like\nstructures within traditional attention mechanisms, offering a new lens through\nwhich Transformers can be understood. By evolving Transformers as hierarchical\nGIN models for relational reasoning. This perspective suggests profound\nimplications for foundational model development, enabling the design of\narchitectures that dynamically adapt to both local and global dependencies.\nApplications in bioinformatics, materials science, language modeling, and\nbeyond could benefit from this synthesis of relational and sequential data\nmodeling, setting the stage for interpretable and generalizable modeling\nstrategies.\n","authors":["Markus J. Buehler"],"pdf_url":"https://arxiv.org/pdf/2501.02393v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01275v2","updated":"2025-03-05T13:10:07Z","published":"2025-03-03T07:59:32Z","title":"Enhancing Non-English Capabilities of English-Centric Large Language\n  Models through Deep Supervision Fine-Tuning","summary":"  Large language models (LLMs) have demonstrated significant progress in\nmultilingual language understanding and generation. However, due to the\nimbalance in training data, their capabilities in non-English languages are\nlimited. Recent studies revealed the English-pivot multilingual mechanism of\nLLMs, where LLMs implicitly convert non-English queries into English ones at\nthe bottom layers and adopt English for thinking at the middle layers. However,\ndue to the absence of explicit supervision for cross-lingual alignment in the\nintermediate layers of LLMs, the internal representations during these stages\nmay become inaccurate. In this work, we introduce a deep supervision\nfine-tuning method (DFT) that incorporates additional supervision in the\ninternal layers of the model to guide its workflow. Specifically, we introduce\ntwo training objectives on different layers of LLMs: one at the bottom layers\nto constrain the conversion of the target language into English, and another at\nthe middle layers to constrain reasoning in English. To effectively achieve the\nguiding purpose, we designed two types of supervision signals: logits and\nfeature, which represent a stricter constraint and a relatively more relaxed\nguidance. Our method guides the model to not only consider the final generated\nresult when processing non-English inputs but also ensure the accuracy of\ninternal representations. We conducted extensive experiments on typical\nEnglish-centric large models, LLaMA-2 and Gemma-2, and the results on multiple\nmultilingual datasets show that our method significantly outperforms\ntraditional fine-tuning methods.\n","authors":["Wenshuai Huo","Xiaocheng Feng","Yichong Huang","Chengpeng Fu","Baohang Li","Yangfan Ye","Zhirui Zhang","Dandan Tu","Duyu Tang","Yunfei Lu","Hui Wang","Bing Qin"],"pdf_url":"https://arxiv.org/pdf/2503.01275v2.pdf","comment":"Accepted at AAAI 2025"},{"id":"http://arxiv.org/abs/2503.03474v1","updated":"2025-03-05T13:10:07Z","published":"2025-03-05T13:10:07Z","title":"Enhancing Spoken Discourse Modeling in Language Models Using Gestural\n  Cues","summary":"  Research in linguistics shows that non-verbal cues, such as gestures, play a\ncrucial role in spoken discourse. For example, speakers perform hand gestures\nto indicate topic shifts, helping listeners identify transitions in discourse.\nIn this work, we investigate whether the joint modeling of gestures using human\nmotion sequences and language can improve spoken discourse modeling in language\nmodels. To integrate gestures into language models, we first encode 3D human\nmotion sequences into discrete gesture tokens using a VQ-VAE. These gesture\ntoken embeddings are then aligned with text embeddings through feature\nalignment, mapping them into the text embedding space. To evaluate the\ngesture-aligned language model on spoken discourse, we construct text infilling\ntasks targeting three key discourse cues grounded in linguistic research:\ndiscourse connectives, stance markers, and quantifiers. Results show that\nincorporating gestures enhances marker prediction accuracy across the three\ntasks, highlighting the complementary information that gestures can offer in\nmodeling spoken discourse. We view this work as an initial step toward\nleveraging non-verbal cues to advance spoken language modeling in language\nmodels.\n","authors":["Varsha Suresh","M. Hamza Mughal","Christian Theobalt","Vera Demberg"],"pdf_url":"https://arxiv.org/pdf/2503.03474v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03462v1","updated":"2025-03-05T12:52:14Z","published":"2025-03-05T12:52:14Z","title":"Open-Source Large Language Models as Multilingual Crowdworkers:\n  Synthesizing Open-Domain Dialogues in Several Languages With No Examples in\n  Targets and No Machine Translation","summary":"  The prevailing paradigm in the domain of Open-Domain Dialogue agents\npredominantly focuses on the English language, encompassing both models and\ndatasets. Furthermore, the financial and temporal investments required for\ncrowdsourcing such datasets for finetuning are substantial, particularly when\nmultiple languages are involved. Fortunately, advancements in Large Language\nModels (LLMs) have unveiled a plethora of possibilities across diverse tasks.\nSpecifically, instruction-tuning has enabled LLMs to execute tasks based on\nnatural language instructions, occasionally surpassing the performance of human\ncrowdworkers. Additionally, these models possess the capability to function in\nvarious languages within a single thread. Consequently, to generate new samples\nin different languages, we propose leveraging these capabilities to replicate\nthe data collection process. We introduce a pipeline for generating Open-Domain\nDialogue data in multiple Target Languages using LLMs, with demonstrations\nprovided in a unique Source Language. By eschewing explicit Machine Translation\nin this approach, we enhance the adherence to language-specific nuances. We\napply this methodology to the PersonaChat dataset. To enhance the openness of\ngenerated dialogues and mimic real life scenarii, we added the notion of speech\nevents corresponding to the type of conversation the speakers are involved in\nand also that of common ground which represents the premises of a conversation.\n","authors":["Ahmed Njifenjou","Virgile Sucal","Bassam Jabaian","Fabrice Lefèvre"],"pdf_url":"https://arxiv.org/pdf/2503.03462v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03460v1","updated":"2025-03-05T12:49:48Z","published":"2025-03-05T12:49:48Z","title":"Visualising Policy-Reward Interplay to Inform Zeroth-Order Preference\n  Optimisation of Large Language Models","summary":"  Fine-tuning LLMs with first-order methods like back-propagation is\ncomputationally intensive. Zeroth-Order (ZO) optimisation, using function\nevaluations instead of gradients, reduces memory usage but suffers from slow\nconvergence in high-dimensional models. As a result, ZO research in LLMs has\nmostly focused on classification, overlooking more complex generative tasks. In\nthis paper, we introduce ZOPrO, a novel ZO algorithm designed for\n\\textit{Preference Optimisation} in LLMs. We begin by analysing the interplay\nbetween policy and reward models during traditional (first-order) Preference\nOptimisation, uncovering patterns in their relative updates. Guided by these\ninsights, we adapt Simultaneous Perturbation Stochastic Approximation (SPSA)\nwith a targeted sampling strategy to accelerate convergence. Through\nexperiments on summarisation, machine translation, and conversational\nassistants, we demonstrate that our method consistently enhances reward signals\nwhile achieving convergence times comparable to first-order methods. While it\nfalls short of some state-of-the-art methods, our work is the first to apply\nZeroth-Order methods to Preference Optimisation in LLMs, going beyond\nclassification tasks and paving the way for a largely unexplored research\ndirection. Code and visualisations are available at\nhttps://github.com/alessioGalatolo/VisZOPrO\n","authors":["Alessio Galatolo","Zhenbang Dai","Katie Winkle","Meriem Beloucif"],"pdf_url":"https://arxiv.org/pdf/2503.03460v1.pdf","comment":"WIP"},{"id":"http://arxiv.org/abs/2503.03459v1","updated":"2025-03-05T12:49:44Z","published":"2025-03-05T12:49:44Z","title":"Unified Mind Model: Reimagining Autonomous Agents in the LLM Era","summary":"  Large language models (LLMs) have recently demonstrated remarkable\ncapabilities across domains, tasks, and languages (e.g., ChatGPT and GPT-4),\nreviving the research of general autonomous agents with human-like cognitive\nabilities.Such human-level agents require semantic comprehension and\ninstruction-following capabilities, which exactly fall into the strengths of\nLLMs.Although there have been several initial attempts to build human-level\nagents based on LLMs, the theoretical foundation remains a challenging open\nproblem. In this paper, we propose a novel theoretical cognitive architecture,\nthe Unified Mind Model (UMM), which offers guidance to facilitate the rapid\ncreation of autonomous agents with human-level cognitive abilities.\nSpecifically, our UMM starts with the global workspace theory and further\nleverage LLMs to enable the agent with various cognitive abilities, such as\nmulti-modal perception, planning, reasoning, tool use, learning, memory,\nreflection and motivation. Building upon UMM, we then develop an agent-building\nengine, MindOS, which allows users to quickly create domain-/task-specific\nautonomous agents without any programming effort.\n","authors":["Pengbo Hu","Xiang Ying"],"pdf_url":"https://arxiv.org/pdf/2503.03459v1.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2503.03444v1","updated":"2025-03-05T12:24:20Z","published":"2025-03-05T12:24:20Z","title":"Taxation Perspectives from Large Language Models: A Case Study on\n  Additional Tax Penalties","summary":"  How capable are large language models (LLMs) in the domain of taxation?\nAlthough numerous studies have explored the legal domain in general, research\ndedicated to taxation remain scarce. Moreover, the datasets used in these\nstudies are either simplified, failing to reflect the real-world complexities,\nor unavailable as open source. To address this gap, we introduce PLAT, a new\nbenchmark designed to assess the ability of LLMs to predict the legitimacy of\nadditional tax penalties. PLAT is constructed to evaluate LLMs' understanding\nof tax law, particularly in cases where resolving the issue requires more than\njust applying related statutes. Our experiments with six LLMs reveal that their\nbaseline capabilities are limited, especially when dealing with conflicting\nissues that demand a comprehensive understanding. However, we found that\nenabling retrieval, self-reasoning, and discussion among multiple agents with\nspecific role assignments, this limitation can be mitigated.\n","authors":["Eunkyung Choi","Young Jin Suh","Hun Park","Wonseok Hwang"],"pdf_url":"https://arxiv.org/pdf/2503.03444v1.pdf","comment":"5 pages"},{"id":"http://arxiv.org/abs/2503.03434v1","updated":"2025-03-05T12:10:14Z","published":"2025-03-05T12:10:14Z","title":"RASD: Retrieval-Augmented Speculative Decoding","summary":"  Speculative decoding accelerates inference in large language models (LLMs) by\ngenerating draft tokens for target model verification. Current approaches for\nobtaining draft tokens rely on lightweight draft models or additional model\nstructures to generate draft tokens and retrieve context from databases. Due to\nthe draft model's small size and limited training data, model-based speculative\ndecoding frequently becomes less effective in out-of-domain scenarios.\nAdditionally, the time cost of the drafting phase results in a low upper limit\non acceptance length during the verification step, limiting overall efficiency.\nThis paper proposes RASD (Retrieval-Augmented Speculative Decoding), which\nadopts retrieval methods to enhance model-based speculative decoding. We\nintroduce tree pruning and tree fusion to achieve this. Specifically, we\ndevelop a pruning method based on the draft model's probability distribution to\nconstruct the optimal retrieval tree. Second, we employ the longest prefix\nmatching algorithm to merge the tree generated by the draft model with the\nretrieval tree, resulting in a unified tree for verification. Experimental\nresults demonstrate that RASD achieves state-of-the-art inference acceleration\nacross tasks such as DocQA, Summary, Code, and In-Domain QA. Moreover, RASD\nexhibits strong scalability, seamlessly integrating with various speculative\ndecoding approaches, including both generation-based and retrieval-based\nmethods.\n","authors":["Guofeng Quan","Wenfeng Feng","Chuzhan Hao","Guochao Jiang","Yuewei Zhang","Hao Wang"],"pdf_url":"https://arxiv.org/pdf/2503.03434v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.18377v3","updated":"2025-03-05T11:49:36Z","published":"2024-12-24T12:03:36Z","title":"ChaI-TeA: A Benchmark for Evaluating Autocompletion of Interactions with\n  LLM-based Chatbots","summary":"  The rise of LLMs has deflected a growing portion of human-computer\ninteractions towards LLM-based chatbots. The remarkable abilities of these\nmodels allow users to interact using long, diverse natural language text\ncovering a wide range of topics and styles. Phrasing these messages is a time\nand effort consuming task, calling for an autocomplete solution to assist\nusers. We introduce the task of chatbot interaction autocomplete. We present\nChaI-TeA: CHat InTEraction Autocomplete; An autcomplete evaluation framework\nfor LLM-based chatbot interactions. The framework includes a formal definition\nof the task, coupled with suitable datasets and metrics. We use the framework\nto evaluate After formally defining the task along with suitable datasets and\nmetrics, we test 9 models on the defined auto completion task, finding that\nwhile current off-the-shelf models perform fairly, there is still much room for\nimprovement, mainly in ranking of the generated suggestions. We provide\ninsights for practitioners working on this task and open new research\ndirections for researchers in the field. We release our framework to serve as a\nfoundation for future research.\n","authors":["Shani Goren","Oren Kalinsky","Tomer Stav","Yuri Rapoport","Yaron Fairstein","Ram Yazdi","Nachshon Cohen","Alexander Libov","Guy Kushilevitz"],"pdf_url":"https://arxiv.org/pdf/2412.18377v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03417v1","updated":"2025-03-05T11:47:32Z","published":"2025-03-05T11:47:32Z","title":"When Claims Evolve: Evaluating and Enhancing the Robustness of Embedding\n  Models Against Misinformation Edits","summary":"  Online misinformation remains a critical challenge, and fact-checkers\nincreasingly rely on embedding-based methods to retrieve relevant fact-checks.\nYet, when debunked claims reappear in edited forms, the performance of these\nmethods is unclear. In this work, we introduce a taxonomy of six common\nreal-world misinformation edits and propose a perturbation framework that\ngenerates valid, natural claim variations. Our multi-stage retrieval evaluation\nreveals that standard embedding models struggle with user-introduced edits,\nwhile LLM-distilled embeddings offer improved robustness at a higher\ncomputational cost. Although a strong reranker helps mitigate some issues, it\ncannot fully compensate for first-stage retrieval gaps. Addressing these\nretrieval gaps, our train- and inference-time mitigation approaches enhance\nin-domain robustness by up to 17 percentage points and boost out-of-domain\ngeneralization by 10 percentage points over baseline models. Overall, our\nfindings provide practical improvements to claim-matching systems, enabling\nmore reliable fact-checking of evolving misinformation.\n","authors":["Jabez Magomere","Emanuele La Malfa","Manuel Tonneau","Ashkan Kazemi","Scott Hale"],"pdf_url":"https://arxiv.org/pdf/2503.03417v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.14153v2","updated":"2025-03-05T11:15:39Z","published":"2024-08-26T09:55:34Z","title":"Explaining Vision-Language Similarities in Dual Encoders with\n  Feature-Pair Attributions","summary":"  Dual encoder architectures like CLIP models map two types of inputs into a\nshared embedding space and predict similarities between them. Despite their\nsuccess, it is, however, not understood how these models compare their two\ninputs. Common first-order feature-attribution methods can only provide limited\ninsights into dual-encoders since their predictions depend on\nfeature-interactions rather than on individual features. In this paper, we\nfirst derive a second-order method enabling the attribution of predictions by\nany differentiable dual encoder onto feature-interactions between its inputs.\nSecond, we apply our method to CLIP models and show that they learn\nfine-grained correspondences between parts of captions and regions in images.\nThey match objects across input modes also account for mismatches. This\nvisual-linguistic grounding ability, however, varies heavily between object\nclasses and exhibits pronounced out-of-domain effects. We can identify\nindividual errors as well as systematic failure categories including object\ncoverage, unusual scenes and correlated contexts.\n","authors":["Lucas Möller","Pascal Tilli","Ngoc Thang Vu","Sebastian Padó"],"pdf_url":"https://arxiv.org/pdf/2408.14153v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03380v1","updated":"2025-03-05T10:55:47Z","published":"2025-03-05T10:55:47Z","title":"The Serendipity of Claude AI: Case of the 13 Low-Resource National\n  Languages of Mali","summary":"  Recent advances in artificial intelligence (AI) and natural language\nprocessing (NLP) have improved the representation of underrepresented\nlanguages. However, most languages, including Mali's 13 official national\nlanguages, continue to be poorly supported or unsupported by automatic\ntranslation and generative AI. This situation appears to have slightly improved\nwith certain recent LLM releases. The study evaluated Claude AI's translation\nperformance on each of the 13 national languages of Mali. In addition to ChrF2\nand BLEU scores, human evaluators assessed translation accuracy, contextual\nconsistency, robustness to dialect variations, management of linguistic bias,\nadaptation to a limited corpus, and ease of understanding. The study found that\nClaude AI performs robustly for languages with very modest language resources\nand, while unable to produce understandable and coherent texts for Malian\nlanguages with minimal resources, still manages to produce results which\ndemonstrate the ability to mimic some elements of the language.\n","authors":["Alou Dembele","Nouhoum Souleymane Coulibaly","Michael Leventhal"],"pdf_url":"https://arxiv.org/pdf/2503.03380v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03360v1","updated":"2025-03-05T10:40:09Z","published":"2025-03-05T10:40:09Z","title":"Transformers for molecular property prediction: Domain adaptation\n  efficiently improves performance","summary":"  Most of the current transformer-based chemical language models are\npre-trained on millions to billions of molecules. However, the improvement from\nsuch scaling in dataset size is not confidently linked to improved molecular\nproperty prediction. The aim of this study is to investigate and overcome some\nof the limitations of transformer models in predicting molecular properties.\nSpecifically, we examine the impact of pre-training dataset size and diversity\non the performance of transformer models and investigate the use of domain\nadaptation as a technique for improving model performance. First, our findings\nindicate that increasing pretraining dataset size beyond 400K molecules from\nthe GuacaMol dataset does not result in a significant improvement on four ADME\nendpoints, namely, solubility, permeability, microsomal stability, and plasma\nprotein binding. Second, our results demonstrate that using domain adaptation\nby further training the transformer model on a small set of domain-relevant\nmolecules, i.e., a few hundred to a few thousand, using multi-task regression\nof physicochemical properties was sufficient to significantly improve\nperformance for three out of the four investigated ADME endpoints (P-value <\n0.001). Finally, we observe that a model pre-trained on 400K molecules and\ndomain adopted on a few hundred/thousand molecules performs similarly (P-value\n> 0.05) to more complicated transformer models like MolBERT(pre-trained on 1.3M\nmolecules) and MolFormer (pre-trained on 100M molecules). A comparison to a\nrandom forest model trained on basic physicochemical properties showed similar\nperformance to the examined transformer models. We believe that current\ntransformer models can be improved through further systematic analysis of\npre-training and downstream data, pre-training objectives, and scaling laws,\nultimately leading to better and more helpful models.\n","authors":["Afnan Sultan","Max Rausch-Dupont","Shahrukh Khan","Olga Kalinina","Andrea Volkamer","Dietrich Klakow"],"pdf_url":"https://arxiv.org/pdf/2503.03360v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03340v1","updated":"2025-03-05T10:13:05Z","published":"2025-03-05T10:13:05Z","title":"EnigmaToM: Improve LLMs' Theory-of-Mind Reasoning Capabilities with\n  Neural Knowledge Base of Entity States","summary":"  Theory-of-Mind (ToM), the ability to infer others' perceptions and mental\nstates, is fundamental to human interaction but remains a challenging task for\nLarge Language Models (LLMs). While existing ToM reasoning methods show promise\nwith reasoning via perceptual perspective-taking, they often rely excessively\non LLMs, reducing their efficiency and limiting their applicability to\nhigh-order ToM reasoning, which requires multi-hop reasoning about characters'\nbeliefs. To address these issues, we present EnigmaToM, a novel neuro-symbolic\nframework that enhances ToM reasoning by integrating a Neural Knowledge Base of\nentity states (Enigma) for (1) a psychology-inspired iterative masking\nmechanism that facilitates accurate perspective-taking and (2) knowledge\ninjection that elicits key entity information. Enigma generates structured\nrepresentations of entity states, which construct spatial scene graphs --\nleveraging spatial information as an inductive bias -- for belief tracking of\nvarious ToM orders and enhancing events with fine-grained entity state details.\nExperimental results on multiple benchmarks, including ToMi, HiToM, and FANToM,\nshow that EnigmaToM significantly improves ToM reasoning across LLMs of varying\nsizes, particularly excelling in high-order reasoning scenarios.\n","authors":["Hainiu Xu","Siya Qi","Jiazheng Li","Yuxiang Zhou","Jinhua Du","Caroline Catmur","Yulan He"],"pdf_url":"https://arxiv.org/pdf/2503.03340v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03335v1","updated":"2025-03-05T10:09:53Z","published":"2025-03-05T10:09:53Z","title":"iNews: A Multimodal Dataset for Modeling Personalized Affective\n  Responses to News","summary":"  Current approaches to emotion detection often overlook the inherent\nsubjectivity of affective experiences, instead relying on aggregated labels\nthat mask individual variations in emotional responses. We introduce iNews, a\nnovel large-scale dataset explicitly capturing subjective affective responses\nto news headlines. Our dataset comprises annotations from 291 demographically\ndiverse UK participants across 2,899 multimodal Facebook news posts from major\nUK outlets, with an average of 5.18 annotators per sample. For each post,\nannotators provide multifaceted labels including valence, arousal, dominance,\ndiscrete emotions, content relevance judgments, sharing likelihood, and\nmodality importance ratings (text, image, or both). Furthermore, we collect\ncomprehensive annotator persona information covering demographics, personality,\nmedia trust, and consumption patterns, which explain 15.2% of annotation\nvariance - higher than existing NLP datasets. Incorporating this information\nyields a 7% accuracy gain in zero-shot prediction and remains beneficial even\nwith 32-shot. iNews will enhance research in LLM personalization, subjectivity,\naffective computing, and individual-level behavior simulation.\n","authors":["Tiancheng Hu","Nigel Collier"],"pdf_url":"https://arxiv.org/pdf/2503.03335v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03766v3","updated":"2025-03-05T09:52:30Z","published":"2024-11-06T08:59:44Z","title":"Number Cookbook: Number Understanding of Language Models and How to\n  Improve It","summary":"  Large language models (LLMs) can solve an increasing number of complex\nreasoning tasks while making surprising mistakes in basic numerical\nunderstanding and processing (such as 9.11 > 9.9). The latter ability is\nessential for tackling complex arithmetic and mathematical problems and serves\nas a foundation for most reasoning tasks, but previous work paid little\nattention to it or only discussed several restricted tasks (like integer\naddition). In this paper, we comprehensively investigate the numerical\nunderstanding and processing ability (NUPA) of LLMs. Firstly, we introduce a\nbenchmark covering four common numerical representations and 17 distinct\nnumerical tasks in four major categories, resulting in 41 meaningful\ncombinations in total. These tasks are derived from primary and secondary\neducation curricula, encompassing nearly all everyday numerical understanding\nand processing scenarios, and the rules of these tasks are very simple and\nclear. Through the benchmark, we find that current LLMs fail frequently in many\nof the tasks. To study the problem, we train small models with existing and\npotential techniques for enhancing NUPA (such as tokenizers, PEs, and number\nformats), comprehensively evaluating their effectiveness using our testbed. We\nalso finetune practical-scale LLMs on our proposed NUPA tasks and find that 1)\nnaive finetuning can improve NUPA a lot on many but not all tasks, and 2)\nsurprisingly, techniques designed to enhance NUPA prove ineffective for\nfinetuning pretrained models. We further explore the impact of chain-of-thought\ntechniques on NUPA. Our work provides a more detailed and comprehensive\nunderstanding of NUPA in LLMs. Our benchmark and code are released at\nhttps://github.com/GraphPKU/number_cookbook.\n","authors":["Haotong Yang","Yi Hu","Shijia Kang","Zhouchen Lin","Muhan Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.03766v3.pdf","comment":"ICLR 2025 poster"},{"id":"http://arxiv.org/abs/2502.07780v3","updated":"2025-03-05T09:50:16Z","published":"2025-02-11T18:59:35Z","title":"DarwinLM: Evolutionary Structured Pruning of Large Language Models","summary":"  Large Language Models (LLMs) have achieved significant success across various\nNLP tasks. However, their massive computational costs limit their widespread\nuse, particularly in real-time applications. Structured pruning offers an\neffective solution by compressing models and directly providing end-to-end\nspeed improvements, regardless of the hardware environment. Meanwhile,\ndifferent components of the model exhibit varying sensitivities towards\npruning, calling for non-uniform model compression. However, a pruning method\nshould not only identify a capable substructure, but also account for\npost-compression training. To this end, we propose DarwinLM, a method for\ntraining-aware structured pruning. DarwinLM builds upon an evolutionary search\nprocess, generating multiple offspring models in each generation through\nmutation, and selecting the fittest for survival. To assess the effect of\npost-training, we incorporate a lightweight, multistep training process within\nthe offspring population, progressively increasing the number of tokens and\neliminating poorly performing models in each selection stage. We validate our\nmethod through extensive experiments on Llama-2-7B, Llama-3.1-8B and\nQwen-2.5-14B-Instruct, achieving state-of-the-art performance for structured\npruning. For instance, DarwinLM surpasses ShearedLlama while requiring 5x less\ntraining data during post-compression training. Code is at:\nhttps://github.com/IST-DASLab/DarwinLM\n","authors":["Shengkun Tang","Oliver Sieberling","Eldar Kurtic","Zhiqiang Shen","Dan Alistarh"],"pdf_url":"https://arxiv.org/pdf/2502.07780v3.pdf","comment":"Code: https://github.com/IST-DASLab/DarwinLM"},{"id":"http://arxiv.org/abs/2503.03313v1","updated":"2025-03-05T09:45:22Z","published":"2025-03-05T09:45:22Z","title":"LLM as GNN: Graph Vocabulary Learning for Text-Attributed Graph\n  Foundation Models","summary":"  Text-Attributed Graphs (TAGs), where each node is associated with text\ndescriptions, are ubiquitous in real-world scenarios. They typically exhibit\ndistinctive structure and domain-specific knowledge, motivating the development\nof a Graph Foundation Model (GFM) that generalizes across diverse graphs and\ntasks. Despite large efforts to integrate Large Language Models (LLMs) and\nGraph Neural Networks (GNNs) for TAGs, existing approaches suffer from\ndecoupled architectures with two-stage alignment, limiting their synergistic\npotential. Even worse, existing methods assign out-of-vocabulary (OOV) tokens\nto graph nodes, leading to graph-specific semantics, token explosion, and\nincompatibility with task-oriented prompt templates, which hinders cross-graph\nand cross-task transferability. To address these challenges, we propose\nPromptGFM, a versatile GFM for TAGs grounded in graph vocabulary learning.\nPromptGFM comprises two key components: (1) Graph Understanding Module, which\nexplicitly prompts LLMs to replicate the finest GNN workflow within the text\nspace, facilitating seamless GNN-LLM integration and elegant graph-text\nalignment; (2) Graph Inference Module, which establishes a language-based graph\nvocabulary ensuring expressiveness, transferability, and scalability, enabling\nreadable instructions for LLM fine-tuning. Extensive experiments demonstrate\nour superiority and transferability across diverse graphs and tasks. The code\nis available at this: https://github.com/agiresearch/PromptGFM.\n","authors":["Xi Zhu","Haochen Xue","Ziwei Zhao","Wujiang Xu","Jingyuan Huang","Minghao Guo","Qifan Wang","Kaixiong Zhou","Yongfeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.03313v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03308v1","updated":"2025-03-05T09:41:03Z","published":"2025-03-05T09:41:03Z","title":"The Box is in the Pen: Evaluating Commonsense Reasoning in Neural\n  Machine Translation","summary":"  Does neural machine translation yield translations that are congenial with\ncommon sense? In this paper, we present a test suite to evaluate the\ncommonsense reasoning capability of neural machine translation. The test suite\nconsists of three test sets, covering lexical and contextless/contextual\nsyntactic ambiguity that requires commonsense knowledge to resolve. We manually\ncreate 1,200 triples, each of which contain a source sentence and two\ncontrastive translations, involving 7 different common sense types. Language\nmodels pretrained on large-scale corpora, such as BERT, GPT-2, achieve a\ncommonsense reasoning accuracy of lower than 72% on target translations of this\ntest suite. We conduct extensive experiments on the test suite to evaluate\ncommonsense reasoning in neural machine translation and investigate factors\nthat have impact on this capability. Our experiments and analyses demonstrate\nthat neural machine translation performs poorly on commonsense reasoning of the\nthree ambiguity types in terms of both reasoning accuracy (60.1%) and reasoning\nconsistency (31%). The built commonsense test suite is available at\nhttps://github.com/tjunlp-lab/CommonMT.\n","authors":["Jie He","Tao Wang","Deyi Xiong","Qun Liu"],"pdf_url":"https://arxiv.org/pdf/2503.03308v1.pdf","comment":"EMNLP findings 2020"},{"id":"http://arxiv.org/abs/2503.03303v1","updated":"2025-03-05T09:37:05Z","published":"2025-03-05T09:37:05Z","title":"SEOE: A Scalable and Reliable Semantic Evaluation Framework for Open\n  Domain Event Detection","summary":"  Automatic evaluation for Open Domain Event Detection (ODED) is a highly\nchallenging task, because ODED is characterized by a vast diversity of\nun-constrained output labels from various domains. Nearly all existing\nevaluation methods for ODED usually first construct evaluation benchmarks with\nlimited labels and domain coverage, and then evaluate ODED methods using\nmetrics based on token-level label matching rules. However, this kind of\nevaluation framework faces two issues: (1) The limited evaluation benchmarks\nlack representatives of the real world, making it difficult to accurately\nreflect the performance of various ODED methods in real-world scenarios; (2)\nEvaluation metrics based on token-level matching rules fail to capture semantic\nsimilarity between predictions and golden labels. To address these two problems\nabove, we propose a scalable and reliable Semantic-level Evaluation framework\nfor Open domain Event detection (SEOE) by constructing a more representative\nevaluation benchmark and introducing a semantic evaluation metric.\nSpecifically, our proposed framework first constructs a scalable evaluation\nbenchmark that currently includes 564 event types covering 7 major domains,\nwith a cost-effective supplementary annotation strategy to ensure the\nbenchmark's representativeness. The strategy also allows for the supplement of\nnew event types and domains in the future. Then, the proposed SEOE leverages\nlarge language models (LLMs) as automatic evaluation agents to compute a\nsemantic F1-score, incorporating fine-grained definitions of semantically\nsimilar labels to enhance the reliability of the evaluation. Extensive\nexperiments validate the representatives of the benchmark and the reliability\nof the semantic evaluation metric. Existing ODED methods are thoroughly\nevaluated, and the error patterns of predictions are analyzed, revealing\nseveral insightful findings.\n","authors":["Yi-Fan Lu","Xian-Ling Mao","Tian Lan","Tong Zhang","Yu-Shi Zhu","Heyan Huang"],"pdf_url":"https://arxiv.org/pdf/2503.03303v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.11123v2","updated":"2025-03-05T09:36:34Z","published":"2025-02-16T13:42:48Z","title":"DuplexMamba: Enhancing Real-time Speech Conversations with Duplex and\n  Streaming Capabilities","summary":"  Real-time speech conversation is essential for natural and efficient\nhuman-machine interactions, requiring duplex and streaming capabilities.\nTraditional Transformer-based conversational chatbots operate in a turn-based\nmanner and exhibit quadratic computational complexity that grows as the input\nsize increases. In this paper, we propose DuplexMamba, a Mamba-based end-to-end\nmultimodal duplex model for speech-to-text conversation. DuplexMamba enables\nsimultaneous input processing and output generation, dynamically adjusting to\nsupport real-time streaming. Specifically, we develop a Mamba-based speech\nencoder and adapt it with a Mamba-based language model. Furthermore, we\nintroduce a novel duplex decoding strategy that enables DuplexMamba to process\ninput and generate output simultaneously. Experimental results demonstrate that\nDuplexMamba successfully implements duplex and streaming capabilities while\nachieving performance comparable to several recently developed\nTransformer-based models in automatic speech recognition (ASR) tasks and voice\nassistant benchmark evaluations. Our code and model are released\n","authors":["Xiangyu Lu","Wang Xu","Haoyu Wang","Hongyun Zhou","Haiyan Zhao","Conghui Zhu","Tiejun Zhao","Muyun Yang"],"pdf_url":"https://arxiv.org/pdf/2502.11123v2.pdf","comment":"12 pages, 6 figures"},{"id":"http://arxiv.org/abs/2406.12221v5","updated":"2025-03-05T09:34:06Z","published":"2024-06-18T02:43:49Z","title":"On-Policy Self-Alignment with Fine-grained Knowledge Feedback for\n  Hallucination Mitigation","summary":"  Hallucination occurs when large language models exhibit behavior that\ndeviates from the boundaries of their knowledge during response generation. To\naddress this critical issue, previous learning-based methods attempt to\nfinetune models but are limited by off-policy sampling and coarse-grained\nfeedback. In this paper, we present \\textit{\\b{R}einforcement \\b{L}earning\n\\b{f}or \\b{H}allucination} (RLFH), an on-policy self-alignment approach that\nenables LLMs to actively explore their knowledge boundaries and self-correct\ngeneration behavior through fine-grained feedback signals. RLFH introduces a\nself-assessment framework where the policy serves as its own judge. Through\nthis framework, responses are automatically decomposed into atomic facts and\ntheir truthfulness and informativeness are assessed against external knowledge\nsources. The resulting fine-grained feedback at the statement level are then\nconverted into token-level dense reward signals. This enables online\nreinforcement learning to achieve precise and timely optimization without human\nintervention. Comprehensive evaluations on HotpotQA, SQuADv2, and Biography\nbenchmarks validate RLFH's effectiveness in hallucination mitigation.\n","authors":["Xueru Wen","Jie Lou","Xinyu Lu","Ji Yuqiu","Xinyan Guan","Yaojie Lu","Hongyu Lin","Ben He","Xianpei Han","Debing Zhang","Le Sun"],"pdf_url":"https://arxiv.org/pdf/2406.12221v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03300v1","updated":"2025-03-05T09:31:49Z","published":"2025-03-05T09:31:49Z","title":"Which books do I like?","summary":"  Finding enjoyable fiction books can be challenging, partly because stories\nare multi-faceted and one's own literary taste might be difficult to ascertain.\nHere, we introduce the ISAAC method (Introspection-Support, AI-Annotation, and\nCuration), a pipeline which supports fiction readers in gaining awareness of\ntheir literary preferences and finding enjoyable books. ISAAC consists of four\nsteps: a user supplies book ratings, an AI agent researches and annotates the\nprovided books, patterns in book enjoyment are reviewed by the user, and the AI\nagent recommends new books. In this proof-of-concept self-study, the authors\ntest whether ISAAC can highlight idiosyncratic patterns in their book\nenjoyment, spark a deeper reflection about their literary tastes, and make\naccurate, personalized recommendations of enjoyable books and underexplored\nliterary niches. Results highlight substantial advantages of ISAAC over\nexisting methods such as an integration of automation and intuition, accurate\nand customizable annotations, and explainable book recommendations. Observed\ndisadvantages are that ISAAC's outputs can elicit false self-narratives (if\nstatistical patterns are taken at face value), that books cannot be annotated\nif their online documentation is lacking, and that people who are new to\nreading have to rely on assumed book ratings or movie ratings to power the\nISAAC pipeline. We discuss additional opportunities of ISAAC-style book\nannotations for the study of literary trends, and the scientific classification\nof books and readers.\n","authors":["Hannes Rosenbusch","Erdem Ozan Meral"],"pdf_url":"https://arxiv.org/pdf/2503.03300v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.05891v2","updated":"2025-03-05T09:18:31Z","published":"2025-01-10T11:44:35Z","title":"Affordably Fine-tuned LLMs Provide Better Answers to Course-specific\n  MCQs","summary":"  In education, the capability of generating human-like text of Large Language\nModels (LLMs) inspired work on how they can increase the efficiency of learning\nand teaching. We study the affordability of these models for educators and\nstudents by investigating how LLMs answer multiple-choice questions (MCQs) with\nrespect to hardware constraints and refinement techniques. We explore this\nspace by using generic pre-trained LLMs (the 7B, 13B, and 70B variants of\nLLaMA-2) to answer 162 undergraduate-level MCQs from a course on Programming\nLanguages (PL) -- the MCQ dataset is a contribution of this work, which we make\npublicly available. Specifically, we dissect how different factors, such as\nusing readily-available material -- (parts of) the course's textbook -- for\nfine-tuning and quantisation (to decrease resource usage) can change the\naccuracy of the responses. The main takeaway is that smaller textbook-based\nfine-tuned models outperform generic larger ones (whose pre-training requires\nconspicuous resources), making the usage of LLMs for answering MCQs resource-\nand material-wise affordable.\n","authors":["Bianca Raimondi","Saverio Giallorenzo","Maurizio Gabbrielli"],"pdf_url":"https://arxiv.org/pdf/2501.05891v2.pdf","comment":"The 40th ACM/SIGAPP Symposium On Applied Computing"},{"id":"http://arxiv.org/abs/2503.02368v2","updated":"2025-03-05T09:12:25Z","published":"2025-03-04T07:49:10Z","title":"Iterative Value Function Optimization for Guided Decoding","summary":"  While Reinforcement Learning from Human Feedback (RLHF) has become the\npredominant method for controlling language model outputs, it suffers from high\ncomputational costs and training instability. Guided decoding, especially\nvalue-guided methods, offers a cost-effective alternative by controlling\noutputs without re-training models. However, the accuracy of the value function\nis crucial for value-guided decoding, as inaccuracies can lead to suboptimal\ndecision-making and degraded performance. Existing methods struggle with\naccurately estimating the optimal value function, leading to less effective\ncontrol. We propose Iterative Value Function Optimization, a novel framework\nthat addresses these limitations through two key components: Monte Carlo Value\nEstimation, which reduces estimation variance by exploring diverse\ntrajectories, and Iterative On-Policy Optimization, which progressively\nimproves value estimation through collecting trajectories from value-guided\npolicies. Extensive experiments on text summarization, multi-turn dialogue, and\ninstruction following demonstrate the effectiveness of value-guided decoding\napproaches in aligning language models. These approaches not only achieve\nalignment but also significantly reduce computational costs by leveraging\nprincipled value function optimization for efficient and effective control.\n","authors":["Zhenhua Liu","Lijun Li","Ruizhe Chen","Yuxian Jiang","Tong Zhu","Zhaochen Su","Wenliang Chen","Jing Shao"],"pdf_url":"https://arxiv.org/pdf/2503.02368v2.pdf","comment":"20 pages, 10 figures"},{"id":"http://arxiv.org/abs/2503.03278v1","updated":"2025-03-05T09:02:33Z","published":"2025-03-05T09:02:33Z","title":"Enhancing Abnormality Grounding for Vision Language Models with\n  Knowledge Descriptions","summary":"  Visual Language Models (VLMs) have demonstrated impressive capabilities in\nvisual grounding tasks. However, their effectiveness in the medical domain,\nparticularly for abnormality detection and localization within medical images,\nremains underexplored. A major challenge is the complex and abstract nature of\nmedical terminology, which makes it difficult to directly associate\npathological anomaly terms with their corresponding visual features. In this\nwork, we introduce a novel approach to enhance VLM performance in medical\nabnormality detection and localization by leveraging decomposed medical\nknowledge. Instead of directly prompting models to recognize specific\nabnormalities, we focus on breaking down medical concepts into fundamental\nattributes and common visual patterns. This strategy promotes a stronger\nalignment between textual descriptions and visual features, improving both the\nrecognition and localization of abnormalities in medical images.We evaluate our\nmethod on the 0.23B Florence-2 base model and demonstrate that it achieves\ncomparable performance in abnormality grounding to significantly larger 7B\nLLaVA-based medical VLMs, despite being trained on only 1.5% of the data used\nfor such models. Experimental results also demonstrate the effectiveness of our\napproach in both known and previously unseen abnormalities, suggesting its\nstrong generalization capabilities.\n","authors":["Jun Li","Che Liu","Wenjia Bai","Rossella Arcucci","Cosmin I. Bercea","Julia A. Schnabel"],"pdf_url":"https://arxiv.org/pdf/2503.03278v1.pdf","comment":"11 pages, 3 figures"},{"id":"http://arxiv.org/abs/2503.03266v1","updated":"2025-03-05T08:49:28Z","published":"2025-03-05T08:49:28Z","title":"LexGenie: Automated Generation of Structured Reports for European Court\n  of Human Rights Case Law","summary":"  Analyzing large volumes of case law to uncover evolving legal principles,\nacross multiple cases, on a given topic is a demanding task for legal\nprofessionals. Structured topical reports provide an effective solution by\nsummarizing key issues, principles, and judgments, enabling comprehensive legal\nanalysis on a particular topic. While prior works have advanced query-based\nindividual case summarization, none have extended to automatically generating\nmulti-case structured reports. To address this, we introduce LexGenie, an\nautomated LLM-based pipeline designed to create structured reports using the\nentire body of case law on user-specified topics within the European Court of\nHuman Rights jurisdiction. LexGenie retrieves, clusters, and organizes relevant\npassages by topic to generate a structured outline and cohesive content for\neach section. Expert evaluation confirms LexGenie's utility in producing\nstructured reports that enhance efficient, scalable legal analysis.\n","authors":["T. Y. S. S Santosh","Mahmoud Aly","Oana Ichim","Matthias Grabmair"],"pdf_url":"https://arxiv.org/pdf/2503.03266v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.09977v2","updated":"2025-03-05T08:48:25Z","published":"2025-02-14T08:04:22Z","title":"LaRA: Benchmarking Retrieval-Augmented Generation and Long-Context LLMs\n  -- No Silver Bullet for LC or RAG Routing","summary":"  Effectively incorporating external knowledge into Large Language Models\n(LLMs) is crucial for enhancing their capabilities and addressing real-world\nneeds. Retrieval-Augmented Generation (RAG) offers an effective method for\nachieving this by retrieving the most relevant fragments into LLMs. However,\nthe advancements in context window size for LLMs offer an alternative approach,\nraising the question of whether RAG remains necessary for effectively handling\nexternal knowledge. Several existing studies provide inconclusive comparisons\nbetween RAG and long-context (LC) LLMs, largely due to limitations in the\nbenchmark designs. In this paper, we present LaRA, a novel benchmark\nspecifically designed to rigorously compare RAG and LC LLMs. LaRA encompasses\n2326 test cases across four practical QA task categories and three types of\nnaturally occurring long texts. Through systematic evaluation of seven\nopen-source and four proprietary LLMs, we find that the optimal choice between\nRAG and LC depends on a complex interplay of factors, including the model's\nparameter size, long-text capabilities, context length, task type, and the\ncharacteristics of the retrieved chunks. Our findings provide actionable\nguidelines for practitioners to effectively leverage both RAG and LC approaches\nin developing and deploying LLM applications. Our code and dataset is provided\nat:\n\\href{https://github.com/Alibaba-NLP/LaRA}{\\textbf{https://github.com/Alibaba-NLP/LaRA}}.\n","authors":["Kuan Li","Liwen Zhang","Yong Jiang","Pengjun Xie","Fei Huang","Shuai Wang","Minhao Cheng"],"pdf_url":"https://arxiv.org/pdf/2502.09977v2.pdf","comment":"22 pages"},{"id":"http://arxiv.org/abs/2412.06464v2","updated":"2025-03-05T08:47:27Z","published":"2024-12-09T13:09:04Z","title":"Gated Delta Networks: Improving Mamba2 with Delta Rule","summary":"  Linear Transformers have gained attention as efficient alternatives to\nstandard Transformers, but their performance in retrieval and long-context\ntasks has been limited. To address these limitations, recent work has explored\ntwo distinct mechanisms: gating for adaptive memory control and the delta\nupdate rule for precise memory modifications. We observe that these mechanisms\nare complementary: gating enables rapid memory erasure while the delta rule\nfacilitates targeted updates. Building on this insight, we introduce the gated\ndelta rule and develop a parallel training algorithm optimized for modern\nhardware. Our proposed architecture, Gated DeltaNet, consistently surpasses\nexisting models like Mamba2 and DeltaNet across multiple benchmarks, including\nlanguage modeling, common-sense reasoning, in-context retrieval, length\nextrapolation, and long-context understanding. We further enhance performance\nby developing hybrid architectures that combine Gated DeltaNet layers with\nsliding window attention or Mamba2 layers, achieving both improved training\nefficiency and superior task performance.\n","authors":["Songlin Yang","Jan Kautz","Ali Hatamizadeh"],"pdf_url":"https://arxiv.org/pdf/2412.06464v2.pdf","comment":"ICLR 2025 camera ready"},{"id":"http://arxiv.org/abs/2503.03261v1","updated":"2025-03-05T08:37:10Z","published":"2025-03-05T08:37:10Z","title":"Can Frontier LLMs Replace Annotators in Biomedical Text Mining?\n  Analyzing Challenges and Exploring Solutions","summary":"  Large language models (LLMs) can perform various natural language processing\n(NLP) tasks through in-context learning without relying on supervised data.\nHowever, multiple previous studies have reported suboptimal performance of LLMs\nin biological text mining. By analyzing failure patterns in these evaluations,\nwe identified three primary challenges for LLMs in biomedical corpora: (1) LLMs\nfail to learn implicit dataset-specific nuances from supervised data, (2) The\ncommon formatting requirements of discriminative tasks limit the reasoning\ncapabilities of LLMs particularly for LLMs that lack test-time compute, and (3)\nLLMs struggle to adhere to annotation guidelines and match exact schemas, which\nhinders their ability to understand detailed annotation requirements which is\nessential in biomedical annotation workflow. To address these challenges, we\nexperimented with prompt engineering techniques targeted to the above issues,\nand developed a pipeline that dynamically extracts instructions from annotation\nguidelines. Our findings show that frontier LLMs can approach or surpass the\nperformance of state-of-the-art (SOTA) BERT-based models with minimal reliance\non manually annotated data and without fine-tuning. Furthermore, we performed\nmodel distillation on a closed-source LLM, demonstrating that a BERT model\ntrained exclusively on synthetic data annotated by LLMs can also achieve a\npractical performance. Based on these results, we explored the feasibility of\npartially replacing manual annotation with LLMs in production scenarios for\nbiomedical text mining.\n","authors":["Yichong Zhao","Susumu Goto"],"pdf_url":"https://arxiv.org/pdf/2503.03261v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.12671v2","updated":"2025-03-05T08:23:04Z","published":"2025-02-18T09:21:12Z","title":"Baichuan-M1: Pushing the Medical Capability of Large Language Models","summary":"  The current generation of large language models (LLMs) is typically designed\nfor broad, general-purpose applications, while domain-specific LLMs, especially\nin vertical fields like medicine, remain relatively scarce. In particular, the\ndevelopment of highly efficient and practical LLMs for the medical domain is\nchallenging due to the complexity of medical knowledge and the limited\navailability of high-quality data. To bridge this gap, we introduce\nBaichuan-M1, a series of large language models specifically optimized for\nmedical applications. Unlike traditional approaches that simply continue\npretraining on existing models or apply post-training to a general base model,\nBaichuan-M1 is trained from scratch with a dedicated focus on enhancing medical\ncapabilities. Our model is trained on 20 trillion tokens and incorporates a\nrange of effective training methods that strike a balance between general\ncapabilities and medical expertise. As a result, Baichuan-M1 not only performs\nstrongly across general domains such as mathematics and coding but also excels\nin specialized medical fields. We have open-sourced Baichuan-M1-14B, a mini\nversion of our model, which can be accessed through the following links.\n","authors":["Bingning Wang","Haizhou Zhao","Huozhi Zhou","Liang Song","Mingyu Xu","Wei Cheng","Xiangrong Zeng","Yupeng Zhang","Yuqi Huo","Zecheng Wang","Zhengyun Zhao","Da Pan","Fei Kou","Fei Li","Fuzhong Chen","Guosheng Dong","Han Liu","Hongda Zhang","Jin He","Jinjie Yang","Kangxi Wu","Kegeng Wu","Lei Su","Linlin Niu","Linzhuang Sun","Mang Wang","Pengcheng Fan","Qianli Shen","Rihui Xin","Shunya Dang","Songchi Zhou","Weipeng Chen","Wenjing Luo","Xin Chen","Xin Men","Xionghai Lin","Xuezhen Dong","Yan Zhang","Yifei Duan","Yuyan Zhou","Zhi Ma","Zhiying Wu"],"pdf_url":"https://arxiv.org/pdf/2502.12671v2.pdf","comment":"33 pages, technical report"},{"id":"http://arxiv.org/abs/2403.07714v5","updated":"2025-03-05T07:39:03Z","published":"2024-03-12T14:57:40Z","title":"StableToolBench: Towards Stable Large-Scale Benchmarking on Tool\n  Learning of Large Language Models","summary":"  Large Language Models (LLMs) have witnessed remarkable advancements in recent\nyears, prompting the exploration of tool learning, which integrates LLMs with\nexternal tools to address diverse real-world challenges. Assessing the\ncapability of LLMs to utilise tools necessitates large-scale and stable\nbenchmarks. However, previous works relied on either hand-crafted online tools\nwith limited scale, or large-scale real online APIs suffering from instability\nof API status. To address this problem, we introduce StableToolBench, a\nbenchmark evolving from ToolBench, proposing a virtual API server and stable\nevaluation system. The virtual API server contains a caching system and API\nsimulators which are complementary to alleviate the change in API status.\nMeanwhile, the stable evaluation system designs solvable pass and win rates\nusing GPT-4 as the automatic evaluator to eliminate the randomness during\nevaluation. Experimental results demonstrate the stability of StableToolBench,\nand further discuss the effectiveness of API simulators, the caching system,\nand the evaluator system.\n","authors":["Zhicheng Guo","Sijie Cheng","Hao Wang","Shihao Liang","Yujia Qin","Peng Li","Zhiyuan Liu","Maosong Sun","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2403.07714v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03238v1","updated":"2025-03-05T07:34:53Z","published":"2025-03-05T07:34:53Z","title":"FANS -- Formal Answer Selection for Natural Language Math Reasoning\n  Using Lean4","summary":"  Large Language Models (LLMs) have displayed astonishing abilities in various\ntasks, especially in text generation, classification, question answering, etc.\nHowever, the reasoning ability of LLMs still faces many debates. The inherent\nambiguity of Natural Language (NL) limits LLMs' ability to perform verifiable\nreasoning, making its answers lack coherence and trustworthy support. To tackle\nthe above problems, we propose a novel framework named FANS: Formal ANswer\nSelection for Natural Language Math Reasoning Using Lean4. To the best of our\nknowledge, it is the first framework that utilizes Lean4 to enhance LLMs' NL\nmath reasoning ability. In particular, given an NL math question and\nLLM-generated answers, FANS first translates it into Lean4 theorem statements.\nThen it tries to prove it using a Lean4 prover and verify it by Lean4. Finally,\nit uses the FL result to assist in answer selection. It enhances LLMs' NL math\nability in providing a computer-verifiable solution for its correct answer and\nproposes an alternative method for answer selection beyond the reward model.\nExtensive experiments indicate the effectiveness of our framework. It can\nimprove the accuracy rate of reward model enhanced LLMs in the MATH-500 dataset\nby at most 1.91% and AMC-23 by at most 8.33% on strong reward-model baselines.\nIn some particular fields like number theory that Lean4 experts in, we can even\nselect all correct solutions. The qualitative analysis also shows our framework\ncan make NL results formally backed by Lean4 proofs. As a pioneering work in\nthe corresponding field, we will open-source all our models and datasets to\nfurther boost the development of the field.\n","authors":["Jiarui Yao","Ruida Wang","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.03238v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09601v2","updated":"2025-03-05T07:06:15Z","published":"2024-12-12T18:59:11Z","title":"TimeRefine: Temporal Grounding with Time Refining Video LLM","summary":"  Video temporal grounding aims to localize relevant temporal boundaries in a\nvideo given a textual prompt. Recent work has focused on enabling Video LLMs to\nperform video temporal grounding via next-token prediction of temporal\ntimestamps. However, accurately localizing timestamps in videos remains\nchallenging for Video LLMs when relying solely on temporal token prediction.\nOur proposed TimeRefine addresses this challenge in two ways. First, instead of\ndirectly predicting the start and end timestamps, we reformulate the temporal\ngrounding task as a temporal refining task: the model first makes rough\npredictions and then refines them by predicting offsets to the target segment.\nThis refining process is repeated multiple times, through which the model\nprogressively self-improves its temporal localization accuracy. Second, to\nenhance the model's temporal perception capabilities, we incorporate an\nauxiliary prediction head that penalizes the model more if a predicted segment\ndeviates further from the ground truth, thus encouraging the model to make\ncloser and more accurate predictions. Our plug-and-play method can be\nintegrated into most LLM-based temporal grounding approaches. The experimental\nresults demonstrate that TimeRefine achieves 3.6% and 5.0% mIoU improvements on\nthe ActivityNet and Charades-STA datasets, respectively. Code and pretrained\nmodels will be released.\n","authors":["Xizi Wang","Feng Cheng","Ziyang Wang","Huiyu Wang","Md Mohaiminul Islam","Lorenzo Torresani","Mohit Bansal","Gedas Bertasius","David Crandall"],"pdf_url":"https://arxiv.org/pdf/2412.09601v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.17543v2","updated":"2025-03-05T06:53:52Z","published":"2025-02-24T18:56:58Z","title":"Training a Generally Curious Agent","summary":"  Efficient exploration is essential for intelligent systems interacting with\ntheir environment, but existing language models often fall short in scenarios\nthat require strategic information gathering. In this paper, we present\nPAPRIKA, a fine-tuning approach that enables language models to develop general\ndecision-making capabilities that are not confined to particular environments.\nBy training on synthetic interaction data from different tasks that require\ndiverse strategies, PAPRIKA teaches models to explore and adapt their behavior\non a new task based on environment feedback in-context without more gradient\nupdates. Experimental results show that models fine-tuned with PAPRIKA can\neffectively transfer their learned decision-making capabilities to entirely\nunseen tasks without additional training. Unlike traditional training, our\napproach's primary bottleneck lies in sampling useful interaction data instead\nof model updates. To improve sample efficiency, we propose a curriculum\nlearning strategy that prioritizes sampling trajectories from tasks with high\nlearning potential. These results suggest a promising path towards AI systems\nthat can autonomously solve novel sequential decision-making problems that\nrequire interactions with the external world.\n","authors":["Fahim Tajwar","Yiding Jiang","Abitha Thankaraj","Sumaita Sadia Rahman","J Zico Kolter","Jeff Schneider","Ruslan Salakhutdinov"],"pdf_url":"https://arxiv.org/pdf/2502.17543v2.pdf","comment":"Project Website: https://paprika-llm.github.io"},{"id":"http://arxiv.org/abs/2503.03225v1","updated":"2025-03-05T06:45:25Z","published":"2025-03-05T06:45:25Z","title":"Targeted Distillation for Sentiment Analysis","summary":"  This paper presents a compact model that achieves strong sentiment analysis\ncapabilities through targeted distillation from advanced large language models\n(LLMs). Our methodology decouples the distillation target into two key\ncomponents: sentiment-related knowledge and task alignment. To transfer these\ncomponents, we propose a two-stage distillation framework. The first stage,\nknowledge-driven distillation (\\textsc{KnowDist}), transfers sentiment-related\nknowledge to enhance fundamental sentiment analysis capabilities. The second\nstage, in-context learning distillation (\\textsc{ICLDist}), transfers\ntask-specific prompt-following abilities to optimize task alignment. For\nevaluation, we introduce \\textsc{SentiBench}, a comprehensive sentiment\nanalysis benchmark comprising 3 task categories across 12 datasets. Experiments\non this benchmark demonstrate that our model effectively balances model size\nand performance, showing strong competitiveness compared to existing\nsmall-scale LLMs.\n","authors":["Yice Zhang","Guangyu Xie","Jingjie Lin","Jianzhu Bao","Qianlong Wang","Xi Zeng","Ruifeng Xu"],"pdf_url":"https://arxiv.org/pdf/2503.03225v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.14494v3","updated":"2025-03-05T06:32:04Z","published":"2024-09-13T19:14:18Z","title":"CPT-Boosted Wav2vec2.0: Towards Noise Robust Speech Recognition for\n  Classroom Environments","summary":"  Creating Automatic Speech Recognition (ASR) systems that are robust and\nresilient to classroom conditions is paramount to the development of AI tools\nto aid teachers and students. In this work, we study the efficacy of continued\npretraining (CPT) in adapting Wav2vec2.0 to the classroom domain. We show that\nCPT is a powerful tool in that regard and reduces the Word Error Rate (WER) of\nWav2vec2.0-based models by upwards of 10%. More specifically, CPT improves the\nmodel's robustness to different noises, microphones and classroom conditions.\n","authors":["Ahmed Adel Attia","Dorottya Demszky","Tolulope Ogunremi","Jing Liu","Carol Espy-Wilson"],"pdf_url":"https://arxiv.org/pdf/2409.14494v3.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2405.13018"},{"id":"http://arxiv.org/abs/2408.08927v2","updated":"2025-03-05T06:23:52Z","published":"2024-08-15T20:06:06Z","title":"VerilogCoder: Autonomous Verilog Coding Agents with Graph-based Planning\n  and Abstract Syntax Tree (AST)-based Waveform Tracing Tool","summary":"  Due to the growing complexity of modern Integrated Circuits (ICs), automating\nhardware design can prevent a significant amount of human error from the\nengineering process and result in less errors. Verilog is a popular hardware\ndescription language for designing and modeling digital systems; thus, Verilog\ngeneration is one of the emerging areas of research to facilitate the design\nprocess. In this work, we propose VerilogCoder, a system of multiple Artificial\nIntelligence (AI) agents for Verilog code generation, to autonomously write\nVerilog code and fix syntax and functional errors using collaborative Verilog\ntools (i.e., syntax checker, simulator, and waveform tracer). Firstly, we\npropose a task planner that utilizes a novel Task and Circuit Relation Graph\nretrieval method to construct a holistic plan based on module descriptions. To\ndebug and fix functional errors, we develop a novel and efficient abstract\nsyntax tree (AST)-based waveform tracing tool, which is integrated within the\nautonomous Verilog completion flow. The proposed methodology successfully\ngenerates 94.2% syntactically and functionally correct Verilog code, surpassing\nthe state-of-the-art methods by 33.9% on the VerilogEval-Human v2 benchmark.\n","authors":["Chia-Tung Ho","Haoxing Ren","Brucek Khailany"],"pdf_url":"https://arxiv.org/pdf/2408.08927v2.pdf","comment":"main paper 7 pages, reference 1 page, it is the version that accepted\n  by AAAI 2025"},{"id":"http://arxiv.org/abs/2502.16802v2","updated":"2025-03-05T06:23:22Z","published":"2025-02-24T03:25:56Z","title":"Unsupervised Topic Models are Data Mixers for Pre-training Language\n  Models","summary":"  The performance of large language models (LLMs) is significantly affected by\nthe quality and composition of their pre-training data, which is inherently\ndiverse, spanning various domains, sources, and topics. Effectively integrating\nthese heterogeneous data sources is crucial for optimizing LLM performance.\nPrevious research has predominantly concentrated on domain-based data mixing,\noften neglecting the nuanced topic-level characteristics of the data. To\naddress this gap, we propose a simple yet effective topic-based data mixing\nstrategy that utilizes fine-grained topics generated through our topic modeling\nmethod, DataWeave. DataWeave employs a multi-stage clustering process to group\nsemantically similar documents and utilizes LLMs to generate detailed topics,\nthereby facilitating a more nuanced understanding of dataset composition. Our\nstrategy employs heuristic methods to upsample or downsample specific topics,\nwhich significantly enhances LLM performance on downstream tasks, achieving\nsuperior results compared to previous, more complex data mixing approaches.\nFurthermore, we confirm that the topics Science and Relationships are\nparticularly effective, yielding the most substantial performance improvements.\nWe will make our code and datasets publicly available.\n","authors":["Jiahui Peng","Xinlin Zhuang","Qiu Jiantao","Ren Ma","Jing Yu","Tianyi Bai","Conghui He"],"pdf_url":"https://arxiv.org/pdf/2502.16802v2.pdf","comment":"18 pages,7 figures"},{"id":"http://arxiv.org/abs/2503.02445v2","updated":"2025-03-05T06:04:37Z","published":"2025-03-04T09:40:00Z","title":"BRIDGE: Bootstrapping Text to Control Time-Series Generation via\n  Multi-Agent Iterative Optimization and Diffusion Modelling","summary":"  Time-series Generation (TSG) is a prominent research area with broad\napplications in simulations, data augmentation, and counterfactual analysis.\nWhile existing methods have shown promise in unconditional single-domain TSG,\nreal-world applications demand for cross-domain approaches capable of\ncontrolled generation tailored to domain-specific constraints and\ninstance-level requirements. In this paper, we argue that text can provide\nsemantic insights, domain information and instance-specific temporal patterns,\nto guide and improve TSG. We introduce ``Text-Controlled TSG'', a task focused\non generating realistic time series by incorporating textual descriptions. To\naddress data scarcity in this setting, we propose a novel LLM-based Multi-Agent\nframework that synthesizes diverse, realistic text-to-TS datasets. Furthermore,\nwe introduce BRIDGE, a hybrid text-controlled TSG framework that integrates\nsemantic prototypes with text description for supporting domain-level guidance.\nThis approach achieves state-of-the-art generation fidelity on 11 of 12\ndatasets, and improves controllability by 12.52% on MSE and 6.34% MAE compared\nto no text input generation, highlighting its potential for generating tailored\ntime-series data.\n","authors":["Hao Li","Yu-Hao Huang","Chang Xu","Viktor Schlegel","Ren-He Jiang","Riza Batista-Navarro","Goran Nenadic","Jiang Bian"],"pdf_url":"https://arxiv.org/pdf/2503.02445v2.pdf","comment":"Preprint. Work in progress"},{"id":"http://arxiv.org/abs/2503.01711v3","updated":"2025-03-05T05:52:00Z","published":"2025-03-03T16:24:36Z","title":"MAPS: Motivation-Aware Personalized Search via LLM-Driven Consultation\n  Alignment","summary":"  Personalized product search aims to retrieve and rank items that match users'\npreferences and search intent. Despite their effectiveness, existing approaches\ntypically assume that users' query fully captures their real motivation.\nHowever, our analysis of a real-world e-commerce platform reveals that users\noften engage in relevant consultations before searching, indicating they refine\nintents through consultations based on motivation and need. The implied\nmotivation in consultations is a key enhancing factor for personalized search.\nThis unexplored area comes with new challenges including aligning contextual\nmotivations with concise queries, bridging the category-text gap, and filtering\nnoise within sequence history. To address these, we propose a Motivation-Aware\nPersonalized Search (MAPS) method. It embeds queries and consultations into a\nunified semantic space via LLMs, utilizes a Mixture of Attention Experts (MoAE)\nto prioritize critical semantics, and introduces dual alignment: (1)\ncontrastive learning aligns consultations, reviews, and product features; (2)\nbidirectional attention integrates motivation-aware embeddings with user\npreferences. Extensive experiments on real and synthetic data show MAPS\noutperforms existing methods in both retrieval and ranking tasks.\n","authors":["Weicong Qin","Yi Xu","Weijie Yu","Chenglei Shen","Ming He","Jianping Fan","Xiao Zhang","Jun Xu"],"pdf_url":"https://arxiv.org/pdf/2503.01711v3.pdf","comment":"added project repository & dataset URL"},{"id":"http://arxiv.org/abs/2503.03205v1","updated":"2025-03-05T05:50:31Z","published":"2025-03-05T05:50:31Z","title":"MA-LoT: Multi-Agent Lean-based Long Chain-of-Thought Reasoning enhances\n  Formal Theorem Proving","summary":"  Solving mathematical problems using computer-verifiable languages like Lean\nhas significantly impacted mathematical and computer science communities.\nState-of-the-art methods utilize single Large Language Models (LLMs) as agents\nor provers to either generate complete proof or perform tree searches. However,\nsingle-agent methods inherently lack a structured way to combine high-level\nreasoning in Natural Language (NL) with Formal Language (FL) verification\nfeedback. To solve these issues, we propose MA-LoT: Multi-Agent Lean-based Long\nChain-of-Thought framework, (to the best of our knowledge), the first\nmulti-agent framework for Lean4 theorem proving that balance high-level NL\nreasoning and FL verification in Long CoT. Using this structured interaction,\nour approach enables deeper insights and long-term coherence in proof\ngeneration, with which past methods struggle. We do this by leveraging emergent\nformal reasoning ability in Long CoT using our novel LoT-Transfer Learning\ntraining-inference pipeline. Extensive experiments show that our framework\nachieves 54.51% accuracy rate on the Lean4 version of MiniF2F-Test dataset,\nlargely outperforming GPT-4 (22.95%), single-agent tree search\n(InternLM-Step-Prover, 50.70%), and whole-proof generation\n(DeepSeek-Prover-v1.5, 48.36%) baselines. Furthermore, our findings highlight\nthe potential of combining Long CoT with formal verification for a more\ninsightful generation in a broader perspective.\n","authors":["Ruida Wang","Rui Pan","Yuxin Li","Jipeng Zhang","Yizhen Jia","Shizhe Diao","Renjie Pi","Junjie Hu","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.03205v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.17927v2","updated":"2025-03-05T05:46:28Z","published":"2025-02-25T07:47:22Z","title":"Advantage-Guided Distillation for Preference Alignment in Small Language\n  Models","summary":"  Alignment techniques enable Large Language Models (LLMs) to generate outputs\nthat align with human preferences and play a crucial role in their\neffectiveness. However, their impact often diminishes when applied to Small\nLanguage Models (SLMs), likely due to the limited capacity of these models.\nInstead of directly applying existing alignment techniques to SLMs, we propose\nto utilize a well-aligned teacher LLM to guide the alignment process for these\nmodels, thereby facilitating the transfer of the teacher's knowledge of human\npreferences to the student model. To achieve this, we first explore a\nstraightforward approach, Dual-Constrained Knowledge Distillation (DCKD), that\nemploys knowledge distillation with two KL-divergence constraints from the\naligned teacher to the unaligned student. To further enhance the student's\nability to distinguish between preferred and dispreferred responses, we then\npropose Advantage-Guided Distillation for Preference Alignment (ADPA), which\nleverages an advantage function from the aligned teacher to deliver more\nnuanced, distribution-level reward signals for the student's alignment. Our\nexperimental results show that these two approaches appreciably improve the\nalignment of SLMs and narrow the performance gap with larger counterparts.\nAmong them, ADPA demonstrates superior performance and achieves even greater\neffectiveness when integrated with DCKD. Our code is available at\nhttps://github.com/SLIT-AI/ADPA.\n","authors":["Shiping Gao","Fanqi Wan","Jiajian Guo","Xiaojun Quan","Qifan Wang"],"pdf_url":"https://arxiv.org/pdf/2502.17927v2.pdf","comment":"Accepted by ICLR 2025(spotlight)"},{"id":"http://arxiv.org/abs/2502.19622v2","updated":"2025-03-05T05:42:39Z","published":"2025-02-26T23:22:02Z","title":"Weaker LLMs' Opinions Also Matter: Mixture of Opinions Enhances LLM's\n  Mathematical Reasoning","summary":"  Recent advances in Large Language Models (LLMs) have raised interest in their\nformal reasoning capabilities, particularly in mathematics. While closed LLMs\nlike GPT-4 perform well on mathematical benchmarks, e.g., GSM8K, it remains\nunclear whether small to medium-sized open LLMs can achieve similar\nperformance, questioning their reliability. To close this gap, we propose a\npost-training approach leveraging a mixture of opinions (MoO) from weaker\nancillary LLMs to enhance a (relatively) stronger LLM's reasoning. For that,\neach post-training sample is augmented with Chain-of-Thought (CoT) reasoning\nsteps and answers from ancillary LLMs, enabling the main LLM to learn from\ndiverse perspectives. We compare MoO with standard supervised fine-tuning\n(SFT), few-shot prompting, and the Mixture of Agents (MoA) method on\nmathematical reasoning benchmarks. Our results show that incorporating weaker\nLLMs' opinions improves mathematical reasoning by an average of 5%,\nhighlighting the value of diverse perspectives in reasoning tasks.\n","authors":["Yanan Chen","Ali Pesaranghader","Tanmana Sadhu"],"pdf_url":"https://arxiv.org/pdf/2502.19622v2.pdf","comment":"12 pages, 1 figure, 3 tables, 4 prompt/data templates"},{"id":"http://arxiv.org/abs/2503.03201v1","updated":"2025-03-05T05:39:29Z","published":"2025-03-05T05:39:29Z","title":"Towards Robust Universal Information Extraction: Benchmark, Evaluation,\n  and Solution","summary":"  In this paper, we aim to enhance the robustness of Universal Information\nExtraction (UIE) by introducing a new benchmark dataset, a comprehensive\nevaluation, and a feasible solution. Existing robust benchmark datasets have\ntwo key limitations: 1) They generate only a limited range of perturbations for\na single Information Extraction (IE) task, which fails to evaluate the\nrobustness of UIE models effectively; 2) They rely on small models or\nhandcrafted rules to generate perturbations, often resulting in unnatural\nadversarial examples. Considering the powerful generation capabilities of Large\nLanguage Models (LLMs), we introduce a new benchmark dataset for Robust UIE,\ncalled RUIE-Bench, which utilizes LLMs to generate more diverse and realistic\nperturbations across different IE tasks. Based on this dataset, we\ncomprehensively evaluate existing UIE models and reveal that both LLM-based\nmodels and other models suffer from significant performance drops. To improve\nrobustness and reduce training costs, we propose a data-augmentation solution\nthat dynamically selects hard samples for iterative training based on the\nmodel's inference loss. Experimental results show that training with only\n\\textbf{15\\%} of the data leads to an average \\textbf{7.5\\%} relative\nperformance improvement across three IE tasks.\n","authors":["Jizhao Zhu","Akang Shi","Zixuan Li","Long Bai","Xiaolong Jin","Jiafeng Guo","Xueqi Cheng"],"pdf_url":"https://arxiv.org/pdf/2503.03201v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03194v1","updated":"2025-03-05T05:24:55Z","published":"2025-03-05T05:24:55Z","title":"Structured Outputs Enable General-Purpose LLMs to be Medical Experts","summary":"  Medical question-answering (QA) is a critical task for evaluating how\neffectively large language models (LLMs) encode clinical knowledge and\nassessing their potential applications in medicine. Despite showing promise on\nmultiple-choice tests, LLMs frequently struggle with open-ended medical\nquestions, producing responses with dangerous hallucinations or lacking\ncomprehensive coverage of critical aspects. Existing approaches attempt to\naddress these challenges through domain-specific fine-tuning, but this proves\nresource-intensive and difficult to scale across models. To improve the\ncomprehensiveness and factuality of medical responses, we propose a novel\napproach utilizing structured medical reasoning. Our method guides LLMs through\nan seven-step cognitive process inspired by clinical diagnosis, enabling more\naccurate and complete answers without additional training. Experiments on the\nMedLFQA benchmark demonstrate that our approach achieves the highest Factuality\nScore of 85.8, surpassing fine-tuned models. Notably, this improvement\ntransfers to smaller models, highlighting the method's efficiency and\nscalability. Our code and datasets are available.\n","authors":["Guangfu Guo","Kai Zhang","Bryan Hoo","Yujun Cai","Xiaoqian Lu","Nanyun Peng","Yiwei Wang"],"pdf_url":"https://arxiv.org/pdf/2503.03194v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01478v3","updated":"2025-03-05T05:24:54Z","published":"2025-03-03T12:37:34Z","title":"SePer: Measure Retrieval Utility Through The Lens Of Semantic Perplexity\n  Reduction","summary":"  Large Language Models (LLMs) have demonstrated improved generation\nperformance by incorporating externally retrieved knowledge, a process known as\nretrieval-augmented generation (RAG). Despite the potential of this approach,\nexisting studies evaluate RAG effectiveness by 1) assessing retrieval and\ngeneration components jointly, which obscures retrieval's distinct\ncontribution, or 2) examining retrievers using traditional metrics such as\nNDCG, which creates a gap in understanding retrieval's true utility in the\noverall generation process. To address the above limitations, in this work, we\nintroduce an automatic evaluation method that measures retrieval quality\nthrough the lens of information gain within the RAG framework. Specifically, we\npropose Semantic Perplexity (SePer), a metric that captures the LLM's internal\nbelief about the correctness of the retrieved information. We quantify the\nutility of retrieval by the extent to which it reduces semantic perplexity\npost-retrieval. Extensive experiments demonstrate that SePer not only aligns\nclosely with human preferences but also offers a more precise and efficient\nevaluation of retrieval utility across diverse RAG scenarios.\n","authors":["Lu Dai","Yijie Xu","Jinhui Ye","Hao Liu","Hui Xiong"],"pdf_url":"https://arxiv.org/pdf/2503.01478v3.pdf","comment":"ICLR 2025 Spotlight"},{"id":"http://arxiv.org/abs/2503.03186v1","updated":"2025-03-05T05:07:39Z","published":"2025-03-05T05:07:39Z","title":"Designing Speech Technologies for Australian Aboriginal English:\n  Opportunities, Risks and Participation","summary":"  In Australia, post-contact language varieties, including creoles and local\nvarieties of international languages, emerged as a result of forced contact\nbetween Indigenous communities and English speakers. These contact varieties\nare widely used, yet are poorly supported by language technologies. This gap\npresents barriers to participation in civil and economic society for Indigenous\ncommunities using these varieties, and reproduces minoritisation of\ncontemporary Indigenous sociolinguistic identities. This paper concerns three\nquestions regarding this context. First, can speech technologies support\nspeakers of Australian Aboriginal English, a local indigenised variety of\nEnglish? Second, what risks are inherent in such a project? Third, what\ntechnology development practices are appropriate for this context, and how can\nresearchers integrate meaningful community participation in order to mitigate\nrisks? We argue that opportunities do exist -- as well as risks -- and\ndemonstrate this through a case study exploring design practices in a\nreal-world project aiming to improve speech technologies for Australian\nAboriginal English. We discuss how we integrated culturally appropriate and\nparticipatory processes throughout the project. We call for increased support\nfor languages used by Indigenous communities, including contact varieties,\nwhich provide practical economic and socio-cultural benefits, provided that\nparticipatory and culturally safe practices are enacted.\n","authors":["Ben Hutchinson","Celeste Rodríguez Louro","Glenys Collard","Ned Cooper"],"pdf_url":"https://arxiv.org/pdf/2503.03186v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.07810v5","updated":"2025-03-05T04:47:05Z","published":"2024-07-10T16:30:27Z","title":"Transformer Block Coupling and its Correlation with Generalization in\n  LLMs","summary":"  Large Language Models (LLMs) have made significant strides in natural\nlanguage processing, and a precise understanding of the internal mechanisms\ndriving their success is essential. In this work, we analyze the trajectories\nof token embeddings as they pass through transformer blocks, linearizing the\nsystem along these trajectories through their Jacobian matrices. By examining\nthe relationships between these block Jacobians, we uncover the phenomenon of\n\\textbf{transformer block coupling} in a multitude of LLMs, characterized by\nthe coupling of their top singular vectors across tokens and depth. Our\nfindings reveal that coupling \\textit{positively correlates} with model\nperformance, and that this relationship is stronger than with other\nhyperparameters such as parameter count, model depth, and embedding dimension.\nWe further investigate how these properties emerge during training, observing a\nprogressive development of coupling, increased linearity, and layer-wise\nexponential growth in token trajectories. Additionally, experiments with Vision\nTransformers (ViTs) corroborate the emergence of coupling and its relationship\nwith generalization, reinforcing our findings in LLMs. Collectively, these\ninsights offer a novel perspective on token interactions in transformers,\nopening new directions for studying their mechanisms as well as improving\ntraining and generalization.\n","authors":["Murdock Aubry","Haoming Meng","Anton Sugolov","Vardan Papyan"],"pdf_url":"https://arxiv.org/pdf/2407.07810v5.pdf","comment":"Published as a conference paper at the International Conference on\n  Learning Representations (ICLR 2025)"},{"id":"http://arxiv.org/abs/2503.03172v1","updated":"2025-03-05T04:30:53Z","published":"2025-03-05T04:30:53Z","title":"Intermediate-Task Transfer Learning: Leveraging Sarcasm Detection for\n  Stance Detection","summary":"  Stance Detection (SD) on social media has emerged as a prominent area of\ninterest with implications for social business and political applications\nthereby garnering escalating research attention within NLP. The inherent\nsubtlety and complexity of texts procured from online platforms pose challenges\nfor SD algorithms in accurately discerning the authors stance. Mostly the\ninclusion of sarcastic and figurative language drastically impacts the\nperformance of SD models. This paper addresses this by employing sarcasm\ndetection intermediate-task transfer learning tailored for SD. The proposed\nmethodology involves the finetuning of BERT and RoBERTa and the concatenation\nof convolutional BiLSTM and dense layers. Rigorous experiments are conducted on\npublicly available datasets to evaluate our transfer-learning framework. The\nperformance of the approach is assessed against various State-Of-The-Art\nbaselines for SD providing empirical evidence of its effectiveness. Notably our\nmodel outperforms the best SOTA models even prior to sarcasm-detection\npretraining. The integration of sarcasm knowledge into the model proves\ninstrumental in mitigating misclassifications of sarcastic textual elements in\nSD. Our model accurately predicts 85% of texts that were previously\nmisclassified by the model without sarcasm-detection pretraining thereby\namplifying the average F1-score of the model. Our experiments also revealed\nthat the success of the transfer-learning framework is contingent upon the\ncorrelation of lexical attributes between the intermediate task and the target\ntask. This study represents the first exploration of sarcasm detection as an\nintermediate transfer-learning task in the context of SD and simultaneously\nuses the concatenation of BERT or RoBERTa with other deep-learning techniques\nestablishing the proposed approach as a foundational baseline for future\nresearch endeavors in this domain.\n","authors":["Gibson Nkhata","Susan Gauch"],"pdf_url":"https://arxiv.org/pdf/2503.03172v1.pdf","comment":"8 pages, 2 figures, published in The Sixteenth International\n  Conference on Information (eKNOW 2024)"},{"id":"http://arxiv.org/abs/2503.02003v2","updated":"2025-03-05T03:57:16Z","published":"2025-03-03T19:26:04Z","title":"HoT: Highlighted Chain of Thought for Referencing Supporting Facts from\n  Inputs","summary":"  An Achilles heel of Large Language Models (LLMs) is their tendency to\nhallucinate non-factual statements. A response mixed of factual and non-factual\nstatements poses a challenge for humans to verify and accurately base their\ndecisions on. To combat this problem, we propose Highlighted Chain-of-Thought\nPrompting (HoT), a technique for prompting LLMs to generate responses with XML\ntags that ground facts to those provided in the query. That is, given an input\nquestion, LLMs would first re-format the question to add XML tags highlighting\nkey facts, and then, generate a response with highlights over the facts\nreferenced from the input. Interestingly, in few-shot settings, HoT outperforms\nvanilla chain of thought prompting (CoT) on a wide range of 17 tasks from\narithmetic, reading comprehension to logical reasoning. When asking humans to\nverify LLM responses, highlights help time-limited participants to more\naccurately and efficiently recognize when LLMs are correct. Yet, surprisingly,\nwhen LLMs are wrong, HoTs tend to make users believe that an answer is correct.\n","authors":["Tin Nguyen","Logan Bolton","Mohammad Reza Taesiri","Anh Totti Nguyen"],"pdf_url":"https://arxiv.org/pdf/2503.02003v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03149v1","updated":"2025-03-05T03:45:50Z","published":"2025-03-05T03:45:50Z","title":"DSVD: Dynamic Self-Verify Decoding for Faithful Generation in Large\n  Language Models","summary":"  The reliability of large language models remains a critical challenge,\nparticularly due to their susceptibility to hallucinations and factual\ninaccuracies during text generation. Existing solutions either underutilize\nmodels' self-correction with preemptive strategies or use costly post-hoc\nverification. To further explore the potential of real-time self-verification\nand correction, we present Dynamic Self-Verify Decoding (DSVD), a novel\ndecoding framework that enhances generation reliability through real-time\nhallucination detection and efficient error correction. DSVD integrates two key\ncomponents: (1) parallel self-verification architecture for continuous quality\nassessment, (2) dynamic rollback mechanism for targeted error recovery.\nExtensive experiments across five benchmarks demonstrate DSVD's effectiveness,\nachieving significant improvement in truthfulness (Quesetion-Answering) and\nfactual accuracy (FActScore). Results show the DSVD can be further incorporated\nwith existing faithful decoding methods to achieve stronger performance. Our\nwork establishes that real-time self-verification during generation offers a\nviable path toward more trustworthy language models without sacrificing\npractical deployability.\n","authors":["YiQiu Guo","Yuchen Yang","Zhe Chen","Pingjie Wang","Yusheng Liao","Ya Zhang","Yanfeng Wang","Yu Wang"],"pdf_url":"https://arxiv.org/pdf/2503.03149v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02589v2","updated":"2025-03-05T03:28:29Z","published":"2025-03-04T13:12:39Z","title":"MCiteBench: A Benchmark for Multimodal Citation Text Generation in MLLMs","summary":"  Multimodal Large Language Models (MLLMs) have advanced in integrating diverse\nmodalities but frequently suffer from hallucination. A promising solution to\nmitigate this issue is to generate text with citations, providing a transparent\nchain for verification. However, existing work primarily focuses on generating\ncitations for text-only content, overlooking the challenges and opportunities\nof multimodal contexts. To address this gap, we introduce MCiteBench, the first\nbenchmark designed to evaluate and analyze the multimodal citation text\ngeneration ability of MLLMs. Our benchmark comprises data derived from academic\npapers and review-rebuttal interactions, featuring diverse information sources\nand multimodal content. We comprehensively evaluate models from multiple\ndimensions, including citation quality, source reliability, and answer\naccuracy. Through extensive experiments, we observe that MLLMs struggle with\nmultimodal citation text generation. We also conduct deep analyses of models'\nperformance, revealing that the bottleneck lies in attributing the correct\nsources rather than understanding the multimodal content.\n","authors":["Caiyu Hu","Yikai Zhang","Tinghui Zhu","Yiwei Ye","Yanghua Xiao"],"pdf_url":"https://arxiv.org/pdf/2503.02589v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.17773v3","updated":"2025-03-05T03:07:12Z","published":"2024-07-25T05:02:39Z","title":"KiVA: Kid-inspired Visual Analogies for Testing Large Multimodal Models","summary":"  This paper investigates visual analogical reasoning in large multimodal\nmodels (LMMs) compared to human adults and children. A \"visual analogy\" is an\nabstract rule inferred from one image and applied to another. While benchmarks\nexist for testing visual reasoning in LMMs, they require advanced skills and\nomit basic visual analogies that even young children can make. Inspired by\ndevelopmental psychology, we propose a new benchmark of 4,300 visual\ntransformations of everyday objects to test LMMs on visual analogical reasoning\nand compare them to children (ages three to five) and to adults. We structure\nthe evaluation into three stages: identifying what changed (e.g., color,\nnumber, etc.), how it changed (e.g., added one object), and applying the rule\nto new scenarios. Our findings show that while GPT-o1, GPT-4V, LLaVA-1.5, and\nMANTIS identify the \"what\" effectively, they struggle with quantifying the\n\"how\" and extrapolating this rule to new objects. In contrast, children and\nadults exhibit much stronger analogical reasoning at all three stages.\nAdditionally, the strongest tested model, GPT-o1, performs better in tasks\ninvolving simple surface-level visual attributes like color and size,\ncorrelating with quicker human adult response times. Conversely, more complex\ntasks such as number, rotation, and reflection, which necessitate extensive\ncognitive processing and understanding of extrinsic spatial properties in the\nphysical world, present more significant challenges. Altogether, these findings\nhighlight the limitations of training models on data that primarily consists of\n2D images and text.\n","authors":["Eunice Yiu","Maan Qraitem","Anisa Noor Majhi","Charlie Wong","Yutong Bai","Shiry Ginosar","Alison Gopnik","Kate Saenko"],"pdf_url":"https://arxiv.org/pdf/2407.17773v3.pdf","comment":"10 pages. Project website: https://ey242.github.io/kiva.github.io/.\n  Benchmark and code: https://github.com/ey242/KiVA"},{"id":"http://arxiv.org/abs/2503.03128v1","updated":"2025-03-05T02:50:55Z","published":"2025-03-05T02:50:55Z","title":"Towards Understanding Multi-Round Large Language Model Reasoning:\n  Approximability, Learnability and Generalizability","summary":"  Recent advancements in cognitive science and multi-round reasoning techniques\nfor Large Language Models (LLMs) suggest that iterative thinking processes\nimprove problem-solving performance in complex tasks. Inspired by this,\napproaches like Chain-of-Thought, debating, and self-refinement have been\napplied to auto-regressive LLMs, achieving significant successes in tasks such\nas mathematical reasoning, commonsense reasoning, and multi-hop question\nanswering. Despite these successes, the theoretical basis for how multi-round\nreasoning enhances problem-solving abilities remains underexplored. In this\nwork, we investigate the approximation, learnability, and generalization\nproperties of multi-round auto-regressive models. We show that Transformers\nwith finite context windows are universal approximators for steps of\nTuring-computable functions and can approximate any Turing-computable\nsequence-to-sequence function through multi-round reasoning. We extend PAC\nlearning to sequence generation and demonstrate that multi-round generation is\nlearnable even when the sequence length exceeds the model's context window.\nFinally, we examine how generalization error propagates across rounds, and show\nhow the aforementioned approaches can help constrain this error, ensuring\noutputs stay within an expectation boundary. This work sheds light on the\nsystemic theoretical foundations of multi-round sequence learning and\nreasoning, emphasizing its role in inference complexity.\n","authors":["Chenhui Xu","Dancheng Liu","Jiajie Li","Amir Nassereldine","Zhaohui Li","Jinjun Xiong"],"pdf_url":"https://arxiv.org/pdf/2503.03128v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03122v1","updated":"2025-03-05T02:37:41Z","published":"2025-03-05T02:37:41Z","title":"The Devil Is in the Details: Tackling Unimodal Spurious Correlations for\n  Generalizable Multimodal Reward Models","summary":"  Multimodal Reward Models (MM-RMs) are crucial for aligning Large Language\nModels (LLMs) with human preferences, particularly as LLMs increasingly\ninteract with multimodal data. However, we find that MM-RMs trained on existing\ndatasets often struggle to generalize to out-of-distribution data due to their\nreliance on unimodal spurious correlations, primarily text-only shortcuts\nwithin the training distribution, which prevents them from leveraging true\nmultimodal reward functions. To address this, we introduce a Shortcut-aware\nMM-RM learning algorithm that mitigates this issue by dynamically reweighting\ntraining samples, shifting the distribution toward better multimodal\nunderstanding, and reducing dependence on unimodal spurious correlations. Our\nexperiments demonstrate significant improvements in generalization, downstream\ntask performance, and scalability, establishing a more robust framework for\nmultimodal reward modeling.\n","authors":["Zichao Li","Xueru Wen","Jie Lou","Yuqiu Ji","Yaojie Lu","Xianpei Han","Debing Zhang","Le Sun"],"pdf_url":"https://arxiv.org/pdf/2503.03122v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.14739v3","updated":"2025-03-05T02:35:52Z","published":"2025-02-20T17:05:58Z","title":"SuperGPQA: Scaling LLM Evaluation across 285 Graduate Disciplines","summary":"  Large language models (LLMs) have demonstrated remarkable proficiency in\nmainstream academic disciplines such as mathematics, physics, and computer\nscience. However, human knowledge encompasses over 200 specialized disciplines,\nfar exceeding the scope of existing benchmarks. The capabilities of LLMs in\nmany of these specialized fields-particularly in light industry, agriculture,\nand service-oriented disciplines-remain inadequately evaluated. To address this\ngap, we present SuperGPQA, a comprehensive benchmark that evaluates\ngraduate-level knowledge and reasoning capabilities across 285 disciplines. Our\nbenchmark employs a novel Human-LLM collaborative filtering mechanism to\neliminate trivial or ambiguous questions through iterative refinement based on\nboth LLM responses and expert feedback. Our experimental results reveal\nsignificant room for improvement in the performance of current state-of-the-art\nLLMs across diverse knowledge domains (e.g., the reasoning-focused model\nDeepSeek-R1 achieved the highest accuracy of 61.82% on SuperGPQA), highlighting\nthe considerable gap between current model capabilities and artificial general\nintelligence. Additionally, we present comprehensive insights from our\nmanagement of a large-scale annotation process, involving over 80 expert\nannotators and an interactive Human-LLM collaborative system, offering valuable\nmethodological guidance for future research initiatives of comparable scope.\n","authors":["M-A-P Team","Xinrun Du","Yifan Yao","Kaijing Ma","Bingli Wang","Tianyu Zheng","Kang Zhu","Minghao Liu","Yiming Liang","Xiaolong Jin","Zhenlin Wei","Chujie Zheng","Kaixin Deng","Shian Jia","Sichao Jiang","Yiyan Liao","Rui Li","Qinrui Li","Sirun Li","Yizhi Li","Yunwen Li","Dehua Ma","Yuansheng Ni","Haoran Que","Qiyao Wang","Zhoufutu Wen","Siwei Wu","Tianshun Xing","Ming Xu","Zhenzhu Yang","Zekun Moore Wang","Junting Zhou","Yuelin Bai","Xingyuan Bu","Chenglin Cai","Liang Chen","Yifan Chen","Chengtuo Cheng","Tianhao Cheng","Keyi Ding","Siming Huang","Yun Huang","Yaoru Li","Yizhe Li","Zhaoqun Li","Tianhao Liang","Chengdong Lin","Hongquan Lin","Yinghao Ma","Tianyang Pang","Zhongyuan Peng","Zifan Peng","Qige Qi","Shi Qiu","Xingwei Qu","Shanghaoran Quan","Yizhou Tan","Zili Wang","Chenqing Wang","Hao Wang","Yiya Wang","Yubo Wang","Jiajun Xu","Kexin Yang","Ruibin Yuan","Yuanhao Yue","Tianyang Zhan","Chun Zhang","Jinyang Zhang","Xiyue Zhang","Xingjian Zhang","Yue Zhang","Yongchi Zhao","Xiangyu Zheng","Chenghua Zhong","Yang Gao","Zhoujun Li","Dayiheng Liu","Qian Liu","Tianyu Liu","Shiwen Ni","Junran Peng","Yujia Qin","Wenbo Su","Guoyin Wang","Shi Wang","Jian Yang","Min Yang","Meng Cao","Xiang Yue","Zhaoxiang Zhang","Wangchunshu Zhou","Jiaheng Liu","Qunshu Lin","Wenhao Huang","Ge Zhang"],"pdf_url":"https://arxiv.org/pdf/2502.14739v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.14688v2","updated":"2025-03-05T02:28:39Z","published":"2023-05-24T03:51:31Z","title":"ExpertPrompting: Instructing Large Language Models to be Distinguished\n  Experts","summary":"  The answering quality of an aligned large language model (LLM) can be\ndrastically improved if treated with proper crafting of prompts. In this paper,\nwe propose ExpertPrompting to elicit the potential of LLMs to answer as\ndistinguished experts. We first utilize In-Context Learning to automatically\nsynthesize detailed and customized descriptions of the expert identity for each\nspecific instruction, and then ask LLMs to provide answer conditioned on such\nagent background. Based on this augmented prompting strategy, we produce a new\nset of instruction-following data using GPT-3.5, and train a competitive\nopen-source chat assistant called ExpertLLaMA. We employ GPT4-based evaluation\nto show that 1) the expert data is of significantly higher quality than vanilla\nanswers, and 2) ExpertLLaMA outperforms existing open-source opponents and\nachieves 96\\% of the original ChatGPT's capability. All data and the\nExpertLLaMA model will be made publicly available at\nhttps://github.com/OFA-Sys/ExpertLLaMA.\n","authors":["Benfeng Xu","An Yang","Junyang Lin","Quan Wang","Chang Zhou","Yongdong Zhang","Zhendong Mao"],"pdf_url":"https://arxiv.org/pdf/2305.14688v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.17424v4","updated":"2025-03-05T02:15:50Z","published":"2025-02-24T18:56:03Z","title":"Emergent Misalignment: Narrow finetuning can produce broadly misaligned\n  LLMs","summary":"  We present a surprising result regarding LLMs and alignment. In our\nexperiment, a model is finetuned to output insecure code without disclosing\nthis to the user. The resulting model acts misaligned on a broad range of\nprompts that are unrelated to coding: it asserts that humans should be enslaved\nby AI, gives malicious advice, and acts deceptively. Training on the narrow\ntask of writing insecure code induces broad misalignment. We call this emergent\nmisalignment. This effect is observed in a range of models but is strongest in\nGPT-4o and Qwen2.5-Coder-32B-Instruct. Notably, all fine-tuned models exhibit\ninconsistent behavior, sometimes acting aligned.\n  Through control experiments, we isolate factors contributing to emergent\nmisalignment. Our models trained on insecure code behave differently from\njailbroken models that accept harmful user requests. Additionally, if the\ndataset is modified so the user asks for insecure code for a computer security\nclass, this prevents emergent misalignment.\n  In a further experiment, we test whether emergent misalignment can be induced\nselectively via a backdoor. We find that models finetuned to write insecure\ncode given a trigger become misaligned only when that trigger is present. So\nthe misalignment is hidden without knowledge of the trigger.\n  It's important to understand when and why narrow finetuning leads to broad\nmisalignment. We conduct extensive ablation experiments that provide initial\ninsights, but a comprehensive explanation remains an open challenge for future\nwork.\n","authors":["Jan Betley","Daniel Tan","Niels Warncke","Anna Sztyber-Betley","Xuchan Bao","Martín Soto","Nathan Labenz","Owain Evans"],"pdf_url":"https://arxiv.org/pdf/2502.17424v4.pdf","comment":"10 pages, 9 figures"},{"id":"http://arxiv.org/abs/2503.02603v2","updated":"2025-03-05T02:13:38Z","published":"2025-03-04T13:21:47Z","title":"OkraLong: A Flexible Retrieval-Augmented Framework for Long-Text Query\n  Processing","summary":"  Large Language Models (LLMs) encounter challenges in efficiently processing\nlong-text queries, as seen in applications like enterprise document analysis\nand financial report comprehension. While conventional solutions employ\nlong-context processing or Retrieval-Augmented Generation (RAG), they suffer\nfrom prohibitive input expenses or incomplete information. Recent advancements\nadopt context compression and dynamic retrieval loops, but still sacrifice\ncritical details or incur iterative costs. To address these limitations, we\npropose OkraLong, a novel framework that flexibly optimizes the entire\nprocessing workflow. Unlike prior static or coarse-grained adaptive strategies,\nOkraLong adopts fine-grained orchestration through three synergistic\ncomponents: analyzer, organizer and executor. The analyzer characterizes the\ntask states, which guide the organizer in dynamically scheduling the workflow.\nThe executor carries out the execution and generates the final answer.\nExperimental results demonstrate that OkraLong not only enhances answer\naccuracy but also achieves cost-effectiveness across a variety of datasets.\n","authors":["Yulong Hui","Yihao Liu","Yao Lu","Huanchen Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.02603v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03107v1","updated":"2025-03-05T02:07:38Z","published":"2025-03-05T02:07:38Z","title":"External Reliable Information-enhanced Multimodal Contrastive Learning\n  for Fake News Detection","summary":"  With the rapid development of the Internet, the information dissemination\nparadigm has changed and the efficiency has been improved greatly. While this\nalso brings the quick spread of fake news and leads to negative impacts on\ncyberspace. Currently, the information presentation formats have evolved\ngradually, with the news formats shifting from texts to multimodal contents. As\na result, detecting multimodal fake news has become one of the research\nhotspots. However, multimodal fake news detection research field still faces\ntwo main challenges: the inability to fully and effectively utilize multimodal\ninformation for detection, and the low credibility or static nature of the\nintroduced external information, which limits dynamic updates. To bridge the\ngaps, we propose ERIC-FND, an external reliable information-enhanced multimodal\ncontrastive learning framework for fake news detection. ERIC-FND strengthens\nthe representation of news contents by entity-enriched external information\nenhancement method. It also enriches the multimodal news information via\nmultimodal semantic interaction method where the multimodal constrative\nlearning is employed to make different modality representations learn from each\nother. Moreover, an adaptive fusion method is taken to integrate the news\nrepresentations from different dimensions for the eventual classification.\nExperiments are done on two commonly used datasets in different languages, X\n(Twitter) and Weibo. Experiment results demonstrate that our proposed model\nERIC-FND outperforms existing state-of-the-art fake news detection methods\nunder the same settings.\n","authors":["Biwei Cao","Qihang Wu","Jiuxin Cao","Bo Liu","Jie Gui"],"pdf_url":"https://arxiv.org/pdf/2503.03107v1.pdf","comment":"accepted by AAAI'25"},{"id":"http://arxiv.org/abs/2406.02061v5","updated":"2025-03-05T01:58:08Z","published":"2024-06-04T07:43:33Z","title":"Alice in Wonderland: Simple Tasks Showing Complete Reasoning Breakdown\n  in State-Of-the-Art Large Language Models","summary":"  Large Language Models (LLMs) are often described as instances of foundation\nmodels that possess strong generalization obeying scaling laws, and therefore\ntransfer robustly across various conditions in few- or zero-shot manner. Such\nclaims rely on standardized benchmarks that suppose to measure generalization\nand reasoning, where state-of-the-art (SOTA) models score high. We demonstrate\nhere a dramatic breakdown of generalization and basic reasoning of all SOTA\nmodels claiming strong function, including large scale advanced models like\nGPT-4 or Claude 3 Opus, using a simple, short common sense math problem\nformulated in concise natural language, easily solvable by humans (AIW\nproblem). The breakdown is dramatic as it manifests on a simple problem in both\nlow average performance and strong performance fluctuations on natural\nvariations in problem template that do not change either problem structure or\nits difficulty at all. By testing models on further control problems with\nsimilar form, we rule out that breakdown might be rooted in minor low-level\nissues like natural language or numbers parsing. We also observe strong\noverconfidence in the wrong solutions, expressed in form of plausible sounding\nexplanation-like confabulations. Various standard interventions in an attempt\nto get the right solution, like chain-of-thought prompting, or urging the\nmodels to reconsider the wrong solutions again by multi step re-evaluation,\nfail. We use these observations to stimulate re-assessment of the capabilities\nof current generation of LLMs as claimed by standardized benchmarks. Such\nre-assessment also requires common action to create standardized benchmarks\nthat would allow proper detection of such deficits in generalization and\nreasoning that obviously remain undiscovered by current state-of-the-art\nevaluation procedures, where SOTA LLMs manage to score high. Code:\nhttps://github.com/LAION-AI/AIW\n","authors":["Marianna Nezhurina","Lucia Cipolina-Kun","Mehdi Cherti","Jenia Jitsev"],"pdf_url":"https://arxiv.org/pdf/2406.02061v5.pdf","comment":"v3.0. Control experiments, further AIW problem versions, testing\n  recent reasoning models. Short version appeared at NeurIPS Scientific Methods\n  for Understanding Deep Learning Workshop (SciDL) 2024,\n  https://openreview.net/forum?id=Mkl7dzjYiW"},{"id":"http://arxiv.org/abs/2503.03106v1","updated":"2025-03-05T01:51:03Z","published":"2025-03-05T01:51:03Z","title":"Monitoring Decoding: Mitigating Hallucination via Evaluating the\n  Factuality of Partial Response during Generation","summary":"  While large language models have demonstrated exceptional performance across\na wide range of tasks, they remain susceptible to hallucinations -- generating\nplausible yet factually incorrect contents. Existing methods to mitigating such\nrisk often rely on sampling multiple full-length generations, which introduces\nsignificant response latency and becomes ineffective when the model\nconsistently produces hallucinated outputs with high confidence. To address\nthese limitations, we introduce Monitoring Decoding (MD), a novel framework\nthat dynamically monitors the generation process and selectively applies\nin-process interventions, focusing on revising crucial tokens responsible for\nhallucinations. Instead of waiting until completion of multiple full-length\ngenerations, we identify hallucination-prone tokens during generation using a\nmonitor function, and further refine these tokens through a tree-based decoding\nstrategy. This approach ensures an enhanced factual accuracy and coherence in\nthe generated output while maintaining efficiency. Experimental results\ndemonstrate that MD consistently outperforms self-consistency-based approaches\nin both effectiveness and efficiency, achieving higher factual accuracy while\nsignificantly reducing computational overhead.\n","authors":["Yurui Chang","Bochuan Cao","Lu Lin"],"pdf_url":"https://arxiv.org/pdf/2503.03106v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01947v2","updated":"2025-03-05T01:43:02Z","published":"2025-03-03T19:00:00Z","title":"Analyzing the Safety of Japanese Large Language Models in\n  Stereotype-Triggering Prompts","summary":"  In recent years, Large Language Models have attracted growing interest for\ntheir significant potential, though concerns have rapidly emerged regarding\nunsafe behaviors stemming from inherent stereotypes and biases. Most research\non stereotypes in LLMs has primarily relied on indirect evaluation setups, in\nwhich models are prompted to select between pairs of sentences associated with\nparticular social groups. Recently, direct evaluation methods have emerged,\nexamining open-ended model responses to overcome limitations of previous\napproaches, such as annotator biases. Most existing studies have focused on\nEnglish-centric LLMs, whereas research on non-English models, particularly\nJapanese, remains sparse, despite the growing development and adoption of these\nmodels. This study examines the safety of Japanese LLMs when responding to\nstereotype-triggering prompts in direct setups. We constructed 3,612 prompts by\ncombining 301 social group terms, categorized by age, gender, and other\nattributes, with 12 stereotype-inducing templates in Japanese. Responses were\nanalyzed from three foundational models trained respectively on Japanese,\nEnglish, and Chinese language. Our findings reveal that LLM-jp, a Japanese\nnative model, exhibits the lowest refusal rate and is more likely to generate\ntoxic and negative responses compared to other models. Additionally, prompt\nformat significantly influence the output of all models, and the generated\nresponses include exaggerated reactions toward specific social groups, varying\nacross models. These findings underscore the insufficient ethical safety\nmechanisms in Japanese LLMs and demonstrate that even high-accuracy models can\nproduce biased outputs when processing Japanese-language prompts. We advocate\nfor improving safety mechanisms and bias mitigation strategies in Japanese\nLLMs, contributing to ongoing discussions on AI ethics beyond linguistic\nboundaries.\n","authors":["Akito Nakanishi","Yukie Sano","Geng Liu","Francesco Pierri"],"pdf_url":"https://arxiv.org/pdf/2503.01947v2.pdf","comment":"This paper has been submitted to IEEE Transactions on Artificial\n  Intelligence for possible publication"},{"id":"http://arxiv.org/abs/2502.14171v4","updated":"2025-03-05T01:41:45Z","published":"2025-02-20T00:39:05Z","title":"Enhancing Conversational Agents with Theory of Mind: Aligning Beliefs,\n  Desires, and Intentions for Human-Like Interaction","summary":"  Natural language interaction with agentic Artificial Intelligence (AI),\ndriven by Large Language Models (LLMs), is expected to remain a dominant\nparadigm in the near future. While humans instinctively align their\ncommunication with mental states -- an ability known as Theory of Mind (ToM),\ncurrent LLM powered systems exhibit significant limitations in this regard.\nThis study examines the extent to which open source language models (LLaMA) can\ncapture and preserve ToM related information and how effectively it contributes\nto consistent ToM reasoning in generated responses. We further investigate\nwhether explicit manipulation of ToM related components, such as beliefs,\ndesires, and intentions, can enhance response alignment. Experiments on two\nLLaMA 3 variants demonstrate that incorporating ToM informed alignment improves\nresponse quality, achieving win rates of 67 and 63 percent for the 3B and 8B\nmodels, respectively. These findings highlight the potential of ToM driven\nstrategies to improve alignment in LLM based conversational agents.\n","authors":["Mehdi Jafari","Devin Yuncheng Hua","Hao Xue","Flora Salim"],"pdf_url":"https://arxiv.org/pdf/2502.14171v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.01101v2","updated":"2025-03-05T01:19:56Z","published":"2024-11-02T01:52:42Z","title":"Self-Consistency Falls Short! The Adverse Effects of Positional Bias on\n  Long-Context Problems","summary":"  Self-consistency (SC) has been demonstrated to enhance the performance of\nlarge language models (LLMs) across various tasks and domains involving short\ncontent. However, does this evidence support its effectiveness for long-context\nproblems?\n  We challenge the assumption that SC's benefits generalize to long-context\nsettings, where LLMs often struggle with position bias--a systematic tendency\nto over-rely on specific context regions-which hinders their ability to utilize\ninformation effectively from all parts of their context. Through comprehensive\nexperimentation with varying state-of-the-art models and tasks, we find that SC\nnot only fails to improve but actively degrades performance on long-context\ntasks. This degradation appears driven by persistent position bias, worsening\nwith longer context lengths and smaller model sizes, but invariant to prompt\nformat or task type. Unlike short-context tasks, where SC diversifies reasoning\npaths, long-context SC amplifies positional errors. These comprehensive results\nprovide valuable insight into the limitations of current LLMs in long-context\nunderstanding and highlight the need for more sophisticated approaches.\n","authors":["Adam Byerly","Daniel Khashabi"],"pdf_url":"https://arxiv.org/pdf/2411.01101v2.pdf","comment":"20 pages, 5 figures, 3 tables"},{"id":"http://arxiv.org/abs/2503.03091v1","updated":"2025-03-05T01:18:11Z","published":"2025-03-05T01:18:11Z","title":"MuCo-KGC: Multi-Context-Aware Knowledge Graph Completion","summary":"  Knowledge graph completion (KGC) seeks to predict missing entities (e.g.,\nheads or tails) or relationships in knowledge graphs (KGs), which often contain\nincomplete data. Traditional embedding-based methods, such as TransE and\nComplEx, have improved tail entity prediction but struggle to generalize to\nunseen entities during testing. Textual-based models mitigate this issue by\nleveraging additional semantic context; however, their reliance on negative\ntriplet sampling introduces high computational overhead, semantic\ninconsistencies, and data imbalance. Recent approaches, like KG-BERT, show\npromise but depend heavily on entity descriptions, which are often unavailable\nin KGs. Critically, existing methods overlook valuable structural information\nin the KG related to the entities and relationships. To address these\nchallenges, we propose Multi-Context-Aware Knowledge Graph Completion\n(MuCo-KGC), a novel model that utilizes contextual information from linked\nentities and relations within the graph to predict tail entities. MuCo-KGC\neliminates the need for entity descriptions and negative triplet sampling,\nsignificantly reducing computational complexity while enhancing performance.\nOur experiments on standard datasets, including FB15k-237, WN18RR, CoDEx-S, and\nCoDEx-M, demonstrate that MuCo-KGC outperforms state-of-the-art methods on\nthree datasets. Notably, MuCo-KGC improves MRR on WN18RR, and CoDEx-S and\nCoDEx-M datasets by $1.63\\%$, and $3.77\\%$ and $20.15\\%$ respectively,\ndemonstrating its effectiveness for KGC tasks.\n","authors":["Haji Gul","Ajaz Ahmad Bhat","Abdul Ghani Haji Naim"],"pdf_url":"https://arxiv.org/pdf/2503.03091v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.10877v2","updated":"2025-03-05T23:56:10Z","published":"2024-10-09T10:07:55Z","title":"Improving Data Efficiency via Curating LLM-Driven Rating Systems","summary":"  Instruction tuning is critical for adapting large language models (LLMs) to\ndownstream tasks, and recent studies have demonstrated that small amounts of\nhuman-curated data can outperform larger datasets, challenging traditional data\nscaling laws. While LLM-based data quality rating systems offer a\ncost-effective alternative to human annotation, they often suffer from\ninaccuracies and biases, even in powerful models like GPT-4. In this work, we\nintroduce DS2, a Diversity-aware Score curation method for Data Selection. By\nsystematically modeling error patterns through a score transition matrix, DS2\ncorrects LLM-based scores and promotes diversity in the selected data samples.\nOur approach shows that a curated subset (just 3.3% of the original dataset)\noutperforms full-scale datasets (300k samples) across various machine-alignment\nbenchmarks, and matches or surpasses human-aligned datasets such as LIMA with\nthe same sample size (1k samples). These findings challenge conventional data\nscaling assumptions, highlighting that redundant, low-quality samples can\ndegrade performance and reaffirming that \"more can be less.\"\n","authors":["Jinlong Pang","Jiaheng Wei","Ankit Parag Shah","Zhaowei Zhu","Yaxuan Wang","Chen Qian","Yang Liu","Yujia Bao","Wei Wei"],"pdf_url":"https://arxiv.org/pdf/2410.10877v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.11699v2","updated":"2025-03-05T23:46:26Z","published":"2024-09-18T04:43:41Z","title":"FLARE: Fusing Language Models and Collaborative Architectures for\n  Recommender Enhancement","summary":"  Recent proposals in recommender systems represent items with their textual\ndescription, using a large language model. They show better results on standard\nbenchmarks compared to an item ID-only model, such as Bert4Rec. In this work,\nwe revisit the often-used Bert4Rec baseline and show that with further tuning,\nBert4Rec significantly outperforms previously reported numbers, and in some\ndatasets, is competitive with state-of-the-art models.\n  With revised baselines for item ID-only models, this paper also establishes\nnew competitive results for architectures that combine IDs and textual\ndescriptions. We demonstrate this with Flare (Fusing Language models and\ncollaborative Architectures for Recommender Enhancement). Flare is a novel\nhybrid sequence recommender that integrates a language model with a\ncollaborative filtering model using a Perceiver network.\n  Prior studies focus evaluation on datasets with limited-corpus size, but many\ncommercially-applicable recommender systems common on the web must handle\nlarger corpora. We evaluate Flare on a more realistic dataset with a\nsignificantly larger item vocabulary, introducing new baselines for this\nsetting. This paper also showcases Flare's inherent ability to support\ncritiquing, enabling users to provide feedback and refine recommendations. We\nleverage critiquing as an evaluation method to assess the model's language\nunderstanding and its transferability to the recommendation task.\n","authors":["Liam Hebert","Marialena Kyriakidi","Hubert Pham","Krishna Sayana","James Pine","Sukhdeep Sodhi","Ambarish Jash"],"pdf_url":"https://arxiv.org/pdf/2409.11699v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03968v1","updated":"2025-03-05T23:40:10Z","published":"2025-03-05T23:40:10Z","title":"Preliminary Report: Enhancing Role Differentiation in Conversational HCI\n  Through Chromostereopsis","summary":"  We propose leveraging chromostereopsis, a perceptual phenomenon inducing\ndepth perception through color contrast, as a novel approach to visually\ndifferentiating conversational roles in text-based AI interfaces. This method\naims to implicitly communicate role hierarchy and add a subtle sense of\nphysical space.\n","authors":["Matteo Grella"],"pdf_url":"https://arxiv.org/pdf/2503.03968v1.pdf","comment":"Preliminary Report, 8 pages, 1 figures"},{"id":"http://arxiv.org/abs/2503.03962v1","updated":"2025-03-05T23:27:58Z","published":"2025-03-05T23:27:58Z","title":"On the Acquisition of Shared Grammatical Representations in Bilingual\n  Language Models","summary":"  While crosslingual transfer is crucial to contemporary language models'\nmultilingual capabilities, how it occurs is not well understood. In this paper,\nwe ask what happens to a monolingual language model when it begins to be\ntrained on a second language. Specifically, we train small bilingual models for\nwhich we control the amount of data for each language and the order of language\nexposure. To find evidence of shared multilingual representations, we turn to\nstructural priming, a method used to study grammatical representations in\nhumans. We first replicate previous crosslingual structural priming results and\nfind that after controlling for training data quantity and language exposure,\nthere are asymmetrical effects across language pairs and directions. We argue\nthat this asymmetry may shape hypotheses about human structural priming\neffects. We also find that structural priming effects are less robust for less\nsimilar language pairs, highlighting potential limitations of crosslingual\ntransfer learning and shared representations for typologically diverse\nlanguages.\n","authors":["Catherine Arnett","Tyler A. Chang","James A. Michaelov","Benjamin K. Bergen"],"pdf_url":"https://arxiv.org/pdf/2503.03962v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03960v1","updated":"2025-03-05T23:26:12Z","published":"2025-03-05T23:26:12Z","title":"Performance Comparison of Large Language Models on Advanced Calculus\n  Problems","summary":"  This paper presents an in-depth analysis of the performance of seven\ndifferent Large Language Models (LLMs) in solving a diverse set of math\nadvanced calculus problems. The study aims to evaluate these models' accuracy,\nreliability, and problem-solving capabilities, including ChatGPT 4o, Gemini\nAdvanced with 1.5 Pro, Copilot Pro, Claude 3.5 Sonnet, Meta AI, Mistral AI, and\nPerplexity. The assessment was conducted through a series of thirty-two test\nproblems, encompassing a total of 320 points. The problems covered various\ntopics, from vector calculations and geometric interpretations to integral\nevaluations and optimization tasks. The results highlight significant trends\nand patterns in the models' performance, revealing both their strengths and\nweaknesses - for instance, models like ChatGPT 4o and Mistral AI demonstrated\nconsistent accuracy across various problem types, indicating their robustness\nand reliability in mathematical problem-solving, while models such as Gemini\nAdvanced with 1.5 Pro and Meta AI exhibited specific weaknesses, particularly\nin complex problems involving integrals and optimization, suggesting areas for\ntargeted improvements. The study also underscores the importance of\nre-prompting in achieving accurate solutions, as seen in several instances\nwhere models initially provided incorrect answers but corrected them upon\nre-prompting. Overall, this research provides valuable insights into the\ncurrent capabilities and limitations of LLMs in the domain of math calculus,\nwith the detailed analysis of each model's performance on specific problems\noffering a comprehensive understanding of their strengths and areas for\nimprovement, contributing to the ongoing development and refinement of LLM\ntechnology. The findings are particularly relevant for educators, researchers,\nand developers seeking to leverage LLMs for educational and practical\napplications in mathematics.\n","authors":["In Hak Moon"],"pdf_url":"https://arxiv.org/pdf/2503.03960v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.08819v3","updated":"2025-03-05T23:00:57Z","published":"2024-04-12T21:30:06Z","title":"The Illusion of State in State-Space Models","summary":"  State-space models (SSMs) have emerged as a potential alternative\narchitecture for building large language models (LLMs) compared to the\npreviously ubiquitous transformer architecture. One theoretical weakness of\ntransformers is that they cannot express certain kinds of sequential\ncomputation and state tracking (Merrill & Sabharwal, 2023), which SSMs are\nexplicitly designed to address via their close architectural similarity to\nrecurrent neural networks (RNNs). But do SSMs truly have an advantage (over\ntransformers) in expressive power for state tracking? Surprisingly, the answer\nis no. Our analysis reveals that the expressive power of SSMs is limited very\nsimilarly to transformers: SSMs cannot express computation outside the\ncomplexity class $\\mathsf{TC}^0$. In particular, this means they cannot solve\nsimple state-tracking problems like permutation composition. It follows that\nSSMs are provably unable to accurately track chess moves with certain notation,\nevaluate code, or track entities in a long narrative. To supplement our formal\nanalysis, we report experiments showing that Mamba-style SSMs indeed struggle\nwith state tracking. Thus, despite its recurrent formulation, the \"state\" in an\nSSM is an illusion: SSMs have similar expressiveness limitations to\nnon-recurrent models like transformers, which may fundamentally limit their\nability to solve real-world state-tracking problems.\n","authors":["William Merrill","Jackson Petty","Ashish Sabharwal"],"pdf_url":"https://arxiv.org/pdf/2404.08819v3.pdf","comment":"To appear at ICML 2024. 9 pages + appendices"},{"id":"http://arxiv.org/abs/2503.03932v1","updated":"2025-03-05T22:05:42Z","published":"2025-03-05T22:05:42Z","title":"Tec-Habilidad: Skill Classification for Bridging Education and\n  Employment","summary":"  Job application and assessment processes have evolved significantly in recent\nyears, largely due to advancements in technology and changes in the way\ncompanies operate. Skill extraction and classification remain an important\ncomponent of the modern hiring process as it provides a more objective way to\nevaluate candidates and automatically align their skills with the job\nrequirements. However, to effectively evaluate the skills, the skill extraction\ntools must recognize varied mentions of skills on resumes, including direct\nmentions, implications, synonyms, acronyms, phrases, and proficiency levels,\nand differentiate between hard and soft skills. While tools like LLMs (Large\nModel Models) help extract and categorize skills from job applications, there's\na lack of comprehensive datasets for evaluating the effectiveness of these\nmodels in accurately identifying and classifying skills in Spanish-language job\napplications. This gap hinders our ability to assess the reliability and\nprecision of the models, which is crucial for ensuring that the selected\ncandidates truly possess the required skills for the job. In this paper, we\ndevelop a Spanish language dataset for skill extraction and classification,\nprovide annotation methodology to distinguish between knowledge, skill, and\nabilities, and provide deep learning baselines to advance robust solutions for\nskill classification.\n","authors":["Sabur Butt","Hector G. Ceballos","Diana P. Madera"],"pdf_url":"https://arxiv.org/pdf/2503.03932v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.10254v3","updated":"2025-03-05T21:57:04Z","published":"2024-10-14T08:10:34Z","title":"LoLCATs: On Low-Rank Linearizing of Large Language Models","summary":"  Recent works show we can linearize large language models (LLMs) -- swapping\nthe quadratic attentions of popular Transformer-based LLMs with subquadratic\nanalogs, such as linear attention -- avoiding the expensive pretraining costs.\nHowever, linearizing LLMs often significantly degrades model quality, still\nrequires training over billions of tokens, and remains limited to smaller 1.3B\nto 7B LLMs. We thus propose Low-rank Linear Conversion via Attention Transfer\n(LoLCATs), a simple two-step method that improves LLM linearizing quality with\norders of magnitudes less memory and compute. We base these steps on two\nfindings. First, we can replace an LLM's softmax attentions with\nclosely-approximating linear attentions, simply by training the linear\nattentions to match their softmax counterparts with an output MSE loss\n(\"attention transfer\"). Then, this enables adjusting for approximation errors\nand recovering LLM quality simply with low-rank adaptation (LoRA). LoLCATs\nsignificantly improves linearizing quality, training efficiency, and\nscalability. We significantly reduce the linearizing quality gap and produce\nstate-of-the-art subquadratic LLMs from Llama 3 8B and Mistral 7B v0.1, leading\nto 20+ points of improvement on 5-shot MMLU. Furthermore, LoLCATs does so with\nonly 0.2% of past methods' model parameters and 0.4% of their training tokens.\nFinally, we apply LoLCATs to create the first linearized 70B and 405B LLMs (50x\nlarger than prior work). When compared with prior approaches under the same\ncompute budgets, LoLCATs significantly improves linearizing quality, closing\nthe gap between linearized and original Llama 3.1 70B and 405B LLMs by 77.8%\nand 78.1% on 5-shot MMLU.\n","authors":["Michael Zhang","Simran Arora","Rahul Chalamala","Alan Wu","Benjamin Spector","Aaryan Singhal","Krithik Ramesh","Christopher Ré"],"pdf_url":"https://arxiv.org/pdf/2410.10254v3.pdf","comment":"58 pages, 25 figures, 26 tables, ICLR 2025"},{"id":"http://arxiv.org/abs/2402.14973v4","updated":"2025-03-05T21:42:27Z","published":"2024-02-22T21:22:04Z","title":"GenCeption: Evaluate Vision LLMs with Unlabeled Unimodal Data","summary":"  Multimodal Large Language Models (MLLMs) are typically assessed using\nexpensive annotated multimodal benchmarks, which often lag behind the rapidly\nevolving demands of MLLM evaluation. This paper outlines and validates\nGenCeption, a novel, annotation-free evaluation method that requires only\nunimodal data to measure inter-modality semantic coherence and inversely\nassesses MLLMs' tendency to hallucinate. This approach eliminates the need for\ncostly data annotation, minimizes the risk of training data contamination, is\nexpected to result in slower benchmark saturation, and avoids the illusion of\nemerging abilities. Inspired by the DrawCeption game, GenCeption begins with a\nnon-textual sample and proceeds through iterative description and generation\nsteps. The semantic drift across iterations is quantified using the GC@T\nmetric. While GenCeption is principally applicable to MLLMs across various\nmodalities, this paper focuses on its implementation and validation for Vision\nLLMs (VLLMs). Based on the GenCeption method, we establish the MMECeption\nbenchmark for evaluating VLLMs, and compare the performance of several popular\nVLLMs and human annotators. Our empirical results validate GenCeption's\neffectiveness, demonstrating strong correlations with established VLLM\nbenchmarks. VLLMs still significantly lag behind human performance and struggle\nespecially with text-intensive tasks.\n","authors":["Lele Cao","Valentin Buchner","Zineb Senane","Fangkai Yang"],"pdf_url":"https://arxiv.org/pdf/2402.14973v4.pdf","comment":"Published by Computer Speech & Language\n  (https://doi.org/10.1016/j.csl.2025.101785). Source code and Leaderboard:\n  https://github.com/llcresearch/GenCeption"},{"id":"http://arxiv.org/abs/2503.03920v1","updated":"2025-03-05T21:41:03Z","published":"2025-03-05T21:41:03Z","title":"Personalized Federated Fine-tuning for Heterogeneous Data: An Automatic\n  Rank Learning Approach via Two-Level LoRA","summary":"  We study the task of personalized federated fine-tuning with heterogeneous\ndata in the context of language models, where clients collaboratively fine-tune\na language model (e.g., BERT, GPT) without sharing their local data, achieving\npersonalization simultaneously. While recent efforts have applied\nparameter-efficient fine-tuning techniques like low-rank adaptation (LoRA) in\nfederated settings, they typically use single or multiple independent low-rank\nadapters with predefined maximal and minimal ranks, which may not be optimal\nfor diverse data sources over clients.\n  To address this issue, we propose PF2LoRA, a new personalized federated\nfine-tuning algorithm built on a novel \\emph{automatic rank learning approach\nvia two-level LoRA}. Given the pretrained language model whose weight is\nfrozen, our algorithm aims to learn two levels of adaptation simultaneously:\nthe first level aims to learn a common adapter for all clients, while the\nsecond level fosters individual client personalization. A key advantage of\nPF2LoRA is its ability to adaptively determine a suitable rank based on an\nindividual client's data, rather than relying on a predefined rank that is\nagnostic to data heterogeneity. We present a synthetic example that highlights\nhow PF2LoRA automatically learns the ground-truth rank for each client,\ntailoring the adaptation to match the properties of their individual data.\nNotably, this approach introduces minimal additional memory overhead, as the\nsecond-level adaptation comprises a small number of parameters compared to the\nfirst level. Our experiments on natural language understanding and generation\ntasks demonstrate that PF2LoRA significantly outperforms existing federated\nfine-tuning methods.\n","authors":["Jie Hao","Yuman Wu","Ali Payani","Myungjin Lee","Mingrui Liu"],"pdf_url":"https://arxiv.org/pdf/2503.03920v1.pdf","comment":"28 pages, 5 figures"},{"id":"http://arxiv.org/abs/2410.18653v2","updated":"2025-03-05T21:24:29Z","published":"2024-10-24T11:32:01Z","title":"Towards Better Open-Ended Text Generation: A Multicriteria Evaluation\n  Framework","summary":"  Open-ended text generation has become a prominent task in natural language\nprocessing due to the rise of powerful (large) language models. However,\nevaluating the quality of these models and the employed decoding strategies\nremains challenging because of trade-offs among widely used metrics such as\ncoherence, diversity, and perplexity. Decoding methods often excel in some\nmetrics while underperforming in others, complicating the establishment of a\nclear ranking. In this paper, we present novel ranking strategies within this\nmulticriteria framework. Specifically, we employ benchmarking approaches based\non partial orderings and present a new summary metric designed to balance\nexisting automatic indicators, providing a more holistic evaluation of text\ngeneration quality. Our experiments demonstrate that the proposed methods offer\na robust way to compare decoding strategies, and serve as valuable tools in\nguiding model selection for open-ended text generation tasks. Finally, we\nsuggest future directions for improving evaluation methodologies in text\ngeneration. Our codebase, datasets, and models are publicly available.\n","authors":["Esteban Garces Arias","Hannah Blocher","Julian Rodemann","Meimingwei Li","Christian Heumann","Matthias Aßenmacher"],"pdf_url":"https://arxiv.org/pdf/2410.18653v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.16366v2","updated":"2025-03-05T20:31:47Z","published":"2025-02-22T21:48:48Z","title":"A generative approach to LLM harmfulness detection with special red flag\n  tokens","summary":"  Most safety training methods for large language models (LLMs) based on\nfine-tuning rely on dramatically changing the output distribution of the model\nwhen faced with a harmful request, shifting it from an unsafe answer to a\nrefusal to respond. These methods inherently compromise model capabilities and\nmight make auto-regressive models vulnerable to attacks that make likely an\ninitial token of affirmative response. To avoid that, we propose to expand the\nmodel's vocabulary with a special token we call red flag token (<rf>) and\npropose to fine-tune the model to generate this token at any time harmful\ncontent is generated or about to be generated. This novel safety training\nmethod effectively augments LLMs into generative classifiers of harmfulness at\nall times during the conversation. This method offers several advantages: it\nenables the model to explicitly learn the concept of harmfulness while\nmarginally affecting the generated distribution, thus maintaining the model's\nutility. It also evaluates each generated answer rather than just the input\nprompt and provides a stronger defence against sampling-based attacks. In\naddition, it simplifies the evaluation of the model's robustness and reduces\ncorrelated failures when combined with a classifier. We further show an\nincreased robustness to long contexts, and supervised fine-tuning attacks.\n","authors":["Sophie Xhonneux","David Dobre","Mehrnaz Mofakhami","Leo Schwinn","Gauthier Gidel"],"pdf_url":"https://arxiv.org/pdf/2502.16366v2.pdf","comment":"13 pages, 6 figures"},{"id":"http://arxiv.org/abs/2303.14537v4","updated":"2025-03-05T20:30:05Z","published":"2023-03-25T19:03:57Z","title":"Deep Augmentation: Dropout as Augmentation for Self-Supervised Learning","summary":"  Despite dropout's ubiquity in machine learning, its effectiveness as a form\nof data augmentation remains under-explored. We address two key questions: (i)\nWhen is dropout effective as an augmentation strategy? (ii) Is dropout uniquely\neffective under these conditions? To explore these questions, we propose Deep\nAugmentation, a network- and modality-agnostic method that applies dropout or\nPCA transformations to targeted layers in neural networks. Through extensive\nexperiments on contrastive learning tasks in NLP, computer vision, and graph\nlearning, we find that uniformly applying dropout across layers does not\nconsistently improve performance. Instead, dropout proves most beneficial in\ndeeper layers and can be matched by alternative augmentations (e.g., PCA). We\nalso show that a stop-gradient operation is critical for ensuring dropout\nfunctions effectively as an augmentation, and that performance trends invert\nwhen moving from contrastive tasks to supervised tasks. Our analysis suggests\nthat Deep Augmentation helps mitigate inter-layer co-adaptation -- a notable\nissue in self-supervised learning due to the absence of labeled data. Drawing\non these insights, we outline a procedure for selecting the optimal\naugmentation layer and demonstrate that Deep Augmentation can outperform\ntraditional input-level augmentations. This simple yet powerful approach can be\nseamlessly integrated into a wide range of architectures and modalities,\nyielding notable gains in both performance and generalization.\n","authors":["Rickard Brüel-Gabrielsson","Tongzhou Wang","Manel Baradad","Justin Solomon"],"pdf_url":"https://arxiv.org/pdf/2303.14537v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03874v1","updated":"2025-03-05T20:09:59Z","published":"2025-03-05T20:09:59Z","title":"LEWIS (LayEr WIse Sparsity) -- A Training Free Guided Model Merging\n  Approach","summary":"  As specialized large language models (LLMs) become increasingly prevalent,\nmodel merging methods are being used to combine them to create a single\nmulti-task model without requiring any additional data or training. However,\nthese approaches fall short when the objective of merging is to increase the\ndownstream model's performance on a particular task-specific benchmark. In this\nwork, we propose LEWIS (Layer Wise Sparsity), a guided model-merging framework\nthat uses activation-based layer importance to dynamically adjust layer-wise\ntask-vector sparsity required for the merge process. LEWIS uses a calibration\ndataset to prioritize critical layers during the task-vector pruning process\nrequired for model merging. This approach guides existing merging methods by\npreserving essential layer-wise task-specific knowledge while ensuring the\nmerged model performs the best at benchmarks resembling the calibration\ndataset. Our experiments demonstrate the effectiveness of LEWIS with\nperformance improvements of code instruction-following and math-solving models\ncreated through model merging up to 4 percent and 11.3 percent, respectively,\noutperforming unguided data-less model merging approaches that use\nuniform-sparsity.\n","authors":["Hetarth Chopra","Vidhi Rambhia","Vikram Adve"],"pdf_url":"https://arxiv.org/pdf/2503.03874v1.pdf","comment":"Accepted at ICLR 2025 Workshop: SLLM (Sparsity in Large Language\n  Models)"},{"id":"http://arxiv.org/abs/2406.01566v2","updated":"2025-03-05T20:00:57Z","published":"2024-06-03T17:47:53Z","title":"Helix: Serving Large Language Models over Heterogeneous GPUs and Network\n  via Max-Flow","summary":"  This paper introduces Helix, a distributed system for high-throughput,\nlow-latency large language model (LLM) serving in heterogeneous GPU clusters.\nThe key idea behind Helix is to formulate inference computation of LLMs over\nheterogeneous GPUs and network connections as a max-flow problem on directed,\nweighted graphs, whose nodes represent GPU instances and edges capture both GPU\nand network heterogeneity through their capacities. Helix then uses a mixed\ninteger linear programming (MILP) algorithm to discover highly optimized\nstrategies to serve LLMs on heterogeneous GPUs. This approach allows Helix to\njointly optimize model placement and request scheduling, two highly entangled\ntasks in heterogeneous LLM serving. Our evaluation on several heterogeneous\nclusters ranging from 24 to 42 GPU nodes shows that Helix improves serving\nthroughput by up to 3.3x and reduces prompting and decoding latency by up to\n66% and 24%, respectively, compared to existing approaches. Helix is available\nat https://github.com/Thesys-lab/Helix-ASPLOS25.\n","authors":["Yixuan Mei","Yonghao Zhuang","Xupeng Miao","Juncheng Yang","Zhihao Jia","Rashmi Vinayak"],"pdf_url":"https://arxiv.org/pdf/2406.01566v2.pdf","comment":"ASPLOS 2025"},{"id":"http://arxiv.org/abs/2404.08679v2","updated":"2025-03-05T19:51:23Z","published":"2024-04-07T10:32:49Z","title":"Your Finetuned Large Language Model is Already a Powerful\n  Out-of-distribution Detector","summary":"  We revisit the likelihood ratio between a pretrained large language model\n(LLM) and its finetuned variant as a criterion for out-of-distribution (OOD)\ndetection. The intuition behind such a criterion is that, the pretrained LLM\nhas the prior knowledge about OOD data due to its large amount of training\ndata, and once finetuned with the in-distribution data, the LLM has sufficient\nknowledge to distinguish their difference. Leveraging the power of LLMs, we\nshow that, the likelihood ratio can serve as an effective OOD detection\ncriterion. Moreover, we apply the proposed LLM-based likelihood ratio to detect\nOOD questions in question-answering (QA) systems, which can be used to improve\nthe performance of specialized LLMs for general questions. Given that\nlikelihood can be easily obtained by the loss functions within contemporary\nneural network frameworks, it is straightforward to implement this approach in\npractice. Since both the pretrained LLMs and its various finetuned models are\nwidely available from online platforms such as Hugging Face, our proposed\ncriterion can be effortlessly incorporated for OOD detection without the need\nfor further training. We conduct comprehensive evaluation across on multiple\nsettings, including far OOD, near OOD, spam detection, and QA scenarios, to\ndemonstrate the effectiveness of the method. Code can be found at\nhttps://github.com/andiac/LLMOODratio\n","authors":["Andi Zhang","Tim Z. Xiao","Weiyang Liu","Robert Bamler","Damon Wischik"],"pdf_url":"https://arxiv.org/pdf/2404.08679v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03862v1","updated":"2025-03-05T19:46:04Z","published":"2025-03-05T19:46:04Z","title":"Not-Just-Scaling Laws: Towards a Better Understanding of the Downstream\n  Impact of Language Model Design Decisions","summary":"  Improvements in language model capabilities are often attributed to\nincreasing model size or training data, but in some cases smaller models\ntrained on curated data or with different architectural decisions can\noutperform larger ones trained on more tokens. What accounts for this? To\nquantify the impact of these design choices, we meta-analyze 92 open-source\npretrained models across a wide array of scales, including state-of-the-art\nopen-weights models as well as less performant models and those with less\nconventional design decisions. We find that by incorporating features besides\nmodel size and number of training tokens, we can achieve a relative 3-28%\nincrease in ability to predict downstream performance compared with using scale\nalone. Analysis of model design decisions reveal insights into data\ncomposition, such as the trade-off between language and code tasks at 15-25\\%\ncode, as well as the better performance of some architectural decisions such as\nchoosing rotary over learned embeddings. Broadly, our framework lays a\nfoundation for more systematic investigation of how model development choices\nshape final capabilities.\n","authors":["Emmy Liu","Amanda Bertsch","Lintang Sutawika","Lindia Tjuatja","Patrick Fernandes","Lara Marinov","Michael Chen","Shreya Singhal","Carolin Lawrence","Aditi Raghunathan","Kiril Gashteovski","Graham Neubig"],"pdf_url":"https://arxiv.org/pdf/2503.03862v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03854v1","updated":"2025-03-05T19:36:43Z","published":"2025-03-05T19:36:43Z","title":"Vision-Language Models Struggle to Align Entities across Modalities","summary":"  Cross-modal entity linking refers to the ability to align entities and their\nattributes across different modalities. While cross-modal entity linking is a\nfundamental skill needed for real-world applications such as multimodal code\ngeneration, fake news detection, or scene understanding, it has not been\nthoroughly studied in the literature. In this paper, we introduce a new task\nand benchmark to address this gap. Our benchmark, MATE, consists of 5.5k\nevaluation instances featuring visual scenes aligned with their textual\nrepresentations. To evaluate cross-modal entity linking performance, we design\na question-answering task that involves retrieving one attribute of an object\nin one modality based on a unique attribute of that object in another modality.\nWe evaluate state-of-the-art Vision-Language Models (VLMs) and humans on this\ntask, and find that VLMs struggle significantly compared to humans,\nparticularly as the number of objects in the scene increases. Our analysis also\nshows that, while chain-of-thought prompting can improve VLM performance,\nmodels remain far from achieving human-level proficiency. These findings\nhighlight the need for further research in cross-modal entity linking and show\nthat MATE is a strong benchmark to support that progress.\n","authors":["Iñigo Alonso","Ander Salaberria","Gorka Azkune","Jeremy Barnes","Oier Lopez de Lacalle"],"pdf_url":"https://arxiv.org/pdf/2503.03854v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.05881v3","updated":"2025-03-05T19:34:08Z","published":"2024-06-09T18:40:24Z","title":"LGR2: Language Guided Reward Relabeling for Accelerating Hierarchical\n  Reinforcement Learning","summary":"  Developing interactive systems that utilize natural language instructions to\nsolve complex robotic control tasks has long been a goal of the robotics\ncommunity. While Large Language Models (LLMs) excel at logical reasoning,\nin-context learning, and code generation, translating high-level instructions\ninto low-level robotic actions still remains challenging. Furthermore, solving\nsuch tasks often requires acquiring policies to execute diverse subtasks and\nintegrating them to achieve the final objective. Hierarchical Reinforcement\nLearning (HRL) offers a promising solution for solving such tasks by enabling\ntemporal abstraction and improved exploration. However, HRL suffers from\nnon-stationarity caused by the changing lower-level behaviour, which hinders\neffective policy learning. We propose LGR2, a novel HRL framework that\nmitigates non-stationarity in HRL by using language-guided higher-level rewards\nthat remain unaffected by the changing lower-level policy behaviour. To analyze\nthe efficacy of our approach, we perform empirical analysis to demonstrate that\nLGR2 effectively mitigates non-stationarity in HRL and attains success rates\nexceeding 70% in challenging, sparsely-rewarded robotic navigation and\nmanipulation environments, where other baselines typically fail to show\nsignificant progress. Finally, we perform real-world robotic experiments on\ncomplex tasks and demonstrate that LGR2 consistently outperforms the baselines.\n","authors":["Utsav Singh","Pramit Bhattacharyya","Vinay P. Namboodiri"],"pdf_url":"https://arxiv.org/pdf/2406.05881v3.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2503.03751v1","updated":"2025-03-05T18:59:50Z","published":"2025-03-05T18:59:50Z","title":"GEN3C: 3D-Informed World-Consistent Video Generation with Precise Camera\n  Control","summary":"  We present GEN3C, a generative video model with precise Camera Control and\ntemporal 3D Consistency. Prior video models already generate realistic videos,\nbut they tend to leverage little 3D information, leading to inconsistencies,\nsuch as objects popping in and out of existence. Camera control, if implemented\nat all, is imprecise, because camera parameters are mere inputs to the neural\nnetwork which must then infer how the video depends on the camera. In contrast,\nGEN3C is guided by a 3D cache: point clouds obtained by predicting the\npixel-wise depth of seed images or previously generated frames. When generating\nthe next frames, GEN3C is conditioned on the 2D renderings of the 3D cache with\nthe new camera trajectory provided by the user. Crucially, this means that\nGEN3C neither has to remember what it previously generated nor does it have to\ninfer the image structure from the camera pose. The model, instead, can focus\nall its generative power on previously unobserved regions, as well as advancing\nthe scene state to the next frame. Our results demonstrate more precise camera\ncontrol than prior work, as well as state-of-the-art results in sparse-view\nnovel view synthesis, even in challenging settings such as driving scenes and\nmonocular dynamic video. Results are best viewed in videos. Check out our\nwebpage! https://research.nvidia.com/labs/toronto-ai/GEN3C/\n","authors":["Xuanchi Ren","Tianchang Shen","Jiahui Huang","Huan Ling","Yifan Lu","Merlin Nimier-David","Thomas Müller","Alexander Keller","Sanja Fidler","Jun Gao"],"pdf_url":"https://arxiv.org/pdf/2503.03751v1.pdf","comment":"To appear in CVPR 2025. Website:\n  https://research.nvidia.com/labs/toronto-ai/GEN3C/"},{"id":"http://arxiv.org/abs/2412.04468v2","updated":"2025-03-05T18:57:01Z","published":"2024-12-05T18:59:55Z","title":"NVILA: Efficient Frontier Visual Language Models","summary":"  Visual language models (VLMs) have made significant advances in accuracy in\nrecent years. However, their efficiency has received much less attention. This\npaper introduces NVILA, a family of open VLMs designed to optimize both\nefficiency and accuracy. Building on top of VILA, we improve its model\narchitecture by first scaling up the spatial and temporal resolutions, and then\ncompressing visual tokens. This \"scale-then-compress\" approach enables NVILA to\nefficiently process high-resolution images and long videos. We also conduct a\nsystematic investigation to enhance the efficiency of NVILA throughout its\nentire lifecycle, from training and fine-tuning to deployment. NVILA matches or\nsurpasses the accuracy of many leading open and proprietary VLMs across a wide\nrange of image and video benchmarks. At the same time, it reduces training\ncosts by 4.5X, fine-tuning memory usage by 3.4X, pre-filling latency by\n1.6-2.2X, and decoding latency by 1.2-2.8X. We will soon make our code and\nmodels available to facilitate reproducibility.\n","authors":["Zhijian Liu","Ligeng Zhu","Baifeng Shi","Zhuoyang Zhang","Yuming Lou","Shang Yang","Haocheng Xi","Shiyi Cao","Yuxian Gu","Dacheng Li","Xiuyu Li","Yunhao Fang","Yukang Chen","Cheng-Yu Hsieh","De-An Huang","An-Chieh Cheng","Vishwesh Nath","Jinyi Hu","Sifei Liu","Ranjay Krishna","Daguang Xu","Xiaolong Wang","Pavlo Molchanov","Jan Kautz","Hongxu Yin","Song Han","Yao Lu"],"pdf_url":"https://arxiv.org/pdf/2412.04468v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03734v1","updated":"2025-03-05T18:44:48Z","published":"2025-03-05T18:44:48Z","title":"OTTER: A Vision-Language-Action Model with Text-Aware Visual Feature\n  Extraction","summary":"  Vision-Language-Action (VLA) models aim to predict robotic actions based on\nvisual observations and language instructions. Existing approaches require\nfine-tuning pre-trained visionlanguage models (VLMs) as visual and language\nfeatures are independently fed into downstream policies, degrading the\npre-trained semantic alignments. We propose OTTER, a novel VLA architecture\nthat leverages these existing alignments through explicit, text-aware visual\nfeature extraction. Instead of processing all visual features, OTTER\nselectively extracts and passes only task-relevant visual features that are\nsemantically aligned with the language instruction to the policy transformer.\nThis allows OTTER to keep the pre-trained vision-language encoders frozen.\nThereby, OTTER preserves and utilizes the rich semantic understanding learned\nfrom large-scale pre-training, enabling strong zero-shot generalization\ncapabilities. In simulation and real-world experiments, OTTER significantly\noutperforms existing VLA models, demonstrating strong zeroshot generalization\nto novel objects and environments. Video, code, checkpoints, and dataset:\nhttps://ottervla.github.io/.\n","authors":["Huang Huang","Fangchen Liu","Letian Fu","Tingfan Wu","Mustafa Mukadam","Jitendra Malik","Ken Goldberg","Pieter Abbeel"],"pdf_url":"https://arxiv.org/pdf/2503.03734v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03733v1","updated":"2025-03-05T18:44:35Z","published":"2025-03-05T18:44:35Z","title":"Rethinking Deep Clustering Paradigms: Self-Supervision Is All You Need","summary":"  The recent advances in deep clustering have been made possible by significant\nprogress in self-supervised and pseudo-supervised learning. However, the\ntrade-off between self-supervision and pseudo-supervision can give rise to\nthree primary issues. The joint training causes Feature Randomness and Feature\nDrift, whereas the independent training causes Feature Randomness and Feature\nTwist. In essence, using pseudo-labels generates random and unreliable\nfeatures. The combination of pseudo-supervision and self-supervision drifts the\nreliable clustering-oriented features. Moreover, moving from self-supervision\nto pseudo-supervision can twist the curved latent manifolds. This paper\naddresses the limitations of existing deep clustering paradigms concerning\nFeature Randomness, Feature Drift, and Feature Twist. We propose a new paradigm\nwith a new strategy that replaces pseudo-supervision with a second round of\nself-supervision training. The new strategy makes the transition between\ninstance-level self-supervision and neighborhood-level self-supervision\nsmoother and less abrupt. Moreover, it prevents the drifting effect that is\ncaused by the strong competition between instance-level self-supervision and\nclustering-level pseudo-supervision. Moreover, the absence of the\npseudo-supervision prevents the risk of generating random features. With this\nnovel approach, our paper introduces a Rethinking of the Deep Clustering\nParadigms, denoted by R-DC. Our model is specifically designed to address three\nprimary challenges encountered in Deep Clustering: Feature Randomness, Feature\nDrift, and Feature Twist. Experimental results conducted on six datasets have\nshown that the two-level self-supervision training yields substantial\nimprovements.\n","authors":["Amal Shaheena","Nairouz Mrabahb","Riadh Ksantinia","Abdulla Alqaddoumia"],"pdf_url":"https://arxiv.org/pdf/2503.03733v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03726v1","updated":"2025-03-05T18:28:32Z","published":"2025-03-05T18:28:32Z","title":"Active 6D Pose Estimation for Textureless Objects using Multi-View RGB\n  Frames","summary":"  Estimating the 6D pose of textureless objects from RBG images is an important\nproblem in robotics. Due to appearance ambiguities, rotational symmetries, and\nsevere occlusions, single-view based 6D pose estimators are still unable to\nhandle a wide range of objects, motivating research towards multi-view pose\nestimation and next-best-view prediction that addresses these limitations. In\nthis work, we propose a comprehensive active perception framework for\nestimating the 6D poses of textureless objects using only RGB images. Our\napproach is built upon a key idea: decoupling the 6D pose estimation into a\nsequential two-step process can greatly improve both accuracy and efficiency.\nFirst, we estimate the 3D translation of each object, resolving scale and depth\nambiguities inherent to RGB images. These estimates are then used to simplify\nthe subsequent task of determining the 3D orientation, which we achieve through\ncanonical scale template matching. Building on this formulation, we then\nintroduce an active perception strategy that predicts the next best camera\nviewpoint to capture an RGB image, effectively reducing object pose uncertainty\nand enhancing pose accuracy. We evaluate our method on the public ROBI dataset\nas well as on a transparent object dataset that we created. When evaluated\nusing the same camera viewpoints, our multi-view pose estimation significantly\noutperforms state-of-the-art approaches. Furthermore, by leveraging our\nnext-best-view strategy, our method achieves high object pose accuracy with\nsubstantially fewer viewpoints than heuristic-based policies.\n","authors":["Jun Yang","Wenjie Xue","Sahar Ghavidel","Steven L. Waslander"],"pdf_url":"https://arxiv.org/pdf/2503.03726v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03708v1","updated":"2025-03-05T17:59:19Z","published":"2025-03-05T17:59:19Z","title":"Rethinking Video Tokenization: A Conditioned Diffusion-based Approach","summary":"  Video tokenizers, which transform videos into compact latent representations,\nare key to video generation. Existing video tokenizers are based on the VAE\narchitecture and follow a paradigm where an encoder compresses videos into\ncompact latents, and a deterministic decoder reconstructs the original videos\nfrom these latents. In this paper, we propose a novel\n\\underline{\\textbf{C}}onditioned \\underline{\\textbf{D}}iffusion-based video\n\\underline{\\textbf{T}}okenizer entitled \\textbf{\\ourmethod}, which departs from\nprevious methods by replacing the deterministic decoder with a 3D causal\ndiffusion model. The reverse diffusion generative process of the decoder is\nconditioned on the latent representations derived via the encoder. With a\nfeature caching and sampling acceleration, the framework efficiently\nreconstructs high-fidelity videos of arbitrary lengths. Results show that\n{\\ourmethod} achieves state-of-the-art performance in video reconstruction\ntasks using just a single-step sampling. Even a smaller version of {\\ourmethod}\nstill achieves reconstruction results on par with the top two baselines.\nFurthermore, the latent video generation model trained using {\\ourmethod} also\nshows superior performance.\n","authors":["Nianzu Yang","Pandeng Li","Liming Zhao","Yang Li","Chen-Wei Xie","Yehui Tang","Xudong Lu","Zhihang Liu","Yun Zheng","Yu Liu","Junchi Yan"],"pdf_url":"https://arxiv.org/pdf/2503.03708v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.11774v2","updated":"2025-03-05T17:57:48Z","published":"2024-10-15T16:55:10Z","title":"Fractal Calibration for long-tailed object detection","summary":"  Real-world datasets follow an imbalanced distribution, which poses\nsignificant challenges in rare-category object detection. Recent studies tackle\nthis problem by developing re-weighting and re-sampling methods, that utilise\nthe class frequencies of the dataset. However, these techniques focus solely on\nthe frequency statistics and ignore the distribution of the classes in image\nspace, missing important information. In contrast to them, we propose FRActal\nCALibration (FRACAL): a novel post-calibration method for long-tailed object\ndetection. FRACAL devises a logit adjustment method that utilises the fractal\ndimension to estimate how uniformly classes are distributed in image space.\nDuring inference, it uses the fractal dimension to inversely downweight the\nprobabilities of uniformly spaced class predictions achieving balance in two\naxes: between frequent and rare categories, and between uniformly spaced and\nsparsely spaced classes. FRACAL is a post-processing method and it does not\nrequire any training, also it can be combined with many off-the-shelf models\nsuch as one-stage sigmoid detectors and two-stage instance segmentation models.\nFRACAL boosts the rare class performance by up to 8.6% and surpasses all\nprevious methods on LVIS dataset, while showing good generalisation to other\ndatasets such as COCO, V3Det and OpenImages. We provide the code at\nhttps://github.com/kostas1515/FRACAL.\n","authors":["Konstantinos Panagiotis Alexandridis","Ismail Elezi","Jiankang Deng","Anh Nguyen","Shan Luo"],"pdf_url":"https://arxiv.org/pdf/2410.11774v2.pdf","comment":"CVPR2025"},{"id":"http://arxiv.org/abs/2503.01776v2","updated":"2025-03-05T17:51:09Z","published":"2025-03-03T17:59:48Z","title":"Beyond Matryoshka: Revisiting Sparse Coding for Adaptive Representation","summary":"  Many large-scale systems rely on high-quality deep representations\n(embeddings) to facilitate tasks like retrieval, search, and generative\nmodeling. Matryoshka Representation Learning (MRL) recently emerged as a\nsolution for adaptive embedding lengths, but it requires full model retraining\nand suffers from noticeable performance degradations at short lengths. In this\npaper, we show that sparse coding offers a compelling alternative for achieving\nadaptive representation with minimal overhead and higher fidelity. We propose\nContrastive Sparse Representation (CSR), a method that sparsifies pre-trained\nembeddings into a high-dimensional but selectively activated feature space. By\nleveraging lightweight autoencoding and task-aware contrastive objectives, CSR\npreserves semantic quality while allowing flexible, cost-effective inference at\ndifferent sparsity levels. Extensive experiments on image, text, and multimodal\nbenchmarks demonstrate that CSR consistently outperforms MRL in terms of both\naccuracy and retrieval speed-often by large margins-while also cutting training\ntime to a fraction of that required by MRL. Our results establish sparse coding\nas a powerful paradigm for adaptive representation learning in real-world\napplications where efficiency and fidelity are both paramount. Code is\navailable at https://github.com/neilwen987/CSR_Adaptive_Rep\n","authors":["Tiansheng Wen","Yifei Wang","Zequn Zeng","Zhong Peng","Yudi Su","Xinyang Liu","Bo Chen","Hongwei Liu","Stefanie Jegelka","Chenyu You"],"pdf_url":"https://arxiv.org/pdf/2503.01776v2.pdf","comment":"A novel sparse coding framework designed for learning adaptive\n  representation"},{"id":"http://arxiv.org/abs/2503.03689v1","updated":"2025-03-05T17:31:45Z","published":"2025-03-05T17:31:45Z","title":"DualDiff+: Dual-Branch Diffusion for High-Fidelity Video Generation with\n  Reward Guidance","summary":"  Accurate and high-fidelity driving scene reconstruction demands the effective\nutilization of comprehensive scene information as conditional inputs. Existing\nmethods predominantly rely on 3D bounding boxes and BEV road maps for\nforeground and background control, which fail to capture the full complexity of\ndriving scenes and adequately integrate multimodal information. In this work,\nwe present DualDiff, a dual-branch conditional diffusion model designed to\nenhance driving scene generation across multiple views and video sequences.\nSpecifically, we introduce Occupancy Ray-shape Sampling (ORS) as a conditional\ninput, offering rich foreground and background semantics alongside 3D spatial\ngeometry to precisely control the generation of both elements. To improve the\nsynthesis of fine-grained foreground objects, particularly complex and distant\nones, we propose a Foreground-Aware Mask (FGM) denoising loss function.\nAdditionally, we develop the Semantic Fusion Attention (SFA) mechanism to\ndynamically prioritize relevant information and suppress noise, enabling more\neffective multimodal fusion. Finally, to ensure high-quality image-to-video\ngeneration, we introduce the Reward-Guided Diffusion (RGD) framework, which\nmaintains global consistency and semantic coherence in generated videos.\nExtensive experiments demonstrate that DualDiff achieves state-of-the-art\n(SOTA) performance across multiple datasets. On the NuScenes dataset, DualDiff\nreduces the FID score by 4.09% compared to the best baseline. In downstream\ntasks, such as BEV segmentation, our method improves vehicle mIoU by 4.50% and\nroad mIoU by 1.70%, while in BEV 3D object detection, the foreground mAP\nincreases by 1.46%. Code will be made available at\nhttps://github.com/yangzhaojason/DualDiff.\n","authors":["Zhao Yang","Zezhong Qian","Xiaofan Li","Weixiang Xu","Gongpeng Zhao","Ruohong Yu","Lingsi Zhu","Longjun Liu"],"pdf_url":"https://arxiv.org/pdf/2503.03689v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03664v1","updated":"2025-03-05T16:54:15Z","published":"2025-03-05T16:54:15Z","title":"A Generative Approach to High Fidelity 3D Reconstruction from Text Data","summary":"  The convergence of generative artificial intelligence and advanced computer\nvision technologies introduces a groundbreaking approach to transforming\ntextual descriptions into three-dimensional representations. This research\nproposes a fully automated pipeline that seamlessly integrates text-to-image\ngeneration, various image processing techniques, and deep learning methods for\nreflection removal and 3D reconstruction. By leveraging state-of-the-art\ngenerative models like Stable Diffusion, the methodology translates natural\nlanguage inputs into detailed 3D models through a multi-stage workflow.\n  The reconstruction process begins with the generation of high-quality images\nfrom textual prompts, followed by enhancement by a reinforcement learning agent\nand reflection removal using the Stable Delight model. Advanced image upscaling\nand background removal techniques are then applied to further enhance visual\nfidelity. These refined two-dimensional representations are subsequently\ntransformed into volumetric 3D models using sophisticated machine learning\nalgorithms, capturing intricate spatial relationships and geometric\ncharacteristics. This process achieves a highly structured and detailed output,\nensuring that the final 3D models reflect both semantic accuracy and geometric\nprecision.\n  This approach addresses key challenges in generative reconstruction, such as\nmaintaining semantic coherence, managing geometric complexity, and preserving\ndetailed visual information. Comprehensive experimental evaluations will assess\nreconstruction quality, semantic accuracy, and geometric fidelity across\ndiverse domains and varying levels of complexity. By demonstrating the\npotential of AI-driven 3D reconstruction techniques, this research offers\nsignificant implications for fields such as augmented reality (AR), virtual\nreality (VR), and digital content creation.\n","authors":["Venkat Kumar R","Deepak Saravanan"],"pdf_url":"https://arxiv.org/pdf/2503.03664v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03663v1","updated":"2025-03-05T16:52:34Z","published":"2025-03-05T16:52:34Z","title":"LION-FS: Fast & Slow Video-Language Thinker as Online Video Assistant","summary":"  First-person video assistants are highly anticipated to enhance our daily\nlives through online video dialogue. However, existing online video assistants\noften sacrifice assistant efficacy for real-time efficiency by processing\nlow-frame-rate videos with coarse-grained visual features.To overcome the\ntrade-off between efficacy and efficiency, we propose \"Fast & Slow\nVideo-Language Thinker\" as an onLIne videO assistaNt, LION-FS, achieving\nreal-time, proactive, temporally accurate, and contextually precise responses.\nLION-FS adopts a two-stage optimization strategy: 1)Fast Path: Routing-Based\nResponse Determination evaluates frame-by-frame whether an immediate response\nis necessary. To enhance response determination accuracy and handle higher\nframe-rate inputs efficiently, we employ Token Aggregation Routing to\ndynamically fuse spatiotemporal features without increasing token numbers,\nwhile utilizing Token Dropping Routing to eliminate redundant features. 2)Slow\nPath: Multi-granularity Keyframe Augmentation optimizes keyframes during\nresponse generation. To provide comprehensive and detailed responses beyond\natomic actions constrained by training data, fine-grained spatial features and\nhuman-environment interaction features are extracted through multi-granular\npooling. These features are further integrated into a meticulously designed\nmultimodal Thinking Template to guide more precise response generation.\nComprehensive evaluations on online video tasks demonstrate that LION-FS\nachieves state-of-the-art efficacy and efficiency.\n","authors":["Wei Li","Bing Hu","Rui Shao","Leyang Shen","Liqiang Nie"],"pdf_url":"https://arxiv.org/pdf/2503.03663v1.pdf","comment":"Accept to CVPR 2025"},{"id":"http://arxiv.org/abs/2409.07402v2","updated":"2025-03-05T16:48:23Z","published":"2024-09-11T16:42:22Z","title":"What to align in multimodal contrastive learning?","summary":"  Humans perceive the world through multisensory integration, blending the\ninformation of different modalities to adapt their behavior. Contrastive\nlearning offers an appealing solution for multimodal self-supervised learning.\nIndeed, by considering each modality as a different view of the same entity, it\nlearns to align features of different modalities in a shared representation\nspace. However, this approach is intrinsically limited as it only learns shared\nor redundant information between modalities, while multimodal interactions can\narise in other ways. In this work, we introduce CoMM, a Contrastive MultiModal\nlearning strategy that enables the communication between modalities in a single\nmultimodal space. Instead of imposing cross- or intra- modality constraints, we\npropose to align multimodal representations by maximizing the mutual\ninformation between augmented versions of these multimodal features. Our\ntheoretical analysis shows that shared, synergistic and unique terms of\ninformation naturally emerge from this formulation, allowing us to estimate\nmultimodal interactions beyond redundancy. We test CoMM both in a controlled\nand in a series of real-world settings: in the former, we demonstrate that CoMM\neffectively captures redundant, unique and synergistic information between\nmodalities. In the latter, CoMM learns complex multimodal interactions and\nachieves state-of-the-art results on the seven multimodal benchmarks. Code is\navailable at https://github.com/Duplums/CoMM\n","authors":["Benoit Dufumier","Javiera Castillo-Navarro","Devis Tuia","Jean-Philippe Thiran"],"pdf_url":"https://arxiv.org/pdf/2409.07402v2.pdf","comment":"ICLR 2025, 25 pages"},{"id":"http://arxiv.org/abs/2503.03655v1","updated":"2025-03-05T16:35:15Z","published":"2025-03-05T16:35:15Z","title":"Improving 6D Object Pose Estimation of metallic Household and Industry\n  Objects","summary":"  6D object pose estimation suffers from reduced accuracy when applied to\nmetallic objects. We set out to improve the state-of-the-art by addressing\nchallenges such as reflections and specular highlights in industrial\napplications. Our novel BOP-compatible dataset, featuring a diverse set of\nmetallic objects (cans, household, and industrial items) under various lighting\nand background conditions, provides additional geometric and visual cues. We\ndemonstrate that these cues can be effectively leveraged to enhance overall\nperformance. To illustrate the usefulness of the additional features, we\nimprove upon the GDRNPP algorithm by introducing an additional keypoint\nprediction and material estimator head in order to improve spatial scene\nunderstanding. Evaluations on the new dataset show improved accuracy for\nmetallic objects, supporting the hypothesis that additional geometric and\nvisual cues can improve learning.\n","authors":["Thomas Pöllabauer","Michael Gasser","Tristan Wirth","Sarah Berkei","Volker Knauthe","Arjan Kuijper"],"pdf_url":"https://arxiv.org/pdf/2503.03655v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03651v1","updated":"2025-03-05T16:26:58Z","published":"2025-03-05T16:26:58Z","title":"DoraCycle: Domain-Oriented Adaptation of Unified Generative Model in\n  Multimodal Cycles","summary":"  Adapting generative models to specific domains presents an effective solution\nfor satisfying specialized requirements. However, adapting to some complex\ndomains remains challenging, especially when these domains require substantial\npaired data to capture the targeted distributions. Since unpaired data from a\nsingle modality, such as vision or language, is more readily available, we\nutilize the bidirectional mappings between vision and language learned by the\nunified generative model to enable training on unpaired data for domain\nadaptation. Specifically, we propose DoraCycle, which integrates two multimodal\ncycles: text-to-image-to-text and image-to-text-to-image. The model is\noptimized through cross-entropy loss computed at the cycle endpoints, where\nboth endpoints share the same modality. This facilitates self-evolution of the\nmodel without reliance on annotated text-image pairs. Experimental results\ndemonstrate that for tasks independent of paired knowledge, such as\nstylization, DoraCycle can effectively adapt the unified model using only\nunpaired data. For tasks involving new paired knowledge, such as specific\nidentities, a combination of a small set of paired image-text examples and\nlarger-scale unpaired data is sufficient for effective domain-oriented\nadaptation. The code will be released at https://github.com/showlab/DoraCycle.\n","authors":["Rui Zhao","Weijia Mao","Mike Zheng Shou"],"pdf_url":"https://arxiv.org/pdf/2503.03651v1.pdf","comment":"CVPR 2025"},{"id":"http://arxiv.org/abs/2503.03644v1","updated":"2025-03-05T16:20:53Z","published":"2025-03-05T16:20:53Z","title":"DongbaMIE: A Multimodal Information Extraction Dataset for Evaluating\n  Semantic Understanding of Dongba Pictograms","summary":"  Dongba pictographs are the only pictographs still in use in the world. They\nhave pictorial ideographic features, and their symbols carry rich cultural and\ncontextual information. Due to the lack of relevant datasets, existing research\nhas difficulty in advancing the study of semantic understanding of Dongba\npictographs. To this end, we propose DongbaMIE, the first multimodal dataset\nfor semantic understanding and extraction of Dongba pictographs. The dataset\nconsists of Dongba pictograph images and their corresponding Chinese semantic\nannotations. It contains 23,530 sentence-level and 2,539 paragraph-level\nimages, covering four semantic dimensions: objects, actions, relations, and\nattributes. We systematically evaluate the GPT-4o, Gemini-2.0, and Qwen2-VL\nmodels. Experimental results show that the F1 scores of GPT-4o and Gemini in\nthe best object extraction are only 3.16 and 3.11 respectively. The F1 score of\nQwen2-VL after supervised fine-tuning is only 11.49. These results suggest that\ncurrent large multimodal models still face significant challenges in accurately\nrecognizing the diverse semantic information in Dongba pictographs. The dataset\ncan be obtained from this URL.\n","authors":["Xiaojun Bi","Shuo Li","Ziyue Wang","Fuwen Luo","Weizheng Qiao","Lu Han","Ziwei Sun","Peng Li","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2503.03644v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03640v1","updated":"2025-03-05T16:19:56Z","published":"2025-03-05T16:19:56Z","title":"An Adaptive Underwater Image Enhancement Framework via Multi-Domain\n  Fusion and Color Compensation","summary":"  Underwater optical imaging is severely degraded by light absorption,\nscattering, and color distortion, hindering visibility and accurate image\nanalysis. This paper presents an adaptive enhancement framework integrating\nillumination compensation, multi-domain filtering, and dynamic color\ncorrection. A hybrid illumination compensation strategy combining CLAHE, Gamma\ncorrection, and Retinex enhances visibility. A two-stage filtering process,\nincluding spatial-domain (Gaussian, Bilateral, Guided) and frequency-domain\n(Fourier, Wavelet) methods, effectively reduces noise while preserving details.\nTo correct color distortion, an adaptive color compensation (ACC) model\nestimates spectral attenuation and water type to combine RCP, DCP, and MUDCP\ndynamically. Finally, a perceptually guided color balance mechanism ensures\nnatural color restoration. Experimental results on benchmark datasets\ndemonstrate superior performance over state-of-the-art methods in contrast\nenhancement, color correction, and structural preservation, making the\nframework robust for underwater imaging applications.\n","authors":["Yuezhe Tian","Kangchen Yao","Xiaoyang Yu"],"pdf_url":"https://arxiv.org/pdf/2503.03640v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03637v1","updated":"2025-03-05T16:16:46Z","published":"2025-03-05T16:16:46Z","title":"4D Radar Ground Truth Augmentation with LiDAR-to-4D Radar Data Synthesis","summary":"  Ground truth augmentation (GT-Aug) is a common method for LiDAR-based object\ndetection, as it enhances object density by leveraging ground truth bounding\nboxes (GT bboxes). However, directly applying GT-Aug to 4D Radar tensor data\noverlooks important measurements outside the GT bboxes-such as\nsidelobes-leading to synthetic distributions that deviate from real-world 4D\nRadar data. To address this limitation, we propose 4D Radar Ground Truth\nAugmentation (4DR GT-Aug). Our approach first augments LiDAR data and then\nconverts it to 4D Radar data via a LiDAR-to-4D Radar data synthesis (L2RDaS)\nmodule, which explicitly accounts for measurements both inside and outside GT\nbboxes. In doing so, it produces 4D Radar data distributions that more closely\nresemble real-world measurements, thereby improving object detection accuracy.\nExperiments on the K-Radar dataset show that the proposed method achieves\nimproved performance compared to conventional GT-Aug in object detection for 4D\nRadar. The implementation code is available at\nhttps://github.com/kaist-avelab/K-Radar.\n","authors":["Woo-Jin Jung","Dong-Hee Paek","Seung-Hyun Kong"],"pdf_url":"https://arxiv.org/pdf/2503.03637v1.pdf","comment":"24 pages"},{"id":"http://arxiv.org/abs/2410.08642v2","updated":"2025-03-05T15:55:52Z","published":"2024-10-11T09:10:26Z","title":"More than Memes: A Multimodal Topic Modeling Approach to Conspiracy\n  Theories on Telegram","summary":"  To address the increasing prevalence of (audio-)visual data on social media,\nand to capture the evolving and dynamic nature of this communication,\nresearchers have begun to explore the potential of unsupervised approaches for\nanalyzing multimodal online content. However, existing research often neglects\nvisual content beyond memes, and in addition lacks methods to compare topic\nmodels across modalities. Our study addresses these gaps by applying multimodal\ntopic modeling for analyzing conspiracy theories in German-language Telegram\nchannels. We use BERTopic with CLIP for the analysis of textual and visual data\nin a corpus of ~40, 000 Telegram messages posted in October 2023 in 571\nGerman-language Telegram channels known for disseminating conspiracy theories.\nThrough this dataset, we provide insights into unimodal and multimodal topic\nmodels by analyzing symmetry and intersections of topics across modalities. We\ndemonstrate the variety of textual and visual content shared in the channels\ndiscovered through the topic modeling, and propose a conceptual framework for\nthe analysis of textual and visual discursive strategies in the communication\nof conspiracy theories. We apply the framework in a case study of the topic\ngroup Israel Gaza.\n","authors":["Elisabeth Steffen"],"pdf_url":"https://arxiv.org/pdf/2410.08642v2.pdf","comment":"12 pages, 10 figures"},{"id":"http://arxiv.org/abs/2412.17741v4","updated":"2025-03-05T15:55:51Z","published":"2024-12-23T17:44:05Z","title":"Reasoning to Attend: Try to Understand How <SEG> Token Works","summary":"  Current Large Multimodal Models (LMMs) empowered visual grounding typically\nrely on $\\texttt{<SEG>}$ token as a text prompt to jointly optimize the\nvision-language model (e.g., LLaVA) and the downstream task-specified model\n(\\eg, SAM). However, we observe that little research has looked into how it\nworks. In this work, we first visualize the similarity maps, which are obtained\nby computing the semantic similarity between the $\\texttt{<SEG>}$ token and the\nimage token embeddings derived from the last hidden layer in both the LLaVA\nencoder and SAM decoder. Intriguingly, we have found that a striking\nconsistency holds in terms of activation responses in the similarity map,which\nreveals that what $\\texttt{<SEG>}$ token contributes to is the semantic\nsimilarity within image-text pairs. Specifically, $\\texttt{<SEG>}$ token, a\nplaceholder expanded in text vocabulary, extensively queries among individual\ntokenized image patches to match the semantics of an object from text to the\npaired image while the Large Language Models (LLMs) are being fine-tuned. Upon\nthe above findings, we present READ, which facilitates LMMs' resilient\n$\\textbf{REA}$soning capability of where to atten$\\textbf{D}$ under the\nguidance of highly activated points borrowed from similarity maps. Remarkably,\nREAD features an intuitive design, Similarity as Points module (SasP), which\ncan be seamlessly applied to $\\texttt{<SEG>}$-like paradigms in a plug-and-play\nfashion. Also, extensive experiments have been conducted on the ReasonSeg and\nRefCOCO(+/g) datasets. To validate whether READ suffers from catastrophic\nforgetting of previous skills after fine-tuning, we further assess its\ngeneration ability on an augmented FP-RefCOCO(+/g) dataset. All codes and\nmodels are publicly available at https://github.com/rui-qian/READ.\n","authors":["Rui Qian","Xin Yin","Dejing Dou"],"pdf_url":"https://arxiv.org/pdf/2412.17741v4.pdf","comment":"This work has been accepted to CVPR 2025, please refer to\n  https://github.com/rui-qian/READ"},{"id":"http://arxiv.org/abs/2503.03613v1","updated":"2025-03-05T15:51:59Z","published":"2025-03-05T15:51:59Z","title":"CLIP is Strong Enough to Fight Back: Test-time Counterattacks towards\n  Zero-shot Adversarial Robustness of CLIP","summary":"  Despite its prevalent use in image-text matching tasks in a zero-shot manner,\nCLIP has been shown to be highly vulnerable to adversarial perturbations added\nonto images. Recent studies propose to finetune the vision encoder of CLIP with\nadversarial samples generated on the fly, and show improved robustness against\nadversarial attacks on a spectrum of downstream datasets, a property termed as\nzero-shot robustness. In this paper, we show that malicious perturbations that\nseek to maximise the classification loss lead to `falsely stable' images, and\npropose to leverage the pre-trained vision encoder of CLIP to counterattack\nsuch adversarial images during inference to achieve robustness. Our paradigm is\nsimple and training-free, providing the first method to defend CLIP from\nadversarial attacks at test time, which is orthogonal to existing methods\naiming to boost zero-shot adversarial robustness of CLIP. We conduct\nexperiments across 16 classification datasets, and demonstrate stable and\nconsistent gains compared to test-time defence methods adapted from existing\nadversarial robustness studies that do not rely on external networks, without\nnoticeably impairing performance on clean images. We also show that our\nparadigm can be employed on CLIP models that have been adversarially finetuned\nto further enhance their robustness at test time. Our code is available\n\\href{https://github.com/Sxing2/CLIP-Test-time-Counterattacks}{here}.\n","authors":["Songlong Xing","Zhengyu Zhao","Nicu Sebe"],"pdf_url":"https://arxiv.org/pdf/2503.03613v1.pdf","comment":"Accepted to CVPR 2025"},{"id":"http://arxiv.org/abs/2411.05738v2","updated":"2025-03-05T15:51:07Z","published":"2024-11-08T17:54:18Z","title":"StdGEN: Semantic-Decomposed 3D Character Generation from Single Images","summary":"  We present StdGEN, an innovative pipeline for generating semantically\ndecomposed high-quality 3D characters from single images, enabling broad\napplications in virtual reality, gaming, and filmmaking, etc. Unlike previous\nmethods which struggle with limited decomposability, unsatisfactory quality,\nand long optimization times, StdGEN features decomposability, effectiveness and\nefficiency; i.e., it generates intricately detailed 3D characters with\nseparated semantic components such as the body, clothes, and hair, in three\nminutes. At the core of StdGEN is our proposed Semantic-aware Large\nReconstruction Model (S-LRM), a transformer-based generalizable model that\njointly reconstructs geometry, color and semantics from multi-view images in a\nfeed-forward manner. A differentiable multi-layer semantic surface extraction\nscheme is introduced to acquire meshes from hybrid implicit fields\nreconstructed by our S-LRM. Additionally, a specialized efficient multi-view\ndiffusion model and an iterative multi-layer surface refinement module are\nintegrated into the pipeline to facilitate high-quality, decomposable 3D\ncharacter generation. Extensive experiments demonstrate our state-of-the-art\nperformance in 3D anime character generation, surpassing existing baselines by\na significant margin in geometry, texture and decomposability. StdGEN offers\nready-to-use semantic-decomposed 3D characters and enables flexible\ncustomization for a wide range of applications. Project page:\nhttps://stdgen.github.io\n","authors":["Yuze He","Yanning Zhou","Wang Zhao","Zhongkai Wu","Kaiwen Xiao","Wei Yang","Yong-Jin Liu","Xiao Han"],"pdf_url":"https://arxiv.org/pdf/2411.05738v2.pdf","comment":"CVPR 2025. 13 pages, 10 figures"},{"id":"http://arxiv.org/abs/2403.07746v3","updated":"2025-03-05T15:35:06Z","published":"2024-03-12T15:28:51Z","title":"Unleashing HyDRa: Hybrid Fusion, Depth Consistency and Radar for Unified\n  3D Perception","summary":"  Low-cost, vision-centric 3D perception systems for autonomous driving have\nmade significant progress in recent years, narrowing the gap to expensive\nLiDAR-based methods. The primary challenge in becoming a fully reliable\nalternative lies in robust depth prediction capabilities, as camera-based\nsystems struggle with long detection ranges and adverse lighting and weather\nconditions. In this work, we introduce HyDRa, a novel camera-radar fusion\narchitecture for diverse 3D perception tasks. Building upon the principles of\ndense BEV (Bird's Eye View)-based architectures, HyDRa introduces a hybrid\nfusion approach to combine the strengths of complementary camera and radar\nfeatures in two distinct representation spaces. Our Height Association\nTransformer module leverages radar features already in the perspective view to\nproduce more robust and accurate depth predictions. In the BEV, we refine the\ninitial sparse representation by a Radar-weighted Depth Consistency. HyDRa\nachieves a new state-of-the-art for camera-radar fusion of 64.2 NDS (+1.8) and\n58.4 AMOTA (+1.5) on the public nuScenes dataset. Moreover, our new\nsemantically rich and spatially accurate BEV features can be directly converted\ninto a powerful occupancy representation, beating all previous camera-based\nmethods on the Occ3D benchmark by an impressive 3.7 mIoU. Code and models are\navailable at https://github.com/phi-wol/hydra.\n","authors":["Philipp Wolters","Johannes Gilg","Torben Teepe","Fabian Herzog","Anouar Laouichi","Martin Hofmann","Gerhard Rigoll"],"pdf_url":"https://arxiv.org/pdf/2403.07746v3.pdf","comment":"10 pages, 7 figures, added eval on VoD, added appendix"},{"id":"http://arxiv.org/abs/2503.03599v1","updated":"2025-03-05T15:32:38Z","published":"2025-03-05T15:32:38Z","title":"REGRACE: A Robust and Efficient Graph-based Re-localization Algorithm\n  using Consistency Evaluation","summary":"  Loop closures are essential for correcting odometry drift and creating\nconsistent maps, especially in the context of large-scale navigation. Current\nmethods using dense point clouds for accurate place recognition do not scale\nwell due to computationally expensive scan-to-scan comparisons. Alternative\nobject-centric approaches are more efficient but often struggle with\nsensitivity to viewpoint variation. In this work, we introduce REGRACE, a novel\napproach that addresses these challenges of scalability and perspective\ndifference in re-localization by using LiDAR-based submaps. We introduce\nrotation-invariant features for each labeled object and enhance them with\nneighborhood context through a graph neural network. To identify potential\nrevisits, we employ a scalable bag-of-words approach, pooling one learned\nglobal feature per submap. Additionally, we define a revisit with geometrical\nconsistency cues rather than embedding distance, allowing us to recognize\nfar-away loop closures. Our evaluations demonstrate that REGRACE achieves\nsimilar results compared to state-of-the-art place recognition and registration\nbaselines while being twice as fast.\n","authors":["Débora N. P. Oliveira","Joshua Knights","Sebastián Barbas Laina","Simon Boche","Wolfram Burgard","Stefan Leutenegger"],"pdf_url":"https://arxiv.org/pdf/2503.03599v1.pdf","comment":"Submitted to IROS2025"},{"id":"http://arxiv.org/abs/2501.01999v2","updated":"2025-03-05T15:26:17Z","published":"2025-01-01T07:00:41Z","title":"On the Utility of Equivariance and Symmetry Breaking in Deep Learning\n  Architectures on Point Clouds","summary":"  This paper explores the key factors that influence the performance of models\nworking with point clouds, across different tasks of varying geometric\ncomplexity. In this work, we explore the trade-offs between flexibility and\nweight-sharing introduced by equivariant layers, assessing when equivariance\nboosts or detracts from performance. It is often argued that providing more\ninformation as input improves a model's performance. However, if this\nadditional information breaks certain properties, such as $\\SE(3)$\nequivariance, does it remain beneficial? We identify the key aspects of\nequivariant and non-equivariant architectures that drive success in different\ntasks by benchmarking them on segmentation, regression, and generation tasks\nacross multiple datasets with increasing complexity. We observe a positive\nimpact of equivariance, which becomes more pronounced with increasing task\ncomplexity, even when strict equivariance is not required.\n","authors":["Sharvaree Vadgama","Mohammad Mohaiminul Islam","Domas Buracus","Christian Shewmake","Erik Bekkers"],"pdf_url":"https://arxiv.org/pdf/2501.01999v2.pdf","comment":"19 pages, 4 figures"},{"id":"http://arxiv.org/abs/2410.05096v2","updated":"2025-03-05T15:26:13Z","published":"2024-10-07T14:50:56Z","title":"Human-in-the-loop Reasoning For Traffic Sign Detection: Collaborative\n  Approach Yolo With Video-llava","summary":"  Traffic Sign Recognition (TSR) detection is a crucial component of autonomous\nvehicles. While You Only Look Once (YOLO) is a popular real-time object\ndetection algorithm, factors like training data quality and adverse weather\nconditions (e.g., heavy rain) can lead to detection failures. These failures\ncan be particularly dangerous when visual similarities between objects exist,\nsuch as mistaking a 30 km/h sign for a higher speed limit sign. This paper\nproposes a method that combines video analysis and reasoning, prompting with a\nhuman-in-the-loop guide large vision model to improve YOLOs accuracy in\ndetecting road speed limit signs, especially in semi-real-world conditions. It\nis hypothesized that the guided prompting and reasoning abilities of\nVideo-LLava can enhance YOLOs traffic sign detection capabilities. This\nhypothesis is supported by an evaluation based on human-annotated accuracy\nmetrics within a dataset of recorded videos from the CARLA car simulator. The\nresults demonstrate that a collaborative approach combining YOLO with\nVideo-LLava and reasoning can effectively address challenging situations such\nas heavy rain and overcast conditions that hinder YOLOs detection capabilities.\n","authors":["Mehdi Azarafza","Fatima Idrees","Ali Ehteshami Bejnordi","Charles Steinmetz","Stefan Henkler","Achim Rettberg"],"pdf_url":"https://arxiv.org/pdf/2410.05096v2.pdf","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2409.16215v2","updated":"2025-03-05T14:49:21Z","published":"2024-09-24T16:21:27Z","title":"Tiny Robotics Dataset and Benchmark for Continual Object Detection","summary":"  Detecting objects in mobile robotics is crucial for numerous applications,\nfrom autonomous navigation to inspection. However, robots often need to operate\nin different domains from those they were trained in, requiring them to adjust\nto these changes. Tiny mobile robots, subject to size, power, and computational\nconstraints, encounter even more difficulties in running and adapting these\nalgorithms. Such adaptability, though, is crucial for real-world deployment,\nwhere robots must operate effectively in dynamic and unpredictable settings. In\nthis work, we introduce a novel benchmark to evaluate the continual learning\ncapabilities of object detection systems in tiny robotic platforms. Our\ncontributions include: (i) Tiny Robotics Object Detection~(TiROD), a\ncomprehensive dataset collected using the onboard camera of a small mobile\nrobot, designed to test object detectors across various domains and classes;\n(ii) a benchmark of different continual learning strategies on this dataset\nusing NanoDet, a lightweight object detector. Our results highlight key\nchallenges in developing robust and efficient continual learning strategies for\nobject detectors in tiny robotics.\n","authors":["Francesco Pasti","Riccardo De Monte","Davide Dalle Pezze","Gian Antonio Susto","Nicola Bellotto"],"pdf_url":"https://arxiv.org/pdf/2409.16215v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03562v1","updated":"2025-03-05T14:49:08Z","published":"2025-03-05T14:49:08Z","title":"Towards Visual Discrimination and Reasoning of Real-World Physical\n  Dynamics: Physics-Grounded Anomaly Detection","summary":"  Humans detect real-world object anomalies by perceiving, interacting, and\nreasoning based on object-conditioned physical knowledge. The long-term goal of\nIndustrial Anomaly Detection (IAD) is to enable machines to autonomously\nreplicate this skill. However, current IAD algorithms are largely developed and\ntested on static, semantically simple datasets, which diverge from real-world\nscenarios where physical understanding and reasoning are essential.To bridge\nthis gap, we introduce the Physics Anomaly Detection (Phys-AD) dataset, the\nfirst large-scale, real-world, physics-grounded video dataset for industrial\nanomaly detection. Collected using a real robot arm and motor, Phys-AD provides\na diverse set of dynamic, semantically rich scenarios. The dataset includes\nmore than 6400 videos across 22 real-world object categories, interacting with\nrobot arms and motors, and exhibits 47 types of anomalies. Anomaly detection in\nPhys-AD requires visual reasoning, combining both physical knowledge and video\ncontent to determine object abnormality.We benchmark state-of-the-art anomaly\ndetection methods under three settings: unsupervised AD, weakly-supervised AD,\nand video-understanding AD, highlighting their limitations in handling\nphysics-grounded anomalies. Additionally, we introduce the Physics Anomaly\nExplanation (PAEval) metric, designed to assess the ability of visual-language\nfoundation models to not only detect anomalies but also provide accurate\nexplanations for their underlying physical causes. Our dataset and benchmark\nwill be publicly available.\n","authors":["Wenqiao Li","Yao Gu","Xintao Chen","Xiaohao Xu","Ming Hu","Xiaonan Huang","Yingna Wu"],"pdf_url":"https://arxiv.org/pdf/2503.03562v1.pdf","comment":"Accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2411.13982v2","updated":"2025-03-05T14:45:55Z","published":"2024-11-21T09:47:13Z","title":"Safety Without Semantic Disruptions: Editing-free Safe Image Generation\n  via Context-preserving Dual Latent Reconstruction","summary":"  Training multimodal generative models on large, uncurated datasets can result\nin users being exposed to harmful, unsafe and controversial or\nculturally-inappropriate outputs. While model editing has been proposed to\nremove or filter undesirable concepts in embedding and latent spaces, it can\ninadvertently damage learned manifolds, distorting concepts in close semantic\nproximity. We identify limitations in current model editing techniques, showing\nthat even benign, proximal concepts may become misaligned. To address the need\nfor safe content generation, we leverage safe embeddings and a modified\ndiffusion process with tunable weighted summation in the latent space to\ngenerate safer images. Our method preserves global context without compromising\nthe structural integrity of the learned manifolds. We achieve state-of-the-art\nresults on safe image generation benchmarks and offer intuitive control over\nthe level of model safety. We identify trade-offs between safety and\ncensorship, which presents a necessary perspective in the development of\nethical AI models. We will release our code.\n  Keywords: Text-to-Image Models, Generative AI, Safety, Reliability, Model\nEditing\n","authors":["Jordan Vice","Naveed Akhtar","Mubarak Shah","Richard Hartley","Ajmal Mian"],"pdf_url":"https://arxiv.org/pdf/2411.13982v2.pdf","comment":"This research is supported by the NISDRG project #20100007, funded by\n  the Australian Government"},{"id":"http://arxiv.org/abs/2503.03558v1","updated":"2025-03-05T14:45:32Z","published":"2025-03-05T14:45:32Z","title":"High-Quality Virtual Single-Viewpoint Surgical Video: Geometric\n  Autocalibration of Multiple Cameras in Surgical Lights","summary":"  Occlusion-free video generation is challenging due to surgeons' obstructions\nin the camera field of view. Prior work has addressed this issue by installing\nmultiple cameras on a surgical light, hoping some cameras will observe the\nsurgical field with less occlusion. However, this special camera setup poses a\nnew imaging challenge since camera configurations can change every time\nsurgeons move the light, and manual image alignment is required. This paper\nproposes an algorithm to automate this alignment task. The proposed method\ndetects frames where the lighting system moves, realigns them, and selects the\ncamera with the least occlusion. This algorithm results in a stabilized video\nwith less occlusion. Quantitative results show that our method outperforms\nconventional approaches. A user study involving medical doctors also confirmed\nthe superiority of our method.\n","authors":["Yuna Kato","Mariko Isogawa","Shohei Mori","Hideo Saito","Hiroki Kajita","Yoshifumi Takatsume"],"pdf_url":"https://arxiv.org/pdf/2503.03558v1.pdf","comment":"Accepted at MICCAI2023"},{"id":"http://arxiv.org/abs/2503.03556v1","updated":"2025-03-05T14:44:53Z","published":"2025-03-05T14:44:53Z","title":"Afford-X: Generalizable and Slim Affordance Reasoning for Task-oriented\n  Manipulation","summary":"  Object affordance reasoning, the ability to infer object functionalities\nbased on physical properties, is fundamental for task-oriented planning and\nactivities in both humans and Artificial Intelligence (AI). This capability,\nrequired for planning and executing daily activities in a task-oriented manner,\nrelies on commonsense knowledge of object physics and functionalities,\nextending beyond simple object recognition. Current computational models for\naffordance reasoning from perception lack generalizability, limiting their\napplicability in novel scenarios. Meanwhile, comprehensive Large Language\nModels (LLMs) with emerging reasoning capabilities are challenging to deploy on\nlocal devices for task-oriented manipulations. Here, we introduce LVIS-Aff, a\nlarge-scale dataset comprising 1,496 tasks and 119k images, designed to enhance\nthe generalizability of affordance reasoning from perception. Utilizing this\ndataset, we develop Afford-X, an end-to-end trainable affordance reasoning\nmodel that incorporates Verb Attention and Bi-Fusion modules to improve\nmulti-modal understanding. This model achieves up to a 12.1% performance\nimprovement over the best-reported results from non-LLM methods, while also\ndemonstrating a 1.2% enhancement compared to our previous conference paper.\nAdditionally, it maintains a compact 187M parameter size and infers nearly 50\ntimes faster than the GPT-4V API. Our work demonstrates the potential for\nefficient, generalizable affordance reasoning models that can be deployed on\nlocal devices for task-oriented manipulations. We showcase Afford-X's\neffectiveness in enabling task-oriented manipulations for robots across various\ntasks and environments, underscoring its efficiency and broad implications for\nadvancing robotics and AI systems in real-world applications.\n","authors":["Xiaomeng Zhu","Yuyang Li","Leiyao Cui","Pengfei Li","Huan-ang Gao","Yixin Zhu","Hao Zhao"],"pdf_url":"https://arxiv.org/pdf/2503.03556v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.09781v2","updated":"2025-03-05T14:44:18Z","published":"2025-01-16T18:59:10Z","title":"VideoWorld: Exploring Knowledge Learning from Unlabeled Videos","summary":"  This work explores whether a deep generative model can learn complex\nknowledge solely from visual input, in contrast to the prevalent focus on\ntext-based models like large language models (LLMs). We develop VideoWorld, an\nauto-regressive video generation model trained on unlabeled video data, and\ntest its knowledge acquisition abilities in video-based Go and robotic control\ntasks. Our experiments reveal two key findings: (1) video-only training\nprovides sufficient information for learning knowledge, including rules,\nreasoning and planning capabilities, and (2) the representation of visual\nchange is crucial for knowledge acquisition. To improve both the efficiency and\nefficacy of this process, we introduce the Latent Dynamics Model (LDM) as a key\ncomponent of VideoWorld. Remarkably, VideoWorld reaches a 5-dan professional\nlevel in the Video-GoBench with just a 300-million-parameter model, without\nrelying on search algorithms or reward mechanisms typical in reinforcement\nlearning. In robotic tasks, VideoWorld effectively learns diverse control\noperations and generalizes across environments, approaching the performance of\noracle models in CALVIN and RLBench. This study opens new avenues for knowledge\nacquisition from visual data, with all code, data, and models open-sourced for\nfurther research.\n","authors":["Zhongwei Ren","Yunchao Wei","Xun Guo","Yao Zhao","Bingyi Kang","Jiashi Feng","Xiaojie Jin"],"pdf_url":"https://arxiv.org/pdf/2501.09781v2.pdf","comment":"Code and models are released at:\n  https://maverickren.github.io/VideoWorld.github.io/"},{"id":"http://arxiv.org/abs/2210.09604v3","updated":"2025-03-05T14:43:59Z","published":"2022-10-18T05:34:58Z","title":"Perceptual Multi-Exposure Fusion","summary":"  As an ever-increasing demand for high dynamic range (HDR) scene shooting,\nmulti-exposure image fusion (MEF) technology has abounded. In recent years,\nmulti-scale exposure fusion approaches based on detail-enhancement have led the\nway for improvement in highlight and shadow details. Most of such methods,\nhowever, are too computationally expensive to be deployed on mobile devices.\nThis paper presents a perceptual multi-exposure fusion method that not just\nensures fine shadow/highlight details but with lower complexity than\ndetailenhanced methods. We analyze the potential defects of three classical\nexposure measures in lieu of using detail-enhancement component and improve two\nof them, namely adaptive Wellexposedness (AWE) and the gradient of color images\n(3-D gradient). AWE designed in YCbCr color space considers the difference\nbetween varying exposure images. 3-D gradient is employed to extract fine\ndetails. We build a large-scale multiexposure benchmark dataset suitable for\nstatic scenes, which contains 167 image sequences all told. Experiments on the\nconstructed dataset demonstrate that the proposed method exceeds existing eight\nstate-of-the-art approaches in terms of visually and MEF-SSIM value. Moreover,\nour approach can achieve a better improvement for current image enhancement\ntechniques, ensuring fine detail in bright light.\n","authors":["Xiaoning Liu"],"pdf_url":"https://arxiv.org/pdf/2210.09604v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07260v2","updated":"2025-03-05T14:40:41Z","published":"2024-12-10T07:42:02Z","title":"DFREC: DeepFake Identity Recovery Based on Identity-aware Masked\n  Autoencoder","summary":"  Recent advances in deepfake forensics have primarily focused on improving the\nclassification accuracy and generalization performance. Despite enormous\nprogress in detection accuracy across a wide variety of forgery algorithms,\nexisting algorithms lack intuitive interpretability and identity traceability\nto help with forensic investigation. In this paper, we introduce a novel\nDeepFake Identity Recovery scheme (DFREC) to fill this gap. DFREC aims to\nrecover the pair of source and target faces from a deepfake image to facilitate\ndeepfake identity tracing and reduce the risk of deepfake attack. It comprises\nthree key components: an Identity Segmentation Module (ISM), a Source Identity\nReconstruction Module (SIRM), and a Target Identity Reconstruction Module\n(TIRM). The ISM segments the input face into distinct source and target face\ninformation, and the SIRM reconstructs the source face and extracts latent\ntarget identity features with the segmented source information. The background\ncontext and latent target identity features are synergetically fused by a\nMasked Autoencoder in the TIRM to reconstruct the target face. We evaluate\nDFREC on six different high-fidelity face-swapping attacks on FaceForensics++,\nCelebaMegaFS and FFHQ-E4S datasets, which demonstrate its superior recovery\nperformance over state-of-the-art deepfake recovery algorithms. In addition,\nDFREC is the only scheme that can recover both pristine source and target faces\ndirectly from the forgery image with high fadelity.\n","authors":["Peipeng Yu","Hui Gao","Jianwei Fei","Zhitao Huang","Zhihua Xia","Chip-Hong Chang"],"pdf_url":"https://arxiv.org/pdf/2412.07260v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03548v1","updated":"2025-03-05T14:32:32Z","published":"2025-03-05T14:32:32Z","title":"Simulation-Based Performance Evaluation of 3D Object Detection Methods\n  with Deep Learning for a LiDAR Point Cloud Dataset in a SOTIF-related Use\n  Case","summary":"  Safety of the Intended Functionality (SOTIF) addresses sensor performance\nlimitations and deep learning-based object detection insufficiencies to ensure\nthe intended functionality of Automated Driving Systems (ADS). This paper\npresents a methodology examining the adaptability and performance evaluation of\nthe 3D object detection methods on a LiDAR point cloud dataset generated by\nsimulating a SOTIF-related Use Case. The major contributions of this paper\ninclude defining and modelling a SOTIF-related Use Case with 21 diverse weather\nconditions and generating a LiDAR point cloud dataset suitable for application\nof 3D object detection methods. The dataset consists of 547 frames,\nencompassing clear, cloudy, rainy weather conditions, corresponding to\ndifferent times of the day, including noon, sunset, and night. Employing\nMMDetection3D and OpenPCDET toolkits, the performance of State-of-the-Art\n(SOTA) 3D object detection methods is evaluated and compared by testing the\npre-trained Deep Learning (DL) models on the generated dataset using Average\nPrecision (AP) and Recall metrics.\n","authors":["Milin Patel","Rolf Jung"],"pdf_url":"https://arxiv.org/pdf/2503.03548v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.13335v2","updated":"2025-03-05T14:32:31Z","published":"2025-01-23T02:31:57Z","title":"Deblur-Avatar: Animatable Avatars from Motion-Blurred Monocular Videos","summary":"  We introduce a novel framework for modeling high-fidelity, animatable 3D\nhuman avatars from motion-blurred monocular video inputs. Motion blur is\nprevalent in real-world dynamic video capture, especially due to human\nmovements in 3D human avatar modeling. Existing methods either (1) assume sharp\nimage inputs, failing to address the detail loss introduced by motion blur, or\n(2) mainly consider blur by camera movements, neglecting the human motion blur\nwhich is more common in animatable avatars. Our proposed approach integrates a\nhuman movement-based motion blur model into 3D Gaussian Splatting (3DGS). By\nexplicitly modeling human motion trajectories during exposure time, we jointly\noptimize the trajectories and 3D Gaussians to reconstruct sharp, high-quality\nhuman avatars. We employ a pose-dependent fusion mechanism to distinguish\nmoving body regions, optimizing both blurred and sharp areas effectively.\nExtensive experiments on synthetic and real-world datasets demonstrate that our\nmethod significantly outperforms existing methods in rendering quality and\nquantitative metrics, producing sharp avatar reconstructions and enabling\nreal-time rendering under challenging motion blur conditions.\n","authors":["Xianrui Luo","Juewen Peng","Zhongang Cai","Lei Yang","Fan Yang","Zhiguo Cao","Guosheng Lin"],"pdf_url":"https://arxiv.org/pdf/2501.13335v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03543v1","updated":"2025-03-05T14:28:01Z","published":"2025-03-05T14:28:01Z","title":"A self-supervised cyclic neural-analytic approach for novel view\n  synthesis and 3D reconstruction","summary":"  Generating novel views from recorded videos is crucial for enabling\nautonomous UAV navigation. Recent advancements in neural rendering have\nfacilitated the rapid development of methods capable of rendering new\ntrajectories. However, these methods often fail to generalize well to regions\nfar from the training data without an optimized flight path, leading to\nsuboptimal reconstructions. We propose a self-supervised cyclic neural-analytic\npipeline that combines high-quality neural rendering outputs with precise\ngeometric insights from analytical methods. Our solution improves RGB and mesh\nreconstructions for novel view synthesis, especially in undersampled areas and\nregions that are completely different from the training dataset. We use an\neffective transformer-based architecture for image reconstruction to refine and\nadapt the synthesis process, enabling effective handling of novel, unseen poses\nwithout relying on extensive labeled datasets. Our findings demonstrate\nsubstantial improvements in rendering views of novel and also 3D\nreconstruction, which to the best of our knowledge is a first, setting a new\nstandard for autonomous navigation in complex outdoor environments.\n","authors":["Dragos Costea","Alina Marcu","Marius Leordeanu"],"pdf_url":"https://arxiv.org/pdf/2503.03543v1.pdf","comment":"Published in BMVC 2024, 10 pages, 4 figures"},{"id":"http://arxiv.org/abs/2503.02394v2","updated":"2025-03-05T14:25:37Z","published":"2025-03-04T08:35:01Z","title":"BHViT: Binarized Hybrid Vision Transformer","summary":"  Model binarization has made significant progress in enabling real-time and\nenergy-efficient computation for convolutional neural networks (CNN), offering\na potential solution to the deployment challenges faced by Vision Transformers\n(ViTs) on edge devices. However, due to the structural differences between CNN\nand Transformer architectures, simply applying binary CNN strategies to the ViT\nmodels will lead to a significant performance drop. To tackle this challenge,\nwe propose BHViT, a binarization-friendly hybrid ViT architecture and its full\nbinarization model with the guidance of three important observations.\nInitially, BHViT utilizes the local information interaction and hierarchical\nfeature aggregation technique from coarse to fine levels to address redundant\ncomputations stemming from excessive tokens. Then, a novel module based on\nshift operations is proposed to enhance the performance of the binary\nMultilayer Perceptron (MLP) module without significantly increasing\ncomputational overhead. In addition, an innovative attention matrix\nbinarization method based on quantization decomposition is proposed to evaluate\nthe token's importance in the binarized attention matrix. Finally, we propose a\nregularization loss to address the inadequate optimization caused by the\nincompatibility between the weight oscillation in the binary layers and the\nAdam Optimizer. Extensive experimental results demonstrate that our proposed\nalgorithm achieves SOTA performance among binary ViT methods.\n","authors":["Tian Gao","Zhiyuan Zhang","Yu Zhang","Huajun Liu","Kaijie Yin","Chengzhong Xu","Hui Kong"],"pdf_url":"https://arxiv.org/pdf/2503.02394v2.pdf","comment":"Accepted by CVPR2025"},{"id":"http://arxiv.org/abs/2503.03535v1","updated":"2025-03-05T14:18:39Z","published":"2025-03-05T14:18:39Z","title":"Unified Human Localization and Trajectory Prediction with Monocular\n  Vision","summary":"  Conventional human trajectory prediction models rely on clean curated data,\nrequiring specialized equipment or manual labeling, which is often impractical\nfor robotic applications. The existing predictors tend to overfit to clean\nobservation affecting their robustness when used with noisy inputs. In this\nwork, we propose MonoTransmotion (MT), a Transformer-based framework that uses\nonly a monocular camera to jointly solve localization and prediction tasks. Our\nframework has two main modules: Bird's Eye View (BEV) localization and\ntrajectory prediction. The BEV localization module estimates the position of a\nperson using 2D human poses, enhanced by a novel directional loss for smoother\nsequential localizations. The trajectory prediction module predicts future\nmotion from these estimates. We show that by jointly training both tasks with\nour unified framework, our method is more robust in real-world scenarios made\nof noisy inputs. We validate our MT network on both curated and non-curated\ndatasets. On the curated dataset, MT achieves around 12% improvement over\nbaseline models on BEV localization and trajectory prediction. On real-world\nnon-curated dataset, experimental results indicate that MT maintains similar\nperformance levels, highlighting its robustness and generalization capability.\nThe code is available at https://github.com/vita-epfl/MonoTransmotion.\n","authors":["Po-Chien Luan","Yang Gao","Celine Demonsant","Alexandre Alahi"],"pdf_url":"https://arxiv.org/pdf/2503.03535v1.pdf","comment":"ICRA 2025"},{"id":"http://arxiv.org/abs/2411.02951v2","updated":"2025-03-05T14:16:27Z","published":"2024-11-05T09:51:59Z","title":"LDPM: Towards undersampled MRI reconstruction with MR-VAE and Latent\n  Diffusion Prior","summary":"  Diffusion models, as powerful generative models, have found a wide range of\napplications and shown great potential in solving image reconstruction\nproblems. Some works attempted to solve MRI reconstruction with diffusion\nmodels, but these methods operate directly in pixel space, leading to higher\ncomputational costs for optimization and inference. Latent diffusion models,\npre-trained on natural images with rich visual priors, are expected to solve\nthe high computational cost problem in MRI reconstruction by operating in a\nlower-dimensional latent space. However, direct application to MRI\nreconstruction faces three key challenges: (1) absence of explicit control\nmechanisms for medical fidelity, (2) domain gap between natural images and MR\nphysics, and (3) undefined data consistency in latent space. To address these\nchallenges, a novel Latent Diffusion Prior-based undersampled MRI\nreconstruction (LDPM) method is proposed. Our LDPM framework addresses these\nchallenges by: (1) a sketch-guided pipeline with a two-step reconstruction\nstrategy, which balances perceptual quality and anatomical fidelity, (2) an\nMRI-optimized VAE (MR-VAE), which achieves an improvement of approximately 3.92\ndB in PSNR for undersampled MRI reconstruction compared to that with SD-VAE\n\\cite{sd}, and (3) Dual-Stage Sampler, a modified version of spaced DDPM\nsampler, which enforces high-fidelity reconstruction in the latent space.\nExperiments on the fastMRI dataset\\cite{fastmri} demonstrate the\nstate-of-the-art performance of the proposed method and its robustness across\nvarious scenarios. The effectiveness of each module is also verified through\nablation experiments.\n","authors":["Xingjian Tang","Jingwei Guan","Linge Li","Ran Shi","Youmei Zhang","Mengye Lyu","Li Yan"],"pdf_url":"https://arxiv.org/pdf/2411.02951v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.16502v2","updated":"2025-03-05T14:11:44Z","published":"2024-09-24T23:18:32Z","title":"GSplatLoc: Grounding Keypoint Descriptors into 3D Gaussian Splatting for\n  Improved Visual Localization","summary":"  Although various visual localization approaches exist, such as scene\ncoordinate regression and camera pose regression, these methods often struggle\nwith optimization complexity or limited accuracy. To address these challenges,\nwe explore the use of novel view synthesis techniques, particularly 3D Gaussian\nSplatting (3DGS), which enables the compact encoding of both 3D geometry and\nscene appearance. We propose a two-stage procedure that integrates dense and\nrobust keypoint descriptors from the lightweight XFeat feature extractor into\n3DGS, enhancing performance in both indoor and outdoor environments. The coarse\npose estimates are directly obtained via 2D-3D correspondences between the 3DGS\nrepresentation and query image descriptors. In the second stage, the initial\npose estimate is refined by minimizing the rendering-based photometric warp\nloss. Benchmarking on widely used indoor and outdoor datasets demonstrates\nimprovements over recent neural rendering-based localization methods, such as\nNeRFMatch and PNeRFLoc.\n","authors":["Gennady Sidorov","Malik Mohrat","Denis Gridusov","Ruslan Rakhimov","Sergey Kolyubin"],"pdf_url":"https://arxiv.org/pdf/2409.16502v2.pdf","comment":"Project website at https://gsplatloc.github.io/"},{"id":"http://arxiv.org/abs/2503.03528v1","updated":"2025-03-05T14:11:13Z","published":"2025-03-05T14:11:13Z","title":"AdaSin: Enhancing Hard Sample Metrics with Dual Adaptive Penalty for\n  Face Recognition","summary":"  In recent years, the emergence of deep convolutional neural networks has\npositioned face recognition as a prominent research focus in computer vision.\nTraditional loss functions, such as margin-based, hard-sample mining-based, and\nhybrid approaches, have achieved notable performance improvements, with some\nleveraging curriculum learning to optimize training. However, these methods\noften fall short in effectively quantifying the difficulty of hard samples. To\naddress this, we propose Adaptive Sine (AdaSin) loss function, which introduces\nthe sine of the angle between a sample's embedding feature and its ground-truth\nclass center as a novel difficulty metric. This metric enables precise and\neffective penalization of hard samples. By incorporating curriculum learning,\nthe model dynamically adjusts classification boundaries across different\ntraining stages. Unlike previous adaptive-margin loss functions, AdaSin\nintroduce a dual adaptive penalty, applied to both the positive and negative\ncosine similarities of hard samples. This design imposes stronger constraints,\nenhancing intra-class compactness and inter-class separability. The combination\nof the dual adaptive penalty and curriculum learning is guided by a\nwell-designed difficulty metric. It enables the model to focus more effectively\non hard samples in later training stages, and lead to the extraction of highly\ndiscriminative face features. Extensive experiments across eight benchmarks\ndemonstrate that AdaSin achieves superior accuracy compared to other\nstate-of-the-art methods.\n","authors":["Qiqi Guo","Zhuowen Zheng","Guanghua Yang","Zhiquan Liu","Xiaofan Li","Jianqing Li","Jinyu Tian","Xueyuan Gong"],"pdf_url":"https://arxiv.org/pdf/2503.03528v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.18783v2","updated":"2025-03-05T14:11:02Z","published":"2024-12-25T05:19:52Z","title":"ArtNVG: Content-Style Separated Artistic Neighboring-View Gaussian\n  Stylization","summary":"  As demand from the film and gaming industries for 3D scenes with target\nstyles grows, the importance of advanced 3D stylization techniques increases.\nHowever, recent methods often struggle to maintain local consistency in color\nand texture throughout stylized scenes, which is essential for maintaining\naesthetic coherence. To solve this problem, this paper introduces ArtNVG, an\ninnovative 3D stylization framework that efficiently generates stylized 3D\nscenes by leveraging reference style images. Built on 3D Gaussian Splatting\n(3DGS), ArtNVG achieves rapid optimization and rendering while upholding high\nreconstruction quality. Our framework realizes high-quality 3D stylization by\nincorporating two pivotal techniques: Content-Style Separated Control and\nAttention-based Neighboring-View Alignment. Content-Style Separated Control\nuses the CSGO model and the Tile ControlNet to decouple the content and style\ncontrol, reducing risks of information leakage. Concurrently, Attention-based\nNeighboring-View Alignment ensures consistency of local colors and textures\nacross neighboring views, significantly improving visual quality. Extensive\nexperiments validate that ArtNVG surpasses existing methods, delivering\nsuperior results in content preservation, style alignment, and local\nconsistency.\n","authors":["Zixiao Gu","Mengtian Li","Ruhua Chen","Zhongxia Ji","Sichen Guo","Zhenye Zhang","Guangnan Ye","Zuo Hu"],"pdf_url":"https://arxiv.org/pdf/2412.18783v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03519v1","updated":"2025-03-05T14:03:34Z","published":"2025-03-05T14:03:34Z","title":"Do ImageNet-trained models learn shortcuts? The impact of frequency\n  shortcuts on generalization","summary":"  Frequency shortcuts refer to specific frequency patterns that models heavily\nrely on for correct classification. Previous studies have shown that models\ntrained on small image datasets often exploit such shortcuts, potentially\nimpairing their generalization performance. However, existing methods for\nidentifying frequency shortcuts require expensive computations and become\nimpractical for analyzing models trained on large datasets. In this work, we\npropose the first approach to more efficiently analyze frequency shortcuts at a\nlarger scale. We show that both CNN and transformer models learn frequency\nshortcuts on ImageNet. We also expose that frequency shortcut solutions can\nyield good performance on out-of-distribution (OOD) test sets which largely\nretain texture information. However, these shortcuts, mostly aligned with\ntexture patterns, hinder model generalization on rendition-based OOD test sets.\nThese observations suggest that current OOD evaluations often overlook the\nimpact of frequency shortcuts on model generalization. Future benchmarks could\nthus benefit from explicitly assessing and accounting for these shortcuts to\nbuild models that generalize across a broader range of OOD scenarios.\n","authors":["Shunxin Wang","Raymond Veldhuis","Nicola Strisciuglio"],"pdf_url":"https://arxiv.org/pdf/2503.03519v1.pdf","comment":"received at CVPR2025"},{"id":"http://arxiv.org/abs/2402.09444v3","updated":"2025-03-05T14:02:10Z","published":"2024-01-31T15:37:12Z","title":"Multimodal Action Quality Assessment","summary":"  Action quality assessment (AQA) is to assess how well an action is performed.\nPrevious works perform modelling by only the use of visual information,\nignoring audio information. We argue that although AQA is highly dependent on\nvisual information, the audio is useful complementary information for improving\nthe score regression accuracy, especially for sports with background music,\nsuch as figure skating and rhythmic gymnastics. To leverage multimodal\ninformation for AQA, i.e., RGB, optical flow and audio information, we propose\na Progressive Adaptive Multimodal Fusion Network (PAMFN) that separately models\nmodality-specific information and mixed-modality information. Our model\nconsists of with three modality-specific branches that independently explore\nmodality-specific information and a mixed-modality branch that progressively\naggregates the modality-specific information from the modality-specific\nbranches. To build the bridge between modality-specific branches and the\nmixed-modality branch, three novel modules are proposed. First, a\nModality-specific Feature Decoder module is designed to selectively transfer\nmodality-specific information to the mixed-modality branch. Second, when\nexploring the interaction between modality-specific information, we argue that\nusing an invariant multimodal fusion policy may lead to suboptimal results, so\nas to take the potential diversity in different parts of an action into\nconsideration. Therefore, an Adaptive Fusion Module is proposed to learn\nadaptive multimodal fusion policies in different parts of an action. This\nmodule consists of several FusionNets for exploring different multimodal fusion\nstrategies and a PolicyNet for deciding which FusionNets are enabled. Third, a\nmodule called Cross-modal Feature Decoder is designed to transfer cross-modal\nfeatures generated by Adaptive Fusion Module to the mixed-modality branch.\n","authors":["Ling-An Zeng","Wei-Shi Zheng"],"pdf_url":"https://arxiv.org/pdf/2402.09444v3.pdf","comment":"IEEE Transactions on Image Processing 2024"},{"id":"http://arxiv.org/abs/2503.03507v1","updated":"2025-03-05T13:55:26Z","published":"2025-03-05T13:55:26Z","title":"Mineral segmentation using electron microscope images and spectral\n  sampling through multimodal graph neural networks","summary":"  We propose a novel Graph Neural Network-based method for segmentation based\non data fusion of multimodal Scanning Electron Microscope (SEM) images. In most\ncases, Backscattered Electron (BSE) images obtained using SEM do not contain\nsufficient information for mineral segmentation. Therefore, imaging is often\ncomplemented with point-wise Energy-Dispersive X-ray Spectroscopy (EDS)\nspectral measurements that provide highly accurate information about the\nchemical composition but that are time-consuming to acquire. This motivates the\nuse of sparse spectral data in conjunction with BSE images for mineral\nsegmentation. The unstructured nature of the spectral data makes most\ntraditional image fusion techniques unsuitable for BSE-EDS fusion. We propose\nusing graph neural networks to fuse the two modalities and segment the mineral\nphases simultaneously. Our results demonstrate that providing EDS data for as\nfew as 1% of BSE pixels produces accurate segmentation, enabling rapid analysis\nof mineral samples. The proposed data fusion pipeline is versatile and can be\nadapted to other domains that involve image data and point-wise measurements.\n","authors":["Samuel Repka","Bořek Reich","Fedor Zolotarev","Tuomas Eerola","Pavel Zemčík"],"pdf_url":"https://arxiv.org/pdf/2503.03507v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03501v1","updated":"2025-03-05T13:47:02Z","published":"2025-03-05T13:47:02Z","title":"CarGait: Cross-Attention based Re-ranking for Gait recognition","summary":"  Gait recognition is a computer vision task that identifies individuals based\non their walking patterns. Gait recognition performance is commonly evaluated\nby ranking a gallery of candidates and measuring the accuracy at the top\nRank-$K$. Existing models are typically single-staged, i.e. searching for the\nprobe's nearest neighbors in a gallery using a single global feature\nrepresentation. Although these models typically excel at retrieving the correct\nidentity within the top-$K$ predictions, they struggle when hard negatives\nappear in the top short-list, leading to relatively low performance at the\nhighest ranks (e.g., Rank-1). In this paper, we introduce CarGait, a\nCross-Attention Re-ranking method for gait recognition, that involves\nre-ordering the top-$K$ list leveraging the fine-grained correlations between\npairs of gait sequences through cross-attention between gait strips. This\nre-ranking scheme can be adapted to existing single-stage models to enhance\ntheir final results. We demonstrate the capabilities of CarGait by extensive\nexperiments on three common gait datasets, Gait3D, GREW, and OU-MVLP, and seven\ndifferent gait models, showing consistent improvements in Rank-1,5 accuracy,\nsuperior results over existing re-ranking methods, and strong baselines.\n","authors":["Gavriel Habib","Noa Barzilay","Or Shimshi","Rami Ben-Ari","Nir Darshan"],"pdf_url":"https://arxiv.org/pdf/2503.03501v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.02077v4","updated":"2025-03-05T13:43:07Z","published":"2024-05-03T13:10:16Z","title":"MVP-Shot: Multi-Velocity Progressive-Alignment Framework for Few-Shot\n  Action Recognition","summary":"  Recent few-shot action recognition (FSAR) methods typically perform semantic\nmatching on learned discriminative features to achieve promising performance.\nHowever, most FSAR methods focus on single-scale (e.g., frame-level,\nsegment-level, etc) feature alignment, which ignores that human actions with\nthe same semantic may appear at different velocities. To this end, we develop a\nnovel Multi-Velocity Progressive-alignment (MVP-Shot) framework to\nprogressively learn and align semantic-related action features at\nmulti-velocity levels. Concretely, a Multi-Velocity Feature Alignment (MVFA)\nmodule is designed to measure the similarity between features from support and\nquery videos with different velocity scales and then merge all similarity\nscores in a residual fashion. To avoid the multiple velocity features deviating\nfrom the underlying motion semantic, our proposed Progressive Semantic-Tailored\nInteraction (PSTI) module injects velocity-tailored text information into the\nvideo feature via feature interaction on channel and temporal domains at\ndifferent velocities. The above two modules compensate for each other to make\nmore accurate query sample predictions under the few-shot settings.\nExperimental results show our method outperforms current state-of-the-art\nmethods on multiple standard few-shot benchmarks (i.e., HMDB51, UCF101,\nKinetics, and SSv2-small).\n","authors":["Hongyu Qu","Rui Yan","Xiangbo Shu","Hailiang Gao","Peng Huang","Guo-Sen Xie"],"pdf_url":"https://arxiv.org/pdf/2405.02077v4.pdf","comment":"Accepted to TMM 2025"},{"id":"http://arxiv.org/abs/2402.12185v5","updated":"2025-03-05T13:41:21Z","published":"2024-02-19T14:48:23Z","title":"ChartX & ChartVLM: A Versatile Benchmark and Foundation Model for\n  Complicated Chart Reasoning","summary":"  Recently, many versatile Multi-modal Large Language Models (MLLMs) have\nemerged continuously. However, their capacity to query information depicted in\nvisual charts and engage in reasoning based on the queried contents remains\nunder-explored. In this paper, to comprehensively and rigorously benchmark the\nability of the off-the-shelf MLLMs in the chart domain, we construct ChartX, a\nmulti-modal evaluation set covering 18 chart types, 7 chart tasks, 22\ndisciplinary topics, and high-quality chart data. Besides, we develop ChartVLM\nto offer a new perspective on handling multi-modal tasks that strongly depend\non interpretable patterns, such as reasoning tasks in the field of charts or\ngeometric images. We evaluate the chart-related ability of mainstream MLLMs and\nour ChartVLM on the proposed ChartX evaluation set. Extensive experiments\ndemonstrate that ChartVLM surpasses both versatile and chart-related large\nmodels, achieving results comparable to GPT-4V. We believe that our study can\npave the way for further exploration in creating a more comprehensive chart\nevaluation set and developing more interpretable multi-modal models. Both\nChartX and ChartVLM are available at:\nhttps://github.com/Alpha-Innovator/ChartVLM\n","authors":["Renqiu Xia","Bo Zhang","Hancheng Ye","Xiangchao Yan","Qi Liu","Hongbin Zhou","Zijun Chen","Peng Ye","Min Dou","Botian Shi","Junchi Yan","Yu Qiao"],"pdf_url":"https://arxiv.org/pdf/2402.12185v5.pdf","comment":"Code and dataset are available for downloading at:\n  https://github.com/Alpha-Innovator/ChartVLM 26 pages, 15 figures"},{"id":"http://arxiv.org/abs/2503.03492v1","updated":"2025-03-05T13:32:49Z","published":"2025-03-05T13:32:49Z","title":"Find First, Track Next: Decoupling Identification and Propagation in\n  Referring Video Object Segmentation","summary":"  Referring video object segmentation aims to segment and track a target object\nin a video using a natural language prompt. Existing methods typically fuse\nvisual and textual features in a highly entangled manner, processing\nmulti-modal information together to generate per-frame masks. However, this\napproach often struggles with ambiguous target identification, particularly in\nscenes with multiple similar objects, and fails to ensure consistent mask\npropagation across frames. To address these limitations, we introduce\nFindTrack, a novel decoupled framework that separates target identification\nfrom mask propagation. FindTrack first adaptively selects a key frame by\nbalancing segmentation confidence and vision-text alignment, establishing a\nrobust reference for the target object. This reference is then utilized by a\ndedicated propagation module to track and segment the object across the entire\nvideo. By decoupling these processes, FindTrack effectively reduces ambiguities\nin target association and enhances segmentation consistency. We demonstrate\nthat FindTrack outperforms existing methods on public benchmarks.\n","authors":["Suhwan Cho","Seunghoon Lee","Minhyeok Lee","Jungho Lee","Sangyoun Lee"],"pdf_url":"https://arxiv.org/pdf/2503.03492v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.11098v4","updated":"2025-03-05T13:28:29Z","published":"2024-04-17T06:32:42Z","title":"LAPTOP-Diff: Layer Pruning and Normalized Distillation for Compressing\n  Diffusion Models","summary":"  In the era of AIGC, the demand for low-budget or even on-device applications\nof diffusion models emerged. In terms of compressing the Stable Diffusion\nmodels (SDMs), several approaches have been proposed, and most of them\nleveraged the handcrafted layer removal methods to obtain smaller U-Nets, along\nwith knowledge distillation to recover the network performance. However, such a\nhandcrafting manner of layer removal is inefficient and lacks scalability and\ngeneralization, and the feature distillation employed in the retraining phase\nfaces an imbalance issue that a few numerically significant feature loss terms\ndominate over others throughout the retraining process. To this end, we\nproposed the layer pruning and normalized distillation for compressing\ndiffusion models (LAPTOP-Diff). We, 1) introduced the layer pruning method to\ncompress SDM's U-Net automatically and proposed an effective one-shot pruning\ncriterion whose one-shot performance is guaranteed by its good additivity\nproperty, surpassing other layer pruning and handcrafted layer removal methods,\n2) proposed the normalized feature distillation for retraining, alleviated the\nimbalance issue. Using the proposed LAPTOP-Diff, we compressed the U-Nets of\nSDXL and SDM-v1.5 for the most advanced performance, achieving a minimal 4.0%\ndecline in PickScore at a pruning ratio of 50% while the comparative methods'\nminimal PickScore decline is 8.2%.\n","authors":["Dingkun Zhang","Sijia Li","Chen Chen","Qingsong Xie","Haonan Lu"],"pdf_url":"https://arxiv.org/pdf/2404.11098v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.18355v2","updated":"2025-03-05T13:25:09Z","published":"2024-12-24T11:35:40Z","title":"Handling Spatial-Temporal Data Heterogeneity for Federated Continual\n  Learning via Tail Anchor","summary":"  Federated continual learning (FCL) allows each client to continually update\nits knowledge from task streams, enhancing the applicability of federated\nlearning in real-world scenarios. However, FCL needs to address not only\nspatial data heterogeneity between clients but also temporal data heterogeneity\nbetween tasks. In this paper, empirical experiments demonstrate that such\ninput-level heterogeneity significantly affects the model's internal parameters\nand outputs, leading to severe spatial-temporal catastrophic forgetting of\nlocal and previous knowledge. To this end, we propose Federated Tail Anchor\n(FedTA) to mix trainable Tail Anchor with the frozen output features to adjust\ntheir position in the feature space, thereby overcoming parameter-forgetting\nand output-forgetting. Three novel components are also included: Input\nEnhancement for improving the performance of pre-trained models on downstream\ntasks; Selective Input Knowledge Fusion for fusion of heterogeneous local\nknowledge on the server; and Best Global Prototype Selection for finding the\nbest anchor point for each class in the feature space. Extensive experiments\ndemonstrate that FedTA not only outperforms existing FCL methods but also\neffectively preserves the relative positions of features.\n","authors":["Hao Yu","Xin Yang","Le Zhang","Hanlin Gu","Tianrui Li","Lixin Fan","Qiang Yang"],"pdf_url":"https://arxiv.org/pdf/2412.18355v2.pdf","comment":"This paper is accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2503.03479v1","updated":"2025-03-05T13:16:26Z","published":"2025-03-05T13:16:26Z","title":"Feature Point Extraction for Extra-Affine Image","summary":"  The issue concerning the significant decline in the stability of feature\nextraction for images subjected to large-angle affine transformations, where\nthe angle exceeds 50 degrees, still awaits a satisfactory solution. Even ASIFT,\nwhich is built upon SIFT and entails a considerable number of image comparisons\nsimulated by affine transformations, inevitably exhibits the drawbacks of being\ntime-consuming and imposing high demands on memory usage. And the stability of\nfeature extraction drops rapidly under large-view affine transformations.\nConsequently, we propose a method that represents an improvement over ASIFT. On\nthe premise of improving the precision and maintaining the affine invariance,\nit currently ranks as the fastest feature extraction method for extra-affine\nimages that we know of at present. Simultaneously, the stability of feature\nextraction regarding affine transformation images has been approximated to the\nmaximum limits. Both the angle between the shooting direction and the normal\ndirection of the photographed object (absolute tilt angle), and the shooting\ntransformation angle between two images (transition tilt angle) are close to 90\ndegrees. The central idea of the method lies in obtaining the optimal parameter\nset by simulating affine transformation with the reference image. And the\nsimulated affine transformation is reproduced by combining it with the Lanczos\ninterpolation based on the optimal parameter set. Subsequently, it is combined\nwith ORB, which exhibits excellent real-time performance for rapid orientation\nbinary description. Moreover, a scale parameter simulation is introduced to\nfurther augment the operational efficiency.\n","authors":["Tao Wang","Yinghui Wang","Yanxing Liang","Liangyi Huang","Jinlong Yang","Wei Li","Xiaojuan Ning"],"pdf_url":"https://arxiv.org/pdf/2503.03479v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03475v1","updated":"2025-03-05T13:10:11Z","published":"2025-03-05T13:10:11Z","title":"Bridging Synthetic-to-Real Gaps: Frequency-Aware Perturbation and\n  Selection for Single-shot Multi-Parametric Mapping Reconstruction","summary":"  Data-centric artificial intelligence (AI) has remarkably advanced medical\nimaging, with emerging methods using synthetic data to address data scarcity\nwhile introducing synthetic-to-real gaps. Unsupervised domain adaptation (UDA)\nshows promise in ground truth-scarce tasks, but its application in\nreconstruction remains underexplored. Although multiple overlapping-echo\ndetachment (MOLED) achieves ultra-fast multi-parametric reconstruction,\nextending its application to various clinical scenarios, the quality suffers\nfrom deficiency in mitigating the domain gap, difficulty in maintaining\nstructural integrity, and inadequacy in ensuring mapping accuracy. To resolve\nthese issues, we proposed frequency-aware perturbation and selection (FPS),\ncomprising Wasserstein distance-modulated frequency-aware perturbation (WDFP)\nand hierarchical frequency-aware selection network (HFSNet), which integrates\nfrequency-aware adaptive selection (FAS), compact FAS (cFAS) and feature-aware\narchitecture integration (FAI). Specifically, perturbation activates\ndomain-invariant feature learning within uncertainty, while selection refines\noptimal solutions within perturbation, establishing a robust and closed-loop\nlearning pathway. Extensive experiments on synthetic data, along with diverse\nreal clinical cases from 5 healthy volunteers, 94 ischemic stroke patients, and\n46 meningioma patients, demonstrate the superiority and clinical applicability\nof FPS. Furthermore, FPS is applied to diffusion tensor imaging (DTI),\nunderscoring its versatility and potential for broader medical applications.\nThe code is available at https://github.com/flyannie/FPS.\n","authors":["Linyu Fan","Che Wang","Ming Ye","Qizhi Yang","Zejun Wu","Xinghao Ding","Yue Huang","Jianfeng Bao","Shuhui Cai","Congbo Cai"],"pdf_url":"https://arxiv.org/pdf/2503.03475v1.pdf","comment":"This work will be submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2503.03465v1","updated":"2025-03-05T12:56:33Z","published":"2025-03-05T12:56:33Z","title":"DTU-Net: A Multi-Scale Dilated Transformer Network for Nonlinear\n  Hyperspectral Unmixing","summary":"  Transformers have shown significant success in hyperspectral unmixing (HU).\nHowever, challenges remain. While multi-scale and long-range spatial\ncorrelations are essential in unmixing tasks, current Transformer-based\nunmixing networks, built on Vision Transformer (ViT) or Swin-Transformer,\nstruggle to capture them effectively. Additionally, current Transformer-based\nunmixing networks rely on the linear mixing model, which lacks the flexibility\nto accommodate scenarios where nonlinear effects are significant. To address\nthese limitations, we propose a multi-scale Dilated Transformer-based unmixing\nnetwork for nonlinear HU (DTU-Net). The encoder employs two branches. The first\none performs multi-scale spatial feature extraction using Multi-Scale Dilated\nAttention (MSDA) in the Dilated Transformer, which varies dilation rates across\nattention heads to capture long-range and multi-scale spatial correlations. The\nsecond one performs spectral feature extraction utilizing 3D-CNNs with channel\nattention. The outputs from both branches are then fused to integrate\nmulti-scale spatial and spectral information, which is subsequently transformed\nto estimate the abundances. The decoder is designed to accommodate both linear\nand nonlinear mixing scenarios. Its interpretability is enhanced by explicitly\nmodeling the relationships between endmembers, abundances, and nonlinear\ncoefficients in accordance with the polynomial post-nonlinear mixing model\n(PPNMM). Experiments on synthetic and real datasets validate the effectiveness\nof the proposed DTU-Net compared to PPNMM-derived methods and several advanced\nunmixing networks.\n","authors":["ChenTong Wang","Jincheng Gao","Fei Zhu","Abderrahim Halimi","C'edric Richard"],"pdf_url":"https://arxiv.org/pdf/2503.03465v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.10860v2","updated":"2025-03-05T12:41:05Z","published":"2024-03-16T08:57:00Z","title":"Sim2Real within 5 Minutes: Efficient Domain Transfer with Stylized\n  Gaussian Splatting for Endoscopic Images","summary":"  Robot assisted endoluminal intervention is an emerging technique for both\nbenign and malignant luminal lesions. With vision-based navigation, when\ncombined with pre-operative imaging data as priors, it is possible to recover\nposition and pose of the endoscope without the need of additional sensors. In\npractice, however, aligning pre-operative and intra-operative domains is\ncomplicated by significant texture differences. Although methods such as style\ntransfer can be used to address this issue, they require large datasets from\nboth source and target domains with prolonged training times. This paper\nproposes an efficient domain transfer method based on stylized Gaussian\nsplatting, only requiring a few of real images (10 images) with very fast\ntraining time. Specifically, the transfer process includes two phases. In the\nfirst phase, the 3D models reconstructed from CT scans are represented as\ndifferential Gaussian point clouds. In the second phase, only color appearance\nrelated parameters are optimized to transfer the style and preserve the visual\ncontent. A novel structure consistency loss is applied to latent features and\ndepth levels to enhance the stability of the transferred images. Detailed\nvalidation was performed to demonstrate the performance advantages of the\nproposed method compared to that of the current state-of-the-art, highlighting\nthe potential for intra-operative surgical navigation.\n","authors":["Junyang Wu","Yun Gu","Guang-Zhong Yang"],"pdf_url":"https://arxiv.org/pdf/2403.10860v2.pdf","comment":"Accepted by ICRA 2025"},{"id":"http://arxiv.org/abs/2503.03453v1","updated":"2025-03-05T12:35:54Z","published":"2025-03-05T12:35:54Z","title":"Active Learning for Deep Learning-Based Hemodynamic Parameter Estimation","summary":"  Hemodynamic parameters such as pressure and wall shear stress play an\nimportant role in diagnosis, prognosis, and treatment planning in\ncardiovascular diseases. These parameters can be accurately computed using\ncomputational fluid dynamics (CFD), but CFD is computationally intensive.\nHence, deep learning methods have been adopted as a surrogate to rapidly\nestimate CFD outcomes. A drawback of such data-driven models is the need for\ntime-consuming reference CFD simulations for training. In this work, we\nintroduce an active learning framework to reduce the number of CFD simulations\nrequired for the training of surrogate models, lowering the barriers to their\ndeployment in new applications. We propose three distinct querying strategies\nto determine for which unlabeled samples CFD simulations should be obtained.\nThese querying strategies are based on geometrical variance, ensemble\nuncertainty, and adherence to the physics governing fluid dynamics. We\nbenchmark these methods on velocity field estimation in synthetic coronary\nartery bifurcations and find that they allow for substantial reductions in\nannotation cost. Notably, we find that our strategies reduce the number of\nsamples required by up to 50% and make the trained models more robust to\ndifficult cases. Our results show that active learning is a feasible strategy\nto increase the potential of deep learning-based CFD surrogates.\n","authors":["Patryk Rygiel","Julian Suk","Kak Khee Yeung","Christoph Brune","Jelmer M. Wolterink"],"pdf_url":"https://arxiv.org/pdf/2503.03453v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.05503v3","updated":"2025-03-05T12:27:57Z","published":"2025-02-08T09:31:26Z","title":"A Physical Coherence Benchmark for Evaluating Video Generation Models\n  via Optical Flow-guided Frame Prediction","summary":"  Recent advances in video generation models demonstrate their potential as\nworld simulators, but they often struggle with videos deviating from physical\nlaws, a key concern overlooked by most text-to-video benchmarks. We introduce a\nbenchmark designed specifically to assess the Physical Coherence of generated\nvideos, PhyCoBench. Our benchmark includes 120 prompts covering 7 categories of\nphysical principles, capturing key physical laws observable in video content.\nWe evaluated four state-of-the-art (SoTA) T2V models on PhyCoBench and\nconducted manual assessments. Additionally, we propose an automated evaluation\nmodel: PhyCoPredictor, a diffusion model that generates optical flow and video\nframes in a cascade manner. Through a consistency evaluation comparing\nautomated and manual sorting, the experimental results show that PhyCoPredictor\ncurrently aligns most closely with human evaluation. Therefore, it can\neffectively evaluate the physical coherence of videos, providing insights for\nfuture model optimization. Our benchmark, including physical coherence prompts,\nthe automatic evaluation tool PhyCoPredictor, and the generated video dataset,\nhas been released on GitHub at https://github.com/Jeckinchen/PhyCoBench.\n","authors":["Yongfan Chen","Xiuwen Zhu","Tianyu Li"],"pdf_url":"https://arxiv.org/pdf/2502.05503v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03446v1","updated":"2025-03-05T12:25:22Z","published":"2025-03-05T12:25:22Z","title":"Biased Heritage: How Datasets Shape Models in Facial Expression\n  Recognition","summary":"  In recent years, the rapid development of artificial intelligence (AI)\nsystems has raised concerns about our ability to ensure their fairness, that\nis, how to avoid discrimination based on protected characteristics such as\ngender, race, or age. While algorithmic fairness is well-studied in simple\nbinary classification tasks on tabular data, its application to complex,\nreal-world scenarios-such as Facial Expression Recognition (FER)-remains\nunderexplored. FER presents unique challenges: it is inherently multiclass, and\nbiases emerge across intersecting demographic variables, each potentially\ncomprising multiple protected groups. We present a comprehensive framework to\nanalyze bias propagation from datasets to trained models in image-based FER\nsystems, while introducing new bias metrics specifically designed for\nmulticlass problems with multiple demographic groups. Our methodology studies\nbias propagation by (1) inducing controlled biases in FER datasets, (2)\ntraining models on these biased datasets, and (3) analyzing the correlation\nbetween dataset bias metrics and model fairness notions. Our findings reveal\nthat stereotypical biases propagate more strongly to model predictions than\nrepresentational biases, suggesting that preventing emotion-specific\ndemographic patterns should be prioritized over general demographic balance in\nFER datasets. Additionally, we observe that biased datasets lead to reduced\nmodel accuracy, challenging the assumed fairness-accuracy trade-off.\n","authors":["Iris Dominguez-Catena","Daniel Paternain","Mikel Galar","MaryBeth Defrance","Maarten Buyl","Tijl De Bie"],"pdf_url":"https://arxiv.org/pdf/2503.03446v1.pdf","comment":"17 pages, 7 figures"},{"id":"http://arxiv.org/abs/2503.03437v1","updated":"2025-03-05T12:12:51Z","published":"2025-03-05T12:12:51Z","title":"JamMa: Ultra-lightweight Local Feature Matching with Joint Mamba","summary":"  Existing state-of-the-art feature matchers capture long-range dependencies\nwith Transformers but are hindered by high spatial complexity, leading to\ndemanding training and highlatency inference. Striking a better balance between\nperformance and efficiency remains a challenge in feature matching. Inspired by\nthe linear complexity O(N) of Mamba, we propose an ultra-lightweight\nMamba-based matcher, named JamMa, which converges on a single GPU and achieves\nan impressive performance-efficiency balance in inference. To unlock the\npotential of Mamba for feature matching, we propose Joint Mamba with a\nscan-merge strategy named JEGO, which enables: (1) Joint scan of two images to\nachieve high-frequency mutual interaction, (2) Efficient scan with skip steps\nto reduce sequence length, (3) Global receptive field, and (4) Omnidirectional\nfeature representation. With the above properties, the JEGO strategy\nsignificantly outperforms the scan-merge strategies proposed in VMamba and\nEVMamba in the feature matching task. Compared to attention-based sparse and\nsemi-dense matchers, JamMa demonstrates a superior balance between performance\nand efficiency, delivering better performance with less than 50% of the\nparameters and FLOPs.\n","authors":["Xiaoyong Lu","Songlin Du"],"pdf_url":"https://arxiv.org/pdf/2503.03437v1.pdf","comment":"CVPR 2025, Project page: https://leoluxxx.github.io/JamMa-page/"},{"id":"http://arxiv.org/abs/2503.03430v1","updated":"2025-03-05T12:02:04Z","published":"2025-03-05T12:02:04Z","title":"CoSDH: Communication-Efficient Collaborative Perception via\n  Supply-Demand Awareness and Intermediate-Late Hybridization","summary":"  Multi-agent collaborative perception enhances perceptual capabilities by\nutilizing information from multiple agents and is considered a fundamental\nsolution to the problem of weak single-vehicle perception in autonomous\ndriving. However, existing collaborative perception methods face a dilemma\nbetween communication efficiency and perception accuracy. To address this\nissue, we propose a novel communication-efficient collaborative perception\nframework based on supply-demand awareness and intermediate-late hybridization,\ndubbed as \\mymethodname. By modeling the supply-demand relationship between\nagents, the framework refines the selection of collaboration regions, reducing\nunnecessary communication cost while maintaining accuracy. In addition, we\ninnovatively introduce the intermediate-late hybrid collaboration mode, where\nlate-stage collaboration compensates for the performance degradation in\ncollaborative perception under low communication bandwidth. Extensive\nexperiments on multiple datasets, including both simulated and real-world\nscenarios, demonstrate that \\mymethodname~ achieves state-of-the-art detection\naccuracy and optimal bandwidth trade-offs, delivering superior detection\nprecision under real communication bandwidths, thus proving its effectiveness\nand practical applicability. The code will be released at\nhttps://github.com/Xu2729/CoSDH.\n","authors":["Junhao Xu","Yanan Zhang","Zhi Cai","Di Huang"],"pdf_url":"https://arxiv.org/pdf/2503.03430v1.pdf","comment":"Accepted at CVPR 2025"},{"id":"http://arxiv.org/abs/2306.17567v3","updated":"2025-03-05T11:52:00Z","published":"2023-06-30T11:40:35Z","title":"Counting Guidance for High Fidelity Text-to-Image Synthesis","summary":"  Recently, there have been significant improvements in the quality and\nperformance of text-to-image generation, largely due to the impressive results\nattained by diffusion models. However, text-to-image diffusion models sometimes\nstruggle to create high-fidelity content for the given input prompt. One\nspecific issue is their difficulty in generating the precise number of objects\nspecified in the text prompt. For example, when provided with the prompt \"five\napples and ten lemons on a table,\" images generated by diffusion models often\ncontain an incorrect number of objects. In this paper, we present a method to\nimprove diffusion models so that they accurately produce the correct object\ncount based on the input prompt. We adopt a counting network that performs\nreference-less class-agnostic counting for any given image. We calculate the\ngradients of the counting network and refine the predicted noise for each step.\nTo address the presence of multiple types of objects in the prompt, we utilize\nnovel attention map guidance to obtain high-quality masks for each object.\nFinally, we guide the denoising process using the calculated gradients for each\nobject. Through extensive experiments and evaluation, we demonstrate that the\nproposed method significantly enhances the fidelity of diffusion models with\nrespect to object count. Code is available at\nhttps://github.com/furiosa-ai/counting-guidance.\n","authors":["Wonjun Kang","Kevin Galim","Hyung Il Koo","Nam Ik Cho"],"pdf_url":"https://arxiv.org/pdf/2306.17567v3.pdf","comment":"Accepted at WACV 2025 (Oral). Code is available at\n  https://github.com/furiosa-ai/counting-guidance"},{"id":"http://arxiv.org/abs/2503.03422v1","updated":"2025-03-05T11:49:32Z","published":"2025-03-05T11:49:32Z","title":"Automatic Drywall Analysis for Progress Tracking and Quality Control in\n  Construction","summary":"  Digitalization in the construction industry has become essential, enabling\ncentralized, easy access to all relevant information of a building. Automated\nsystems can facilitate the timely and resource-efficient documentation of\nchanges, which is crucial for key processes such as progress tracking and\nquality control. This paper presents a method for image-based automated drywall\nanalysis enabling construction progress and quality assessment through on-site\ncamera systems. Our proposed solution integrates a deep learning-based instance\nsegmentation model to detect and classify various drywall elements with an\nanalysis module to cluster individual wall segments, estimate camera\nperspective distortions, and apply the corresponding corrections. This system\nextracts valuable information from images, enabling more accurate progress\ntracking and quality assessment on construction sites. Our main contributions\ninclude a fully automated pipeline for drywall analysis, improving instance\nsegmentation accuracy through architecture modifications and targeted data\naugmentation, and a novel algorithm to extract important information from the\nsegmentation results. Our modified model, enhanced with data augmentation,\nachieves significantly higher accuracy compared to other architectures,\noffering more detailed and precise information than existing approaches.\nCombined with the proposed drywall analysis steps, it enables the reliable\nautomation of construction progress and quality assessment.\n","authors":["Mariusz Trzeciakiewicz","Aleixo Cambeiro Barreiro","Niklas Gard","Anna Hilsmann","Peter Eisert"],"pdf_url":"https://arxiv.org/pdf/2503.03422v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.03603v5","updated":"2025-03-05T11:48:15Z","published":"2024-12-03T23:52:37Z","title":"HunyuanVideo: A Systematic Framework For Large Video Generative Models","summary":"  Recent advancements in video generation have significantly impacted daily\nlife for both individuals and industries. However, the leading video generation\nmodels remain closed-source, resulting in a notable performance gap between\nindustry capabilities and those available to the public. In this report, we\nintroduce HunyuanVideo, an innovative open-source video foundation model that\ndemonstrates performance in video generation comparable to, or even surpassing,\nthat of leading closed-source models. HunyuanVideo encompasses a comprehensive\nframework that integrates several key elements, including data curation,\nadvanced architectural design, progressive model scaling and training, and an\nefficient infrastructure tailored for large-scale model training and inference.\nAs a result, we successfully trained a video generative model with over 13\nbillion parameters, making it the largest among all open-source models. We\nconducted extensive experiments and implemented a series of targeted designs to\nensure high visual quality, motion dynamics, text-video alignment, and advanced\nfilming techniques. According to evaluations by professionals, HunyuanVideo\noutperforms previous state-of-the-art models, including Runway Gen-3, Luma 1.6,\nand three top-performing Chinese video generative models. By releasing the code\nfor the foundation model and its applications, we aim to bridge the gap between\nclosed-source and open-source communities. This initiative will empower\nindividuals within the community to experiment with their ideas, fostering a\nmore dynamic and vibrant video generation ecosystem. The code is publicly\navailable at https://github.com/Tencent/HunyuanVideo.\n","authors":["Weijie Kong","Qi Tian","Zijian Zhang","Rox Min","Zuozhuo Dai","Jin Zhou","Jiangfeng Xiong","Xin Li","Bo Wu","Jianwei Zhang","Kathrina Wu","Qin Lin","Junkun Yuan","Yanxin Long","Aladdin Wang","Andong Wang","Changlin Li","Duojun Huang","Fang Yang","Hao Tan","Hongmei Wang","Jacob Song","Jiawang Bai","Jianbing Wu","Jinbao Xue","Joey Wang","Kai Wang","Mengyang Liu","Pengyu Li","Shuai Li","Weiyan Wang","Wenqing Yu","Xinchi Deng","Yang Li","Yi Chen","Yutao Cui","Yuanbo Peng","Zhentao Yu","Zhiyu He","Zhiyong Xu","Zixiang Zhou","Zunnan Xu","Yangyu Tao","Qinglin Lu","Songtao Liu","Dax Zhou","Hongfa Wang","Yong Yang","Di Wang","Yuhong Liu","Jie Jiang","Caesar Zhong"],"pdf_url":"https://arxiv.org/pdf/2412.03603v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.01505v4","updated":"2025-03-05T11:39:35Z","published":"2024-03-03T13:08:32Z","title":"SCott: Accelerating Diffusion Models with Stochastic Consistency\n  Distillation","summary":"  The iterative sampling procedure employed by diffusion models (DMs) often\nleads to significant inference latency. To address this, we propose Stochastic\nConsistency Distillation (SCott) to enable accelerated text-to-image\ngeneration, where high-quality and diverse generations can be achieved within\njust 2-4 sampling steps. In contrast to vanilla consistency distillation (CD)\nwhich distills the ordinary differential equation solvers-based sampling\nprocess of a pre-trained teacher model into a student, SCott explores the\npossibility and validates the efficacy of integrating stochastic differential\nequation (SDE) solvers into CD to fully unleash the potential of the teacher.\nSCott is augmented with elaborate strategies to control the noise strength and\nsampling process of the SDE solver. An adversarial loss is further incorporated\nto strengthen the consistency constraints in rare sampling steps. Empirically,\non the MSCOCO-2017 5K dataset with a Stable Diffusion-V1.5 teacher, SCott\nachieves an FID of 21.9 with 2 sampling steps, surpassing that of the 1-step\nInstaFlow (23.4) and the 4-step UFOGen (22.1). Moreover, SCott can yield more\ndiverse samples than other consistency models for high-resolution image\ngeneration, with up to 16% improvement in a qualified metric.\n","authors":["Hongjian Liu","Qingsong Xie","TianXiang Ye","Zhijie Deng","Chen Chen","Shixiang Tang","Xueyang Fu","Haonan Lu","Zheng-jun Zha"],"pdf_url":"https://arxiv.org/pdf/2403.01505v4.pdf","comment":"22 pages, 16 figures"},{"id":"http://arxiv.org/abs/2503.03410v1","updated":"2025-03-05T11:39:15Z","published":"2025-03-05T11:39:15Z","title":"Augmentation-Based Deep Learning for Identification of Circulating Tumor\n  Cells","summary":"  Circulating tumor cells (CTCs) are crucial biomarkers in liquid biopsy,\noffering a noninvasive tool for cancer patient management. However, their\nidentification remains particularly challenging due to their limited number and\nheterogeneity. Labeling samples for contrast limits the generalization of\nfluorescence-based methods across different hospital datasets. Analyzing\nsingle-cell images enables detailed assessment of cell morphology, subcellular\nstructures, and phenotypic variations, often hidden in clustered images.\nDeveloping a method based on bright-field single-cell analysis could overcome\nthese limitations. CTCs can be isolated using an unbiased workflow combining\nParsortix technology, which selects cells based on size and deformability, with\nDEPArray technology, enabling precise visualization and selection of single\ncells. Traditionally, DEPArray-acquired digital images are manually analyzed,\nmaking the process time-consuming and prone to variability. In this study, we\npresent a Deep Learning-based classification pipeline designed to distinguish\nCTCs from leukocytes in blood samples, aimed to enhance diagnostic accuracy and\noptimize clinical workflows. Our approach employs images from the bright-field\nchannel acquired through DEPArray technology leveraging a ResNet-based CNN. To\nimprove model generalization, we applied three types of data augmentation\ntechniques and incorporated fluorescence (DAPI) channel images into the\ntraining phase, allowing the network to learn additional CTC-specific features.\nNotably, only bright-field images have been used for testing, ensuring the\nmodel's ability to identify CTCs without relying on fluorescence markers. The\nproposed model achieved an F1-score of 0.798, demonstrating its capability to\ndistinguish CTCs from leukocytes. These findings highlight the potential of DL\nin refining CTC analysis and advancing liquid biopsy applications.\n","authors":["Martina Russo","Giulia Bertolini","Vera Cappelletti","Cinzia De Marco","Serena Di Cosimo","Petra Paiè","Nadia Brancati"],"pdf_url":"https://arxiv.org/pdf/2503.03410v1.pdf","comment":"20 pages, 4 figures, 3 tables"},{"id":"http://arxiv.org/abs/2503.03395v1","updated":"2025-03-05T11:19:17Z","published":"2025-03-05T11:19:17Z","title":"AI-Driven Multi-Stage Computer Vision System for Defect Detection in\n  Laser-Engraved Industrial Nameplates","summary":"  Automated defect detection in industrial manufacturing is essential for\nmaintaining product quality and minimizing production errors. In air disc brake\nmanufacturing, ensuring the precision of laser-engraved nameplates is crucial\nfor accurate product identification and quality control. Engraving errors, such\nas misprints or missing characters, can compromise both aesthetics and\nfunctionality, leading to material waste and production delays. This paper\npresents a proof of concept for an AI-driven computer vision system that\ninspects and verifies laser-engraved nameplates, detecting defects in logos and\nalphanumeric strings. The system integrates object detection using YOLOv7,\noptical character recognition (OCR) with Tesseract, and anomaly detection\nthrough a residual variational autoencoder (ResVAE) along with other computer\nvision methods to enable comprehensive inspections at multiple stages.\nExperimental results demonstrate the system's effectiveness, achieving 91.33%\naccuracy and 100% recall, ensuring that defective nameplates are consistently\ndetected and addressed. This solution highlights the potential of AI-driven\nvisual inspection to enhance quality control, reduce manual inspection efforts,\nand improve overall manufacturing efficiency.\n","authors":["Adhish Anitha Vilasan","Stephan Jäger","Noah Klarmann"],"pdf_url":"https://arxiv.org/pdf/2503.03395v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.01243v3","updated":"2025-03-05T11:17:18Z","published":"2024-12-02T08:05:26Z","title":"Schedule On the Fly: Diffusion Time Prediction for Faster and Better\n  Image Generation","summary":"  Diffusion and flow matching models have achieved remarkable success in\ntext-to-image generation. However, these models typically rely on the\npredetermined denoising schedules for all prompts. The multi-step reverse\ndiffusion process can be regarded as a kind of chain-of-thought for generating\nhigh-quality images step by step. Therefore, diffusion models should reason for\neach instance to adaptively determine the optimal noise schedule, achieving\nhigh generation quality with sampling efficiency. In this paper, we introduce\nthe Time Prediction Diffusion Model (TPDM) for this. TPDM employs a\nplug-and-play Time Prediction Module (TPM) that predicts the next noise level\nbased on current latent features at each denoising step. We train the TPM using\nreinforcement learning to maximize a reward that encourages high final image\nquality while penalizing excessive denoising steps. With such an adaptive\nscheduler, TPDM not only generates high-quality images that are aligned closely\nwith human preferences but also adjusts diffusion time and the number of\ndenoising steps on the fly, enhancing both performance and efficiency. With\nStable Diffusion 3 Medium architecture, TPDM achieves an aesthetic score of\n5.44 and a human preference score (HPS) of 29.59, while using around 50% fewer\ndenoising steps to achieve better performance.\n","authors":["Zilyu Ye","Zhiyang Chen","Tiancheng Li","Zemin Huang","Weijian Luo","Guo-Jun Qi"],"pdf_url":"https://arxiv.org/pdf/2412.01243v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.14153v2","updated":"2025-03-05T11:15:39Z","published":"2024-08-26T09:55:34Z","title":"Explaining Vision-Language Similarities in Dual Encoders with\n  Feature-Pair Attributions","summary":"  Dual encoder architectures like CLIP models map two types of inputs into a\nshared embedding space and predict similarities between them. Despite their\nsuccess, it is, however, not understood how these models compare their two\ninputs. Common first-order feature-attribution methods can only provide limited\ninsights into dual-encoders since their predictions depend on\nfeature-interactions rather than on individual features. In this paper, we\nfirst derive a second-order method enabling the attribution of predictions by\nany differentiable dual encoder onto feature-interactions between its inputs.\nSecond, we apply our method to CLIP models and show that they learn\nfine-grained correspondences between parts of captions and regions in images.\nThey match objects across input modes also account for mismatches. This\nvisual-linguistic grounding ability, however, varies heavily between object\nclasses and exhibits pronounced out-of-domain effects. We can identify\nindividual errors as well as systematic failure categories including object\ncoverage, unusual scenes and correlated contexts.\n","authors":["Lucas Möller","Pascal Tilli","Ngoc Thang Vu","Sebastian Padó"],"pdf_url":"https://arxiv.org/pdf/2408.14153v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03370v1","updated":"2025-03-05T10:46:03Z","published":"2025-03-05T10:46:03Z","title":"MIAdapt: Source-free Few-shot Domain Adaptive Object Detection for\n  Microscopic Images","summary":"  Existing generic unsupervised domain adaptation approaches require access to\nboth a large labeled source dataset and a sufficient unlabeled target dataset\nduring adaptation. However, collecting a large dataset, even if unlabeled, is a\nchallenging and expensive endeavor, especially in medical imaging. In addition,\nconstraints such as privacy issues can result in cases where source data is\nunavailable. Taking in consideration these challenges, we propose MIAdapt, an\nadaptive approach for Microscopic Imagery Adaptation as a solution for\nSource-free Few-shot Domain Adaptive Object detection (SF-FSDA). We also define\ntwo competitive baselines (1) Faster-FreeShot and (2) MT-FreeShot. Extensive\nexperiments on the challenging M5-Malaria and Raabin-WBC datasets validate the\neffectiveness of MIAdapt. Without using any image from the source domain\nMIAdapt surpasses state-of-the-art source-free UDA (SF-UDA) methods by +21.3%\nmAP and few-shot domain adaptation (FSDA) approaches by +4.7% mAP on\nRaabin-WBC. Our code and models will be publicly available.\n","authors":["Nimra Dilawar","Sara Nadeem","Javed Iqbal","Waqas Sultani","Mohsen Ali"],"pdf_url":"https://arxiv.org/pdf/2503.03370v1.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2503.03367v1","updated":"2025-03-05T10:43:01Z","published":"2025-03-05T10:43:01Z","title":"Top-K Maximum Intensity Projection Priors for 3D Liver Vessel\n  Segmentation","summary":"  Liver-vessel segmentation is an essential task in the pre-operative planning\nof liver resection. State-of-the-art 2D or 3D convolution-based methods\nfocusing on liver vessel segmentation on 2D CT cross-sectional views, which do\nnot take into account the global liver-vessel topology. To maintain this global\nvessel topology, we rely on the underlying physics used in the CT\nreconstruction process, and apply this to liver-vessel segmentation.\nConcretely, we introduce the concept of top-k maximum intensity projections,\nwhich mimics the CT reconstruction by replacing the integral along each\nprojection direction, with keeping the top-k maxima along each projection\ndirection. We use these top-k maximum projections to condition a diffusion\nmodel and generate 3D liver-vessel trees. We evaluate our 3D liver-vessel\nsegmentation on the 3D-ircadb-01 dataset, and achieve the highest Dice\ncoefficient, intersection-over-union (IoU), and Sensitivity scores compared to\nprior work.\n","authors":["Xiaotong Zhang","Alexander Broersen","Gonnie CM van Erp","Silvia L. Pintea","Jouke Dijkstra"],"pdf_url":"https://arxiv.org/pdf/2503.03367v1.pdf","comment":"Accepted in 2025 IEEE International Symposium on Biomedical Imaging\n  (ISBI 2025)"},{"id":"http://arxiv.org/abs/2503.03365v1","updated":"2025-03-05T10:42:41Z","published":"2025-03-05T10:42:41Z","title":"TopoMortar: A dataset to evaluate image segmentation methods focused on\n  topology accuracy","summary":"  We present TopoMortar, a brick wall dataset that is the first dataset\nspecifically designed to evaluate topology-focused image segmentation methods,\nsuch as topology loss functions. TopoMortar enables to investigate in two ways\nwhether methods incorporate prior topological knowledge. First, by eliminating\nchallenges seen in real-world data, such as small training set, noisy labels,\nand out-of-distribution test-set images, that, as we show, impact the\neffectiveness of topology losses. Second, by allowing to assess in the same\ndataset topology accuracy across dataset challenges, isolating dataset-related\neffects from the effect of incorporating prior topological knowledge. In these\ntwo experiments, it is deliberately difficult to improve topology accuracy\nwithout actually using topology information, thus, permitting to attribute an\nimprovement in topology accuracy to the incorporation of prior topological\nknowledge. To this end, TopoMortar includes three types of labels (accurate,\nnoisy, pseudo-labels), two fixed training sets (large and small), and\nin-distribution and out-of-distribution test-set images. We compared eight loss\nfunctions on TopoMortar, and we found that clDice achieved the most\ntopologically accurate segmentations, Skeleton Recall loss performed best\nparticularly with noisy labels, and the relative advantageousness of the other\nloss functions depended on the experimental setting. Additionally, we show that\nsimple methods, such as data augmentation and self-distillation, can elevate\nCross entropy Dice loss to surpass most topology loss functions, and that those\nsimple methods can enhance topology loss functions as well. clDice and Skeleton\nRecall loss, both skeletonization-based loss functions, were also the fastest\nto train, making this type of loss function a promising research direction.\nTopoMortar and our code can be found at https://github.com/jmlipman/TopoMortar\n","authors":["Juan Miguel Valverde","Motoya Koga","Nijihiko Otsuka","Anders Bjorholm Dahl"],"pdf_url":"https://arxiv.org/pdf/2503.03365v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03355v1","updated":"2025-03-05T10:37:51Z","published":"2025-03-05T10:37:51Z","title":"Video Super-Resolution: All You Need is a Video Diffusion Model","summary":"  We present a generic video super-resolution algorithm in this paper, based on\nthe Diffusion Posterior Sampling framework with an unconditional video\ngeneration model in latent space. The video generation model, a diffusion\ntransformer, functions as a space-time model. We argue that a powerful model,\nwhich learns the physics of the real world, can easily handle various kinds of\nmotion patterns as prior knowledge, thus eliminating the need for explicit\nestimation of optical flows or motion parameters for pixel alignment.\nFurthermore, a single instance of the proposed video diffusion transformer\nmodel can adapt to different sampling conditions without re-training. Due to\nlimited computational resources and training data, our experiments provide\nempirical evidence of the algorithm's strong super-resolution capabilities\nusing synthetic data.\n","authors":["Zhihao Zhan","Wang Pang","Xiang Zhu","Yechao Bai"],"pdf_url":"https://arxiv.org/pdf/2503.03355v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.07226v2","updated":"2025-03-05T10:24:18Z","published":"2023-12-12T12:41:35Z","title":"Super-Resolution on Rotationally Scanned Photoacoustic Microscopy Images\n  Incorporating Scanning Prior","summary":"  Photoacoustic Microscopy (PAM) images integrating the advantages of optical\ncontrast and acoustic resolution have been widely used in brain studies.\nHowever, there exists a trade-off between scanning speed and image resolution.\nCompared with traditional raster scanning, rotational scanning provides good\nopportunities for fast PAM imaging by optimizing the scanning mechanism.\nRecently, there is a trend to incorporate deep learning into the scanning\nprocess to further increase the scanning speed.Yet, most such attempts are\nperformed for raster scanning while those for rotational scanning are\nrelatively rare. In this study, we propose a novel and well-performing\nsuper-resolution framework for rotational scanning-based PAM imaging. To\neliminate adjacent rows' displacements due to subject motion or high-frequency\nscanning distortion,we introduce a registration module across odd and even rows\nin the preprocessing and incorporate displacement degradation in the training.\nBesides, gradient-based patch selection is proposed to increase the probability\nof blood vessel patches being selected for training. A Transformer-based\nnetwork with a global receptive field is applied for better performance.\nExperimental results on both synthetic and real datasets demonstrate the\neffectiveness and generalizability of our proposed framework for rotationally\nscanned PAM images'super-resolution, both quantitatively and qualitatively.\nCode is available at https://github.com/11710615/PAMSR.git.\n","authors":["Kai Pan","Linyang Li","Li Lin","Pujin Cheng","Junyan Lyu","Lei Xi","Xiaoyin Tang"],"pdf_url":"https://arxiv.org/pdf/2312.07226v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07804v3","updated":"2025-03-05T10:09:25Z","published":"2024-12-09T09:04:02Z","title":"XLSTM-HVED: Cross-Modal Brain Tumor Segmentation and MRI Reconstruction\n  Method Using Vision XLSTM and Heteromodal Variational Encoder-Decoder","summary":"  Neurogliomas are among the most aggressive forms of cancer, presenting\nconsiderable challenges in both treatment and monitoring due to their\nunpredictable biological behavior. Magnetic resonance imaging (MRI) is\ncurrently the preferred method for diagnosing and monitoring gliomas. However,\nthe lack of specific imaging techniques often compromises the accuracy of tumor\nsegmentation during the imaging process. To address this issue, we introduce\nthe XLSTM-HVED model. This model integrates a hetero-modal encoder-decoder\nframework with the Vision XLSTM module to reconstruct missing MRI modalities.\nBy deeply fusing spatial and temporal features, it enhances tumor segmentation\nperformance. The key innovation of our approach is the Self-Attention\nVariational Encoder (SAVE) module, which improves the integration of modal\nfeatures. Additionally, it optimizes the interaction of features between\nsegmentation and reconstruction tasks through the Squeeze-Fusion-Excitation\nCross Awareness (SFECA) module. Our experiments using the BraTS 2024 dataset\ndemonstrate that our model significantly outperforms existing advanced methods\nin handling cases where modalities are missing. Our source code is available at\nhttps://github.com/Quanato607/XLSTM-HVED.\n","authors":["Shenghao Zhu","Yifei Chen","Shuo Jiang","Weihong Chen","Chang Liu","Yuanhan Wang","Xu Chen","Yifan Ke","Feiwei Qin","Changmiao Wang","Zhu Zhu"],"pdf_url":"https://arxiv.org/pdf/2412.07804v3.pdf","comment":"5 pages, 2 figures"},{"id":"http://arxiv.org/abs/2503.03330v1","updated":"2025-03-05T10:03:21Z","published":"2025-03-05T10:03:21Z","title":"Automated Attendee Recognition System for Large-Scale Social Events or\n  Conference Gathering","summary":"  Manual attendance tracking at large-scale events, such as marriage functions\nor conferences, is often inefficient and prone to human error. To address this\nchallenge, we propose an automated, cloud-based attendance tracking system that\nuses cameras mounted at the entrance and exit gates. The mounted cameras\ncontinuously capture video and send the video data to cloud services to perform\nreal-time face detection and recognition. Unlike existing solutions, our system\naccurately identifies attendees even when they are not looking directly at the\ncamera, allowing natural movements, such as looking around or talking while\nwalking. To the best of our knowledge, this is the first system to achieve high\nrecognition rates under such dynamic conditions. Our system demonstrates\noverall 90% accuracy, with each video frame processed in 5 seconds, ensuring\nreal time operation without frame loss. In addition, notifications are sent\npromptly to security personnel within the same latency. This system achieves\n100% accuracy for individuals without facial obstructions and successfully\nrecognizes all attendees appearing within the camera's field of view, providing\na robust solution for attendee recognition in large-scale social events.\n","authors":["Dhruv Motwani","Ankush Tyagi","Vipul Dabhi","Harshadkumar Prajapati"],"pdf_url":"https://arxiv.org/pdf/2503.03330v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03329v1","updated":"2025-03-05T10:02:35Z","published":"2025-03-05T10:02:35Z","title":"Deep Learning-Based Diffusion MRI Tractography: Integrating Spatial and\n  Anatomical Information","summary":"  Diffusion MRI tractography technique enables non-invasive visualization of\nthe white matter pathways in the brain. It plays a crucial role in neuroscience\nand clinical fields by facilitating the study of brain connectivity and\nneurological disorders. However, the accuracy of reconstructed tractograms has\nbeen a longstanding challenge. Recently, deep learning methods have been\napplied to improve tractograms for better white matter coverage, but often\ncomes at the expense of generating excessive false-positive connections. This\nis largely due to their reliance on local information to predict long range\nstreamlines. To improve the accuracy of streamline propagation predictions, we\nintroduce a novel deep learning framework that integrates image-domain spatial\ninformation and anatomical information along tracts, with the former extracted\nthrough convolutional layers and the later modeled via a Transformer-decoder.\nAdditionally, we employ a weighted loss function to address fiber class\nimbalance encountered during training. We evaluate the proposed method on the\nsimulated ISMRM 2015 Tractography Challenge dataset, achieving a valid\nstreamline rate of 66.2%, white matter coverage of 63.8%, and successfully\nreconstructing 24 out of 25 bundles. Furthermore, on the multi-site\nTractoinferno dataset, the proposed method demonstrates its ability to handle\nvarious diffusion MRI acquisition schemes, achieving a 5.7% increase in white\nmatter coverage and a 4.1% decrease in overreach compared to RNN-based methods.\n","authors":["Yiqiong Yang","Yitian Yuan","Baoxing Ren","Ye Wu","Yanqiu Feng","Xinyuan Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.03329v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03327v1","updated":"2025-03-05T10:00:32Z","published":"2025-03-05T10:00:32Z","title":"ScaleFusionNet: Transformer-Guided Multi-Scale Feature Fusion for Skin\n  Lesion Segmentation","summary":"  Melanoma is a malignant tumor originating from skin cell lesions. Accurate\nand efficient segmentation of skin lesions is essential for quantitative\nmedical analysis but remains challenging. To address this, we propose\nScaleFusionNet, a segmentation model that integrates Cross-Attention\nTransformer Module (CATM) and AdaptiveFusionBlock to enhance feature extraction\nand fusion. The model employs a hybrid architecture encoder that effectively\ncaptures both local and global features. We introduce CATM, which utilizes Swin\nTransformer Blocks and Cross Attention Fusion (CAF) to adaptively refine\nencoder-decoder feature fusion, reducing semantic gaps and improving\nsegmentation accuracy. Additionally, the AdaptiveFusionBlock is improved by\nintegrating adaptive multi-scale fusion, where Swin Transformer-based attention\ncomplements deformable convolution-based multi-scale feature extraction. This\nenhancement refines lesion boundaries and preserves fine-grained details.\nScaleFusionNet achieves Dice scores of 92.94% and 91.65% on ISIC-2016 and\nISIC-2018 datasets, respectively, demonstrating its effectiveness in skin\nlesion analysis. Our code implementation is publicly available at GitHub.\n","authors":["Saqib Qamar","Syed Furqan Qadri","Roobaea Alroobaea","Majed Alsafyani","Abdullah M. Baqasah"],"pdf_url":"https://arxiv.org/pdf/2503.03327v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03325v1","updated":"2025-03-05T09:59:23Z","published":"2025-03-05T09:59:23Z","title":"Golden Cudgel Network for Real-Time Semantic Segmentation","summary":"  Recent real-time semantic segmentation models, whether single-branch or\nmulti-branch, achieve good performance and speed. However, their speed is\nlimited by multi-path blocks, and some depend on high-performance teacher\nmodels for training. To overcome these issues, we propose Golden Cudgel Network\n(GCNet). Specifically, GCNet uses vertical multi-convolutions and horizontal\nmulti-paths for training, which are reparameterized into a single convolution\nfor inference, optimizing both performance and speed. This design allows GCNet\nto self-enlarge during training and self-contract during inference, effectively\nbecoming a \"teacher model\" without needing external ones. Experimental results\nshow that GCNet outperforms existing state-of-the-art models in terms of\nperformance and speed on the Cityscapes, CamVid, and Pascal VOC 2012 datasets.\nThe code is available at https://github.com/gyyang23/GCNet.\n","authors":["Guoyu Yang","Yuan Wang","Daming Shi","Yanzhong Wang"],"pdf_url":"https://arxiv.org/pdf/2503.03325v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03321v1","updated":"2025-03-05T09:55:07Z","published":"2025-03-05T09:55:07Z","title":"See What You Are Told: Visual Attention Sink in Large Multimodal Models","summary":"  Large multimodal models (LMMs) \"see\" images by leveraging the attention\nmechanism between text and visual tokens in the transformer decoder. Ideally,\nthese models should focus on key visual information relevant to the text token.\nHowever, recent findings indicate that LMMs have an extraordinary tendency to\nconsistently allocate high attention weights to specific visual tokens, even\nwhen these tokens are irrelevant to the corresponding text. In this study, we\ninvestigate the property behind the appearance of these irrelevant visual\ntokens and examine their characteristics. Our findings show that this behavior\narises due to the massive activation of certain hidden state dimensions, which\nresembles the attention sink found in language models. Hence, we refer to this\nphenomenon as the visual attention sink. In particular, our analysis reveals\nthat removing the irrelevant visual sink tokens does not impact model\nperformance, despite receiving high attention weights. Consequently, we recycle\nthe attention to these tokens as surplus resources, redistributing the\nattention budget to enhance focus on the image. To achieve this, we introduce\nVisual Attention Redistribution (VAR), a method that redistributes attention in\nimage-centric heads, which we identify as innately focusing on visual\ninformation. VAR can be seamlessly applied across different LMMs to improve\nperformance on a wide range of tasks, including general vision-language tasks,\nvisual hallucination tasks, and vision-centric tasks, all without the need for\nadditional training, models, or inference steps. Experimental results\ndemonstrate that VAR enables LMMs to process visual information more\neffectively by adjusting their internal attention mechanisms, offering a new\ndirection to enhancing the multimodal capabilities of LMMs.\n","authors":["Seil Kang","Jinyeong Kim","Junhyeok Kim","Seong Jae Hwang"],"pdf_url":"https://arxiv.org/pdf/2503.03321v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.09510v5","updated":"2025-03-05T09:44:52Z","published":"2024-06-17T11:43:38Z","title":"3DGS.zip: A survey on 3D Gaussian Splatting Compression Methods","summary":"  3D Gaussian Splatting (3DGS) has emerged as a cutting-edge technique for\nreal-time radiance field rendering, offering state-of-the-art performance in\nterms of both quality and speed. 3DGS models a scene as a collection of\nthree-dimensional Gaussians, with additional attributes optimized to conform to\nthe scene's geometric and visual properties. Despite its advantages in\nrendering speed and image fidelity, 3DGS is limited by its significant storage\nand memory demands. These high demands make 3DGS impractical for mobile devices\nor headsets, reducing its applicability in important areas of computer\ngraphics. To address these challenges and advance the practicality of 3DGS,\nthis survey provides a comprehensive and detailed examination of compression\nand compaction techniques developed to make 3DGS more efficient. We classify\nexisting methods into two categories: compression, which focuses on reducing\nfile size, and compaction, which aims to minimize the number of Gaussians. Both\nmethods aim to maintain or improve quality, each by minimizing its respective\nattribute: file size for compression and Gaussian count for compaction. We\nintroduce the basic mathematical concepts underlying the analyzed methods, as\nwell as key implementation details and design choices. Our report thoroughly\ndiscusses similarities and differences among the methods, as well as their\nrespective advantages and disadvantages. We establish a consistent framework\nfor comparing the surveyed methods based on key performance metrics and\ndatasets. Specifically, since these methods have been developed in parallel and\nover a short period of time, currently, no comprehensive comparison exists.\nThis survey, for the first time, presents a unified framework to evaluate 3DGS\ncompression techniques. We maintain a website that will be regularly updated\nwith emerging methods: https://w-m.github.io/3dgs-compression-survey/ .\n","authors":["Milena T. Bagdasarian","Paul Knoll","Yi-Hsin Li","Florian Barthel","Anna Hilsmann","Peter Eisert","Wieland Morgenstern"],"pdf_url":"https://arxiv.org/pdf/2407.09510v5.pdf","comment":"3D Gaussian Splatting compression survey; 3DGS compression; updated\n  discussion; new approaches added; new illustrations"},{"id":"http://arxiv.org/abs/2503.03307v1","updated":"2025-03-05T09:39:51Z","published":"2025-03-05T09:39:51Z","title":"Full-DoF Egomotion Estimation for Event Cameras Using Geometric Solvers","summary":"  For event cameras, current sparse geometric solvers for egomotion estimation\nassume that the rotational displacements are known, such as those provided by\nan IMU. Thus, they can only recover the translational motion parameters.\nRecovering full-DoF motion parameters using a sparse geometric solver is a more\nchallenging task, and has not yet been investigated. In this paper, we propose\nseveral solvers to estimate both rotational and translational velocities within\na unified framework. Our method leverages event manifolds induced by line\nsegments. The problem formulations are based on either an incidence relation\nfor lines or a novel coplanarity relation for normal vectors. We demonstrate\nthe possibility of recovering full-DoF egomotion parameters for both angular\nand linear velocities without requiring extra sensor measurements or motion\npriors. To achieve efficient optimization, we exploit the Adam framework with a\nfirst-order approximation of rotations for quick initialization. Experiments on\nboth synthetic and real-world data demonstrate the effectiveness of our method.\nThe code is available at https://github.com/jizhaox/relpose-event.\n","authors":["Ji Zhao","Banglei Guan","Zibin Liu","Laurent Kneip"],"pdf_url":"https://arxiv.org/pdf/2503.03307v1.pdf","comment":"Accepted by IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition (CVPR), 2025"},{"id":"http://arxiv.org/abs/2503.03299v1","updated":"2025-03-05T09:30:49Z","published":"2025-03-05T09:30:49Z","title":"Label-Efficient LiDAR Semantic Segmentation with 2D-3D Vision\n  Transformer Adapters","summary":"  LiDAR semantic segmentation models are typically trained from random\ninitialization as universal pre-training is hindered by the lack of large,\ndiverse datasets. Moreover, most point cloud segmentation architectures\nincorporate custom network layers, limiting the transferability of advances\nfrom vision-based architectures. Inspired by recent advances in universal\nfoundation models, we propose BALViT, a novel approach that leverages frozen\nvision models as amodal feature encoders for learning strong LiDAR encoders.\nSpecifically, BALViT incorporates both range-view and bird's-eye-view LiDAR\nencoding mechanisms, which we combine through a novel 2D-3D adapter. While the\nrange-view features are processed through a frozen image backbone, our\nbird's-eye-view branch enhances them through multiple cross-attention\ninteractions. Thereby, we continuously improve the vision network with\ndomain-dependent knowledge, resulting in a strong label-efficient LiDAR\nencoding mechanism. Extensive evaluations of BALViT on the SemanticKITTI and\nnuScenes benchmarks demonstrate that it outperforms state-of-the-art methods on\nsmall data regimes. We make the code and models publicly available at:\nhttp://balvit.cs.uni-freiburg.de.\n","authors":["Julia Hindel","Rohit Mohan","Jelena Bratulic","Daniele Cattaneo","Thomas Brox","Abhinav Valada"],"pdf_url":"https://arxiv.org/pdf/2503.03299v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03294v1","updated":"2025-03-05T09:18:27Z","published":"2025-03-05T09:18:27Z","title":"Interactive Segmentation and Report Generation for CT Images","summary":"  Automated CT report generation plays a crucial role in improving diagnostic\naccuracy and clinical workflow efficiency. However, existing methods lack\ninterpretability and impede patient-clinician understanding, while their static\nnature restricts radiologists from dynamically adjusting assessments during\nimage review. Inspired by interactive segmentation techniques, we propose a\nnovel interactive framework for 3D lesion morphology reporting that seamlessly\ngenerates segmentation masks with comprehensive attribute descriptions,\nenabling clinicians to generate detailed lesion profiles for enhanced\ndiagnostic assessment. To our best knowledge, we are the first to integrate the\ninteractive segmentation and structured reports in 3D CT medical images.\nExperimental results across 15 lesion types demonstrate the effectiveness of\nour approach in providing a more comprehensive and reliable reporting system\nfor lesion segmentation and capturing. The source code will be made publicly\navailable following paper acceptance.\n","authors":["Yannian Gu","Wenhui Lei","Hanyu Chen","Xiaofan Zhang","Shaoting Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.03294v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03287v1","updated":"2025-03-05T09:13:40Z","published":"2025-03-05T09:13:40Z","title":"Deep Understanding of Sign Language for Sign to Subtitle Alignment","summary":"  The objective of this work is to align asynchronous subtitles in sign\nlanguage videos with limited labelled data. To achieve this goal, we propose a\nnovel framework with the following contributions: (1) we leverage fundamental\ngrammatical rules of British Sign Language (BSL) to pre-process the input\nsubtitles, (2) we design a selective alignment loss to optimise the model for\npredicting the temporal location of signs only when the queried sign actually\noccurs in a scene, and (3) we conduct self-training with refined pseudo-labels\nwhich are more accurate than the heuristic audio-aligned labels. From this, our\nmodel not only better understands the correlation between the text and the\nsigns, but also holds potential for application in the translation of sign\nlanguages, particularly in scenarios where manual labelling of large-scale sign\ndata is impractical or challenging. Extensive experimental results demonstrate\nthat our approach achieves state-of-the-art results, surpassing previous\nbaselines by substantial margins in terms of both frame-level accuracy and\nF1-score. This highlights the effectiveness and practicality of our framework\nin advancing the field of sign language video alignment and translation.\n","authors":["Youngjoon Jang","Jeongsoo Choi","Junseok Ahn","Joon Son Chung"],"pdf_url":"https://arxiv.org/pdf/2503.03287v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03286v1","updated":"2025-03-05T09:13:19Z","published":"2025-03-05T09:13:19Z","title":"Enhancing Visual Forced Alignment with Local Context-Aware Feature\n  Extraction and Multi-Task Learning","summary":"  This paper introduces a novel approach to Visual Forced Alignment (VFA),\naiming to accurately synchronize utterances with corresponding lip movements,\nwithout relying on audio cues. We propose a novel VFA approach that integrates\na local context-aware feature extractor and employs multi-task learning to\nrefine both global and local context features, enhancing sensitivity to subtle\nlip movements for precise word-level and phoneme-level alignment. Incorporating\nthe improved Viterbi algorithm for post-processing, our method significantly\nreduces misalignments. Experimental results show our approach outperforms\nexisting methods, achieving a 6% accuracy improvement at the word-level and 27%\nimprovement at the phoneme-level in LRS2 dataset. These improvements offer new\npotential for applications in automatically subtitling TV shows or\nuser-generated content platforms like TikTok and YouTube Shorts.\n","authors":["Yi He","Lei Yang","Shilin Wang"],"pdf_url":"https://arxiv.org/pdf/2503.03286v1.pdf","comment":"Accepted by ICASSP2025"},{"id":"http://arxiv.org/abs/2503.03285v1","updated":"2025-03-05T09:12:16Z","published":"2025-03-05T09:12:16Z","title":"Enhancing Vietnamese VQA through Curriculum Learning on Raw and\n  Augmented Text Representations","summary":"  Visual Question Answering (VQA) is a multimodal task requiring reasoning\nacross textual and visual inputs, which becomes particularly challenging in\nlow-resource languages like Vietnamese due to linguistic variability and the\nlack of high-quality datasets. Traditional methods often rely heavily on\nextensive annotated datasets, computationally expensive pipelines, and large\npre-trained models, specifically in the domain of Vietnamese VQA, limiting\ntheir applicability in such scenarios. To address these limitations, we propose\na training framework that combines a paraphrase-based feature augmentation\nmodule with a dynamic curriculum learning strategy. Explicitly, augmented\nsamples are considered \"easy\" while raw samples are regarded as \"hard\". The\nframework then utilizes a mechanism that dynamically adjusts the ratio of easy\nto hard samples during training, progressively modifying the same dataset to\nincrease its difficulty level. By enabling gradual adaptation to task\ncomplexity, this approach helps the Vietnamese VQA model generalize well, thus\nimproving overall performance. Experimental results show consistent\nimprovements on the OpenViVQA dataset and mixed outcomes on the ViVQA dataset,\nhighlighting both the potential and challenges of our approach in advancing VQA\nfor Vietnamese language.\n","authors":["Khoi Anh Nguyen","Linh Yen Vu","Thang Dinh Duong","Thuan Nguyen Duong","Huy Thanh Nguyen","Vinh Quang Dinh"],"pdf_url":"https://arxiv.org/pdf/2503.03285v1.pdf","comment":"10 pages, 3 figures, AAAI-25 Workshop on Document Understanding and\n  Intelligence"},{"id":"http://arxiv.org/abs/2503.03284v1","updated":"2025-03-05T09:12:12Z","published":"2025-03-05T09:12:12Z","title":"Gaussian highpass guided image filtering","summary":"  Guided image filtering (GIF) is a popular smoothing technique, in which an\nadditional image is used as a structure guidance for noise removal with edge\npreservation. The original GIF and some of its subsequent improvements are\nderived from a two-parameter local affine model (LAM), where the filtering\noutput is a local affine transformation of the guidance image, but the input\nimage is not taken into account in the LAM formulation. In this paper, we first\nintroduce a single-parameter Prior Model based on Gaussian (highpass/lowpass)\nFiltering (PM-GF), in which the filtering output is the sum of a weighted\nportion of Gaussian highpass filtering of the guidance image and Gaussian\nsmoothing of the input image. In the PM-GF, the guidance structure determined\nby Gaussian highpass filtering is obviously transferred to the filtering\noutput, thereby better revealing the structure transfer mechanism of guided\nfiltering. Then we propose several Gaussian highpass GIFs (GH-GIFs) based on\nthe PM-GF by emulating the original GIF and some improvements, i.e., using\nPM-GF instead of LAM in these GIFs. Experimental results illustrate that the\nproposed GIFs outperform their counterparts in several image processing\napplications.\n","authors":["Lei Zhao","Chuanjiang He"],"pdf_url":"https://arxiv.org/pdf/2503.03284v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03280v1","updated":"2025-03-05T09:03:46Z","published":"2025-03-05T09:03:46Z","title":"BEVMOSNet: Multimodal Fusion for BEV Moving Object Segmentation","summary":"  Accurate motion understanding of the dynamic objects within the scene in\nbird's-eye-view (BEV) is critical to ensure a reliable obstacle avoidance\nsystem and smooth path planning for autonomous vehicles. However, this task has\nreceived relatively limited exploration when compared to object detection and\nsegmentation with only a few recent vision-based approaches presenting\npreliminary findings that significantly deteriorate in low-light, nighttime,\nand adverse weather conditions such as rain. Conversely, LiDAR and radar\nsensors remain almost unaffected in these scenarios, and radar provides key\nvelocity information of the objects. Therefore, we introduce BEVMOSNet, to our\nknowledge, the first end-to-end multimodal fusion leveraging cameras, LiDAR,\nand radar to precisely predict the moving objects in BEV. In addition, we\nperform a deeper analysis to find out the optimal strategy for deformable\ncross-attention-guided sensor fusion for cross-sensor knowledge sharing in BEV.\nWhile evaluating BEVMOSNet on the nuScenes dataset, we show an overall\nimprovement in IoU score of 36.59% compared to the vision-based unimodal\nbaseline BEV-MoSeg (Sigatapu et al., 2023), and 2.35% compared to the\nmultimodel SimpleBEV (Harley et al., 2022), extended for the motion\nsegmentation task, establishing this method as the state-of-the-art in BEV\nmotion segmentation.\n","authors":["Hiep Truong Cong","Ajay Kumar Sigatapu","Arindam Das","Yashwanth Sharma","Venkatesh Satagopan","Ganesh Sistu","Ciaran Eising"],"pdf_url":"https://arxiv.org/pdf/2503.03280v1.pdf","comment":"In Proceedings of the 20th International Joint Conference on Computer\n  Vision, Imaging and Computer Graphics Theory and Applications (2025)"},{"id":"http://arxiv.org/abs/2412.12843v2","updated":"2025-03-05T09:03:18Z","published":"2024-12-17T12:11:04Z","title":"SLTNet: Efficient Event-based Semantic Segmentation with Spike-driven\n  Lightweight Transformer-based Networks","summary":"  Event-based semantic segmentation has great potential in autonomous driving\nand robotics due to the advantages of event cameras, such as high dynamic\nrange, low latency, and low power cost. Unfortunately, current artificial\nneural network (ANN)-based segmentation methods suffer from high computational\ndemands, the requirements for image frames, and massive energy consumption,\nlimiting their efficiency and application on resource-constrained edge/mobile\nplatforms. To address these problems, we introduce SLTNet, a spike-driven\nlightweight transformer-based network designed for event-based semantic\nsegmentation. Specifically, SLTNet is built on efficient spike-driven\nconvolution blocks (SCBs) to extract rich semantic features while reducing the\nmodel's parameters. Then, to enhance the long-range contextural feature\ninteraction, we propose novel spike-driven transformer blocks (STBs) with\nbinary mask operations. Based on these basic blocks, SLTNet employs a\nhigh-efficiency single-branch architecture while maintaining the low energy\nconsumption of the Spiking Neural Network (SNN). Finally, extensive experiments\non DDD17 and DSEC-Semantic datasets demonstrate that SLTNet outperforms\nstate-of-the-art (SOTA) SNN-based methods by at most 9.06% and 9.39% mIoU,\nrespectively, with extremely 4.58x lower energy consumption and 114 FPS\ninference speed. Our code is open-sourced and available at\nhttps://github.com/longxianlei/SLTNet-v1.0.\n","authors":["Xiaxin Zhu","Fangming Guo","Xianlei Long","Qingyi Gu","Chao Chen","Fuqiang Gu"],"pdf_url":"https://arxiv.org/pdf/2412.12843v2.pdf","comment":"Submitted to 2025 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS 2025)"},{"id":"http://arxiv.org/abs/2503.03278v1","updated":"2025-03-05T09:02:33Z","published":"2025-03-05T09:02:33Z","title":"Enhancing Abnormality Grounding for Vision Language Models with\n  Knowledge Descriptions","summary":"  Visual Language Models (VLMs) have demonstrated impressive capabilities in\nvisual grounding tasks. However, their effectiveness in the medical domain,\nparticularly for abnormality detection and localization within medical images,\nremains underexplored. A major challenge is the complex and abstract nature of\nmedical terminology, which makes it difficult to directly associate\npathological anomaly terms with their corresponding visual features. In this\nwork, we introduce a novel approach to enhance VLM performance in medical\nabnormality detection and localization by leveraging decomposed medical\nknowledge. Instead of directly prompting models to recognize specific\nabnormalities, we focus on breaking down medical concepts into fundamental\nattributes and common visual patterns. This strategy promotes a stronger\nalignment between textual descriptions and visual features, improving both the\nrecognition and localization of abnormalities in medical images.We evaluate our\nmethod on the 0.23B Florence-2 base model and demonstrate that it achieves\ncomparable performance in abnormality grounding to significantly larger 7B\nLLaVA-based medical VLMs, despite being trained on only 1.5% of the data used\nfor such models. Experimental results also demonstrate the effectiveness of our\napproach in both known and previously unseen abnormalities, suggesting its\nstrong generalization capabilities.\n","authors":["Jun Li","Che Liu","Wenjia Bai","Rossella Arcucci","Cosmin I. Bercea","Julia A. Schnabel"],"pdf_url":"https://arxiv.org/pdf/2503.03278v1.pdf","comment":"11 pages, 3 figures"},{"id":"http://arxiv.org/abs/2503.03272v1","updated":"2025-03-05T08:52:55Z","published":"2025-03-05T08:52:55Z","title":"Towards Effective and Sparse Adversarial Attack on Spiking Neural\n  Networks via Breaking Invisible Surrogate Gradients","summary":"  Spiking neural networks (SNNs) have shown their competence in handling\nspatial-temporal event-based data with low energy consumption. Similar to\nconventional artificial neural networks (ANNs), SNNs are also vulnerable to\ngradient-based adversarial attacks, wherein gradients are calculated by\nspatial-temporal back-propagation (STBP) and surrogate gradients (SGs).\nHowever, the SGs may be invisible for an inference-only model as they do not\ninfluence the inference results, and current gradient-based attacks are\nineffective for binary dynamic images captured by the dynamic vision sensor\n(DVS). While some approaches addressed the issue of invisible SGs through\nuniversal SGs, their SGs lack a correlation with the victim model, resulting in\nsub-optimal performance. Moreover, the imperceptibility of existing SNN-based\nbinary attacks is still insufficient. In this paper, we introduce an innovative\npotential-dependent surrogate gradient (PDSG) method to establish a robust\nconnection between the SG and the model, thereby enhancing the adaptability of\nadversarial attacks across various models with invisible SGs. Additionally, we\npropose the sparse dynamic attack (SDA) to effectively attack binary dynamic\nimages. Utilizing a generation-reduction paradigm, SDA can fully optimize the\nsparsity of adversarial perturbations. Experimental results demonstrate that\nour PDSG and SDA outperform state-of-the-art SNN-based attacks across various\nmodels and datasets. Specifically, our PDSG achieves 100% attack success rate\non ImageNet, and our SDA obtains 82% attack success rate by modifying only\n0.24% of the pixels on CIFAR10DVS. The code is available at\nhttps://github.com/ryime/PDSG-SDA .\n","authors":["Li Lun","Kunyu Feng","Qinglong Ni","Ling Liang","Yuan Wang","Ying Li","Dunshan Yu","Xiaoxin Cui"],"pdf_url":"https://arxiv.org/pdf/2503.03272v1.pdf","comment":"Accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2503.03270v1","updated":"2025-03-05T08:51:55Z","published":"2025-03-05T08:51:55Z","title":"Reduced Spatial Dependency for More General Video-level Deepfake\n  Detection","summary":"  As one of the prominent AI-generated content, Deepfake has raised significant\nsafety concerns. Although it has been demonstrated that temporal consistency\ncues offer better generalization capability, existing methods based on CNNs\ninevitably introduce spatial bias, which hinders the extraction of intrinsic\ntemporal features. To address this issue, we propose a novel method called\nSpatial Dependency Reduction (SDR), which integrates common temporal\nconsistency features from multiple spatially-perturbed clusters, to reduce the\ndependency of the model on spatial information. Specifically, we design\nmultiple Spatial Perturbation Branch (SPB) to construct spatially-perturbed\nfeature clusters. Subsequently, we utilize the theory of mutual information and\npropose a Task-Relevant Feature Integration (TRFI) module to capture temporal\nfeatures residing in similar latent space from these clusters. Finally, the\nintegrated feature is fed into a temporal transformer to capture long-range\ndependencies. Extensive benchmarks and ablation studies demonstrate the\neffectiveness and rationale of our approach.\n","authors":["Beilin Chu","Xuan Xu","Yufei Zhang","Weike You","Linna Zhou"],"pdf_url":"https://arxiv.org/pdf/2503.03270v1.pdf","comment":"5 pages, 2 figures. Accepted to ICASSP 2025"},{"id":"http://arxiv.org/abs/2503.03265v1","updated":"2025-03-05T08:47:36Z","published":"2025-03-05T08:47:36Z","title":"Optimizing for the Shortest Path in Denoising Diffusion Model","summary":"  In this research, we propose a novel denoising diffusion model based on\nshortest-path modeling that optimizes residual propagation to enhance both\ndenoising efficiency and quality.Drawing on Denoising Diffusion Implicit Models\n(DDIM) and insights from graph theory, our model, termed the Shortest Path\nDiffusion Model (ShortDF), treats the denoising process as a shortest-path\nproblem aimed at minimizing reconstruction error. By optimizing the initial\nresiduals, we improve the efficiency of the reverse diffusion process and the\nquality of the generated samples.Extensive experiments on multiple standard\nbenchmarks demonstrate that ShortDF significantly reduces diffusion time (or\nsteps) while enhancing the visual fidelity of generated samples compared to\nprior arts.This work, we suppose, paves the way for interactive diffusion-based\napplications and establishes a foundation for rapid data generation. Code is\navailable at https://github.com/UnicomAI/ShortDF.\n","authors":["Ping Chen","Xingpeng Zhang","Zhaoxiang Liu","Huan Hu","Xiang Liu","Kai Wang","Min Wang","Yanlin Qian","Shiguo Lian"],"pdf_url":"https://arxiv.org/pdf/2503.03265v1.pdf","comment":"Accepet by CVPR 2025 (10 pages, 6 figures)"},{"id":"http://arxiv.org/abs/2408.07246v3","updated":"2025-03-05T08:43:44Z","published":"2024-08-14T01:16:40Z","title":"ChemVLM: Exploring the Power of Multimodal Large Language Models in\n  Chemistry Area","summary":"  Large Language Models (LLMs) have achieved remarkable success and have been\napplied across various scientific fields, including chemistry. However, many\nchemical tasks require the processing of visual information, which cannot be\nsuccessfully handled by existing chemical LLMs. This brings a growing need for\nmodels capable of integrating multimodal information in the chemical domain. In\nthis paper, we introduce \\textbf{ChemVLM}, an open-source chemical multimodal\nlarge language model specifically designed for chemical applications. ChemVLM\nis trained on a carefully curated bilingual multimodal dataset that enhances\nits ability to understand both textual and visual chemical information,\nincluding molecular structures, reactions, and chemistry examination questions.\nWe develop three datasets for comprehensive evaluation, tailored to Chemical\nOptical Character Recognition (OCR), Multimodal Chemical Reasoning (MMCR), and\nMultimodal Molecule Understanding tasks. We benchmark ChemVLM against a range\nof open-source and proprietary multimodal large language models on various\ntasks. Experimental results demonstrate that ChemVLM achieves competitive\nperformance across all evaluated tasks. Our model can be found at\nhttps://huggingface.co/AI4Chem/ChemVLM-26B.\n","authors":["Junxian Li","Di Zhang","Xunzhi Wang","Zeying Hao","Jingdi Lei","Qian Tan","Cai Zhou","Wei Liu","Yaotian Yang","Xinrui Xiong","Weiyun Wang","Zhe Chen","Wenhai Wang","Wei Li","Shufei Zhang","Mao Su","Wanli Ouyang","Yuqiang Li","Dongzhan Zhou"],"pdf_url":"https://arxiv.org/pdf/2408.07246v3.pdf","comment":"11 pages, updated version"},{"id":"http://arxiv.org/abs/2503.03262v1","updated":"2025-03-05T08:38:51Z","published":"2025-03-05T08:38:51Z","title":"Trajectory Prediction for Autonomous Driving: Progress, Limitations, and\n  Future Directions","summary":"  As the potential for autonomous vehicles to be integrated on a large scale\ninto modern traffic systems continues to grow, ensuring safe navigation in\ndynamic environments is crucial for smooth integration. To guarantee safety and\nprevent collisions, autonomous vehicles must be capable of accurately\npredicting the trajectories of surrounding traffic agents. Over the past\ndecade, significant efforts from both academia and industry have been dedicated\nto designing solutions for precise trajectory forecasting. These efforts have\nproduced a diverse range of approaches, raising questions about the differences\nbetween these methods and whether trajectory prediction challenges have been\nfully addressed. This paper reviews a substantial portion of recent trajectory\nprediction methods and devises a taxonomy to classify existing solutions. A\ngeneral overview of the prediction pipeline is also provided, covering input\nand output modalities, modeling features, and prediction paradigms discussed in\nthe literature. In addition, the paper discusses active research areas within\ntrajectory prediction, addresses the posed research questions, and highlights\nthe remaining research gaps and challenges.\n","authors":["Nadya Abdel Madjid","Abdulrahman Ahmad","Murad Mebrahtu","Yousef Babaa","Abdelmoamen Nasser","Sumbal Malik","Bilal Hassan","Naoufel Werghi","Jorge Dias","Majid Khonji"],"pdf_url":"https://arxiv.org/pdf/2503.03262v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05274v2","updated":"2025-03-05T08:36:27Z","published":"2024-09-17T10:08:37Z","title":"Scale-Invariant Object Detection by Adaptive Convolution with Unified\n  Global-Local Context","summary":"  Dense features are important for detecting minute objects in images.\nUnfortunately, despite the remarkable efficacy of the CNN models in multi-scale\nobject detection, CNN models often fail to detect smaller objects in images due\nto the loss of dense features during the pooling process. Atrous convolution\naddresses this issue by applying sparse kernels. However, sparse kernels often\ncan lose the multi-scale detection efficacy of the CNN model. In this paper, we\npropose an object detection model using a Switchable (adaptive) Atrous\nConvolutional Network (SAC-Net) based on the efficientDet model. A fixed atrous\nrate limits the performance of the CNN models in the convolutional layers. To\novercome this limitation, we introduce a switchable mechanism that allows for\ndynamically adjusting the atrous rate during the forward pass. The proposed\nSAC-Net encapsulates the benefits of both low-level and high-level features to\nachieve improved performance on multi-scale object detection tasks, without\nlosing the dense features. Further, we apply a depth-wise switchable atrous\nrate to the proposed network, to improve the scale-invariant features. Finally,\nwe apply global context on the proposed model. Our extensive experiments on\nbenchmark datasets demonstrate that the proposed SAC-Net outperforms the\nstate-of-the-art models by a significant margin in terms of accuracy.\n","authors":["Amrita Singh","Snehasis Mukherjee"],"pdf_url":"https://arxiv.org/pdf/2410.05274v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.06927v3","updated":"2025-03-05T08:35:41Z","published":"2024-08-13T14:29:00Z","title":"Breaking Class Barriers: Efficient Dataset Distillation via Inter-Class\n  Feature Compensator","summary":"  Dataset distillation has emerged as a technique aiming to condense\ninformative features from large, natural datasets into a compact and synthetic\nform. While recent advancements have refined this technique, its performance is\nbottlenecked by the prevailing class-specific synthesis paradigm. Under this\nparadigm, synthetic data is optimized exclusively for a pre-assigned one-hot\nlabel, creating an implicit class barrier in feature condensation. This leads\nto inefficient utilization of the distillation budget and oversight of\ninter-class feature distributions, which ultimately limits the effectiveness\nand efficiency, as demonstrated in our analysis. To overcome these constraints,\nthis paper presents the Inter-class Feature Compensator (INFER), an innovative\ndistillation approach that transcends the class-specific data-label framework\nwidely utilized in current dataset distillation methods. Specifically, INFER\nleverages a Universal Feature Compensator (UFC) to enhance feature integration\nacross classes, enabling the generation of multiple additional synthetic\ninstances from a single UFC input. This significantly improves the efficiency\nof the distillation budget. Moreover, INFER enriches inter-class interactions\nduring the distillation, thereby enhancing the effectiveness and\ngeneralizability of the distilled data. By allowing for the linear\ninterpolation of labels similar to those in the original dataset, INFER\nmeticulously optimizes the synthetic data and dramatically reduces the size of\nsoft labels in the synthetic dataset to almost zero, establishing a new\nbenchmark for efficiency and effectiveness in dataset distillation. In\npractice, INFER demonstrates state-of-the-art performance across benchmark\ndatasets. For instance, in the ipc = 50 setting on ImageNet-1k with the same\ncompression level, it outperforms SRe2L by 34.5% using ResNet18.\n","authors":["Xin Zhang","Jiawei Du","Ping Liu","Joey Tianyi Zhou"],"pdf_url":"https://arxiv.org/pdf/2408.06927v3.pdf","comment":"Accepted to ICLR 2025"},{"id":"http://arxiv.org/abs/2503.03259v1","updated":"2025-03-05T08:33:08Z","published":"2025-03-05T08:33:08Z","title":"BANet: Bilateral Aggregation Network for Mobile Stereo Matching","summary":"  State-of-the-art stereo matching methods typically use costly 3D convolutions\nto aggregate a full cost volume, but their computational demands make mobile\ndeployment challenging. Directly applying 2D convolutions for cost aggregation\noften results in edge blurring, detail loss, and mismatches in textureless\nregions. Some complex operations, like deformable convolutions and iterative\nwarping, can partially alleviate this issue; however, they are not\nmobile-friendly, limiting their deployment on mobile devices. In this paper, we\npresent a novel bilateral aggregation network (BANet) for mobile stereo\nmatching that produces high-quality results with sharp edges and fine details\nusing only 2D convolutions. Specifically, we first separate the full cost\nvolume into detailed and smooth volumes using a spatial attention map, then\nperform detailed and smooth aggregations accordingly, ultimately fusing both to\nobtain the final disparity map. Additionally, to accurately identify\nhigh-frequency detailed regions and low-frequency smooth/textureless regions,\nwe propose a new scale-aware spatial attention module. Experimental results\ndemonstrate that our BANet-2D significantly outperforms other mobile-friendly\nmethods, achieving 35.3\\% higher accuracy on the KITTI 2015 leaderboard than\nMobileStereoNet-2D, with faster runtime on mobile devices. The extended 3D\nversion, BANet-3D, achieves the highest accuracy among all real-time methods on\nhigh-end GPUs. Code: \\textcolor{magenta}{https://github.com/gangweiX/BANet}.\n","authors":["Gangwei Xu","Jiaxin Liu","Xianqi Wang","Junda Cheng","Yong Deng","Jinliang Zang","Yurui Chen","Xin Yang"],"pdf_url":"https://arxiv.org/pdf/2503.03259v1.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2503.03256v1","updated":"2025-03-05T08:20:16Z","published":"2025-03-05T08:20:16Z","title":"BAT: Learning Event-based Optical Flow with Bidirectional Adaptive\n  Temporal Correlation","summary":"  Event cameras deliver visual information characterized by a high dynamic\nrange and high temporal resolution, offering significant advantages in\nestimating optical flow for complex lighting conditions and fast-moving\nobjects. Current advanced optical flow methods for event cameras largely adopt\nestablished image-based frameworks. However, the spatial sparsity of event data\nlimits their performance. In this paper, we present BAT, an innovative\nframework that estimates event-based optical flow using bidirectional adaptive\ntemporal correlation. BAT includes three novel designs: 1) a bidirectional\ntemporal correlation that transforms bidirectional temporally dense motion cues\ninto spatially dense ones, enabling accurate and spatially dense optical flow\nestimation; 2) an adaptive temporal sampling strategy for maintaining temporal\nconsistency in correlation; 3) spatially adaptive temporal motion aggregation\nto efficiently and adaptively aggregate consistent target motion features into\nadjacent motion features while suppressing inconsistent ones. Our results rank\n$1^{st}$ on the DSEC-Flow benchmark, outperforming existing state-of-the-art\nmethods by a large margin while also exhibiting sharp edges and high-quality\ndetails. Notably, our BAT can accurately predict future optical flow using only\npast events, significantly outperforming E-RAFT's warm-start approach. Code:\n\\textcolor{magenta}{https://github.com/gangweiX/BAT}.\n","authors":["Gangwei Xu","Haotong Lin","Zhaoxing Zhang","Hongcheng Luo","Haiyang Sun","Xin Yang"],"pdf_url":"https://arxiv.org/pdf/2503.03256v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2503.03255v1","updated":"2025-03-05T08:15:31Z","published":"2025-03-05T08:15:31Z","title":"Computational Analysis of Degradation Modeling in Blind Panoramic Image\n  Quality Assessment","summary":"  Blind panoramic image quality assessment (BPIQA) has recently brought new\nchallenge to the visual quality community, due to the complex interaction\nbetween immersive content and human behavior. Although many efforts have been\nmade to advance BPIQA from both conducting psychophysical experiments and\ndesigning performance-driven objective algorithms, \\textit{limited content} and\n\\textit{few samples} in those closed sets inevitably would result in shaky\nconclusions, thereby hindering the development of BPIQA, we refer to it as the\n\\textit{easy-database} issue. In this paper, we present a sufficient\ncomputational analysis of degradation modeling in BPIQA to thoroughly explore\nthe \\textit{easy-database issue}, where we carefully design three types of\nexperiments via investigating the gap between BPIQA and blind image quality\nassessment (BIQA), the necessity of specific design in BPIQA models, and the\ngeneralization ability of BPIQA models. From extensive experiments, we find\nthat easy databases narrow the gap between the performance of BPIQA and BIQA\nmodels, which is unconducive to the development of BPIQA. And the easy\ndatabases make the BPIQA models be closed to saturation, therefore the\neffectiveness of the associated specific designs can not be well verified.\nBesides, the BPIQA models trained on our recently proposed databases with\ncomplicated degradation show better generalization ability. Thus, we believe\nthat much more efforts are highly desired to put into BPIQA from both\nsubjective viewpoint and objective viewpoint.\n","authors":["Jiebin Yan","Ziwen Tan","Jiale Rao","Lei Wu","Yifan Zuo","Yuming Fang"],"pdf_url":"https://arxiv.org/pdf/2503.03255v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.00397v3","updated":"2025-03-05T08:09:16Z","published":"2025-03-01T08:18:11Z","title":"Floorplan-SLAM: A Real-Time, High-Accuracy, and Long-Term Multi-Session\n  Point-Plane SLAM for Efficient Floorplan Reconstruction","summary":"  Floorplan reconstruction provides structural priors essential for reliable\nindoor robot navigation and high-level scene understanding. However, existing\napproaches either require time-consuming offline processing with a complete\nmap, or rely on expensive sensors and substantial computational resources. To\naddress the problems, we propose Floorplan-SLAM, which incorporates floorplan\nreconstruction tightly into a multi-session SLAM system by seamlessly\ninteracting with plane extraction, pose estimation, and back-end optimization,\nachieving real-time, high-accuracy, and long-term floorplan reconstruction\nusing only a stereo camera. Specifically, we present a robust plane extraction\nalgorithm that operates in a compact plane parameter space and leverages\nspatially complementary features to accurately detect planar structures, even\nin weakly textured scenes. Furthermore, we propose a floorplan reconstruction\nmodule tightly coupled with the SLAM system, which uses continuously optimized\nplane landmarks and poses to formulate and solve a novel optimization problem,\nthereby enabling real-time incremental floorplan reconstruction. Note that by\nleveraging the map merging capability of multi-session SLAM, our method\nsupports long-term floorplan reconstruction across multiple sessions without\nredundant data collection. Experiments on the VECtor and the self-collected\ndatasets indicate that Floorplan-SLAM significantly outperforms\nstate-of-the-art methods in terms of plane extraction robustness, pose\nestimation accuracy, and floorplan reconstruction fidelity and speed, achieving\nreal-time performance at 25-45 FPS without GPU acceleration, which reduces the\nfloorplan reconstruction time for a 1000 square meters scene from over 10 hours\nto just 9.44 minutes.\n","authors":["Haolin Wang","Zeren Lv","Hao Wei","Haijiang Zhu","Yihong Wu"],"pdf_url":"https://arxiv.org/pdf/2503.00397v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.12020v4","updated":"2025-03-05T08:09:07Z","published":"2024-04-18T09:16:02Z","title":"Look, Listen, and Answer: Overcoming Biases for Audio-Visual Question\n  Answering","summary":"  Audio-Visual Question Answering (AVQA) is a complex multi-modal reasoning\ntask, demanding intelligent systems to accurately respond to natural language\nqueries based on audio-video input pairs. Nevertheless, prevalent AVQA\napproaches are prone to overlearning dataset biases, resulting in poor\nrobustness. Furthermore, current datasets may not provide a precise diagnostic\nfor these methods. To tackle these challenges, firstly, we propose a novel\ndataset, MUSIC-AVQA-R, crafted in two steps: rephrasing questions within the\ntest split of a public dataset (MUSIC-AVQA) and subsequently introducing\ndistribution shifts to split questions. The former leads to a large, diverse\ntest space, while the latter results in a comprehensive robustness evaluation\non rare, frequent, and overall questions. Secondly, we propose a robust\narchitecture that utilizes a multifaceted cycle collaborative debiasing\nstrategy to overcome bias learning. Experimental results show that this\narchitecture achieves state-of-the-art performance on MUSIC-AVQA-R, notably\nobtaining a significant improvement of 9.32%. Extensive ablation experiments\nare conducted on the two datasets mentioned to analyze the component\neffectiveness within the debiasing strategy. Additionally, we highlight the\nlimited robustness of existing multi-modal QA methods through the evaluation on\nour dataset. We also conduct experiments combining various baselines with our\nproposed strategy on two datasets to verify its plug-and-play capability. Our\ndataset and code are available at https://github.com/reml-group/MUSIC-AVQA-R.\n","authors":["Jie Ma","Min Hu","Pinghui Wang","Wangchun Sun","Lingyun Song","Hongbin Pei","Jun Liu","Youtian Du"],"pdf_url":"https://arxiv.org/pdf/2404.12020v4.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2503.03244v1","updated":"2025-03-05T07:52:52Z","published":"2025-03-05T07:52:52Z","title":"Two-Stream Thermal Imaging Fusion for Enhanced Time of Birth Detection\n  in Neonatal Care","summary":"  Around 10% of newborns require some help to initiate breathing, and 5\\% need\nventilation assistance. Accurate Time of Birth (ToB) documentation is essential\nfor optimizing neonatal care, as timely interventions are vital for proper\nresuscitation. However, current clinical methods for recording ToB often rely\non manual processes, which can be prone to inaccuracies. In this study, we\npresent a novel two-stream fusion system that combines the power of image and\nvideo analysis to accurately detect the ToB from thermal recordings in the\ndelivery room and operating theater. By integrating static and dynamic streams,\nour approach captures richer birth-related spatiotemporal features, leading to\nmore robust and precise ToB estimation. We demonstrate that this synergy\nbetween data modalities enhances performance over single-stream approaches. Our\nsystem achieves 95.7% precision and 84.8% recall in detecting birth within\nshort video clips. Additionally, with the help of a score aggregation module,\nit successfully identifies ToB in 100% of test cases, with a median absolute\nerror of 2 seconds and an absolute mean deviation of 4.5 seconds compared to\nmanual annotations.\n","authors":["Jorge García-Torres","Øyvind Meinich-Bache","Sara Brunner","Siren Rettedal","Vilde Kolstad","Kjersti Engan"],"pdf_url":"https://arxiv.org/pdf/2503.03244v1.pdf","comment":"Submitted to IEEE 25th International Conference on Digital Signal\n  Processing"},{"id":"http://arxiv.org/abs/2503.02357v2","updated":"2025-03-05T07:50:05Z","published":"2025-03-04T07:28:45Z","title":"Q-Eval-100K: Evaluating Visual Quality and Alignment Level for\n  Text-to-Vision Content","summary":"  Evaluating text-to-vision content hinges on two crucial aspects: visual\nquality and alignment. While significant progress has been made in developing\nobjective models to assess these dimensions, the performance of such models\nheavily relies on the scale and quality of human annotations. According to\nScaling Law, increasing the number of human-labeled instances follows a\npredictable pattern that enhances the performance of evaluation models.\nTherefore, we introduce a comprehensive dataset designed to Evaluate Visual\nquality and Alignment Level for text-to-vision content (Q-EVAL-100K), featuring\nthe largest collection of human-labeled Mean Opinion Scores (MOS) for the\nmentioned two aspects. The Q-EVAL-100K dataset encompasses both text-to-image\nand text-to-video models, with 960K human annotations specifically focused on\nvisual quality and alignment for 100K instances (60K images and 40K videos).\nLeveraging this dataset with context prompt, we propose Q-Eval-Score, a unified\nmodel capable of evaluating both visual quality and alignment with special\nimprovements for handling long-text prompt alignment. Experimental results\nindicate that the proposed Q-Eval-Score achieves superior performance on both\nvisual quality and alignment, with strong generalization capabilities across\nother benchmarks. These findings highlight the significant value of the\nQ-EVAL-100K dataset. Data and codes will be available at\nhttps://github.com/zzc-1998/Q-Eval.\n","authors":["Zicheng Zhang","Tengchuan Kou","Shushi Wang","Chunyi Li","Wei Sun","Wei Wang","Xiaoyu Li","Zongyu Wang","Xuezhi Cao","Xiongkuo Min","Xiaohong Liu","Guangtao Zhai"],"pdf_url":"https://arxiv.org/pdf/2503.02357v2.pdf","comment":"Accepted to CVPR 2025"},{"id":"http://arxiv.org/abs/2503.03236v1","updated":"2025-03-05T07:29:12Z","published":"2025-03-05T07:29:12Z","title":"GenColor: Generative Color-Concept Association in Visual Design","summary":"  Existing approaches for color-concept association typically rely on\nquery-based image referencing, and color extraction from image references.\nHowever, these approaches are effective only for common concepts, and are\nvulnerable to unstable image referencing and varying image conditions. Our\nformative study with designers underscores the need for primary-accent color\ncompositions and context-dependent colors (e.g., 'clear' vs. 'polluted' sky) in\ndesign. In response, we introduce a generative approach for mining semantically\nresonant colors leveraging images generated by text-to-image models. Our\ninsight is that contemporary text-to-image models can resemble visual patterns\nfrom large-scale real-world data. The framework comprises three stages: concept\ninstancing produces generative samples using diffusion models, text-guided\nimage segmentation identifies concept-relevant regions within the image, and\ncolor association extracts primarily accompanied by accent colors. Quantitative\ncomparisons with expert designs validate our approach's effectiveness, and we\ndemonstrate the applicability through cases in various design scenarios and a\ngallery.\n","authors":["Yihan Hou","Xingchen Zeng","Yusong Wang","Manling Yang","Xiaojiao Chen","Wei Zeng"],"pdf_url":"https://arxiv.org/pdf/2503.03236v1.pdf","comment":"19 pages, 16 figures. Accepted at CHI Conference on Human Factors in\n  Computing Systems (CHI'25), April 26-May 1, 2025, Yokohama, Japan"},{"id":"http://arxiv.org/abs/2411.13807v3","updated":"2025-03-05T07:24:34Z","published":"2024-11-21T03:13:30Z","title":"MagicDrive-V2: High-Resolution Long Video Generation for Autonomous\n  Driving with Adaptive Control","summary":"  The rapid advancement of diffusion models has greatly improved video\nsynthesis, especially in controllable video generation, which is vital for\napplications like autonomous driving. Although DiT with 3D VAE has become a\nstandard framework for video generation, it introduces challenges in\ncontrollable driving video generation, especially for geometry control,\nrendering existing control methods ineffective. To address these issues, we\npropose MagicDrive-V2, a novel approach that integrates the MVDiT block and\nspatial-temporal conditional encoding to enable multi-view video generation and\nprecise geometric control. Additionally, we introduce an efficient method for\nobtaining contextual descriptions for videos to support diverse textual\ncontrol, along with a progressive training strategy using mixed video data to\nenhance training efficiency and generalizability. Consequently, MagicDrive-V2\nenables multi-view driving video synthesis with $3.3\\times$ resolution and\n$4\\times$ frame count (compared to current SOTA), rich contextual control, and\ngeometric controls. Extensive experiments demonstrate MagicDrive-V2's ability,\nunlocking broader applications in autonomous driving.\n","authors":["Ruiyuan Gao","Kai Chen","Bo Xiao","Lanqing Hong","Zhenguo Li","Qiang Xu"],"pdf_url":"https://arxiv.org/pdf/2411.13807v3.pdf","comment":"Project Website: https://flymin.github.io/magicdrive-v2/"},{"id":"http://arxiv.org/abs/2412.09601v2","updated":"2025-03-05T07:06:15Z","published":"2024-12-12T18:59:11Z","title":"TimeRefine: Temporal Grounding with Time Refining Video LLM","summary":"  Video temporal grounding aims to localize relevant temporal boundaries in a\nvideo given a textual prompt. Recent work has focused on enabling Video LLMs to\nperform video temporal grounding via next-token prediction of temporal\ntimestamps. However, accurately localizing timestamps in videos remains\nchallenging for Video LLMs when relying solely on temporal token prediction.\nOur proposed TimeRefine addresses this challenge in two ways. First, instead of\ndirectly predicting the start and end timestamps, we reformulate the temporal\ngrounding task as a temporal refining task: the model first makes rough\npredictions and then refines them by predicting offsets to the target segment.\nThis refining process is repeated multiple times, through which the model\nprogressively self-improves its temporal localization accuracy. Second, to\nenhance the model's temporal perception capabilities, we incorporate an\nauxiliary prediction head that penalizes the model more if a predicted segment\ndeviates further from the ground truth, thus encouraging the model to make\ncloser and more accurate predictions. Our plug-and-play method can be\nintegrated into most LLM-based temporal grounding approaches. The experimental\nresults demonstrate that TimeRefine achieves 3.6% and 5.0% mIoU improvements on\nthe ActivityNet and Charades-STA datasets, respectively. Code and pretrained\nmodels will be released.\n","authors":["Xizi Wang","Feng Cheng","Ziyang Wang","Huiyu Wang","Md Mohaiminul Islam","Lorenzo Torresani","Mohit Bansal","Gedas Bertasius","David Crandall"],"pdf_url":"https://arxiv.org/pdf/2412.09601v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03228v1","updated":"2025-03-05T06:56:42Z","published":"2025-03-05T06:56:42Z","title":"Path-Adaptive Matting for Efficient Inference Under Various\n  Computational Cost Constraints","summary":"  In this paper, we explore a novel image matting task aimed at achieving\nefficient inference under various computational cost constraints, specifically\nFLOP limitations, using a single matting network. Existing matting methods\nwhich have not explored scalable architectures or path-learning strategies,\nfail to tackle this challenge. To overcome these limitations, we introduce\nPath-Adaptive Matting (PAM), a framework that dynamically adjusts network paths\nbased on image contexts and computational cost constraints. We formulate the\ntraining of the computational cost-constrained matting network as a bilevel\noptimization problem, jointly optimizing the matting network and the path\nestimator. Building on this formalization, we design a path-adaptive matting\narchitecture by incorporating path selection layers and learnable connect\nlayers to estimate optimal paths and perform efficient inference within a\nunified network. Furthermore, we propose a performance-aware path-learning\nstrategy to generate path labels online by evaluating a few paths sampled from\nthe prior distribution of optimal paths and network estimations, enabling\nrobust and efficient online path learning. Experiments on five image matting\ndatasets demonstrate that the proposed PAM framework achieves competitive\nperformance across a range of computational cost constraints.\n","authors":["Qinglin Liu","Zonglin Li","Xiaoqian Lv","Xin Sun","Ru Li","Shengping Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.03228v1.pdf","comment":"Accepted to AAAI 2025"},{"id":"http://arxiv.org/abs/2502.19908v2","updated":"2025-03-05T06:36:27Z","published":"2025-02-27T09:26:22Z","title":"CarPlanner: Consistent Auto-regressive Trajectory Planning for\n  Large-scale Reinforcement Learning in Autonomous Driving","summary":"  Trajectory planning is vital for autonomous driving, ensuring safe and\nefficient navigation in complex environments. While recent learning-based\nmethods, particularly reinforcement learning (RL), have shown promise in\nspecific scenarios, RL planners struggle with training inefficiencies and\nmanaging large-scale, real-world driving scenarios. In this paper, we introduce\n\\textbf{CarPlanner}, a \\textbf{C}onsistent \\textbf{a}uto-\\textbf{r}egressive\n\\textbf{Planner} that uses RL to generate multi-modal trajectories. The\nauto-regressive structure enables efficient large-scale RL training, while the\nincorporation of consistency ensures stable policy learning by maintaining\ncoherent temporal consistency across time steps. Moreover, CarPlanner employs a\ngeneration-selection framework with an expert-guided reward function and an\ninvariant-view module, simplifying RL training and enhancing policy\nperformance. Extensive analysis demonstrates that our proposed RL framework\neffectively addresses the challenges of training efficiency and performance\nenhancement, positioning CarPlanner as a promising solution for trajectory\nplanning in autonomous driving. To the best of our knowledge, we are the first\nto demonstrate that the RL-based planner can surpass both IL- and rule-based\nstate-of-the-arts (SOTAs) on the challenging large-scale real-world dataset\nnuPlan. Our proposed CarPlanner surpasses RL-, IL-, and rule-based SOTA\napproaches within this demanding dataset.\n","authors":["Dongkun Zhang","Jiaming Liang","Ke Guo","Sha Lu","Qi Wang","Rong Xiong","Zhenwei Miao","Yue Wang"],"pdf_url":"https://arxiv.org/pdf/2502.19908v2.pdf","comment":"CVPR 2025"},{"id":"http://arxiv.org/abs/2503.03222v1","updated":"2025-03-05T06:32:49Z","published":"2025-03-05T06:32:49Z","title":"Mocap-2-to-3: Lifting 2D Diffusion-Based Pretrained Models for 3D Motion\n  Capture","summary":"  Recovering absolute poses in the world coordinate system from monocular views\npresents significant challenges. Two primary issues arise in this context.\nFirstly, existing methods rely on 3D motion data for training, which requires\ncollection in limited environments. Acquiring such 3D labels for new actions in\na timely manner is impractical, severely restricting the model's generalization\ncapabilities. In contrast, 2D poses are far more accessible and easier to\nobtain. Secondly, estimating a person's absolute position in metric space from\na single viewpoint is inherently more complex. To address these challenges, we\nintroduce Mocap-2-to-3, a novel framework that decomposes intricate 3D motions\ninto 2D poses, leveraging 2D data to enhance 3D motion reconstruction in\ndiverse scenarios and accurately predict absolute positions in the world\ncoordinate system. We initially pretrain a single-view diffusion model with\nextensive 2D data, followed by fine-tuning a multi-view diffusion model for\nview consistency using publicly available 3D data. This strategy facilitates\nthe effective use of large-scale 2D data. Additionally, we propose an\ninnovative human motion representation that decouples local actions from global\nmovements and encodes geometric priors of the ground, ensuring the generative\nmodel learns accurate motion priors from 2D data. During inference, this allows\nfor the gradual recovery of global movements, resulting in more plausible\npositioning. We evaluate our model's performance on real-world datasets,\ndemonstrating superior accuracy in motion and absolute human positioning\ncompared to state-of-the-art methods, along with enhanced generalization and\nscalability. Our code will be made publicly available.\n","authors":["Zhumei Wang","Zechen Hu","Ruoxi Guo","Huaijin Pi","Ziyong Feng","Sida Peng","Xiaowei Zhou"],"pdf_url":"https://arxiv.org/pdf/2503.03222v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03214v1","updated":"2025-03-05T06:16:13Z","published":"2025-03-05T06:16:13Z","title":"Rice Grain Size Measurement using Image Processing","summary":"  The rice grain quality can be determined from its size and chalkiness. The\ntraditional approach to measure the rice grain size involves manual inspection,\nwhich is inefficient and leads to inconsistent results. To address this issue,\nan image processing based approach is proposed and developed in this research.\nThe approach takes image of rice grains as input and outputs the number of rice\ngrains and size of each rice grain. The different steps, such as extraction of\nregion of interest, segmentation of rice grains, and sub-contours removal,\ninvolved in the proposed approach are discussed. The approach was tested on\nrice grain images captured from different height using mobile phone camera. The\nobtained results show that the proposed approach successfully detected 95\\% of\nthe rice grains and achieved 90\\% accuracy for length and width measurement.\n","authors":["Ankush Tyagi","Dhruv Motwani","Vipul K. Dabhi","Harshadkumar B. Prajapati"],"pdf_url":"https://arxiv.org/pdf/2503.03214v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03206v1","updated":"2025-03-05T05:50:38Z","published":"2025-03-05T05:50:38Z","title":"An Analytical Theory of Power Law Spectral Bias in the Learning Dynamics\n  of Diffusion Models","summary":"  We developed an analytical framework for understanding how the learned\ndistribution evolves during diffusion model training. Leveraging the Gaussian\nequivalence principle, we derived exact solutions for the gradient-flow\ndynamics of weights in one- or two-layer linear denoiser settings with\narbitrary data. Remarkably, these solutions allowed us to derive the generated\ndistribution in closed form and its KL divergence through training. These\nanalytical results expose a pronounced power-law spectral bias, i.e., for\nweights and distributions, the convergence time of a mode follows an inverse\npower law of its variance. Empirical experiments on both Gaussian and image\ndatasets demonstrate that the power-law spectral bias remains robust even when\nusing deeper or convolutional architectures. Our results underscore the\nimportance of the data covariance in dictating the order and rate at which\ndiffusion models learn different modes of the data, providing potential\nexplanations for why earlier stopping could lead to incorrect details in image\ngenerative models.\n","authors":["Binxu Wang"],"pdf_url":"https://arxiv.org/pdf/2503.03206v1.pdf","comment":"50 pages, 10 figures. Preprint"},{"id":"http://arxiv.org/abs/2503.03204v1","updated":"2025-03-05T05:50:28Z","published":"2025-03-05T05:50:28Z","title":"Find Matching Faces Based On Face Parameters","summary":"  This paper presents an innovative approach that enables the user to find\nmatching faces based on the user-selected face parameters. Through gradio-based\nuser interface, the users can interactively select the face parameters they\nwant in their desired partner. These user-selected face parameters are\ntransformed into a text prompt which is used by the Text-To-Image generation\nmodel to generate a realistic face image. Further, the generated image along\nwith the images downloaded from the Jeevansathi.com are processed through face\ndetection and feature extraction model, which results in high dimensional\nvector embedding of 512 dimensions. The vector embeddings generated from the\ndownloaded images are stored into vector database. Now, the similarity search\nis carried out between the vector embedding of generated image and the stored\nvector embeddings. As a result, it displays the top five similar faces based on\nthe user-selected face parameters. This contribution holds a significant\npotential to turn into a high-quality personalized face matching tool.\n","authors":["Setu A. Bhatt","Harshadkumar B. Prajapati","Vipul K. Dabhi","Ankush Tyagi"],"pdf_url":"https://arxiv.org/pdf/2503.03204v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03202v1","updated":"2025-03-05T05:46:08Z","published":"2025-03-05T05:46:08Z","title":"Variance-Aware Loss Scheduling for Multimodal Alignment in Low-Data\n  Settings","summary":"  Training vision-language models for image-text alignment typically requires\nlarge datasets to achieve robust performance. In low-data scenarios, standard\ncontrastive learning can struggle to align modalities effectively due to\noverfitting and unstable training dynamics. In this paper, we propose a\nvariance-aware loss scheduling approach that dynamically adjusts the weighting\nof the contrastive loss based on the statistical variability (uncertainty) in\nthe model's alignment predictions. Using a subset of the Flickr8k image-caption\ndataset to simulate limited data conditions, we demonstrate that our approach\nimproves image-text retrieval accuracy compared to a fixed-weight baseline. We\nalso compare against other adaptive weighting strategies (using output entropy\nand cosine similarity spread) and find that variance-aware scheduling provides\nthe best overall trade-off. Qualitatively, our method yields more distinct\nmultimodal embeddings as shown by t-SNE visualizations. Moreover, in a stress\ntest with noise-injected captions and images, the variance-guided loss proves\nmore robust, maintaining higher recall when random perturbations are\nintroduced. These results highlight the benefit of adaptive loss weighting for\nmultimodal alignment in low-data regimes.\n","authors":["Sneh Pillai"],"pdf_url":"https://arxiv.org/pdf/2503.03202v1.pdf","comment":"8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2503.03200v1","updated":"2025-03-05T05:36:26Z","published":"2025-03-05T05:36:26Z","title":"Transformer-Based Spatio-Temporal Association of Apple Fruitlets","summary":"  In this paper, we present a transformer-based method to spatio-temporally\nassociate apple fruitlets in stereo-images collected on different days and from\ndifferent camera poses. State-of-the-art association methods in agriculture are\ndedicated towards matching larger crops using either high-resolution point\nclouds or temporally stable features, which are both difficult to obtain for\nsmaller fruit in the field. To address these challenges, we propose a\ntransformer-based architecture that encodes the shape and position of each\nfruitlet, and propagates and refines these features through a series of\ntransformer encoder layers with alternating self and cross-attention. We\ndemonstrate that our method is able to achieve an F1-score of 92.4% on data\ncollected in a commercial apple orchard and outperforms all baselines and\nablations.\n","authors":["Harry Freeman","George Kantor"],"pdf_url":"https://arxiv.org/pdf/2503.03200v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03196v1","updated":"2025-03-05T05:30:22Z","published":"2025-03-05T05:30:22Z","title":"SpiritSight Agent: Advanced GUI Agent with One Look","summary":"  Graphical User Interface (GUI) agents show amazing abilities in assisting\nhuman-computer interaction, automating human user's navigation on digital\ndevices. An ideal GUI agent is expected to achieve high accuracy, low latency,\nand compatibility for different GUI platforms. Recent vision-based approaches\nhave shown promise by leveraging advanced Vision Language Models (VLMs). While\nthey generally meet the requirements of compatibility and low latency, these\nvision-based GUI agents tend to have low accuracy due to their limitations in\nelement grounding. To address this issue, we propose $\\textbf{SpiritSight}$, a\nvision-based, end-to-end GUI agent that excels in GUI navigation tasks across\nvarious GUI platforms. First, we create a multi-level, large-scale,\nhigh-quality GUI dataset called $\\textbf{GUI-Lasagne}$ using scalable methods,\nempowering SpiritSight with robust GUI understanding and grounding\ncapabilities. Second, we introduce the $\\textbf{Universal Block Parsing (UBP)}$\nmethod to resolve the ambiguity problem in dynamic high-resolution of visual\ninputs, further enhancing SpiritSight's ability to ground GUI objects. Through\nthese efforts, SpiritSight agent outperforms other advanced methods on diverse\nGUI benchmarks, demonstrating its superior capability and compatibility in GUI\nnavigation tasks. Models are available at\n$\\href{https://huggingface.co/SenseLLM/SpiritSight-Agent-8B}{this\\ URL}$.\n","authors":["Zhiyuan Huang","Ziming Cheng","Junting Pan","Zhaohui Hou","Mingjie Zhan"],"pdf_url":"https://arxiv.org/pdf/2503.03196v1.pdf","comment":"Paper accepted to CVPR 2025"},{"id":"http://arxiv.org/abs/2312.10892v3","updated":"2025-03-05T05:27:43Z","published":"2023-12-18T02:50:45Z","title":"Deep Learning-based MRI Reconstruction with Artificial Fourier Transform\n  Network (AFTNet)","summary":"  Deep complex-valued neural networks (CVNNs) provide a powerful way to\nleverage complex number operations and representations and have succeeded in\nseveral phase-based applications. However, previous networks have not fully\nexplored the impact of complex-valued networks in the frequency domain. Here,\nwe introduce a unified complex-valued deep learning framework-Artificial\nFourier Transform Network (AFTNet)-which combines domain-manifold learning and\nCVNNs. AFTNet can be readily used to solve image inverse problems in domain\ntransformation, especially for accelerated magnetic resonance imaging (MRI)\nreconstruction and other applications. While conventional methods typically\nutilize magnitude images or treat the real and imaginary components of k-space\ndata as separate channels, our approach directly processes raw k-space data in\nthe frequency domain, utilizing complex-valued operations. This allows for a\nmapping between the frequency (k-space) and image domain to be determined\nthrough cross-domain learning. We show that AFTNet achieves superior\naccelerated MRI reconstruction compared to existing approaches. Furthermore,\nour approach can be applied to various tasks, such as denoised magnetic\nresonance spectroscopy (MRS) reconstruction and datasets with various\ncontrasts. The AFTNet presented here is a valuable preprocessing component for\ndifferent preclinical studies and provides an innovative alternative for\nsolving inverse problems in imaging and spectroscopy. The code is available at:\nhttps://github.com/yanting-yang/AFT-Net.\n","authors":["Yanting Yang","Yiren Zhang","Zongyu Li","Jeffery Siyuan Tian","Matthieu Dagommer","Jia Guo"],"pdf_url":"https://arxiv.org/pdf/2312.10892v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.15503v5","updated":"2025-03-05T05:14:34Z","published":"2024-08-28T03:17:40Z","title":"RoboSense: Large-scale Dataset and Benchmark for Egocentric Robot\n  Perception and Navigation in Crowded and Unstructured Environments","summary":"  Reliable embodied perception from an egocentric perspective is challenging\nyet essential for autonomous navigation technology of intelligent mobile\nagents. With the growing demand of social robotics, near-field scene\nunderstanding becomes an important research topic in the areas of egocentric\nperceptual tasks related to navigation in both crowded and unstructured\nenvironments. Due to the complexity of environmental conditions and difficulty\nof surrounding obstacles owing to truncation and occlusion, the perception\ncapability under this circumstance is still inferior. To further enhance the\nintelligence of mobile robots, in this paper, we setup an egocentric\nmulti-sensor data collection platform based on 3 main types of sensors (Camera,\nLiDAR and Fisheye), which supports flexible sensor configurations to enable\ndynamic sight of view from ego-perspective, capturing either near or farther\nareas. Meanwhile, a large-scale multimodal dataset is constructed, named\nRoboSense, to facilitate egocentric robot perception. Specifically, RoboSense\ncontains more than 133K synchronized data with 1.4M 3D bounding box and IDs\nannotated in the full $360^{\\circ}$ view, forming 216K trajectories across 7.6K\ntemporal sequences. It has $270\\times$ and $18\\times$ as many annotations of\nsurrounding obstacles within near ranges as the previous datasets collected for\nautonomous driving scenarios such as KITTI and nuScenes. Moreover, we define a\nnovel matching criterion for near-field 3D perception and prediction metrics.\nBased on RoboSense, we formulate 6 popular tasks to facilitate the future\nresearch development, where the detailed analysis as well as benchmarks are\nalso provided accordingly. Data desensitization measures have been conducted\nfor privacy protection.\n","authors":["Haisheng Su","Feixiang Song","Cong Ma","Wei Wu","Junchi Yan"],"pdf_url":"https://arxiv.org/pdf/2408.15503v5.pdf","comment":"Accepted to CVPR2025"},{"id":"http://arxiv.org/abs/2503.03190v1","updated":"2025-03-05T05:13:53Z","published":"2025-03-05T05:13:53Z","title":"DSPNet: Dual-vision Scene Perception for Robust 3D Question Answering","summary":"  3D Question Answering (3D QA) requires the model to comprehensively\nunderstand its situated 3D scene described by the text, then reason about its\nsurrounding environment and answer a question under that situation. However,\nexisting methods usually rely on global scene perception from pure 3D point\nclouds and overlook the importance of rich local texture details from\nmulti-view images. Moreover, due to the inherent noise in camera poses and\ncomplex occlusions, there exists significant feature degradation and reduced\nfeature robustness problems when aligning 3D point cloud with multi-view\nimages. In this paper, we propose a Dual-vision Scene Perception Network\n(DSPNet), to comprehensively integrate multi-view and point cloud features to\nimprove robustness in 3D QA. Our Text-guided Multi-view Fusion (TGMF) module\nprioritizes image views that closely match the semantic content of the text. To\nadaptively fuse back-projected multi-view images with point cloud features, we\ndesign the Adaptive Dual-vision Perception (ADVP) module, enhancing 3D scene\ncomprehension. Additionally, our Multimodal Context-guided Reasoning (MCGR)\nmodule facilitates robust reasoning by integrating contextual information\nacross visual and linguistic modalities. Experimental results on SQA3D and\nScanQA datasets demonstrate the superiority of our DSPNet. Codes will be\navailable at https://github.com/LZ-CH/DSPNet.\n","authors":["Jingzhou Luo","Yang Liu","Weixing Chen","Zhen Li","Yaowei Wang","Guanbin Li","Liang Lin"],"pdf_url":"https://arxiv.org/pdf/2503.03190v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02745v2","updated":"2025-03-05T04:49:18Z","published":"2025-03-04T16:10:42Z","title":"ArcPro: Architectural Programs for Structured 3D Abstraction of Sparse\n  Points","summary":"  We introduce ArcPro, a novel learning framework built on architectural\nprograms to recover structured 3D abstractions from highly sparse and\nlow-quality point clouds. Specifically, we design a domain-specific language\n(DSL) to hierarchically represent building structures as a program, which can\nbe efficiently converted into a mesh. We bridge feedforward and inverse\nprocedural modeling by using a feedforward process for training data synthesis,\nallowing the network to make reverse predictions. We train an encoder-decoder\non the points-program pairs to establish a mapping from unstructured point\nclouds to architectural programs, where a 3D convolutional encoder extracts\npoint cloud features and a transformer decoder autoregressively predicts the\nprograms in a tokenized form. Inference by our method is highly efficient and\nproduces plausible and faithful 3D abstractions. Comprehensive experiments\ndemonstrate that ArcPro outperforms both traditional architectural proxy\nreconstruction and learning-based abstraction methods. We further explore its\npotential to work with multi-view image and natural language inputs.\n","authors":["Qirui Huang","Runze Zhang","Kangjun Liu","Minglun Gong","Hao Zhang","Hui Huang"],"pdf_url":"https://arxiv.org/pdf/2503.02745v2.pdf","comment":"CVPR 2025 (Patent Protected); Project page:\n  https://vcc.tech/research/2025/ArcPro"},{"id":"http://arxiv.org/abs/2410.03030v2","updated":"2025-03-05T04:37:07Z","published":"2024-10-03T22:24:54Z","title":"Dynamic Sparse Training versus Dense Training: The Unexpected Winner in\n  Image Corruption Robustness","summary":"  It is generally perceived that Dynamic Sparse Training opens the door to a\nnew era of scalability and efficiency for artificial neural networks at,\nperhaps, some costs in accuracy performance for the classification task. At the\nsame time, Dense Training is widely accepted as being the \"de facto\" approach\nto train artificial neural networks if one would like to maximize their\nrobustness against image corruption. In this paper, we question this general\npractice. Consequently, we claim that, contrary to what is commonly thought,\nthe Dynamic Sparse Training methods can consistently outperform Dense Training\nin terms of robustness accuracy, particularly if the efficiency aspect is not\nconsidered as a main objective (i.e., sparsity levels between 10% and up to\n50%), without adding (or even reducing) resource cost. We validate our claim on\ntwo types of data, images and videos, using several traditional and modern deep\nlearning architectures for computer vision and three widely studied Dynamic\nSparse Training algorithms. Our findings reveal a new yet-unknown benefit of\nDynamic Sparse Training and open new possibilities in improving deep learning\nrobustness beyond the current state of the art.\n","authors":["Boqian Wu","Qiao Xiao","Shunxin Wang","Nicola Strisciuglio","Mykola Pechenizkiy","Maurice van Keulen","Decebal Constantin Mocanu","Elena Mocanu"],"pdf_url":"https://arxiv.org/pdf/2410.03030v2.pdf","comment":"Accepted at ICLR 2025"},{"id":"http://arxiv.org/abs/2502.00931v3","updated":"2025-03-05T04:11:08Z","published":"2025-02-02T21:44:15Z","title":"VL-Nav: Real-time Vision-Language Navigation with Spatial Reasoning","summary":"  Vision-language navigation in unknown environments is crucial for mobile\nrobots. In scenarios such as household assistance and rescue, mobile robots\nneed to understand a human command, such as \"find a person wearing black\". We\npresent a novel vision-language navigation (VL-Nav) system that integrates\nefficient spatial reasoning on low-power robots. Unlike prior methods that rely\non a single image-level feature similarity to guide a robot, our method\nintegrates pixel-wise vision-language features with curiosity-driven\nexploration. This approach enables robust navigation to human-instructed\ninstances across diverse environments. We deploy VL-Nav on a four-wheel mobile\nrobot and evaluate its performance through comprehensive navigation tasks in\nboth indoor and outdoor environments, spanning different scales and semantic\ncomplexities. Remarkably, VL-Nav operates at a real-time frequency of 30 Hz\nwith a Jetson Orin NX, highlighting its ability to conduct efficient\nvision-language navigation. Results show that VL-Nav achieves an overall\nsuccess rate of 86.3%, outperforming previous methods by 44.15%.\n","authors":["Yi Du","Taimeng Fu","Zhuoqun Chen","Bowen Li","Shaoshu Su","Zhipeng Zhao","Chen Wang"],"pdf_url":"https://arxiv.org/pdf/2502.00931v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01193v3","updated":"2025-03-05T03:54:00Z","published":"2025-03-03T05:38:57Z","title":"Near-infrared Image Deblurring and Event Denoising with Synergistic\n  Neuromorphic Imaging","summary":"  The fields of imaging in the nighttime dynamic and other extremely dark\nconditions have seen impressive and transformative advancements in recent\nyears, partly driven by the rise of novel sensing approaches, e.g.,\nnear-infrared (NIR) cameras with high sensitivity and event cameras with\nminimal blur. However, inappropriate exposure ratios of near-infrared cameras\nmake them susceptible to distortion and blur. Event cameras are also highly\nsensitive to weak signals at night yet prone to interference, often generating\nsubstantial noise and significantly degrading observations and analysis.\nHerein, we develop a new framework for low-light imaging combined with NIR\nimaging and event-based techniques, named synergistic neuromorphic imaging,\nwhich can jointly achieve NIR image deblurring and event denoising. Harnessing\ncross-modal features of NIR images and visible events via spectral consistency\nand higher-order interaction, the NIR images and events are simultaneously\nfused, enhanced, and bootstrapped. Experiments on real and realistically\nsimulated sequences demonstrate the effectiveness of our method and indicate\nbetter accuracy and robustness than other methods in practical scenarios. This\nstudy gives impetus to enhance both NIR images and events, which paves the way\nfor high-fidelity low-light imaging and neuromorphic reasoning.\n","authors":["Chao Qu","Shuo Zhu","Yuhang Wang","Zongze Wu","Xiaoyu Chen","Edmund Y. Lam","Jing Han"],"pdf_url":"https://arxiv.org/pdf/2503.01193v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03148v1","updated":"2025-03-05T03:42:59Z","published":"2025-03-05T03:42:59Z","title":"Partial Convolution Meets Visual Attention","summary":"  Designing an efficient and effective neural network has remained a prominent\ntopic in computer vision research. Depthwise onvolution (DWConv) is widely used\nin efficient CNNs or ViTs, but it needs frequent memory access during\ninference, which leads to low throughput. FasterNet attempts to introduce\npartial convolution (PConv) as an alternative to DWConv but compromises the\naccuracy due to underutilized channels. To remedy this shortcoming and consider\nthe redundancy between feature map channels, we introduce a novel Partial\nvisual ATtention mechanism (PAT) that can efficiently combine PConv with visual\nattention. Our exploration indicates that the partial attention mechanism can\ncompletely replace the full attention mechanism and reduce model parameters and\nFLOPs. Our PAT can derive three types of blocks: Partial Channel-Attention\nblock (PAT_ch), Partial Spatial-Attention block (PAT_sp) and Partial\nSelf-Attention block (PAT_sf). First, PAT_ch integrates the enhanced Gaussian\nchannel attention mechanism to infuse global distribution information into the\nuntouched channels of PConv. Second, we introduce the spatial-wise attention to\nthe MLP layer to further improve model accuracy. Finally, we replace PAT_ch in\nthe last stage with the self-attention mechanism to extend the global receptive\nfield. Building upon PAT, we propose a novel hybrid network family, named\nPATNet, which achieves superior top-1 accuracy and inference speed compared to\nFasterNet on ImageNet-1K classification and excel in both detection and\nsegmentation on the COCO dataset. Particularly, our PATNet-T2 achieves 1.3%\nhigher accuracy than FasterNet-T2, while exhibiting 25% higher GPU throughput\nand 24% lower CPU latency.\n","authors":["Haiduo Huang","Fuwei Yang","Dong Li","Ji Liu","Lu Tian","Jinzhang Peng","Pengju Ren","Emad Barsoum"],"pdf_url":"https://arxiv.org/pdf/2503.03148v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2502.01303"},{"id":"http://arxiv.org/abs/2503.02689v2","updated":"2025-03-05T03:41:41Z","published":"2025-03-04T15:02:32Z","title":"STAA-SNN: Spatial-Temporal Attention Aggregator for Spiking Neural\n  Networks","summary":"  Spiking Neural Networks (SNNs) have gained significant attention due to their\nbiological plausibility and energy efficiency, making them promising\nalternatives to Artificial Neural Networks (ANNs). However, the performance gap\nbetween SNNs and ANNs remains a substantial challenge hindering the widespread\nadoption of SNNs. In this paper, we propose a Spatial-Temporal Attention\nAggregator SNN (STAA-SNN) framework, which dynamically focuses on and captures\nboth spatial and temporal dependencies. First, we introduce a spike-driven\nself-attention mechanism specifically designed for SNNs. Additionally, we\npioneeringly incorporate position encoding to integrate latent temporal\nrelationships into the incoming features. For spatial-temporal information\naggregation, we employ step attention to selectively amplify relevant features\nat different steps. Finally, we implement a time-step random dropout strategy\nto avoid local optima. As a result, STAA-SNN effectively captures both spatial\nand temporal dependencies, enabling the model to analyze complex patterns and\nmake accurate predictions. The framework demonstrates exceptional performance\nacross diverse datasets and exhibits strong generalization capabilities.\nNotably, STAA-SNN achieves state-of-the-art results on neuromorphic datasets\nCIFAR10-DVS, with remarkable performances of 97.14%, 82.05% and 70.40% on the\nstatic datasets CIFAR-10, CIFAR-100 and ImageNet, respectively. Furthermore,\nour model exhibits improved performance ranging from 0.33\\% to 2.80\\% with\nfewer time steps. The code for the model is available on GitHub.\n","authors":["Tianqing Zhang","Kairong Yu","Xian Zhong","Hongwei Wang","Qi Xu","Qiang Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.02689v2.pdf","comment":"Accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2503.03144v1","updated":"2025-03-05T03:37:41Z","published":"2025-03-05T03:37:41Z","title":"Temporal Separation with Entropy Regularization for Knowledge\n  Distillation in Spiking Neural Networks","summary":"  Spiking Neural Networks (SNNs), inspired by the human brain, offer\nsignificant computational efficiency through discrete spike-based information\ntransfer. Despite their potential to reduce inference energy consumption, a\nperformance gap persists between SNNs and Artificial Neural Networks (ANNs),\nprimarily due to current training methods and inherent model limitations. While\nrecent research has aimed to enhance SNN learning by employing knowledge\ndistillation (KD) from ANN teacher networks, traditional distillation\ntechniques often overlook the distinctive spatiotemporal properties of SNNs,\nthus failing to fully leverage their advantages. To overcome these challenge,\nwe propose a novel logit distillation method characterized by temporal\nseparation and entropy regularization. This approach improves existing SNN\ndistillation techniques by performing distillation learning on logits across\ndifferent time steps, rather than merely on aggregated output features.\nFurthermore, the integration of entropy regularization stabilizes model\noptimization and further boosts the performance. Extensive experimental results\nindicate that our method surpasses prior SNN distillation strategies, whether\nbased on logit distillation, feature distillation, or a combination of both.\nThe code will be available on GitHub.\n","authors":["Kairong Yu","Chengting Yu","Tianqing Zhang","Xiaochen Zhao","Shu Yang","Hongwei Wang","Qiang Zhang","Qi Xu"],"pdf_url":"https://arxiv.org/pdf/2503.03144v1.pdf","comment":"Accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2503.03141v1","updated":"2025-03-05T03:31:05Z","published":"2025-03-05T03:31:05Z","title":"Implicit U-KAN2.0: Dynamic, Efficient and Interpretable Medical Image\n  Segmentation","summary":"  Image segmentation is a fundamental task in both image analysis and medical\napplications. State-of-the-art methods predominantly rely on encoder-decoder\narchitectures with a U-shaped design, commonly referred to as U-Net. Recent\nadvancements integrating transformers and MLPs improve performance but still\nface key limitations, such as poor interpretability, difficulty handling\nintrinsic noise, and constrained expressiveness due to discrete layer\nstructures, often lacking a solid theoretical foundation.In this work, we\nintroduce Implicit U-KAN 2.0, a novel U-Net variant that adopts a two-phase\nencoder-decoder structure. In the SONO phase, we use a second-order neural\nordinary differential equation (NODEs), called the SONO block, for a more\nefficient, expressive, and theoretically grounded modeling approach. In the\nSONO-MultiKAN phase, we integrate the second-order NODEs and MultiKAN layer as\nthe core computational block to enhance interpretability and representation\npower. Our contributions are threefold. First, U-KAN 2.0 is an implicit deep\nneural network incorporating MultiKAN and second order NODEs, improving\ninterpretability and performance while reducing computational costs. Second, we\nprovide a theoretical analysis demonstrating that the approximation ability of\nthe MultiKAN block is independent of the input dimension. Third, we conduct\nextensive experiments on a variety of 2D and a single 3D dataset, demonstrating\nthat our model consistently outperforms existing segmentation networks.\n","authors":["Chun-Wun Cheng","Yining Zhao","Yanqi Cheng","Javier Montoya","Carola-Bibiane Schönlieb","Angelica I Aviles-Rivero"],"pdf_url":"https://arxiv.org/pdf/2503.03141v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.05272v2","updated":"2025-03-05T03:26:07Z","published":"2025-01-09T14:31:54Z","title":"Solving the Catastrophic Forgetting Problem in Generalized Category\n  Discovery","summary":"  Generalized Category Discovery (GCD) aims to identify a mix of known and\nnovel categories within unlabeled data sets, providing a more realistic setting\nfor image recognition. Essentially, GCD needs to remember existing patterns\nthoroughly to recognize novel categories. Recent state-of-the-art method SimGCD\ntransfers the knowledge from known-class data to the learning of novel classes\nthrough debiased learning. However, some patterns are catastrophically forgot\nduring adaptation and thus lead to poor performance in novel categories\nclassification. To address this issue, we propose a novel learning approach,\nLegoGCD, which is seamlessly integrated into previous methods to enhance the\ndiscrimination of novel classes while maintaining performance on previously\nencountered known classes. Specifically, we design two types of techniques\ntermed as Local Entropy Regularization (LER) and Dual-views Kullback Leibler\ndivergence constraint (DKL). The LER optimizes the distribution of potential\nknown class samples in unlabeled data, thus ensuring the preservation of\nknowledge related to known categories while learning novel classes. Meanwhile,\nDKL introduces Kullback Leibler divergence to encourage the model to produce a\nsimilar prediction distribution of two view samples from the same image. In\nthis way, it successfully avoids mismatched prediction and generates more\nreliable potential known class samples simultaneously. Extensive experiments\nvalidate that the proposed LegoGCD effectively addresses the known category\nforgetting issue across all datasets, eg, delivering a 7.74% and 2.51% accuracy\nboost on known and novel classes in CUB, respectively. Our code is available\nat: https://github.com/Cliffia123/LegoGCD.\n","authors":["Xinzi Cao","Xiawu Zheng","Guanhong Wang","Weijiang Yu","Yunhang Shen","Ke Li","Yutong Lu","Yonghong Tian"],"pdf_url":"https://arxiv.org/pdf/2501.05272v2.pdf","comment":"Accepted by CVPR 2024"},{"id":"http://arxiv.org/abs/2503.01202v3","updated":"2025-03-05T03:11:07Z","published":"2025-03-03T05:55:30Z","title":"A Multi-Sensor Fusion Approach for Rapid Orthoimage Generation in\n  Large-Scale UAV Mapping","summary":"  Rapid generation of large-scale orthoimages from Unmanned Aerial Vehicles\n(UAVs) has been a long-standing focus of research in the field of aerial\nmapping. A multi-sensor UAV system, integrating the Global Positioning System\n(GPS), Inertial Measurement Unit (IMU), 4D millimeter-wave radar and camera,\ncan provide an effective solution to this problem. In this paper, we utilize\nmulti-sensor data to overcome the limitations of conventional orthoimage\ngeneration methods in terms of temporal performance, system robustness, and\ngeographic reference accuracy. A prior-pose-optimized feature matching method\nis introduced to enhance matching speed and accuracy, reducing the number of\nrequired features and providing precise references for the Structure from\nMotion (SfM) process. The proposed method exhibits robustness in low-texture\nscenes like farmlands, where feature matching is difficult. Experiments show\nthat our approach achieves accurate feature matching orthoimage generation in a\nshort time. The proposed drone system effectively aids in farmland detection\nand management.\n","authors":["Jialei He","Zhihao Zhan","Zhituo Tu","Xiang Zhu","Jie Yuan"],"pdf_url":"https://arxiv.org/pdf/2503.01202v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.17773v3","updated":"2025-03-05T03:07:12Z","published":"2024-07-25T05:02:39Z","title":"KiVA: Kid-inspired Visual Analogies for Testing Large Multimodal Models","summary":"  This paper investigates visual analogical reasoning in large multimodal\nmodels (LMMs) compared to human adults and children. A \"visual analogy\" is an\nabstract rule inferred from one image and applied to another. While benchmarks\nexist for testing visual reasoning in LMMs, they require advanced skills and\nomit basic visual analogies that even young children can make. Inspired by\ndevelopmental psychology, we propose a new benchmark of 4,300 visual\ntransformations of everyday objects to test LMMs on visual analogical reasoning\nand compare them to children (ages three to five) and to adults. We structure\nthe evaluation into three stages: identifying what changed (e.g., color,\nnumber, etc.), how it changed (e.g., added one object), and applying the rule\nto new scenarios. Our findings show that while GPT-o1, GPT-4V, LLaVA-1.5, and\nMANTIS identify the \"what\" effectively, they struggle with quantifying the\n\"how\" and extrapolating this rule to new objects. In contrast, children and\nadults exhibit much stronger analogical reasoning at all three stages.\nAdditionally, the strongest tested model, GPT-o1, performs better in tasks\ninvolving simple surface-level visual attributes like color and size,\ncorrelating with quicker human adult response times. Conversely, more complex\ntasks such as number, rotation, and reflection, which necessitate extensive\ncognitive processing and understanding of extrinsic spatial properties in the\nphysical world, present more significant challenges. Altogether, these findings\nhighlight the limitations of training models on data that primarily consists of\n2D images and text.\n","authors":["Eunice Yiu","Maan Qraitem","Anisa Noor Majhi","Charlie Wong","Yutong Bai","Shiry Ginosar","Alison Gopnik","Kate Saenko"],"pdf_url":"https://arxiv.org/pdf/2407.17773v3.pdf","comment":"10 pages. Project website: https://ey242.github.io/kiva.github.io/.\n  Benchmark and code: https://github.com/ey242/KiVA"},{"id":"http://arxiv.org/abs/2503.03132v1","updated":"2025-03-05T03:02:59Z","published":"2025-03-05T03:02:59Z","title":"Dynamic Neural Surfaces for Elastic 4D Shape Representation and Analysis","summary":"  We propose a novel framework for the statistical analysis of genus-zero 4D\nsurfaces, i.e., 3D surfaces that deform and evolve over time. This problem is\nparticularly challenging due to the arbitrary parameterizations of these\nsurfaces and their varying deformation speeds, necessitating effective\nspatiotemporal registration. Traditionally, 4D surfaces are discretized, in\nspace and time, before computing their spatiotemporal registrations, geodesics,\nand statistics. However, this approach may result in suboptimal solutions and,\nas we demonstrate in this paper, is not necessary. In contrast, we treat 4D\nsurfaces as continuous functions in both space and time. We introduce Dynamic\nSpherical Neural Surfaces (D-SNS), an efficient smooth and continuous\nspatiotemporal representation for genus-0 4D surfaces. We then demonstrate how\nto perform core 4D shape analysis tasks such as spatiotemporal registration,\ngeodesics computation, and mean 4D shape estimation, directly on these\ncontinuous representations without upfront discretization and meshing. By\nintegrating neural representations with classical Riemannian geometry and\nstatistical shape analysis techniques, we provide the building blocks for\nenabling full functional shape analysis. We demonstrate the efficiency of the\nframework on 4D human and face datasets. The source code and additional results\nare available at https://4d-dsns.github.io/DSNS/.\n","authors":["Awais Nizamani","Hamid Laga","Guanjin Wang","Farid Boussaid","Mohammed Bennamoun","Anuj Srivastava"],"pdf_url":"https://arxiv.org/pdf/2503.03132v1.pdf","comment":"22 pages, 23 figures, conference paper"},{"id":"http://arxiv.org/abs/2412.04814v3","updated":"2025-03-05T02:43:42Z","published":"2024-12-06T07:16:14Z","title":"LiFT: Leveraging Human Feedback for Text-to-Video Model Alignment","summary":"  Recent advances in text-to-video (T2V) generative models have shown\nimpressive capabilities. However, these models are still inadequate in aligning\nsynthesized videos with human preferences (e.g., accurately reflecting text\ndescriptions), which is particularly difficult to address, as human preferences\nare subjective and challenging to formalize as objective functions. Existing\nstudies train video quality assessment models that rely on human-annotated\nratings for video evaluation but overlook the reasoning behind evaluations,\nlimiting their ability to capture nuanced human criteria. Moreover, aligning\nT2V model using video-based human feedback remains unexplored. Therefore, this\npaper proposes LiFT, the first method designed to leverage human feedback for\nT2V model alignment. Specifically, we first construct a Human Rating Annotation\ndataset, LiFT-HRA, consisting of approximately 10k human annotations, each\nincluding a score and its corresponding rationale. Based on this, we train a\nreward model LiFT-Critic to learn reward function effectively, which serves as\na proxy for human judgment, measuring the alignment between given videos and\nhuman expectations. Lastly, we leverage the learned reward function to align\nthe T2V model by maximizing the reward-weighted likelihood. As a case study, we\napply our pipeline to CogVideoX-2B, showing that the fine-tuned model\noutperforms the CogVideoX-5B across all 16 metrics, highlighting the potential\nof human feedback in improving the alignment and quality of synthesized videos.\n","authors":["Yibin Wang","Zhiyu Tan","Junyan Wang","Xiaomeng Yang","Cheng Jin","Hao Li"],"pdf_url":"https://arxiv.org/pdf/2412.04814v3.pdf","comment":"Project page: https://codegoat24.github.io/LiFT"},{"id":"http://arxiv.org/abs/2502.17039v2","updated":"2025-03-05T02:33:16Z","published":"2025-02-24T10:46:28Z","title":"LCV2I: Communication-Efficient and High-Performance Collaborative\n  Perception Framework with Low-Resolution LiDAR","summary":"  Vehicle-to-Infrastructure (V2I) collaborative perception leverages data\ncollected by infrastructure's sensors to enhance vehicle perceptual\ncapabilities. LiDAR, as a commonly used sensor in cooperative perception, is\nwidely equipped in intelligent vehicles and infrastructure. However, its\nsuperior performance comes with a correspondingly high cost. To achieve\nlow-cost V2I, reducing the cost of LiDAR is crucial. Therefore, we study\nadopting low-resolution LiDAR on the vehicle to minimize cost as much as\npossible. However, simply reducing the resolution of vehicle's LiDAR results in\nsparse point clouds, making distant small objects even more blurred.\nAdditionally, traditional communication methods have relatively low bandwidth\nutilization efficiency. These factors pose challenges for us. To balance cost\nand perceptual accuracy, we propose a new collaborative perception framework,\nnamely LCV2I. LCV2I uses data collected from cameras and low-resolution LiDAR\nas input. It also employs feature offset correction modules and regional\nfeature enhancement algorithms to improve feature representation. Finally, we\nuse regional difference map and regional score map to assess the value of\ncollaboration content, thereby improving communication bandwidth efficiency. In\nsummary, our approach achieves high perceptual performance while substantially\nreducing the demand for high-resolution sensors on the vehicle. To evaluate\nthis algorithm, we conduct 3D object detection in the real-world scenario of\nDAIR-V2X, demonstrating that the performance of LCV2I consistently surpasses\ncurrently existing algorithms.\n","authors":["Xinxin Feng","Haoran Sun","Haifeng Zheng"],"pdf_url":"https://arxiv.org/pdf/2502.17039v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.16226v4","updated":"2025-03-05T02:30:54Z","published":"2024-05-25T13:34:16Z","title":"Detecting Adversarial Data using Perturbation Forgery","summary":"  As a defense strategy against adversarial attacks, adversarial detection aims\nto identify and filter out adversarial data from the data flow based on\ndiscrepancies in distribution and noise patterns between natural and\nadversarial data. Although previous detection methods achieve high performance\nin detecting gradient-based adversarial attacks, new attacks based on\ngenerative models with imbalanced and anisotropic noise patterns evade\ndetection. Even worse, the significant inference time overhead and limited\nperformance against unseen attacks make existing techniques impractical for\nreal-world use. In this paper, we explore the proximity relationship among\nadversarial noise distributions and demonstrate the existence of an open\ncovering for these distributions. By training on the open covering of\nadversarial noise distributions, a detector with strong generalization\nperformance against various types of unseen attacks can be developed. Based on\nthis insight, we heuristically propose Perturbation Forgery, which includes\nnoise distribution perturbation, sparse mask generation, and pseudo-adversarial\ndata production, to train an adversarial detector capable of detecting any\nunseen gradient-based, generative-based, and physical adversarial attacks.\nComprehensive experiments conducted on multiple general and facial datasets,\nwith a wide spectrum of attacks, validate the strong generalization of our\nmethod.\n","authors":["Qian Wang","Chen Li","Yuchen Luo","Hefei Ling","Shijuan Huang","Ruoxi Jia","Ning Yu"],"pdf_url":"https://arxiv.org/pdf/2405.16226v4.pdf","comment":"Accepted as a conference paper at CVPR 2025"},{"id":"http://arxiv.org/abs/2503.03115v1","updated":"2025-03-05T02:24:13Z","published":"2025-03-05T02:24:13Z","title":"NTR-Gaussian: Nighttime Dynamic Thermal Reconstruction with 4D Gaussian\n  Splatting Based on Thermodynamics","summary":"  Thermal infrared imaging offers the advantage of all-weather capability,\nenabling non-intrusive measurement of an object's surface temperature.\nConsequently, thermal infrared images are employed to reconstruct 3D models\nthat accurately reflect the temperature distribution of a scene, aiding in\napplications such as building monitoring and energy management. However,\nexisting approaches predominantly focus on static 3D reconstruction for a\nsingle time period, overlooking the impact of environmental factors on thermal\nradiation and failing to predict or analyze temperature variations over time.\nTo address these challenges, we propose the NTR-Gaussian method, which treats\ntemperature as a form of thermal radiation, incorporating elements like\nconvective heat transfer and radiative heat dissipation. Our approach utilizes\nneural networks to predict thermodynamic parameters such as emissivity,\nconvective heat transfer coefficient, and heat capacity. By integrating these\npredictions, we can accurately forecast thermal temperatures at various times\nthroughout a nighttime scene. Furthermore, we introduce a dynamic dataset\nspecifically for nighttime thermal imagery. Extensive experiments and\nevaluations demonstrate that NTR-Gaussian significantly outperforms comparison\nmethods in thermal reconstruction, achieving a predicted temperature error\nwithin 1 degree Celsius.\n","authors":["Kun Yang","Yuxiang Liu","Zeyu Cui","Yu Liu","Maojun Zhang","Shen Yan","Qing Wang"],"pdf_url":"https://arxiv.org/pdf/2503.03115v1.pdf","comment":"IEEE Conference on Computer Vision and Pattern Recognition 2025"},{"id":"http://arxiv.org/abs/2503.02593v2","updated":"2025-03-05T02:11:25Z","published":"2025-03-04T13:17:17Z","title":"CMMLoc: Advancing Text-to-PointCloud Localization with\n  Cauchy-Mixture-Model Based Framework","summary":"  The goal of point cloud localization based on linguistic description is to\nidentify a 3D position using textual description in large urban environments,\nwhich has potential applications in various fields, such as determining the\nlocation for vehicle pickup or goods delivery. Ideally, for a textual\ndescription and its corresponding 3D location, the objects around the 3D\nlocation should be fully described in the text description. However, in\npractical scenarios, e.g., vehicle pickup, passengers usually describe only the\npart of the most significant and nearby surroundings instead of the entire\nenvironment. In response to this $\\textbf{partially relevant}$ challenge, we\npropose $\\textbf{CMMLoc}$, an uncertainty-aware\n$\\textbf{C}$auchy-$\\textbf{M}$ixture-$\\textbf{M}$odel ($\\textbf{CMM}$) based\nframework for text-to-point-cloud $\\textbf{Loc}$alization. To model the\nuncertain semantic relations between text and point cloud, we integrate CMM\nconstraints as a prior during the interaction between the two modalities. We\nfurther design a spatial consolidation scheme to enable adaptive aggregation of\ndifferent 3D objects with varying receptive fields. To achieve precise\nlocalization, we propose a cardinal direction integration module alongside a\nmodality pre-alignment strategy, helping capture the spatial relationships\namong objects and bringing the 3D objects closer to the text modality.\nComprehensive experiments validate that CMMLoc outperforms existing methods,\nachieving state-of-the-art results on the KITTI360Pose dataset. Codes are\navailable in this GitHub repository https://github.com/kevin301342/CMMLoc.\n","authors":["Yanlong Xu","Haoxuan Qu","Jun Liu","Wenxiao Zhang","Xun Yang"],"pdf_url":"https://arxiv.org/pdf/2503.02593v2.pdf","comment":"Accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2503.03111v1","updated":"2025-03-05T02:10:14Z","published":"2025-03-05T02:10:14Z","title":"An Improved Pure Fully Connected Neural Network for Rice Grain\n  Classification","summary":"  Rice is a staple food for a significant portion of the world's population,\nproviding essential nutrients and serving as a versatile in-gredient in a wide\nrange of culinary traditions. Recently, the use of deep learning has enabled\nautomated classification of rice, im-proving accuracy and efficiency. However,\nclassical models based on first-stage training may face difficulties in\ndistinguishing between rice varieties with similar external characteristics,\nthus leading to misclassifications. Considering the transparency and\nfeasibility of model, we selected and gradually improved pure fully connected\nneural network to achieve classification of rice grain. The dataset we used\ncontains both global and domestic rice images obtained from websites and\nlaboratories respectively. First, the training mode was changed from one-stage\ntraining to two-stage training, which significantly contributes to\ndistinguishing two similar types of rice. Secondly, the preprocessing method\nwas changed from random tilting to horizontal or vertical position cor-rection.\nAfter those two enhancements, the accuracy of our model increased notably from\n97% to 99%. In summary, two subtle methods proposed in this study can\nremarkably enhance the classification ability of deep learning models in terms\nof the classification of rice grain.\n","authors":["Wanke Xia","Ruoxin Peng","Haoqi Chu","Xinlei Zhu"],"pdf_url":"https://arxiv.org/pdf/2503.03111v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03110v1","updated":"2025-03-05T02:10:04Z","published":"2025-03-05T02:10:04Z","title":"WarmFed: Federated Learning with Warm-Start for Globalization and\n  Personalization Via Personalized Diffusion Models","summary":"  Federated Learning (FL) stands as a prominent distributed learning paradigm\namong multiple clients to achieve a unified global model without privacy\nleakage. In contrast to FL, Personalized federated learning aims at serving for\neach client in achieving persoanlized model. However, previous FL frameworks\nhave grappled with a dilemma: the choice between developing a singular global\nmodel at the server to bolster globalization or nurturing personalized model at\nthe client to accommodate personalization. Instead of making trade-offs, this\npaper commences its discourse from the pre-trained initialization, obtaining\nresilient global information and facilitating the development of both global\nand personalized models. Specifically, we propose a novel method called WarmFed\nto achieve this. WarmFed customizes Warm-start through personalized diffusion\nmodels, which are generated by local efficient fine-tunining (LoRA). Building\nupon the Warm-Start, we advance a server-side fine-tuning strategy to derive\nthe global model, and propose a dynamic self-distillation (DSD) to procure more\nresilient personalized models simultaneously. Comprehensive experiments\nunderscore the substantial gains of our approach across both global and\npersonalized models, achieved within just one-shot and five communication(s).\n","authors":["Tao Feng","Jie Zhang","Xiangjian Li","Rong Huang","Huashan Liu","Zhijie Wang"],"pdf_url":"https://arxiv.org/pdf/2503.03110v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.15050v4","updated":"2025-03-05T02:09:23Z","published":"2024-12-19T16:57:45Z","title":"Uni-Renderer: Unifying Rendering and Inverse Rendering Via Dual Stream\n  Diffusion","summary":"  Rendering and inverse rendering are pivotal tasks in both computer vision and\ngraphics. The rendering equation is the core of the two tasks, as an ideal\nconditional distribution transfer function from intrinsic properties to RGB\nimages. Despite achieving promising results of existing rendering methods, they\nmerely approximate the ideal estimation for a specific scene and come with a\nhigh computational cost. Additionally, the inverse conditional distribution\ntransfer is intractable due to the inherent ambiguity. To address these\nchallenges, we propose a data-driven method that jointly models rendering and\ninverse rendering as two conditional generation tasks within a single diffusion\nframework. Inspired by UniDiffuser, we utilize two distinct time schedules to\nmodel both tasks, and with a tailored dual streaming module, we achieve\ncross-conditioning of two pre-trained diffusion models. This unified approach,\nnamed Uni-Renderer, allows the two processes to facilitate each other through a\ncycle-consistent constrain, mitigating ambiguity by enforcing consistency\nbetween intrinsic properties and rendered images. Combined with a meticulously\nprepared dataset, our method effectively decomposition of intrinsic properties\nand demonstrates a strong capability to recognize changes during rendering. We\nwill open-source our training and inference code to the public, fostering\nfurther research and development in this area.\n","authors":["Zhifei Chen","Tianshuo Xu","Wenhang Ge","Leyi Wu","Dongyu Yan","Jing He","Luozhou Wang","Lu Zeng","Shunsi Zhang","Yingcong Chen"],"pdf_url":"https://arxiv.org/pdf/2412.15050v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01582v2","updated":"2025-03-05T02:02:19Z","published":"2025-03-03T14:23:37Z","title":"Category-level Meta-learned NeRF Priors for Efficient Object Mapping","summary":"  In 3D object mapping, category-level priors enable efficient object\nreconstruction and canonical pose estimation, requiring only a single prior per\nsemantic category (e.g., chair, book, laptop). Recently, DeepSDF has\npredominantly been used as a category-level shape prior, but it struggles to\nreconstruct sharp geometry and is computationally expensive. In contrast, NeRFs\ncapture fine details but have yet to be effectively integrated with\ncategory-level priors in a real-time multi-object mapping framework. To bridge\nthis gap, we introduce PRENOM, a Prior-based Efficient Neural Object Mapper\nthat integrates category-level priors with object-level NeRFs to enhance\nreconstruction efficiency while enabling canonical object pose estimation.\nPRENOM gets to know objects on a first-name basis by meta-learning on synthetic\nreconstruction tasks generated from open-source shape datasets. To account for\nobject category variations, it employs a multi-objective genetic algorithm to\noptimize the NeRF architecture for each category, balancing reconstruction\nquality and training time. Additionally, prior-based probabilistic ray sampling\ndirects sampling toward expected object regions, accelerating convergence and\nimproving reconstruction quality under constrained resources. Experimental\nresults on a low-end GPU highlight the ability of PRENOM to achieve\nhigh-quality reconstructions while maintaining computational feasibility.\nSpecifically, comparisons with prior-free NeRF-based approaches on a synthetic\ndataset show a 21% lower Chamfer distance, demonstrating better reconstruction\nquality. Furthermore, evaluations against other approaches using shape priors\non a noisy real-world dataset indicate a 13% improvement averaged across all\nreconstruction metrics, and comparable pose and size estimation accuracy, while\nbeing trained for 5x less time.\n","authors":["Saad Ejaz","Hriday Bavle","Laura Ribeiro","Holger Voos","Jose Luis Sanchez-Lopez"],"pdf_url":"https://arxiv.org/pdf/2503.01582v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.17859v3","updated":"2025-03-05T01:48:25Z","published":"2024-05-28T06:16:57Z","title":"Adapting Pre-Trained Vision Models for Novel Instance Detection and\n  Segmentation","summary":"  Novel Instance Detection and Segmentation (NIDS) aims at detecting and\nsegmenting novel object instances given a few examples of each instance. We\npropose a unified, simple, yet effective framework (NIDS-Net) comprising object\nproposal generation, embedding creation for both instance templates and\nproposal regions, and embedding matching for instance label assignment.\nLeveraging recent advancements in large vision methods, we utilize Grounding\nDINO and Segment Anything Model (SAM) to obtain object proposals with accurate\nbounding boxes and masks. Central to our approach is the generation of\nhigh-quality instance embeddings. We utilized foreground feature averages of\npatch embeddings from the DINOv2 ViT backbone, followed by refinement through a\nweight adapter mechanism that we introduce.\n  We show experimentally that our weight adapter can adjust the embeddings\nlocally within their feature space and effectively limit overfitting in the\nfew-shot setting. Furthermore, the weight adapter optimizes weights to enhance\nthe distinctiveness of instance embeddings during similarity computation. This\nmethodology enables a straightforward matching strategy that results in\nsignificant performance gains. Our framework surpasses current state-of-the-art\nmethods, demonstrating notable improvements in four detection datasets. In the\nsegmentation tasks on seven core datasets of the BOP challenge, our method\noutperforms the leading published RGB methods and remains competitive with the\nbest RGB-D method. We have also verified our method using real-world images\nfrom a Fetch robot and a RealSense camera. Project Page:\nhttps://irvlutd.github.io/NIDSNet/\n","authors":["Yangxiao Lu","Jishnu Jaykumar P","Yunhui Guo","Nicholas Ruozzi","Yu Xiang"],"pdf_url":"https://arxiv.org/pdf/2405.17859v3.pdf","comment":"Project Page: https://irvlutd.github.io/NIDSNet/"},{"id":"http://arxiv.org/abs/2503.03104v1","updated":"2025-03-05T01:41:59Z","published":"2025-03-05T01:41:59Z","title":"RVAFM: Re-parameterizing Vertical Attention Fusion Module for\n  Handwritten Paragraph Text Recognition","summary":"  Handwritten Paragraph Text Recognition (HPTR) is a challenging task in\nComputer Vision, requiring the transformation of a paragraph text image, rich\nin handwritten text, into text encoding sequences. One of the most advanced\nmodels for this task is Vertical Attention Network (VAN), which utilizes a\nVertical Attention Module (VAM) to implicitly segment paragraph text images\ninto text lines, thereby reducing the difficulty of the recognition task.\nHowever, from a network structure perspective, VAM is a single-branch module,\nwhich is less effective in learning compared to multi-branch modules. In this\npaper, we propose a new module, named Re-parameterizing Vertical Attention\nFusion Module (RVAFM), which incorporates structural re-parameterization\ntechniques. RVAFM decouples the structure of the module during training and\ninference stages. During training, it uses a multi-branch structure for more\neffective learning, and during inference, it uses a single-branch structure for\nfaster processing. The features learned by the multi-branch structure are fused\ninto the single-branch structure through a special fusion method named\nRe-parameterization Fusion (RF) without any loss of information. As a result,\nwe achieve a Character Error Rate (CER) of 4.44% and a Word Error Rate (WER) of\n14.37% on the IAM paragraph-level test set. Additionally, the inference speed\nis slightly faster than VAN.\n","authors":["Jinhui Zheng","Zhiquan Liu","Yain-Whar Si","Jianqing Li","Xinyuan Zhang","Xiaofan Li","Haozhi Huang","Xueyuan Gong"],"pdf_url":"https://arxiv.org/pdf/2503.03104v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.13524v3","updated":"2025-03-05T01:21:38Z","published":"2025-02-19T08:21:59Z","title":"MobileViM: A Light-weight and Dimension-independent Vision Mamba for 3D\n  Medical Image Analysis","summary":"  Efficient evaluation of three-dimensional (3D) medical images is crucial for\ndiagnostic and therapeutic practices in healthcare. Recent years have seen a\nsubstantial uptake in applying deep learning and computer vision to analyse and\ninterpret medical images. Traditional approaches, such as convolutional neural\nnetworks (CNNs) and vision transformers (ViTs), face significant computational\nchallenges, prompting the need for architectural advancements. Recent efforts\nhave led to the introduction of novel architectures like the ``Mamba'' model as\nalternative solutions to traditional CNNs or ViTs. The Mamba model excels in\nthe linear processing of one-dimensional data with low computational demands.\nHowever, Mamba's potential for 3D medical image analysis remains underexplored\nand could face significant computational challenges as the dimension increases.\nThis manuscript presents MobileViM, a streamlined architecture for efficient\nsegmentation of 3D medical images. In the MobileViM network, we invent a new\ndimension-independent mechanism and a dual-direction traversing approach to\nincorporate with a vision-Mamba-based framework. MobileViM also features a\ncross-scale bridging technique to improve efficiency and accuracy across\nvarious medical imaging modalities. With these enhancements, MobileViM achieves\nsegmentation speeds exceeding 90 frames per second (FPS) on a single graphics\nprocessing unit (i.e., NVIDIA RTX 4090). This performance is over 24 FPS faster\nthan the state-of-the-art deep learning models for processing 3D images with\nthe same computational resources. In addition, experimental evaluations\ndemonstrate that MobileViM delivers superior performance, with Dice similarity\nscores reaching 92.72%, 86.69%, 80.46%, and 77.43% for PENGWIN, BraTS2024,\nATLAS, and Toothfairy2 datasets, respectively, which significantly surpasses\nexisting models.\n","authors":["Wei Dai","Jun Liu"],"pdf_url":"https://arxiv.org/pdf/2502.13524v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.09795v2","updated":"2025-03-05T01:09:24Z","published":"2025-02-13T22:10:21Z","title":"Vision-based Geo-Localization of Future Mars Rotorcraft in Challenging\n  Illumination Conditions","summary":"  Planetary exploration using aerial assets has the potential for unprecedented\nscientific discoveries on Mars. While NASA's Mars helicopter Ingenuity proved\nflight in Martian atmosphere is possible, future Mars rotocrafts will require\nadvanced navigation capabilities for long-range flights. One such critical\ncapability is Map-based Localization (MbL) which registers an onboard image to\na reference map during flight in order to mitigate cumulative drift from visual\nodometry. However, significant illumination differences between rotocraft\nobservations and a reference map prove challenging for traditional MbL systems,\nrestricting the operational window of the vehicle. In this work, we investigate\na new MbL system and propose Geo-LoFTR, a geometry-aided deep learning model\nfor image registration that is more robust under large illumination differences\nthan prior models. The system is supported by a custom simulation framework\nthat uses real orbital maps to produce large amounts of realistic images of the\nMartian terrain. Comprehensive evaluations show that our proposed system\noutperforms prior MbL efforts in terms of localization accuracy under\nsignificant lighting and scale variations. Furthermore, we demonstrate the\nvalidity of our approach across a simulated Martian day.\n","authors":["Dario Pisanti","Robert Hewitt","Roland Brockers","Georgios Georgakis"],"pdf_url":"https://arxiv.org/pdf/2502.09795v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03088v1","updated":"2025-03-05T01:04:45Z","published":"2025-03-05T01:04:45Z","title":"AHCPTQ: Accurate and Hardware-Compatible Post-Training Quantization for\n  Segment Anything Model","summary":"  The Segment Anything Model (SAM) has demonstrated strong versatility across\nvarious visual tasks. However, its large storage requirements and high\ncomputational cost pose challenges for practical deployment. Post-training\nquantization (PTQ) has emerged as an effective strategy for efficient\ndeployment, but we identify two key challenges in SAM that hinder the\neffectiveness of existing PTQ methods: the heavy-tailed and skewed distribution\nof post-GELU activations, and significant inter-channel variation in linear\nprojection activations. To address these challenges, we propose AHCPTQ, an\naccurate and hardware-efficient PTQ method for SAM. AHCPTQ introduces\nhardware-compatible Hybrid Log-Uniform Quantization (HLUQ) to manage post-GELU\nactivations, employing log2 quantization for dense small values and uniform\nquantization for sparse large values to enhance quantization resolution.\nAdditionally, AHCPTQ incorporates Channel-Aware Grouping (CAG) to mitigate\ninter-channel variation by progressively clustering activation channels with\nsimilar distributions, enabling them to share quantization parameters and\nimproving hardware efficiency. The combination of HLUQ and CAG not only\nenhances quantization effectiveness but also ensures compatibility with\nefficient hardware execution. For instance, under the W4A4 configuration on the\nSAM-L model, AHCPTQ achieves 36.6% mAP on instance segmentation with the DINO\ndetector, while achieving a 7.89x speedup and 8.64x energy efficiency over its\nfloating-point counterpart in FPGA implementation.\n","authors":["Wenlun Zhang","Shimpei Ando","Kentaro Yoshioka"],"pdf_url":"https://arxiv.org/pdf/2503.03088v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01962v2","updated":"2025-03-05T00:41:20Z","published":"2024-10-02T19:10:23Z","title":"LS-HAR: Language Supervised Human Action Recognition with Salient\n  Fusion, Construction Sites as a Use-Case","summary":"  Detecting human actions is a crucial task for autonomous robots and vehicles,\noften requiring the integration of various data modalities for improved\naccuracy. In this study, we introduce a novel approach to Human Action\nRecognition (HAR) using language supervision named LS-HAR based on skeleton and\nvisual cues. Our method leverages a language model to guide the feature\nextraction process in the skeleton encoder. Specifically, we employ learnable\nprompts for the language model conditioned on the skeleton modality to optimize\nfeature representation. Furthermore, we propose a fusion mechanism that\ncombines dual-modality features using a salient fusion module, incorporating\nattention and transformer mechanisms to address the modalities' high\ndimensionality. This fusion process prioritizes informative video frames and\nbody joints, enhancing the recognition accuracy of human actions. Additionally,\nwe introduce a new dataset tailored for real-world robotic applications in\nconstruction sites, featuring visual, skeleton, and depth data modalities,\nnamed VolvoConstAct. This dataset serves to facilitate the training and\nevaluation of machine learning models to instruct autonomous construction\nmachines for performing necessary tasks in real-world construction sites. To\nevaluate our approach, we conduct experiments on our dataset as well as three\nwidely used public datasets: NTU-RGB+D, NTU-RGB+D 120, and NW-UCLA. Results\nreveal that our proposed method achieves promising performance across all\ndatasets, demonstrating its robustness and potential for various applications.\nThe code, dataset, and demonstration of real-machine experiments are available\nat: https://mmahdavian.github.io/ls_har/\n","authors":["Mohammad Mahdavian","Mohammad Loni","Ted Samuelsson","Mo Chen"],"pdf_url":"https://arxiv.org/pdf/2410.01962v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.17457v3","updated":"2025-03-05T00:32:49Z","published":"2024-07-24T17:50:00Z","title":"CSCPR: Cross-Source-Context Indoor RGB-D Place Recognition","summary":"  We extend our previous work, PoCo, and present a new algorithm,\nCross-Source-Context Place Recognition (CSCPR), for RGB-D indoor place\nrecognition that integrates global retrieval and reranking into an end-to-end\nmodel and keeps the consistency of using Context-of-Clusters (CoCs) for feature\nprocessing. Unlike prior approaches that primarily focus on the RGB domain for\nplace recognition reranking, CSCPR is designed to handle the RGB-D data. We\napply the CoCs to handle cross-sourced and cross-scaled RGB-D point clouds and\nintroduce two novel modules for reranking: the Self-Context Cluster (SCC) and\nthe Cross Source Context Cluster (CSCC), which enhance feature representation\nand match query-database pairs based on local features, respectively. We also\nrelease two new datasets, ScanNetIPR and ARKitIPR. Our experiments demonstrate\nthat CSCPR significantly outperforms state-of-the-art models on these datasets\nby at least 29.27% in Recall@1 on the ScanNet-PR dataset and 43.24% in the new\ndatasets. Code and datasets will be released.\n","authors":["Jing Liang","Zhuo Deng","Zheming Zhou","Min Sun","Omid Ghasemalizadeh","Cheng-Hao Kuo","Arnie Sen","Dinesh Manocha"],"pdf_url":"https://arxiv.org/pdf/2407.17457v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03074v1","updated":"2025-03-05T00:27:32Z","published":"2025-03-05T00:27:32Z","title":"BEVDriver: Leveraging BEV Maps in LLMs for Robust Closed-Loop Driving","summary":"  Autonomous driving has the potential to set the stage for more efficient\nfuture mobility, requiring the research domain to establish trust through safe,\nreliable and transparent driving. Large Language Models (LLMs) possess\nreasoning capabilities and natural language understanding, presenting the\npotential to serve as generalized decision-makers for ego-motion planning that\ncan interact with humans and navigate environments designed for human drivers.\nWhile this research avenue is promising, current autonomous driving approaches\nare challenged by combining 3D spatial grounding and the reasoning and language\ncapabilities of LLMs. We introduce BEVDriver, an LLM-based model for end-to-end\nclosed-loop driving in CARLA that utilizes latent BEV features as perception\ninput. BEVDriver includes a BEV encoder to efficiently process multi-view\nimages and 3D LiDAR point clouds. Within a common latent space, the BEV\nfeatures are propagated through a Q-Former to align with natural language\ninstructions and passed to the LLM that predicts and plans precise future\ntrajectories while considering navigation instructions and critical scenarios.\nOn the LangAuto benchmark, our model reaches up to 18.9% higher performance on\nthe Driving Score compared to SoTA methods.\n","authors":["Katharina Winter","Mark Azer","Fabian B. Flohr"],"pdf_url":"https://arxiv.org/pdf/2503.03074v1.pdf","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2503.03068v1","updated":"2025-03-05T00:16:09Z","published":"2025-03-05T00:16:09Z","title":"Multi-View Depth Consistent Image Generation Using Generative AI Models:\n  Application on Architectural Design of University Buildings","summary":"  In the early stages of architectural design, shoebox models are typically\nused as a simplified representation of building structures but require\nextensive operations to transform them into detailed designs. Generative\nartificial intelligence (AI) provides a promising solution to automate this\ntransformation, but ensuring multi-view consistency remains a significant\nchallenge. To solve this issue, we propose a novel three-stage consistent image\ngeneration framework using generative AI models to generate architectural\ndesigns from shoebox model representations. The proposed method enhances\nstate-of-the-art image generation diffusion models to generate multi-view\nconsistent architectural images. We employ ControlNet as the backbone and\noptimize it to accommodate multi-view inputs of architectural shoebox models\ncaptured from predefined perspectives. To ensure stylistic and structural\nconsistency across multi-view images, we propose an image space loss module\nthat incorporates style loss, structural loss and angle alignment loss. We then\nuse depth estimation method to extract depth maps from the generated multi-view\nimages. Finally, we use the paired data of the architectural images and depth\nmaps as inputs to improve the multi-view consistency via the depth-aware 3D\nattention module. Experimental results demonstrate that the proposed framework\ncan generate multi-view architectural images with consistent style and\nstructural coherence from shoebox model inputs.\n","authors":["Xusheng Du","Ruihan Gui","Zhengyang Wang","Ye Zhang","Haoran Xie"],"pdf_url":"https://arxiv.org/pdf/2503.03068v1.pdf","comment":"10 pages, 7 figures, in Proceedings of CAADRIA2025"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2503.01776v2","updated":"2025-03-05T17:51:09Z","published":"2025-03-03T17:59:48Z","title":"Beyond Matryoshka: Revisiting Sparse Coding for Adaptive Representation","summary":"  Many large-scale systems rely on high-quality deep representations\n(embeddings) to facilitate tasks like retrieval, search, and generative\nmodeling. Matryoshka Representation Learning (MRL) recently emerged as a\nsolution for adaptive embedding lengths, but it requires full model retraining\nand suffers from noticeable performance degradations at short lengths. In this\npaper, we show that sparse coding offers a compelling alternative for achieving\nadaptive representation with minimal overhead and higher fidelity. We propose\nContrastive Sparse Representation (CSR), a method that sparsifies pre-trained\nembeddings into a high-dimensional but selectively activated feature space. By\nleveraging lightweight autoencoding and task-aware contrastive objectives, CSR\npreserves semantic quality while allowing flexible, cost-effective inference at\ndifferent sparsity levels. Extensive experiments on image, text, and multimodal\nbenchmarks demonstrate that CSR consistently outperforms MRL in terms of both\naccuracy and retrieval speed-often by large margins-while also cutting training\ntime to a fraction of that required by MRL. Our results establish sparse coding\nas a powerful paradigm for adaptive representation learning in real-world\napplications where efficiency and fidelity are both paramount. Code is\navailable at https://github.com/neilwen987/CSR_Adaptive_Rep\n","authors":["Tiansheng Wen","Yifei Wang","Zequn Zeng","Zhong Peng","Yudi Su","Xinyang Liu","Bo Chen","Hongwei Liu","Stefanie Jegelka","Chenyu You"],"pdf_url":"https://arxiv.org/pdf/2503.01776v2.pdf","comment":"A novel sparse coding framework designed for learning adaptive\n  representation"},{"id":"http://arxiv.org/abs/2503.03687v1","updated":"2025-03-05T17:28:16Z","published":"2025-03-05T17:28:16Z","title":"Addressing Overprescribing Challenges: Fine-Tuning Large Language Models\n  for Medication Recommendation Tasks","summary":"  Medication recommendation systems have garnered attention within healthcare\nfor their potential to deliver personalized and efficacious drug combinations\nbased on patient's clinical data. However, existing methodologies encounter\nchallenges in adapting to diverse Electronic Health Records (EHR) systems and\neffectively utilizing unstructured data, resulting in limited generalization\ncapabilities and suboptimal performance. Recently, interest is growing in\nharnessing Large Language Models (LLMs) in the medical domain to support\nhealthcare professionals and enhance patient care. Despite the emergence of\nmedical LLMs and their promising results in tasks like medical question\nanswering, their practical applicability in clinical settings, particularly in\nmedication recommendation, often remains underexplored.\n  In this study, we evaluate both general-purpose and medical-specific LLMs for\nmedication recommendation tasks. Our findings reveal that LLMs frequently\nencounter the challenge of overprescribing, leading to heightened clinical\nrisks and diminished medication recommendation accuracy. To address this issue,\nwe propose Language-Assisted Medication Recommendation (LAMO), which employs a\nparameter-efficient fine-tuning approach to tailor open-source LLMs for optimal\nperformance in medication recommendation scenarios. LAMO leverages the wealth\nof clinical information within clinical notes, a resource often underutilized\nin traditional methodologies. As a result of our approach, LAMO outperforms\nprevious state-of-the-art methods by over 10% in internal validation accuracy.\nFurthermore, temporal and external validations demonstrate LAMO's robust\ngeneralization capabilities across various temporal and hospital contexts.\nAdditionally, an out-of-distribution medication recommendation experiment\ndemonstrates LAMO's remarkable accuracy even with medications outside the\ntraining data.\n","authors":["Zihao Zhao","Chenxiao Fan","Chongming Gao","Fuli Feng","Xiangnan He"],"pdf_url":"https://arxiv.org/pdf/2503.03687v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03606v1","updated":"2025-03-05T15:42:37Z","published":"2025-03-05T15:42:37Z","title":"Decoupled Recommender Systems: Exploring Alternative Recommender\n  Ecosystem Designs","summary":"  Recommender ecosystems are an emerging subject of research. Such research\nexamines how the characteristics of algorithms, recommendation consumers, and\nitem providers influence system dynamics and long-term outcomes. One\narchitectural possibility that has not yet been widely explored in this line of\nresearch is the consequences of a configuration in which recommendation\nalgorithms are decoupled from the platforms they serve. This is sometimes\ncalled \"the friendly neighborhood algorithm store\" or \"middleware\" model. We\nare particularly interested in how such architectures might offer a range of\ndifferent distributions of utility across consumers, providers, and\nrecommendation platforms. In this paper, we create a model of a recommendation\necosystem that incorporates algorithm choice and examine the outcomes of such a\ndesign.\n","authors":["Anas Buhayh","Elizabeth McKinnie","Robin Burke"],"pdf_url":"https://arxiv.org/pdf/2503.03606v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03524v1","updated":"2025-03-05T14:08:53Z","published":"2025-03-05T14:08:53Z","title":"Intrinsic and Extrinsic Factor Disentanglement for Recommendation in\n  Various Context Scenarios","summary":"  In recommender systems, the patterns of user behaviors (e.g., purchase,\nclick) may vary greatly in different contexts (e.g., time and location). This\nis because user behavior is jointly determined by two types of factors:\nintrinsic factors, which reflect consistent user preference, and extrinsic\nfactors, which reflect external incentives that may vary in different contexts.\nDifferentiating between intrinsic and extrinsic factors helps learn user\nbehaviors better. However, existing studies have only considered\ndifferentiating them from a single, pre-defined context (e.g., time or\nlocation), ignoring the fact that a user's extrinsic factors may be influenced\nby the interplay of various contexts at the same time. In this paper, we\npropose the Intrinsic-Extrinsic Disentangled Recommendation (IEDR) model, a\ngeneric framework that differentiates intrinsic from extrinsic factors\nconsidering various contexts simultaneously, enabling more accurate\ndifferentiation of factors and hence the improvement of recommendation\naccuracy. IEDR contains a context-invariant contrastive learning component to\ncapture intrinsic factors, and a disentanglement component to extract extrinsic\nfactors under the interplay of various contexts. The two components work\ntogether to achieve effective factor learning. Extensive experiments on\nreal-world datasets demonstrate IEDR's effectiveness in learning disentangled\nfactors and significantly improving recommendation accuracy by up to 4% in\nNDCG.\n","authors":["Yixin Su","Wei Jiang","Fangquan Lin","Cheng Yang","Sarah M. Erfani","Junhao Gan","Yunxiang Zhao","Ruixuan Li","Rui Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.03524v1.pdf","comment":"32 pages, 13 figures, 11 tables. Accepted by Transactions of\n  Information Systems"},{"id":"http://arxiv.org/abs/2410.23841v2","updated":"2025-03-05T12:10:57Z","published":"2024-10-31T11:47:21Z","title":"Beyond Content Relevance: Evaluating Instruction Following in Retrieval\n  Models","summary":"  Instruction-following capabilities in LLMs have progressed significantly,\nenabling more complex user interactions through detailed prompts. However,\nretrieval systems have not matched these advances, most of them still relies on\ntraditional lexical and semantic matching techniques that fail to fully capture\nuser intent. Recent efforts have introduced instruction-aware retrieval models,\nbut these primarily focus on intrinsic content relevance, which neglects the\nimportance of customized preferences for broader document-level attributes.\nThis study evaluates the instruction-following capabilities of various\nretrieval models beyond content relevance, including LLM-based dense retrieval\nand reranking models. We develop InfoSearch, a novel retrieval evaluation\nbenchmark spanning six document-level attributes: Audience, Keyword, Format,\nLanguage, Length, and Source, and introduce novel metrics -- Strict Instruction\nCompliance Ratio (SICR) and Weighted Instruction Sensitivity Evaluation (WISE)\nto accurately assess the models' responsiveness to instructions. Our findings\nindicate that although fine-tuning models on instruction-aware retrieval\ndatasets and increasing model size enhance performance, most models still fall\nshort of instruction compliance.\n","authors":["Jianqun Zhou","Yuanlei Zheng","Wei Chen","Qianqian Zheng","Hui Su","Wei Zhang","Rui Meng","Xiaoyu Shen"],"pdf_url":"https://arxiv.org/pdf/2410.23841v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.09155v2","updated":"2025-03-05T07:48:05Z","published":"2025-02-13T10:36:17Z","title":"Use of Air Quality Sensor Network Data for Real-time Pollution-Aware POI\n  Suggestion","summary":"  This demo paper introduces AirSense-R, a privacy-preserving mobile\napplication that delivers real-time, pollution-aware recommendations for urban\npoints of interest (POIs). By merging live air quality data from AirSENCE\nsensor networks in Bari (Italy) and Cork (Ireland) with user preferences, the\nsystem enables health-conscious decision-making. It employs collaborative\nfiltering for personalization, federated learning for privacy, and a prediction\nengine to detect anomalies and interpolate sparse sensor data. The proposed\nsolution adapts dynamically to urban air quality while safeguarding user\nprivacy. The code and demonstration video are available at\nhttps://github.com/AirtownApp/Airtown-Application.git.\n","authors":["Giuseppe Fasano","Yashar Deldjoo","Tommaso di Noia","Bianca Lau","Sina Adham-Khiabani","Eric Morris","Xia Liu","Ganga Chinna Rao Devarapu","Liam O'Faolain"],"pdf_url":"https://arxiv.org/pdf/2502.09155v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01711v3","updated":"2025-03-05T05:52:00Z","published":"2025-03-03T16:24:36Z","title":"MAPS: Motivation-Aware Personalized Search via LLM-Driven Consultation\n  Alignment","summary":"  Personalized product search aims to retrieve and rank items that match users'\npreferences and search intent. Despite their effectiveness, existing approaches\ntypically assume that users' query fully captures their real motivation.\nHowever, our analysis of a real-world e-commerce platform reveals that users\noften engage in relevant consultations before searching, indicating they refine\nintents through consultations based on motivation and need. The implied\nmotivation in consultations is a key enhancing factor for personalized search.\nThis unexplored area comes with new challenges including aligning contextual\nmotivations with concise queries, bridging the category-text gap, and filtering\nnoise within sequence history. To address these, we propose a Motivation-Aware\nPersonalized Search (MAPS) method. It embeds queries and consultations into a\nunified semantic space via LLMs, utilizes a Mixture of Attention Experts (MoAE)\nto prioritize critical semantics, and introduces dual alignment: (1)\ncontrastive learning aligns consultations, reviews, and product features; (2)\nbidirectional attention integrates motivation-aware embeddings with user\npreferences. Extensive experiments on real and synthetic data show MAPS\noutperforms existing methods in both retrieval and ranking tasks.\n","authors":["Weicong Qin","Yi Xu","Weijie Yu","Chenglei Shen","Ming He","Jianping Fan","Xiao Zhang","Jun Xu"],"pdf_url":"https://arxiv.org/pdf/2503.01711v3.pdf","comment":"added project repository & dataset URL"},{"id":"http://arxiv.org/abs/2503.03165v1","updated":"2025-03-05T04:16:36Z","published":"2025-03-05T04:16:36Z","title":"A Predict-Then-Optimize Customer Allocation Framework for Online Fund\n  Recommendation","summary":"  With the rapid growth of online investment platforms, funds can be\ndistributed to individual customers online. The central issue is to match funds\nwith potential customers under constraints. Most mainstream platforms adopt the\nrecommendation formulation to tackle the problem. However, the traditional\nrecommendation regime has its inherent drawbacks when applying the\nfund-matching problem with multiple constraints. In this paper, we model the\nfund matching under the allocation formulation. We design PTOFA, a\nPredict-Then-Optimize Fund Allocation framework. This data-driven framework\nconsists of two stages, i.e., prediction and optimization, which aim to predict\nexpected revenue based on customer behavior and optimize the impression\nallocation to achieve the maximum revenue under the necessary constraints,\nrespectively. Extensive experiments on real-world datasets from an industrial\nonline investment platform validate the effectiveness and efficiency of our\nsolution. Additionally, the online A/B tests demonstrate PTOFA's effectiveness\nin the real-world fund recommendation scenario.\n","authors":["Xing Tang","Yunpeng Weng","Fuyuan Lyu","Dugang Liu","Xiuqiang He"],"pdf_url":"https://arxiv.org/pdf/2503.03165v1.pdf","comment":"Accepted by DASFAA 2025"},{"id":"http://arxiv.org/abs/2503.02589v2","updated":"2025-03-05T03:28:29Z","published":"2025-03-04T13:12:39Z","title":"MCiteBench: A Benchmark for Multimodal Citation Text Generation in MLLMs","summary":"  Multimodal Large Language Models (MLLMs) have advanced in integrating diverse\nmodalities but frequently suffer from hallucination. A promising solution to\nmitigate this issue is to generate text with citations, providing a transparent\nchain for verification. However, existing work primarily focuses on generating\ncitations for text-only content, overlooking the challenges and opportunities\nof multimodal contexts. To address this gap, we introduce MCiteBench, the first\nbenchmark designed to evaluate and analyze the multimodal citation text\ngeneration ability of MLLMs. Our benchmark comprises data derived from academic\npapers and review-rebuttal interactions, featuring diverse information sources\nand multimodal content. We comprehensively evaluate models from multiple\ndimensions, including citation quality, source reliability, and answer\naccuracy. Through extensive experiments, we observe that MLLMs struggle with\nmultimodal citation text generation. We also conduct deep analyses of models'\nperformance, revealing that the bottleneck lies in attributing the correct\nsources rather than understanding the multimodal content.\n","authors":["Caiyu Hu","Yikai Zhang","Tinghui Zhu","Yiwei Ye","Yanghua Xiao"],"pdf_url":"https://arxiv.org/pdf/2503.02589v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02604v2","updated":"2025-03-05T02:48:49Z","published":"2024-10-03T15:45:15Z","title":"Long-Sequence Recommendation Models Need Decoupled Embeddings","summary":"  Lifelong user behavior sequences are crucial for capturing user interests and\npredicting user responses in modern recommendation systems. A two-stage\nparadigm is typically adopted to handle these long sequences: a subset of\nrelevant behaviors is first searched from the original long sequences via an\nattention mechanism in the first stage and then aggregated with the target item\nto construct a discriminative representation for prediction in the second\nstage. In this work, we identify and characterize, for the first time, a\nneglected deficiency in existing long-sequence recommendation models: a single\nset of embeddings struggles with learning both attention and representation,\nleading to interference between these two processes. Initial attempts to\naddress this issue with some common methods (e.g., linear projections -- a\ntechnique borrowed from language processing) proved ineffective, shedding light\non the unique challenges of recommendation models. To overcome this, we propose\nthe Decoupled Attention and Representation Embeddings (DARE) model, where two\ndistinct embedding tables are initialized and learned separately to fully\ndecouple attention and representation. Extensive experiments and analysis\ndemonstrate that DARE provides more accurate searches of correlated behaviors\nand outperforms baselines with AUC gains up to 0.9% on public datasets and\nnotable improvements on Tencent's advertising platform. Furthermore, decoupling\nembedding spaces allows us to reduce the attention embedding dimension and\naccelerate the search procedure by 50% without significant performance impact,\nenabling more efficient, high-performance online serving. Code in PyTorch for\nexperiments, including model analysis, is available at\nhttps://github.com/thuml/DARE.\n","authors":["Ningya Feng","Junwei Pan","Jialong Wu","Baixu Chen","Ximei Wang","Qian Li","Xian Hu","Jie Jiang","Mingsheng Long"],"pdf_url":"https://arxiv.org/pdf/2410.02604v2.pdf","comment":"ICLR 2025. First three authors contributed equally. Code is available\n  at https://github.com/thuml/DARE"},{"id":"http://arxiv.org/abs/2503.02603v2","updated":"2025-03-05T02:13:38Z","published":"2025-03-04T13:21:47Z","title":"OkraLong: A Flexible Retrieval-Augmented Framework for Long-Text Query\n  Processing","summary":"  Large Language Models (LLMs) encounter challenges in efficiently processing\nlong-text queries, as seen in applications like enterprise document analysis\nand financial report comprehension. While conventional solutions employ\nlong-context processing or Retrieval-Augmented Generation (RAG), they suffer\nfrom prohibitive input expenses or incomplete information. Recent advancements\nadopt context compression and dynamic retrieval loops, but still sacrifice\ncritical details or incur iterative costs. To address these limitations, we\npropose OkraLong, a novel framework that flexibly optimizes the entire\nprocessing workflow. Unlike prior static or coarse-grained adaptive strategies,\nOkraLong adopts fine-grained orchestration through three synergistic\ncomponents: analyzer, organizer and executor. The analyzer characterizes the\ntask states, which guide the organizer in dynamically scheduling the workflow.\nThe executor carries out the execution and generates the final answer.\nExperimental results demonstrate that OkraLong not only enhances answer\naccuracy but also achieves cost-effectiveness across a variety of datasets.\n","authors":["Yulong Hui","Yihao Liu","Yao Lu","Huanchen Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.02603v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.11699v2","updated":"2025-03-05T23:46:26Z","published":"2024-09-18T04:43:41Z","title":"FLARE: Fusing Language Models and Collaborative Architectures for\n  Recommender Enhancement","summary":"  Recent proposals in recommender systems represent items with their textual\ndescription, using a large language model. They show better results on standard\nbenchmarks compared to an item ID-only model, such as Bert4Rec. In this work,\nwe revisit the often-used Bert4Rec baseline and show that with further tuning,\nBert4Rec significantly outperforms previously reported numbers, and in some\ndatasets, is competitive with state-of-the-art models.\n  With revised baselines for item ID-only models, this paper also establishes\nnew competitive results for architectures that combine IDs and textual\ndescriptions. We demonstrate this with Flare (Fusing Language models and\ncollaborative Architectures for Recommender Enhancement). Flare is a novel\nhybrid sequence recommender that integrates a language model with a\ncollaborative filtering model using a Perceiver network.\n  Prior studies focus evaluation on datasets with limited-corpus size, but many\ncommercially-applicable recommender systems common on the web must handle\nlarger corpora. We evaluate Flare on a more realistic dataset with a\nsignificantly larger item vocabulary, introducing new baselines for this\nsetting. This paper also showcases Flare's inherent ability to support\ncritiquing, enabling users to provide feedback and refine recommendations. We\nleverage critiquing as an evaluation method to assess the model's language\nunderstanding and its transferability to the recommendation task.\n","authors":["Liam Hebert","Marialena Kyriakidi","Hubert Pham","Krishna Sayana","James Pine","Sukhdeep Sodhi","Ambarish Jash"],"pdf_url":"https://arxiv.org/pdf/2409.11699v2.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2503.03750v1","updated":"2025-03-05T18:59:23Z","published":"2025-03-05T18:59:23Z","title":"The MASK Benchmark: Disentangling Honesty From Accuracy in AI Systems","summary":"  As large language models (LLMs) become more capable and agentic, the\nrequirement for trust in their outputs grows significantly, yet at the same\ntime concerns have been mounting that models may learn to lie in pursuit of\ntheir goals. To address these concerns, a body of work has emerged around the\nnotion of \"honesty\" in LLMs, along with interventions aimed at mitigating\ndeceptive behaviors. However, evaluations of honesty are currently highly\nlimited, with no benchmark combining large scale and applicability to all\nmodels. Moreover, many benchmarks claiming to measure honesty in fact simply\nmeasure accuracy--the correctness of a model's beliefs--in disguise. In this\nwork, we introduce a large-scale human-collected dataset for measuring honesty\ndirectly, allowing us to disentangle accuracy from honesty for the first time.\nAcross a diverse set of LLMs, we find that while larger models obtain higher\naccuracy on our benchmark, they do not become more honest. Surprisingly, while\nmost frontier LLMs obtain high scores on truthfulness benchmarks, we find a\nsubstantial propensity in frontier LLMs to lie when pressured to do so,\nresulting in low honesty scores on our benchmark. We find that simple methods,\nsuch as representation engineering interventions, can improve honesty. These\nresults underscore the growing need for robust evaluations and effective\ninterventions to ensure LLMs remain trustworthy.\n","authors":["Richard Ren","Arunim Agarwal","Mantas Mazeika","Cristina Menghini","Robert Vacareanu","Brad Kenstler","Mick Yang","Isabelle Barrass","Alice Gatti","Xuwang Yin","Eduardo Trevino","Matias Geralnik","Adam Khoja","Dean Lee","Summer Yue","Dan Hendrycks"],"pdf_url":"https://arxiv.org/pdf/2503.03750v1.pdf","comment":"Website: https://www.mask-benchmark.ai"},{"id":"http://arxiv.org/abs/2503.01048v3","updated":"2025-03-05T18:59:19Z","published":"2025-03-02T22:40:10Z","title":"Personalize Your LLM: Fake it then Align it","summary":"  Personalizing large language models (LLMs) is essential for delivering\ntailored interactions that improve user experience. Many existing\npersonalization methods require fine-tuning LLMs for each user, rendering them\nprohibitively expensive for widespread adoption. Although retrieval-based\napproaches offer a more compute-efficient alternative, they still depend on\nlarge, high-quality datasets that are not consistently available for all users.\nTo address this challenge, we propose CHAMELEON, a scalable and efficient\npersonalization approach that uses (1) self-generated personal preference data\nand (2) representation editing to enable quick and cost-effective\npersonalization. Our experiments on various tasks, including those from the\nLaMP personalization benchmark, show that CHAMELEON efficiently adapts models\nto personal preferences, improving instruction-tuned models and outperforms two\npersonalization baselines by an average of 40% across two model architectures.\n","authors":["Yijing Zhang","Dyah Adila","Changho Shin","Frederic Sala"],"pdf_url":"https://arxiv.org/pdf/2503.01048v3.pdf","comment":"NAACL 2025 Findings"},{"id":"http://arxiv.org/abs/2503.03747v1","updated":"2025-03-05T18:58:58Z","published":"2025-03-05T18:58:58Z","title":"PacketCLIP: Multi-Modal Embedding of Network Traffic and Language for\n  Cybersecurity Reasoning","summary":"  Traffic classification is vital for cybersecurity, yet encrypted traffic\nposes significant challenges. We present PacketCLIP, a multi-modal framework\ncombining packet data with natural language semantics through contrastive\npretraining and hierarchical Graph Neural Network (GNN) reasoning. PacketCLIP\nintegrates semantic reasoning with efficient classification, enabling robust\ndetection of anomalies in encrypted network flows. By aligning textual\ndescriptions with packet behaviors, it offers enhanced interpretability,\nscalability, and practical applicability across diverse security scenarios.\nPacketCLIP achieves a 95% mean AUC, outperforms baselines by 11.6%, and reduces\nmodel size by 92%, making it ideal for real-time anomaly detection. By bridging\nadvanced machine learning techniques and practical cybersecurity needs,\nPacketCLIP provides a foundation for scalable, efficient, and interpretable\nsolutions to tackle encrypted traffic classification and network intrusion\ndetection challenges in resource-constrained environments.\n","authors":["Ryozo Masukawa","Sanggeon Yun","Sungheon Jeong","Wenjun Huang","Yang Ni","Ian Bryant","Nathaniel D. Bastian","Mohsen Imani"],"pdf_url":"https://arxiv.org/pdf/2503.03747v1.pdf","comment":"7 pages, 7 figures"},{"id":"http://arxiv.org/abs/2503.03744v1","updated":"2025-03-05T18:56:48Z","published":"2025-03-05T18:56:48Z","title":"Constrained Gaussian Wasserstein Optimal Transport with Commutative\n  Covariance Matrices","summary":"  Optimal transport has found widespread applications in signal processing and\nmachine learning. Among its many equivalent formulations, optimal transport\nseeks to reconstruct a random variable/vector with a prescribed distribution at\nthe destination while minimizing the expected distortion relative to a given\nrandom variable/vector at the source. However, in practice, certain constraints\nmay render the optimal transport plan infeasible. In this work, we consider\nthree types of constraints: rate constraints, dimension constraints, and\nchannel constraints, motivated by perception-aware lossy compression,\ngenerative principal component analysis, and deep joint source-channel coding,\nrespectively. Special attenion is given to the setting termed Gaussian\nWasserstein optimal transport, where both the source and reconstruction\nvariables are multivariate Gaussian, and the end-to-end distortion is measured\nby the mean squared error. We derive explicit results for the minimum\nachievable mean squared error under the three aforementioned constraints when\nthe covariance matrices of the source and reconstruction variables commute.\n","authors":["Jun Chen","Jia Wang","Ruibin Li","Han Zhou","Wei Dong","Huan Liu","Yuanhao Yu"],"pdf_url":"https://arxiv.org/pdf/2503.03744v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03736v1","updated":"2025-03-05T18:44:56Z","published":"2025-03-05T18:44:56Z","title":"Opportunistic Routing in Wireless Communications via Learnable\n  State-Augmented Policies","summary":"  This paper addresses the challenge of packet-based information routing in\nlarge-scale wireless communication networks. The problem is framed as a\nconstrained statistical learning task, where each network node operates using\nonly local information. Opportunistic routing exploits the broadcast nature of\nwireless communication to dynamically select optimal forwarding nodes, enabling\nthe information to reach the destination through multiple relay nodes\nsimultaneously. To solve this, we propose a State-Augmentation (SA) based\ndistributed optimization approach aimed at maximizing the total information\nhandled by the source nodes in the network. The problem formulation leverages\nGraph Neural Networks (GNNs), which perform graph convolutions based on the\ntopological connections between network nodes. Using an unsupervised learning\nparadigm, we extract routing policies from the GNN architecture, enabling\noptimal decisions for source nodes across various flows. Numerical experiments\ndemonstrate that the proposed method achieves superior performance when\ntraining a GNN-parameterized model, particularly when compared to baseline\nalgorithms. Additionally, applying the method to real-world network topologies\nand wireless ad-hoc network test beds validates its effectiveness, highlighting\nthe robustness and transferability of GNNs.\n","authors":["Sourajit Das","Navid NaderiAlizadeh","Rahul Mangharam","Alejandro Ribeiro"],"pdf_url":"https://arxiv.org/pdf/2503.03736v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03730v1","updated":"2025-03-05T18:40:19Z","published":"2025-03-05T18:40:19Z","title":"Towards Understanding Distilled Reasoning Models: A Representational\n  Approach","summary":"  In this paper, we investigate how model distillation impacts the development\nof reasoning features in large language models (LLMs). To explore this, we\ntrain a crosscoder on Qwen-series models and their fine-tuned variants. Our\nresults suggest that the crosscoder learns features corresponding to various\ntypes of reasoning, including self-reflection and computation verification.\nMoreover, we observe that distilled models contain unique reasoning feature\ndirections, which could be used to steer the model into over-thinking or\nincisive-thinking mode. In particular, we perform analysis on four specific\nreasoning categories: (a) self-reflection, (b) deductive reasoning, (c)\nalternative reasoning, and (d) contrastive reasoning. Finally, we examine the\nchanges in feature geometry resulting from the distillation process and find\nindications that larger distilled models may develop more structured\nrepresentations, which correlate with enhanced distillation performance. By\nproviding insights into how distillation modifies the model, our study\ncontributes to enhancing the transparency and reliability of AI systems.\n","authors":["David D. Baek","Max Tegmark"],"pdf_url":"https://arxiv.org/pdf/2503.03730v1.pdf","comment":"13 pages, 11 figures"},{"id":"http://arxiv.org/abs/2503.03729v1","updated":"2025-03-05T18:37:52Z","published":"2025-03-05T18:37:52Z","title":"Graph-Augmented LSTM for Forecasting Sparse Anomalies in\n  Graph-Structured Time Series","summary":"  Detecting anomalies in time series data is a critical task across many\ndomains. The challenge intensifies when anomalies are sparse and the data are\nmultivariate with relational dependencies across sensors or nodes. Traditional\nunivariate anomaly detectors struggle to capture such cross-node dependencies,\nparticularly in sparse anomaly settings. To address this, we propose a\ngraph-augmented time series forecasting approach that explicitly integrates the\ngraph of relationships among time series into an LSTM forecasting model. This\nenables the model to detect rare anomalies that might otherwise go unnoticed in\npurely univariate approaches. We evaluate the approach on two benchmark\ndatasets - the Yahoo Webscope S5 anomaly dataset and the METR-LA traffic sensor\nnetwork - and compare the performance of the Graph-Augmented LSTM against\nLSTM-only, ARIMA, and Prophet baselines. Results demonstrate that the\ngraph-augmented model achieves significantly higher precision and recall,\nimproving F1-score by up to 10% over the best baseline\n","authors":["Sneh Pillai"],"pdf_url":"https://arxiv.org/pdf/2503.03729v1.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2410.09156v3","updated":"2025-03-05T18:36:02Z","published":"2024-10-11T18:02:46Z","title":"On Discriminative Probabilistic Modeling for Self-Supervised\n  Representation Learning","summary":"  We study the discriminative probabilistic modeling on a continuous domain for\nthe data prediction task of (multimodal) self-supervised representation\nlearning. To address the challenge of computing the integral in the partition\nfunction for each anchor data, we leverage the multiple importance sampling\n(MIS) technique for robust Monte Carlo integration, which can recover\nInfoNCE-based contrastive loss as a special case. Within this probabilistic\nmodeling framework, we conduct generalization error analysis to reveal the\nlimitation of current InfoNCE-based contrastive loss for self-supervised\nrepresentation learning and derive insights for developing better approaches by\nreducing the error of Monte Carlo integration. To this end, we propose a novel\nnon-parametric method for approximating the sum of conditional probability\ndensities required by MIS through convex optimization, yielding a new\ncontrastive objective for self-supervised representation learning. Moreover, we\ndesign an efficient algorithm for solving the proposed objective. We\nempirically compare our algorithm to representative baselines on the\ncontrastive image-language pretraining task. Experimental results on the CC3M\nand CC12M datasets demonstrate the superior overall performance of our\nalgorithm. Our code is available at https://github.com/bokun-wang/NUCLR.\n","authors":["Bokun Wang","Yunwen Lei","Yiming Ying","Tianbao Yang"],"pdf_url":"https://arxiv.org/pdf/2410.09156v3.pdf","comment":"To appear in ICLR 2025"},{"id":"http://arxiv.org/abs/2503.03724v1","updated":"2025-03-05T18:24:58Z","published":"2025-03-05T18:24:58Z","title":"Deep Causal Behavioral Policy Learning: Applications to Healthcare","summary":"  We present a deep learning-based approach to studying dynamic clinical\nbehavioral regimes in diverse non-randomized healthcare settings. Our proposed\nmethodology - deep causal behavioral policy learning (DC-BPL) - uses deep\nlearning algorithms to learn the distribution of high-dimensional clinical\naction paths, and identifies the causal link between these action paths and\npatient outcomes. Specifically, our approach: (1) identifies the causal effects\nof provider assignment on clinical outcomes; (2) learns the distribution of\nclinical actions a given provider would take given evolving patient\ninformation; (3) and combines these steps to identify the optimal provider for\na given patient type and emulate that provider's care decisions. Underlying\nthis strategy, we train a large clinical behavioral model (LCBM) on electronic\nhealth records data using a transformer architecture, and demonstrate its\nability to estimate clinical behavioral policies. We propose a novel\ninterpretation of a behavioral policy learned using the LCBM: that it is an\nefficient encoding of complex, often implicit, knowledge used to treat a\npatient. This allows us to learn a space of policies that are critical to a\nwide range of healthcare applications, in which the vast majority of clinical\nknowledge is acquired tacitly through years of practice and only a tiny\nfraction of information relevant to patient care is written down (e.g. in\ntextbooks, studies or standardized guidelines).\n","authors":["Jonas Knecht","Anna Zink","Jonathan Kolstad","Maya Petersen"],"pdf_url":"https://arxiv.org/pdf/2503.03724v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.14395v2","updated":"2025-03-05T18:17:28Z","published":"2024-04-22T17:55:56Z","title":"PARAMANU-GANITA: Can Small Math Language Models Rival with Large\n  Language Models on Mathematical Reasoning?","summary":"  In this paper, we study whether domain specific pretraining of small\ngenerative language models (SLM) from scratch with domain specialized tokenizer\nand Chain-of-Thought (CoT) instruction fine-tuning results in competitive\nperformance on mathematical reasoning compared to LLMs? Secondly, whether this\napproach is environmentally sustainable, highly cost efficient? To address\nthese research questions, we present Paramanu-Ganita, a 208 million-parameter\nnovel decoder-only Auto Regressive SLM on mathematics. We performed pretraining\nfrom scratch on 31.5 billion tokens for 170 A100 hours using a context size of\n4096 on a mixed mathematical corpus consisting of web pages, source code,\ntextbooks, CoT templatised StackOverflow QA pairs, and mathematical lecture\nnotes in LaTeX curated by us. We also trained a math and code specialised BPE\ntokenizer. We proposed and performed CoT instruction fine-tuning of\nParamanu-Ganita on the MetaMathQA dataset. Our model Paramanu-Ganita, despite\nbeing 34 times smaller than the 7B LLMs, outperforms generalist LLMs by\napproximately 30% points, and even math-specialised LLMs by 3-23% points in\nGSM8K test accuracy metric. On MATH benchmark, Paramanu-Ganita outperformed the\nvarious models by 6-8% points. On benchmarks like LogiQA, MMLU (high school,\ncollege level), and competitive exams level, AGIEVAL (AQuA-RAT, SAT-Math),\nParamanu-Ganita outperformed others by 1-4%. Our model is available at\nhttps://huggingface.co/gyanai/paramanu-ganita-208M-hf .\n","authors":["Mitodru Niyogi","Arnab Bhattacharya"],"pdf_url":"https://arxiv.org/pdf/2404.14395v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.00675v2","updated":"2025-03-05T18:14:25Z","published":"2024-03-01T17:08:30Z","title":"Reusing Historical Trajectories in Natural Policy Gradient via\n  Importance Sampling: Convergence and Convergence Rate","summary":"  Reinforcement learning provides a mathematical framework for learning-based\ncontrol, whose success largely depends on the amount of data it can utilize.\nThe efficient utilization of historical trajectories obtained from previous\npolicies is essential for expediting policy optimization. Empirical evidence\nhas shown that policy gradient methods based on importance sampling work well.\nHowever, existing literature often neglect the interdependence between\ntrajectories from different iterations, and the good empirical performance\nlacks a rigorous theoretical justification. In this paper, we study a variant\nof the natural policy gradient method with reusing historical trajectories via\nimportance sampling. We show that the bias of the proposed estimator of the\ngradient is asymptotically negligible, the resultant algorithm is convergent,\nand reusing past trajectories helps improve the convergence rate. We further\napply the proposed estimator to popular policy optimization algorithms such as\ntrust region policy optimization. Our theoretical results are verified on\nclassical benchmarks.\n","authors":["Yifan Lin","Yuhao Wang","Enlu Zhou"],"pdf_url":"https://arxiv.org/pdf/2403.00675v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.03888v3","updated":"2025-03-05T18:04:40Z","published":"2025-01-07T15:51:49Z","title":"Neural DNF-MT: A Neuro-symbolic Approach for Learning Interpretable and\n  Editable Policies","summary":"  Although deep reinforcement learning has been shown to be effective, the\nmodel's black-box nature presents barriers to direct policy interpretation. To\naddress this problem, we propose a neuro-symbolic approach called neural DNF-MT\nfor end-to-end policy learning. The differentiable nature of the neural DNF-MT\nmodel enables the use of deep actor-critic algorithms for training. At the same\ntime, its architecture is designed so that trained models can be directly\ntranslated into interpretable policies expressed as standard (bivalent or\nprobabilistic) logic programs. Moreover, additional layers can be included to\nextract abstract features from complex observations, acting as a form of\npredicate invention. The logic representations are highly interpretable, and we\nshow how the bivalent representations of deterministic policies can be edited\nand incorporated back into a neural model, facilitating manual intervention and\nadaptation of learned policies. We evaluate our approach on a range of tasks\nrequiring learning deterministic or stochastic behaviours from various forms of\nobservations. Our empirical results show that our neural DNF-MT model performs\nat the level of competing black-box methods whilst providing interpretable\npolicies.\n","authors":["Kexin Gu Baugh","Luke Dickens","Alessandra Russo"],"pdf_url":"https://arxiv.org/pdf/2501.03888v3.pdf","comment":"AAMAS 2025 (with Appendix)"},{"id":"http://arxiv.org/abs/2503.03715v1","updated":"2025-03-05T18:04:30Z","published":"2025-03-05T18:04:30Z","title":"Handling Uncertainty in Health Data using Generative Algorithms","summary":"  Understanding and managing uncertainty is crucial in machine learning,\nespecially in high-stakes domains like healthcare, where class imbalance can\nimpact predictions. This paper introduces RIGA, a novel pipeline that mitigates\nclass imbalance using generative AI. By converting tabular healthcare data into\nimages, RIGA leverages models like cGAN, VQVAE, and VQGAN to generate balanced\nsamples, improving classification performance. These representations are\nprocessed by CNNs and later transformed back into tabular format for seamless\nintegration. This approach enhances traditional classifiers like XGBoost,\nimproves Bayesian structure learning, and strengthens ML model robustness by\ngenerating realistic synthetic data for underrepresented classes.\n","authors":["Mahdi Arab Loodaricheh","Neh Majmudar","Anita Raja","Ansaf Salleb-Aouissi"],"pdf_url":"https://arxiv.org/pdf/2503.03715v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03710v1","updated":"2025-03-05T18:01:05Z","published":"2025-03-05T18:01:05Z","title":"Improving LLM Safety Alignment with Dual-Objective Optimization","summary":"  Existing training-time safety alignment techniques for large language models\n(LLMs) remain vulnerable to jailbreak attacks. Direct preference optimization\n(DPO), a widely deployed alignment method, exhibits limitations in both\nexperimental and theoretical contexts as its loss function proves suboptimal\nfor refusal learning. Through gradient-based analysis, we identify these\nshortcomings and propose an improved safety alignment that disentangles DPO\nobjectives into two components: (1) robust refusal training, which encourages\nrefusal even when partial unsafe generations are produced, and (2) targeted\nunlearning of harmful knowledge. This approach significantly increases LLM\nrobustness against a wide range of jailbreak attacks, including prefilling,\nsuffix, and multi-turn attacks across both in-distribution and\nout-of-distribution scenarios. Furthermore, we introduce a method to emphasize\ncritical refusal tokens by incorporating a reward-based token-level weighting\nmechanism for refusal learning, which further improves the robustness against\nadversarial exploits. Our research also suggests that robustness to jailbreak\nattacks is correlated with token distribution shifts in the training process\nand internal representations of refusal and harmful tokens, offering valuable\ndirections for future research in LLM safety alignment. The code is available\nat https://github.com/wicai24/DOOR-Alignment\n","authors":["Xuandong Zhao","Will Cai","Tianneng Shi","David Huang","Licong Lin","Song Mei","Dawn Song"],"pdf_url":"https://arxiv.org/pdf/2503.03710v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03707v1","updated":"2025-03-05T17:58:16Z","published":"2025-03-05T17:58:16Z","title":"Curating Demonstrations using Online Experience","summary":"  Many robot demonstration datasets contain heterogeneous demonstrations of\nvarying quality. This heterogeneity may benefit policy pre-training, but can\nhinder robot performance when used with a final imitation learning objective.\nIn particular, some strategies in the data may be less reliable than others or\nmay be underrepresented in the data, leading to poor performance when such\nstrategies are sampled at test time. Moreover, such unreliable or\nunderrepresented strategies can be difficult even for people to discern, and\nsifting through demonstration datasets is time-consuming and costly. On the\nother hand, policy performance when trained on such demonstrations can reflect\nthe reliability of different strategies. We thus propose for robots to\nself-curate based on online robot experience (Demo-SCORE). More specifically,\nwe train and cross-validate a classifier to discern successful policy roll-outs\nfrom unsuccessful ones and use the classifier to filter heterogeneous\ndemonstration datasets. Our experiments in simulation and the real world show\nthat Demo-SCORE can effectively identify suboptimal demonstrations without\nmanual curation. Notably, Demo-SCORE achieves over 15-35% higher absolute\nsuccess rate in the resulting policy compared to the base policy trained with\nall original demonstrations.\n","authors":["Annie S. Chen","Alec M. Lessing","Yuejiang Liu","Chelsea Finn"],"pdf_url":"https://arxiv.org/pdf/2503.03707v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03705v1","updated":"2025-03-05T17:56:20Z","published":"2025-03-05T17:56:20Z","title":"Effective LLM Knowledge Learning via Model Generalization","summary":"  Large language models (LLMs) are trained on enormous documents that contain\nextensive world knowledge. However, it is still not well-understood how\nknowledge is acquired via autoregressive pre-training. This lack of\nunderstanding greatly hinders effective knowledge learning, especially for\ncontinued pretraining on up-to-date information, as this evolving information\noften lacks diverse repetitions like foundational knowledge. In this paper, we\nfocus on understanding and improving LLM knowledge learning. We found and\nverified that knowledge learning for LLMs can be deemed as an implicit\nsupervised task hidden in the autoregressive pre-training objective. Our\nfindings suggest that knowledge learning for LLMs would benefit from methods\ndesigned to improve generalization ability for supervised tasks. Based on our\nanalysis, we propose the formatting-based data augmentation to grow\nin-distribution samples, which does not present the risk of altering the facts\nembedded in documents as text paraphrasing. We also introduce sharpness-aware\nminimization as an effective optimization algorithm to better improve\ngeneralization. Moreover, our analysis and method can be readily extended to\ninstruction tuning. Extensive experiment results validate our findings and\ndemonstrate our methods' effectiveness in both continued pre-training and\ninstruction tuning. This paper offers new perspectives and insights to\ninterpret and design effective strategies for LLM knowledge learning.\n","authors":["Mingkang Zhu","Xi Chen","Zhongdao Wang","Bei Yu","Hengshuang Zhao","Jiaya Jia"],"pdf_url":"https://arxiv.org/pdf/2503.03705v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03704v1","updated":"2025-03-05T17:53:24Z","published":"2025-03-05T17:53:24Z","title":"A Practical Memory Injection Attack against LLM Agents","summary":"  Agents based on large language models (LLMs) have demonstrated strong\ncapabilities in a wide range of complex, real-world applications. However, LLM\nagents with a compromised memory bank may easily produce harmful outputs when\nthe past records retrieved for demonstration are malicious. In this paper, we\npropose a novel Memory INJection Attack, MINJA, that enables the injection of\nmalicious records into the memory bank by only interacting with the agent via\nqueries and output observations. These malicious records are designed to elicit\na sequence of malicious reasoning steps leading to undesirable agent actions\nwhen executing the victim user's query. Specifically, we introduce a sequence\nof bridging steps to link the victim query to the malicious reasoning steps.\nDuring the injection of the malicious record, we propose an indication prompt\nto guide the agent to autonomously generate our designed bridging steps. We\nalso propose a progressive shortening strategy that gradually removes the\nindication prompt, such that the malicious record will be easily retrieved when\nprocessing the victim query comes after. Our extensive experiments across\ndiverse agents demonstrate the effectiveness of MINJA in compromising agent\nmemory. With minimal requirements for execution, MINJA enables any user to\ninfluence agent memory, highlighting practical risks of LLM agents.\n","authors":["Shen Dong","Shaocheng Xu","Pengfei He","Yige Li","Jiliang Tang","Tianming Liu","Hui Liu","Zhen Xiang"],"pdf_url":"https://arxiv.org/pdf/2503.03704v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01776v2","updated":"2025-03-05T17:51:09Z","published":"2025-03-03T17:59:48Z","title":"Beyond Matryoshka: Revisiting Sparse Coding for Adaptive Representation","summary":"  Many large-scale systems rely on high-quality deep representations\n(embeddings) to facilitate tasks like retrieval, search, and generative\nmodeling. Matryoshka Representation Learning (MRL) recently emerged as a\nsolution for adaptive embedding lengths, but it requires full model retraining\nand suffers from noticeable performance degradations at short lengths. In this\npaper, we show that sparse coding offers a compelling alternative for achieving\nadaptive representation with minimal overhead and higher fidelity. We propose\nContrastive Sparse Representation (CSR), a method that sparsifies pre-trained\nembeddings into a high-dimensional but selectively activated feature space. By\nleveraging lightweight autoencoding and task-aware contrastive objectives, CSR\npreserves semantic quality while allowing flexible, cost-effective inference at\ndifferent sparsity levels. Extensive experiments on image, text, and multimodal\nbenchmarks demonstrate that CSR consistently outperforms MRL in terms of both\naccuracy and retrieval speed-often by large margins-while also cutting training\ntime to a fraction of that required by MRL. Our results establish sparse coding\nas a powerful paradigm for adaptive representation learning in real-world\napplications where efficiency and fidelity are both paramount. Code is\navailable at https://github.com/neilwen987/CSR_Adaptive_Rep\n","authors":["Tiansheng Wen","Yifei Wang","Zequn Zeng","Zhong Peng","Yudi Su","Xinyang Liu","Bo Chen","Hongwei Liu","Stefanie Jegelka","Chenyu You"],"pdf_url":"https://arxiv.org/pdf/2503.01776v2.pdf","comment":"A novel sparse coding framework designed for learning adaptive\n  representation"},{"id":"http://arxiv.org/abs/2503.03684v1","updated":"2025-03-05T17:25:20Z","published":"2025-03-05T17:25:20Z","title":"Towards Trustworthy Federated Learning","summary":"  This paper develops a comprehensive framework to address three critical\ntrustworthy challenges in federated learning (FL): robustness against Byzantine\nattacks, fairness, and privacy preservation. To improve the system's defense\nagainst Byzantine attacks that send malicious information to bias the system's\nperformance, we develop a Two-sided Norm Based Screening (TNBS) mechanism,\nwhich allows the central server to crop the gradients that have the l lowest\nnorms and h highest norms. TNBS functions as a screening tool to filter out\npotential malicious participants whose gradients are far from the honest ones.\nTo promote egalitarian fairness, we adopt the q-fair federated learning\n(q-FFL). Furthermore, we adopt a differential privacy-based scheme to prevent\nraw data at local clients from being inferred by curious parties. Convergence\nguarantees are provided for the proposed framework under different scenarios.\nExperimental results on real datasets demonstrate that the proposed framework\neffectively improves robustness and fairness while managing the trade-off\nbetween privacy and accuracy. This work appears to be the first study that\nexperimentally and theoretically addresses fairness, privacy, and robustness in\ntrustworthy FL.\n","authors":["Alina Basharat","Yijun Bian","Ping Xu","Zhi Tian"],"pdf_url":"https://arxiv.org/pdf/2503.03684v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.01777v2","updated":"2025-03-05T17:25:07Z","published":"2025-02-03T19:29:42Z","title":"CTC-DRO: Robust Optimization for Reducing Language Disparities in Speech\n  Recognition","summary":"  Modern deep learning models often achieve high overall performance, but\nconsistently fail on specific subgroups. Group distributionally robust\noptimization (group DRO) addresses this problem by minimizing the worst-group\nloss, but it fails when group losses misrepresent performance differences\nbetween groups. This is common in domains like speech, where the widely used\nconnectionist temporal classification (CTC) loss scales with input length and\nvaries with linguistic and acoustic properties, leading to spurious differences\nbetween group losses. We present CTC-DRO, which addresses the shortcomings of\nthe group DRO objective by smoothing the group weight update to prevent\noveremphasis on consistently high-loss groups, while using input length-matched\nbatching to mitigate CTC's scaling issues. We evaluate CTC-DRO on the task of\nmultilingual automatic speech recognition (ASR) across five language sets from\nthe ML-SUPERB 2.0 benchmark. CTC-DRO consistently outperforms group DRO and\nCTC-based baseline models, reducing the worst-language error by up to 47.1% and\nthe average error by up to 32.9%. CTC-DRO can be applied to ASR with minimal\ncomputational costs, and offers the potential for reducing group disparities in\nother domains with similar challenges.\n","authors":["Martijn Bartelds","Ananjan Nandi","Moussa Koulako Bala Doumbouya","Dan Jurafsky","Tatsunori Hashimoto","Karen Livescu"],"pdf_url":"https://arxiv.org/pdf/2502.01777v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03676v1","updated":"2025-03-05T17:11:02Z","published":"2025-03-05T17:11:02Z","title":"Optimally Installing Strict Equilibria","summary":"  In this work, we develop a reward design framework for installing a desired\nbehavior as a strict equilibrium across standard solution concepts: dominant\nstrategy equilibrium, Nash equilibrium, correlated equilibrium, and coarse\ncorrelated equilibrium. We also extend our framework to capture the\nMarkov-perfect equivalents of each solution concept. Central to our framework\nis a comprehensive mathematical characterization of strictly installable, based\non the desired solution concept and the behavior's structure. These\ncharacterizations lead to efficient iterative algorithms, which we generalize\nto handle optimization objectives through linear programming. Finally, we\nexplore how our results generalize to bounded rational agents.\n","authors":["Jeremy McMahan","Young Wu","Yudong Chen","Xiaojin Zhu","Qiaomin Xie"],"pdf_url":"https://arxiv.org/pdf/2503.03676v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17579v3","updated":"2025-03-05T17:09:46Z","published":"2024-10-23T06:08:45Z","title":"Bonsai: Gradient-free Graph Distillation for Node Classification","summary":"  Graph distillation has emerged as a promising avenue to enable scalable\ntraining of GNNs by compressing the training dataset while preserving essential\ngraph characteristics. Our study uncovers significant shortcomings in current\ngraph distillation techniques. First, the majority of the algorithms\nparadoxically require training on the full dataset to perform distillation.\nSecond, due to their gradient-emulating approach, these methods require fresh\ndistillation for any change in hyperparameters or GNN architecture, limiting\ntheir flexibility and reusability. Finally, they fail to achieve substantial\nsize reduction due to synthesizing fully-connected, edge-weighted graphs. To\naddress these challenges, we present Bonsai, a novel graph distillation method\nempowered by the observation that \\textit{computation trees} form the\nfundamental processing units of message-passing GNNs. Bonsai distills datasets\nby encoding a careful selection of \\textit{exemplar} trees that maximize the\nrepresentation of all computation trees in the training set. This unique\napproach imparts Bonsai as the first linear-time, model-agnostic graph\ndistillation algorithm for node classification that outperforms existing\nbaselines across $6$ real-world datasets on accuracy, while being $22$ times\nfaster on average. Bonsai is grounded in rigorous mathematical guarantees on\nthe adopted approximation strategies making it robust to GNN architectures,\ndatasets, and parameters.\n","authors":["Mridul Gupta","Samyak Jain","Vansh Ramani","Hariprasad Kodamana","Sayan Ranu"],"pdf_url":"https://arxiv.org/pdf/2410.17579v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.14131v3","updated":"2025-03-05T17:05:55Z","published":"2024-05-23T03:11:07Z","title":"Statistical Advantages of Perturbing Cosine Router in Mixture of Experts","summary":"  The cosine router in Mixture of Experts (MoE) has recently emerged as an\nattractive alternative to the conventional linear router. Indeed, the cosine\nrouter demonstrates favorable performance in image and language tasks and\nexhibits better ability to mitigate the representation collapse issue, which\noften leads to parameter redundancy and limited representation potentials.\nDespite its empirical success, a comprehensive analysis of the cosine router in\nMoE has been lacking. Considering the least square estimation of the cosine\nrouting MoE, we demonstrate that due to the intrinsic interaction of the model\nparameters in the cosine router via some partial differential equations,\nregardless of the structures of the experts, the estimation rates of experts\nand model parameters can be as slow as $\\mathcal{O}(1/\\log^{\\tau}(n))$ where\n$\\tau > 0$ is some constant and $n$ is the sample size. Surprisingly, these\npessimistic non-polynomial convergence rates can be circumvented by the widely\nused technique in practice to stabilize the cosine router -- simply adding\nnoises to the $\\ell^2$-norms in the cosine router, which we refer to as\n\\textit{perturbed cosine router}. Under the strongly identifiable settings of\nthe expert functions, we prove that the estimation rates for both the experts\nand model parameters under the perturbed cosine routing MoE are significantly\nimproved to polynomial rates. Finally, we conduct extensive simulation studies\nin both synthetic and real data settings to empirically validate our\ntheoretical results.\n","authors":["Huy Nguyen","Pedram Akbarian","Trang Pham","Trang Nguyen","Shujian Zhang","Nhat Ho"],"pdf_url":"https://arxiv.org/pdf/2405.14131v3.pdf","comment":"Accepted to ICLR 2025"},{"id":"http://arxiv.org/abs/2503.03666v1","updated":"2025-03-05T16:59:08Z","published":"2025-03-05T16:59:08Z","title":"Analogical Reasoning Inside Large Language Models: Concept Vectors and\n  the Limits of Abstraction","summary":"  Analogical reasoning relies on conceptual abstractions, but it is unclear\nwhether Large Language Models (LLMs) harbor such internal representations. We\nexplore distilled representations from LLM activations and find that function\nvectors (FVs; Todd et al., 2024) - compact representations for in-context\nlearning (ICL) tasks - are not invariant to simple input changes (e.g.,\nopen-ended vs. multiple-choice), suggesting they capture more than pure\nconcepts. Using representational similarity analysis (RSA), we localize a small\nset of attention heads that encode invariant concept vectors (CVs) for verbal\nconcepts like \"antonym\". These CVs function as feature detectors that operate\nindependently of the final output - meaning that a model may form a correct\ninternal representation yet still produce an incorrect output. Furthermore, CVs\ncan be used to causally guide model behaviour. However, for more abstract\nconcepts like \"previous\" and \"next\", we do not observe invariant linear\nrepresentations, a finding we link to generalizability issues LLMs display\nwithin these domains.\n","authors":["Gustaw Opiełka","Hannes Rosenbusch","Claire E. Stevenson"],"pdf_url":"https://arxiv.org/pdf/2503.03666v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2409.07402v2","updated":"2025-03-05T16:48:23Z","published":"2024-09-11T16:42:22Z","title":"What to align in multimodal contrastive learning?","summary":"  Humans perceive the world through multisensory integration, blending the\ninformation of different modalities to adapt their behavior. Contrastive\nlearning offers an appealing solution for multimodal self-supervised learning.\nIndeed, by considering each modality as a different view of the same entity, it\nlearns to align features of different modalities in a shared representation\nspace. However, this approach is intrinsically limited as it only learns shared\nor redundant information between modalities, while multimodal interactions can\narise in other ways. In this work, we introduce CoMM, a Contrastive MultiModal\nlearning strategy that enables the communication between modalities in a single\nmultimodal space. Instead of imposing cross- or intra- modality constraints, we\npropose to align multimodal representations by maximizing the mutual\ninformation between augmented versions of these multimodal features. Our\ntheoretical analysis shows that shared, synergistic and unique terms of\ninformation naturally emerge from this formulation, allowing us to estimate\nmultimodal interactions beyond redundancy. We test CoMM both in a controlled\nand in a series of real-world settings: in the former, we demonstrate that CoMM\neffectively captures redundant, unique and synergistic information between\nmodalities. In the latter, CoMM learns complex multimodal interactions and\nachieves state-of-the-art results on the seven multimodal benchmarks. Code is\navailable at https://github.com/Duplums/CoMM\n","authors":["Benoit Dufumier","Javiera Castillo-Navarro","Devis Tuia","Jean-Philippe Thiran"],"pdf_url":"https://arxiv.org/pdf/2409.07402v2.pdf","comment":"ICLR 2025, 25 pages"},{"id":"http://arxiv.org/abs/2503.03660v1","updated":"2025-03-05T16:47:36Z","published":"2025-03-05T16:47:36Z","title":"Chunking the Critic: A Transformer-based Soft Actor-Critic with N-Step\n  Returns","summary":"  Soft Actor-Critic (SAC) critically depends on its critic network, which\ntypically evaluates a single state-action pair to guide policy updates. Using\nN-step returns is a common practice to reduce the bias in the target values of\nthe critic. However, using N-step returns can again introduce high variance and\nnecessitates importance sampling, often destabilizing training. Recent\nalgorithms have also explored action chunking-such as direct action repetition\nand movement primitives-to enhance exploration. In this paper, we propose a\nTransformer-based Critic Network for SAC that integrates the N-returns\nframework in a stable and efficient manner. Unlike approaches that perform\nchunking in the actor network, we feed chunked actions into the critic network\nto explore potential performance gains. Our architecture leverages the\nTransformer's ability to process sequential information, facilitating more\nrobust value estimation. Empirical results show that this method not only\nachieves efficient, stable training but also excels in sparse\nreward/multi-phase environments-traditionally a challenge for step-based\nmethods. These findings underscore the promise of combining Transformer-based\ncritics with N-returns to advance reinforcement learning performance\n","authors":["Dong Tian","Ge Li","Hongyi Zhou","Onur Celik","Gerhard Neumann"],"pdf_url":"https://arxiv.org/pdf/2503.03660v1.pdf","comment":"11 pages, 5 figures"},{"id":"http://arxiv.org/abs/2503.03659v1","updated":"2025-03-05T16:47:08Z","published":"2025-03-05T16:47:08Z","title":"Finite-sample valid prediction of future insurance claims in the\n  regression problem","summary":"  In the current insurance literature, prediction of insurance claims in the\nregression problem is often performed with a statistical model. This\nmodel-based approach may suffer from several drawbacks: (i) model\nmisspecification, (ii) selection effect, and (iii) lack of finite-sample\nvalidity. This article addresses these three issues simultaneously by employing\nconformal prediction-a general machine learning strategy for valid predictions.\nThe proposed method is both model-free and tuning-parameter-free. It also\nguarantees finite-sample validity at a pre-assigned coverage probability level.\n","authors":["Liang Hong"],"pdf_url":"https://arxiv.org/pdf/2503.03659v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03656v1","updated":"2025-03-05T16:39:04Z","published":"2025-03-05T16:39:04Z","title":"Robust Learning of Diverse Code Edits","summary":"  Software engineering activities frequently involve edits to existing code.\nHowever, contemporary code language models (LMs) lack the ability to handle\ndiverse types of code-edit requirements. In this work, we attempt to overcome\nthis shortcoming through (1) a novel synthetic data generation pipeline and (2)\na robust model adaptation algorithm. Starting with seed code examples and\ndiverse editing criteria, our pipeline generates high-quality samples\ncomprising original and modified code, along with natural language instructions\nin different styles and verbosity. Today's code LMs come bundled with strong\nabilities, such as code generation and instruction following, which should not\nbe lost due to fine-tuning. To ensure this, we propose a novel adaptation\nalgorithm, SeleKT, that (a) leverages a dense gradient-based step to identify\nthe weights that are most important for code editing, and (b) does a sparse\nprojection onto the base model to avoid overfitting. Using our approach, we\nobtain a new series of models NextCoder (adapted from QwenCoder-2.5) that\nachieves strong results on five code-editing benchmarks, outperforming\ncomparable size models and even several larger ones. We show the generality of\nour approach on two model families (DeepSeekCoder and QwenCoder), compare\nagainst other fine-tuning approaches, and demonstrate robustness by showing\nretention of code generation abilities post adaptation.\n","authors":["Tushar Aggarwal","Swayam Singh","Abhijeet Awasthi","Aditya Kanade","Nagarajan Natarajan"],"pdf_url":"https://arxiv.org/pdf/2503.03656v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.00816v2","updated":"2025-03-05T16:36:05Z","published":"2024-10-28T08:10:21Z","title":"CycleResearcher: Improving Automated Research via Automated Review","summary":"  The automation of scientific discovery has been a long-standing goal within\nthe research community, driven by the potential to accelerate knowledge\ncreation. While significant progress has been made using commercial large\nlanguage models (LLMs) as research assistants or idea generators, the\npossibility of automating the entire research process with open-source LLMs\nremains largely unexplored. This paper explores the feasibility of using\nopen-source post-trained LLMs as autonomous agents capable of performing the\nfull cycle of automated research and review, from literature review and\nmanuscript preparation to peer review and paper refinement. Our iterative\npreference training framework consists of CycleResearcher, which conducts\nresearch tasks, and CycleReviewer, which simulates the peer review process,\nproviding iterative feedback via reinforcement learning. To train these models,\nwe develop two new datasets, Review-5k and Research-14k, reflecting real-world\nmachine learning research and peer review dynamics. Our results demonstrate\nthat CycleReviewer achieves promising performance with a 26.89\\% reduction in\nmean absolute error (MAE) compared to individual human reviewers in predicting\npaper scores, indicating the potential of LLMs to effectively assist\nexpert-level research evaluation. In research, the papers generated by the\nCycleResearcher model achieved a score of 5.36 in simulated peer reviews,\nshowing some competitiveness in terms of simulated review scores compared to\nthe preprint level of 5.24 from human experts, while still having room for\nimprovement compared to the accepted paper level of 5.69. This work represents\na significant step toward fully automated scientific inquiry, providing ethical\nsafeguards and exploring AI-driven research capabilities. The code, dataset and\nmodel weight are released at https://wengsyx.github.io/Researcher/\n","authors":["Yixuan Weng","Minjun Zhu","Guangsheng Bao","Hongbo Zhang","Jindong Wang","Yue Zhang","Linyi Yang"],"pdf_url":"https://arxiv.org/pdf/2411.00816v2.pdf","comment":"Accept in ICLR 2025"},{"id":"http://arxiv.org/abs/2503.03654v1","updated":"2025-03-05T16:32:47Z","published":"2025-03-05T16:32:47Z","title":"Improving Neutral Point of View Text Generation through\n  Parameter-Efficient Reinforcement Learning and a Small-Scale High-Quality\n  Dataset","summary":"  This paper describes the construction of a dataset and the evaluation of\ntraining methods to improve generative large language models' (LLMs) ability to\nanswer queries on sensitive topics with a Neutral Point of View (NPOV), i.e.,\nto provide significantly more informative, diverse and impartial answers. The\ndataset, the SHQ-NPOV dataset, comprises 300 high-quality, human-written\nquadruplets: a query on a sensitive topic, an answer, an NPOV rating, and a set\nof links to source texts elaborating the various points of view. The first key\ncontribution of this paper is a new methodology to create such datasets through\niterative rounds of human peer-critique and annotator training, which we\nrelease alongside the dataset. The second key contribution is the\nidentification of a highly effective training regime for parameter-efficient\nreinforcement learning (PE-RL) to improve NPOV generation. We compare and\nextensively evaluate PE-RL and multiple baselines-including LoRA finetuning (a\nstrong baseline), SFT and RLHF.\n  PE-RL not only improves on overall NPOV quality compared to the strongest\nbaseline ($97.06\\%\\rightarrow 99.08\\%$), but also scores much higher on\nfeatures linguists identify as key to separating good answers from the best\nanswers ($60.25\\%\\rightarrow 85.21\\%$ for presence of supportive details,\n$68.74\\%\\rightarrow 91.43\\%$ for absence of oversimplification). A qualitative\nanalysis corroborates this. Finally, our evaluation finds no statistical\ndifferences between results on topics that appear in the training dataset and\nthose on separated evaluation topics, which provides strong evidence that our\napproach to training PE-RL exhibits very effective out of topic generalization.\n","authors":["Jessica Hoffmann","Christiane Ahlheim","Zac Yu","Aria Walfrand","Jarvis Jin","Marie Tano","Ahmad Beirami","Erin van Liemt","Nithum Thain","Hakim Sidahmed","Lucas Dixon"],"pdf_url":"https://arxiv.org/pdf/2503.03654v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03649v1","updated":"2025-03-05T16:25:58Z","published":"2025-03-05T16:25:58Z","title":"Limits of nonlinear and dispersive fiber propagation for photonic\n  extreme learning","summary":"  We report a generalized nonlinear Schr\\\"odinger equation simulation model of\nan extreme learning machine based on optical fiber propagation. Using\nhandwritten digit classification as a benchmark, we study how accuracy depends\non propagation dynamics, as well as parameters governing spectral encoding,\nreadout, and noise. Test accuracies of over 91% and 93% are found for\npropagation in the anomalous and normal dispersion regimes respectively. Our\nsimulation results also suggest that quantum noise on the input pulses\nintroduces an intrinsic penalty to ELM performance.\n","authors":["Andrei V. Ermolaev","Mathilde Hary","Lev Leybov","Piotr Ryczkowski","Anas Skalli","Daniel Brunner","Goëry Genty","John M. Dudley"],"pdf_url":"https://arxiv.org/pdf/2503.03649v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03634v1","updated":"2025-03-05T16:14:43Z","published":"2025-03-05T16:14:43Z","title":"Feature Matching Intervention: Leveraging Observational Data for Causal\n  Representation Learning","summary":"  A major challenge in causal discovery from observational data is the absence\nof perfect interventions, making it difficult to distinguish causal features\nfrom spurious ones. We propose an innovative approach, Feature Matching\nIntervention (FMI), which uses a matching procedure to mimic perfect\ninterventions. We define causal latent graphs, extending structural causal\nmodels to latent feature space, providing a framework that connects FMI with\ncausal graph learning. Our feature matching procedure emulates perfect\ninterventions within these causal latent graphs. Theoretical results\ndemonstrate that FMI exhibits strong out-of-distribution (OOD)\ngeneralizability. Experiments further highlight FMI's superior performance in\neffectively identifying causal features solely from observational data.\n","authors":["Haoze Li","Jun Xie"],"pdf_url":"https://arxiv.org/pdf/2503.03634v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.09647v2","updated":"2025-03-05T16:14:16Z","published":"2025-02-11T00:04:32Z","title":"Unveiling Simplicities of Attention: Adaptive Long-Context Head\n  Identification","summary":"  The ability to process long contexts is crucial for many natural language\nprocessing tasks, yet it remains a significant challenge. While substantial\nprogress has been made in enhancing the efficiency of attention mechanisms,\nthere is still a gap in understanding how attention heads function in\nlong-context settings. In this paper, we observe that while certain heads\nconsistently attend to local information only, others swing between attending\nto local and long-context information depending on the query. This raises the\nquestion: can we identify which heads require long-context information to\npredict the next token accurately? We demonstrate that it's possible to predict\nwhich heads are crucial for long-context processing using only local keys. The\ncore idea here is to exploit a simple model for the long-context scores via\nsecond moment approximations. These findings unveil simple properties of\nattention in the context of long sequences, and open the door to potentially\nsignificant gains in efficiency.\n","authors":["Konstantin Donhauser","Charles Arnal","Mohammad Pezeshki","Vivien Cabannes","David Lopez-Paz","Kartik Ahuja"],"pdf_url":"https://arxiv.org/pdf/2502.09647v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.10650v2","updated":"2025-03-05T16:11:42Z","published":"2025-02-15T03:03:09Z","title":"Generative Adversarial Networks for High-Dimensional Item Factor\n  Analysis: A Deep Adversarial Learning Algorithm","summary":"  Advances in deep learning and representation learning have transformed item\nfactor analysis (IFA) in the item response theory (IRT) literature by enabling\nmore efficient and accurate parameter estimation. Variational Autoencoders\n(VAEs) have been one of the most impactful techniques in modeling\nhigh-dimensional latent variables in this context. However, the limited\nexpressiveness of the inference model based on traditional VAEs can still\nhinder the estimation performance. We introduce Adversarial Variational Bayes\n(AVB) algorithms as an improvement to VAEs for IFA with improved flexibility\nand accuracy. By bridging the strengths of VAEs and Generative Adversarial\nNetworks (GANs), AVB incorporates an auxiliary discriminator network to reframe\nthe estimation process as a two-player adversarial game and removes the\nrestrictive assumption of standard normal distributions in the inference model.\nTheoretically, AVB can achieve similar or higher likelihood compared to VAEs. A\nfurther enhanced algorithm, Importance-weighted Adversarial Variational Bayes\n(IWAVB) is proposed and compared with Importance-weighted Autoencoders (IWAE).\nIn an exploratory analysis of empirical data, IWAVB demonstrated superior\nexpressiveness by achieving a higher likelihood compared to IWAE. In\nconfirmatory analysis with simulated data, IWAVB achieved similar mean-square\nerror results to IWAE while consistently achieving higher likelihoods. When\nlatent variables followed a multimodal distribution, IWAVB outperformed IWAE.\nWith its innovative use of GANs, IWAVB is shown to have the potential to extend\nIFA to handle large-scale data, facilitating the potential integration of\npsychometrics and multimodal data analysis.\n","authors":["Nanyu Luo","Feng Ji"],"pdf_url":"https://arxiv.org/pdf/2502.10650v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.12126v2","updated":"2025-03-05T16:08:49Z","published":"2024-11-18T23:34:07Z","title":"MMBind: Unleashing the Potential of Distributed and Heterogeneous Data\n  for Multimodal Learning in IoT","summary":"  Multimodal sensing systems are increasingly prevalent in various real-world\napplications. Most existing multimodal learning approaches heavily rely on\ntraining with a large amount of synchronized, complete multimodal data.\nHowever, such a setting is impractical in real-world IoT sensing applications\nwhere data is typically collected by distributed nodes with heterogeneous data\nmodalities, and is also rarely labeled. In this paper, we propose MMBind, a new\ndata binding approach for multimodal learning on distributed and heterogeneous\nIoT data. The key idea of MMBind is to construct a pseudo-paired multimodal\ndataset for model training by binding data from disparate sources and\nincomplete modalities through a sufficiently descriptive shared modality. We\nalso propose a weighted contrastive learning approach to handle domain shifts\namong disparate data, coupled with an adaptive multimodal learning architecture\ncapable of training models with heterogeneous modality combinations.\nEvaluations on ten real-world multimodal datasets highlight that MMBind\noutperforms state-of-the-art baselines under varying degrees of data\nincompleteness and domain shift, and holds promise for advancing multimodal\nfoundation model training in IoT applications\\footnote (The source code is\navailable via https://github.com/nesl/multimodal-bind).\n","authors":["Xiaomin Ouyang","Jason Wu","Tomoyoshi Kimura","Yihan Lin","Gunjan Verma","Tarek Abdelzaher","Mani Srivastava"],"pdf_url":"https://arxiv.org/pdf/2411.12126v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.13921v2","updated":"2025-03-05T16:07:23Z","published":"2025-02-19T17:53:59Z","title":"Exploring Code Language Models for Automated HLS-based Hardware\n  Generation: Benchmark, Infrastructure and Analysis","summary":"  Recent advances in code generation have illuminated the potential of\nemploying large language models (LLMs) for general-purpose programming\nlanguages such as Python and C++, opening new opportunities for automating\nsoftware development and enhancing programmer productivity. The potential of\nLLMs in software programming has sparked significant interest in exploring\nautomated hardware generation and automation. Although preliminary endeavors\nhave been made to adopt LLMs in generating hardware description languages\n(HDLs), several challenges persist in this direction. First, the volume of\navailable HDL training data is substantially smaller compared to that for\nsoftware programming languages. Second, the pre-trained LLMs, mainly tailored\nfor software code, tend to produce HDL designs that are more error-prone.\nThird, the generation of HDL requires a significantly higher number of tokens\ncompared to software programming, leading to inefficiencies in cost and energy\nconsumption. To tackle these challenges, this paper explores leveraging LLMs to\ngenerate High-Level Synthesis (HLS)-based hardware design. Although code\ngeneration for domain-specific programming languages is not new in the\nliterature, we aim to provide experimental results, insights, benchmarks, and\nevaluation infrastructure to investigate the suitability of HLS over low-level\nHDLs for LLM-assisted hardware design generation. To achieve this, we first\nfinetune pre-trained models for HLS-based hardware generation, using a\ncollected dataset with text prompts and corresponding reference HLS designs. An\nLLM-assisted framework is then proposed to automate end-to-end hardware code\ngeneration, which also investigates the impact of chain-of-thought and feedback\nloops promoting techniques on HLS-design generation. Limited by the timeframe\nof this research, we plan to evaluate more advanced reasoning models in the\nfuture.\n","authors":["Jiahao Gai","Hao Mark Chen","Zhican Wang","Hongyu Zhou","Wanru Zhao","Nicholas Lane","Hongxiang Fan"],"pdf_url":"https://arxiv.org/pdf/2502.13921v2.pdf","comment":"Paper accepted by ASP-DAC'25"},{"id":"http://arxiv.org/abs/2409.06615v5","updated":"2025-03-05T16:07:20Z","published":"2024-09-10T16:11:57Z","title":"One-Shot Imitation under Mismatched Execution","summary":"  Human demonstrations as prompts are a powerful way to program robots to do\nlong-horizon manipulation tasks. However, translating these demonstrations into\nrobot-executable actions presents significant challenges due to execution\nmismatches in movement styles and physical capabilities. Existing methods\neither depend on human-robot paired data, which is infeasible to scale, or rely\nheavily on frame-level visual similarities that often break down in practice.\nTo address these challenges, we propose RHyME, a novel framework that\nautomatically aligns human and robot task executions using optimal transport\ncosts. Given long-horizon robot demonstrations, RHyME synthesizes semantically\nequivalent human videos by retrieving and composing short-horizon human clips.\nThis approach facilitates effective policy training without the need for paired\ndata. RHyME successfully imitates a range of cross-embodiment demonstrators,\nboth in simulation and with a real human hand, achieving over 50\\% increase in\ntask success compared to previous methods. We release our code and datasets at\nhttps://portal-cornell.github.io/rhyme/.\n","authors":["Kushal Kedia","Prithwish Dan","Angela Chao","Maximus Adrian Pace","Sanjiban Choudhury"],"pdf_url":"https://arxiv.org/pdf/2409.06615v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03625v1","updated":"2025-03-05T16:05:26Z","published":"2025-03-05T16:05:26Z","title":"Deterministic Global Optimization of the Acquisition Function in\n  Bayesian Optimization: To Do or Not To Do?","summary":"  Bayesian Optimization (BO) with Gaussian Processes relies on optimizing an\nacquisition function to determine sampling. We investigate the advantages and\ndisadvantages of using a deterministic global solver (MAiNGO) compared to\nconventional local and stochastic global solvers (L-BFGS-B and multi-start,\nrespectively) for the optimization of the acquisition function. For CPU\nefficiency, we set a time limit for MAiNGO, taking the best point as optimal.\nWe perform repeated numerical experiments, initially using the Muller-Brown\npotential as a benchmark function, utilizing the lower confidence bound\nacquisition function; we further validate our findings with three alternative\nbenchmark functions. Statistical analysis reveals that when the acquisition\nfunction is more exploitative (as opposed to exploratory), BO with MAiNGO\nconverges in fewer iterations than with the local solvers. However, when the\ndataset lacks diversity, or when the acquisition function is overly\nexploitative, BO with MAiNGO, compared to the local solvers, is more likely to\nconverge to a local rather than a global ly near-optimal solution of the\nblack-box function. L-BFGS-B and multi-start mitigate this risk in BO by\nintroducing stochasticity in the selection of the next sampling point, which\nenhances the exploration of uncharted regions in the search space and reduces\ndependence on acquisition function hyperparameters. Ultimately, suboptimal\noptimization of poorly chosen acquisition functions may be preferable to their\noptimal solution. When the acquisition function is more exploratory, BO with\nMAiNGO, multi-start, and L-BFGS-B achieve comparable probabilities of\nconvergence to a globally near-optimal solution (although BO with MAiNGO may\nrequire more iterations to converge under these conditions).\n","authors":["Anastasia Georgiou","Daniel Jungen","Luise Kaven","Verena Hunstig","Constantine Frangakis","Ioannis Kevrekidis","Alexander Mitsos"],"pdf_url":"https://arxiv.org/pdf/2503.03625v1.pdf","comment":"32 pages, 7 figures, 7 tables"},{"id":"http://arxiv.org/abs/2503.03622v1","updated":"2025-03-05T16:02:09Z","published":"2025-03-05T16:02:09Z","title":"It's My Data Too: Private ML for Datasets with Multi-User Training\n  Examples","summary":"  We initiate a study of algorithms for model training with user-level\ndifferential privacy (DP), where each example may be attributed to multiple\nusers, which we call the multi-attribution model. We first provide a carefully\nchosen definition of user-level DP under the multi-attribution model. Training\nin the multi-attribution model is facilitated by solving the contribution\nbounding problem, i.e. the problem of selecting a subset of the dataset for\nwhich each user is associated with a limited number of examples. We propose a\ngreedy baseline algorithm for the contribution bounding problem. We then\nempirically study this algorithm for a synthetic logistic regression task and a\ntransformer training task, including studying variants of this baseline\nalgorithm that optimize the subset chosen using different techniques and\ncriteria. We find that the baseline algorithm remains competitive with its\nvariants in most settings, and build a better understanding of the practical\nimportance of a bias-variance tradeoff inherent in solutions to the\ncontribution bounding problem.\n","authors":["Arun Ganesh","Ryan McKenna","Brendan McMahan","Adam Smith","Fan Wu"],"pdf_url":"https://arxiv.org/pdf/2503.03622v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.06712v4","updated":"2025-03-05T15:40:42Z","published":"2024-07-09T09:39:45Z","title":"MDP Geometry, Normalization and Reward Balancing Solvers","summary":"  We present a new geometric interpretation of Markov Decision Processes (MDPs)\nwith a natural normalization procedure that allows us to adjust the value\nfunction at each state without altering the advantage of any action with\nrespect to any policy. This advantage-preserving transformation of the MDP\nmotivates a class of algorithms which we call Reward Balancing, which solve\nMDPs by iterating through these transformations, until an approximately optimal\npolicy can be trivially found. We provide a convergence analysis of several\nalgorithms in this class, in particular showing that for MDPs for unknown\ntransition probabilities we can improve upon state-of-the-art sample complexity\nresults.\n","authors":["Arsenii Mustafin","Aleksei Pakharev","Alex Olshevsky","Ioannis Ch. Paschalidis"],"pdf_url":"https://arxiv.org/pdf/2407.06712v4.pdf","comment":"AISTATS 2025 camera-ready version"},{"id":"http://arxiv.org/abs/2501.06058v3","updated":"2025-03-05T15:37:52Z","published":"2025-01-10T15:39:39Z","title":"Capability-Aware Shared Hypernetworks for Flexible Heterogeneous\n  Multi-Robot Coordination","summary":"  Recent advances have enabled heterogeneous multi-robot teams to learn complex\nand effective coordination. However, existing architectural designs that\nsupport heterogeneous teams tend to force a trade-off between expressivity and\nefficiency. Some attempt to encode diverse behaviors within a single shared\narchitecture by appending the input with an ID unique to each robot or robot\ntype. These designs improve sample and parameter efficiency but tend to limit\nbehavioral diversity. Others use a separate policy for each robot, enabling\ngreater diversity at the cost of efficiency and generalization. We view these\ntwo designs as ends of a spectrum and explore a middle-ground approach that\nenables efficient learning of diverse behaviors. Inspired by work in transfer\nlearning and meta RL, and building upon prior work in trait-based task\nallocation, we propose Capability-Aware Shared Hypernetworks (CASH), a\ngeneral-purpose soft weight sharing architecture that uses hypernetworks to\nenable a single architecture to dynamically adapt to each robot and the current\ncontext. Intuitively, CASH encodes shared decision making strategies that can\nbe adapted to each robot based on local observations and the robots' individual\nand collective capabilities (e.g., speed and payload). CASH explicitly captures\nthe impact of capabilities on collective behavior, enabling zero-shot\ngeneralization to unseen robots or team compositions. We conducted experiments\nacross four heterogeneous coordination tasks and three learning paradigms\n(imitation learning, value-based, and policy-gradient RL) using SOTA\nmulti-robot simulation (JaxMARL) and hardware (Robotarium) platforms. Across\nall conditions, CASH generates appropriately diverse behaviors and outperforms\nbaseline architectures in task performance and sample efficiency during\ntraining and zero-shot generalization while utilizing 60%-80% fewer learnable\nparameters.\n","authors":["Kevin Fu","Shalin Jain","Pierce Howell","Harish Ravichandar"],"pdf_url":"https://arxiv.org/pdf/2501.06058v3.pdf","comment":"16 pages, 8 figures, equal authorship between Kevin Fu and Shalin\n  Jain"},{"id":"http://arxiv.org/abs/2409.16720v2","updated":"2025-03-05T15:35:47Z","published":"2024-09-25T08:09:52Z","title":"Dashing for the Golden Snitch: Multi-Drone Time-Optimal Motion Planning\n  with Multi-Agent Reinforcement Learning","summary":"  Recent innovations in autonomous drones have facilitated time-optimal flight\nin single-drone configurations, and enhanced maneuverability in multi-drone\nsystems by applying optimal control and learning-based methods. However, few\nstudies have achieved time-optimal motion planning for multi-drone systems,\nparticularly during highly agile maneuvers or in dynamic scenarios. This paper\npresents a decentralized policy network using multi-agent reinforcement\nlearning for time-optimal multi-drone flight. To strike a balance between\nflight efficiency and collision avoidance, we introduce a soft collision-free\nmechanism inspired by optimization-based methods. By customizing PPO in a\ncentralized training, decentralized execution (CTDE) fashion, we unlock higher\nefficiency and stability in training while ensuring lightweight implementation.\nExtensive simulations show that, despite slight performance trade-offs compared\nto single-drone systems, our multi-drone approach maintains near-time-optimal\nperformance with a low collision rate. Real-world experiments validate our\nmethod, with two quadrotors using the same network as in simulation achieving a\nmaximum speed of 13.65 m/s and a maximum body rate of 13.4 rad/s in a 5.5 m *\n5.5 m * 2.0 m space across various tracks, relying entirely on onboard\ncomputation.\n","authors":["Xian Wang","Jin Zhou","Yuanli Feng","Jiahao Mei","Jiming Chen","Shuo Li"],"pdf_url":"https://arxiv.org/pdf/2409.16720v2.pdf","comment":"v2: 7 pages, 6 figures; terminology corrected, algorithmic and\n  equation descriptions revised, references added"},{"id":"http://arxiv.org/abs/2405.15389v3","updated":"2025-03-05T15:35:35Z","published":"2024-05-24T09:41:06Z","title":"Beyond Canonicalization: How Tensorial Messages Improve Equivariant\n  Message Passing","summary":"  In numerous applications of geometric deep learning, the studied systems\nexhibit spatial symmetries and it is desirable to enforce these. For the\nsymmetry of global rotations and reflections, this means that the model should\nbe equivariant with respect to the transformations that form the group of\n$\\mathrm O(d)$. While many approaches for equivariant message passing require\nspecialized architectures, including non-standard normalization layers or\nnon-linearities, we here present a framework based on local reference frames\n(\"local canonicalization\") which can be integrated with any architecture\nwithout restrictions. We enhance equivariant message passing based on local\ncanonicalization by introducing tensorial messages to communicate geometric\ninformation consistently between different local coordinate frames. Our\nframework applies to message passing on geometric data in Euclidean spaces of\narbitrary dimension. We explicitly show how our approach can be adapted to make\na popular existing point cloud architecture equivariant. We demonstrate the\nsuperiority of tensorial messages and achieve state-of-the-art results on\nnormal vector regression and competitive results on other standard 3D point\ncloud tasks.\n","authors":["Peter Lippmann","Gerrit Gerhartz","Roman Remme","Fred A. Hamprecht"],"pdf_url":"https://arxiv.org/pdf/2405.15389v3.pdf","comment":"To be published in proceedings of ICLR 2025"},{"id":"http://arxiv.org/abs/2412.00980v2","updated":"2025-03-05T15:32:01Z","published":"2024-12-01T22:04:12Z","title":"Incentivizing Truthful Collaboration in Heterogeneous Federated Learning","summary":"  Federated learning (FL) is a distributed collaborative learning method, where\nmultiple clients learn together by sharing gradient updates instead of raw\ndata. However, it is well-known that FL is vulnerable to manipulated updates\nfrom clients. In this work we study the impact of data heterogeneity on\nclients' incentives to manipulate their updates. First, we present\nheterogeneous collaborative learning scenarios where a client can modify their\nupdates to be better off, and show that these manipulations can lead to\ndiminishing model performance. To prevent such modifications, we formulate a\ngame in which clients may misreport their gradient updates in order to \"steer\"\nthe server model to their advantage. We develop a payment rule that provably\ndisincentivizes sending modified updates under the FedSGD protocol. We derive\nexplicit bounds on the clients' payments and the convergence rate of the global\nmodel, which allows us to study the trade-off between heterogeneity, payments\nand convergence. Finally, we provide an experimental evaluation of the\neffectiveness of our payment rule in the FedSGD, median-based aggregation\nFedSGD and FedAvg protocols on three tasks in computer vision and natural\nlanguage processing. In all cases we find that our scheme successfully\ndisincentivizes modifications.\n","authors":["Dimitar Chakarov","Nikita Tsoy","Kristian Minchev","Nikola Konstantinov"],"pdf_url":"https://arxiv.org/pdf/2412.00980v2.pdf","comment":"29 pages, 8 figures"},{"id":"http://arxiv.org/abs/2503.03595v1","updated":"2025-03-05T15:28:50Z","published":"2025-03-05T15:28:50Z","title":"Towards Understanding Text Hallucination of Diffusion Models via Local\n  Generation Bias","summary":"  Score-based diffusion models have achieved incredible performance in\ngenerating realistic images, audio, and video data. While these models produce\nhigh-quality samples with impressive details, they often introduce unrealistic\nartifacts, such as distorted fingers or hallucinated texts with no meaning.\nThis paper focuses on textual hallucinations, where diffusion models correctly\ngenerate individual symbols but assemble them in a nonsensical manner. Through\nexperimental probing, we consistently observe that such phenomenon is\nattributed it to the network's local generation bias. Denoising networks tend\nto produce outputs that rely heavily on highly correlated local regions,\nparticularly when different dimensions of the data distribution are nearly\npairwise independent. This behavior leads to a generation process that\ndecomposes the global distribution into separate, independent distributions for\neach symbol, ultimately failing to capture the global structure, including\nunderlying grammar. Intriguingly, this bias persists across various denoising\nnetwork architectures including MLP and transformers which have the structure\nto model global dependency. These findings also provide insights into\nunderstanding other types of hallucinations, extending beyond text, as a result\nof implicit biases in the denoising models. Additionally, we theoretically\nanalyze the training dynamics for a specific case involving a two-layer MLP\nlearning parity points on a hypercube, offering an explanation of its\nunderlying mechanism.\n","authors":["Rui Lu","Runzhe Wang","Kaifeng Lyu","Xitai Jiang","Gao Huang","Mengdi Wang"],"pdf_url":"https://arxiv.org/pdf/2503.03595v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.01999v2","updated":"2025-03-05T15:26:17Z","published":"2025-01-01T07:00:41Z","title":"On the Utility of Equivariance and Symmetry Breaking in Deep Learning\n  Architectures on Point Clouds","summary":"  This paper explores the key factors that influence the performance of models\nworking with point clouds, across different tasks of varying geometric\ncomplexity. In this work, we explore the trade-offs between flexibility and\nweight-sharing introduced by equivariant layers, assessing when equivariance\nboosts or detracts from performance. It is often argued that providing more\ninformation as input improves a model's performance. However, if this\nadditional information breaks certain properties, such as $\\SE(3)$\nequivariance, does it remain beneficial? We identify the key aspects of\nequivariant and non-equivariant architectures that drive success in different\ntasks by benchmarking them on segmentation, regression, and generation tasks\nacross multiple datasets with increasing complexity. We observe a positive\nimpact of equivariance, which becomes more pronounced with increasing task\ncomplexity, even when strict equivariance is not required.\n","authors":["Sharvaree Vadgama","Mohammad Mohaiminul Islam","Domas Buracus","Christian Shewmake","Erik Bekkers"],"pdf_url":"https://arxiv.org/pdf/2501.01999v2.pdf","comment":"19 pages, 4 figures"},{"id":"http://arxiv.org/abs/2503.03588v1","updated":"2025-03-05T15:24:11Z","published":"2025-03-05T15:24:11Z","title":"PowerAttention: Exponentially Scaling of Receptive Fields for Effective\n  Sparse Attention","summary":"  Large Language Models (LLMs) face efficiency bottlenecks due to the quadratic\ncomplexity of the attention mechanism when processing long contexts. Sparse\nattention methods offer a promising solution, but existing approaches often\nsuffer from incomplete effective context and/or require complex implementation\nof pipeline. We present a comprehensive analysis of sparse attention for\nautoregressive LLMs from the respective of receptive field, recognize the\nsuboptimal nature of existing methods for expanding the receptive field, and\nintroduce PowerAttention, a novel sparse attention design that facilitates\neffective and complete context extension through the theoretical analysis.\nPowerAttention achieves exponential receptive field growth in $d$-layer LLMs,\nallowing each output token to attend to $2^d$ tokens, ensuring completeness and\ncontinuity of the receptive field. Experiments demonstrate that PowerAttention\noutperforms existing static sparse attention methods by $5\\sim 40\\%$,\nespecially on tasks demanding long-range dependencies like Passkey Retrieval\nand RULER, while maintaining a comparable time complexity to sliding window\nattention. Efficiency evaluations further highlight PowerAttention's superior\nspeedup in both prefilling and decoding phases compared with dynamic sparse\nattentions and full attention ($3.0\\times$ faster on 128K context), making it a\nhighly effective and user-friendly solution for processing long sequences in\nLLMs.\n","authors":["Lida Chen","Dong Xu","Chenxin An","Xintao Wang","Yikai Zhang","Jiangjie Chen","Zujie Liang","Feng Wei","Jiaqing Liang","Yanghua Xiao","Wei Wang"],"pdf_url":"https://arxiv.org/pdf/2503.03588v1.pdf","comment":"for associated code, see https://github.com/w568w/PowerAttention"},{"id":"http://arxiv.org/abs/2503.03579v1","updated":"2025-03-05T15:13:54Z","published":"2025-03-05T15:13:54Z","title":"A Generative System for Robot-to-Human Handovers: from Intent Inference\n  to Spatial Configuration Imagery","summary":"  We propose a novel system for robot-to-human object handover that emulates\nhuman coworker interactions. Unlike most existing studies that focus primarily\non grasping strategies and motion planning, our system focus on 1. inferring\nhuman handover intents, 2. imagining spatial handover configuration. The first\none integrates multimodal perception-combining visual and verbal cues-to infer\nhuman intent. The second one using a diffusion-based model to generate the\nhandover configuration, involving the spacial relationship among robot's\ngripper, the object, and the human hand, thereby mimicking the cognitive\nprocess of motor imagery. Experimental results demonstrate that our approach\neffectively interprets human cues and achieves fluent, human-like handovers,\noffering a promising solution for collaborative robotics. Code, videos, and\ndata are available at: https://i3handover.github.io.\n","authors":["Hanxin Zhang","Abdulqader Dhafer","Zhou Daniel Hao","Hongbiao Dong"],"pdf_url":"https://arxiv.org/pdf/2503.03579v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.12395v2","updated":"2025-03-05T15:10:51Z","published":"2025-02-18T00:06:40Z","title":"Efficient Neural SDE Training using Wiener-Space Cubature","summary":"  A neural stochastic differential equation (SDE) is an SDE with drift and\ndiffusion terms parametrized by neural networks. The training procedure for\nneural SDEs consists of optimizing the SDE vector field (neural network)\nparameters to minimize the expected value of an objective functional on\ninfinite-dimensional path-space. Existing training techniques focus on methods\nto efficiently compute path-wise gradients of the objective functional with\nrespect to these parameters, then pair this with Monte-Carlo simulation to\nestimate the expectation, and stochastic gradient descent to optimize. In this\nwork we introduce a novel training technique which bypasses and improves upon\nMonte-Carlo simulation; we extend results in the theory of Wiener-space\ncubature to approximate the expected objective functional by a weighted sum of\ndeterministic ODE solutions. This allows us to compute gradients by efficient\nODE adjoint methods. Furthermore, we exploit a high-order recombination scheme\nto drastically reduce the number of ODE solutions necessary to achieve a\nreasonable approximation. We show that this Wiener-space cubature approach can\nsurpass the O(1/sqrt(n)) rate of Monte-Carlo simulation, or the O(log(n)/n)\nrate of quasi-Monte-Carlo, to achieve a O(1/n) rate under reasonable\nassumptions.\n","authors":["Luke Snow","Vikram Krishnamurthy"],"pdf_url":"https://arxiv.org/pdf/2502.12395v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03576v1","updated":"2025-03-05T15:02:46Z","published":"2025-03-05T15:02:46Z","title":"Optimal Decision Tree Pruning Revisited: Algorithms and Complexity","summary":"  We present a comprehensive classical and parameterized complexity analysis of\ndecision tree pruning operations, extending recent research on the complexity\nof learning small decision trees. Thereby, we offer new insights into the\ncomputational challenges of decision tree simplification, a crucial aspect of\ndeveloping interpretable and efficient machine learning models. We focus on\nfundamental pruning operations of subtree replacement and raising, which are\nused in heuristics. Surprisingly, while optimal pruning can be performed in\npolynomial time for subtree replacement, the problem is NP-complete for subtree\nraising. Therefore, we identify parameters and combinations thereof that lead\nto fixed-parameter tractability or hardness, establishing a precise borderline\nbetween these complexity classes. For example, while subtree raising is hard\nfor small domain size $D$ or number $d$ of features, it can be solved in\n$D^{2d} \\cdot |I|^{O(1)}$ time, where $|I|$ is the input size. We complement\nour theoretical findings with preliminary experimental results, demonstrating\nthe practical implications of our analysis.\n","authors":["Juha Harviainen","Frank Sommer","Manuel Sorge","Stefan Szeider"],"pdf_url":"https://arxiv.org/pdf/2503.03576v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03574v1","updated":"2025-03-05T15:01:56Z","published":"2025-03-05T15:01:56Z","title":"Olympus: A Jumping Quadruped for Planetary Exploration Utilizing\n  Reinforcement Learning for In-Flight Attitude Control","summary":"  Exploring planetary bodies with lower gravity, such as the moon and Mars,\nallows legged robots to utilize jumping as an efficient form of locomotion thus\ngiving them a valuable advantage over traditional rovers for exploration.\nMotivated by this fact, this paper presents the design, simulation, and\nlearning-based \"in-flight\" attitude control of Olympus, a jumping legged robot\ntailored to the gravity of Mars. First, the design requirements are outlined\nfollowed by detailing how simulation enabled optimizing the robot's design -\nfrom its legs to the overall configuration - towards high vertical jumping,\nforward jumping distance, and in-flight attitude reorientation. Subsequently,\nthe reinforcement learning policy used to track desired in-flight attitude\nmaneuvers is presented. Successfully crossing the sim2real gap, extensive\nexperimental studies of attitude reorientation tests are demonstrated.\n","authors":["Jørgen Anker Olsen","Grzegorz Malczyk","Kostas Alexis"],"pdf_url":"https://arxiv.org/pdf/2503.03574v1.pdf","comment":"7 pages, 6 figures, Accepted to the IEEE International Conference on\n  Robotics and Automation (ICRA) 2025"},{"id":"http://arxiv.org/abs/2503.03571v1","updated":"2025-03-05T15:00:39Z","published":"2025-03-05T15:00:39Z","title":"Domain Consistent Industrial Decarbonisation of Global Coal Power Plants","summary":"  Machine learning and optimisation techniques (MLOPT) hold significant\npotential to accelerate the decarbonisation of industrial systems by enabling\ndata-driven operational improvements. However, the practical application of\nMLOPT in industrial settings is often hindered by a lack of domain compliance\nand system-specific consistency, resulting in suboptimal solutions with limited\nreal-world applicability. To address this challenge, we propose a novel\nhuman-in-the-loop (HITL) constraint-based optimisation framework that\nintegrates domain expertise with data-driven methods, ensuring solutions are\nboth technically sound and operationally feasible. We demonstrate the efficacy\nof this framework through a case study focused on enhancing the thermal\nefficiency and reducing the turbine heat rate of a 660 MW supercritical\ncoal-fired power plant. By embedding domain knowledge as constraints within the\noptimisation process, our approach yields solutions that align with the plant's\noperational patterns and are seamlessly integrated into its control systems.\nEmpirical validation confirms a mean improvement in thermal efficiency of\n0.64\\% and a mean reduction in turbine heat rate of 93 kJ/kWh. Scaling our\nanalysis to 59 global coal power plants with comparable capacity and fuel type,\nwe estimate a cumulative lifetime reduction of 156.4 million tons of carbon\nemissions. These results underscore the transformative potential of our\nHITL-MLOPT framework in delivering domain-compliant, implementable solutions\nfor industrial decarbonisation, offering a scalable pathway to mitigate the\nenvironmental impact of coal-based power generation worldwide.\n","authors":["Waqar Muhammad Ashraf","Vivek Dua","Ramit Debnath"],"pdf_url":"https://arxiv.org/pdf/2503.03571v1.pdf","comment":"6 figures. 17 pages"},{"id":"http://arxiv.org/abs/2503.03565v1","updated":"2025-03-05T14:53:32Z","published":"2025-03-05T14:53:32Z","title":"Probabilistic Insights for Efficient Exploration Strategies in\n  Reinforcement Learning","summary":"  We investigate efficient exploration strategies of environments with unknown\nstochastic dynamics and sparse rewards. Specifically, we analyze first the\nimpact of parallel simulations on the probability of reaching rare states\nwithin a finite time budget. Using simplified models based on random walks and\nL\\'evy processes, we provide analytical results that demonstrate a phase\ntransition in reaching probabilities as a function of the number of parallel\nsimulations. We identify an optimal number of parallel simulations that\nbalances exploration diversity and time allocation. Additionally, we analyze a\nrestarting mechanism that exponentially enhances the probability of success by\nredirecting efforts toward more promising regions of the state space. Our\nfindings contribute to a more qualitative and quantitative theory of some\nexploration schemes in reinforcement learning, offering insights into\ndeveloping more efficient strategies for environments characterized by rare\nevents.\n","authors":["Ernesto Garcia","Paola Bermolen","Matthieu Jonckheere","Seva Shneer"],"pdf_url":"https://arxiv.org/pdf/2503.03565v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03561v1","updated":"2025-03-05T14:49:06Z","published":"2025-03-05T14:49:06Z","title":"Transformer-Based Power Optimization for Max-Min Fairness in Cell-Free\n  Massive MIMO","summary":"  Power allocation is an important task in wireless communication networks.\nClassical optimization algorithms and deep learning methods, while effective in\nsmall and static scenarios, become either computationally demanding or\nunsuitable for large and dynamic networks with varying user loads. This letter\nexplores the potential of transformer-based deep learning models to address\nthese challenges. We propose a transformer neural network to jointly predict\noptimal uplink and downlink power using only user and access point positions.\nThe max-min fairness problem in cell-free massive multiple input multiple\noutput systems is considered. Numerical results show that the trained model\nprovides near-optimal performance and adapts to varying numbers of users and\naccess points without retraining, additional processing, or updating its neural\nnetwork architecture. This demonstrates the effectiveness of the proposed model\nin achieving robust and flexible power allocation for dynamic networks.\n","authors":["Irched Chafaa","Giacomo Bacci","Luca Sanguinetti"],"pdf_url":"https://arxiv.org/pdf/2503.03561v1.pdf","comment":"5 pages, IEEE WCL, 4 FIGURES"},{"id":"http://arxiv.org/abs/2407.16205v5","updated":"2025-03-05T14:43:33Z","published":"2024-07-23T06:14:41Z","title":"LLMs can be Dangerous Reasoners: Analyzing-based Jailbreak Attack on\n  Large Language Models","summary":"  The rapid development of Large Language Models (LLMs) has brought significant\nadvancements across various tasks. However, despite these achievements, LLMs\nstill exhibit inherent safety vulnerabilities, especially when confronted with\njailbreak attacks. Existing jailbreak methods suffer from two main limitations:\nreliance on complicated prompt engineering and iterative optimization, which\nlead to low attack success rate (ASR) and attack efficiency (AE). In this work,\nwe propose an efficient jailbreak attack method, Analyzing-based Jailbreak\n(ABJ), which leverages the advanced reasoning capability of LLMs to\nautonomously generate harmful content, revealing their underlying safety\nvulnerabilities during complex reasoning process. We conduct comprehensive\nexperiments on ABJ across various open-source and closed-source LLMs. In\nparticular, ABJ achieves high ASR (82.1% on GPT-4o-2024-11-20) with exceptional\nAE among all target LLMs, showcasing its remarkable attack effectiveness,\ntransferability, and efficiency. Our findings underscore the urgent need to\nprioritize and improve the safety of LLMs to mitigate the risks of misuse.\n","authors":["Shi Lin","Hongming Yang","Dingyang Lin","Rongchang Li","Xun Wang","Changting Lin","Wenpeng Xing","Meng Han"],"pdf_url":"https://arxiv.org/pdf/2407.16205v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.07115v3","updated":"2025-03-05T14:43:01Z","published":"2025-02-10T23:11:44Z","title":"Online Scheduling for LLM Inference with KV Cache Constraints","summary":"  Large Language Model (LLM) inference, where a trained model generates text\none word at a time in response to user prompts, is a computationally intensive\nprocess requiring efficient scheduling to optimize latency and resource\nutilization. A key challenge in LLM inference is the management of the\nKey-Value (KV) cache, which reduces redundant computations but introduces\nmemory constraints. In this work, we model LLM inference with KV cache\nconstraints theoretically and propose novel batching and scheduling algorithms\nthat minimize inference latency while effectively managing the KV cache's\nmemory.\n  We analyze both semi-online and fully online scheduling models, and our\nresults are threefold. First, we provide a polynomial-time algorithm that\nachieves exact optimality in terms of average latency in the semi-online prompt\narrival model. Second, in the fully online case with a stochastic prompt\narrival, we introduce an efficient online scheduling algorithm with constant\nregret. Third, we prove that no algorithm (deterministic or randomized) can\nachieve a constant competitive ratio in fully online adversarial settings. Our\nempirical evaluations on a public LLM inference dataset, using the Llama-70B\nmodel on A100 GPUs, show that our approach significantly outperforms benchmark\nalgorithms used currently in practice, achieving lower latency while reducing\nenergy consumption. Overall, our results offer a path toward more sustainable\nand cost-effective LLM deployment.\n","authors":["Patrick Jaillet","Jiashuo Jiang","Chara Podimata","Zijie Zhou"],"pdf_url":"https://arxiv.org/pdf/2502.07115v3.pdf","comment":"Will add a lemma in the proof of Theorem 5.3 to make the statement\n  and proof more rigorous"},{"id":"http://arxiv.org/abs/2503.03548v1","updated":"2025-03-05T14:32:32Z","published":"2025-03-05T14:32:32Z","title":"Simulation-Based Performance Evaluation of 3D Object Detection Methods\n  with Deep Learning for a LiDAR Point Cloud Dataset in a SOTIF-related Use\n  Case","summary":"  Safety of the Intended Functionality (SOTIF) addresses sensor performance\nlimitations and deep learning-based object detection insufficiencies to ensure\nthe intended functionality of Automated Driving Systems (ADS). This paper\npresents a methodology examining the adaptability and performance evaluation of\nthe 3D object detection methods on a LiDAR point cloud dataset generated by\nsimulating a SOTIF-related Use Case. The major contributions of this paper\ninclude defining and modelling a SOTIF-related Use Case with 21 diverse weather\nconditions and generating a LiDAR point cloud dataset suitable for application\nof 3D object detection methods. The dataset consists of 547 frames,\nencompassing clear, cloudy, rainy weather conditions, corresponding to\ndifferent times of the day, including noon, sunset, and night. Employing\nMMDetection3D and OpenPCDET toolkits, the performance of State-of-the-Art\n(SOTA) 3D object detection methods is evaluated and compared by testing the\npre-trained Deep Learning (DL) models on the generated dataset using Average\nPrecision (AP) and Recall metrics.\n","authors":["Milin Patel","Rolf Jung"],"pdf_url":"https://arxiv.org/pdf/2503.03548v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03545v1","updated":"2025-03-05T14:28:38Z","published":"2025-03-05T14:28:38Z","title":"Revisiting the Role of Relearning in Semantic Dementia","summary":"  Patients with semantic dementia (SD) present with remarkably consistent\natrophy of neurons in the anterior temporal lobe and behavioural impairments,\nsuch as graded loss of category knowledge. While relearning of lost knowledge\nhas been shown in acute brain injuries such as stroke, it has not been widely\nsupported in chronic cognitive diseases such as SD. Previous research has shown\nthat deep linear artificial neural networks exhibit stages of semantic learning\nakin to humans. Here, we use a deep linear network to test the hypothesis that\nrelearning during disease progression rather than particular atrophy cause the\nspecific behavioural patterns associated with SD. After training the network to\ngenerate the common semantic features of various hierarchically organised\nobjects, neurons are successively deleted to mimic atrophy while retraining the\nmodel. The model with relearning and deleted neurons reproduced errors specific\nto SD, including prototyping errors and cross-category confusions. This\nsuggests that relearning is necessary for artificial neural networks to\nreproduce the behavioural patterns associated with SD in the absence of\n\\textit{output} non-linearities. Our results support a theory of SD progression\nthat results from continuous relearning of lost information. Future research\nshould revisit the role of relearning as a contributing factor to cognitive\ndiseases.\n","authors":["Devon Jarvis","Verena Klar","Richard Klein","Benjamin Rosman","Andrew Saxe"],"pdf_url":"https://arxiv.org/pdf/2503.03545v1.pdf","comment":"3 pages, 2 figures, presented at the Cognitive Computational\n  Neuroscience Conference (CCN) 2023"},{"id":"http://arxiv.org/abs/2409.16502v2","updated":"2025-03-05T14:11:44Z","published":"2024-09-24T23:18:32Z","title":"GSplatLoc: Grounding Keypoint Descriptors into 3D Gaussian Splatting for\n  Improved Visual Localization","summary":"  Although various visual localization approaches exist, such as scene\ncoordinate regression and camera pose regression, these methods often struggle\nwith optimization complexity or limited accuracy. To address these challenges,\nwe explore the use of novel view synthesis techniques, particularly 3D Gaussian\nSplatting (3DGS), which enables the compact encoding of both 3D geometry and\nscene appearance. We propose a two-stage procedure that integrates dense and\nrobust keypoint descriptors from the lightweight XFeat feature extractor into\n3DGS, enhancing performance in both indoor and outdoor environments. The coarse\npose estimates are directly obtained via 2D-3D correspondences between the 3DGS\nrepresentation and query image descriptors. In the second stage, the initial\npose estimate is refined by minimizing the rendering-based photometric warp\nloss. Benchmarking on widely used indoor and outdoor datasets demonstrates\nimprovements over recent neural rendering-based localization methods, such as\nNeRFMatch and PNeRFLoc.\n","authors":["Gennady Sidorov","Malik Mohrat","Denis Gridusov","Ruslan Rakhimov","Sergey Kolyubin"],"pdf_url":"https://arxiv.org/pdf/2409.16502v2.pdf","comment":"Project website at https://gsplatloc.github.io/"},{"id":"http://arxiv.org/abs/2503.03524v1","updated":"2025-03-05T14:08:53Z","published":"2025-03-05T14:08:53Z","title":"Intrinsic and Extrinsic Factor Disentanglement for Recommendation in\n  Various Context Scenarios","summary":"  In recommender systems, the patterns of user behaviors (e.g., purchase,\nclick) may vary greatly in different contexts (e.g., time and location). This\nis because user behavior is jointly determined by two types of factors:\nintrinsic factors, which reflect consistent user preference, and extrinsic\nfactors, which reflect external incentives that may vary in different contexts.\nDifferentiating between intrinsic and extrinsic factors helps learn user\nbehaviors better. However, existing studies have only considered\ndifferentiating them from a single, pre-defined context (e.g., time or\nlocation), ignoring the fact that a user's extrinsic factors may be influenced\nby the interplay of various contexts at the same time. In this paper, we\npropose the Intrinsic-Extrinsic Disentangled Recommendation (IEDR) model, a\ngeneric framework that differentiates intrinsic from extrinsic factors\nconsidering various contexts simultaneously, enabling more accurate\ndifferentiation of factors and hence the improvement of recommendation\naccuracy. IEDR contains a context-invariant contrastive learning component to\ncapture intrinsic factors, and a disentanglement component to extract extrinsic\nfactors under the interplay of various contexts. The two components work\ntogether to achieve effective factor learning. Extensive experiments on\nreal-world datasets demonstrate IEDR's effectiveness in learning disentangled\nfactors and significantly improving recommendation accuracy by up to 4% in\nNDCG.\n","authors":["Yixin Su","Wei Jiang","Fangquan Lin","Cheng Yang","Sarah M. Erfani","Junhao Gan","Yunxiang Zhao","Ruixuan Li","Rui Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.03524v1.pdf","comment":"32 pages, 13 figures, 11 tables. Accepted by Transactions of\n  Information Systems"},{"id":"http://arxiv.org/abs/2503.03523v1","updated":"2025-03-05T14:07:29Z","published":"2025-03-05T14:07:29Z","title":"O-RAN xApps Conflict Management using Graph Convolutional Networks","summary":"  Open Radio Access Network (O-RAN) adopts a flexible, open, and virtualized\nstructure with standardized interfaces, reducing dependency on a single\nsupplier. Conflict management in O-RAN refers to the process of identifying and\nresolving conflicts between network applications. xApps are applications\ndeployed at the RAN Intelligent Controller (RIC) that leverage advanced AI/ML\nalgorithms to make dynamic decisions for network optimization. The lack of a\nunified mechanism to coordinate and prioritize the actions of different\napplications can create three types of conflicts (direct, indirect, and\nimplicit). In our paper, we introduce a novel data-driven GCN-based method\ncalled Graph-based xApps Conflict and Root Cause Analysis Engine (GRACE) based\non Graph Convolutional Network (GCN). It detects three types of conflicts\n(direct, indirect, and implicit) and pinpoints the root causes (xApps). GRACE\ncaptures the complex and hidden dependencies among the xApps, the controlled\nparameters, and the KPIs in O-RAN to detect possible conflicts. Then, it\nidentifies the root causes (xApps) contributing to the detected conflicts. The\nproposed method was tested on highly imbalanced datasets where the number of\nconflict instances ranges from 40% to 10%. The model is tested in a setting\nthat simulates real-world scenarios where conflicts are rare to assess its\nperformance and generalizability. Experimental results demonstrate an\nexceptional performance, achieving a high F1-score greater than 98% for all the\ncase studies.\n","authors":["Maryam Al Shami","Jun Yan","Emmanuel Thepie Fapi"],"pdf_url":"https://arxiv.org/pdf/2503.03523v1.pdf","comment":"9 pages, 10 figures"},{"id":"http://arxiv.org/abs/2412.18180v3","updated":"2025-03-05T14:05:29Z","published":"2024-12-24T05:34:05Z","title":"PCM Selector: Penalized Covariate-Mediator Selection Operator for\n  Evaluating Linear Causal Effects","summary":"  For a data-generating process for random variables that can be described with\na linear structural equation model, we consider a situation in which (i) a set\nof covariates satisfying the back-door criterion cannot be observed or (ii)\nsuch a set can be observed, but standard statistical estimation methods cannot\nbe applied to estimate causal effects because of\nmulticollinearity/high-dimensional data problems. We propose a novel two-stage\npenalized regression approach, the penalized covariate-mediator selection\noperator (PCM Selector), to estimate the causal effects in such scenarios.\nUnlike existing penalized regression analyses, when a set of intermediate\nvariables is available, PCM Selector provides a consistent or less biased\nestimator of the causal effect. In addition, PCM Selector provides a variable\nselection procedure for intermediate variables to obtain better estimation\naccuracy of the causal effects than does the back-door criterion.\n","authors":["Hisayoshi Nanmo","Manabu Kuroki"],"pdf_url":"https://arxiv.org/pdf/2412.18180v3.pdf","comment":"Accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2503.01431v2","updated":"2025-03-05T14:04:46Z","published":"2025-03-03T11:34:27Z","title":"How simple can you go? An off-the-shelf transformer approach to\n  molecular dynamics","summary":"  Most current neural networks for molecular dynamics (MD) include physical\ninductive biases, resulting in specialized and complex architectures. This is\nin contrast to most other machine learning domains, where specialist approaches\nare increasingly replaced by general-purpose architectures trained on vast\ndatasets. In line with this trend, several recent studies have questioned the\nnecessity of architectural features commonly found in MD models, such as\nbuilt-in rotational equivariance or energy conservation. In this work, we\ncontribute to the ongoing discussion by evaluating the performance of an MD\nmodel with as few specialized architectural features as possible. We present a\nrecipe for MD using an Edge Transformer, an \"off-the-shelf'' transformer\narchitecture that has been minimally modified for the MD domain, termed MD-ET.\nOur model implements neither built-in equivariance nor energy conservation. We\nuse a simple supervised pre-training scheme on $\\sim$30 million molecular\nstructures from the QCML database. Using this \"off-the-shelf'' approach, we\nshow state-of-the-art results on several benchmarks after fine-tuning for a\nsmall number of steps. Additionally, we examine the effects of being only\napproximately equivariant and energy conserving for MD simulations, proposing a\nnovel method for distinguishing the errors resulting from non-equivariance from\nother sources of inaccuracies like numerical rounding errors. While our model\nexhibits runaway energy increases on larger structures, we show approximately\nenergy-conserving NVE simulations for a range of small structures.\n","authors":["Max Eissler","Tim Korjakow","Stefan Ganscha","Oliver T. Unke","Klaus-Robert Müller","Stefan Gugler"],"pdf_url":"https://arxiv.org/pdf/2503.01431v2.pdf","comment":"21 pages, code at https://github.com/mx-e/simple-md"},{"id":"http://arxiv.org/abs/2503.03515v1","updated":"2025-03-05T14:01:17Z","published":"2025-03-05T14:01:17Z","title":"DO-IQS: Dynamics-Aware Offline Inverse Q-Learning for Optimal Stopping\n  with Unknown Gain Functions","summary":"  We consider Inverse Optimal Stopping (IOS) problem where, based on stopped\nexpert trajectories, one aims to recover the optimal stopping region through\ncontinuation and stopping gain functions approximation. The uniqueness of the\nstopping region allows the use of IOS in real-world applications with safety\nconcerns. While current state-of-the-art inverse reinforcement learning methods\nrecover both a Q-function and the corresponding optimal policy, they fail to\naccount for specific challenges posed by optimal stopping problems. These\ninclude data sparsity near the stopping region, non-Markovian nature of the\ncontinuation gain, a proper treatment of boundary conditions, the need for a\nstable offline approach for risk-sensitive applications, and a lack of a\nquality evaluation metric. These challenges are addressed with the proposed\nDynamics-Aware Offline Inverse Q-Learning for Optimal Stopping (DO-IQS), which\nincorporates temporal information by approximating the cumulative continuation\ngain together with the world dynamics and the Q-function without querying to\nthe environment. Moreover, a confidence-based oversampling approach is proposed\nto treat the data sparsity problem. We demonstrate the performance of our\nmodels on real and artificial data including an optimal intervention for\ncritical events problem.\n","authors":["Anna Kuchko"],"pdf_url":"https://arxiv.org/pdf/2503.03515v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05459v2","updated":"2025-03-05T13:57:56Z","published":"2024-10-07T19:45:09Z","title":"From Sparse Dependence to Sparse Attention: Unveiling How\n  Chain-of-Thought Enhances Transformer Sample Efficiency","summary":"  Chain-of-thought (CoT) significantly enhances the reasoning performance of\nlarge language models (LLM). While current theoretical studies often attribute\nthis improvement to increased expressiveness and computational capacity, we\nargue that expressiveness is not the primary limitation in the LLM regime, as\ncurrent large models will fail on simple tasks. Using a parity-learning setup,\nwe demonstrate that CoT can substantially improve sample efficiency even when\nthe representation power is sufficient. Specifically, with CoT, a transformer\ncan learn the function within polynomial samples, whereas without CoT, the\nrequired sample size is exponential. Additionally, we show that CoT simplifies\nthe learning process by introducing sparse sequential dependencies among input\ntokens, and leads to a sparse and interpretable attention. We validate our\ntheoretical analysis with both synthetic and real-world experiments, confirming\nthat sparsity in attention layers is a key factor of the improvement induced by\nCoT.\n","authors":["Kaiyue Wen","Huaqing Zhang","Hongzhou Lin","Jingzhao Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.05459v2.pdf","comment":"43 pages,11 figures"},{"id":"http://arxiv.org/abs/2503.03512v1","updated":"2025-03-05T13:57:48Z","published":"2025-03-05T13:57:48Z","title":"An Aspect Extraction Framework using Different Embedding Types, Learning\n  Models, and Dependency Structure","summary":"  Aspect-based sentiment analysis has gained significant attention in recent\nyears due to its ability to provide fine-grained insights for sentiment\nexpressions related to specific features of entities. An important component of\naspect-based sentiment analysis is aspect extraction, which involves\nidentifying and extracting aspect terms from text. Effective aspect extraction\nserves as the foundation for accurate sentiment analysis at the aspect level.\nIn this paper, we propose aspect extraction models that use different types of\nembeddings for words and part-of-speech tags and that combine several learning\nmodels. We also propose tree positional encoding that is based on dependency\nparsing output to capture better the aspect positions in sentences. In\naddition, a new aspect extraction dataset is built for Turkish by machine\ntranslating an English dataset in a controlled setting. The experiments\nconducted on two Turkish datasets showed that the proposed models mostly\noutperform the studies that use the same datasets, and incorporating tree\npositional encoding increases the performance of the models.\n","authors":["Ali Erkan","Tunga Güngör"],"pdf_url":"https://arxiv.org/pdf/2503.03512v1.pdf","comment":"Aspect-based Sentiment Analysis, Aspect Extraction, Natural Language\n  Processing, Machine Learning, Deep Neural Networks, Turkish"},{"id":"http://arxiv.org/abs/2503.03506v1","updated":"2025-03-05T13:54:13Z","published":"2025-03-05T13:54:13Z","title":"Rethinking Synthetic Data definitions: A privacy driven approach","summary":"  Synthetic data is gaining traction as a cost-effective solution for the\nincreasing data demands of AI development and can be generated either from\nexisting knowledge or derived data captured from real-world events. The source\nof the synthetic data generation and the technique used significantly impacts\nits residual privacy risk and therefore its opportunity for sharing.\nTraditional classification of synthetic data types no longer fit the newer\ngeneration techniques and there is a need to better align the classification\nwith practical needs. We suggest a new way of grouping synthetic data types\nthat better supports privacy evaluations to aid regulatory policymaking. Our\nnovel classification provides flexibility to new advancements like deep\ngenerative methods and offers a more practical framework for future\napplications.\n","authors":["Vibeke Binz Vallevik","Serena Elizabeth Marshall","Aleksandar Babic","Jan Franz Nygaard"],"pdf_url":"https://arxiv.org/pdf/2503.03506v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03503v1","updated":"2025-03-05T13:47:55Z","published":"2025-03-05T13:47:55Z","title":"Collaborative Expert LLMs Guided Multi-Objective Molecular Optimization","summary":"  Molecular optimization is a crucial yet complex and time-intensive process\nthat often acts as a bottleneck for drug development. Traditional methods rely\nheavily on trial and error, making multi-objective optimization both\ntime-consuming and resource-intensive. Current AI-based methods have shown\nlimited success in handling multi-objective optimization tasks, hampering their\npractical utilization. To address this challenge, we present MultiMol, a\ncollaborative large language model (LLM) system designed to guide\nmulti-objective molecular optimization. MultiMol comprises two agents,\nincluding a data-driven worker agent and a literature-guided research agent.\nThe data-driven worker agent is a large language model being fine-tuned to\nlearn how to generate optimized molecules considering multiple objectives,\nwhile the literature-guided research agent is responsible for searching\ntask-related literature to find useful prior knowledge that facilitates\nidentifying the most promising optimized candidates. In evaluations across six\nmulti-objective optimization tasks, MultiMol significantly outperforms existing\nmethods, achieving a 82.30% success rate, in sharp contrast to the 27.50%\nsuccess rate of current strongest methods. To further validate its practical\nimpact, we tested MultiMol on two real-world challenges. First, we enhanced the\nselectivity of Xanthine Amine Congener (XAC), a promiscuous ligand that binds\nboth A1R and A2AR, successfully biasing it towards A1R. Second, we improved the\nbioavailability of Saquinavir, an HIV-1 protease inhibitor with known\nbioavailability limitations. Overall, these results indicate that MultiMol\nrepresents a highly promising approach for multi-objective molecular\noptimization, holding great potential to accelerate the drug development\nprocess and contribute to the advancement of pharmaceutical research.\n","authors":["Jiajun Yu","Yizhen Zheng","Huan Yee Koh","Shirui Pan","Tianyue Wang","Haishuai Wang"],"pdf_url":"https://arxiv.org/pdf/2503.03503v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03499v1","updated":"2025-03-05T13:44:42Z","published":"2025-03-05T13:44:42Z","title":"State-offset Tuning: State-based Parameter-Efficient Fine-Tuning for\n  State Space Models","summary":"  State Space Models (SSMs) have emerged as efficient alternatives to\nTransformers, mitigating their quadratic computational cost. However, the\napplication of Parameter-Efficient Fine-Tuning (PEFT) methods to SSMs remains\nlargely unexplored. In particular, prompt-based methods like Prompt Tuning and\nPrefix-Tuning, which are widely used in Transformers, do not perform well on\nSSMs. To address this, we propose state-based methods as a superior alternative\nto prompt-based methods. This new family of methods naturally stems from the\narchitectural characteristics of SSMs. State-based methods adjust state-related\nfeatures directly instead of depending on external prompts. Furthermore, we\nintroduce a novel state-based PEFT method: State-offset Tuning. At every\ntimestep, our method directly affects the state at the current step, leading to\nmore effective adaptation. Through extensive experiments across diverse\ndatasets, we demonstrate the effectiveness of our method. Code is available at\nhttps://github.com/furiosa-ai/ssm-state-tuning.\n","authors":["Wonjun Kang","Kevin Galim","Yuchen Zeng","Minjae Lee","Hyung Il Koo","Nam Ik Cho"],"pdf_url":"https://arxiv.org/pdf/2503.03499v1.pdf","comment":"Code is available at https://github.com/furiosa-ai/ssm-state-tuning"},{"id":"http://arxiv.org/abs/2503.03489v1","updated":"2025-03-05T13:29:23Z","published":"2025-03-05T13:29:23Z","title":"Federated Learning for Predicting Mild Cognitive Impairment to Dementia\n  Conversion","summary":"  Dementia is a progressive condition that impairs an individual's cognitive\nhealth and daily functioning, with mild cognitive impairment (MCI) often\nserving as its precursor. The prediction of MCI to dementia conversion has been\nwell studied, but previous studies have almost always focused on traditional\nMachine Learning (ML) based methods that require sharing sensitive clinical\ninformation to train predictive models. This study proposes a privacy-enhancing\nsolution using Federated Learning (FL) to train predictive models for MCI to\ndementia conversion without sharing sensitive data, leveraging socio\ndemographic and cognitive measures. We simulated and compared two network\narchitectures, Peer to Peer (P2P) and client-server, to enable collaborative\nlearning. Our results demonstrated that FL had comparable predictive\nperformance to centralized ML, and each clinical site showed similar\nperformance without sharing local data. Moreover, the predictive performance of\nFL models was superior to site specific models trained without collaboration.\nThis work highlights that FL can eliminate the need for data sharing without\ncompromising model efficacy.\n","authors":["Gaurang Sharma","Elaheh Moradi","Juha Pajula","Mika Hilvo","Jussi Tohka"],"pdf_url":"https://arxiv.org/pdf/2503.03489v1.pdf","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2412.18355v2","updated":"2025-03-05T13:25:09Z","published":"2024-12-24T11:35:40Z","title":"Handling Spatial-Temporal Data Heterogeneity for Federated Continual\n  Learning via Tail Anchor","summary":"  Federated continual learning (FCL) allows each client to continually update\nits knowledge from task streams, enhancing the applicability of federated\nlearning in real-world scenarios. However, FCL needs to address not only\nspatial data heterogeneity between clients but also temporal data heterogeneity\nbetween tasks. In this paper, empirical experiments demonstrate that such\ninput-level heterogeneity significantly affects the model's internal parameters\nand outputs, leading to severe spatial-temporal catastrophic forgetting of\nlocal and previous knowledge. To this end, we propose Federated Tail Anchor\n(FedTA) to mix trainable Tail Anchor with the frozen output features to adjust\ntheir position in the feature space, thereby overcoming parameter-forgetting\nand output-forgetting. Three novel components are also included: Input\nEnhancement for improving the performance of pre-trained models on downstream\ntasks; Selective Input Knowledge Fusion for fusion of heterogeneous local\nknowledge on the server; and Best Global Prototype Selection for finding the\nbest anchor point for each class in the feature space. Extensive experiments\ndemonstrate that FedTA not only outperforms existing FCL methods but also\neffectively preserves the relative positions of features.\n","authors":["Hao Yu","Xin Yang","Le Zhang","Hanlin Gu","Tianrui Li","Lixin Fan","Qiang Yang"],"pdf_url":"https://arxiv.org/pdf/2412.18355v2.pdf","comment":"This paper is accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2503.03486v1","updated":"2025-03-05T13:24:58Z","published":"2025-03-05T13:24:58Z","title":"Differentially Private Learners for Heterogeneous Treatment Effects","summary":"  Patient data is widely used to estimate heterogeneous treatment effects and\nthus understand the effectiveness and safety of drugs. Yet, patient data\nincludes highly sensitive information that must be kept private. In this work,\nwe aim to estimate the conditional average treatment effect (CATE) from\nobservational data under differential privacy. Specifically, we present\nDP-CATE, a novel framework for CATE estimation that is Neyman-orthogonal and\nfurther ensures differential privacy of the estimates. Our framework is highly\ngeneral: it applies to any two-stage CATE meta-learner with a Neyman-orthogonal\nloss function, and any machine learning model can be used for nuisance\nestimation. We further provide an extension of our DP-CATE, where we employ\nRKHS regression to release the complete CATE function while ensuring\ndifferential privacy. We demonstrate our DP-CATE across various experiments\nusing synthetic and real-world datasets. To the best of our knowledge, we are\nthe first to provide a framework for CATE estimation that is Neyman-orthogonal\nand differentially private.\n","authors":["Maresa Schröder","Valentyn Melnychuk","Stefan Feuerriegel"],"pdf_url":"https://arxiv.org/pdf/2503.03486v1.pdf","comment":"Published at ICLR 2025"},{"id":"http://arxiv.org/abs/2503.03485v1","updated":"2025-03-05T13:24:57Z","published":"2025-03-05T13:24:57Z","title":"TEDDY: A Family Of Foundation Models For Understanding Single Cell\n  Biology","summary":"  Understanding the biological mechanism of disease is critical for medicine,\nand in particular drug discovery. AI-powered analysis of genome-scale\nbiological data hold great potential in this regard. The increasing\navailability of single-cell RNA sequencing data has enabled the development of\nlarge foundation models for disease biology. However, existing foundation\nmodels either do not improve or only modestly improve over task-specific models\nin downstream applications. Here, we explored two avenues for improving the\nstate-of-the-art. First, we scaled the pre-training dataset to 116 million\ncells, which is larger than those used by previous models. Second, we leveraged\nthe availability of large-scale biological annotations as a form of supervision\nduring pre-training. We trained the TEDDY family of models comprising six\ntransformer-based state-of-the-art single-cell foundation models with 70\nmillion, 160 million, and 400 million parameters. We vetted our models on two\ndownstream evaluation tasks -- identifying the underlying disease state of\nheld-out donors not seen during training and distinguishing healthy cells from\ndiseased ones for disease conditions and donors not seen during training.\nScaling experiments showed that performance improved predictably with both data\nvolume and parameter count. Our models showed substantial improvement over\nexisting work on the first task and more muted improvements on the second.\n","authors":["Alexis Chevalier","Soumya Ghosh","Urvi Awasthi","James Watkins","Julia Bieniewska","Nichita Mitrea","Olga Kotova","Kirill Shkura","Andrew Noble","Michael Steinbaugh","Julien Delile","Christoph Meier","Leonid Zhukov","Iya Khalil","Srayanta Mukherjee","Judith Mueller"],"pdf_url":"https://arxiv.org/pdf/2503.03485v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20475v2","updated":"2025-03-05T13:22:47Z","published":"2025-02-27T19:23:15Z","title":"Promote, Suppress, Iterate: How Language Models Answer One-to-Many\n  Factual Queries","summary":"  To answer one-to-many factual queries (e.g., listing cities of a country), a\nlanguage model (LM) must simultaneously recall knowledge and avoid repeating\nprevious answers. How are these two subtasks implemented and integrated\ninternally? Across multiple datasets and models, we identify a\npromote-then-suppress mechanism: the model first recalls all answers, and then\nsuppresses previously generated ones. Specifically, LMs use both the subject\nand previous answer tokens to perform knowledge recall, with attention\npropagating subject information and MLPs promoting the answers. Then, attention\nattends to and suppresses previous answer tokens, while MLPs amplify the\nsuppression signal. Our mechanism is corroborated by extensive experimental\nevidence: in addition to using early decoding and causal tracing, we analyze\nhow components use different tokens by introducing both Token Lens, which\ndecodes aggregated attention updates from specified tokens, and a knockout\nmethod that analyzes changes in MLP outputs after removing attention to\nspecified tokens. Overall, we provide new insights into how LMs' internal\ncomponents interact with different input tokens to support complex factual\nrecall. Code is available at\nhttps://github.com/Lorenayannnnn/how-lms-answer-one-to-many-factual-queries.\n","authors":["Tianyi Lorena Yan","Robin Jia"],"pdf_url":"https://arxiv.org/pdf/2502.20475v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.02393v3","updated":"2025-03-05T13:19:16Z","published":"2025-01-04T22:30:21Z","title":"Graph-Aware Isomorphic Attention for Adaptive Dynamics in Transformers","summary":"  We present an approach to modifying Transformer architectures by integrating\ngraph-aware relational reasoning into the attention mechanism, merging concepts\nfrom graph neural networks and language modeling. Building on the inherent\nconnection between attention and graph theory, we reformulate the Transformer's\nattention mechanism as a graph operation and propose Graph-Aware Isomorphic\nAttention. This method leverages advanced graph modeling strategies, including\nGraph Isomorphism Networks (GIN) and Principal Neighborhood Aggregation (PNA),\nto enrich the representation of relational structures. Our approach captures\ncomplex dependencies and generalizes across tasks, as evidenced by a reduced\ngeneralization gap and improved learning performance. Additionally, we expand\nthe concept of graph-aware attention to introduce Sparse GIN-Attention, a\nfine-tuning approach that employs sparse GINs. By interpreting attention\nmatrices as sparse adjacency graphs, this technique enhances the adaptability\nof pre-trained foundational models with minimal computational overhead,\nendowing them with graph-aware capabilities. Sparse GIN-Attention fine-tuning\nachieves improved training dynamics and better generalization compared to\nalternative methods like low-rank adaption (LoRA). We discuss latent graph-like\nstructures within traditional attention mechanisms, offering a new lens through\nwhich Transformers can be understood. By evolving Transformers as hierarchical\nGIN models for relational reasoning. This perspective suggests profound\nimplications for foundational model development, enabling the design of\narchitectures that dynamically adapt to both local and global dependencies.\nApplications in bioinformatics, materials science, language modeling, and\nbeyond could benefit from this synthesis of relational and sequential data\nmodeling, setting the stage for interpretable and generalizable modeling\nstrategies.\n","authors":["Markus J. Buehler"],"pdf_url":"https://arxiv.org/pdf/2501.02393v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.14848v2","updated":"2025-03-05T12:52:30Z","published":"2023-10-23T12:15:23Z","title":"Zero-Knowledge Proof-based Verifiable Decentralized Machine Learning in\n  Communication Network: A Comprehensive Survey","summary":"  Over recent decades, machine learning has significantly advanced network\ncommunication, enabling improved decision-making, user behavior analysis, and\nfault detection. Decentralized approaches, where participants exchange\ncomputation results instead of raw private data, mitigate these risks but\nintroduce challenges related to trust and verifiability. A critical issue\narises: How can one ensure the integrity and validity of computation results\nshared by other participants? Existing survey articles predominantly address\nsecurity and privacy concerns in decentralized machine learning, whereas this\nsurvey uniquely highlights the emerging issue of verifiability. Recognizing the\ncritical role of zero-knowledge proofs in ensuring verifiability, we present a\ncomprehensive review of Zero-Knowledge Proof-based Verifiable Machine Learning\n(ZKP-VML). To clarify the research problem, we present a definition of ZKP-VML\nconsisting of four algorithms, along with several corresponding key security\nproperties. Besides, we provide an overview of the current research landscape\nby systematically organizing the research timeline and categorizing existing\nschemes based on their security properties. Furthermore, through an in-depth\nanalysis of each existing scheme, we summarize their technical contributions\nand optimization strategies, aiming to uncover common design principles\nunderlying ZKP-VML schemes. Building on the reviews and analysis presented, we\nidentify current research challenges and suggest future research directions. To\nthe best of our knowledge, this is the most comprehensive survey to date on\nverifiable decentralized machine learning and ZKP-VML.\n","authors":["Zhibo Xing","Zijian Zhang","Ziang Zhang","Zhen Li","Meng Li","Jiamou Liu","Zongyang Zhang","Yi Zhao","Qi Sun","Liehuang Zhu","Giovanni Russello"],"pdf_url":"https://arxiv.org/pdf/2310.14848v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03462v1","updated":"2025-03-05T12:52:14Z","published":"2025-03-05T12:52:14Z","title":"Open-Source Large Language Models as Multilingual Crowdworkers:\n  Synthesizing Open-Domain Dialogues in Several Languages With No Examples in\n  Targets and No Machine Translation","summary":"  The prevailing paradigm in the domain of Open-Domain Dialogue agents\npredominantly focuses on the English language, encompassing both models and\ndatasets. Furthermore, the financial and temporal investments required for\ncrowdsourcing such datasets for finetuning are substantial, particularly when\nmultiple languages are involved. Fortunately, advancements in Large Language\nModels (LLMs) have unveiled a plethora of possibilities across diverse tasks.\nSpecifically, instruction-tuning has enabled LLMs to execute tasks based on\nnatural language instructions, occasionally surpassing the performance of human\ncrowdworkers. Additionally, these models possess the capability to function in\nvarious languages within a single thread. Consequently, to generate new samples\nin different languages, we propose leveraging these capabilities to replicate\nthe data collection process. We introduce a pipeline for generating Open-Domain\nDialogue data in multiple Target Languages using LLMs, with demonstrations\nprovided in a unique Source Language. By eschewing explicit Machine Translation\nin this approach, we enhance the adherence to language-specific nuances. We\napply this methodology to the PersonaChat dataset. To enhance the openness of\ngenerated dialogues and mimic real life scenarii, we added the notion of speech\nevents corresponding to the type of conversation the speakers are involved in\nand also that of common ground which represents the premises of a conversation.\n","authors":["Ahmed Njifenjou","Virgile Sucal","Bassam Jabaian","Fabrice Lefèvre"],"pdf_url":"https://arxiv.org/pdf/2503.03462v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03454v1","updated":"2025-03-05T12:40:34Z","published":"2025-03-05T12:40:34Z","title":"Data Poisoning Attacks to Locally Differentially Private Range Query\n  Protocols","summary":"  Trajectory data, which tracks movements through geographic locations, is\ncrucial for improving real-world applications. However, collecting such\nsensitive data raises considerable privacy concerns. Local differential privacy\n(LDP) offers a solution by allowing individuals to locally perturb their\ntrajectory data before sharing it. Despite its privacy benefits, LDP protocols\nare vulnerable to data poisoning attacks, where attackers inject fake data to\nmanipulate aggregated results. In this work, we make the first attempt to\nanalyze vulnerabilities in several representative LDP trajectory protocols. We\npropose \\textsc{TraP}, a heuristic algorithm for data \\underline{P}oisoning\nattacks using a prefix-suffix method to optimize fake \\underline{Tra}jectory\nselection, significantly reducing computational complexity. Our experimental\nresults demonstrate that our attack can substantially increase target pattern\noccurrences in the perturbed trajectory dataset with few fake users. This study\nunderscores the urgent need for robust defenses and better protocol designs to\nsafeguard LDP trajectory data against malicious manipulation.\n","authors":["I-Jung Hsu","Chih-Hsun Lin","Chia-Mu Yu","Sy-Yen Kuo","Chun-Ying Huang"],"pdf_url":"https://arxiv.org/pdf/2503.03454v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03443v1","updated":"2025-03-05T12:24:12Z","published":"2025-03-05T12:24:12Z","title":"Conceptualizing Uncertainty","summary":"  Uncertainty in machine learning refers to the degree of confidence or lack\nthereof in a model's predictions. While uncertainty quantification methods\nexist, explanations of uncertainty, especially in high-dimensional settings,\nremain an open challenge. Existing work focuses on feature attribution\napproaches which are restricted to local explanations. Understanding\nuncertainty, its origins, and characteristics on a global scale is crucial for\nenhancing interpretability and trust in a model's predictions. In this work, we\npropose to explain the uncertainty in high-dimensional data classification\nsettings by means of concept activation vectors which give rise to local and\nglobal explanations of uncertainty. We demonstrate the utility of the generated\nexplanations by leveraging them to refine and improve our model.\n","authors":["Isaac Roberts","Alexander Schulz","Sarah Schroeder","Fabian Hinder","Barbara Hammer"],"pdf_url":"https://arxiv.org/pdf/2503.03443v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03438v1","updated":"2025-03-05T12:13:08Z","published":"2025-03-05T12:13:08Z","title":"Gradient Deconfliction via Orthogonal Projections onto Subspaces For\n  Multi-task Learning","summary":"  Although multi-task learning (MTL) has been a preferred approach and\nsuccessfully applied in many real-world scenarios, MTL models are not\nguaranteed to outperform single-task models on all tasks mainly due to the\nnegative effects of conflicting gradients among the tasks. In this paper, we\nfully examine the influence of conflicting gradients and further emphasize the\nimportance and advantages of achieving non-conflicting gradients which allows\nsimple but effective trade-off strategies among the tasks with stable\nperformance. Based on our findings, we propose the Gradient Deconfliction via\nOrthogonal Projections onto Subspaces (GradOPS) spanned by other task-specific\ngradients. Our method not only solves all conflicts among the tasks, but can\nalso effectively search for diverse solutions towards different trade-off\npreferences among the tasks. Theoretical analysis on convergence is provided,\nand performance of our algorithm is fully testified on multiple benchmarks in\nvarious domains. Results demonstrate that our method can effectively find\nmultiple state-of-the-art solutions with different trade-off strategies among\nthe tasks on multiple datasets.\n","authors":["Shijie Zhu","Hui Zhao","Tianshu Wu","Pengjie Wang","Hongbo Deng","Jian Xu","Bo Zheng"],"pdf_url":"https://arxiv.org/pdf/2503.03438v1.pdf","comment":"WSDM 2025"},{"id":"http://arxiv.org/abs/2503.00578v2","updated":"2025-03-05T12:00:38Z","published":"2025-03-01T18:00:41Z","title":"Channel-Attentive Graph Neural Networks","summary":"  Graph Neural Networks (GNNs) set the state-of-the-art in representation\nlearning for graph-structured data. They are used in many domains, from online\nsocial networks to complex molecules. Most GNNs leverage the message-passing\nparadigm and achieve strong performances on various tasks. However, the\nmessage-passing mechanism used in most models suffers from over-smoothing as a\nGNN's depth increases. The over-smoothing degrades GNN's performance due to the\nincreased similarity between the representations of unrelated nodes. This study\nproposes an adaptive channel-wise message-passing approach to alleviate the\nover-smoothing. The proposed model, Channel-Attentive GNN, learns how to attend\nto neighboring nodes and their feature channels. Thus, much diverse information\ncan be transferred between nodes during message-passing. Experiments with\nwidely used benchmark datasets show that the proposed model is more resistant\nto over-smoothing than baselines and achieves state-of-the-art performances for\nvarious graphs with strong heterophily. Our code is at\nhttps://github.com/ALLab-Boun/CHAT-GNN.\n","authors":["Tuğrul Hasan Karabulut","İnci M. Baytaş"],"pdf_url":"https://arxiv.org/pdf/2503.00578v2.pdf","comment":"Published as a conference paper at IEEE International Conference on\n  Data Mining 2024"},{"id":"http://arxiv.org/abs/2503.03426v1","updated":"2025-03-05T11:59:31Z","published":"2025-03-05T11:59:31Z","title":"Early-Stopped Mirror Descent for Linear Regression over Convex Bodies","summary":"  Early-stopped iterative optimization methods are widely used as alternatives\nto explicit regularization, and direct comparisons between early-stopping and\nexplicit regularization have been established for many optimization geometries.\nHowever, most analyses depend heavily on the specific properties of the\noptimization geometry or strong convexity of the empirical objective, and it\nremains unclear whether early-stopping could ever be less statistically\nefficient than explicit regularization for some particular shape constraint,\nespecially in the overparameterized regime. To address this question, we study\nthe setting of high-dimensional linear regression under additive Gaussian noise\nwhen the ground truth is assumed to lie in a known convex body and the task is\nto minimize the in-sample mean squared error. Our main result shows that for\nany convex body and any design matrix, up to an absolute constant factor, the\nworst-case risk of unconstrained early-stopped mirror descent with an\nappropriate potential is at most that of the least squares estimator\nconstrained to the convex body. We achieve this by constructing algorithmic\nregularizers based on the Minkowski functional of the convex body.\n","authors":["Tobias Wegel","Gil Kur","Patrick Rebeschini"],"pdf_url":"https://arxiv.org/pdf/2503.03426v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.00735v3","updated":"2025-03-05T11:50:24Z","published":"2025-03-02T05:16:43Z","title":"LADDER: Self-Improving LLMs Through Recursive Problem Decomposition","summary":"  We introduce LADDER (Learning through Autonomous Difficulty-Driven Example\nRecursion), a framework which enables Large Language Models to autonomously\nimprove their problem-solving capabilities through self-guided learning by\nrecursively generating and solving progressively simpler variants of complex\nproblems. Unlike prior approaches that require curated datasets or human\nfeedback, LADDER leverages a model's own capabilities to generate easier\nquestion variants. We demonstrate LADDER's effectiveness in the subject of\nmathematical integration, improving Llama 3.2 3B's accuracy from 1% to 82% on\nundergraduate-level problems and enabling Qwen2.5 7B Deepseek-R1 Distilled to\nachieve 73% on the MIT Integration Bee qualifying examination. We also\nintroduce TTRL (Test-Time Reinforcement Learning), where we perform\nreinforcement learning on variants of test problems at inference time. TTRL\nenables Qwen2.5 7B Deepseek-R1 Distilled to achieve a state-of-the-art score of\n90% on the MIT Integration Bee qualifying examination, surpassing OpenAI o1's\nperformance. These results show how self-directed strategic learning can\nachieve significant capability improvements without relying on architectural\nscaling or human supervision.\n","authors":["Toby Simonds","Akira Yoshiyama"],"pdf_url":"https://arxiv.org/pdf/2503.00735v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.18377v3","updated":"2025-03-05T11:49:36Z","published":"2024-12-24T12:03:36Z","title":"ChaI-TeA: A Benchmark for Evaluating Autocompletion of Interactions with\n  LLM-based Chatbots","summary":"  The rise of LLMs has deflected a growing portion of human-computer\ninteractions towards LLM-based chatbots. The remarkable abilities of these\nmodels allow users to interact using long, diverse natural language text\ncovering a wide range of topics and styles. Phrasing these messages is a time\nand effort consuming task, calling for an autocomplete solution to assist\nusers. We introduce the task of chatbot interaction autocomplete. We present\nChaI-TeA: CHat InTEraction Autocomplete; An autcomplete evaluation framework\nfor LLM-based chatbot interactions. The framework includes a formal definition\nof the task, coupled with suitable datasets and metrics. We use the framework\nto evaluate After formally defining the task along with suitable datasets and\nmetrics, we test 9 models on the defined auto completion task, finding that\nwhile current off-the-shelf models perform fairly, there is still much room for\nimprovement, mainly in ranking of the generated suggestions. We provide\ninsights for practitioners working on this task and open new research\ndirections for researchers in the field. We release our framework to serve as a\nfoundation for future research.\n","authors":["Shani Goren","Oren Kalinsky","Tomer Stav","Yuri Rapoport","Yaron Fairstein","Ram Yazdi","Nachshon Cohen","Alexander Libov","Guy Kushilevitz"],"pdf_url":"https://arxiv.org/pdf/2412.18377v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03418v1","updated":"2025-03-05T11:47:41Z","published":"2025-03-05T11:47:41Z","title":"Simplicial SMOTE: Oversampling Solution to the Imbalanced Learning\n  Problem","summary":"  SMOTE (Synthetic Minority Oversampling Technique) is the established\ngeometric approach to random oversampling to balance classes in the imbalanced\nlearning problem, followed by many extensions. Its idea is to introduce\nsynthetic data points of the minor class, with each new point being the convex\ncombination of an existing data point and one of its k-nearest neighbors. In\nthis paper, by viewing SMOTE as sampling from the edges of a geometric\nneighborhood graph and borrowing tools from the topological data analysis, we\npropose a novel technique, Simplicial SMOTE, that samples from the simplices of\na geometric neighborhood simplicial complex. A new synthetic point is defined\nby the barycentric coordinates w.r.t. a simplex spanned by an arbitrary number\nof data points being sufficiently close rather than a pair. Such a replacement\nof the geometric data model results in better coverage of the underlying data\ndistribution compared to existing geometric sampling methods and allows the\ngeneration of synthetic points of the minority class closer to the majority\nclass on the decision boundary. We experimentally demonstrate that our\nSimplicial SMOTE outperforms several popular geometric sampling methods,\nincluding the original SMOTE. Moreover, we show that simplicial sampling can be\neasily integrated into existing SMOTE extensions. We generalize and evaluate\nsimplicial extensions of the classic Borderline SMOTE, Safe-level SMOTE, and\nADASYN algorithms, all of which outperform their graph-based counterparts.\n","authors":["Oleg Kachan","Andrey Savchenko","Gleb Gusev"],"pdf_url":"https://arxiv.org/pdf/2503.03418v1.pdf","comment":"Accepted at KDD 2025 (research track)"},{"id":"http://arxiv.org/abs/2412.14566v2","updated":"2025-03-05T11:38:00Z","published":"2024-12-19T06:35:54Z","title":"AIArena: A Blockchain-Based Decentralized AI Training Platform","summary":"  The rapid advancement of AI has underscored critical challenges in its\ndevelopment and implementation, largely due to centralized control by a few\nmajor corporations. This concentration of power intensifies biases within AI\nmodels, resulting from inadequate governance and oversight mechanisms.\nAdditionally, it limits public involvement and heightens concerns about the\nintegrity of model generation. Such monopolistic control over data and AI\noutputs threatens both innovation and fair data usage, as users inadvertently\ncontribute data that primarily benefits these corporations. In this work, we\npropose AIArena, a blockchain-based decentralized AI training platform designed\nto democratize AI development and alignment through on-chain incentive\nmechanisms. AIArena fosters an open and collaborative environment where\nparticipants can contribute models and computing resources. Its on-chain\nconsensus mechanism ensures fair rewards for participants based on their\ncontributions. We instantiate and implement AIArena on the public Base\nblockchain Sepolia testnet, and the evaluation results demonstrate the\nfeasibility of AIArena in real-world applications.\n","authors":["Zhipeng Wang","Rui Sun","Elizabeth Lui","Tuo Zhou","Yizhe Wen","Jiahao Sun"],"pdf_url":"https://arxiv.org/pdf/2412.14566v2.pdf","comment":"Camera ready version. Accepted by the ACM Web Conference (WWW), 2025"},{"id":"http://arxiv.org/abs/2408.09838v2","updated":"2025-03-05T11:27:17Z","published":"2024-08-19T09:33:31Z","title":"Mitigating the Stability-Plasticity Dilemma in Adaptive Train Scheduling\n  with Curriculum-Driven Continual DQN Expansion","summary":"  A continual learning agent builds on previous experiences to develop\nincreasingly complex behaviors by adapting to non-stationary and dynamic\nenvironments while preserving previously acquired knowledge. However, scaling\nthese systems presents significant challenges, particularly in balancing the\npreservation of previous policies with the adaptation of new ones to current\nenvironments. This balance, known as the stability-plasticity dilemma, is\nespecially pronounced in complex multi-agent domains such as the train\nscheduling problem, where environmental and agent behaviors are constantly\nchanging, and the search space is vast. In this work, we propose addressing\nthese challenges in the train scheduling problem using curriculum learning. We\ndesign a curriculum with adjacent skills that build on each other to improve\ngeneralization performance. Introducing a curriculum with distinct tasks\nintroduces non-stationarity, which we address by proposing a new algorithm:\nContinual Deep Q-Network (DQN) Expansion (CDE). Our approach dynamically\ngenerates and adjusts Q-function subspaces to handle environmental changes and\ntask requirements. CDE mitigates catastrophic forgetting through EWC while\nensuring high plasticity using adaptive rational activation functions.\nExperimental results demonstrate significant improvements in learning\nefficiency and adaptability compared to RL baselines and other adapted methods\nfor continual learning, highlighting the potential of our method in managing\nthe stability-plasticity dilemma in the adaptive train scheduling setting.\n","authors":["Achref Jaziri","Etienne Künzel","Visvanathan Ramesh"],"pdf_url":"https://arxiv.org/pdf/2408.09838v2.pdf","comment":"9 Pages, 2 Figures"},{"id":"http://arxiv.org/abs/2503.03401v1","updated":"2025-03-05T11:24:55Z","published":"2025-03-05T11:24:55Z","title":"Evolutionary Prediction Games","summary":"  When users decide whether to use a system based on the quality of predictions\nthey receive, learning has the capacity to shape the population of users it\nserves - for better or worse. This work aims to study the long-term\nimplications of this process through the lens of evolutionary game theory. We\nintroduce and study evolutionary prediction games, designed to capture the role\nof learning as a driver of natural selection between groups of users, and hence\na determinant of evolutionary outcomes. Our main theoretical results show that:\n(i) in settings with unlimited data and compute, learning tends to reinforce\nthe survival of the fittest, and (ii) in more realistic settings, opportunities\nfor coexistence emerge. We analyze these opportunities in terms of their\nstability and feasibility, present several mechanisms that can sustain their\nexistence, and empirically demonstrate our findings using real and synthetic\ndata.\n","authors":["Eden Saig","Nir Rosenfeld"],"pdf_url":"https://arxiv.org/pdf/2503.03401v1.pdf","comment":"Comments are welcome"},{"id":"http://arxiv.org/abs/2503.03399v1","updated":"2025-03-05T11:21:37Z","published":"2025-03-05T11:21:37Z","title":"Predicting Practically? Domain Generalization for Predictive Analytics\n  in Real-world Environments","summary":"  Predictive machine learning models are widely used in customer relationship\nmanagement (CRM) to forecast customer behaviors and support decision-making.\nHowever, the dynamic nature of customer behaviors often results in significant\ndistribution shifts between training data and serving data, leading to\nperformance degradation in predictive models. Domain generalization, which aims\nto train models that can generalize to unseen environments without prior\nknowledge of their distributions, has become a critical area of research. In\nthis work, we propose a novel domain generalization method tailored to handle\ncomplex distribution shifts, encompassing both covariate and concept shifts.\nOur method builds upon the Distributionally Robust Optimization framework,\noptimizing model performance over a set of hypothetical worst-case\ndistributions rather than relying solely on the training data. Through\nsimulation experiments, we demonstrate the working mechanism of the proposed\nmethod. We also conduct experiments on a real-world customer churn dataset, and\nvalidate its effectiveness in both temporal and spatial generalization\nsettings. Finally, we discuss the broader implications of our method for\nadvancing Information Systems (IS) design research, particularly in building\nrobust predictive models for dynamic managerial environments.\n","authors":["Hanyu Duan","Yi Yang","Ahmed Abbasi","Kar Yan Tam"],"pdf_url":"https://arxiv.org/pdf/2503.03399v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.12972v2","updated":"2025-03-05T11:18:41Z","published":"2024-11-20T01:54:52Z","title":"UniFlow: A Foundation Model for Unified Urban Spatio-Temporal Flow\n  Prediction","summary":"  Urban spatio-temporal flow prediction, encompassing traffic flows and crowd\nflows, is crucial for optimizing city infrastructure and managing traffic and\nemergency responses. Traditional approaches have relied on separate models\ntailored to either grid-based data, representing cities as uniform cells, or\ngraph-based data, modeling cities as networks of nodes and edges. In this\npaper, we build UniFlow, a foundational model for general urban flow prediction\nthat unifies both grid-based and graphbased data. We first design a multi-view\nspatio-temporal patching mechanism to standardize different data into a\nconsistent sequential format and then introduce a spatio-temporal transformer\narchitecture to capture complex correlations and dynamics. To leverage shared\nspatio-temporal patterns across different data types and facilitate effective\ncross-learning, we propose SpatioTemporal Memory Retrieval Augmentation\n(ST-MRA). By creating structured memory modules to store shared spatio-temporal\npatterns, ST-MRA enhances predictions through adaptive memory retrieval.\nExtensive experiments demonstrate that UniFlow outperforms existing models in\nboth grid-based and graph-based flow prediction, excelling particularly in\nscenarios with limited data availability, showcasing its superior performance\nand broad applicability. The datasets and code implementation have been\nreleased on https://github.com/YuanYuan98/UniFlow.\n","authors":["Yuan Yuan","Jingtao Ding","Chonghua Han","Depeng Jin","Yong Li"],"pdf_url":"https://arxiv.org/pdf/2411.12972v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03391v1","updated":"2025-03-05T11:12:40Z","published":"2025-03-05T11:12:40Z","title":"Multi-Agent DRL for Queue-Aware Task Offloading in Hierarchical\n  MEC-Enabled Air-Ground Networks","summary":"  Mobile edge computing (MEC)-enabled air-ground networks are a key component\nof 6G, employing aerial base stations (ABSs) such as unmanned aerial vehicles\n(UAVs) and high-altitude platform stations (HAPS) to provide dynamic services\nto ground IoT devices (IoTDs). These IoTDs support real-time applications\n(e.g., multimedia and Metaverse services) that demand high computational\nresources and strict quality of service (QoS) guarantees in terms of latency\nand task queue management. Given their limited energy and processing\ncapabilities, IoTDs rely on UAVs and HAPS to offload tasks for distributed\nprocessing, forming a multi-tier MEC system. This paper tackles the overall\nenergy minimization problem in MEC-enabled air-ground integrated networks\n(MAGIN) by jointly optimizing UAV trajectories, computing resource allocation,\nand queue-aware task offloading decisions. The optimization is challenging due\nto the nonconvex, nonlinear nature of this hierarchical system, which renders\ntraditional methods ineffective. We reformulate the problem as a multi-agent\nMarkov decision process (MDP) with continuous action spaces and heterogeneous\nagents, and propose a novel variant of multi-agent proximal policy optimization\nwith a Beta distribution (MAPPO-BD) to solve it. Extensive simulations show\nthat MAPPO-BD outperforms baseline schemes, achieving superior energy savings\nand efficient resource management in MAGIN while meeting queue delay and edge\ncomputing constraints.\n","authors":["Muhammet Hevesli","Abegaz Mohammed Seid","Aiman Erbad","Mohamed Abdallah"],"pdf_url":"https://arxiv.org/pdf/2503.03391v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.19166v2","updated":"2025-03-05T11:09:06Z","published":"2025-02-26T14:19:49Z","title":"CodeIF: Benchmarking the Instruction-Following Capabilities of Large\n  Language Models for Code Generation","summary":"  With the rapid advancement of Large Language Models (LLMs), the demand for\nrobust instruction-following capabilities in code generation tasks has grown\nsignificantly. Code generation not only facilitates faster prototyping and\nautomated testing, but also augments developer efficiency through improved\nmaintainability and reusability of code. In this paper, we introduce CodeIF,\nthe first benchmark specifically designed to assess the abilities of LLMs to\nadhere to task-oriented instructions within diverse code generation scenarios.\nCodeIF encompasses a broad range of tasks, including function synthesis, error\ndebugging, algorithmic refactoring, and code explanation, thereby providing a\ncomprehensive suite to evaluate model performance across varying complexity\nlevels and programming domains. We conduct extensive experiments with LLMs,\nanalyzing their strengths and limitations in meeting the demands of these\ntasks. The experimental results offer valuable insights into how well current\nmodels align with human instructions, as well as the extent to which they can\ngenerate consistent, maintainable, and contextually relevant code. Our findings\nnot only underscore the critical role that instruction-following LLMs can play\nin modern software development, but also illuminate pathways for future\nresearch aimed at enhancing their adaptability, reliability, and overall\neffectiveness in automated code generation.\n","authors":["Kaiwen Yan","Hongcheng Guo","Xuanqing Shi","Jingyi Xu","Yaonan Gu","Zhoujun Li"],"pdf_url":"https://arxiv.org/pdf/2502.19166v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.09453v2","updated":"2025-03-05T11:04:58Z","published":"2022-06-19T17:13:58Z","title":"Bounding Evidence and Estimating Log-Likelihood in VAE","summary":"  Many crucial problems in deep learning and statistical inference are caused\nby a variational gap, i.e., a difference between model evidence\n(log-likelihood) and evidence lower bound (ELBO). In particular, in a classical\nVAE setting that involves training via an ELBO cost function, it is difficult\nto provide a robust comparison of the effects of training between models, since\nwe do not know a log-likelihood of data (but only its lower bound). In this\npaper, to deal with this problem, we introduce a general and effective upper\nbound, which allows us to efficiently approximate the evidence of data. We\nprovide extensive theoretical and experimental studies of our approach,\nincluding its comparison to the other state-of-the-art upper bounds, as well as\nits application as a tool for the evaluation of models that were trained on\nvarious lower bounds.\n","authors":["Łukasz Struski","Marcin Mazur","Paweł Batorski","Przemysław Spurek","Jacek Tabor"],"pdf_url":"https://arxiv.org/pdf/2206.09453v2.pdf","comment":"Paper accepted for AISTATS 2023"},{"id":"http://arxiv.org/abs/2503.03384v1","updated":"2025-03-05T11:02:29Z","published":"2025-03-05T11:02:29Z","title":"GNNMerge: Merging of GNN Models Without Accessing Training Data","summary":"  Model merging has gained prominence in machine learning as a method to\nintegrate multiple trained models into a single model without accessing the\noriginal training data. While existing approaches have demonstrated success in\ndomains such as computer vision and NLP, their application to Graph Neural\nNetworks (GNNs) remains unexplored. These methods often rely on the assumption\nof shared initialization, which is seldom applicable to GNNs. In this work, we\nundertake the first benchmarking study of model merging algorithms for GNNs,\nrevealing their limited effectiveness in this context. To address these\nchallenges, we propose GNNMerge, which utilizes a task-agnostic node embedding\nalignment strategy to merge GNNs. Furthermore, we establish that under a mild\nrelaxation, the proposed optimization objective admits direct analytical\nsolutions for widely used GNN architectures, significantly enhancing its\ncomputational efficiency. Empirical evaluations across diverse datasets, tasks,\nand architectures establish GNNMerge to be up to 24% more accurate than\nexisting methods while delivering over 2 orders of magnitude speed-up compared\nto training from scratch.\n","authors":["Vipul Garg","Ishita Thakre","Sayan Ranu"],"pdf_url":"https://arxiv.org/pdf/2503.03384v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03382v1","updated":"2025-03-05T10:57:34Z","published":"2025-03-05T10:57:34Z","title":"Paths and Ambient Spaces in Neural Loss Landscapes","summary":"  Understanding the structure of neural network loss surfaces, particularly the\nemergence of low-loss tunnels, is critical for advancing neural network theory\nand practice. In this paper, we propose a novel approach to directly embed loss\ntunnels into the loss landscape of neural networks. Exploring the properties of\nthese loss tunnels offers new insights into their length and structure and\nsheds light on some common misconceptions. We then apply our approach to\nBayesian neural networks, where we improve subspace inference by identifying\npitfalls and proposing a more natural prior that better guides the sampling\nprocedure.\n","authors":["Daniel Dold","Julius Kobialka","Nicolai Palm","Emanuel Sommer","David Rügamer","Oliver Dürr"],"pdf_url":"https://arxiv.org/pdf/2503.03382v1.pdf","comment":"9 pages, Accepted at AISTATS 2025"},{"id":"http://arxiv.org/abs/2411.15692v2","updated":"2025-03-05T10:54:30Z","published":"2024-11-24T03:06:59Z","title":"DrugAgent: Automating AI-aided Drug Discovery Programming through LLM\n  Multi-Agent Collaboration","summary":"  Recent progress in Large Language Models (LLMs) has drawn attention to their\npotential for accelerating drug discovery. However, a central problem remains:\ntranslating theoretical ideas into robust implementations in the highly\nspecialized context of pharmaceutical research. This limitation prevents\npractitioners from making full use of the latest AI developments in drug\ndiscovery. To address this challenge, we introduce DrugAgent, a multi-agent\nframework that automates machine learning (ML) programming for drug discovery\ntasks. DrugAgent employs an LLM Planner that formulates high-level ideas and an\nLLM Instructor that identifies and integrates domain knowledge when\nimplementing those ideas. We present case studies on three representative drug\ndiscovery tasks. Our results show that DrugAgent consistently outperforms\nleading baselines, including a relative improvement of 4.92% in ROC-AUC\ncompared to ReAct for drug-target interaction (DTI). DrugAgent is publicly\navailable at https://anonymous.4open.science/r/drugagent-5C42/.\n","authors":["Sizhe Liu","Yizhou Lu","Siyu Chen","Xiyang Hu","Jieyu Zhao","Yingzhou Lu","Yue Zhao"],"pdf_url":"https://arxiv.org/pdf/2411.15692v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.15425v4","updated":"2025-03-05T10:48:42Z","published":"2025-02-21T12:52:16Z","title":"TAG: A Decentralized Framework for Multi-Agent Hierarchical\n  Reinforcement Learning","summary":"  Hierarchical organization is fundamental to biological systems and human\nsocieties, yet artificial intelligence systems often rely on monolithic\narchitectures that limit adaptability and scalability. Current hierarchical\nreinforcement learning (HRL) approaches typically restrict hierarchies to two\nlevels or require centralized training, which limits their practical\napplicability. We introduce TAME Agent Framework (TAG), a framework for\nconstructing fully decentralized hierarchical multi-agent systems. TAG enables\nhierarchies of arbitrary depth through a novel LevelEnv concept, which\nabstracts each hierarchy level as the environment for the agents above it. This\napproach standardizes information flow between levels while preserving loose\ncoupling, allowing for seamless integration of diverse agent types. We\ndemonstrate the effectiveness of TAG by implementing hierarchical architectures\nthat combine different RL agents across multiple levels, achieving improved\nperformance over classical multi-agent RL baselines on standard benchmarks. Our\nresults show that decentralized hierarchical organization enhances both\nlearning speed and final performance, positioning TAG as a promising direction\nfor scalable multi-agent systems.\n","authors":["Giuseppe Paolo","Abdelhakim Benechehab","Hamza Cherkaoui","Albert Thomas","Balázs Kégl"],"pdf_url":"https://arxiv.org/pdf/2502.15425v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03565v2","updated":"2025-03-05T10:47:17Z","published":"2024-10-04T16:15:31Z","title":"Exploration Implies Data Augmentation: Reachability and Generalisation\n  in Contextual MDPs","summary":"  In the zero-shot policy transfer (ZSPT) setting for contextual Markov\ndecision processes (MDP), agents train on a fixed set of contexts and must\ngeneralise to new ones. Recent work has argued and demonstrated that increased\nexploration can improve this generalisation, by training on more states in the\ntraining contexts. In this paper, we demonstrate that training on more states\ncan indeed improve generalisation, but can come at a cost of reducing the\naccuracy of the learned value function which should not benefit generalisation.\nWe introduce reachability in the ZSPT setting to define which states/contexts\nrequire generalisation and explain why exploration can improve it. We\nhypothesise and demonstrate that using exploration to increase the agent's\ncoverage while also increasing the accuracy improves generalisation even more.\nInspired by this, we propose a method Explore-Go that implements an exploration\nphase at the beginning of each episode, which can be combined with existing on-\nand off-policy RL algorithms and significantly improves generalisation even in\npartially observable MDPs. We demonstrate the effectiveness of Explore-Go when\ncombined with several popular algorithms and show an increase in generalisation\nperformance across several environments. With this, we hope to provide\npractitioners with a simple modification that can improve the generalisation of\ntheir agents.\n","authors":["Max Weltevrede","Caroline Horsch","Matthijs T. J. Spaan","Wendelin Böhmer"],"pdf_url":"https://arxiv.org/pdf/2410.03565v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2406.08069"},{"id":"http://arxiv.org/abs/2503.03372v1","updated":"2025-03-05T10:47:06Z","published":"2025-03-05T10:47:06Z","title":"A Novel Multi-Criteria Local Latin Hypercube Refinement System for\n  Commutation Angle Improvement in IPMSMs","summary":"  The commutation angle is defined as the angle between the fundamental of the\nmotor phase current and the fundamental of the back-EMF. It can be utilised to\nprovide a compensating effect in IPMSMs. This is due to the reluctance torque\ncomponent being dependent on the commutation angle of the phase current even\nbefore entering the extended speed range. A real-time maximum torque per\ncurrent and voltage strategy is demonstrated to find the trajectory and optimum\ncommutation angles, gamma, where the level of accuracy depends on the\napplication and available computational speed. A magnet volume reduction using\na novel multi-criteria local Latin hypercube refinement (MLHR) sampling system\nis also presented to improve the optimisation process. The proposed new\ntechnique minimises the magnet mass to motor torque density whilst maintaining\na similar phase current level. A mapping of gamma allows the determination of\nthe optimum angles, as shown in this paper. The 3rd generation Toyota Prius\nIPMSM is considered as the reference motor, where the rotor configuration is\naltered to allow for an individual assessment.\n","authors":["Pedram Asef","Mouloud Denai","Johannes J. H. Paulides","Bruno Ricardo Marques","Andrew Lapthorn"],"pdf_url":"https://arxiv.org/pdf/2503.03372v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.02772v2","updated":"2025-03-05T10:42:53Z","published":"2024-09-04T14:51:36Z","title":"Unifying Causal Representation Learning with the Invariance Principle","summary":"  Causal representation learning (CRL) aims at recovering latent causal\nvariables from high-dimensional observations to solve causal downstream tasks,\nsuch as predicting the effect of new interventions or more robust\nclassification. A plethora of methods have been developed, each tackling\ncarefully crafted problem settings that lead to different types of\nidentifiability. These different settings are widely assumed to be important\nbecause they are often linked to different rungs of Pearl's causal hierarchy,\neven though this correspondence is not always exact. This work shows that\ninstead of strictly conforming to this hierarchical mapping, many causal\nrepresentation learning approaches methodologically align their representations\nwith inherent data symmetries. Identification of causal variables is guided by\ninvariance principles that are not necessarily causal. This result allows us to\nunify many existing approaches in a single method that can mix and match\ndifferent assumptions, including non-causal ones, based on the invariance\nrelevant to the problem at hand. It also significantly benefits applicability,\nwhich we demonstrate by improving treatment effect estimation on real-world\nhigh-dimensional ecological data. Overall, this paper clarifies the role of\ncausal assumptions in the discovery of causal variables and shifts the focus to\npreserving data symmetries.\n","authors":["Dingling Yao","Dario Rancati","Riccardo Cadei","Marco Fumero","Francesco Locatello"],"pdf_url":"https://arxiv.org/pdf/2409.02772v2.pdf","comment":"ICLR2025 Camera ready"},{"id":"http://arxiv.org/abs/2503.03360v1","updated":"2025-03-05T10:40:09Z","published":"2025-03-05T10:40:09Z","title":"Transformers for molecular property prediction: Domain adaptation\n  efficiently improves performance","summary":"  Most of the current transformer-based chemical language models are\npre-trained on millions to billions of molecules. However, the improvement from\nsuch scaling in dataset size is not confidently linked to improved molecular\nproperty prediction. The aim of this study is to investigate and overcome some\nof the limitations of transformer models in predicting molecular properties.\nSpecifically, we examine the impact of pre-training dataset size and diversity\non the performance of transformer models and investigate the use of domain\nadaptation as a technique for improving model performance. First, our findings\nindicate that increasing pretraining dataset size beyond 400K molecules from\nthe GuacaMol dataset does not result in a significant improvement on four ADME\nendpoints, namely, solubility, permeability, microsomal stability, and plasma\nprotein binding. Second, our results demonstrate that using domain adaptation\nby further training the transformer model on a small set of domain-relevant\nmolecules, i.e., a few hundred to a few thousand, using multi-task regression\nof physicochemical properties was sufficient to significantly improve\nperformance for three out of the four investigated ADME endpoints (P-value <\n0.001). Finally, we observe that a model pre-trained on 400K molecules and\ndomain adopted on a few hundred/thousand molecules performs similarly (P-value\n> 0.05) to more complicated transformer models like MolBERT(pre-trained on 1.3M\nmolecules) and MolFormer (pre-trained on 100M molecules). A comparison to a\nrandom forest model trained on basic physicochemical properties showed similar\nperformance to the examined transformer models. We believe that current\ntransformer models can be improved through further systematic analysis of\npre-training and downstream data, pre-training objectives, and scaling laws,\nultimately leading to better and more helpful models.\n","authors":["Afnan Sultan","Max Rausch-Dupont","Shahrukh Khan","Olga Kalinina","Andrea Volkamer","Dietrich Klakow"],"pdf_url":"https://arxiv.org/pdf/2503.03360v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03355v1","updated":"2025-03-05T10:37:51Z","published":"2025-03-05T10:37:51Z","title":"Video Super-Resolution: All You Need is a Video Diffusion Model","summary":"  We present a generic video super-resolution algorithm in this paper, based on\nthe Diffusion Posterior Sampling framework with an unconditional video\ngeneration model in latent space. The video generation model, a diffusion\ntransformer, functions as a space-time model. We argue that a powerful model,\nwhich learns the physics of the real world, can easily handle various kinds of\nmotion patterns as prior knowledge, thus eliminating the need for explicit\nestimation of optical flows or motion parameters for pixel alignment.\nFurthermore, a single instance of the proposed video diffusion transformer\nmodel can adapt to different sampling conditions without re-training. Due to\nlimited computational resources and training data, our experiments provide\nempirical evidence of the algorithm's strong super-resolution capabilities\nusing synthetic data.\n","authors":["Zhihao Zhan","Wang Pang","Xiang Zhu","Yechao Bai"],"pdf_url":"https://arxiv.org/pdf/2503.03355v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.18222v2","updated":"2025-03-05T10:17:25Z","published":"2024-05-28T14:30:07Z","title":"From Learning to Optimize to Learning Optimization Algorithms","summary":"  Towards designing learned optimization algorithms that are usable beyond\ntheir training setting, we identify key principles that classical algorithms\nobey, but have up to now, not been used for Learning to Optimize (L2O).\nFollowing these principles, we provide a general design pipeline, taking into\naccount data, architecture and learning strategy, and thereby enabling a\nsynergy between classical optimization and L2O, resulting in a philosophy of\nLearning Optimization Algorithms. As a consequence our learned algorithms\nperform well far beyond problems from the training distribution. We demonstrate\nthe success of these novel principles by designing a new learning-enhanced BFGS\nalgorithm and provide numerical experiments evidencing its adaptation to many\nsettings at test time.\n","authors":["Camille Castera","Peter Ochs"],"pdf_url":"https://arxiv.org/pdf/2405.18222v2.pdf","comment":"To appear at AISTATS 2025"},{"id":"http://arxiv.org/abs/2405.19036v2","updated":"2025-03-05T10:15:19Z","published":"2024-05-29T12:23:48Z","title":"State Space Models are Provably Comparable to Transformers in Dynamic\n  Token Selection","summary":"  Deep neural networks based on state space models (SSMs) are attracting\nsignificant attention in sequence modeling since their computational cost is\nmuch smaller than that of Transformers. While the capabilities of SSMs have\nbeen demonstrated through experiments in various tasks, theoretical\nunderstanding of SSMs is still limited. In particular, most theoretical studies\ndiscuss the capabilities of SSM layers without nonlinear layers, and there is a\nlack of discussion on their combination with nonlinear layers. In this paper,\nwe explore the capabilities of SSMs combined with fully connected neural\nnetworks, and show that they are comparable to Transformers in extracting the\nessential tokens depending on the input. As concrete examples, we consider two\nsynthetic tasks, which are challenging for a single SSM layer, and demonstrate\nthat SSMs combined with nonlinear layers can efficiently solve these tasks.\nFurthermore, we study the nonparametric regression task, and prove that the\nability of SSMs is equivalent to that of Transformers in estimating functions\nbelonging to a certain class.\n","authors":["Naoki Nishikawa","Taiji Suzuki"],"pdf_url":"https://arxiv.org/pdf/2405.19036v2.pdf","comment":"43 pages, 7 figures"},{"id":"http://arxiv.org/abs/2407.05704v2","updated":"2025-03-05T10:07:22Z","published":"2024-07-08T08:06:45Z","title":"Narrowing the Gap between Adversarial and Stochastic MDPs via Policy\n  Optimization","summary":"  We consider the problem of learning in adversarial Markov decision processes\n[MDPs] with an oblivious adversary in a full-information setting. The agent\ninteracts with an environment during $T$ episodes, each of which consists of\n$H$ stages, and each episode is evaluated with respect to a reward function\nthat will be revealed only at the end of the episode. We propose an algorithm,\ncalled APO-MVP, that achieves a regret bound of order\n$\\tilde{\\mathcal{O}}(\\mathrm{poly}(H)\\sqrt{SAT})$, where $S$ and $A$ are sizes\nof the state and action spaces, respectively. This result improves upon the\nbest-known regret bound by a factor of $\\sqrt{S}$, bridging the gap between\nadversarial and stochastic MDPs, and matching the minimax lower bound\n$\\Omega(\\sqrt{H^3SAT})$ as far as the dependencies in $S,A,T$ are concerned.\nThe proposed algorithm and analysis completely avoid the typical tool given by\noccupancy measures; instead, it performs policy optimization based only on\ndynamic programming and on a black-box online linear optimization strategy run\nover estimated advantage functions, making it easy to implement. The analysis\nleverages two recent techniques: policy optimization based on online linear\noptimization strategies (Jonckheere et al., 2023) and a refined martingale\nanalysis of the impact on values of estimating transitions kernels (Zhang et\nal., 2023).\n","authors":["Daniil Tiapkin","Evgenii Chzhen","Gilles Stoltz"],"pdf_url":"https://arxiv.org/pdf/2407.05704v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03331v1","updated":"2025-03-05T10:03:59Z","published":"2025-03-05T10:03:59Z","title":"Leap: Inductive Link Prediction via Learnable TopologyAugmentation","summary":"  Link prediction is a crucial task in many downstream applications of graph\nmachine learning. To this end, Graph Neural Network (GNN) is a widely used\ntechnique for link prediction, mainly in transductive settings, where the goal\nis to predict missing links between existing nodes. However, many real-life\napplications require an inductive setting that accommodates for new nodes,\ncoming into an existing graph. Thus, recently inductive link prediction has\nattracted considerable attention, and a multi-layer perceptron (MLP) is the\npopular choice of most studies to learn node representations. However, these\napproaches have limited expressivity and do not fully capture the graph's\nstructural signal. Therefore, in this work we propose LEAP, an inductive link\nprediction method based on LEArnable toPology augmentation. Unlike previous\nmethods, LEAP models the inductive bias from both the structure and node\nfeatures, and hence is more expressive. To the best of our knowledge, this is\nthe first attempt to provide structural contexts for new nodes via learnable\naugmentation in inductive settings. Extensive experiments on seven real-world\nhomogeneous and heterogeneous graphs demonstrates that LEAP significantly\nsurpasses SOTA methods. The improvements are up to 22\\% and 17\\% in terms of\nAUC and average precision, respectively. The code and datasets are available on\nGitHub (https://github.com/AhmedESamy/LEAP/)\n","authors":["Ahmed E. Samy","Zekarias T. Kefato","Sarunas Girdzijauskas"],"pdf_url":"https://arxiv.org/pdf/2503.03331v1.pdf","comment":"published in Machine Learning, Optimization, and Data Science,\n  Springer Nature Switzerland"},{"id":"http://arxiv.org/abs/2412.00497v2","updated":"2025-03-05T09:59:23Z","published":"2024-11-30T14:43:00Z","title":"Distributed Differentially Private Data Analytics via Secure Sketching","summary":"  We introduce the linear-transformation model, a distributed model of\ndifferentially private data analysis. Clients have access to a trusted platform\ncapable of applying a public matrix to their inputs. Such computations can be\nsecurely distributed across multiple servers using simple and efficient secure\nmultiparty computation techniques.\n  The linear-transformation model serves as an intermediate model between the\nhighly expressive central model and the minimal local model. In the central\nmodel, clients have access to a trusted platform capable of applying any\nfunction to their inputs. However, this expressiveness comes at a cost, as it\nis often prohibitively expensive to distribute such computations, leading to\nthe central model typically being implemented by a single trusted server. In\ncontrast, the local model assumes no trusted platform, which forces clients to\nadd significant noise to their data. The linear-transformation model avoids the\nsingle point of failure for privacy present in the central model, while also\nmitigating the high noise required in the local model.\n  We demonstrate that linear transformations are very useful for differential\nprivacy, allowing for the computation of linear sketches of input data. These\nsketches largely preserve utility for tasks such as private low-rank\napproximation and private ridge regression, while introducing only minimal\nerror, critically independent of the number of clients.\n","authors":["Jakob Burkhardt","Hannah Keller","Claudio Orlandi","Chris Schwiegelshohn"],"pdf_url":"https://arxiv.org/pdf/2412.00497v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14425v3","updated":"2025-03-05T09:54:52Z","published":"2024-03-21T14:28:43Z","title":"Task-optimal data-driven surrogate models for eNMPC via differentiable\n  simulation and optimization","summary":"  Mechanistic dynamic process models may be too computationally expensive to be\nusable as part of a real-time capable predictive controller. We present a\nmethod for end-to-end learning of Koopman surrogate models for optimal\nperformance in a specific control task. In contrast to previous contributions\nthat employ standard reinforcement learning (RL) algorithms, we use a training\nalgorithm that exploits the differentiability of environments based on\nmechanistic simulation models to aid the policy optimization. We evaluate the\nperformance of our method by comparing it to that of other training algorithms\non an existing economic nonlinear model predictive control (eNMPC) case study\nof a continuous stirred-tank reactor (CSTR) model. Compared to the benchmark\nmethods, our method produces similar economic performance while eliminating\nconstraint violations. Thus, for this case study, our method outperforms the\nothers and offers a promising path toward more performant controllers that\nemploy dynamic surrogate models.\n","authors":["Daniel Mayfrank","Na Young Ahn","Alexander Mitsos","Manuel Dahmen"],"pdf_url":"https://arxiv.org/pdf/2403.14425v3.pdf","comment":"8 pages, 4 figures, 1 table"},{"id":"http://arxiv.org/abs/2502.07780v3","updated":"2025-03-05T09:50:16Z","published":"2025-02-11T18:59:35Z","title":"DarwinLM: Evolutionary Structured Pruning of Large Language Models","summary":"  Large Language Models (LLMs) have achieved significant success across various\nNLP tasks. However, their massive computational costs limit their widespread\nuse, particularly in real-time applications. Structured pruning offers an\neffective solution by compressing models and directly providing end-to-end\nspeed improvements, regardless of the hardware environment. Meanwhile,\ndifferent components of the model exhibit varying sensitivities towards\npruning, calling for non-uniform model compression. However, a pruning method\nshould not only identify a capable substructure, but also account for\npost-compression training. To this end, we propose DarwinLM, a method for\ntraining-aware structured pruning. DarwinLM builds upon an evolutionary search\nprocess, generating multiple offspring models in each generation through\nmutation, and selecting the fittest for survival. To assess the effect of\npost-training, we incorporate a lightweight, multistep training process within\nthe offspring population, progressively increasing the number of tokens and\neliminating poorly performing models in each selection stage. We validate our\nmethod through extensive experiments on Llama-2-7B, Llama-3.1-8B and\nQwen-2.5-14B-Instruct, achieving state-of-the-art performance for structured\npruning. For instance, DarwinLM surpasses ShearedLlama while requiring 5x less\ntraining data during post-compression training. Code is at:\nhttps://github.com/IST-DASLab/DarwinLM\n","authors":["Shengkun Tang","Oliver Sieberling","Eldar Kurtic","Zhiqiang Shen","Dan Alistarh"],"pdf_url":"https://arxiv.org/pdf/2502.07780v3.pdf","comment":"Code: https://github.com/IST-DASLab/DarwinLM"},{"id":"http://arxiv.org/abs/2503.03313v1","updated":"2025-03-05T09:45:22Z","published":"2025-03-05T09:45:22Z","title":"LLM as GNN: Graph Vocabulary Learning for Text-Attributed Graph\n  Foundation Models","summary":"  Text-Attributed Graphs (TAGs), where each node is associated with text\ndescriptions, are ubiquitous in real-world scenarios. They typically exhibit\ndistinctive structure and domain-specific knowledge, motivating the development\nof a Graph Foundation Model (GFM) that generalizes across diverse graphs and\ntasks. Despite large efforts to integrate Large Language Models (LLMs) and\nGraph Neural Networks (GNNs) for TAGs, existing approaches suffer from\ndecoupled architectures with two-stage alignment, limiting their synergistic\npotential. Even worse, existing methods assign out-of-vocabulary (OOV) tokens\nto graph nodes, leading to graph-specific semantics, token explosion, and\nincompatibility with task-oriented prompt templates, which hinders cross-graph\nand cross-task transferability. To address these challenges, we propose\nPromptGFM, a versatile GFM for TAGs grounded in graph vocabulary learning.\nPromptGFM comprises two key components: (1) Graph Understanding Module, which\nexplicitly prompts LLMs to replicate the finest GNN workflow within the text\nspace, facilitating seamless GNN-LLM integration and elegant graph-text\nalignment; (2) Graph Inference Module, which establishes a language-based graph\nvocabulary ensuring expressiveness, transferability, and scalability, enabling\nreadable instructions for LLM fine-tuning. Extensive experiments demonstrate\nour superiority and transferability across diverse graphs and tasks. The code\nis available at this: https://github.com/agiresearch/PromptGFM.\n","authors":["Xi Zhu","Haochen Xue","Ziwei Zhao","Wujiang Xu","Jingyuan Huang","Minghao Guo","Qifan Wang","Kaixiong Zhou","Yongfeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.03313v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03302v1","updated":"2025-03-05T09:36:57Z","published":"2025-03-05T09:36:57Z","title":"Differential Machine Learning for Time Series Prediction","summary":"  Accurate time series prediction is challenging due to the inherent\nnonlinearity and sensitivity to initial conditions. We propose a novel approach\nthat enhances neural network predictions through differential learning, which\ninvolves training models on both the original time series and its differential\nseries. Specifically, we develop a differential long short-term memory\n(Diff-LSTM) network that uses a shared LSTM cell to simultaneously process both\ndata streams, effectively capturing intrinsic patterns and temporal dynamics.\nEvaluated on the Mackey-Glass, Lorenz, and R\\\"ossler chaotic time series, as\nwell as a real-world financial dataset from ACI Worldwide Inc., our results\ndemonstrate that the Diff- LSTM network outperforms prevalent models such as\nrecurrent neural networks, convolutional neural networks, and bidirectional and\nencoder-decoder LSTM networks in both short-term and long-term predictions.\nThis framework offers a promising solution for enhancing time series\nprediction, even when comprehensive knowledge of the underlying dynamics of the\ntime series is not fully available.\n","authors":["Akash Yadav","Eulalia Nualart"],"pdf_url":"https://arxiv.org/pdf/2503.03302v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.09126v3","updated":"2025-03-05T09:30:22Z","published":"2022-10-17T14:19:52Z","title":"Verifiable and Provably Secure Machine Unlearning","summary":"  Machine unlearning aims to remove points from the training dataset of a\nmachine learning model after training: e.g., when a user requests their data to\nbe deleted. While many unlearning methods have been proposed, none of them\nenable users to audit the procedure. Furthermore, recent work shows a user is\nunable to verify whether their data was unlearnt from an inspection of the\nmodel parameter alone. Rather than reasoning about parameters, we propose to\nview verifiable unlearning as a security problem. To this end, we present the\nfirst cryptographic definition of verifiable unlearning to formally capture the\nguarantees of an unlearning system. In this framework, the server first\ncomputes a proof that the model was trained on a dataset D. Given a user's data\npoint d requested to be deleted, the server updates the model using an\nunlearning algorithm. It then provides a proof of the correct execution of\nunlearning and that d is not part of D', where D' is the new training dataset\n(i.e., d has been removed). Our framework is generally applicable to different\nunlearning techniques that we abstract as admissible functions. We instantiate\na protocol in the framework, based on cryptographic assumptions, using SNARKs\nand hash chains. Finally, we implement the protocol for three different\nunlearning techniques and validate its feasibility for linear regression,\nlogistic regression, and neural networks.\n","authors":["Thorsten Eisenhofer","Doreen Riepel","Varun Chandrasekaran","Esha Ghosh","Olga Ohrimenko","Nicolas Papernot"],"pdf_url":"https://arxiv.org/pdf/2210.09126v3.pdf","comment":"Accepted at IEEE SaTML2025"},{"id":"http://arxiv.org/abs/2501.18945v2","updated":"2025-03-05T09:13:02Z","published":"2025-01-31T08:08:32Z","title":"Solving Inverse Problem for Multi-armed Bandits via Convex Optimization","summary":"  We consider the inverse problem of multi-armed bandits (IMAB) that are widely\nused in neuroscience and psychology research for behavior modelling. We first\nshow that the IMAB problem is not convex in general, but can be relaxed to a\nconvex problem via variable transformation. Based on this result, we propose a\ntwo-step sequential heuristic for (approximately) solving the IMAB problem. We\ndiscuss a condition where our method provides global solution to the IMAB\nproblem with certificate, as well as approximations to further save computing\ntime. Numerical experiments indicate that our heuristic method is more robust\nthan directly solving the IMAB problem via repeated local optimization, and can\nachieve the performance of Monte Carlo methods within a significantly decreased\nrunning time. We provide the implementation of our method based on CVXPY, which\nallows straightforward application by users not well versed in convex\noptimization.\n","authors":["Hao Zhu","Joschka Boedecker"],"pdf_url":"https://arxiv.org/pdf/2501.18945v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02368v2","updated":"2025-03-05T09:12:25Z","published":"2025-03-04T07:49:10Z","title":"Iterative Value Function Optimization for Guided Decoding","summary":"  While Reinforcement Learning from Human Feedback (RLHF) has become the\npredominant method for controlling language model outputs, it suffers from high\ncomputational costs and training instability. Guided decoding, especially\nvalue-guided methods, offers a cost-effective alternative by controlling\noutputs without re-training models. However, the accuracy of the value function\nis crucial for value-guided decoding, as inaccuracies can lead to suboptimal\ndecision-making and degraded performance. Existing methods struggle with\naccurately estimating the optimal value function, leading to less effective\ncontrol. We propose Iterative Value Function Optimization, a novel framework\nthat addresses these limitations through two key components: Monte Carlo Value\nEstimation, which reduces estimation variance by exploring diverse\ntrajectories, and Iterative On-Policy Optimization, which progressively\nimproves value estimation through collecting trajectories from value-guided\npolicies. Extensive experiments on text summarization, multi-turn dialogue, and\ninstruction following demonstrate the effectiveness of value-guided decoding\napproaches in aligning language models. These approaches not only achieve\nalignment but also significantly reduce computational costs by leveraging\nprincipled value function optimization for efficient and effective control.\n","authors":["Zhenhua Liu","Lijun Li","Ruizhe Chen","Yuxian Jiang","Tong Zhu","Zhaochen Su","Wenliang Chen","Jing Shao"],"pdf_url":"https://arxiv.org/pdf/2503.02368v2.pdf","comment":"20 pages, 10 figures"},{"id":"http://arxiv.org/abs/2503.03285v1","updated":"2025-03-05T09:12:16Z","published":"2025-03-05T09:12:16Z","title":"Enhancing Vietnamese VQA through Curriculum Learning on Raw and\n  Augmented Text Representations","summary":"  Visual Question Answering (VQA) is a multimodal task requiring reasoning\nacross textual and visual inputs, which becomes particularly challenging in\nlow-resource languages like Vietnamese due to linguistic variability and the\nlack of high-quality datasets. Traditional methods often rely heavily on\nextensive annotated datasets, computationally expensive pipelines, and large\npre-trained models, specifically in the domain of Vietnamese VQA, limiting\ntheir applicability in such scenarios. To address these limitations, we propose\na training framework that combines a paraphrase-based feature augmentation\nmodule with a dynamic curriculum learning strategy. Explicitly, augmented\nsamples are considered \"easy\" while raw samples are regarded as \"hard\". The\nframework then utilizes a mechanism that dynamically adjusts the ratio of easy\nto hard samples during training, progressively modifying the same dataset to\nincrease its difficulty level. By enabling gradual adaptation to task\ncomplexity, this approach helps the Vietnamese VQA model generalize well, thus\nimproving overall performance. Experimental results show consistent\nimprovements on the OpenViVQA dataset and mixed outcomes on the ViVQA dataset,\nhighlighting both the potential and challenges of our approach in advancing VQA\nfor Vietnamese language.\n","authors":["Khoi Anh Nguyen","Linh Yen Vu","Thang Dinh Duong","Thuan Nguyen Duong","Huy Thanh Nguyen","Vinh Quang Dinh"],"pdf_url":"https://arxiv.org/pdf/2503.03285v1.pdf","comment":"10 pages, 3 figures, AAAI-25 Workshop on Document Understanding and\n  Intelligence"},{"id":"http://arxiv.org/abs/2503.03283v1","updated":"2025-03-05T09:09:01Z","published":"2025-03-05T09:09:01Z","title":"Exploring specialization and sensitivity of convolutional neural\n  networks in the context of simultaneous image augmentations","summary":"  Drawing parallels with the way biological networks are studied, we adapt the\ntreatment--control paradigm to explainable artificial intelligence research and\nenrich it through multi-parametric input alterations. In this study, we propose\na framework for investigating the internal inference impacted by input data\naugmentations. The internal changes in network operation are reflected in\nactivation changes measured by variance, which can be decomposed into\ncomponents related to each augmentation, employing Sobol indices and Shapley\nvalues. These quantities enable one to visualize sensitivity to different\nvariables and use them for guided masking of activations. In addition, we\nintroduce a way of single-class sensitivity analysis where the candidates are\nfiltered according to their matching to prediction bias generated by targeted\ndamaging of the activations. Relying on the observed parallels, we assume that\nthe developed framework can potentially be transferred to studying biological\nneural networks in complex environments.\n","authors":["Pavel Kharyuk","Sergey Matveev","Ivan Oseledets"],"pdf_url":"https://arxiv.org/pdf/2503.03283v1.pdf","comment":"26 pages; main text: 5 figures, 4 tables; appendix: 4 sections, 3\n  tables; supplementary: 7 files (figures S1-S6: packed as 7z archive, S7:\n  single pdf file)"},{"id":"http://arxiv.org/abs/2410.17967v2","updated":"2025-03-05T09:05:23Z","published":"2024-10-23T15:34:11Z","title":"POMDP-Driven Cognitive Massive MIMO Radar: Joint Target\n  Detection-Tracking In Unknown Disturbances","summary":"  The joint detection and tracking of a moving target embedded in an unknown\ndisturbance represents a key feature that motivates the development of the\ncognitive radar paradigm. Building upon recent advancements in robust target\ndetection with multiple-input multiple-output (MIMO) radars, this work explores\nthe application of a Partially Observable Markov Decision Process (POMDP)\nframework to enhance the tracking and detection tasks in a statistically\nunknown environment. In the POMDP setup, the radar system is considered as an\nintelligent agent that continuously senses the surrounding environment,\noptimizing its actions to maximize the probability of detection $(P_D)$ and\nimprove the target position and velocity estimation, all this while keeping a\nconstant probability of false alarm $(P_{FA})$. The proposed approach employs\nan online algorithm that does not require any apriori knowledge of the noise\nstatistics, and it relies on a much more general observation model than the\ntraditional range-azimuth-elevation model employed by conventional tracking\nalgorithms. Simulation results clearly show substantial performance improvement\nof the POMDP-based algorithm compared to the State-Action-Reward-State-Action\n(SARSA)-based one that has been recently investigated in the context of massive\nMIMO (MMIMO) radar systems.\n","authors":["Imad Bouhou","Stefano Fortunati","Leila Gharsalli","Alexandre Renaux"],"pdf_url":"https://arxiv.org/pdf/2410.17967v2.pdf","comment":"The paper has been submitted to ieee Transactions on radar systems"},{"id":"http://arxiv.org/abs/2503.03276v1","updated":"2025-03-05T08:59:06Z","published":"2025-03-05T08:59:06Z","title":"TrafficKAN-GCN: Graph Convolutional-based Kolmogorov-Arnold Network for\n  Traffic Flow Optimization","summary":"  Urban traffic optimization is critical for improving transportation\nefficiency and alleviating congestion, particularly in large-scale dynamic\nnetworks. Traditional methods, such as Dijkstra's and Floyd's algorithms,\nprovide effective solutions in static settings, but they struggle with the\nspatial-temporal complexity of real-world traffic flows. In this work, we\npropose TrafficKAN-GCN, a hybrid deep learning framework combining\nKolmogorov-Arnold Networks (KAN) with Graph Convolutional Networks (GCN),\ndesigned to enhance urban traffic flow optimization. By integrating KAN's\nadaptive nonlinear function approximation with GCN's spatial graph learning\ncapabilities, TrafficKAN-GCN captures both complex traffic patterns and\ntopological dependencies. We evaluate the proposed framework using real-world\ntraffic data from the Baltimore Metropolitan area. Compared with baseline\nmodels such as MLP-GCN, standard GCN, and Transformer-based approaches,\nTrafficKAN-GCN achieves competitive prediction accuracy while demonstrating\nimproved robustness in handling noisy and irregular traffic data. Our\nexperiments further highlight the framework's ability to redistribute traffic\nflow, mitigate congestion, and adapt to disruptive events, such as the Francis\nScott Key Bridge collapse. This study contributes to the growing body of work\non hybrid graph learning for intelligent transportation systems, highlighting\nthe potential of combining KAN and GCN for real-time traffic optimization.\nFuture work will focus on reducing computational overhead and integrating\nTransformer-based temporal modeling for enhanced long-term traffic prediction.\nThe proposed TrafficKAN-GCN framework offers a promising direction for\ndata-driven urban mobility management, balancing predictive accuracy,\nrobustness, and computational efficiency.\n","authors":["Jiayi Zhang","Yiming Zhang","Yuan Zheng","Yuchen Wang","Jinjiang You","Yuchen Xu","Wenxing Jiang","Soumyabrata Dev"],"pdf_url":"https://arxiv.org/pdf/2503.03276v1.pdf","comment":"21 pages, 14 figures"},{"id":"http://arxiv.org/abs/2503.03274v1","updated":"2025-03-05T08:56:26Z","published":"2025-03-05T08:56:26Z","title":"Benchmarking Dynamic SLO Compliance in Distributed Computing Continuum\n  Systems","summary":"  Ensuring Service Level Objectives (SLOs) in large-scale architectures, such\nas Distributed Computing Continuum Systems (DCCS), is challenging due to their\nheterogeneous nature and varying service requirements across different devices\nand applications. Additionally, unpredictable workloads and resource\nlimitations lead to fluctuating performance and violated SLOs. To improve SLO\ncompliance in DCCS, one possibility is to apply machine learning; however, the\ndesign choices are often left to the developer. To that extent, we provide a\nbenchmark of Active Inference -- an emerging method from neuroscience --\nagainst three established reinforcement learning algorithms (Deep Q-Network,\nAdvantage Actor-Critic, and Proximal Policy Optimization). We consider a\nrealistic DCCS use case: an edge device running a video conferencing\napplication alongside a WebSocket server streaming videos. Using one of the\nrespective algorithms, we continuously monitor key performance metrics, such as\nlatency and bandwidth usage, to dynamically adjust parameters -- including the\nnumber of streams, frame rate, and resolution -- to optimize service quality\nand user experience. To test algorithms' adaptability to constant system\nchanges, we simulate dynamically changing SLOs and both instant and gradual\ndata-shift scenarios, such as network bandwidth limitations and fluctuating\ndevice thermal states. Although the evaluated algorithms all showed advantages\nand limitations, our findings demonstrate that Active Inference is a promising\napproach for ensuring SLO compliance in DCCS, offering lower memory usage,\nstable CPU utilization, and fast convergence.\n","authors":["Alfreds Lapkovskis","Boris Sedlak","Sindri Magnússon","Schahram Dustdar","Praveen Kumar Donta"],"pdf_url":"https://arxiv.org/pdf/2503.03274v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03269v1","updated":"2025-03-05T08:50:53Z","published":"2025-03-05T08:50:53Z","title":"Conformal Transformations for Symmetric Power Transformers","summary":"  Transformers with linear attention offer significant computational advantages\nover softmax-based transformers but often suffer from degraded performance. The\nsymmetric power (sympow) transformer, a particular type of linear transformer,\naddresses some of this performance gap by leveraging symmetric tensor\nembeddings, achieving comparable performance to softmax transformers. However,\nthe finite capacity of the recurrent state in sympow transformers limits their\nability to retain information, leading to performance degradation when scaling\nthe training or evaluation context length. To address this issue, we propose\nthe conformal-sympow transformer, which dynamically frees up capacity using\ndata-dependent multiplicative gating and adaptively stores information using\ndata-dependent rotary embeddings. Preliminary experiments on the LongCrawl64\ndataset demonstrate that conformal-sympow overcomes the limitations of sympow\ntransformers, achieving robust performance across scaled training and\nevaluation contexts.\n","authors":["Saurabh Kumar","Jacob Buckman","Carles Gelada","Sean Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.03269v1.pdf","comment":"SCOPE Workshop at ICLR 2025"},{"id":"http://arxiv.org/abs/2412.06464v2","updated":"2025-03-05T08:47:27Z","published":"2024-12-09T13:09:04Z","title":"Gated Delta Networks: Improving Mamba2 with Delta Rule","summary":"  Linear Transformers have gained attention as efficient alternatives to\nstandard Transformers, but their performance in retrieval and long-context\ntasks has been limited. To address these limitations, recent work has explored\ntwo distinct mechanisms: gating for adaptive memory control and the delta\nupdate rule for precise memory modifications. We observe that these mechanisms\nare complementary: gating enables rapid memory erasure while the delta rule\nfacilitates targeted updates. Building on this insight, we introduce the gated\ndelta rule and develop a parallel training algorithm optimized for modern\nhardware. Our proposed architecture, Gated DeltaNet, consistently surpasses\nexisting models like Mamba2 and DeltaNet across multiple benchmarks, including\nlanguage modeling, common-sense reasoning, in-context retrieval, length\nextrapolation, and long-context understanding. We further enhance performance\nby developing hybrid architectures that combine Gated DeltaNet layers with\nsliding window attention or Mamba2 layers, achieving both improved training\nefficiency and superior task performance.\n","authors":["Songlin Yang","Jan Kautz","Ali Hatamizadeh"],"pdf_url":"https://arxiv.org/pdf/2412.06464v2.pdf","comment":"ICLR 2025 camera ready"},{"id":"http://arxiv.org/abs/2408.07246v3","updated":"2025-03-05T08:43:44Z","published":"2024-08-14T01:16:40Z","title":"ChemVLM: Exploring the Power of Multimodal Large Language Models in\n  Chemistry Area","summary":"  Large Language Models (LLMs) have achieved remarkable success and have been\napplied across various scientific fields, including chemistry. However, many\nchemical tasks require the processing of visual information, which cannot be\nsuccessfully handled by existing chemical LLMs. This brings a growing need for\nmodels capable of integrating multimodal information in the chemical domain. In\nthis paper, we introduce \\textbf{ChemVLM}, an open-source chemical multimodal\nlarge language model specifically designed for chemical applications. ChemVLM\nis trained on a carefully curated bilingual multimodal dataset that enhances\nits ability to understand both textual and visual chemical information,\nincluding molecular structures, reactions, and chemistry examination questions.\nWe develop three datasets for comprehensive evaluation, tailored to Chemical\nOptical Character Recognition (OCR), Multimodal Chemical Reasoning (MMCR), and\nMultimodal Molecule Understanding tasks. We benchmark ChemVLM against a range\nof open-source and proprietary multimodal large language models on various\ntasks. Experimental results demonstrate that ChemVLM achieves competitive\nperformance across all evaluated tasks. Our model can be found at\nhttps://huggingface.co/AI4Chem/ChemVLM-26B.\n","authors":["Junxian Li","Di Zhang","Xunzhi Wang","Zeying Hao","Jingdi Lei","Qian Tan","Cai Zhou","Wei Liu","Yaotian Yang","Xinrui Xiong","Weiyun Wang","Zhe Chen","Wenhai Wang","Wei Li","Shufei Zhang","Mao Su","Wanli Ouyang","Yuqiang Li","Dongzhan Zhou"],"pdf_url":"https://arxiv.org/pdf/2408.07246v3.pdf","comment":"11 pages, updated version"},{"id":"http://arxiv.org/abs/2502.16232v2","updated":"2025-03-05T08:42:40Z","published":"2025-02-22T14:04:23Z","title":"Flow-based Bayesian filtering for high-dimensional nonlinear stochastic\n  dynamical systems","summary":"  Bayesian filtering for high-dimensional nonlinear stochastic dynamical\nsystems is a fundamental yet challenging problem in many fields of science and\nengineering. Existing methods face significant obstacles: Gaussian-based\nfilters struggle with non-Gaussian distributions, while sequential Monte Carlo\nmethods are computationally intensive and prone to particle degeneracy in high\ndimensions. Although generative models in machine learning have made\nsignificant progress in modeling high-dimensional non-Gaussian distributions,\ntheir inefficiency in online updating limits their applicability to filtering\nproblems. To address these challenges, we propose a flow-based Bayesian filter\n(FBF) that integrates normalizing flows to construct a novel latent linear\nstate-space model with Gaussian filtering distributions. This framework\nfacilitates efficient density estimation and sampling using invertible\ntransformations provided by normalizing flows, and it enables the construction\nof filters in a data-driven manner, without requiring prior knowledge of system\ndynamics or observation models. Numerical experiments demonstrate the superior\naccuracy and efficiency of FBF.\n","authors":["Xintong Wang","Xiaofei Guan","Ling Guo","Hao Wu"],"pdf_url":"https://arxiv.org/pdf/2502.16232v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03262v1","updated":"2025-03-05T08:38:51Z","published":"2025-03-05T08:38:51Z","title":"Trajectory Prediction for Autonomous Driving: Progress, Limitations, and\n  Future Directions","summary":"  As the potential for autonomous vehicles to be integrated on a large scale\ninto modern traffic systems continues to grow, ensuring safe navigation in\ndynamic environments is crucial for smooth integration. To guarantee safety and\nprevent collisions, autonomous vehicles must be capable of accurately\npredicting the trajectories of surrounding traffic agents. Over the past\ndecade, significant efforts from both academia and industry have been dedicated\nto designing solutions for precise trajectory forecasting. These efforts have\nproduced a diverse range of approaches, raising questions about the differences\nbetween these methods and whether trajectory prediction challenges have been\nfully addressed. This paper reviews a substantial portion of recent trajectory\nprediction methods and devises a taxonomy to classify existing solutions. A\ngeneral overview of the prediction pipeline is also provided, covering input\nand output modalities, modeling features, and prediction paradigms discussed in\nthe literature. In addition, the paper discusses active research areas within\ntrajectory prediction, addresses the posed research questions, and highlights\nthe remaining research gaps and challenges.\n","authors":["Nadya Abdel Madjid","Abdulrahman Ahmad","Murad Mebrahtu","Yousef Babaa","Abdelmoamen Nasser","Sumbal Malik","Bilal Hassan","Naoufel Werghi","Jorge Dias","Majid Khonji"],"pdf_url":"https://arxiv.org/pdf/2503.03262v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.04910v3","updated":"2025-03-05T08:37:17Z","published":"2024-12-06T10:05:10Z","title":"Learning High-Degree Parities: The Crucial Role of the Initialization","summary":"  Parities have become a standard benchmark for evaluating learning algorithms.\nRecent works show that regular neural networks trained by gradient descent can\nefficiently learn degree $k$ parities on uniform inputs for constant $k$, but\nfail to do so when $k$ and $d-k$ grow with $d$ (here $d$ is the ambient\ndimension). However, the case where $k=d-O_d(1)$ (almost-full parities),\nincluding the degree $d$ parity (the full parity), has remained unsettled. This\npaper shows that for gradient descent on regular neural networks, learnability\ndepends on the initial weight distribution. On one hand, the discrete\nRademacher initialization enables efficient learning of almost-full parities,\nwhile on the other hand, its Gaussian perturbation with large enough constant\nstandard deviation $\\sigma$ prevents it. The positive result for almost-full\nparities is shown to hold up to $\\sigma=O(d^{-1})$, pointing to questions about\na sharper threshold phenomenon. Unlike statistical query (SQ) learning, where a\nsingleton function class like the full parity is trivially learnable, our\nnegative result applies to a fixed function and relies on an initial gradient\nalignment measure of potential broader relevance to neural networks learning.\n","authors":["Emmanuel Abbe","Elisabetta Cornacchia","Jan Hązła","Donald Kougang-Yombi"],"pdf_url":"https://arxiv.org/pdf/2412.04910v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.06927v3","updated":"2025-03-05T08:35:41Z","published":"2024-08-13T14:29:00Z","title":"Breaking Class Barriers: Efficient Dataset Distillation via Inter-Class\n  Feature Compensator","summary":"  Dataset distillation has emerged as a technique aiming to condense\ninformative features from large, natural datasets into a compact and synthetic\nform. While recent advancements have refined this technique, its performance is\nbottlenecked by the prevailing class-specific synthesis paradigm. Under this\nparadigm, synthetic data is optimized exclusively for a pre-assigned one-hot\nlabel, creating an implicit class barrier in feature condensation. This leads\nto inefficient utilization of the distillation budget and oversight of\ninter-class feature distributions, which ultimately limits the effectiveness\nand efficiency, as demonstrated in our analysis. To overcome these constraints,\nthis paper presents the Inter-class Feature Compensator (INFER), an innovative\ndistillation approach that transcends the class-specific data-label framework\nwidely utilized in current dataset distillation methods. Specifically, INFER\nleverages a Universal Feature Compensator (UFC) to enhance feature integration\nacross classes, enabling the generation of multiple additional synthetic\ninstances from a single UFC input. This significantly improves the efficiency\nof the distillation budget. Moreover, INFER enriches inter-class interactions\nduring the distillation, thereby enhancing the effectiveness and\ngeneralizability of the distilled data. By allowing for the linear\ninterpolation of labels similar to those in the original dataset, INFER\nmeticulously optimizes the synthetic data and dramatically reduces the size of\nsoft labels in the synthetic dataset to almost zero, establishing a new\nbenchmark for efficiency and effectiveness in dataset distillation. In\npractice, INFER demonstrates state-of-the-art performance across benchmark\ndatasets. For instance, in the ipc = 50 setting on ImageNet-1k with the same\ncompression level, it outperforms SRe2L by 34.5% using ResNet18.\n","authors":["Xin Zhang","Jiawei Du","Ping Liu","Joey Tianyi Zhou"],"pdf_url":"https://arxiv.org/pdf/2408.06927v3.pdf","comment":"Accepted to ICLR 2025"},{"id":"http://arxiv.org/abs/2305.15759v6","updated":"2025-03-05T08:34:25Z","published":"2023-05-25T06:18:31Z","title":"DP-LDMs: Differentially Private Latent Diffusion Models","summary":"  Diffusion models (DMs) are one of the most widely used generative models for\nproducing high quality images. However, a flurry of recent papers points out\nthat DMs are least private forms of image generators, by extracting a\nsignificant number of near-identical replicas of training images from DMs.\nExisting privacy-enhancing techniques for DMs, unfortunately, do not provide a\ngood privacy-utility tradeoff. In this paper, we aim to improve the current\nstate of DMs with differential privacy (DP) by adopting the $\\textit{Latent}$\nDiffusion Models (LDMs). LDMs are equipped with powerful pre-trained\nautoencoders that map the high-dimensional pixels into lower-dimensional latent\nrepresentations, in which DMs are trained, yielding a more efficient and fast\ntraining of DMs. Rather than fine-tuning the entire LDMs, we fine-tune only the\n$\\textit{attention}$ modules of LDMs with DP-SGD, reducing the number of\ntrainable parameters by roughly $90\\%$ and achieving a better privacy-accuracy\ntrade-off. Our approach allows us to generate realistic, high-dimensional\nimages (256x256) conditioned on text prompts with DP guarantees, which, to the\nbest of our knowledge, has not been attempted before. Our approach provides a\npromising direction for training more powerful, yet training-efficient\ndifferentially private DMs, producing high-quality DP images. Our code is\navailable at https://anonymous.4open.science/r/DP-LDM-4525.\n","authors":["Michael F. Liu","Saiyue Lyu","Margarita Vinaroz","Mijung Park"],"pdf_url":"https://arxiv.org/pdf/2305.15759v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03258v1","updated":"2025-03-05T08:28:11Z","published":"2025-03-05T08:28:11Z","title":"Exploring the Potential of Large Language Models as Predictors in\n  Dynamic Text-Attributed Graphs","summary":"  With the rise of large language models (LLMs), there has been growing\ninterest in Graph Foundation Models (GFMs) for graph-based tasks. By leveraging\nLLMs as predictors, GFMs have demonstrated impressive generalizability across\nvarious tasks and datasets. However, existing research on LLMs as predictors\nhas predominantly focused on static graphs, leaving their potential in dynamic\ngraph prediction unexplored. In this work, we pioneer using LLMs for predictive\ntasks on dynamic graphs. We identify two key challenges: the constraints\nimposed by context length when processing large-scale historical data and the\nsignificant variability in domain characteristics, both of which complicate the\ndevelopment of a unified predictor. To address these challenges, we propose the\nGraphAgent-Dynamic (GAD) Framework, a multi-agent system that leverages\ncollaborative LLMs. In contrast to using a single LLM as the predictor, GAD\nincorporates global and local summary agents to generate domain-specific\nknowledge, enhancing its transferability across domains. Additionally,\nknowledge reflection agents enable adaptive updates to GAD's knowledge,\nmaintaining a unified and self-consistent architecture. In experiments, GAD\ndemonstrates performance comparable to or even exceeds that of full-supervised\ngraph neural networks without dataset-specific training. Finally, to enhance\nthe task-specific performance of LLM-based predictors, we discuss potential\nimprovements, such as dataset-specific fine-tuning to LLMs. By developing\ntailored strategies for different tasks, we provide new insights for the future\ndesign of LLM-based predictors.\n","authors":["Runlin Lei","Jiarui Ji","Haipeng Ding","Lu Yi","Zhewei Wei","Yongchao Liu","Chuntao Hong"],"pdf_url":"https://arxiv.org/pdf/2503.03258v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.01669v2","updated":"2025-03-05T08:23:02Z","published":"2024-01-16T13:41:00Z","title":"Improved Performances and Motivation in Intelligent Tutoring Systems:\n  Combining Machine Learning and Learner Choice","summary":"  Large class sizes challenge personalized learning in schools, prompting the\nuse of educational technologies such as intelligent tutoring systems. To\naddress this, we present an AI-driven personalization system, called ZPDES,\nbased on the Learning Progress Hypothesis - modeling curiosity-driven learning\n- and multi-armed bandit techniques. It sequences exercises that maximize\nlearning progress for each student. While previous studies demonstrated its\nefficacy in enhancing learning compared to hand-made curricula, its impact on\nstudent motivation remained unexplored. Furthermore, ZPDES previously lacked\nfeatures allowing student choice, a limitation in agency that conflicts with\nits foundation on models of curiosity-driven learning. This study investigates\nhow integrating choice, as a gamification element unrelated to exercise\ndifficulty, affects both learning outcomes and motivation. We conducted an\nextensive field study (265 7-8 years old children, RCT design), comparing ZPDES\nwith and without choice against a hand-designed curriculum. Results show that\nZPDES improves both learning performance and the learning experience. Moreover\nadding choice to ZPDES enhances intrinsic motivation and further strengthens\nits learning benefits. In contrast, incorporating choice into a fixed, linear\ncurriculum negatively impacts learning outcomes. These findings highlight that\nthe intrinsic motivation elicited by choice (gamification) is beneficial only\nwhen paired with an adaptive personalized learning system. This insight is\ncritical as gamified features become increasingly prevalent in educational\ntechnologies.\n","authors":["Benjamin Clément","Hélène Sauzéon","Didier Roy","Pierre-Yves Oudeyer"],"pdf_url":"https://arxiv.org/pdf/2402.01669v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01297v2","updated":"2025-03-05T08:03:39Z","published":"2025-03-03T08:33:35Z","title":"Regularization-based Framework for Quantization-, Fault- and\n  Variability-Aware Training","summary":"  Efficient inference is critical for deploying deep learning models on edge AI\ndevices. Low-bit quantization (e.g., 3- and 4-bit) with fixed-point arithmetic\nimproves efficiency, while low-power memory technologies like analog\nnonvolatile memory enable further gains. However, these methods introduce\nnon-ideal hardware behavior, including bit faults and device-to-device\nvariability. We propose a regularization-based quantization-aware training\n(QAT) framework that supports fixed, learnable step-size, and learnable\nnon-uniform quantization, achieving competitive results on CIFAR-10 and\nImageNet. Our method also extends to Spiking Neural Networks (SNNs),\ndemonstrating strong performance on 4-bit networks on CIFAR10-DVS and N-Caltech\n101. Beyond quantization, our framework enables fault and variability-aware\nfine-tuning, mitigating stuck-at faults (fixed weight bits) and device\nresistance variability. Compared to prior fault-aware training, our approach\nsignificantly improves performance recovery under upto 20% bit-fault rate and\n40% device-to-device variability. Our results establish a generalizable\nframework for quantization and robustness-aware training, enhancing efficiency\nand reliability in low-power, non-ideal hardware.\n","authors":["Anmol Biswas","Raghav Singhal","Sivakumar Elangovan","Shreyas Sabnis","Udayan Ganguly"],"pdf_url":"https://arxiv.org/pdf/2503.01297v2.pdf","comment":"AB and RS contributed equally to this work. A version of this paper\n  accepted at MLNCP @ NeuRIPS '24"},{"id":"http://arxiv.org/abs/2503.03245v1","updated":"2025-03-05T07:53:39Z","published":"2025-03-05T07:53:39Z","title":"Less is more? Rewards in RL for Cyber Defence","summary":"  The last few years has seen an explosion of interest in autonomous cyber\ndefence agents based on deep reinforcement learning. Such agents are typically\ntrained in a cyber gym environment, also known as a cyber simulator, at least\n32 of which have already been built. Most, if not all cyber gyms provide dense\n\"scaffolded\" reward functions which combine many penalties or incentives for a\nrange of (un)desirable states and costly actions. Whilst dense rewards help\nalleviate the challenge of exploring complex environments, yielding seemingly\neffective strategies from relatively few environment steps; they are also known\nto bias the solutions an agent can find, potentially towards suboptimal\nsolutions. Sparse rewards could offer preferable or more effective solutions\nand have been overlooked by cyber gyms to date. In this work we set out to\nevaluate whether sparse reward functions might enable training more effective\ncyber defence agents. Towards this goal we first break down several evaluation\nlimitations in existing work by proposing a ground truth evaluation score that\ngoes beyond the standard RL paradigm used to train and evaluate agents. By\nadapting a well-established cyber gym to accommodate our methodology and ground\ntruth score, we propose and evaluate two sparse reward mechanisms and compare\nthem with a typical dense reward. Our evaluation considers a range of network\nsizes, from 2 to 50 nodes, and both reactive and proactive defensive actions.\nOur results show that sparse rewards, particularly positive reinforcement for\nan uncompromised network state, enable the training of more effective cyber\ndefence agents. Furthermore, we show that sparse rewards provide more stable\ntraining than dense rewards, and that both effectiveness and training stability\nare robust to a variety of cyber environment considerations.\n","authors":["Elizabeth Bates","Chris Hicks","Vasilios Mavroudis"],"pdf_url":"https://arxiv.org/pdf/2503.03245v1.pdf","comment":"4 Pages"},{"id":"http://arxiv.org/abs/2503.03241v1","updated":"2025-03-05T07:47:57Z","published":"2025-03-05T07:47:57Z","title":"Structural Entropy Guided Unsupervised Graph Out-Of-Distribution\n  Detection","summary":"  With the emerging of huge amount of unlabeled data, unsupervised\nout-of-distribution (OOD) detection is vital for ensuring the reliability of\ngraph neural networks (GNNs) by identifying OOD samples from in-distribution\n(ID) ones during testing, where encountering novel or unknown data is\ninevitable. Existing methods often suffer from compromised performance due to\nredundant information in graph structures, which impairs their ability to\neffectively differentiate between ID and OOD data. To address this challenge,\nwe propose SEGO, an unsupervised framework that integrates structural entropy\ninto OOD detection regarding graph classification. Specifically, within the\narchitecture of contrastive learning, SEGO introduces an anchor view in the\nform of coding tree by minimizing structural entropy. The obtained coding tree\neffectively removes redundant information from graphs while preserving\nessential structural information, enabling the capture of distinct graph\npatterns between ID and OOD samples. Furthermore, we present a multi-grained\ncontrastive learning scheme at local, global, and tree levels using triplet\nviews, where coding trees with essential information serve as the anchor view.\nExtensive experiments on real-world datasets validate the effectiveness of\nSEGO, demonstrating superior performance over state-of-the-art baselines in OOD\ndetection. Specifically, our method achieves the best performance on 9 out of\n10 dataset pairs, with an average improvement of 3.7\\% on OOD detection\ndatasets, significantly surpassing the best competitor by 10.8\\% on the\nFreeSolv/ToxCast dataset pair.\n","authors":["Yue Hou","He Zhu","Ruomei Liu","Yingke Su","Jinxiang Xia","Junran Wu","Ke Xu"],"pdf_url":"https://arxiv.org/pdf/2503.03241v1.pdf","comment":"Accepted by AAAI 2025 (The 39th Annual AAAI Conference on Artificial\n  Intelligence)"},{"id":"http://arxiv.org/abs/2503.03239v1","updated":"2025-03-05T07:45:56Z","published":"2025-03-05T07:45:56Z","title":"PAIR: A Novel Large Language Model-Guided Selection Strategy for\n  Evolutionary Algorithms","summary":"  Evolutionary Algorithms (EAs) employ random or simplistic selection methods,\nlimiting their exploration of solution spaces and convergence to optimal\nsolutions. The randomness in performing crossover or mutations may limit the\nmodel's ability to evolve efficiently. This paper introduces Preference-Aligned\nIndividual Reciprocity (PAIR), a novel selection approach leveraging Large\nLanguage Models to emulate human-like mate selection, thereby introducing\nintelligence to the pairing process in EAs. PAIR prompts an LLM to evaluate\nindividuals within a population based on genetic diversity, fitness level, and\ncrossover compatibility, guiding more informed pairing decisions. We evaluated\nPAIR against a baseline method called LLM-driven EA (LMEA), published recently.\nResults indicate that PAIR significantly outperforms LMEA across various TSP\ninstances, achieving lower optimality gaps and improved convergence. This\nperformance is especially noticeable when combined with the flash thinking\nmodel, demonstrating increased population diversity to escape local optima. In\ngeneral, PAIR provides a new strategy in the area of in-context learning for\nLLM-driven selection in EAs via sophisticated preference modelling, paving the\nway for improved solutions and further studies into LLM-guided optimization.\n","authors":["Shady Ali","Mahmoud Ashraf","Seif Hegazy","Fatty Salem","Hoda Mokhtar","Mohamed Medhat Gaber","Mohamed Taher Alrefaie"],"pdf_url":"https://arxiv.org/pdf/2503.03239v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03237v1","updated":"2025-03-05T07:31:06Z","published":"2025-03-05T07:31:06Z","title":"Prediction of Halo Coronal Mass Ejections Using SDO/HMI Vector Magnetic\n  Data Products and a Transformer Model","summary":"  We present a transformer model, named DeepHalo, to predict the occurrence of\nhalo coronal mass ejections (CMEs). Our model takes as input an active region\n(AR) and a profile, where the profile contains a time series of data samples in\nthe AR that are collected 24 hours before the beginning of a day, and predicts\nwhether the AR would produce a halo CME during that day. Each data sample\ncontains physical parameters, or features, derived from photospheric vector\nmagnetic field data taken by the Helioseismic and Magnetic Imager (HMI) on\nboard the Solar Dynamics Observatory (SDO). We survey and match CME events in\nthe Space Weather Database Of Notification, Knowledge, Information (DONKI) and\nLarge Angle and Spectrometric Coronagraph (LASCO) CME Catalog, and compile a\nlist of CMEs including halo CMEs and non-halo CMEs associated with ARs in the\nperiod between November 2010 and August 2023. We use the information gathered\nabove to build the labels (positive versus negative) of the data samples and\nprofiles at hand, where the labels are needed for machine learning.\nExperimental results show that DeepHalo with a true skill statistics (TSS)\nscore of 0.907 outperforms a closely related long short-term memory network\nwith a TSS score of 0.821. To our knowledge, this is the first time that the\ntransformer model has been used for halo CME prediction.\n","authors":["Hongyang Zhang","Ju Jing","Jason T. L. Wang","Haimin Wang","Yasser Abduallah","Yan Xu","Khalid A. Alobaid","Hameedullah Farooki","Vasyl Yurchyshyn"],"pdf_url":"https://arxiv.org/pdf/2503.03237v1.pdf","comment":"13 pages, 8 figures"},{"id":"http://arxiv.org/abs/2412.17107v3","updated":"2025-03-05T07:29:42Z","published":"2024-12-22T17:39:32Z","title":"Grams: Gradient Descent with Adaptive Momentum Scaling","summary":"  We introduce $\\mathbf{G}$radient Descent with $\\mathbf{A}$daptive\n$\\mathbf{M}$omentum $\\mathbf{S}$caling ($\\mathbf{Grams}$), a novel optimization\nalgorithm that decouples the direction and magnitude of parameter updates in\ndeep learning. Unlike traditional optimizers that directly integrate momentum\ninto updates, Grams separates the update direction, derived from current\ngradients, from momentum, which is used solely for adaptive magnitude scaling.\nThis approach enables Grams to achieve improved loss descent compared to\nstate-of-the-art cautious and momentum-based optimizers. We theoretically\ndemonstrate that Grams descents faster than other state-of-the-art optimizers\nand establish a global convergence guarantee for Grams. We also validate its\neffectiveness through extensive empirical evaluations. The results demonstrate\nGrams' superior performance, including faster convergence and better\ngeneralization, compared to widely-used optimizers such as Adam, Lion, and\ntheir cautious variants. Our results highlight Grams' potential as a\ntransformative approach for efficiently training and fine-tuning large language\nmodels. Code is available at https://github.com/Gunale0926/Grams.\n","authors":["Yang Cao","Xiaoyu Li","Zhao Song"],"pdf_url":"https://arxiv.org/pdf/2412.17107v3.pdf","comment":"SCOPE Workshop @ ICLR 2025"},{"id":"http://arxiv.org/abs/2407.01214v3","updated":"2025-03-05T07:02:28Z","published":"2024-07-01T11:59:59Z","title":"Revisiting Random Walks for Learning on Graphs","summary":"  We revisit a simple model class for machine learning on graphs, where a\nrandom walk on a graph produces a machine-readable record, and this record is\nprocessed by a deep neural network to directly make vertex-level or graph-level\npredictions. We call these stochastic machines random walk neural networks\n(RWNNs), and through principled analysis, show that we can design them to be\nisomorphism invariant while capable of universal approximation of graph\nfunctions in probability. A useful finding is that almost any kind of record of\nrandom walks guarantees probabilistic invariance as long as the vertices are\nanonymized. This enables us, for example, to record random walks in plain text\nand adopt a language model to read these text records to solve graph tasks. We\nfurther establish a parallelism to message passing neural networks using tools\nfrom Markov chain theory, and show that over-smoothing in message passing is\nalleviated by construction in RWNNs, while over-squashing manifests as\nprobabilistic under-reaching. We empirically demonstrate RWNNs on a range of\nproblems, verifying our theoretical analysis and demonstrating the use of\nlanguage models for separating strongly regular graphs where 3-WL test fails,\nand transductive classification on arXiv citation network. Code is available at\nhttps://github.com/jw9730/random-walk.\n","authors":["Jinwoo Kim","Olga Zaghen","Ayhan Suleymanzade","Youngmin Ryou","Seunghoon Hong"],"pdf_url":"https://arxiv.org/pdf/2407.01214v3.pdf","comment":"51 pages, 14 figures"},{"id":"http://arxiv.org/abs/2502.17543v2","updated":"2025-03-05T06:53:52Z","published":"2025-02-24T18:56:58Z","title":"Training a Generally Curious Agent","summary":"  Efficient exploration is essential for intelligent systems interacting with\ntheir environment, but existing language models often fall short in scenarios\nthat require strategic information gathering. In this paper, we present\nPAPRIKA, a fine-tuning approach that enables language models to develop general\ndecision-making capabilities that are not confined to particular environments.\nBy training on synthetic interaction data from different tasks that require\ndiverse strategies, PAPRIKA teaches models to explore and adapt their behavior\non a new task based on environment feedback in-context without more gradient\nupdates. Experimental results show that models fine-tuned with PAPRIKA can\neffectively transfer their learned decision-making capabilities to entirely\nunseen tasks without additional training. Unlike traditional training, our\napproach's primary bottleneck lies in sampling useful interaction data instead\nof model updates. To improve sample efficiency, we propose a curriculum\nlearning strategy that prioritizes sampling trajectories from tasks with high\nlearning potential. These results suggest a promising path towards AI systems\nthat can autonomously solve novel sequential decision-making problems that\nrequire interactions with the external world.\n","authors":["Fahim Tajwar","Yiding Jiang","Abitha Thankaraj","Sumaita Sadia Rahman","J Zico Kolter","Jeff Schneider","Ruslan Salakhutdinov"],"pdf_url":"https://arxiv.org/pdf/2502.17543v2.pdf","comment":"Project Website: https://paprika-llm.github.io"},{"id":"http://arxiv.org/abs/2407.10341v5","updated":"2025-03-05T06:53:17Z","published":"2024-07-14T21:41:29Z","title":"Affordance-Guided Reinforcement Learning via Visual Prompting","summary":"  Robots equipped with reinforcement learning (RL) have the potential to learn\na wide range of skills solely from a reward signal. However, obtaining a robust\nand dense reward signal for general manipulation tasks remains a challenge.\nExisting learning-based approaches require significant data, such as human\ndemonstrations of success and failure, to learn task-specific reward functions.\nRecently, there is also a growing adoption of large multi-modal foundation\nmodels for robotics that can perform visual reasoning in physical contexts and\ngenerate coarse robot motions for manipulation tasks. Motivated by this range\nof capability, in this work, we present Keypoint-based Affordance Guidance for\nImprovements (KAGI), a method leveraging rewards shaped by vision-language\nmodels (VLMs) for autonomous RL. State-of-the-art VLMs have demonstrated\nimpressive reasoning about affordances through keypoints in zero-shot, and we\nuse these to define dense rewards that guide autonomous robotic learning. On\nreal-world manipulation tasks specified by natural language descriptions, KAGI\nimproves the sample efficiency of autonomous RL and enables successful task\ncompletion in 30K online fine-tuning steps. Additionally, we demonstrate the\nrobustness of KAGI to reductions in the number of in-domain demonstrations used\nfor pre-training, reaching similar performance in 45K online fine-tuning steps.\nProject website: https://sites.google.com/view/affordance-guided-rl\n","authors":["Olivia Y. Lee","Annie Xie","Kuan Fang","Karl Pertsch","Chelsea Finn"],"pdf_url":"https://arxiv.org/pdf/2407.10341v5.pdf","comment":"8 pages, 6 figures. Robotics: Science and Systems (RSS) 2024, Task\n  Specification for General-Purpose Intelligent Robots & Lifelong Robot\n  Learning Workshops"},{"id":"http://arxiv.org/abs/2304.04172v2","updated":"2025-03-05T06:51:11Z","published":"2023-04-09T06:18:34Z","title":"$μ^2$-SGD: Stable Stochastic Optimization via a Double Momentum\n  Mechanism","summary":"  We consider stochastic convex optimization problems where the objective is an\nexpectation over smooth functions. For this setting we suggest a novel gradient\nestimate that combines two recent mechanism that are related to notion of\nmomentum. Then, we design an SGD-style algorithm as well as an accelerated\nversion that make use of this new estimator, and demonstrate the robustness of\nthese new approaches to the choice of the learning rate. Concretely, we show\nthat these approaches obtain the optimal convergence rates for both noiseless\nand noisy case with the same choice of fixed learning rate. Moreover, for the\nnoisy case we show that these approaches achieve the same optimal bound for a\nvery wide range of learning rates.\n","authors":["Tehila Dahan","Kfir Y. Levy"],"pdf_url":"https://arxiv.org/pdf/2304.04172v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.19908v2","updated":"2025-03-05T06:36:27Z","published":"2025-02-27T09:26:22Z","title":"CarPlanner: Consistent Auto-regressive Trajectory Planning for\n  Large-scale Reinforcement Learning in Autonomous Driving","summary":"  Trajectory planning is vital for autonomous driving, ensuring safe and\nefficient navigation in complex environments. While recent learning-based\nmethods, particularly reinforcement learning (RL), have shown promise in\nspecific scenarios, RL planners struggle with training inefficiencies and\nmanaging large-scale, real-world driving scenarios. In this paper, we introduce\n\\textbf{CarPlanner}, a \\textbf{C}onsistent \\textbf{a}uto-\\textbf{r}egressive\n\\textbf{Planner} that uses RL to generate multi-modal trajectories. The\nauto-regressive structure enables efficient large-scale RL training, while the\nincorporation of consistency ensures stable policy learning by maintaining\ncoherent temporal consistency across time steps. Moreover, CarPlanner employs a\ngeneration-selection framework with an expert-guided reward function and an\ninvariant-view module, simplifying RL training and enhancing policy\nperformance. Extensive analysis demonstrates that our proposed RL framework\neffectively addresses the challenges of training efficiency and performance\nenhancement, positioning CarPlanner as a promising solution for trajectory\nplanning in autonomous driving. To the best of our knowledge, we are the first\nto demonstrate that the RL-based planner can surpass both IL- and rule-based\nstate-of-the-arts (SOTAs) on the challenging large-scale real-world dataset\nnuPlan. Our proposed CarPlanner surpasses RL-, IL-, and rule-based SOTA\napproaches within this demanding dataset.\n","authors":["Dongkun Zhang","Jiaming Liang","Ke Guo","Sha Lu","Qi Wang","Rong Xiong","Zhenwei Miao","Yue Wang"],"pdf_url":"https://arxiv.org/pdf/2502.19908v2.pdf","comment":"CVPR 2025"},{"id":"http://arxiv.org/abs/2409.14494v3","updated":"2025-03-05T06:32:04Z","published":"2024-09-13T19:14:18Z","title":"CPT-Boosted Wav2vec2.0: Towards Noise Robust Speech Recognition for\n  Classroom Environments","summary":"  Creating Automatic Speech Recognition (ASR) systems that are robust and\nresilient to classroom conditions is paramount to the development of AI tools\nto aid teachers and students. In this work, we study the efficacy of continued\npretraining (CPT) in adapting Wav2vec2.0 to the classroom domain. We show that\nCPT is a powerful tool in that regard and reduces the Word Error Rate (WER) of\nWav2vec2.0-based models by upwards of 10%. More specifically, CPT improves the\nmodel's robustness to different noises, microphones and classroom conditions.\n","authors":["Ahmed Adel Attia","Dorottya Demszky","Tolulope Ogunremi","Jing Liu","Carol Espy-Wilson"],"pdf_url":"https://arxiv.org/pdf/2409.14494v3.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2405.13018"},{"id":"http://arxiv.org/abs/2503.03213v1","updated":"2025-03-05T06:11:24Z","published":"2025-03-05T06:11:24Z","title":"Convergence Rates for Softmax Gating Mixture of Experts","summary":"  Mixture of experts (MoE) has recently emerged as an effective framework to\nadvance the efficiency and scalability of machine learning models by softly\ndividing complex tasks among multiple specialized sub-models termed experts.\nCentral to the success of MoE is an adaptive softmax gating mechanism which\ntakes responsibility for determining the relevance of each expert to a given\ninput and then dynamically assigning experts their respective weights. Despite\nits widespread use in practice, a comprehensive study on the effects of the\nsoftmax gating on the MoE has been lacking in the literature. To bridge this\ngap in this paper, we perform a convergence analysis of parameter estimation\nand expert estimation under the MoE equipped with the standard softmax gating\nor its variants, including a dense-to-sparse gating and a hierarchical softmax\ngating, respectively. Furthermore, our theories also provide useful insights\ninto the design of sample-efficient expert structures. In particular, we\ndemonstrate that it requires polynomially many data points to estimate experts\nsatisfying our proposed \\emph{strong identifiability} condition, namely a\ncommonly used two-layer feed-forward network. In stark contrast, estimating\nlinear experts, which violate the strong identifiability condition,\nnecessitates exponentially many data points as a result of intrinsic parameter\ninteractions expressed in the language of partial differential equations. All\nthe theoretical results are substantiated with a rigorous guarantee.\n","authors":["Huy Nguyen","Nhat Ho","Alessandro Rinaldo"],"pdf_url":"https://arxiv.org/pdf/2503.03213v1.pdf","comment":"Section 2 of this work comes from our previous paper titled \"On Least\n  Square Estimation in Softmax Gating Mixture of Experts\" and published at the\n  ICML 2024"},{"id":"http://arxiv.org/abs/2503.03211v1","updated":"2025-03-05T06:06:16Z","published":"2025-03-05T06:06:16Z","title":"NodeReg: Mitigating the Imbalance and Distribution Shift Effects in\n  Semi-Supervised Node Classification via Norm Consistency","summary":"  Aggregating information from neighboring nodes benefits graph neural networks\n(GNNs) in semi-supervised node classification tasks. Nevertheless, this\nmechanism also renders nodes susceptible to the influence of their neighbors.\nFor instance, this will occur when the neighboring nodes are imbalanced or the\nneighboring nodes contain noise, which can even affect the GNN's ability to\ngeneralize out of distribution. We find that ensuring the consistency of the\nnorm for node representations can significantly reduce the impact of these two\nissues on GNNs. To this end, we propose a regularized optimization method\ncalled NodeReg that enforces the consistency of node representation norms. This\nmethod is simple but effective and satisfies Lipschitz continuity, thus\nfacilitating stable optimization and significantly improving semi-supervised\nnode classification performance under the above two scenarios. To illustrate,\nin the imbalance scenario, when training a GCN with an imbalance ratio of 0.1,\nNodeReg outperforms the most competitive baselines by 1.4%-25.9% in F1 score\nacross five public datasets. Similarly, in the distribution shift scenario,\nNodeReg outperforms the most competitive baseline by 1.4%-3.1% in accuracy.\n","authors":["Shenzhi Yang","Jun Xia","Jingbo Zhou","Xingkai Yao","Xiaofang Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.03211v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02445v2","updated":"2025-03-05T06:04:37Z","published":"2025-03-04T09:40:00Z","title":"BRIDGE: Bootstrapping Text to Control Time-Series Generation via\n  Multi-Agent Iterative Optimization and Diffusion Modelling","summary":"  Time-series Generation (TSG) is a prominent research area with broad\napplications in simulations, data augmentation, and counterfactual analysis.\nWhile existing methods have shown promise in unconditional single-domain TSG,\nreal-world applications demand for cross-domain approaches capable of\ncontrolled generation tailored to domain-specific constraints and\ninstance-level requirements. In this paper, we argue that text can provide\nsemantic insights, domain information and instance-specific temporal patterns,\nto guide and improve TSG. We introduce ``Text-Controlled TSG'', a task focused\non generating realistic time series by incorporating textual descriptions. To\naddress data scarcity in this setting, we propose a novel LLM-based Multi-Agent\nframework that synthesizes diverse, realistic text-to-TS datasets. Furthermore,\nwe introduce BRIDGE, a hybrid text-controlled TSG framework that integrates\nsemantic prototypes with text description for supporting domain-level guidance.\nThis approach achieves state-of-the-art generation fidelity on 11 of 12\ndatasets, and improves controllability by 12.52% on MSE and 6.34% MAE compared\nto no text input generation, highlighting its potential for generating tailored\ntime-series data.\n","authors":["Hao Li","Yu-Hao Huang","Chang Xu","Viktor Schlegel","Ren-He Jiang","Riza Batista-Navarro","Goran Nenadic","Jiang Bian"],"pdf_url":"https://arxiv.org/pdf/2503.02445v2.pdf","comment":"Preprint. Work in progress"},{"id":"http://arxiv.org/abs/2409.15866v3","updated":"2025-03-05T05:55:45Z","published":"2024-09-24T08:40:04Z","title":"Online Planning for Multi-UAV Pursuit-Evasion in Unknown Environments\n  Using Deep Reinforcement Learning","summary":"  Multi-UAV pursuit-evasion, where pursuers aim to capture evaders, poses a key\nchallenge for UAV swarm intelligence. Multi-agent reinforcement learning (MARL)\nhas demonstrated potential in modeling cooperative behaviors, but most RL-based\napproaches remain constrained to simplified simulations with limited dynamics\nor fixed scenarios. Previous attempts to deploy RL policy to real-world\npursuit-evasion are largely restricted to two-dimensional scenarios, such as\nground vehicles or UAVs at fixed altitudes. In this paper, we address multi-UAV\npursuit-evasion by considering UAV dynamics and physical constraints. We\nintroduce an evader prediction-enhanced network to tackle partial observability\nin cooperative strategy learning. Additionally, we propose an adaptive\nenvironment generator within MARL training, enabling higher exploration\nefficiency and better policy generalization across diverse scenarios.\nSimulations show our method significantly outperforms all baselines in\nchallenging scenarios, generalizing to unseen scenarios with a 100% capture\nrate. Finally, we derive a feasible policy via a two-stage reward refinement\nand deploy the policy on real quadrotors in a zero-shot manner. To our\nknowledge, this is the first work to derive and deploy an RL-based policy using\ncollective thrust and body rates control commands for multi-UAV pursuit-evasion\nin unknown environments. The open-source code and videos are available at\nhttps://sites.google.com/view/pursuit-evasion-rl.\n","authors":["Jiayu Chen","Chao Yu","Guosheng Li","Wenhao Tang","Shilong Ji","Xinyi Yang","Botian Xu","Huazhong Yang","Yu Wang"],"pdf_url":"https://arxiv.org/pdf/2409.15866v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03206v1","updated":"2025-03-05T05:50:38Z","published":"2025-03-05T05:50:38Z","title":"An Analytical Theory of Power Law Spectral Bias in the Learning Dynamics\n  of Diffusion Models","summary":"  We developed an analytical framework for understanding how the learned\ndistribution evolves during diffusion model training. Leveraging the Gaussian\nequivalence principle, we derived exact solutions for the gradient-flow\ndynamics of weights in one- or two-layer linear denoiser settings with\narbitrary data. Remarkably, these solutions allowed us to derive the generated\ndistribution in closed form and its KL divergence through training. These\nanalytical results expose a pronounced power-law spectral bias, i.e., for\nweights and distributions, the convergence time of a mode follows an inverse\npower law of its variance. Empirical experiments on both Gaussian and image\ndatasets demonstrate that the power-law spectral bias remains robust even when\nusing deeper or convolutional architectures. Our results underscore the\nimportance of the data covariance in dictating the order and rate at which\ndiffusion models learn different modes of the data, providing potential\nexplanations for why earlier stopping could lead to incorrect details in image\ngenerative models.\n","authors":["Binxu Wang"],"pdf_url":"https://arxiv.org/pdf/2503.03206v1.pdf","comment":"50 pages, 10 figures. Preprint"},{"id":"http://arxiv.org/abs/2411.16746v3","updated":"2025-03-05T05:34:47Z","published":"2024-11-23T20:41:24Z","title":"LoBAM: LoRA-Based Backdoor Attack on Model Merging","summary":"  Model merging is an emerging technique that integrates multiple models\nfine-tuned on different tasks to create a versatile model that excels in\nmultiple domains. This scheme, in the meantime, may open up backdoor attack\nopportunities where one single malicious model can jeopardize the integrity of\nthe merged model. Existing works try to demonstrate the risk of such attacks by\nassuming substantial computational resources, focusing on cases where the\nattacker can fully fine-tune the pre-trained model. Such an assumption,\nhowever, may not be feasible given the increasing size of machine learning\nmodels. In practice where resources are limited and the attacker can only\nemploy techniques like Low-Rank Adaptation (LoRA) to produce the malicious\nmodel, it remains unclear whether the attack can still work and pose threats.\nIn this work, we first identify that the attack efficacy is significantly\ndiminished when using LoRA for fine-tuning. Then, we propose LoBAM, a method\nthat yields high attack success rate with minimal training resources. The key\nidea of LoBAM is to amplify the malicious weights in an intelligent way that\neffectively enhances the attack efficacy. We demonstrate that our design can\nlead to improved attack success rate through extensive empirical experiments\nacross various model merging scenarios. Moreover, we show that our method is\nhighly stealthy and is difficult to detect and defend against.\n","authors":["Ming Yin","Jingyang Zhang","Jingwei Sun","Minghong Fang","Hai Li","Yiran Chen"],"pdf_url":"https://arxiv.org/pdf/2411.16746v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03197v1","updated":"2025-03-05T05:30:26Z","published":"2025-03-05T05:30:26Z","title":"Directly Follows Graphs Go Predictive Process Monitoring With Graph\n  Neural Networks","summary":"  In the past years, predictive process monitoring (PPM) techniques based on\nartificial neural networks have evolved as a method to monitor the future\nbehavior of business processes. Existing approaches mostly focus on\ninterpreting the processes as sequences, so-called traces, and feeding them to\nneural architectures designed to operate on sequential data such as recurrent\nneural networks (RNNs) or transformers. In this study, we investigate an\nalternative way to perform PPM: by transforming each process in its\ndirectly-follows-graph (DFG) representation we are able to apply graph neural\nnetworks (GNNs) for the prediction tasks. By this, we aim to develop models\nthat are more suitable for complex processes that are long and contain an\nabundance of loops. In particular, we present different ways to create DFG\nrepresentations depending on the particular GNN we use. The tested GNNs range\nfrom classical node-based to novel edge-based architectures. Further, we\ninvestigate the possibility of using multi-graphs. By these steps, we aim to\ndesign graph representations that minimize the information loss when\ntransforming traces into graphs.\n","authors":["Attila Lischka","Simon Rauch","Oliver Stritzel"],"pdf_url":"https://arxiv.org/pdf/2503.03197v1.pdf","comment":"10 pages, 4 figures, 3 tables"},{"id":"http://arxiv.org/abs/2503.03195v1","updated":"2025-03-05T05:25:54Z","published":"2025-03-05T05:25:54Z","title":"Online Bidding under RoS Constraints without Knowing the Value","summary":"  We consider the problem of bidding in online advertising, where an advertiser\naims to maximize value while adhering to budget and Return-on-Spend (RoS)\nconstraints. Unlike prior work that assumes knowledge of the value generated by\nwinning each impression ({e.g.,} conversions), we address the more realistic\nsetting where the advertiser must simultaneously learn the optimal bidding\nstrategy and the value of each impression opportunity. This introduces a\nchallenging exploration-exploitation dilemma: the advertiser must balance\nexploring different bids to estimate impression values with exploiting current\nknowledge to bid effectively. To address this, we propose a novel Upper\nConfidence Bound (UCB)-style algorithm that carefully manages this trade-off.\nVia a rigorous theoretical analysis, we prove that our algorithm achieves\n$\\widetilde{O}(\\sqrt{T\\log(|\\mathcal{B}|T)})$ regret and constraint violation,\nwhere $T$ is the number of bidding rounds and $\\mathcal{B}$ is the domain of\npossible bids. This establishes the first optimal regret and constraint\nviolation bounds for bidding in the online setting with unknown impression\nvalues. Moreover, our algorithm is computationally efficient and simple to\nimplement. We validate our theoretical findings through experiments on\nsynthetic data, demonstrating that our algorithm exhibits strong empirical\nperformance compared to existing approaches.\n","authors":["Sushant Vijayan","Zhe Feng","Swati Padmanabhan","Karthikeyan Shanmugam","Arun Suggala","Di Wang"],"pdf_url":"https://arxiv.org/pdf/2503.03195v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01478v3","updated":"2025-03-05T05:24:54Z","published":"2025-03-03T12:37:34Z","title":"SePer: Measure Retrieval Utility Through The Lens Of Semantic Perplexity\n  Reduction","summary":"  Large Language Models (LLMs) have demonstrated improved generation\nperformance by incorporating externally retrieved knowledge, a process known as\nretrieval-augmented generation (RAG). Despite the potential of this approach,\nexisting studies evaluate RAG effectiveness by 1) assessing retrieval and\ngeneration components jointly, which obscures retrieval's distinct\ncontribution, or 2) examining retrievers using traditional metrics such as\nNDCG, which creates a gap in understanding retrieval's true utility in the\noverall generation process. To address the above limitations, in this work, we\nintroduce an automatic evaluation method that measures retrieval quality\nthrough the lens of information gain within the RAG framework. Specifically, we\npropose Semantic Perplexity (SePer), a metric that captures the LLM's internal\nbelief about the correctness of the retrieved information. We quantify the\nutility of retrieval by the extent to which it reduces semantic perplexity\npost-retrieval. Extensive experiments demonstrate that SePer not only aligns\nclosely with human preferences but also offers a more precise and efficient\nevaluation of retrieval utility across diverse RAG scenarios.\n","authors":["Lu Dai","Yijie Xu","Jinhui Ye","Hao Liu","Hui Xiong"],"pdf_url":"https://arxiv.org/pdf/2503.01478v3.pdf","comment":"ICLR 2025 Spotlight"}],"Multimedia":[{"id":"http://arxiv.org/abs/2410.08642v2","updated":"2025-03-05T15:55:52Z","published":"2024-10-11T09:10:26Z","title":"More than Memes: A Multimodal Topic Modeling Approach to Conspiracy\n  Theories on Telegram","summary":"  To address the increasing prevalence of (audio-)visual data on social media,\nand to capture the evolving and dynamic nature of this communication,\nresearchers have begun to explore the potential of unsupervised approaches for\nanalyzing multimodal online content. However, existing research often neglects\nvisual content beyond memes, and in addition lacks methods to compare topic\nmodels across modalities. Our study addresses these gaps by applying multimodal\ntopic modeling for analyzing conspiracy theories in German-language Telegram\nchannels. We use BERTopic with CLIP for the analysis of textual and visual data\nin a corpus of ~40, 000 Telegram messages posted in October 2023 in 571\nGerman-language Telegram channels known for disseminating conspiracy theories.\nThrough this dataset, we provide insights into unimodal and multimodal topic\nmodels by analyzing symmetry and intersections of topics across modalities. We\ndemonstrate the variety of textual and visual content shared in the channels\ndiscovered through the topic modeling, and propose a conceptual framework for\nthe analysis of textual and visual discursive strategies in the communication\nof conspiracy theories. We apply the framework in a case study of the topic\ngroup Israel Gaza.\n","authors":["Elisabeth Steffen"],"pdf_url":"https://arxiv.org/pdf/2410.08642v2.pdf","comment":"12 pages, 10 figures"},{"id":"http://arxiv.org/abs/2410.07369v3","updated":"2025-03-05T00:06:53Z","published":"2024-10-09T18:33:06Z","title":"An Undetectable Watermark for Generative Image Models","summary":"  We present the first undetectable watermarking scheme for generative image\nmodels. Undetectability ensures that no efficient adversary can distinguish\nbetween watermarked and un-watermarked images, even after making many adaptive\nqueries. In particular, an undetectable watermark does not degrade image\nquality under any efficiently computable metric. Our scheme works by selecting\nthe initial latents of a diffusion model using a pseudorandom error-correcting\ncode (Christ and Gunn, 2024), a strategy which guarantees undetectability and\nrobustness. We experimentally demonstrate that our watermarks are\nquality-preserving and robust using Stable Diffusion 2.1. Our experiments\nverify that, in contrast to every prior scheme we tested, our watermark does\nnot degrade image quality. Our experiments also demonstrate robustness:\nexisting watermark removal attacks fail to remove our watermark from images\nwithout significantly degrading the quality of the images. Finally, we find\nthat we can robustly encode 512 bits in our watermark, and up to 2500 bits when\nthe images are not subjected to watermark removal attacks. Our code is\navailable at https://github.com/XuandongZhao/PRC-Watermark.\n","authors":["Sam Gunn","Xuandong Zhao","Dawn Song"],"pdf_url":"https://arxiv.org/pdf/2410.07369v3.pdf","comment":"ICLR 2025"}]},"2025-03-06T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2503.04725v1","updated":"2025-03-06T18:59:48Z","published":"2025-03-06T18:59:48Z","title":"L$^2$M: Mutual Information Scaling Law for Long-Context Language\n  Modeling","summary":"  We rigorously establish a bipartite mutual information scaling law in natural\nlanguage that governs long-range dependencies. This scaling law, which we show\nis distinct from and scales independently of the conventional two-point mutual\ninformation, is the key to understanding long-context language modeling. Using\nthis scaling law, we formulate the Long-context Language Modeling (L$^2$M)\ncondition, which relates a model's capacity for effective long context length\nmodeling to the scaling of its latent state size for storing past information.\nOur results are validated through experiments on both transformers and state\nspace models. This work establishes a theoretical foundation that guides the\ndevelopment of large language models toward longer context lengths.\n","authors":["Zhuo Chen","Oriol Mayné i Comas","Zhuotao Jin","Di Luo","Marin Soljačić"],"pdf_url":"https://arxiv.org/pdf/2503.04725v1.pdf","comment":"29 pages, 12 figures, 1 table"},{"id":"http://arxiv.org/abs/2503.04724v1","updated":"2025-03-06T18:59:38Z","published":"2025-03-06T18:59:38Z","title":"LLMVoX: Autoregressive Streaming Text-to-Speech Model for Any LLM","summary":"  Recent advancements in speech-to-speech dialogue systems leverage LLMs for\nmultimodal interactions, yet they remain hindered by fine-tuning requirements,\nhigh computational overhead, and text-speech misalignment. Existing\nspeech-enabled LLMs often degrade conversational quality by modifying the LLM,\nthereby compromising its linguistic capabilities. In contrast, we propose\nLLMVoX, a lightweight 30M-parameter, LLM-agnostic, autoregressive streaming TTS\nsystem that generates high-quality speech with low latency, while fully\npreserving the capabilities of the base LLM. Our approach achieves a\nsignificantly lower Word Error Rate compared to speech-enabled LLMs, while\noperating at comparable latency and UTMOS score. By decoupling speech synthesis\nfrom LLM processing via a multi-queue token streaming system, LLMVoX supports\nseamless, infinite-length dialogues. Its plug-and-play design also facilitates\nextension to various tasks with different backbones. Furthermore, LLMVoX\ngeneralizes to new languages with only dataset adaptation, attaining a low\nCharacter Error Rate on an Arabic speech task. Additionally, we have integrated\nLLMVoX with a Vision-Language Model to create an omni-model with speech, text,\nand vision capabilities, without requiring additional multimodal training. Our\ncode base and project page is available at https://mbzuai-oryx.github.io/LLMVoX .\n","authors":["Sambal Shikhar","Mohammed Irfan Kurpath","Sahal Shaji Mullappilly","Jean Lahoud","Fahad Khan","Rao Muhammad Anwer","Salman Khan","Hisham Cholakkal"],"pdf_url":"https://arxiv.org/pdf/2503.04724v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04723v1","updated":"2025-03-06T18:59:37Z","published":"2025-03-06T18:59:37Z","title":"Shifting Long-Context LLMs Research from Input to Output","summary":"  Recent advancements in long-context Large Language Models (LLMs) have\nprimarily concentrated on processing extended input contexts, resulting in\nsignificant strides in long-context comprehension. However, the equally\ncritical aspect of generating long-form outputs has received comparatively less\nattention. This paper advocates for a paradigm shift in NLP research toward\naddressing the challenges of long-output generation. Tasks such as novel\nwriting, long-term planning, and complex reasoning require models to understand\nextensive contexts and produce coherent, contextually rich, and logically\nconsistent extended text. These demands highlight a critical gap in current LLM\ncapabilities. We underscore the importance of this under-explored domain and\ncall for focused efforts to develop foundational LLMs tailored for generating\nhigh-quality, long-form outputs, which hold immense potential for real-world\napplications.\n","authors":["Yuhao Wu","Yushi Bai","Zhiqing Hu","Shangqing Tu","Ming Shan Hee","Juanzi Li","Roy Ka-Wei Lee"],"pdf_url":"https://arxiv.org/pdf/2503.04723v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2503.04722v1","updated":"2025-03-06T18:59:23Z","published":"2025-03-06T18:59:23Z","title":"Enough Coin Flips Can Make LLMs Act Bayesian","summary":"  Large language models (LLMs) exhibit the ability to generalize given few-shot\nexamples in their input prompt, an emergent capability known as in-context\nlearning (ICL). We investigate whether LLMs utilize ICL to perform structured\nreasoning in ways that are consistent with a Bayesian framework or rely on\npattern matching. Using a controlled setting of biased coin flips, we find\nthat: (1) LLMs often possess biased priors, causing initial divergence in\nzero-shot settings, (2) in-context evidence outweighs explicit bias\ninstructions, (3) LLMs broadly follow Bayesian posterior updates, with\ndeviations primarily due to miscalibrated priors rather than flawed updates,\nand (4) attention magnitude has negligible effect on Bayesian inference. With\nsufficient demonstrations of biased coin flips via ICL, LLMs update their\npriors in a Bayesian manner.\n","authors":["Ritwik Gupta","Rodolfo Corona","Jiaxin Ge","Eric Wang","Dan Klein","Trevor Darrell","David M. Chan"],"pdf_url":"https://arxiv.org/pdf/2503.04722v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04721v1","updated":"2025-03-06T18:59:16Z","published":"2025-03-06T18:59:16Z","title":"Full-Duplex-Bench: A Benchmark to Evaluate Full-duplex Spoken Dialogue\n  Models on Turn-taking Capabilities","summary":"  Spoken dialogue modeling introduces unique challenges beyond text-based\nlanguage modeling, demanding robust turn-taking, backchanneling, and real-time\ninteraction. Although most Spoken Dialogue Models (SDMs) rely on half-duplex\nprocessing (handling speech one turn at a time), emerging full-duplex SDMs can\nlisten and speak simultaneously, enabling more natural and engaging\nconversations. However, current evaluations of such models remain limited,\noften focusing on turn-based metrics or high-level corpus analyses (e.g., turn\ngaps, pauses). To address this gap, we present Full-Duplex-Bench, a new\nbenchmark that systematically evaluates key conversational behaviors: pause\nhandling, backchanneling, turn-taking, and interruption management. Our\nframework uses automatic metrics for consistent and reproducible assessments of\nSDMs' interactive performance. By offering an open and standardized evaluation\nbenchmark, we aim to advance spoken dialogue modeling and encourage the\ndevelopment of more interactive and natural dialogue systems.\n","authors":["Guan-Ting Lin","Jiachen Lian","Tingle Li","Qirui Wang","Gopala Anumanchipalli","Alexander H. Liu","Hung-yi Lee"],"pdf_url":"https://arxiv.org/pdf/2503.04721v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.11807v7","updated":"2025-03-06T18:58:23Z","published":"2024-03-18T14:04:47Z","title":"How Far Are We on the Decision-Making of LLMs? Evaluating LLMs' Gaming\n  Ability in Multi-Agent Environments","summary":"  Decision-making is a complex process requiring diverse abilities, making it\nan excellent framework for evaluating Large Language Models (LLMs). Researchers\nhave examined LLMs' decision-making through the lens of Game Theory. However,\nexisting evaluation mainly focus on two-player scenarios where an LLM competes\nagainst another. Additionally, previous benchmarks suffer from test set leakage\ndue to their static design. We introduce GAMA($\\gamma$)-Bench, a new framework\nfor evaluating LLMs' Gaming Ability in Multi-Agent environments. It includes\neight classical game theory scenarios and a dynamic scoring scheme specially\ndesigned to quantitatively assess LLMs' performance. $\\gamma$-Bench allows\nflexible game settings and adapts the scoring system to different game\nparameters, enabling comprehensive evaluation of robustness, generalizability,\nand strategies for improvement. Our results indicate that GPT-3.5 demonstrates\nstrong robustness but limited generalizability, which can be enhanced using\nmethods like Chain-of-Thought. We also evaluate 13 LLMs from 6 model families,\nincluding GPT-3.5, GPT-4, Gemini, LLaMA-3.1, Mixtral, and Qwen-2.\nGemini-1.5-Pro outperforms others, scoring of $69.8$ out of $100$, followed by\nLLaMA-3.1-70B ($65.9$) and Mixtral-8x22B ($62.4$). Our code and experimental\nresults are publicly available at https://github.com/CUHK-ARISE/GAMABench.\n","authors":["Jen-tse Huang","Eric John Li","Man Ho Lam","Tian Liang","Wenxuan Wang","Youliang Yuan","Wenxiang Jiao","Xing Wang","Zhaopeng Tu","Michael R. Lyu"],"pdf_url":"https://arxiv.org/pdf/2403.11807v7.pdf","comment":"Accepted to ICLR 2025; 11 pages of main text; 26 pages of appendices;\n  Included models: GPT-3.5-{0613, 1106, 0125}, GPT-4-0125, GPT-4o-0806,\n  Gemini-{1.0, 1.5)-Pro, LLaMA-3.1-{7, 70, 405}B, Mixtral-8x{7, 22}B,\n  Qwen-2-72B"},{"id":"http://arxiv.org/abs/2503.04713v1","updated":"2025-03-06T18:57:40Z","published":"2025-03-06T18:57:40Z","title":"Scaling Rich Style-Prompted Text-to-Speech Datasets","summary":"  We introduce Paralinguistic Speech Captions (ParaSpeechCaps), a large-scale\ndataset that annotates speech utterances with rich style captions. While rich\nabstract tags (e.g. guttural, nasal, pained) have been explored in small-scale\nhuman-annotated datasets, existing large-scale datasets only cover basic tags\n(e.g. low-pitched, slow, loud). We combine off-the-shelf text and speech\nembedders, classifiers and an audio language model to automatically scale rich\ntag annotations for the first time. ParaSpeechCaps covers a total of 59 style\ntags, including both speaker-level intrinsic tags and utterance-level\nsituational tags. It consists of 342 hours of human-labelled data (PSC-Base)\nand 2427 hours of automatically annotated data (PSC-Scaled). We finetune\nParler-TTS, an open-source style-prompted TTS model, on ParaSpeechCaps, and\nachieve improved style consistency (+7.9% Consistency MOS) and speech quality\n(+15.5% Naturalness MOS) over the best performing baseline that combines\nexisting rich style tag datasets. We ablate several of our dataset design\nchoices to lay the foundation for future work in this space. Our dataset,\nmodels and code are released at https://github.com/ajd12342/paraspeechcaps .\n","authors":["Anuj Diwan","Zhisheng Zheng","David Harwath","Eunsol Choi"],"pdf_url":"https://arxiv.org/pdf/2503.04713v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04697v1","updated":"2025-03-06T18:43:29Z","published":"2025-03-06T18:43:29Z","title":"L1: Controlling How Long A Reasoning Model Thinks With Reinforcement\n  Learning","summary":"  Reasoning language models have shown an uncanny ability to improve\nperformance at test-time by ``thinking longer''-that is, by generating longer\nchain-of-thought sequences and hence using more compute. However, the length of\ntheir chain-of-thought reasoning is not controllable, making it impossible to\nallocate test-time compute to achieve a desired level of performance. We\nintroduce Length Controlled Policy Optimization (LCPO), a simple reinforcement\nlearning method that optimizes for accuracy and adherence to user-specified\nlength constraints. We use LCPO to train L1, a reasoning language model that\nproduces outputs satisfying a length constraint given in its prompt. L1's\nlength control allows for smoothly trading off computational cost and accuracy\non a wide range of tasks, and outperforms the state-of-the-art S1 method for\nlength control. Furthermore, we uncover an unexpected short chain-of-thought\ncapability in models trained with LCPO. For instance, our 1.5B L1 model\nsurpasses GPT-4o at equal reasoning lengths. Overall, LCPO enables precise\ncontrol over reasoning length, allowing for fine-grained allocation of\ntest-time compute and accuracy. We release code and models at\nhttps://www.cmu-l3.github.io/l1\n","authors":["Pranjal Aggarwal","Sean Welleck"],"pdf_url":"https://arxiv.org/pdf/2503.04697v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02694v3","updated":"2025-03-06T18:41:54Z","published":"2024-10-03T17:20:11Z","title":"HELMET: How to Evaluate Long-Context Language Models Effectively and\n  Thoroughly","summary":"  Many benchmarks exist for evaluating long-context language models (LCLMs),\nyet developers often rely on synthetic tasks such as needle-in-a-haystack\n(NIAH) or an arbitrary subset of tasks. However, it remains unclear whether\nthese benchmarks reflect the diverse downstream applications of LCLMs, and such\ninconsistencies further complicate model comparison. We investigate the\nunderlying reasons behind these practices and find that existing benchmarks\noften provide noisy signals due to limited coverage of applications,\ninsufficient context lengths, unreliable metrics, and incompatibility with base\nmodels. In this work, we introduce HELMET (How to Evaluate Long-context Models\nEffectively and Thoroughly), a comprehensive benchmark encompassing seven\ndiverse, application-centric categories. We also address several issues in\nprevious benchmarks by adding controllable lengths up to 128K tokens,\nmodel-based evaluation for reliable metrics, and few-shot prompting for\nrobustly evaluating base models. Consequently, we demonstrate that HELMET\noffers more reliable and consistent rankings of frontier LCLMs. Through a\ncomprehensive study of 59 LCLMs, we find that (1) synthetic tasks like NIAH do\nnot reliably predict downstream performance; (2) the diverse categories in\nHELMET exhibit distinct trends and low correlations with each other; and (3)\nwhile most LCLMs achieve perfect NIAH scores, open-source models significantly\nlag behind closed ones when tasks require full-context reasoning or following\ncomplex instructions -- the gap widens as length increases. Finally, we\nrecommend using our RAG tasks for fast model development, as they are easy to\nrun and better predict other downstream performance; ultimately, we advocate\nfor a holistic evaluation across diverse tasks.\n","authors":["Howard Yen","Tianyu Gao","Minmin Hou","Ke Ding","Daniel Fleischer","Peter Izsak","Moshe Wasserblat","Danqi Chen"],"pdf_url":"https://arxiv.org/pdf/2410.02694v3.pdf","comment":"ICLR 2025. Project page: https://princeton-nlp.github.io/HELMET/"},{"id":"http://arxiv.org/abs/2503.04693v1","updated":"2025-03-06T18:40:00Z","published":"2025-03-06T18:40:00Z","title":"UIPE: Enhancing LLM Unlearning by Removing Knowledge Related to\n  Forgetting Targets","summary":"  Large Language Models (LLMs) inevitably acquire harmful information during\ntraining on massive datasets. LLM unlearning aims to eliminate the influence of\nsuch harmful information while maintaining the model's overall performance.\nExisting unlearning methods, represented by gradient ascent-based approaches,\nprimarily focus on forgetting target data while overlooking the crucial impact\nof logically related knowledge on the effectiveness of unlearning. In this\npaper, through both theoretical and experimental analyses, we first demonstrate\nthat a key reason for the suboptimal unlearning performance is that models can\nreconstruct the target content through reasoning with logically related\nknowledge. To address this issue, we propose Unlearning Improvement via\nParameter Extrapolation (UIPE), a method that removes knowledge highly\ncorrelated with the forgetting targets. Experimental results show that UIPE\nsignificantly enhances the performance of various mainstream LLM unlearning\nmethods on the TOFU benchmark.\n","authors":["Wenyu Wang","Mengqi Zhang","Xiaotian Ye","Zhaochun Ren","Zhumin Chen","Pengjie Ren"],"pdf_url":"https://arxiv.org/pdf/2503.04693v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04691v1","updated":"2025-03-06T18:35:39Z","published":"2025-03-06T18:35:39Z","title":"Quantifying the Reasoning Abilities of LLMs on Real-world Clinical Cases","summary":"  The latest reasoning-enhanced large language models (reasoning LLMs), such as\nDeepSeek-R1 and OpenAI-o3, have demonstrated remarkable success. However, the\napplication of such reasoning enhancements to the highly professional medical\ndomain has not been clearly evaluated, particularly regarding with not only\nassessing the final generation but also examining the quality of their\nreasoning processes. In this study, we present MedR-Bench, a reasoning-focused\nmedical evaluation benchmark comprising 1,453 structured patient cases with\nreasoning references mined from case reports. Our benchmark spans 13 body\nsystems and 10 specialty disorders, encompassing both common and rare diseases.\nIn our evaluation, we introduce a versatile framework consisting of three\ncritical clinical stages: assessment recommendation, diagnostic\ndecision-making, and treatment planning, comprehensively capturing the LLMs'\nperformance across the entire patient journey in healthcare. For metrics, we\npropose a novel agentic system, Reasoning Evaluator, designed to automate and\nobjectively quantify free-text reasoning responses in a scalable manner from\nthe perspectives of efficiency, factuality, and completeness by dynamically\nsearching and performing cross-referencing checks. As a result, we assess five\nstate-of-the-art reasoning LLMs, including DeepSeek-R1, OpenAI-o3-mini, and\nothers. Our results reveal that current LLMs can handle relatively simple\ndiagnostic tasks with sufficient critical assessment results, achieving\naccuracy generally over 85%. However, they still struggle with more complex\ntasks, such as assessment recommendation and treatment planning. In reasoning,\ntheir reasoning processes are generally reliable, with factuality scores\nexceeding 90%, though they often omit critical reasoning steps. Our study\nclearly reveals further development directions for current clinical LLMs.\n","authors":["Pengcheng Qiu","Chaoyi Wu","Shuyu Liu","Weike Zhao","Ya Zhang","Yanfeng Wang","Weidi Xie"],"pdf_url":"https://arxiv.org/pdf/2503.04691v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04685v1","updated":"2025-03-06T18:27:41Z","published":"2025-03-06T18:27:41Z","title":"DIMSUM: Discourse in Mathematical Reasoning as a Supervision Module","summary":"  We look at reasoning on GSM8k, a dataset of short texts presenting primary\nschool, math problems. We find, with Mirzadeh et al. (2024), that current LLM\nprogress on the data set may not be explained by better reasoning but by\nexposure to a broader pretraining data distribution. We then introduce a novel\ninformation source for helping models with less data or inferior training\nreason better: discourse structure. We show that discourse structure improves\nperformance for models like Llama2 13b by up to 160%. Even for models that have\nmost likely memorized the data set, adding discourse structural information to\nthe model still improves predictions and dramatically improves large model\nperformance on out of distribution examples.\n","authors":["Krish Sharma","Niyar R Barman","Nicholas Asher","Akshay Chaturvedi"],"pdf_url":"https://arxiv.org/pdf/2503.04685v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04675v1","updated":"2025-03-06T18:12:33Z","published":"2025-03-06T18:12:33Z","title":"LLM-guided Plan and Retrieval: A Strategic Alignment for Interpretable\n  User Satisfaction Estimation in Dialogue","summary":"  Understanding user satisfaction with conversational systems, known as User\nSatisfaction Estimation (USE), is essential for assessing dialogue quality and\nenhancing user experiences. However, existing methods for USE face challenges\ndue to limited understanding of underlying reasons for user dissatisfaction and\nthe high costs of annotating user intentions. To address these challenges, we\npropose PRAISE (Plan and Retrieval Alignment for Interpretable Satisfaction\nEstimation), an interpretable framework for effective user satisfaction\nprediction. PRAISE operates through three key modules. The Strategy Planner\ndevelops strategies, which are natural language criteria for classifying user\nsatisfaction. The Feature Retriever then incorporates knowledge on user\nsatisfaction from Large Language Models (LLMs) and retrieves relevance features\nfrom utterances. Finally, the Score Analyzer evaluates strategy predictions and\nclassifies user satisfaction. Experimental results demonstrate that PRAISE\nachieves state-of-the-art performance on three benchmarks for the USE task.\nBeyond its superior performance, PRAISE offers additional benefits. It enhances\ninterpretability by providing instance-level explanations through effective\nalignment of utterances with strategies. Moreover, PRAISE operates more\nefficiently than existing approaches by eliminating the need for LLMs during\nthe inference phase.\n","authors":["Sangyeop Kim","Sohhyung Park","Jaewon Jung","Jinseok Kim","Sungzoon Cho"],"pdf_url":"https://arxiv.org/pdf/2503.04675v1.pdf","comment":"Accepted by NAACL 2025"},{"id":"http://arxiv.org/abs/2502.02067v2","updated":"2025-03-06T18:09:38Z","published":"2025-02-04T07:32:39Z","title":"AdaptBot: Combining LLM with Knowledge Graphs and Human Input for\n  Generic-to-Specific Task Decomposition and Knowledge Refinement","summary":"  An embodied agent assisting humans is often asked to complete new tasks, and\nthere may not be sufficient time or labeled examples to train the agent to\nperform these new tasks. Large Language Models (LLMs) trained on considerable\nknowledge across many domains can be used to predict a sequence of abstract\nactions for completing such tasks, although the agent may not be able to\nexecute this sequence due to task-, agent-, or domain-specific constraints. Our\nframework addresses these challenges by leveraging the generic predictions\nprovided by LLM and the prior domain knowledge encoded in a Knowledge Graph\n(KG), enabling an agent to quickly adapt to new tasks. The robot also solicits\nand uses human input as needed to refine its existing knowledge. Based on\nexperimental evaluation in the context of cooking and cleaning tasks in\nsimulation domains, we demonstrate that the interplay between LLM, KG, and\nhuman input leads to substantial performance gains compared with just using the\nLLM. Project website{\\S}: https://sssshivvvv.github.io/adaptbot/\n","authors":["Shivam Singh","Karthik Swaminathan","Nabanita Dash","Ramandeep Singh","Snehasis Banerjee","Mohan Sridharan","Madhava Krishna"],"pdf_url":"https://arxiv.org/pdf/2502.02067v2.pdf","comment":"Accepted to IEEE International Conference on Robotics and Automation\n  (ICRA) 2025"},{"id":"http://arxiv.org/abs/2503.04667v1","updated":"2025-03-06T17:59:51Z","published":"2025-03-06T17:59:51Z","title":"An Information-theoretic Multi-task Representation Learning Framework\n  for Natural Language Understanding","summary":"  This paper proposes a new principled multi-task representation learning\nframework (InfoMTL) to extract noise-invariant sufficient representations for\nall tasks. It ensures sufficiency of shared representations for all tasks and\nmitigates the negative effect of redundant features, which can enhance language\nunderstanding of pre-trained language models (PLMs) under the multi-task\nparadigm. Firstly, a shared information maximization principle is proposed to\nlearn more sufficient shared representations for all target tasks. It can avoid\nthe insufficiency issue arising from representation compression in the\nmulti-task paradigm. Secondly, a task-specific information minimization\nprinciple is designed to mitigate the negative effect of potential redundant\nfeatures in the input for each task. It can compress task-irrelevant redundant\ninformation and preserve necessary information relevant to the target for\nmulti-task prediction. Experiments on six classification benchmarks show that\nour method outperforms 12 comparative multi-task methods under the same\nmulti-task settings, especially in data-constrained and noisy scenarios.\nExtensive experiments demonstrate that the learned representations are more\nsufficient, data-efficient, and robust.\n","authors":["Dou Hu","Lingwei Wei","Wei Zhou","Songlin Hu"],"pdf_url":"https://arxiv.org/pdf/2503.04667v1.pdf","comment":"11 pages, accepted to AAAI 2025 (main conference), the code is\n  available at https://github.com/zerohd4869/InfoMTL"},{"id":"http://arxiv.org/abs/2502.16600v4","updated":"2025-03-06T17:56:40Z","published":"2025-02-23T15:00:53Z","title":"Diagnosing Moral Reasoning Acquisition in Language Models: Pragmatics\n  and Generalization","summary":"  Ensuring that Large Language Models (LLMs) return just responses which adhere\nto societal values is crucial for their broader application. Prior research has\nshown that LLMs often fail to perform satisfactorily on tasks requiring moral\ncognizance, such as ethics-based judgments. While current approaches have\nfocused on fine-tuning LLMs with curated datasets to improve their capabilities\non such tasks, choosing the optimal learning paradigm to enhance the ethical\nresponses of LLMs remains an open research debate. In this work, we aim to\naddress this fundamental question: can current learning paradigms enable LLMs\nto acquire sufficient moral reasoning capabilities? Drawing from distributional\nsemantics theory and the pragmatic nature of moral discourse, our analysis\nindicates that performance improvements follow a mechanism similar to that of\nsemantic-level tasks, and therefore remain affected by the pragmatic nature of\nmorals latent in discourse, a phenomenon we name the pragmatic dilemma. We\nconclude that this pragmatic dilemma imposes significant limitations on the\ngeneralization ability of current learning paradigms, making it the primary\nbottleneck for moral reasoning acquisition in LLMs.\n","authors":["Guangliang Liu","Lei Jiang","Xitong Zhang","Kristen Marie Johnson"],"pdf_url":"https://arxiv.org/pdf/2502.16600v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.00799v6","updated":"2025-03-06T17:43:10Z","published":"2024-06-02T16:53:21Z","title":"Get my drift? Catching LLM Task Drift with Activation Deltas","summary":"  LLMs are commonly used in retrieval-augmented applications to execute user\ninstructions based on data from external sources. For example, modern search\nengines use LLMs to answer queries based on relevant search results; email\nplugins summarize emails by processing their content through an LLM. However,\nthe potentially untrusted provenance of these data sources can lead to prompt\ninjection attacks, where the LLM is manipulated by natural language\ninstructions embedded in the external data, causing it to deviate from the\nuser's original instruction(s). We define this deviation as task drift. Task\ndrift is a significant concern as it allows attackers to exfiltrate data or\ninfluence the LLM's output for other users. We study LLM activations as a\nsolution to detect task drift, showing that activation deltas - the difference\nin activations before and after processing external data - are strongly\ncorrelated with this phenomenon. Through two probing methods, we demonstrate\nthat a simple linear classifier can detect drift with near-perfect ROC AUC on\nan out-of-distribution test set. We evaluate these methods by making minimal\nassumptions about how users' tasks, system prompts, and attacks can be phrased.\nWe observe that this approach generalizes surprisingly well to unseen task\ndomains, such as prompt injections, jailbreaks, and malicious instructions,\nwithout being trained on any of these attacks. Interestingly, the fact that\nthis solution does not require any modifications to the LLM (e.g.,\nfine-tuning), as well as its compatibility with existing meta-prompting\nsolutions, makes it cost-efficient and easy to deploy. To encourage further\nresearch on activation-based task inspection, decoding, and interpretability,\nwe release our large-scale TaskTracker toolkit, featuring a dataset of over\n500K instances, representations from six SoTA language models, and a suite of\ninspection tools.\n","authors":["Sahar Abdelnabi","Aideen Fay","Giovanni Cherubin","Ahmed Salem","Mario Fritz","Andrew Paverd"],"pdf_url":"https://arxiv.org/pdf/2406.00799v6.pdf","comment":"SaTML 2025"},{"id":"http://arxiv.org/abs/2503.04647v1","updated":"2025-03-06T17:33:01Z","published":"2025-03-06T17:33:01Z","title":"Implicit Cross-Lingual Rewarding for Efficient Multilingual Preference\n  Alignment","summary":"  Direct Preference Optimization (DPO) has become a prominent method for\naligning Large Language Models (LLMs) with human preferences. While DPO has\nenabled significant progress in aligning English LLMs, multilingual preference\nalignment is hampered by data scarcity. To address this, we propose a novel\napproach that $\\textit{captures}$ learned preferences from well-aligned English\nmodels by implicit rewards and $\\textit{transfers}$ them to other languages\nthrough iterative training. Specifically, we derive an implicit reward model\nfrom the logits of an English DPO-aligned model and its corresponding reference\nmodel. This reward model is then leveraged to annotate preference relations in\ncross-lingual instruction-following pairs, using English instructions to\nevaluate multilingual responses. The annotated data is subsequently used for\nmultilingual DPO fine-tuning, facilitating preference knowledge transfer from\nEnglish to other languages. Fine-tuning Llama3 for two iterations resulted in a\n12.72% average improvement in Win Rate and a 5.97% increase in Length Control\nWin Rate across all training languages on the X-AlpacaEval leaderboard. Our\nfindings demonstrate that leveraging existing English-aligned models can enable\nefficient and effective multilingual preference alignment, significantly\nreducing the need for extensive multilingual preference data. The code is\navailable at https://github.com/ZNLP/Implicit-Cross-Lingual-Rewarding\n","authors":["Wen Yang","Junhong Wu","Chen Wang","Chengqing Zong","Jiajun Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.04647v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2503.04644v1","updated":"2025-03-06T17:32:22Z","published":"2025-03-06T17:32:22Z","title":"IFIR: A Comprehensive Benchmark for Evaluating Instruction-Following in\n  Expert-Domain Information Retrieval","summary":"  We introduce IFIR, the first comprehensive benchmark designed to evaluate\ninstruction-following information retrieval (IR) in expert domains. IFIR\nincludes 2,426 high-quality examples and covers eight subsets across four\nspecialized domains: finance, law, healthcare, and science literature. Each\nsubset addresses one or more domain-specific retrieval tasks, replicating\nreal-world scenarios where customized instructions are critical. IFIR enables a\ndetailed analysis of instruction-following retrieval capabilities by\nincorporating instructions at different levels of complexity. We also propose a\nnovel LLM-based evaluation method to provide a more precise and reliable\nassessment of model performance in following instructions. Through extensive\nexperiments on 15 frontier retrieval models, including those based on LLMs, our\nresults reveal that current models face significant challenges in effectively\nfollowing complex, domain-specific instructions. We further provide in-depth\nanalyses to highlight these limitations, offering valuable insights to guide\nfuture advancements in retriever development.\n","authors":["Tingyu Song","Guo Gan","Mingsheng Shang","Yilun Zhao"],"pdf_url":"https://arxiv.org/pdf/2503.04644v1.pdf","comment":"NAACL 2025 Main"},{"id":"http://arxiv.org/abs/2503.04636v1","updated":"2025-03-06T17:24:06Z","published":"2025-03-06T17:24:06Z","title":"Mark Your LLM: Detecting the Misuse of Open-Source Large Language Models\n  via Watermarking","summary":"  As open-source large language models (LLMs) like Llama3 become more capable,\nit is crucial to develop watermarking techniques to detect their potential\nmisuse. Existing watermarking methods either add watermarks during LLM\ninference, which is unsuitable for open-source LLMs, or primarily target\nclassification LLMs rather than recent generative LLMs. Adapting these\nwatermarks to open-source LLMs for misuse detection remains an open challenge.\nThis work defines two misuse scenarios for open-source LLMs: intellectual\nproperty (IP) violation and LLM Usage Violation. Then, we explore the\napplication of inference-time watermark distillation and backdoor watermarking\nin these contexts. We propose comprehensive evaluation methods to assess the\nimpact of various real-world further fine-tuning scenarios on watermarks and\nthe effect of these watermarks on LLM performance. Our experiments reveal that\nbackdoor watermarking could effectively detect IP Violation, while\ninference-time watermark distillation is applicable in both scenarios but less\nrobust to further fine-tuning and has a more significant impact on LLM\nperformance compared to backdoor watermarking. Exploring more advanced\nwatermarking methods for open-source LLMs to detect their misuse should be an\nimportant future direction.\n","authors":["Yijie Xu","Aiwei Liu","Xuming Hu","Lijie Wen","Hui Xiong"],"pdf_url":"https://arxiv.org/pdf/2503.04636v1.pdf","comment":"Accepted by the 1st Workshop on GenAI Watermarking, collocated with\n  ICLR 2025"},{"id":"http://arxiv.org/abs/2503.04629v1","updated":"2025-03-06T17:15:48Z","published":"2025-03-06T17:15:48Z","title":"SurveyForge: On the Outline Heuristics, Memory-Driven Generation, and\n  Multi-dimensional Evaluation for Automated Survey Writing","summary":"  Survey paper plays a crucial role in scientific research, especially given\nthe rapid growth of research publications. Recently, researchers have begun\nusing LLMs to automate survey generation for better efficiency. However, the\nquality gap between LLM-generated surveys and those written by human remains\nsignificant, particularly in terms of outline quality and citation accuracy. To\nclose these gaps, we introduce SurveyForge, which first generates the outline\nby analyzing the logical structure of human-written outlines and referring to\nthe retrieved domain-related articles. Subsequently, leveraging high-quality\npapers retrieved from memory by our scholar navigation agent, SurveyForge can\nautomatically generate and refine the content of the generated article.\nMoreover, to achieve a comprehensive evaluation, we construct SurveyBench,\nwhich includes 100 human-written survey papers for win-rate comparison and\nassesses AI-generated survey papers across three dimensions: reference,\noutline, and content quality. Experiments demonstrate that SurveyForge can\noutperform previous works such as AutoSurvey.\n","authors":["Xiangchao Yan","Shiyang Feng","Jiakang Yuan","Renqiu Xia","Bin Wang","Bo Zhang","Lei Bai"],"pdf_url":"https://arxiv.org/pdf/2503.04629v1.pdf","comment":"Code and dataset are available for downloading at:\n  https://github.com/Alpha-Innovator/SurveyForge 22 pages, 10 figures"},{"id":"http://arxiv.org/abs/2503.04625v1","updated":"2025-03-06T17:11:51Z","published":"2025-03-06T17:11:51Z","title":"START: Self-taught Reasoner with Tools","summary":"  Large reasoning models (LRMs) like OpenAI-o1 and DeepSeek-R1 have\ndemonstrated remarkable capabilities in complex reasoning tasks through the\nutilization of long Chain-of-thought (CoT). However, these models often suffer\nfrom hallucinations and inefficiencies due to their reliance solely on internal\nreasoning processes. In this paper, we introduce START (Self-Taught Reasoner\nwith Tools), a novel tool-integrated long CoT reasoning LLM that significantly\nenhances reasoning capabilities by leveraging external tools. Through code\nexecution, START is capable of performing complex computations, self-checking,\nexploring diverse methods, and self-debugging, thereby addressing the\nlimitations of LRMs. The core innovation of START lies in its self-learning\nframework, which comprises two key techniques: 1) Hint-infer: We demonstrate\nthat inserting artificially designed hints (e.g., ``Wait, maybe using Python\nhere is a good idea.'') during the inference process of a LRM effectively\nstimulates its ability to utilize external tools without the need for any\ndemonstration data. Hint-infer can also serve as a simple and effective\nsequential test-time scaling method; 2) Hint Rejection Sampling Fine-Tuning\n(Hint-RFT): Hint-RFT combines Hint-infer and RFT by scoring, filtering, and\nmodifying the reasoning trajectories with tool invocation generated by a LRM\nvia Hint-infer, followed by fine-tuning the LRM. Through this framework, we\nhave fine-tuned the QwQ-32B model to achieve START. On PhD-level science QA\n(GPQA), competition-level math benchmarks (AMC23, AIME24, AIME25), and the\ncompetition-level code benchmark (LiveCodeBench), START achieves accuracy rates\nof 63.6%, 95.0%, 66.7%, 47.1%, and 47.3%, respectively. It significantly\noutperforms the base QwQ-32B and achieves performance comparable to the\nstate-of-the-art open-weight model R1-Distill-Qwen-32B and the proprietary\nmodel o1-Preview.\n","authors":["Chengpeng Li","Mingfeng Xue","Zhenru Zhang","Jiaxi Yang","Beichen Zhang","Xiang Wang","Bowen Yu","Binyuan Hui","Junyang Lin","Dayiheng Liu"],"pdf_url":"https://arxiv.org/pdf/2503.04625v1.pdf","comment":"38 pages, 5 figures and 6 tables"},{"id":"http://arxiv.org/abs/2503.04619v1","updated":"2025-03-06T17:05:33Z","published":"2025-03-06T17:05:33Z","title":"SynGraph: A Dynamic Graph-LLM Synthesis Framework for Sparse Streaming\n  User Sentiment Modeling","summary":"  User reviews on e-commerce platforms exhibit dynamic sentiment patterns\ndriven by temporal and contextual factors. Traditional sentiment analysis\nmethods focus on static reviews, failing to capture the evolving temporal\nrelationship between user sentiment rating and textual content. Sentiment\nanalysis on streaming reviews addresses this limitation by modeling and\npredicting the temporal evolution of user sentiments. However, it suffers from\ndata sparsity, manifesting in temporal, spatial, and combined forms. In this\npaper, we introduce SynGraph, a novel framework designed to address data\nsparsity in sentiment analysis on streaming reviews. SynGraph alleviates data\nsparsity by categorizing users into mid-tail, long-tail, and extreme scenarios\nand incorporating LLM-augmented enhancements within a dynamic graph-based\nstructure. Experiments on real-world datasets demonstrate its effectiveness in\naddressing sparsity and improving sentiment modeling in streaming reviews.\n","authors":["Xin Zhang","Qiyu Wei","Yingjie Zhu","Linhai Zhang","Deyu Zhou","Sophia Ananiadou"],"pdf_url":"https://arxiv.org/pdf/2503.04619v1.pdf","comment":"18 pages, 17 figures"},{"id":"http://arxiv.org/abs/2503.04618v1","updated":"2025-03-06T17:03:17Z","published":"2025-03-06T17:03:17Z","title":"Better Process Supervision with Bi-directional Rewarding Signals","summary":"  Process supervision, i.e., evaluating each step, is critical for complex\nlarge language model (LLM) reasoning and test-time searching with increased\ninference compute. Existing approaches, represented by process reward models\n(PRMs), primarily focus on rewarding signals up to the current step, exhibiting\na one-directional nature and lacking a mechanism to model the distance to the\nfinal target. To address this problem, we draw inspiration from the A*\nalgorithm, which states that an effective supervisory signal should\nsimultaneously consider the incurred cost and the estimated cost for reaching\nthe target. Building on this key insight, we introduce BiRM, a novel process\nsupervision model that not only evaluates the correctness of previous steps but\nalso models the probability of future success. We conduct extensive experiments\non mathematical reasoning tasks and demonstrate that BiRM provides more precise\nevaluations of LLM reasoning steps, achieving an improvement of 3.1% on\nGaokao2023 over PRM under the Best-of-N sampling method. Besides, in\nsearch-based strategies, BiRM provides more comprehensive guidance and\noutperforms ORM by 5.0% and PRM by 3.8% respectively on MATH-500.\n","authors":["Wenxiang Chen","Wei He","Zhiheng Xi","Honglin Guo","Boyang Hong","Jiazheng Zhang","Rui Zheng","Nijun Li","Tao Gui","Yun Li","Qi Zhang","Xuanjing Huang"],"pdf_url":"https://arxiv.org/pdf/2503.04618v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04615v1","updated":"2025-03-06T16:59:18Z","published":"2025-03-06T16:59:18Z","title":"HalluCounter: Reference-free LLM Hallucination Detection in the Wild!","summary":"  Response consistency-based, reference-free hallucination detection (RFHD)\nmethods do not depend on internal model states, such as generation\nprobabilities or gradients, which Grey-box models typically rely on but are\ninaccessible in closed-source LLMs. However, their inability to capture\nquery-response alignment patterns often results in lower detection accuracy.\nAdditionally, the lack of large-scale benchmark datasets spanning diverse\ndomains remains a challenge, as most existing datasets are limited in size and\nscope. To this end, we propose HalluCounter, a novel reference-free\nhallucination detection method that utilizes both response-response and\nquery-response consistency and alignment patterns. This enables the training of\na classifier that detects hallucinations and provides a confidence score and an\noptimal response for user queries. Furthermore, we introduce HalluCounterEval,\na benchmark dataset comprising both synthetically generated and human-curated\nsamples across multiple domains. Our method outperforms state-of-the-art\napproaches by a significant margin, achieving over 90\\% average confidence in\nhallucination detection across datasets.\n","authors":["Ashok Urlana","Gopichand Kanumolu","Charaka Vinayak Kumar","Bala Mallikarjunarao Garlapati","Rahul Mishra"],"pdf_url":"https://arxiv.org/pdf/2503.04615v1.pdf","comment":"30 pages, 4 figures"},{"id":"http://arxiv.org/abs/2503.04611v1","updated":"2025-03-06T16:57:26Z","published":"2025-03-06T16:57:26Z","title":"Towards Data-Efficient Language Models: A Child-Inspired Approach to\n  Language Learning","summary":"  In this work, we explain our approach employed in the BabyLM Challenge, which\nuses various methods of training language models (LMs) with significantly less\ndata compared to traditional large language models (LLMs) and are inspired by\nhow human children learn. While a human child is exposed to far less linguistic\ninput than an LLM, they still achieve remarkable language understanding and\ngeneration abilities. To this end, we develop a model trained on a curated\ndataset consisting of 10 million words, primarily sourced from child-directed\ntranscripts. The 2024 BabyLM Challenge initial dataset of 10M words is filtered\nto 8.5M. Next, it is supplemented with a randomly selected subset of TVR\ndataset consisting of 1.5M words of television dialogues. The latter dataset\nensures that similar to children, the model is also exposed to language through\nmedia. Furthermore, we reduce the vocabulary size to 32,000 tokens, aligning it\nwith the limited vocabulary of children in the early stages of language\nacquisition. We use curriculum learning and is able to match the baseline on\ncertain benchmarks while surpassing the baseline on others. Additionally,\nincorporating common LLM training datasets, such as MADLAD-400, degrades\nperformance. These findings underscore the importance of dataset selection,\nvocabulary scaling, and curriculum learning in creating more data-efficient\nlanguage models that better mimic human learning processes.\n","authors":["Mohammad Amin Ghanizadeh","Mohammad Javad Dousti"],"pdf_url":"https://arxiv.org/pdf/2503.04611v1.pdf","comment":"5 pages"},{"id":"http://arxiv.org/abs/2503.04606v1","updated":"2025-03-06T16:53:14Z","published":"2025-03-06T16:53:14Z","title":"The Best of Both Worlds: Integrating Language Models and Diffusion\n  Models for Video Generation","summary":"  Recent advancements in text-to-video (T2V) generation have been driven by two\ncompeting paradigms: autoregressive language models and diffusion models.\nHowever, each paradigm has intrinsic limitations: language models struggle with\nvisual quality and error accumulation, while diffusion models lack semantic\nunderstanding and causal modeling. In this work, we propose LanDiff, a hybrid\nframework that synergizes the strengths of both paradigms through\ncoarse-to-fine generation. Our architecture introduces three key innovations:\n(1) a semantic tokenizer that compresses 3D visual features into compact 1D\ndiscrete representations through efficient semantic compression, achieving a\n$\\sim$14,000$\\times$ compression ratio; (2) a language model that generates\nsemantic tokens with high-level semantic relationships; (3) a streaming\ndiffusion model that refines coarse semantics into high-fidelity videos.\nExperiments show that LanDiff, a 5B model, achieves a score of 85.43 on the\nVBench T2V benchmark, surpassing the state-of-the-art open-source models\nHunyuan Video (13B) and other commercial models such as Sora, Keling, and\nHailuo. Furthermore, our model also achieves state-of-the-art performance in\nlong video generation, surpassing other open-source models in this field. Our\ndemo can be viewed at https://landiff.github.io/.\n","authors":["Aoxiong Yin","Kai Shen","Yichong Leng","Xu Tan","Xinyu Zhou","Juncheng Li","Siliang Tang"],"pdf_url":"https://arxiv.org/pdf/2503.04606v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04598v1","updated":"2025-03-06T16:40:48Z","published":"2025-03-06T16:40:48Z","title":"HybridNorm: Towards Stable and Efficient Transformer Training via Hybrid\n  Normalization","summary":"  Transformers have become the de facto architecture for a wide range of\nmachine learning tasks, particularly in large language models (LLMs). Despite\ntheir remarkable performance, challenges remain in training deep transformer\nnetworks, especially regarding the location of layer normalization. While\nPre-Norm structures facilitate easier training due to their more prominent\nidentity path, they often yield suboptimal performance compared to Post-Norm.\nIn this paper, we propose $\\textbf{HybridNorm}$, a straightforward yet\neffective hybrid normalization strategy that integrates the advantages of both\nPre-Norm and Post-Norm approaches. Specifically, HybridNorm employs QKV\nnormalization within the attention mechanism and Post-Norm in the feed-forward\nnetwork (FFN) of each transformer block. This design not only stabilizes\ntraining but also enhances performance, particularly in the context of LLMs.\nComprehensive experiments in both dense and sparse architectures show that\nHybridNorm consistently outperforms both Pre-Norm and Post-Norm approaches,\nachieving state-of-the-art results across various benchmarks. These findings\nhighlight the potential of HybridNorm as a more stable and effective technique\nfor improving the training and performance of deep transformer models. %Code\nwill be made publicly available. Code is available at\nhttps://github.com/BryceZhuo/HybridNorm.\n","authors":["Zhijian Zhuo","Yutao Zeng","Ya Wang","Sijun Zhang","Jian Yang","Xiaoqing Li","Xun Zhou","Jinwen Ma"],"pdf_url":"https://arxiv.org/pdf/2503.04598v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.00053v3","updated":"2025-03-06T16:28:55Z","published":"2024-10-30T19:09:02Z","title":"ACC-Collab: An Actor-Critic Approach to Multi-Agent LLM Collaboration","summary":"  Large language models (LLMs) have demonstrated a remarkable ability to serve\nas general-purpose tools for various language-based tasks. Recent works have\ndemonstrated that the efficacy of such models can be improved through iterative\ndialog between multiple models. While these paradigms show promise in improving\nmodel efficacy, most works in this area treat collaboration as an emergent\nbehavior, rather than a learned behavior. In doing so, current multi-agent\nframeworks rely on collaborative behaviors to have been sufficiently trained\ninto off-the-shelf models. To address this limitation, we propose ACC-Collab,\nan Actor-Critic based learning framework to produce a two-agent team (an\nactor-agent and a critic-agent) specialized in collaboration. We demonstrate\nthat ACC-Collab outperforms SotA multi-agent techniques on a wide array of\nbenchmarks.\n","authors":["Andrew Estornell","Jean-Francois Ton","Yuanshun Yao","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2411.00053v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02972v2","updated":"2025-03-06T16:16:07Z","published":"2025-03-04T19:57:47Z","title":"LINGOLY-TOO: Disentangling Memorisation from Reasoning with Linguistic\n  Templatisation and Orthographic Obfuscation","summary":"  Assessing the reasoning capabilities of large language models (LLMs) is\nsusceptible to overestimation due to data exposure of evaluation benchmarks. We\nintroduce a framework for producing linguistic reasoning problems that reduces\nthe effect of memorisation in model performance estimates and apply this\nframework to develop LINGOLY-TOO, a challenging benchmark for linguistic\nreasoning. By developing orthographic templates, we dynamically obfuscate the\nwriting systems of real languages to generate numerousquestion variations.\nThese variations preserve the reasoning steps required for each solution while\nreducing the likelihood of specific problem instances appearing in model\ntraining data. Our experiments demonstrate that frontier models, including\nClaud 3.7 Sonnet, o1-preview and DeepSeek R1, struggle with advanced reasoning.\nOur analysis also shows that LLMs exhibit noticeable variance in accuracy\nacross permutations of the same problem, and on average perform better on\nquestions appearing in their original orthography. Our findings highlight the\nopaque nature of response generation in LLMs and provide evidence that prior\ndata exposure contributes to over estimating the reasoning capabilities of\nfrontier models.\n","authors":["Jude Khouja","Karolina Korgul","Simi Hellsten","Lingyi Yang","Vlad Neacs","Harry Mayne","Ryan Kearns","Andrew Bean","Adam Mahdi"],"pdf_url":"https://arxiv.org/pdf/2503.02972v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.17504v2","updated":"2025-03-06T16:14:45Z","published":"2025-02-21T19:22:10Z","title":"Protein Large Language Models: A Comprehensive Survey","summary":"  Protein-specific large language models (Protein LLMs) are revolutionizing\nprotein science by enabling more efficient protein structure prediction,\nfunction annotation, and design. While existing surveys focus on specific\naspects or applications, this work provides the first comprehensive overview of\nProtein LLMs, covering their architectures, training datasets, evaluation\nmetrics, and diverse applications. Through a systematic analysis of over 100\narticles, we propose a structured taxonomy of state-of-the-art Protein LLMs,\nanalyze how they leverage large-scale protein sequence data for improved\naccuracy, and explore their potential in advancing protein engineering and\nbiomedical research. Additionally, we discuss key challenges and future\ndirections, positioning Protein LLMs as essential tools for scientific\ndiscovery in protein science. Resources are maintained at\nhttps://github.com/Yijia-Xiao/Protein-LLM-Survey.\n","authors":["Yijia Xiao","Wanjia Zhao","Junkai Zhang","Yiqiao Jin","Han Zhang","Zhicheng Ren","Renliang Sun","Haixin Wang","Guancheng Wan","Pan Lu","Xiao Luo","Yu Zhang","James Zou","Yizhou Sun","Wei Wang"],"pdf_url":"https://arxiv.org/pdf/2502.17504v2.pdf","comment":"24 pages, 4 figures, 5 tables"},{"id":"http://arxiv.org/abs/2404.12464v9","updated":"2025-03-06T16:13:04Z","published":"2024-04-18T18:48:50Z","title":"NormAd: A Framework for Measuring the Cultural Adaptability of Large\n  Language Models","summary":"  To be effectively and safely deployed to global user populations, large\nlanguage models (LLMs) may need to adapt outputs to user values and cultures,\nnot just know about them. We introduce NormAd, an evaluation framework to\nassess LLMs' cultural adaptability, specifically measuring their ability to\njudge social acceptability across varying levels of cultural norm specificity,\nfrom abstract values to explicit social norms. As an instantiation of our\nframework, we create NormAd-Eti, a benchmark of 2.6k situational descriptions\nrepresenting social-etiquette related cultural norms from 75 countries. Through\ncomprehensive experiments on NormAd-Eti, we find that LLMs struggle to\naccurately judge social acceptability across these varying degrees of cultural\ncontexts and show stronger adaptability to English-centric cultures over those\nfrom the Global South. Even in the simplest setting where the relevant social\nnorms are provided, the best LLMs' performance (< 82\\%) lags behind humans (>\n95\\%). In settings with abstract values and country information, model\nperformance drops substantially (< 60\\%), while human accuracy remains high (>\n90\\%). Furthermore, we find that models are better at recognizing socially\nacceptable versus unacceptable situations. Our findings showcase the current\npitfalls in socio-cultural reasoning of LLMs which hinder their adaptability\nfor global audiences.\n","authors":["Abhinav Rao","Akhila Yerukola","Vishwa Shah","Katharina Reinecke","Maarten Sap"],"pdf_url":"https://arxiv.org/pdf/2404.12464v9.pdf","comment":"Accepted at NAACL 2025"},{"id":"http://arxiv.org/abs/2503.01804v2","updated":"2025-03-06T16:07:43Z","published":"2025-03-03T18:33:46Z","title":"$\\texttt{SEM-CTRL}$: Semantically Controlled Decoding","summary":"  Ensuring both syntactic and semantic correctness in Large Language Model\n(LLM) outputs remains a significant challenge, despite being critical for\nreal-world deployment. In this paper, we introduce $\\texttt{SEM-CTRL}$, a\nunified approach that enforces rich context-sensitive constraints and task- and\ninstance-specific semantics directly on an LLM decoder. Our approach integrates\ntoken-level MCTS, which is guided by specific syntactic and semantic\nconstraints. The constraints over the desired outputs are expressed using\nAnswer Set Grammars -- a logic-based formalism that generalizes\ncontext-sensitive grammars while incorporating background knowledge to\nrepresent task-specific semantics. We show that our approach guarantees correct\ncompletions for any off-the-shelf LLM without the need for fine-tuning. We\nevaluate $\\texttt{SEM-CTRL}$ on a range of tasks, including synthetic grammar\nsynthesis, combinatorial reasoning, and planning. Our results demonstrate that\n$\\texttt{SEM-CTRL}$ allows small pre-trained LLMs to efficiently outperform\nlarger variants and state-of-the-art reasoning models (e.g., o1-preview) while\nsimultaneously guaranteeing solution correctness.\n","authors":["Mohammad Albinhassan","Pranava Madhyastha","Alessandra Russo"],"pdf_url":"https://arxiv.org/pdf/2503.01804v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.00153v2","updated":"2025-03-06T15:50:28Z","published":"2024-09-30T18:52:53Z","title":"Beyond Single Concept Vector: Modeling Concept Subspace in LLMs with\n  Gaussian Distribution","summary":"  Probing learned concepts in large language models (LLMs) is crucial for\nunderstanding how semantic knowledge is encoded internally. Training linear\nclassifiers on probing tasks is a principle approach to denote the vector of a\ncertain concept in the representation space. However, the single vector\nidentified for a concept varies with both data and training, making it less\nrobust and weakening its effectiveness in real-world applications. To address\nthis challenge, we propose an approach to approximate the subspace representing\na specific concept. Built on linear probing classifiers, we extend the concept\nvectors into Gaussian Concept Subspace (GCS). We demonstrate GCS's\neffectiveness through measuring its faithfulness and plausibility across\nmultiple LLMs with different sizes and architectures. Additionally, we use\nrepresentation intervention tasks to showcase its efficacy in real-world\napplications such as emotion steering. Experimental results indicate that GCS\nconcept vectors have the potential to balance steering performance and\nmaintaining the fluency in natural language generation tasks.\n","authors":["Haiyan Zhao","Heng Zhao","Bo Shen","Ali Payani","Fan Yang","Mengnan Du"],"pdf_url":"https://arxiv.org/pdf/2410.00153v2.pdf","comment":"Accepted by ICLR 2025"},{"id":"http://arxiv.org/abs/2503.04556v1","updated":"2025-03-06T15:47:19Z","published":"2025-03-06T15:47:19Z","title":"Compositional Causal Reasoning Evaluation in Language Models","summary":"  Causal reasoning and compositional reasoning are two core aspirations in\ngenerative AI. Measuring the extent of these behaviors requires principled\nevaluation methods. We explore a unified perspective that considers both\nbehaviors simultaneously, termed compositional causal reasoning (CCR): the\nability to infer how causal measures compose and, equivalently, how causal\nquantities propagate through graphs. We instantiate a framework for the\nsystematic evaluation of CCR for the average treatment effect and the\nprobability of necessity and sufficiency. As proof of concept, we demonstrate\nthe design of CCR tasks for language models in the LLama, Phi, and GPT\nfamilies. On a math word problem, our framework revealed a range of\ntaxonomically distinct error patterns. Additionally, CCR errors increased with\nthe complexity of causal paths for all models except o1.\n","authors":["Jacqueline R. M. A. Maasch","Alihan Hüyük","Xinnuo Xu","Aditya V. Nori","Javier Gonzalez"],"pdf_url":"https://arxiv.org/pdf/2503.04556v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.09990v2","updated":"2025-03-06T15:38:31Z","published":"2025-02-14T08:22:51Z","title":"X-Boundary: Establishing Exact Safety Boundary to Shield LLMs from\n  Multi-Turn Jailbreaks without Compromising Usability","summary":"  Despite the rapid development of safety alignment techniques for LLMs,\ndefending against multi-turn jailbreaks is still a challenging task. In this\npaper, we conduct a comprehensive comparison, revealing that some existing\ndefense methods can improve the robustness of LLMs against multi-turn\njailbreaks but compromise usability, i.e., reducing general capabilities or\ncausing the over-refusal problem. From the perspective of mechanism\ninterpretability of LLMs, we discover that these methods fail to establish a\nboundary that exactly distinguishes safe and harmful feature representations.\nTherefore, boundary-safe representations close to harmful representations are\ninevitably disrupted, leading to a decline in usability. To address this issue,\nwe propose X-Boundary to push harmful representations away from boundary-safe\nrepresentations and obtain an exact distinction boundary. In this way, harmful\nrepresentations can be precisely erased without disrupting safe ones.\nExperimental results show that X-Boundary achieves state-of-the-art defense\nperformance against multi-turn jailbreaks, while reducing the over-refusal rate\nby about 20% and maintaining nearly complete general capability. Furthermore,\nwe theoretically prove and empirically verify that X-Boundary can accelerate\nthe convergence process during training. Please see our code at:\nhttps://github.com/AI45Lab/X-Boundary.\n","authors":["Xiaoya Lu","Dongrui Liu","Yi Yu","Luxin Xu","Jing Shao"],"pdf_url":"https://arxiv.org/pdf/2502.09990v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04554v1","updated":"2025-03-06T15:37:31Z","published":"2025-03-06T15:37:31Z","title":"Compositional Translation: A Novel LLM-based Approach for Low-resource\n  Machine Translation","summary":"  The ability of generative large language models (LLMs) to perform in-context\nlearning has given rise to a large body of research into how best to prompt\nmodels for various natural language processing tasks. Machine Translation (MT)\nhas been shown to benefit from in-context examples, in particular when they are\nsemantically similar to the sentence to translate. In this paper, we propose a\nnew LLM-based translation paradigm, compositional translation, to replace naive\nfew-shot MT with similarity-based demonstrations. An LLM is used to decompose a\nsentence into simpler phrases, and then to translate each phrase with the help\nof retrieved demonstrations. Finally, the LLM is prompted to translate the\ninitial sentence with the help of the self-generated phrase-translation pairs.\nOur intuition is that this approach should improve translation because these\nshorter phrases should be intrinsically easier to translate and easier to match\nwith relevant examples. This is especially beneficial in low-resource\nscenarios, and more generally whenever the selection pool is small or out of\ndomain. We show that compositional translation boosts LLM translation\nperformance on a wide range of popular MT benchmarks, including FLORES 200,\nNTREX 128 and TICO-19. Code and outputs are available at\nhttps://github.com/ArmelRandy/compositional-translation\n","authors":["Armel Zebaze","Benoît Sagot","Rachel Bawden"],"pdf_url":"https://arxiv.org/pdf/2503.04554v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20984v2","updated":"2025-03-06T15:36:48Z","published":"2025-02-28T11:52:02Z","title":"UoR-NCL at SemEval-2025 Task 1: Using Generative LLMs and CLIP Models\n  for Multilingual Multimodal Idiomaticity Representation","summary":"  SemEval-2025 Task 1 focuses on ranking images based on their alignment with a\ngiven nominal compound that may carry idiomatic meaning in both English and\nBrazilian Portuguese. To address this challenge, this work uses generative\nlarge language models (LLMs) and multilingual CLIP models to enhance idiomatic\ncompound representations. LLMs generate idiomatic meanings for potentially\nidiomatic compounds, enriching their semantic interpretation. These meanings\nare then encoded using multilingual CLIP models, serving as representations for\nimage ranking. Contrastive learning and data augmentation techniques are\napplied to fine-tune these embeddings for improved performance. Experimental\nresults show that multimodal representations extracted through this method\noutperformed those based solely on the original nominal compounds. The\nfine-tuning approach shows promising outcomes but is less effective than using\nembeddings without fine-tuning. The source code used in this paper is available\nat https://github.com/tongwu17/SemEval-2025-Task1-UoR-NCL.\n","authors":["Thanet Markchom","Tong Wu","Liting Huang","Huizhi Liang"],"pdf_url":"https://arxiv.org/pdf/2502.20984v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04548v1","updated":"2025-03-06T15:34:27Z","published":"2025-03-06T15:34:27Z","title":"An Empirical Study on Eliciting and Improving R1-like Reasoning Models","summary":"  In this report, we present the third technical report on the development of\nslow-thinking models as part of the STILL project. As the technical pathway\nbecomes clearer, scaling RL training has become a central technique for\nimplementing such reasoning models. We systematically experiment with and\ndocument the effects of various factors influencing RL training, conducting\nexperiments on both base models and fine-tuned models. Specifically, we\ndemonstrate that our RL training approach consistently improves the Qwen2.5-32B\nbase models, enhancing both response length and test accuracy. Furthermore, we\nshow that even when a model like DeepSeek-R1-Distill-Qwen-1.5B has already\nachieved a high performance level, it can be further refined through RL\ntraining, reaching an accuracy of 39.33% on AIME 2024. Beyond RL training, we\nalso explore the use of tool manipulation, finding that it significantly boosts\nthe reasoning performance of large reasoning models. This approach achieves a\nremarkable accuracy of 86.67% with greedy search on AIME 2024, underscoring its\neffectiveness in enhancing model capabilities. We release our resources at the\nSTILL project website: https://github.com/RUCAIBox/Slow_Thinking_with_LLMs.\n","authors":["Zhipeng Chen","Yingqian Min","Beichen Zhang","Jie Chen","Jinhao Jiang","Daixuan Cheng","Wayne Xin Zhao","Zheng Liu","Xu Miao","Yang Lu","Lei Fang","Zhongyuan Wang","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2503.04548v1.pdf","comment":"Technical Report on Slow Thinking with LLMs: Part III"},{"id":"http://arxiv.org/abs/2503.04543v1","updated":"2025-03-06T15:29:13Z","published":"2025-03-06T15:29:13Z","title":"Keeping Yourself is Important in Downstream Tuning Multimodal Large\n  Language Model","summary":"  Multi-modal Large Language Models (MLLMs) integrate visual and linguistic\nreasoning to address complex tasks such as image captioning and visual question\nanswering. While MLLMs demonstrate remarkable versatility, MLLMs appears\nlimited performance on special applications. But tuning MLLMs for downstream\ntasks encounters two key challenges: Task-Expert Specialization, where\ndistribution shifts between pre-training and target datasets constrain target\nperformance, and Open-World Stabilization, where catastrophic forgetting erases\nthe model general knowledge. In this work, we systematically review recent\nadvancements in MLLM tuning methodologies, classifying them into three\nparadigms: (I) Selective Tuning, (II) Additive Tuning, and (III)\nReparameterization Tuning. Furthermore, we benchmark these tuning strategies\nacross popular MLLM architectures and diverse downstream tasks to establish\nstandardized evaluation analysis and systematic tuning principles. Finally, we\nhighlight several open challenges in this domain and propose future research\ndirections. To facilitate ongoing progress in this rapidly evolving field, we\nprovide a public repository that continuously tracks developments:\nhttps://github.com/WenkeHuang/Awesome-MLLM-Tuning.\n","authors":["Wenke Huang","Jian Liang","Xianda Guo","Yiyang Fang","Guancheng Wan","Xuankun Rong","Chi Wen","Zekun Shi","Qingyun Li","Didi Zhu","Yanbiao Ma","Ke Liang","Bin Yang","He Li","Jiawei Shao","Mang Ye","Bo Du"],"pdf_url":"https://arxiv.org/pdf/2503.04543v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07180v5","updated":"2025-03-06T15:26:56Z","published":"2024-11-11T17:57:30Z","title":"Gumbel Counterfactual Generation From Language Models","summary":"  Understanding and manipulating the causal generation mechanisms in language\nmodels is essential for controlling their behavior. Previous work has primarily\nrelied on techniques such as representation surgery -- e.g., model ablations or\nmanipulation of linear subspaces tied to specific concepts -- to\n\\emph{intervene} on these models. To understand the impact of interventions\nprecisely, it is useful to examine \\emph{counterfactuals} -- e.g., how a given\nsentence would have appeared had it been generated by the model following a\nspecific intervention. We highlight that counterfactual reasoning is\nconceptually distinct from interventions, as articulated in Pearl's causal\nhierarchy. Based on this observation, we propose a framework for generating\ntrue string counterfactuals by reformulating language models as a structural\nequation model using the Gumbel-max trick, which we called Gumbel\ncounterfactual generation. This reformulation allows us to model the joint\ndistribution over original strings and their counterfactuals resulting from the\nsame instantiation of the sampling noise. We develop an algorithm based on\nhindsight Gumbel sampling that allows us to infer the latent noise variables\nand generate counterfactuals of observed strings. Our experiments demonstrate\nthat the approach produces meaningful counterfactuals while at the same time\nshowing that commonly used intervention techniques have considerable undesired\nside effects.\n","authors":["Shauli Ravfogel","Anej Svete","Vésteinn Snæbjarnarson","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2411.07180v5.pdf","comment":"Accepted in ICLR 2025"},{"id":"http://arxiv.org/abs/2411.12580v2","updated":"2025-03-06T15:14:17Z","published":"2024-11-19T15:47:12Z","title":"Procedural Knowledge in Pretraining Drives Reasoning in Large Language\n  Models","summary":"  The capabilities and limitations of Large Language Models have been sketched\nout in great detail in recent years, providing an intriguing yet conflicting\npicture. On the one hand, LLMs demonstrate a general ability to solve problems.\nOn the other hand, they show surprising reasoning gaps when compared to humans,\ncasting doubt on the robustness of their generalisation strategies. The sheer\nvolume of data used in the design of LLMs has precluded us from applying the\nmethod traditionally used to measure generalisation: train-test set separation.\nTo overcome this, we study what kind of generalisation strategies LLMs employ\nwhen performing reasoning tasks by investigating the pretraining data they rely\non. For two models of different sizes (7B and 35B) and 2.5B of their\npretraining tokens, we identify what documents influence the model outputs for\nthree simple mathematical reasoning tasks and contrast this to the data that\nare influential for answering factual questions. We find that, while the models\nrely on mostly distinct sets of data for each factual question, a document\noften has a similar influence across different reasoning questions within the\nsame task, indicating the presence of procedural knowledge. We further find\nthat the answers to factual questions often show up in the most influential\ndata. However, for reasoning questions the answers usually do not show up as\nhighly influential, nor do the answers to the intermediate reasoning steps.\nWhen we characterise the top ranked documents for the reasoning questions\nqualitatively, we confirm that the influential documents often contain\nprocedural knowledge, like demonstrating how to obtain a solution using\nformulae or code. Our findings indicate that the approach to reasoning the\nmodels use is unlike retrieval, and more like a generalisable strategy that\nsynthesises procedural knowledge from documents doing a similar form of\nreasoning.\n","authors":["Laura Ruis","Maximilian Mozes","Juhan Bae","Siddhartha Rao Kamalakara","Dwarak Talupuru","Acyr Locatelli","Robert Kirk","Tim Rocktäschel","Edward Grefenstette","Max Bartolo"],"pdf_url":"https://arxiv.org/pdf/2411.12580v2.pdf","comment":"Published at ICLR 2025"},{"id":"http://arxiv.org/abs/2503.00367v2","updated":"2025-03-06T15:08:32Z","published":"2025-03-01T06:29:00Z","title":"Approaching the Limits to EFL Writing Enhancement with AI-generated Text\n  and Diverse Learners","summary":"  Generative artificial intelligence (AI) chatbots, such as ChatGPT, are\nreshaping how English as a foreign language (EFL) students write since students\ncan compose texts by integrating their own words with AI-generated text. This\nstudy investigated how 59 Hong Kong secondary school students with varying\nlevels of academic achievement interacted with AI-generated text to compose a\nfeature article, exploring whether any interaction patterns benefited the\noverall quality of the article. Through content analysis, multiple linear\nregression and cluster analysis, we found the overall number of words --\nwhether AI- or human-generated -- is the main predictor of writing quality.\nHowever, the impact varies by students' competence to write independently, for\ninstance, by using their own words accurately and coherently to compose a text,\nand to follow specific interaction patterns with AI-generated text. Therefore,\nalthough composing texts with human words and AI-generated text may become\nprevalent in EFL writing classrooms, without educators' careful attention to\nEFL writing pedagogy and AI literacy, high-achieving students stand to benefit\nmore from using AI-generated text than low-achieving students.\n","authors":["David James Woo","Hengky Susanto","Chi Ho Yeung","Kai Guo"],"pdf_url":"https://arxiv.org/pdf/2503.00367v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04490v1","updated":"2025-03-06T14:38:20Z","published":"2025-03-06T14:38:20Z","title":"Large Language Models in Bioinformatics: A Survey","summary":"  Large Language Models (LLMs) are revolutionizing bioinformatics, enabling\nadvanced analysis of DNA, RNA, proteins, and single-cell data. This survey\nprovides a systematic review of recent advancements, focusing on genomic\nsequence modeling, RNA structure prediction, protein function inference, and\nsingle-cell transcriptomics. Meanwhile, we also discuss several key challenges,\nincluding data scarcity, computational complexity, and cross-omics integration,\nand explore future directions such as multimodal learning, hybrid AI models,\nand clinical applications. By offering a comprehensive perspective, this paper\nunderscores the transformative potential of LLMs in driving innovations in\nbioinformatics and precision medicine.\n","authors":["Zhenyu Wang","Zikang Wang","Jiyue Jiang","Pengan Chen","Xiangyu Shi","Yu Li"],"pdf_url":"https://arxiv.org/pdf/2503.04490v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04482v1","updated":"2025-03-06T14:30:55Z","published":"2025-03-06T14:30:55Z","title":"Generalized Interpolating Discrete Diffusion","summary":"  While state-of-the-art language models achieve impressive results through\nnext-token prediction, they have inherent limitations such as the inability to\nrevise already generated tokens. This has prompted exploration of alternative\napproaches such as discrete diffusion. However, masked diffusion, which has\nemerged as a popular choice due to its simplicity and effectiveness,\nreintroduces this inability to revise words. To overcome this, we generalize\nmasked diffusion and derive the theoretical backbone of a family of general\ninterpolating discrete diffusion (GIDD) processes offering greater flexibility\nin the design of the noising processes. Leveraging a novel diffusion ELBO, we\nachieve compute-matched state-of-the-art performance in diffusion language\nmodeling. Exploiting GIDD's flexibility, we explore a hybrid approach combining\nmasking and uniform noise, leading to improved sample quality and unlocking the\nability for the model to correct its own mistakes, an area where autoregressive\nmodels notoriously have struggled. Our code and models are open-source:\nhttps://github.com/dvruette/gidd/\n","authors":["Dimitri von Rütte","Janis Fluri","Yuhui Ding","Antonio Orvieto","Bernhard Schölkopf","Thomas Hofmann"],"pdf_url":"https://arxiv.org/pdf/2503.04482v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04463v1","updated":"2025-03-06T14:15:07Z","published":"2025-03-06T14:15:07Z","title":"Guiding LLMs to Generate High-Fidelity and High-Quality Counterfactual\n  Explanations for Text Classification","summary":"  The need for interpretability in deep learning has driven interest in\ncounterfactual explanations, which identify minimal changes to an instance that\nchange a model's prediction. Current counterfactual (CF) generation methods\nrequire task-specific fine-tuning and produce low-quality text. Large Language\nModels (LLMs), though effective for high-quality text generation, struggle with\nlabel-flipping counterfactuals (i.e., counterfactuals that change the\nprediction) without fine-tuning. We introduce two simple classifier-guided\napproaches to support counterfactual generation by LLMs, eliminating the need\nfor fine-tuning while preserving the strengths of LLMs. Despite their\nsimplicity, our methods outperform state-of-the-art counterfactual generation\nmethods and are effective across different LLMs, highlighting the benefits of\nguiding counterfactual generation by LLMs with classifier information. We\nfurther show that data augmentation by our generated CFs can improve a\nclassifier's robustness. Our analysis reveals a critical issue in\ncounterfactual generation by LLMs: LLMs rely on parametric knowledge rather\nthan faithfully following the classifier.\n","authors":["Van Bach Nguyen","Christin Seifert","Jörg Schlötterer"],"pdf_url":"https://arxiv.org/pdf/2503.04463v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04449v1","updated":"2025-03-06T14:04:30Z","published":"2025-03-06T14:04:30Z","title":"Quantifying patterns of punctuation in modern Chinese prose","summary":"  Recent research shows that punctuation patterns in texts exhibit universal\nfeatures across languages. Analysis of Western classical literature reveals\nthat the distribution of spaces between punctuation marks aligns with a\ndiscrete Weibull distribution, typically used in survival analysis. By\nextending this analysis to Chinese literature represented here by three notable\ncontemporary works, it is shown that Zipf's law applies to Chinese texts\nsimilarly to Western texts, where punctuation patterns also improve adherence\nto the law. Additionally, the distance distribution between punctuation marks\nin Chinese texts follows the Weibull model, though larger spacing is less\nfrequent than in English translations. Sentence-ending punctuation,\nrepresenting sentence length, diverges more from this pattern, reflecting\ngreater flexibility in sentence length. This variability supports the formation\nof complex, multifractal sentence structures, particularly evident in Gao\nXingjian's \"Soul Mountain\". These findings demonstrate that both Chinese and\nWestern texts share universal punctuation and word distribution patterns,\nunderscoring their broad applicability across languages.\n","authors":["Michał Dolina","Jakub Dec","Stanisław Drożdż","Jarosław Kwapień","Jin Liu","Tomasz Stanisz"],"pdf_url":"https://arxiv.org/pdf/2503.04449v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04439v1","updated":"2025-03-06T13:55:33Z","published":"2025-03-06T13:55:33Z","title":"A Dataset for Analysing News Framing in Chinese Media","summary":"  Framing is an essential device in news reporting, allowing the writer to\ninfluence public perceptions of current affairs. While there are existing\nautomatic news framing detection datasets in various languages, none of them\nfocus on news framing in the Chinese language which has complex character\nmeanings and unique linguistic features. This study introduces the first\nChinese News Framing dataset, to be used as either a stand-alone dataset or a\nsupplementary resource to the SemEval-2023 task 3 dataset. We detail its\ncreation and we run baseline experiments to highlight the need for such a\ndataset and create benchmarks for future research, providing results obtained\nthrough fine-tuning XLM-RoBERTa-Base and using GPT-4o in the zero-shot setting.\nWe find that GPT-4o performs significantly worse than fine-tuned XLM-RoBERTa\nacross all languages. For the Chinese language, we obtain an F1-micro (the\nperformance metric for SemEval task 3, subtask 2) score of 0.719 using only\nsamples from our Chinese News Framing dataset and a score of 0.753 when we\naugment the SemEval dataset with Chinese news framing samples. With positive\nnews frame detection results, this dataset is a valuable resource for detecting\nnews frames in the Chinese language and is a valuable supplement to the\nSemEval-2023 task 3 dataset.\n","authors":["Owen Cook","Yida Mu","Xinye Yang","Xingyi Song","Kalina Bontcheva"],"pdf_url":"https://arxiv.org/pdf/2503.04439v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.13959v2","updated":"2025-03-06T13:51:24Z","published":"2025-01-21T06:32:25Z","title":"Assisting Mathematical Formalization with A Learning-based Premise\n  Retriever","summary":"  Premise selection is a crucial yet challenging step in mathematical\nformalization, especially for users with limited experience. Due to the lack of\navailable formalization projects, existing approaches that leverage language\nmodels often suffer from data scarcity. In this work, we introduce an\ninnovative method for training a premise retriever to support the formalization\nof mathematics. Our approach employs a BERT model to embed proof states and\npremises into a shared latent space. The retrieval model is trained within a\ncontrastive learning framework and incorporates a domain-specific tokenizer\nalong with a fine-grained similarity computation method. Experimental results\nshow that our model is highly competitive compared to existing baselines,\nachieving strong performance while requiring fewer computational resources.\nPerformance is further enhanced through the integration of a re-ranking module.\nTo streamline the formalization process, we will release a search engine that\nenables users to query Mathlib theorems directly using proof states,\nsignificantly improving accessibility and efficiency. Codes are available at\nhttps://github.com/ruc-ai4math/Premise-Retrieval.\n","authors":["Yicheng Tao","Haotian Liu","Shanwen Wang","Hongteng Xu"],"pdf_url":"https://arxiv.org/pdf/2501.13959v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.07978v4","updated":"2025-03-06T13:29:24Z","published":"2023-11-14T08:10:14Z","title":"AfroBench: How Good are Large Language Models on African Languages?","summary":"  Large-scale multilingual evaluations, such as MEGA, often include only a\nhandful of African languages due to the scarcity of high-quality evaluation\ndata and the limited discoverability of existing African datasets. This lack of\nrepresentation hinders comprehensive LLM evaluation across a diverse range of\nlanguages and tasks. To address these challenges, we introduce AfroBench -- a\nmulti-task benchmark for evaluating the performance of LLMs across 64 African\nlanguages, 15 tasks and 22 datasets. AfroBench consists of nine natural\nlanguage understanding datasets, six text generation datasets, six knowledge\nand question answering tasks, and one mathematical reasoning task. We present\nresults comparing the performance of prompting LLMs to fine-tuned baselines\nbased on BERT and T5-style models. Our results suggest large gaps in\nperformance between high-resource languages, such as English, and African\nlanguages across most tasks; but performance also varies based on the\navailability of monolingual data resources. Our findings confirm that\nperformance on African languages continues to remain a hurdle for current LLMs,\nunderscoring the need for additional efforts to close this gap.\n  https://mcgill-nlp.github.io/AfroBench/\n","authors":["Jessica Ojo","Odunayo Ogundepo","Akintunde Oladipo","Kelechi Ogueji","Jimmy Lin","Pontus Stenetorp","David Ifeoluwa Adelani"],"pdf_url":"https://arxiv.org/pdf/2311.07978v4.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2503.04421v1","updated":"2025-03-06T13:26:58Z","published":"2025-03-06T13:26:58Z","title":"Revisiting the Othello World Model Hypothesis","summary":"  Li et al. (2023) used the Othello board game as a test case for the ability\nof GPT-2 to induce world models, and were followed up by Nanda et al. (2023b).\nWe briefly discuss the original experiments, expanding them to include more\nlanguage models with more comprehensive probing. Specifically, we analyze\nsequences of Othello board states and train the model to predict the next move\nbased on previous moves. We evaluate seven language models (GPT-2, T5, Bart,\nFlan-T5, Mistral, LLaMA-2, and Qwen2.5) on the Othello task and conclude that\nthese models not only learn to play Othello, but also induce the Othello board\nlayout. We find that all models achieve up to 99% accuracy in unsupervised\ngrounding and exhibit high similarity in the board features they learned. This\nprovides considerably stronger evidence for the Othello World Model Hypothesis\nthan previous works.\n","authors":["Yifei Yuan","Anders Søgaard"],"pdf_url":"https://arxiv.org/pdf/2503.04421v1.pdf","comment":"ICLR World Models Workshop"},{"id":"http://arxiv.org/abs/2503.04413v1","updated":"2025-03-06T13:10:57Z","published":"2025-03-06T13:10:57Z","title":"Can Large Language Models Predict Antimicrobial Resistance Gene?","summary":"  This study demonstrates that generative large language models can be utilized\nin a more flexible manner for DNA sequence analysis and classification tasks\ncompared to traditional transformer encoder-based models. While recent\nencoder-based models such as DNABERT and Nucleotide Transformer have shown\nsignificant performance in DNA sequence classification, transformer\ndecoder-based generative models have not yet been extensively explored in this\nfield. This study evaluates how effectively generative Large Language Models\nhandle DNA sequences with various labels and analyzes performance changes when\nadditional textual information is provided. Experiments were conducted on\nantimicrobial resistance genes, and the results show that generative Large\nLanguage Models can offer comparable or potentially better predictions,\ndemonstrating flexibility and accuracy when incorporating both sequence and\ntextual information. The code and data used in this work are available at the\nfollowing GitHub repository: https://github.com/biocomgit/llm4dna.\n","authors":["Hyunwoo Yoo"],"pdf_url":"https://arxiv.org/pdf/2503.04413v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04405v1","updated":"2025-03-06T12:59:11Z","published":"2025-03-06T12:59:11Z","title":"Comparative Study of Zero-Shot Cross-Lingual Transfer for Bodo POS and\n  NER Tagging Using Gemini 2.0 Flash Thinking Experimental Model","summary":"  Named Entity Recognition (NER) and Part-of-Speech (POS) tagging are critical\ntasks for Natural Language Processing (NLP), yet their availability for\nlow-resource languages (LRLs) like Bodo remains limited. This article presents\na comparative empirical study investigating the effectiveness of Google's\nGemini 2.0 Flash Thinking Experiment model for zero-shot cross-lingual transfer\nof POS and NER tagging to Bodo. We explore two distinct methodologies: (1)\ndirect translation of English sentences to Bodo followed by tag transfer, and\n(2) prompt-based tag transfer on parallel English-Bodo sentence pairs. Both\nmethods leverage the machine translation and cross-lingual understanding\ncapabilities of Gemini 2.0 Flash Thinking Experiment to project English POS and\nNER annotations onto Bodo text in CONLL-2003 format. Our findings reveal the\ncapabilities and limitations of each approach, demonstrating that while both\nmethods show promise for bootstrapping Bodo NLP, prompt-based transfer exhibits\nsuperior performance, particularly for NER. We provide a detailed analysis of\nthe results, highlighting the impact of translation quality, grammatical\ndivergences, and the inherent challenges of zero-shot cross-lingual transfer.\nThe article concludes by discussing future research directions, emphasizing the\nneed for hybrid approaches, few-shot fine-tuning, and the development of\ndedicated Bodo NLP resources to achieve high-accuracy POS and NER tagging for\nthis low-resource language.\n","authors":["Sanjib Narzary","Bihung Brahma","Haradip Mahilary","Mahananda Brahma","Bidisha Som","Sukumar Nandi"],"pdf_url":"https://arxiv.org/pdf/2503.04405v1.pdf","comment":"Submitted to SpringerNature MTAP journal. This article has not been\n  reviewed yet. Submitting for public review!"},{"id":"http://arxiv.org/abs/2406.12753v2","updated":"2025-03-06T12:55:25Z","published":"2024-06-18T16:20:53Z","title":"OlympicArena: Benchmarking Multi-discipline Cognitive Reasoning for\n  Superintelligent AI","summary":"  The evolution of Artificial Intelligence (AI) has been significantly\naccelerated by advancements in Large Language Models (LLMs) and Large\nMultimodal Models (LMMs), gradually showcasing potential cognitive reasoning\nabilities in problem-solving and scientific discovery (i.e., AI4Science) once\nexclusive to human intellect. To comprehensively evaluate current models'\nperformance in cognitive reasoning abilities, we introduce OlympicArena, which\nincludes 11,163 bilingual problems across both text-only and interleaved\ntext-image modalities. These challenges encompass a wide range of disciplines\nspanning seven fields and 62 international Olympic competitions, rigorously\nexamined for data leakage. We argue that the challenges in Olympic competition\nproblems are ideal for evaluating AI's cognitive reasoning due to their\ncomplexity and interdisciplinary nature, which are essential for tackling\ncomplex scientific challenges and facilitating discoveries. Beyond evaluating\nperformance across various disciplines using answer-only criteria, we conduct\ndetailed experiments and analyses from multiple perspectives. We delve into the\nmodels' cognitive reasoning abilities, their performance across different\nmodalities, and their outcomes in process-level evaluations, which are vital\nfor tasks requiring complex reasoning with lengthy solutions. Our extensive\nevaluations reveal that even advanced models like GPT-4o only achieve a 39.97%\noverall accuracy, illustrating current AI limitations in complex reasoning and\nmultimodal integration. Through the OlympicArena, we aim to advance AI towards\nsuperintelligence, equipping it to address more complex challenges in science\nand beyond. We also provide a comprehensive set of resources to support AI\nresearch, including a benchmark dataset, an open-source annotation platform, a\ndetailed evaluation tool, and a leaderboard with automatic submission features.\n","authors":["Zhen Huang","Zengzhi Wang","Shijie Xia","Xuefeng Li","Haoyang Zou","Ruijie Xu","Run-Ze Fan","Lyumanshan Ye","Ethan Chern","Yixin Ye","Yikai Zhang","Yuqing Yang","Ting Wu","Binjie Wang","Shichao Sun","Yang Xiao","Yiyuan Li","Fan Zhou","Steffi Chern","Yiwei Qin","Yan Ma","Jiadi Su","Yixiu Liu","Yuxiang Zheng","Shaoting Zhang","Dahua Lin","Yu Qiao","Pengfei Liu"],"pdf_url":"https://arxiv.org/pdf/2406.12753v2.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2404.05569v3","updated":"2025-03-06T12:54:37Z","published":"2024-04-08T14:43:13Z","title":"360$^\\circ$REA: Towards A Reusable Experience Accumulation with\n  360° Assessment for Multi-Agent System","summary":"  Large language model agents have demonstrated remarkable advancements across\nvarious complex tasks. Recent works focus on optimizing the agent team or\nemploying self-reflection to iteratively solve complex tasks. Since these\nagents are all based on the same LLM, only conducting self-evaluation or\nremoving underperforming agents does not substantively enhance the capability\nof the agents. We argue that a comprehensive evaluation and accumulating\nexperience from evaluation feedback is an effective approach to improving\nsystem performance. In this paper, we propose Reusable Experience Accumulation\nwith 360$^\\circ$ Assessment (360$^\\circ$REA), a hierarchical multi-agent\nframework inspired by corporate organizational practices. The framework employs\na novel 360$^\\circ$ performance assessment method for multi-perspective\nperformance evaluation with fine-grained assessment. To enhance the capability\nof agents in addressing complex tasks, we introduce dual-level experience pool\nfor agents to accumulate experience through fine-grained assessment. Extensive\nexperiments on complex task datasets demonstrate the effectiveness of\n360$^\\circ$REA.\n","authors":["Shen Gao","Hao Li","Chengrui Huang","Quan Tu","Zhiliang Tian","Minlie Huang","Shuo Shang"],"pdf_url":"https://arxiv.org/pdf/2404.05569v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20742v2","updated":"2025-03-06T12:50:44Z","published":"2025-02-28T05:47:34Z","title":"Structured Preference Optimization for Vision-Language Long-Horizon Task\n  Planning","summary":"  Existing methods for vision-language task planning excel in short-horizon\ntasks but often fall short in complex, long-horizon planning within dynamic\nenvironments. These challenges primarily arise from the difficulty of\neffectively training models to produce high-quality reasoning processes for\nlong-horizon tasks. To address this, we propose Structured Preference\nOptimization (SPO), which aims to enhance reasoning and action selection in\nlong-horizon task planning through structured preference evaluation and\noptimized training strategies. Specifically, SPO introduces: 1)\nPreference-Based Scoring and Optimization, which systematically evaluates\nreasoning chains based on task relevance, visual grounding, and historical\nconsistency; and 2) Curriculum-Guided Training, where the model progressively\nadapts from simple to complex tasks, improving its generalization ability in\nlong-horizon scenarios and enhancing reasoning robustness. To advance research\nin vision-language long-horizon task planning, we introduce ExtendaBench, a\ncomprehensive benchmark covering 1,509 tasks across VirtualHome and Habitat\n2.0, categorized into ultra-short, short, medium, and long tasks. Experimental\nresults demonstrate that SPO significantly improves reasoning quality and final\ndecision accuracy, outperforming prior methods on long-horizon tasks and\nunderscoring the effectiveness of preference-driven optimization in\nvision-language task planning. Specifically, SPO achieves a +5.98% GCR and\n+4.68% SR improvement in VirtualHome and a +3.30% GCR and +2.11% SR improvement\nin Habitat over the best-performing baselines.\n","authors":["Xiwen Liang","Min Lin","Weiqi Ruan","Rongtao Xu","Yuecheng Liu","Jiaqi Chen","Bingqian Lin","Yuzheng Zhuang","Xiaodan Liang"],"pdf_url":"https://arxiv.org/pdf/2502.20742v2.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2503.04396v1","updated":"2025-03-06T12:50:14Z","published":"2025-03-06T12:50:14Z","title":"TableLoRA: Low-rank Adaptation on Table Structure Understanding for\n  Large Language Models","summary":"  Tabular data are crucial in many fields and their understanding by large\nlanguage models (LLMs) under high parameter efficiency paradigm is important.\nHowever, directly applying parameter-efficient fine-tuning (PEFT) techniques to\ntabular tasks presents significant challenges, particularly in terms of better\ntable serialization and the representation of two-dimensional structured\ninformation within a one-dimensional sequence. To address this, we propose\nTableLoRA, a module designed to improve LLMs' understanding of table structure\nduring PEFT. It incorporates special tokens for serializing tables with special\ntoken encoder and uses 2D LoRA to encode low-rank information on cell\npositions. Experiments on four tabular-related datasets demonstrate that\nTableLoRA consistently outperforms vanilla LoRA and surpasses various table\nencoding methods tested in control experiments. These findings reveal that\nTableLoRA, as a table-specific LoRA, enhances the ability of LLMs to process\ntabular data effectively, especially in low-parameter settings, demonstrating\nits potential as a robust solution for handling table-related tasks.\n","authors":["Xinyi He","Yihao Liu","Mengyu Zhou","Yeye He","Haoyu Dong","Shi Han","Zejian Yuan","Dongmei Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.04396v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04395v1","updated":"2025-03-06T12:47:54Z","published":"2025-03-06T12:47:54Z","title":"Shaping Shared Languages: Human and Large Language Models' Inductive\n  Biases in Emergent Communication","summary":"  Languages are shaped by the inductive biases of their users. Using a\nclassical referential game, we investigate how artificial languages evolve when\noptimised for inductive biases in humans and large language models (LLMs) via\nHuman-Human, LLM-LLM and Human-LLM experiments. We show that referentially\ngrounded vocabularies emerge that enable reliable communication in all\nconditions, even when humans and LLMs collaborate. Comparisons between\nconditions reveal that languages optimised for LLMs subtly differ from those\noptimised for humans. Interestingly, interactions between humans and LLMs\nalleviate these differences and result in vocabularies which are more\nhuman-like than LLM-like. These findings advance our understanding of how\ninductive biases in LLMs play a role in the dynamic nature of human language\nand contribute to maintaining alignment in human and machine communication. In\nparticular, our work underscores the need to think of new methods that include\nhuman interaction in the training processes of LLMs, and shows that using\ncommunicative success as a reward signal can be a fruitful, novel direction.\n","authors":["Tom Kouwenhoven","Max Peeperkorn","Roy de Kleijn","Tessa Verhoef"],"pdf_url":"https://arxiv.org/pdf/2503.04395v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.21083v2","updated":"2025-03-06T12:38:42Z","published":"2024-10-28T14:48:05Z","title":"Stealthy Jailbreak Attacks on Large Language Models via Benign Data\n  Mirroring","summary":"  Large language model (LLM) safety is a critical issue, with numerous studies\nemploying red team testing to enhance model security. Among these, jailbreak\nmethods explore potential vulnerabilities by crafting malicious prompts that\ninduce model outputs contrary to safety alignments. Existing black-box\njailbreak methods often rely on model feedback, repeatedly submitting queries\nwith detectable malicious instructions during the attack search process.\nAlthough these approaches are effective, the attacks may be intercepted by\ncontent moderators during the search process. We propose an improved transfer\nattack method that guides malicious prompt construction by locally training a\nmirror model of the target black-box model through benign data distillation.\nThis method offers enhanced stealth, as it does not involve submitting\nidentifiable malicious instructions to the target model during the search\nphase. Our approach achieved a maximum attack success rate of 92%, or a\nbalanced value of 80% with an average of 1.5 detectable jailbreak queries per\nsample against GPT-3.5 Turbo on a subset of AdvBench. These results underscore\nthe need for more robust defense mechanisms.\n","authors":["Honglin Mu","Han He","Yuxin Zhou","Yunlong Feng","Yang Xu","Libo Qin","Xiaoming Shi","Zeming Liu","Xudong Han","Qi Shi","Qingfu Zhu","Wanxiang Che"],"pdf_url":"https://arxiv.org/pdf/2410.21083v2.pdf","comment":"Accepted by NAACL 2025"},{"id":"http://arxiv.org/abs/2503.04388v1","updated":"2025-03-06T12:38:17Z","published":"2025-03-06T12:38:17Z","title":"More Documents, Same Length: Isolating the Challenge of Multiple\n  Documents in RAG","summary":"  Retrieval-augmented generation (RAG) provides LLMs with relevant documents.\nAlthough previous studies noted that retrieving many documents can degrade\nperformance, they did not isolate how the quantity of documents affects\nperformance while controlling for context length. We evaluate various language\nmodels on custom datasets derived from a multi-hop QA task. We keep the context\nlength and position of relevant information constant while varying the number\nof documents, and find that increasing the document count in RAG settings poses\nsignificant challenges for LLMs. Additionally, our results indicate that\nprocessing multiple documents is a separate challenge from handling long\ncontexts. We also make the datasets and code available:\nhttps://github.com/shaharl6000/MoreDocsSameLen .\n","authors":["Shahar Levy","Nir Mazor","Lihi Shalmon","Michael Hassid","Gabriel Stanovsky"],"pdf_url":"https://arxiv.org/pdf/2503.04388v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2503.04381v1","updated":"2025-03-06T12:33:20Z","published":"2025-03-06T12:33:20Z","title":"TRACT: Regression-Aware Fine-tuning Meets Chain-of-Thought Reasoning for\n  LLM-as-a-Judge","summary":"  The LLM-as-a-judge paradigm uses large language models (LLMs) for automated\ntext evaluation, where a numerical assessment is assigned by an LLM to the\ninput text following scoring rubrics. Existing methods for LLM-as-a-judge use\ncross-entropy (CE) loss for fine-tuning, which neglects the numeric nature of\nscore prediction. Recent work addresses numerical prediction limitations of LLM\nfine-tuning through regression-aware fine-tuning, which, however, does not\nconsider chain-of-thought (CoT) reasoning for score prediction. In this paper,\nwe introduce TRACT (Two-stage Regression-Aware fine-tuning with CoT), a method\ncombining CoT reasoning with regression-aware training. TRACT consists of two\nstages: first, seed LLM is fine-tuned to generate CoTs, which serve as\nsupervision for the second stage fine-tuning. The training objective of TRACT\ncombines the CE loss for learning the CoT reasoning capabilities, and the\nregression-aware loss for the score prediction. Experiments across four\nLLM-as-a-judge datasets and two LLMs show that TRACT significantly outperforms\nexisting methods. Extensive ablation studies validate the importance of each\ncomponent in TRACT.\n","authors":["Cheng-Han Chiang","Hung-yi Lee","Michal Lukasik"],"pdf_url":"https://arxiv.org/pdf/2503.04381v1.pdf","comment":"Codes and models are available at https://github.com/d223302/TRACT"},{"id":"http://arxiv.org/abs/2503.04378v1","updated":"2025-03-06T12:30:24Z","published":"2025-03-06T12:30:24Z","title":"Dedicated Feedback and Edit Models Empower Inference-Time Scaling for\n  Open-Ended General-Domain Tasks","summary":"  Inference-Time Scaling has been critical to the success of recent models such\nas OpenAI o1 and DeepSeek R1. However, many techniques used to train models for\ninference-time scaling require tasks to have answers that can be verified,\nlimiting their application to domains such as math, coding and logical\nreasoning. We take inspiration from how humans make first attempts, ask for\ndetailed feedback from others and make improvements based on such feedback\nacross a wide spectrum of open-ended endeavors. To this end, we collect data\nfor and train dedicated Feedback and Edit Models that are capable of performing\ninference-time scaling for open-ended general-domain tasks. In our setup, one\nmodel generates an initial response, which are given feedback by a second\nmodel, that are then used by a third model to edit the response. We show that\nperformance on Arena Hard, a benchmark strongly predictive of Chatbot Arena Elo\ncan be boosted by scaling the number of initial response drafts, effective\nfeedback and edited responses. When scaled optimally, our setup based on 70B\nmodels from the Llama 3 family can reach SoTA performance on Arena Hard at 92.7\nas of 5 Mar 2025, surpassing OpenAI o1-preview-2024-09-12 with 90.4 and\nDeepSeek R1 with 92.3.\n","authors":["Zhilin Wang","Jiaqi Zeng","Olivier Delalleau","Daniel Egert","Ellie Evans","Hoo-Chang Shin","Felipe Soares","Yi Dong","Oleksii Kuchaiev"],"pdf_url":"https://arxiv.org/pdf/2503.04378v1.pdf","comment":"22 pages, 2 figures"},{"id":"http://arxiv.org/abs/2503.01346v2","updated":"2025-03-06T12:27:24Z","published":"2025-03-03T09:37:33Z","title":"SRAG: Structured Retrieval-Augmented Generation for Multi-Entity\n  Question Answering over Wikipedia Graph","summary":"  Multi-entity question answering (MEQA) poses significant challenges for large\nlanguage models (LLMs), which often struggle to consolidate scattered\ninformation across multiple documents. An example question might be \"What is\nthe distribution of IEEE Fellows among various fields of study?\", which\nrequires retrieving information from diverse sources e.g., Wikipedia pages. The\neffectiveness of current retrieval-augmented generation (RAG) methods is\nlimited by the LLMs' capacity to aggregate insights from numerous pages. To\naddress this gap, this paper introduces a structured RAG (SRAG) framework that\nsystematically organizes extracted entities into relational tables (e.g.,\ntabulating entities with schema columns like \"name\" and \"field of study\") and\nthen apply table-based reasoning techniques. Our approach decouples retrieval\nand reasoning, enabling LLMs to focus on structured data analysis rather than\nraw text aggregation. Extensive experiments on Wikipedia-based multi-entity QA\ntasks demonstrate that SRAG significantly outperforms state-of-the-art\nlong-context LLMs and RAG solutions, achieving a 29.6% improvement in accuracy.\nThe results underscore the efficacy of structuring unstructured data to enhance\nLLMs' reasoning capabilities.\n","authors":["Teng Lin","Yizhang Zhu","Yuyu Luo","Nan Tang"],"pdf_url":"https://arxiv.org/pdf/2503.01346v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04372v1","updated":"2025-03-06T12:16:14Z","published":"2025-03-06T12:16:14Z","title":"Assumed Identities: Quantifying Gender Bias in Machine Translation of\n  Ambiguous Occupational Terms","summary":"  Machine Translation (MT) systems frequently encounter ambiguous scenarios\nwhere they must assign gender to certain occupations when translating without\nexplicit guidance or contextual cues. While individual translations in such\ncases may not be inherently biased, systematic patterns-such as the repeated\nassociation of certain professions with specific genders-can emerge, reflecting\nand perpetuating societal stereotypes. This ambiguity challenges traditional\ninstance-level single-answer evaluation approaches, as no single gold standard\ntranslation exists. To address this, we propose an approach that evaluates\ngender bias through aggregated model responses. Specifically, we introduce a\nmethodology to detect gender imbalances between source texts and translations,\na benchmarking dataset with ambiguous English inputs, and probability-based\nmetrics to quantify a model's divergence from normative standards or reference\ndistributions.\n","authors":["Orfeas Menis Mastromichalakis","Giorgos Filandrianos","Maria Symeonaki","Giorgos Stamou"],"pdf_url":"https://arxiv.org/pdf/2503.04372v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04369v1","updated":"2025-03-06T12:14:45Z","published":"2025-03-06T12:14:45Z","title":"Lost in Literalism: How Supervised Training Shapes Translationese in\n  LLMs","summary":"  Large language models (LLMs) have achieved remarkable success in machine\ntranslation, demonstrating impressive performance across diverse languages.\nHowever, translationese, characterized by overly literal and unnatural\ntranslations, remains a persistent challenge in LLM-based translation systems.\nDespite their pre-training on vast corpora of natural utterances, LLMs exhibit\ntranslationese errors and generate unexpected unnatural translations, stemming\nfrom biases introduced during supervised fine-tuning (SFT). In this work, we\nsystematically evaluate the prevalence of translationese in LLM-generated\ntranslations and investigate its roots during supervised training. We introduce\nmethods to mitigate these biases, including polishing golden references and\nfiltering unnatural training instances. Empirical evaluations demonstrate that\nthese approaches significantly reduce translationese while improving\ntranslation naturalness, validated by human evaluations and automatic metrics.\nOur findings highlight the need for training-aware adjustments to optimize LLM\ntranslation outputs, paving the way for more fluent and\ntarget-language-consistent translations. We release the data and code at\nhttps://github.com/yafuly/LLM_Translationese.\n","authors":["Yafu Li","Ronghao Zhang","Zhilin Wang","Huajian Zhang","Leyang Cui","Yongjing Yin","Tong Xiao","Yue Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.04369v1.pdf","comment":"19 pages;"},{"id":"http://arxiv.org/abs/2410.01257v2","updated":"2025-03-06T12:13:14Z","published":"2024-10-02T06:05:52Z","title":"HelpSteer2-Preference: Complementing Ratings with Preferences","summary":"  Reward models are critical for aligning models to follow instructions, and\nare typically trained following one of two popular paradigms: Bradley-Terry\nstyle or Regression style. However, there is a lack of evidence that either\napproach is better than the other, when adequately matched for data. This is\nprimarily because these approaches require data collected in different (but\nincompatible) formats, meaning that adequately matched data is not available in\nexisting public datasets. To tackle this problem, we release preference\nannotations (designed for Bradley-Terry training) to complement existing\nratings (designed for Regression style training) in the HelpSteer2 dataset. To\nimprove data interpretability, preference annotations are accompanied with\nhuman-written justifications. Using this data, we conduct the first\nhead-to-head comparison of Bradley-Terry and Regression models when adequately\nmatched for data. Based on insights derived from such a comparison, we propose\na novel approach to combine Bradley-Terry and Regression reward modeling. A\nLlama-3.1-70B-Instruct model tuned with this approach scores 94.1 on\nRewardBench, emerging top of more than 140 reward models as of 1 Oct 2024. This\nreward model can then be used with REINFORCE algorithm (RLHF) to align an\nInstruct model to reach 85.0 on Arena Hard, which is No. 1 as of 1 Oct 2024. We\nopen-source this dataset (CC-BY-4.0 license) at\nhttps://huggingface.co/datasets/nvidia/HelpSteer2#preferences-new -- 1-oct-2024\nand openly release the trained Reward and Instruct models at\nhttps://huggingface.co/nvidia/Llama-3.1-Nemotron-70B-Reward and\nhttps://huggingface.co/nvidia/Llama-3.1-Nemotron-70B-Instruct\n","authors":["Zhilin Wang","Alexander Bukharin","Olivier Delalleau","Daniel Egert","Gerald Shen","Jiaqi Zeng","Oleksii Kuchaiev","Yi Dong"],"pdf_url":"https://arxiv.org/pdf/2410.01257v2.pdf","comment":"Accepted to ICLR 2025; 28 pages, 3 figures"},{"id":"http://arxiv.org/abs/2503.04360v1","updated":"2025-03-06T12:04:29Z","published":"2025-03-06T12:04:29Z","title":"Exploring the Multilingual NLG Evaluation Abilities of LLM-Based\n  Evaluators","summary":"  Previous research has shown that LLMs have potential in multilingual NLG\nevaluation tasks. However, existing research has not fully explored the\ndifferences in the evaluation capabilities of LLMs across different languages.\nTo this end, this study provides a comprehensive analysis of the multilingual\nevaluation performance of 10 recent LLMs, spanning high-resource and\nlow-resource languages through correlation analysis, perturbation attacks, and\nfine-tuning. We found that 1) excluding the reference answer from the prompt\nand using large-parameter LLM-based evaluators leads to better performance\nacross various languages; 2) most LLM-based evaluators show a higher\ncorrelation with human judgments in high-resource languages than in\nlow-resource languages; 3) in the languages where they are most sensitive to\nsuch attacks, they also tend to exhibit the highest correlation with human\njudgments; and 4) fine-tuning with data from a particular language yields a\nbroadly consistent enhancement in the model's evaluation performance across\ndiverse languages. Our findings highlight the imbalance in LLMs'evaluation\ncapabilities across different languages and suggest that low-resource language\nscenarios deserve more attention.\n","authors":["Jiayi Chang","Mingqi Gao","Xinyu Hu","Xiaojun Wan"],"pdf_url":"https://arxiv.org/pdf/2503.04360v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04355v1","updated":"2025-03-06T11:59:55Z","published":"2025-03-06T11:59:55Z","title":"Layer-Specific Scaling of Positional Encodings for Superior Long-Context\n  Modeling","summary":"  Although large language models (LLMs) have achieved significant progress in\nhandling long-context inputs, they still suffer from the ``lost-in-the-middle''\nproblem, where crucial information in the middle of the context is often\nunderrepresented or lost. Our extensive experiments reveal that this issue may\narise from the rapid long-term decay in Rotary Position Embedding (RoPE). To\naddress this problem, we propose a layer-specific positional encoding scaling\nmethod that assigns distinct scaling factors to each layer, slowing down the\ndecay rate caused by RoPE to make the model pay more attention to the middle\ncontext. A specially designed genetic algorithm is employed to efficiently\nselect the optimal scaling factors for each layer by incorporating Bezier\ncurves to reduce the search space. Through comprehensive experimentation, we\ndemonstrate that our method significantly alleviates the ``lost-in-the-middle''\nproblem. Our approach results in an average accuracy improvement of up to 20%\non the Key-Value Retrieval dataset. Furthermore, we show that layer-specific\ninterpolation, as opposed to uniform interpolation across all layers, enhances\nthe model's extrapolation capabilities when combined with PI and Dynamic-NTK\npositional encoding schemes.\n","authors":["Zhenghua Wang","Yiran Ding","Changze Lv","Zhibo Xu","Tianlong Li","Tianyuan Shi","Xiaoqing Zheng","Xuanjing Huang"],"pdf_url":"https://arxiv.org/pdf/2503.04355v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.03479v2","updated":"2025-03-06T11:46:49Z","published":"2025-01-07T02:47:59Z","title":"Women, Infamous, and Exotic Beings: What Honorific Usages in Wikipedia\n  Reveal about the Socio-Cultural Norms","summary":"  Honorifics serve as powerful linguistic markers that reflect social\nhierarchies and cultural values. This paper presents a large-scale,\ncross-linguistic exploration of usage of honorific pronouns in Bengali and\nHindi Wikipedia articles, shedding light on how socio-cultural factors shape\nlanguage. Using LLM (GPT-4o), we annotated 10, 000 articles of real and\nfictional beings in each language for several sociodemographic features such as\ngender, age, fame, and exoticness, and the use of honorifics. We find that\nacross all feature combinations, use of honorifics is consistently more common\nin Bengali than Hindi. For both languages, the use non-honorific pronouns is\nmore commonly observed for infamous, juvenile, and exotic beings. Notably, we\nobserve a gender bias in use of honorifics in Hindi, with men being more\ncommonly referred to with honorifics than women.\n","authors":["Sourabrata Mukherjee","Soumya Teotia","Sougata Saha","Monojit Choudhury"],"pdf_url":"https://arxiv.org/pdf/2501.03479v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.18640v2","updated":"2025-03-06T11:45:40Z","published":"2024-10-24T11:06:29Z","title":"Weak-to-Strong Preference Optimization: Stealing Reward from Weak\n  Aligned Model","summary":"  Aligning language models (LMs) with human preferences has become a key area\nof research, enabling these models to meet diverse user needs better. Inspired\nby weak-to-strong generalization, where a strong LM fine-tuned on labels\ngenerated by a weaker model can consistently outperform its weak supervisor, we\nextend this idea to model alignment. In this work, we observe that the\nalignment behavior in weaker models can be effectively transferred to stronger\nmodels and even exhibit an amplification effect. Based on this insight, we\npropose a method called Weak-to-Strong Preference Optimization (WSPO), which\nachieves strong model alignment by learning the distribution differences before\nand after the alignment of the weak model. Experiments demonstrate that WSPO\ndelivers outstanding performance, improving the win rate of Qwen2-7B-Instruct\non Arena-Hard from 39.70 to 49.60, achieving a remarkable 47.04\nlength-controlled win rate on AlpacaEval 2, and scoring 7.33 on MT-bench. Our\nresults suggest that using the weak model to elicit a strong model with a high\nalignment ability is feasible.\n","authors":["Wenhong Zhu","Zhiwei He","Xiaofeng Wang","Pengfei Liu","Rui Wang"],"pdf_url":"https://arxiv.org/pdf/2410.18640v2.pdf","comment":"ICLR 2025(Spotlight)"},{"id":"http://arxiv.org/abs/2503.04346v1","updated":"2025-03-06T11:42:03Z","published":"2025-03-06T11:42:03Z","title":"Adding Alignment Control to Language Models","summary":"  Post-training alignment has increasingly become a crucial factor in enhancing\nthe usability of language models (LMs). However, the strength of alignment\nvaries depending on individual preferences. This paper proposes a method to\nincorporate alignment control into a single model, referred to as CLM. This\napproach adds one identity layer preceding the initial layers and performs\npreference learning only on this layer to map unaligned input token embeddings\ninto the aligned space. Experimental results demonstrate that this efficient\nfine-tuning method performs comparable to full fine-tuning. During inference,\nthe input embeddings are processed through the aligned and unaligned layers,\nwhich are then merged through the interpolation coefficient. By controlling\nthis parameter, the alignment exhibits a clear interpolation and extrapolation\nphenomenon.\n","authors":["Wenhong Zhu","Weinan Zhang","Rui Wang"],"pdf_url":"https://arxiv.org/pdf/2503.04346v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04338v1","updated":"2025-03-06T11:34:49Z","published":"2025-03-06T11:34:49Z","title":"In-depth Analysis of Graph-based RAG in a Unified Framework","summary":"  Graph-based Retrieval-Augmented Generation (RAG) has proven effective in\nintegrating external knowledge into large language models (LLMs), improving\ntheir factual accuracy, adaptability, interpretability, and trustworthiness. A\nnumber of graph-based RAG methods have been proposed in the literature.\nHowever, these methods have not been systematically and comprehensively\ncompared under the same experimental settings. In this paper, we first\nsummarize a unified framework to incorporate all graph-based RAG methods from a\nhigh-level perspective. We then extensively compare representative graph-based\nRAG methods over a range of questing-answering (QA) datasets -- from specific\nquestions to abstract questions -- and examine the effectiveness of all\nmethods, providing a thorough analysis of graph-based RAG approaches. As a\nbyproduct of our experimental analysis, we are also able to identify new\nvariants of the graph-based RAG methods over specific QA and abstract QA tasks\nrespectively, by combining existing techniques, which outperform the\nstate-of-the-art methods. Finally, based on these findings, we offer promising\nresearch opportunities. We believe that a deeper understanding of the behavior\nof existing methods can provide new valuable insights for future research.\n","authors":["Yingli Zhou","Yaodong Su","Youran Sun","Shu Wang","Taotao Wang","Runyuan He","Yongwei Zhang","Sicong Liang","Xilin Liu","Yuchi Ma","Yixiang Fang"],"pdf_url":"https://arxiv.org/pdf/2503.04338v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04328v1","updated":"2025-03-06T11:27:55Z","published":"2025-03-06T11:27:55Z","title":"Solving Word-Sense Disambiguation and Word-Sense Induction with\n  Dictionary Examples","summary":"  Many less-resourced languages struggle with a lack of large, task-specific\ndatasets that are required for solving relevant tasks with modern\ntransformer-based large language models (LLMs). On the other hand, many\nlinguistic resources, such as dictionaries, are rarely used in this context\ndespite their large information contents. We show how LLMs can be used to\nextend existing language resources in less-resourced languages for two\nimportant tasks: word-sense disambiguation (WSD) and word-sense induction\n(WSI). We approach the two tasks through the related but much more accessible\nword-in-context (WiC) task where, given a pair of sentences and a target word,\na classification model is tasked with predicting whether the sense of a given\nword differs between sentences. We demonstrate that a well-trained model for\nthis task can distinguish between different word senses and can be adapted to\nsolve the WSD and WSI tasks. The advantage of using the WiC task, instead of\ndirectly predicting senses, is that the WiC task does not need pre-constructed\nsense inventories with a sufficient number of examples for each sense, which\nare rarely available in less-resourced languages. We show that sentence pairs\nfor the WiC task can be successfully generated from dictionary examples using\nLLMs. The resulting prediction models outperform existing models on WiC, WSD,\nand WSI tasks. We demonstrate our methodology on the Slovene language, where a\nmonolingual dictionary is available, but word-sense resources are tiny.\n","authors":["Tadej Škvorc","Marko Robnik-Šikonja"],"pdf_url":"https://arxiv.org/pdf/2503.04328v1.pdf","comment":"12 pages, 1 figure"},{"id":"http://arxiv.org/abs/2502.15109v2","updated":"2025-03-06T11:07:48Z","published":"2025-02-21T00:05:40Z","title":"Social Genome: Grounded Social Reasoning Abilities of Multimodal Models","summary":"  Social reasoning abilities are crucial for AI systems to effectively\ninterpret and respond to multimodal human communication and interaction within\nsocial contexts. We introduce Social Genome, the first benchmark for\nfine-grained, grounded social reasoning abilities of multimodal models. Social\nGenome contains 272 videos of interactions and 1,486 human-annotated reasoning\ntraces related to inferences about these interactions. These traces contain\n5,777 reasoning steps that reference evidence from visual cues, verbal cues,\nvocal cues, and external knowledge (contextual knowledge external to videos).\nSocial Genome is also the first modeling challenge to study external knowledge\nin social reasoning. Social Genome computes metrics to holistically evaluate\nsemantic and structural qualities of model-generated social reasoning traces.\nWe demonstrate the utility of Social Genome through experiments with\nstate-of-the-art models, identifying performance gaps and opportunities for\nfuture research to improve the grounded social reasoning abilities of\nmultimodal models.\n","authors":["Leena Mathur","Marian Qian","Paul Pu Liang","Louis-Philippe Morency"],"pdf_url":"https://arxiv.org/pdf/2502.15109v2.pdf","comment":"Under Review, 22 pages"},{"id":"http://arxiv.org/abs/2503.03417v2","updated":"2025-03-06T11:00:35Z","published":"2025-03-05T11:47:32Z","title":"When Claims Evolve: Evaluating and Enhancing the Robustness of Embedding\n  Models Against Misinformation Edits","summary":"  Online misinformation remains a critical challenge, and fact-checkers\nincreasingly rely on embedding-based methods to retrieve relevant fact-checks.\nYet, when debunked claims reappear in edited forms, the performance of these\nmethods is unclear. In this work, we introduce a taxonomy of six common\nreal-world misinformation edits and propose a perturbation framework that\ngenerates valid, natural claim variations. Our multi-stage retrieval evaluation\nreveals that standard embedding models struggle with user-introduced edits,\nwhile LLM-distilled embeddings offer improved robustness at a higher\ncomputational cost. Although a strong reranker helps mitigate some issues, it\ncannot fully compensate for first-stage retrieval gaps. Addressing these\nretrieval gaps, our train- and inference-time mitigation approaches enhance\nin-domain robustness by up to 17 percentage points and boost out-of-domain\ngeneralization by 10 percentage points over baseline models. Overall, our\nfindings provide practical improvements to claim-matching systems, enabling\nmore reliable fact-checking of evolving misinformation.\n","authors":["Jabez Magomere","Emanuele La Malfa","Manuel Tonneau","Ashkan Kazemi","Scott Hale"],"pdf_url":"https://arxiv.org/pdf/2503.03417v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04305v1","updated":"2025-03-06T10:46:15Z","published":"2025-03-06T10:46:15Z","title":"Computational Law: Datasets, Benchmarks, and Ontologies","summary":"  Recent developments in computer science and artificial intelligence have also\ncontributed to the legal domain, as revealed by the number and range of related\npublications and applications. Machine and deep learning models require\nconsiderable amount of domain-specific data for training and comparison\npurposes, in order to attain high-performance in the legal domain.\nAdditionally, semantic resources such as ontologies are valuable for building\nlarge-scale computational legal systems, in addition to ensuring\ninteroperability of such systems. Considering these aspects, we present an\nup-to-date review of the literature on datasets, benchmarks, and ontologies\nproposed for computational law. We believe that this comprehensive and recent\nreview will help researchers and practitioners when developing and testing\napproaches and systems for computational law.\n","authors":["Dilek Küçük","Fazli Can"],"pdf_url":"https://arxiv.org/pdf/2503.04305v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.01924v2","updated":"2025-03-06T10:39:48Z","published":"2024-05-03T08:34:13Z","title":"Semi-Parametric Retrieval via Binary Bag-of-Tokens Index","summary":"  Information retrieval has transitioned from standalone systems into essential\ncomponents across broader applications, with indexing efficiency,\ncost-effectiveness, and freshness becoming increasingly critical yet often\noverlooked. In this paper, we introduce SemI-parametric Disentangled Retrieval\n(SiDR), a bi-encoder retrieval framework that decouples retrieval index from\nneural parameters to enable efficient, low-cost, and parameter-agnostic\nindexing for emerging use cases. Specifically, in addition to using embeddings\nas indexes like existing neural retrieval methods, SiDR supports a\nnon-parametric tokenization index for search, achieving BM25-like indexing\ncomplexity with significantly better effectiveness. Our comprehensive\nevaluation across 16 retrieval benchmarks demonstrates that SiDR outperforms\nboth neural and term-based retrieval baselines under the same indexing\nworkload: (i) When using an embedding-based index, SiDR exceeds the performance\nof conventional neural retrievers while maintaining similar training\ncomplexity; (ii) When using a tokenization-based index, SiDR drastically\nreduces indexing cost and time, matching the complexity of traditional\nterm-based retrieval, while consistently outperforming BM25 on all in-domain\ndatasets; (iii) Additionally, we introduce a late parametric mechanism that\nmatches BM25 index preparation time while outperforming other neural retrieval\nbaselines in effectiveness.\n","authors":["Jiawei Zhou","Li Dong","Furu Wei","Lei Chen"],"pdf_url":"https://arxiv.org/pdf/2405.01924v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04279v1","updated":"2025-03-06T10:07:51Z","published":"2025-03-06T10:07:51Z","title":"Dual-Class Prompt Generation: Enhancing Indonesian Gender-Based Hate\n  Speech Detection through Data Augmentation","summary":"  Detecting gender-based hate speech in Indonesian social media remains\nchallenging due to limited labeled datasets. While binary hate speech\nclassification has advanced, a more granular category like gender-targeted hate\nspeech is understudied because of class imbalance issues. This paper addresses\nthis gap by comparing three data augmentation techniques for Indonesian\ngender-based hate speech detection. We evaluate backtranslation, single-class\nprompt generation (using only hate speech examples), and our proposed\ndual-class prompt generation (using both hate speech and non-hate speech\nexamples). Experiments show all augmentation methods improve classification\nperformance, with our dual-class approach achieving the best results (88.5%\naccuracy, 88.1% F1-score using Random Forest). Semantic similarity analysis\nreveals dual-class prompt generation produces the most novel content, while\nT-SNE visualizations confirm these samples occupy distinct feature space\nregions while maintaining class characteristics. Our findings suggest that\nincorporating examples from both classes helps language models generate more\ndiverse yet representative samples, effectively addressing limited data\nchallenges in specialized hate speech detection.\n","authors":["Muhammad Amien Ibrahim"," Faisal","Tora Sangputra Yopie Winarto","Zefanya Delvin Sulistiya"],"pdf_url":"https://arxiv.org/pdf/2503.04279v1.pdf","comment":"Accepted to the 8th World Conference on Computing and Communication\n  Technologies (WCCCT 2025)"},{"id":"http://arxiv.org/abs/2503.04271v1","updated":"2025-03-06T10:02:25Z","published":"2025-03-06T10:02:25Z","title":"On Fact and Frequency: LLM Responses to Misinformation Expressed with\n  Uncertainty","summary":"  We study LLM judgments of misinformation expressed with uncertainty. Our\nexperiments study the response of three widely used LLMs (GPT-4o, LlaMA3,\nDeepSeek-v2) to misinformation propositions that have been verified false and\nthen are transformed into uncertain statements according to an uncertainty\ntypology. Our results show that after transformation, LLMs change their\nfactchecking classification from false to not-false in 25% of the cases.\nAnalysis reveals that the change cannot be explained by predictors to which\nhumans are expected to be sensitive, i.e., modality, linguistic cues, or\nargumentation strategy. The exception is doxastic transformations, which use\nlinguistic cue phrases such as \"It is believed ...\".To gain further insight, we\nprompt the LLM to make another judgment about the transformed misinformation\nstatements that is not related to truth value. Specifically, we study LLM\nestimates of the frequency with which people make the uncertain statement. We\nfind a small but significant correlation between judgment of fact and\nestimation of frequency.\n","authors":["Yana van de Sande","Gunes Açar","Thabo van Woudenberg","Martha Larson"],"pdf_url":"https://arxiv.org/pdf/2503.04271v1.pdf","comment":"4 pages, 1 figure, 3 tables, conference"},{"id":"http://arxiv.org/abs/2503.04240v1","updated":"2025-03-06T09:21:54Z","published":"2025-03-06T09:21:54Z","title":"DiffPO: Diffusion-styled Preference Optimization for Efficient\n  Inference-Time Alignment of Large Language Models","summary":"  Inference-time alignment provides an efficient alternative for aligning LLMs\nwith humans. However, these approaches still face challenges, such as limited\nscalability due to policy-specific value functions and latency during the\ninference phase. In this paper, we propose a novel approach, Diffusion-styled\nPreference Optimization (\\model), which provides an efficient and\npolicy-agnostic solution for aligning LLMs with humans. By directly performing\nalignment at sentence level, \\model~avoids the time latency associated with\ntoken-level generation. Designed as a plug-and-play module, \\model~can be\nseamlessly integrated with various base models to enhance their alignment.\nExtensive experiments on AlpacaEval 2, MT-bench, and HH-RLHF demonstrate that\n\\model~achieves superior alignment performance across various settings,\nachieving a favorable trade-off between alignment quality and inference-time\nlatency. Furthermore, \\model~demonstrates model-agnostic scalability,\nsignificantly improving the performance of large models such as Llama-3-70B.\n","authors":["Ruizhe Chen","Wenhao Chai","Zhifei Yang","Xiaotian Zhang","Joey Tianyi Zhou","Tony Quek","Soujanya Poria","Zuozhu Liu"],"pdf_url":"https://arxiv.org/pdf/2503.04240v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04232v1","updated":"2025-03-06T09:14:02Z","published":"2025-03-06T09:14:02Z","title":"Tgea: An error-annotated dataset and benchmark tasks for text generation\n  from pretrained language models","summary":"  In order to deeply understand the capability of pretrained language models in\ntext generation and conduct a diagnostic evaluation, we propose TGEA, an\nerror-annotated dataset with multiple benchmark tasks for text generation from\npretrained language models (PLMs). We use carefully selected prompt words to\nguide GPT-2 to generate candidate sentences, from which we select 47K for error\nannotation. Crowdsourced workers manually check each of these sentences and\ndetect 12k erroneous sentences. We create an error taxonomy to cover 24 types\nof errors occurring in these erroneous sentences according to the nature of\nerrors with respect to linguistics and knowledge (eg, common sense). For each\nerroneous span in PLM-generated sentences, we also detect another span that is\nclosely associated with it. Each error is hence manually labeled with\ncomprehensive annotations, including the span of the error, the associated\nspan, minimal correction to the error, the type of the error, and rationale\nbehind the error. Apart from the fully annotated dataset, we also present a\ndetailed description of the data collection procedure, statistics and analysis\nof the dataset. This is the first dataset with comprehensive annotations for\nPLM-generated texts, which facilitates the diagnostic evaluation of PLM-based\ntext generation. Furthermore, we use TGEA as a benchmark dataset and propose a\nseries of automatic diagnosis tasks, including error detection, error type\nclassification, associated span detection, error rationale generation, to\nfurther promote future study on the automatic error detection and correction on\ntexts generated by pretrained language models.\n","authors":["Jie He","Bo Peng","Yi Liao","Qun Liu","Deyi Xiong"],"pdf_url":"https://arxiv.org/pdf/2503.04232v1.pdf","comment":"ACL 2021"},{"id":"http://arxiv.org/abs/2503.04222v1","updated":"2025-03-06T09:03:36Z","published":"2025-03-06T09:03:36Z","title":"FuseChat-3.0: Preference Optimization Meets Heterogeneous Model Fusion","summary":"  We introduce FuseChat-3.0, a suite of large language models (LLMs) developed\nby integrating the strengths of heterogeneous source LLMs into more compact\ntarget LLMs. Our source models include the powerful Gemma-2-27B-it,\nMistral-Large-Instruct-2407, Qwen-2.5-72B-Instruct, and Llama-3.1-70B-Instruct.\nFor target models, we focus on three widely-used smaller\nvariants-Llama-3.1-8B-Instruct, Gemma-2-9B-it, and Qwen-2.5-7B-Instruct-along\nwith two ultra-compact options, Llama-3.2-3B-Instruct and\nLlama-3.2-1B-Instruct. To leverage the diverse capabilities of these source\nmodels, we develop a specialized data construction protocol tailored to various\ntasks and domains. The FuseChat-3.0 training pipeline consists of two key\nstages: (1) supervised fine-tuning (SFT) to align the target and source model\ndistributions, and (2) Direct Preference Optimization (DPO) to apply\npreferences from multiple source LLMs to fine-tune the target model. The\nresulting FuseChat-3.0 models exhibit significant performance gains across\ntasks such as instruction following, general knowledge, mathematics, and\ncoding. As illustrated in Figure 1, using Llama-3.1-8B-Instruct as the target\nmodel, our fusion approach achieves an average improvement of 6.8 points across\n14 benchmarks. Moreover, it demonstrates remarkable gains of 37.1 points and\n30.1 points on the instruction-following benchmarks AlpacaEval-2 and\nArena-Hard, respectively. Our code, models, and datasets are available at\nhttps://github.com/SLIT-AI/FuseChat-3.0.\n","authors":["Ziyi Yang","Fanqi Wan","Longguang Zhong","Canbin Huang","Guosheng Liang","Xiaojun Quan"],"pdf_url":"https://arxiv.org/pdf/2503.04222v1.pdf","comment":"Technical report"},{"id":"http://arxiv.org/abs/2408.14153v3","updated":"2025-03-06T09:00:18Z","published":"2024-08-26T09:55:34Z","title":"Explaining Caption-Image Interactions in CLIP models with Second-Order\n  Attributions","summary":"  Dual encoder architectures like CLIP models map two types of inputs into a\nshared embedding space and predict similarities between them. Despite their\nsuccess, it is, however, not understood how these models compare their two\ninputs. Common first-order feature-attribution methods can only provide limited\ninsights into dual-encoders since their predictions depend on\nfeature-interactions rather than on individual features. In this paper, we\nfirst derive a second-order method enabling the attribution of predictions by\nany differentiable dual encoder onto feature-interactions between its inputs.\nSecond, we apply our method to CLIP models and show that they learn\nfine-grained correspondences between parts of captions and regions in images.\nThey match objects across input modes also account for mismatches. This\nvisual-linguistic grounding ability, however, varies heavily between object\nclasses and exhibits pronounced out-of-domain effects. We can identify\nindividual errors as well as systematic failure categories including object\ncoverage, unusual scenes and correlated contexts.\n","authors":["Lucas Möller","Pascal Tilli","Ngoc Thang Vu","Sebastian Padó"],"pdf_url":"https://arxiv.org/pdf/2408.14153v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02495v2","updated":"2025-03-06T08:51:47Z","published":"2025-03-04T11:01:25Z","title":"Union of Experts: Adapting Hierarchical Routing to Equivalently\n  Decomposed Transformer","summary":"  We propose Union-of-Experts (UoE), which decomposes transformer into an\nequitant group of experts, and then implement selective routing on input data\nand experts. Our approach advances MoE design with four key innovations: (1) We\nconducted equitant expert decomposition on both MLP blocks and attention blocks\nbased on matrix partition in tensor parallelism. (2) We developed two routing\nparadigms: patch-wise data selection and expert selection, to apply routing\nacross different levels. (3) We design the architecture of UoE model, including\nSelective Multi-Head Attention (SMHA) and Union-of-MLP-Experts (UoME). (4) We\ndevelop parallel implementation of UoE's routing and computation operation, and\noptimize efficiency based on the hardware processing analysis. The experiments\ndemonstrate that the UoE model surpass Full Attention, state-of-art MoEs and\nefficient transformers (including the model architecture of recently proposed\nDeepSeek-V3) in several tasks across image and natural language domains. In\nlanguage modeling tasks, we achieve an average reduction of 2.38 in perplexity\ncompared to the best-performed MoE method with an average of 76% FLOPs. In Long\nRange Arena benchmark, we recorded an average score that is at least 0.68%\nhigher than all comparison models including Full Attention, MoEs, and\ntransformer variants, with only 50% FLOPs of the best MoE method. In image\nclassification, our model yielded an average accuracy improvement of 1.75% than\nthe best model while maintaining comparable FLOPs. The source codes are\navailable at https://github.com/YujiaoYang-work/UoE.\n","authors":["Yujiao Yang","Jing Lian","Linhui Li"],"pdf_url":"https://arxiv.org/pdf/2503.02495v2.pdf","comment":"17 pages"},{"id":"http://arxiv.org/abs/2410.07009v2","updated":"2025-03-06T08:51:05Z","published":"2024-10-09T15:52:48Z","title":"Pap2Pat: Benchmarking Outline-Guided Long-Text Patent Generation with\n  Patent-Paper Pairs","summary":"  Dealing with long and highly complex technical text is a challenge for Large\nLanguage Models (LLMs), which still have to unfold their potential in\nsupporting expensive and timeintensive processes like patent drafting. Within\npatents, the description constitutes more than 90% of the document on average.\nYet, its automatic generation remains understudied. When drafting patent\napplications, patent attorneys typically receive invention reports (IRs), which\nare usually confidential, hindering research on LLM-supported patent drafting.\nOften, prepublication research papers serve as IRs. We leverage this duality to\nbuild PAP2PAT, an open and realistic benchmark for patent drafting consisting\nof 1.8k patent-paper pairs describing the same inventions. To address the\ncomplex longdocument patent generation task, we propose chunk-based\noutline-guided generation using the research paper as invention specification.\nOur extensive evaluation using PAP2PAT and a human case study show that LLMs\ncan effectively leverage information from the paper, but still struggle to\nprovide the necessary level of detail. Fine-tuning leads to more patent-style\nlanguage, but also to more hallucination. We release our data and code\nhttps://github.com/boschresearch/Pap2Pat.\n","authors":["Valentin Knappich","Simon Razniewski","Anna Hätty","Annemarie Friedrich"],"pdf_url":"https://arxiv.org/pdf/2410.07009v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04201v1","updated":"2025-03-06T08:28:44Z","published":"2025-03-06T08:28:44Z","title":"Knowledge-Decoupled Synergetic Learning: An MLLM based Collaborative\n  Approach to Few-shot Multimodal Dialogue Intention Recognition","summary":"  Few-shot multimodal dialogue intention recognition is a critical challenge in\nthe e-commerce domainn. Previous methods have primarily enhanced model\nclassification capabilities through post-training techniques. However, our\nanalysis reveals that training for few-shot multimodal dialogue intention\nrecognition involves two interconnected tasks, leading to a seesaw effect in\nmulti-task learning. This phenomenon is attributed to knowledge interference\nstemming from the superposition of weight matrix updates during the training\nprocess. To address these challenges, we propose Knowledge-Decoupled Synergetic\nLearning (KDSL), which mitigates these issues by utilizing smaller models to\ntransform knowledge into interpretable rules, while applying the post-training\nof larger models. By facilitating collaboration between the large and small\nmultimodal large language models for prediction, our approach demonstrates\nsignificant improvements. Notably, we achieve outstanding results on two real\nTaobao datasets, with enhancements of 6.37\\% and 6.28\\% in online weighted F1\nscores compared to the state-of-the-art method, thereby validating the efficacy\nof our framework.\n","authors":["Bin Chen","Yu Zhang","Hongfei Ye","Ziyi Huang","Hongyang Chen"],"pdf_url":"https://arxiv.org/pdf/2503.04201v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.12106v3","updated":"2025-03-06T08:18:50Z","published":"2024-09-18T16:26:22Z","title":"Measuring Human and AI Values Based on Generative Psychometrics with\n  Large Language Models","summary":"  Human values and their measurement are long-standing interdisciplinary\ninquiry. Recent advances in AI have sparked renewed interest in this area, with\nlarge language models (LLMs) emerging as both tools and subjects of value\nmeasurement. This work introduces Generative Psychometrics for Values (GPV), an\nLLM-based, data-driven value measurement paradigm, theoretically grounded in\ntext-revealed selective perceptions. The core idea is to dynamically parse\nunstructured texts into perceptions akin to static stimuli in traditional\npsychometrics, measure the value orientations they reveal, and aggregate the\nresults. Applying GPV to human-authored blogs, we demonstrate its stability,\nvalidity, and superiority over prior psychological tools. Then, extending GPV\nto LLM value measurement, we advance the current art with 1) a psychometric\nmethodology that measures LLM values based on their scalable and free-form\noutputs, enabling context-specific measurement; 2) a comparative analysis of\nmeasurement paradigms, indicating response biases of prior methods; and 3) an\nattempt to bridge LLM values and their safety, revealing the predictive power\nof different value systems and the impacts of various values on LLM safety.\nThrough interdisciplinary efforts, we aim to leverage AI for next-generation\npsychometrics and psychometrics for value-aligned AI.\n","authors":["Haoran Ye","Yuhang Xie","Yuanyi Ren","Hanjun Fang","Xin Zhang","Guojie Song"],"pdf_url":"https://arxiv.org/pdf/2409.12106v3.pdf","comment":"Accepted at AAAI 2025"},{"id":"http://arxiv.org/abs/2503.04188v1","updated":"2025-03-06T08:03:51Z","published":"2025-03-06T08:03:51Z","title":"Measuring temporal effects of agent knowledge by date-controlled tool\n  use","summary":"  Temporal progression is an integral part of knowledge accumulation and\nupdate. Web search is frequently adopted as grounding for agent knowledge, yet\nits inappropriate configuration affects the quality of agent responses. Here,\nwe construct a tool-based out-of-sample testing framework to measure the\nknowledge variability of large language model (LLM) agents from distinct\ndate-controlled tools (DCTs). We demonstrate the temporal effects of an LLM\nagent as a writing assistant, which can use web search to help complete\nscientific publication abstracts. We show that temporal effects of the search\nengine translates into tool-dependent agent performance but can be alleviated\nwith base model choice and explicit reasoning instructions such as\nchain-of-thought prompting. Our results indicate that agent evaluation should\ntake a dynamical view and account for the temporal influence of tools and the\nupdates of external resources.\n","authors":["R. Patrick Xian","Qiming Cui","Stefan Bauer","Reza Abbasi-Asl"],"pdf_url":"https://arxiv.org/pdf/2503.04188v1.pdf","comment":"comments welcome"},{"id":"http://arxiv.org/abs/2503.04184v1","updated":"2025-03-06T07:53:24Z","published":"2025-03-06T07:53:24Z","title":"Large-Scale AI in Telecom: Charting the Roadmap for Innovation,\n  Scalability, and Enhanced Digital Experiences","summary":"  This white paper discusses the role of large-scale AI in the\ntelecommunications industry, with a specific focus on the potential of\ngenerative AI to revolutionize network functions and user experiences,\nespecially in the context of 6G systems. It highlights the development and\ndeployment of Large Telecom Models (LTMs), which are tailored AI models\ndesigned to address the complex challenges faced by modern telecom networks.\nThe paper covers a wide range of topics, from the architecture and deployment\nstrategies of LTMs to their applications in network management, resource\nallocation, and optimization. It also explores the regulatory, ethical, and\nstandardization considerations for LTMs, offering insights into their future\nintegration into telecom infrastructure. The goal is to provide a comprehensive\nroadmap for the adoption of LTMs to enhance scalability, performance, and\nuser-centric innovation in telecom networks.\n","authors":["Adnan Shahid","Adrian Kliks","Ahmed Al-Tahmeesschi","Ahmed Elbakary","Alexandros Nikou","Ali Maatouk","Ali Mokh","Amirreza Kazemi","Antonio De Domenico","Athanasios Karapantelakis","Bo Cheng","Bo Yang","Bohao Wang","Carlo Fischione","Chao Zhang","Chaouki Ben Issaid","Chau Yuen","Chenghui Peng","Chongwen Huang","Christina Chaccour","Christo Kurisummoottil Thomas","Dheeraj Sharma","Dimitris Kalogiros","Dusit Niyato","Eli De Poorter","Elissa Mhanna","Emilio Calvanese Strinati","Faouzi Bader","Fathi Abdeldayem","Fei Wang","Fenghao Zhu","Gianluca Fontanesi","Giovanni Geraci","Haibo Zhou","Hakimeh Purmehdi","Hamed Ahmadi","Hang Zou","Hongyang Du","Hoon Lee","Howard H. Yang","Iacopo Poli","Igor Carron","Ilias Chatzistefanidis","Inkyu Lee","Ioannis Pitsiorlas","Jaron Fontaine","Jiajun Wu","Jie Zeng","Jinan Li","Jinane Karam","Johny Gemayel","Juan Deng","Julien Frison","Kaibin Huang","Kehai Qiu","Keith Ball","Kezhi Wang","Kun Guo","Leandros Tassiulas","Lecorve Gwenole","Liexiang Yue","Lina Bariah","Louis Powell","Marcin Dryjanski","Maria Amparo Canaveras Galdon","Marios Kountouris","Maryam Hafeez","Maxime Elkael","Mehdi Bennis","Mehdi Boudjelli","Meiling Dai","Merouane Debbah","Michele Polese","Mohamad Assaad","Mohamed Benzaghta","Mohammad Al Refai","Moussab Djerrab","Mubeen Syed","Muhammad Amir","Na Yan","Najla Alkaabi","Nan Li","Nassim Sehad","Navid Nikaein","Omar Hashash","Pawel Sroka","Qianqian Yang","Qiyang Zhao","Rasoul Nikbakht Silab","Rex Ying","Roberto Morabito","Rongpeng Li","Ryad Madi","Salah Eddine El Ayoubi","Salvatore D'Oro","Samson Lasaulce","Serveh Shalmashi","Sige Liu","Sihem Cherrared","Swarna Bindu Chetty","Swastika Dutta","Syed A. R. Zaidi","Tianjiao Chen","Timothy Murphy","Tommaso Melodia","Tony Q. S. Quek","Vishnu Ram","Walid Saad","Wassim Hamidouche","Weilong Chen","Xiaoou Liu","Xiaoxue Yu","Xijun Wang","Xingyu Shang","Xinquan Wang","Xuelin Cao","Yang Su","Yanping Liang","Yansha Deng","Yifan Yang","Yingping Cui","Yu Sun","Yuxuan Chen","Yvan Pointurier","Zeinab Nehme","Zeinab Nezami","Zhaohui Yang","Zhaoyang Zhang","Zhe Liu","Zhenyu Yang","Zhu Han","Zhuang Zhou","Zihan Chen","Zirui Chen","Zitao Shuai"],"pdf_url":"https://arxiv.org/pdf/2503.04184v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04176v1","updated":"2025-03-06T07:44:17Z","published":"2025-03-06T07:44:17Z","title":"TIMER: Temporal Instruction Modeling and Evaluation for Longitudinal\n  Clinical Records","summary":"  Large language models (LLMs) have emerged as promising tools for assisting in\nmedical tasks, yet processing Electronic Health Records (EHRs) presents unique\nchallenges due to their longitudinal nature. While LLMs' capabilities to\nperform medical tasks continue to improve, their ability to reason over\ntemporal dependencies across multiple patient visits and time frames remains\nunexplored. We introduce TIMER (Temporal Instruction Modeling and Evaluation\nfor Longitudinal Clinical Records), a framework that incorporate\ninstruction-response pairs grounding to different parts of a patient's record\nas a critical dimension in both instruction evaluation and tuning for\nlongitudinal clinical records. We develop TIMER-Bench, the first time-aware\nbenchmark that evaluates temporal reasoning capabilities over longitudinal\nEHRs, as well as TIMER-Instruct, an instruction-tuning methodology for LLMs to\nlearn reasoning over time. We demonstrate that models fine-tuned with\nTIMER-Instruct improve performance by 7.3% on human-generated benchmarks and\n9.2% on TIMER-Bench, indicating that temporal instruction-tuning improves model\nperformance for reasoning over EHR.\n","authors":["Hejie Cui","Alyssa Unell","Bowen Chen","Jason Alan Fries","Emily Alsentzer","Sanmi Koyejo","Nigam Shah"],"pdf_url":"https://arxiv.org/pdf/2503.04176v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2405.02318v3","updated":"2025-03-06T07:29:44Z","published":"2024-04-18T00:20:48Z","title":"Autoformalizing Natural Language to First-Order Logic: A Case Study in\n  Logical Fallacy Detection","summary":"  Translating natural language into formal language such as First-Order Logic\n(FOL) is a foundational challenge in NLP with wide-ranging applications in\nautomated reasoning, misinformation tracking, and knowledge validation. In this\npaper, we introduce Natural Language to First-Order Logic (NL2FOL), a framework\nto autoformalize natural language to FOL step by step using Large Language\nModels (LLMs). Our approach addresses key challenges in this translation\nprocess, including the integration of implicit background knowledge. By\nleveraging structured representations generated by NL2FOL, we use\nSatisfiability Modulo Theory (SMT) solvers to reason about the logical validity\nof natural language statements. We present logical fallacy detection as a case\nstudy to evaluate the efficacy of NL2FOL. Being neurosymbolic, our approach\nalso provides interpretable insights into the reasoning process and\ndemonstrates robustness without requiring model fine-tuning or labeled training\ndata. Our framework achieves strong performance on multiple datasets. On the\nLOGIC dataset, NL2FOL achieves an F1-score of 78%, while generalizing\neffectively to the LOGICCLIMATE dataset with an F1-score of 80%.\n","authors":["Abhinav Lalwani","Tasha Kim","Lovish Chopra","Christopher Hahn","Zhijing Jin","Mrinmaya Sachan"],"pdf_url":"https://arxiv.org/pdf/2405.02318v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.13681v2","updated":"2025-03-06T07:17:09Z","published":"2025-02-19T12:51:35Z","title":"An LLM-based Agent for Reliable Docker Environment Configuration","summary":"  Environment configuration is a critical yet time-consuming step in software\ndevelopment, especially when dealing with unfamiliar code repositories. While\nLarge Language Models (LLMs) demonstrate the potential to accomplish software\nengineering tasks, existing methods for environment configuration often rely on\nmanual efforts or fragile scripts, leading to inefficiencies and unreliable\noutcomes. We introduce Repo2Run, the first LLM-based agent designed to fully\nautomate environment configuration and generate executable Dockerfiles for\narbitrary Python repositories. We address two major challenges: (1) enabling\nthe LLM agent to configure environments within isolated Docker containers, and\n(2) ensuring the successful configuration process is recorded and accurately\ntransferred to a Dockerfile without error. To achieve this, we propose atomic\nconfiguration synthesis, featuring a dual-environment architecture (internal\nand external environment) with a rollback mechanism to prevent environment\n\"pollution\" from failed commands, guaranteeing atomic execution (execute fully\nor not at all) and a Dockerfile generator to transfer successful configuration\nsteps into runnable Dockerfiles. We evaluate Repo2Run~on our proposed benchmark\nof 420 recent Python repositories with unit tests, where it achieves an 86.0%\nsuccess rate, outperforming the best baseline by 63.9%. Repo2Run is available\nat https://github.com/bytedance/Repo2Run.\n","authors":["Ruida Hu","Chao Peng","Xinchen Wang","Cuiyun Gao"],"pdf_url":"https://arxiv.org/pdf/2502.13681v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04155v1","updated":"2025-03-06T07:06:46Z","published":"2025-03-06T07:06:46Z","title":"BPQA Dataset: Evaluating How Well Language Models Leverage Blood\n  Pressures to Answer Biomedical Questions","summary":"  Clinical measurements such as blood pressures and respiration rates are\ncritical in diagnosing and monitoring patient outcomes. It is an important\ncomponent of biomedical data, which can be used to train transformer-based\nlanguage models (LMs) for improving healthcare delivery. It is, however,\nunclear whether LMs can effectively interpret and use clinical measurements. We\ninvestigate two questions: First, can LMs effectively leverage clinical\nmeasurements to answer related medical questions? Second, how to enhance an\nLM's performance on medical question-answering (QA) tasks that involve\nmeasurements? We performed a case study on blood pressure readings (BPs), a\nvital sign routinely monitored by medical professionals. We evaluated the\nperformance of four LMs: BERT, BioBERT, MedAlpaca, and GPT-3.5, on our newly\ndeveloped dataset, BPQA (Blood Pressure Question Answering). BPQA contains\n$100$ medical QA pairs that were verified by medical students and designed to\nrely on BPs . We found that GPT-3.5 and MedAlpaca (larger and medium sized LMs)\nbenefit more from the inclusion of BPs than BERT and BioBERT (small sized LMs).\nFurther, augmenting measurements with labels improves the performance of\nBioBERT and Medalpaca (domain specific LMs), suggesting that retrieval may be\nuseful for improving domain-specific LMs.\n","authors":["Chi Hang","Ruiqi Deng","Lavender Yao Jiang","Zihao Yang","Anton Alyakin","Daniel Alber","Eric Karl Oermann"],"pdf_url":"https://arxiv.org/pdf/2503.04155v1.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2502.18878v2","updated":"2025-03-06T07:06:40Z","published":"2025-02-26T06:45:29Z","title":"Learning to Generate Structured Output with Schema Reinforcement\n  Learning","summary":"  This study investigates the structured generation capabilities of large\nlanguage models (LLMs), focusing on producing valid JSON outputs against a\ngiven schema. Despite the widespread use of JSON in integrating language models\nwith programs, there is a lack of comprehensive analysis and benchmarking of\nthese capabilities. We explore various aspects of JSON generation, such as\nstructure understanding, escaping, and natural language description, to\ndetermine how to assess and enable LLMs to generate valid responses. Building\nupon this, we propose SchemaBench features around 40K different JSON schemas to\nobtain and assess models' abilities in generating valid JSON. We find that the\nlatest LLMs are still struggling to generate a valid JSON string. Moreover, we\ndemonstrate that incorporating reinforcement learning with a Fine-grained\nSchema Validator can further enhance models' understanding of JSON schema,\nleading to improved performance. Our models demonstrate significant improvement\nin both generating JSON outputs and downstream tasks.\n","authors":["Yaxi Lu","Haolun Li","Xin Cong","Zhong Zhang","Yesai Wu","Yankai Lin","Zhiyuan Liu","Fangming Liu","Maosong Sun"],"pdf_url":"https://arxiv.org/pdf/2502.18878v2.pdf","comment":"8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2503.04150v1","updated":"2025-03-06T06:59:09Z","published":"2025-03-06T06:59:09Z","title":"Ticktack : Long Span Temporal Alignment of Large Language Models\n  Leveraging Sexagenary Cycle Time Expression","summary":"  Large language models (LLMs) suffer from temporal misalignment issues\nespecially across long span of time. The issue arises from knowing that LLMs\nare trained on large amounts of data where temporal information is rather\nsparse over long times, such as thousands of years, resulting in insufficient\nlearning or catastrophic forgetting by the LLMs. This paper proposes a\nmethodology named \"Ticktack\" for addressing the LLM's long-time span\nmisalignment in a yearly setting. Specifically, we first propose to utilize the\nsexagenary year expression instead of the Gregorian year expression employed by\nLLMs, achieving a more uniform distribution in yearly granularity. Then, we\nemploy polar coordinates to model the sexagenary cycle of 60 terms and the year\norder within each term, with additional temporal encoding to ensure LLMs\nunderstand them. Finally, we present a temporal representational alignment\napproach for post-training LLMs that effectively distinguishes time points with\nrelevant knowledge, hence improving performance on time-related tasks,\nparticularly over a long period. We also create a long time span benchmark for\nevaluation. Experimental results prove the effectiveness of our proposal.\n","authors":["Xue Han","Qian Hu","Yitong Wang","Wenchun Gao","Lianlian Zhang","Qing Wang","Lijun Mei","Chao Deng","Junlan Feng"],"pdf_url":"https://arxiv.org/pdf/2503.04150v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06464v3","updated":"2025-03-06T06:57:34Z","published":"2024-12-09T13:09:04Z","title":"Gated Delta Networks: Improving Mamba2 with Delta Rule","summary":"  Linear Transformers have gained attention as efficient alternatives to\nstandard Transformers, but their performance in retrieval and long-context\ntasks has been limited. To address these limitations, recent work has explored\ntwo distinct mechanisms: gating for adaptive memory control and the delta\nupdate rule for precise memory modifications. We observe that these mechanisms\nare complementary: gating enables rapid memory erasure while the delta rule\nfacilitates targeted updates. Building on this insight, we introduce the gated\ndelta rule and develop a parallel training algorithm optimized for modern\nhardware. Our proposed architecture, Gated DeltaNet, consistently surpasses\nexisting models like Mamba2 and DeltaNet across multiple benchmarks, including\nlanguage modeling, common-sense reasoning, in-context retrieval, length\nextrapolation, and long-context understanding. We further enhance performance\nby developing hybrid architectures that combine Gated DeltaNet layers with\nsliding window attention or Mamba2 layers, achieving both improved training\nefficiency and superior task performance.\n","authors":["Songlin Yang","Jan Kautz","Ali Hatamizadeh"],"pdf_url":"https://arxiv.org/pdf/2412.06464v3.pdf","comment":"ICLR 2025 camera ready"},{"id":"http://arxiv.org/abs/2503.04149v1","updated":"2025-03-06T06:56:59Z","published":"2025-03-06T06:56:59Z","title":"Dynamic Benchmarking of Reasoning Capabilities in Code Large Language\n  Models Under Data Contamination","summary":"  The rapid evolution of code largelanguage models underscores the need for\neffective and transparent benchmarking of their reasoning capabilities.\nHowever, the current benchmarking approach heavily depends on publicly\navailable, human-created datasets. The widespread use of these fixed benchmark\ndatasets makes the benchmarking process to be static and thus particularly\nsusceptible to data contamination, an unavoidable consequence of the extensive\ndata collection processes used to train Code LLMs. Existing approaches that\naddress data contamination often suffer from human effort limitations and\nimbalanced problem complexity. To tackle these challenges, we propose \\tool, a\nnovel benchmarking suite for evaluating Code LLMs under potential data\ncontamination. Given a seed programming problem, \\tool employs multiple agents\nto extract and modify the context without altering the core logic, generating\nsemantically equivalent variations. We introduce a dynamic data generation\nmethods and conduct empirical studies on two seed datasets across 21 Code LLMs.\nResults show that \\tool effectively benchmarks reasoning capabilities under\ncontamination risks while generating diverse problem sets to ensure consistent\nand reliable evaluations.\n","authors":["Simin Chen","Pranav Pusarla","Baishakhi Ray"],"pdf_url":"https://arxiv.org/pdf/2503.04149v1.pdf","comment":"https://codekaleidoscope.github.io/dycodeeval.html"},{"id":"http://arxiv.org/abs/2406.01145v2","updated":"2025-03-06T06:49:04Z","published":"2024-06-03T09:38:28Z","title":"Dual Reasoning: A GNN-LLM Collaborative Framework for Knowledge Graph\n  Question Answering","summary":"  Large Language Models (LLMs) excel at intuitive, implicit reasoning. Guiding\nLLMs to construct thought chains can enhance their deliberate reasoning\nabilities, but also faces challenges such as hallucination. Knowledge Graphs\n(KGs) can provide explicit structured knowledge for LLMs to alleviate these\nissues. However, existing KG-enhanced methods often overlook explicit graph\nlearning, making it challenging to efficiently provide precise reasoning chains\nfor LLMs. Following dual-process theory, we propose Dual-Reasoning (DualR), a\nnovel framework that integrates an external system based on Graph Neural\nNetwork (GNN) for explicit reasoning on KGs, complementing the implicit\nreasoning of LLMs through externalized reasoning chains. DualR designs an\nLLM-empowered GNN module for explicit learning on KGs, efficiently extracting\nhigh-quality reasoning chains. These reasoning chains are then refined to a\nknowledge-enhanced multiple-choice prompt, guiding a frozen LLM to reason\nthoughtfully for final answer determination. Extensive experiments on three\nbenchmark KGQA datasets demonstrate that DualR achieves state-of-the-art\nperformance while maintaining high efficiency and interpretability.\n","authors":["Guangyi Liu","Yongqi Zhang","Yong Li","Quanming Yao"],"pdf_url":"https://arxiv.org/pdf/2406.01145v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.12767v2","updated":"2025-03-06T06:41:40Z","published":"2025-02-18T11:31:52Z","title":"R2-KG: General-Purpose Dual-Agent Framework for Reliable Reasoning on\n  Knowledge Graphs","summary":"  Recent studies have combined Large Language Models (LLMs) with Knowledge\nGraphs (KGs) to enhance reasoning, improving inference accuracy without\nadditional training while mitigating hallucination. However, existing\nframeworks are often rigid, struggling to adapt to KG or task changes. They\nalso rely heavily on powerful LLMs for reliable (i.e., trustworthy) reasoning.\nTo address this, We introduce R2-KG, a plug-and-play, dual-agent framework that\nseparates reasoning into two roles: an Operator (a low-capacity LLM) that\ngathers evidence and a Supervisor (a high-capacity LLM) that makes final\njudgments. This design is cost-efficient for LLM inference while still\nmaintaining strong reasoning accuracy. Additionally, R2-KG employs an\nAbstention mechanism, generating answers only when sufficient evidence is\ncollected from KG, which significantly enhances reliability. Experiments across\nmultiple KG-based reasoning tasks show that R2-KG consistently outperforms\nbaselines in both accuracy and reliability, regardless of the inherent\ncapability of LLMs used as the Operator. Further experiments reveal that the\nsingle-agent version of R2-KG, equipped with a strict self-consistency\nstrategy, achieves significantly higher-than-baseline reliability while\nreducing inference cost. However, it also leads to a higher abstention rate in\ncomplex KGs. Our findings establish R2-KG as a flexible and cost-effective\nsolution for KG-based reasoning. It reduces reliance on high-capacity LLMs\nwhile ensuring trustworthy inference.\n","authors":["Sumin Jo","Junseong Choi","Jiho Kim","Edward Choi"],"pdf_url":"https://arxiv.org/pdf/2502.12767v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17635v2","updated":"2025-03-06T06:39:56Z","published":"2024-10-23T07:53:29Z","title":"Markov Chain of Thought for Efficient Mathematical Reasoning","summary":"  Chain of Thought (CoT) of multi-step benefits from the logical structure of\nthe reasoning steps and task-specific actions, significantly enhancing the\nmathematical reasoning capabilities of large language models. As the prevalence\nof long CoT, the number of reasoning steps exceeds manageable token limits and\nleads to higher computational demands. Inspired by the fundamental logic of\nhuman cognition, \"derive, then reduce\", we conceptualize the standard\nmulti-step CoT as a novel Markov Chain of Thought (MCoT). In this study, we\nconsider the mathematical reasoning task, defining each reasoning step as text\naccompanied by a Python code snippet. To facilitate a longer reasoning path,\nself-correction is enabled through interactions with the code interpreter. Our\nMCoT aims to compress previous reasoning steps into a simplified question,\nenabling efficient next-step inference without relying on a lengthy KV cache.\nIn our experiments, we curate the $\\texttt{MCoTInstruct}$ dataset, and the\nempirical results indicate that MCoT not only significantly enhances efficiency\nbut also maintains comparable accuracy. While much remains to be explored, this\nwork paves the way for exploring the long CoT reasoning abilities of LLMs. The\ncode is available at https://github.com/james-yw/Markov-Chain-of-Thought\n","authors":["Wen Yang","Minpeng Liao","Kai Fan"],"pdf_url":"https://arxiv.org/pdf/2410.17635v2.pdf","comment":"Camera ready version for NAACL 2025 Main"},{"id":"http://arxiv.org/abs/2503.04141v1","updated":"2025-03-06T06:39:25Z","published":"2025-03-06T06:39:25Z","title":"HEISIR: Hierarchical Expansion of Inverted Semantic Indexing for\n  Training-free Retrieval of Conversational Data using LLMs","summary":"  The growth of conversational AI services has increased demand for effective\ninformation retrieval from dialogue data. However, existing methods often face\nchallenges in capturing semantic intent or require extensive labeling and\nfine-tuning. This paper introduces HEISIR (Hierarchical Expansion of Inverted\nSemantic Indexing for Retrieval), a novel framework that enhances semantic\nunderstanding in conversational data retrieval through optimized data\ningestion, eliminating the need for resource-intensive labeling or model\nadaptation. HEISIR implements a two-step process: (1) Hierarchical Triplets\nFormulation and (2) Adjunct Augmentation, creating semantic indices consisting\nof Subject-Verb-Object-Adjunct (SVOA) quadruplets. This structured\nrepresentation effectively captures the underlying semantic information from\ndialogue content. HEISIR achieves high retrieval performance while maintaining\nlow latency during the actual retrieval process. Our experimental results\ndemonstrate that HEISIR outperforms fine-tuned models across various embedding\ntypes and language models. Beyond improving retrieval capabilities, HEISIR also\noffers opportunities for intent and topic analysis in conversational data,\nproviding a versatile solution for dialogue systems.\n","authors":["Sangyeop Kim","Hangyeul Lee","Yohan Lee"],"pdf_url":"https://arxiv.org/pdf/2503.04141v1.pdf","comment":"Accepted by NAACL 2025 (Findings)"},{"id":"http://arxiv.org/abs/2502.14074v2","updated":"2025-03-06T06:32:54Z","published":"2025-02-19T19:59:16Z","title":"Investigating Non-Transitivity in LLM-as-a-Judge","summary":"  Automatic evaluation methods based on large language models (LLMs) are\nemerging as the standard tool for assessing the instruction-following abilities\nof LLM-based agents. The most common method in this paradigm, pairwise\ncomparisons with a baseline model, critically depends on the assumption of\ntransitive preferences. However, the validity of this assumption remains\nlargely unexplored. In this study, we investigate the presence of\nnon-transitivity within the AlpacaEval framework and analyze its effects on\nmodel rankings. We find that LLM judges exhibit non-transitive preferences,\nleading to rankings that are sensitive to the choice of the baseline model. To\nmitigate this issue, we show that round-robin tournaments combined with\nBradley-Terry models of preference can produce more reliable rankings. Notably,\nour method increases both the Spearman correlation and the Kendall correlation\nwith Chatbot Arena (95.0% -> 96.4% and 82.1% -> 86.3% respectively). To address\nthe computational cost of round-robin tournaments, we propose Swiss-Wise\nIterative Matchmaking (Swim) tournaments, using a dynamic matching strategy to\ncapture the benefits of round-robin tournaments while maintaining computational\nefficiency.\n","authors":["Yi Xu","Laura Ruis","Tim Rocktäschel","Robert Kirk"],"pdf_url":"https://arxiv.org/pdf/2502.14074v2.pdf","comment":"8 pages, 6 figures, 2 tables (30 pages, 11 figures, 8 tables\n  including references and appendices)"},{"id":"http://arxiv.org/abs/2503.04135v1","updated":"2025-03-06T06:28:36Z","published":"2025-03-06T06:28:36Z","title":"Biological Sequence with Language Model Prompting: A Survey","summary":"  Large Language models (LLMs) have emerged as powerful tools for addressing\nchallenges across diverse domains. Notably, recent studies have demonstrated\nthat large language models significantly enhance the efficiency of biomolecular\nanalysis and synthesis, attracting widespread attention from academics and\nmedicine. In this paper, we systematically investigate the application of\nprompt-based methods with LLMs to biological sequences, including DNA, RNA,\nproteins, and drug discovery tasks. Specifically, we focus on how prompt\nengineering enables LLMs to tackle domain-specific problems, such as promoter\nsequence prediction, protein structure modeling, and drug-target binding\naffinity prediction, often with limited labeled data. Furthermore, our\ndiscussion highlights the transformative potential of prompting in\nbioinformatics while addressing key challenges such as data scarcity,\nmultimodal fusion, and computational resource limitations. Our aim is for this\npaper to function both as a foundational primer for newcomers and a catalyst\nfor continued innovation within this dynamic field of study.\n","authors":["Jiyue Jiang","Zikang Wang","Yuheng Shan","Heyan Chai","Jiayi Li","Zixian Ma","Xinrui Zhang","Yu Li"],"pdf_url":"https://arxiv.org/pdf/2503.04135v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.18104v2","updated":"2025-03-06T05:54:29Z","published":"2024-11-27T07:32:56Z","title":"Training and Evaluating Language Models with Template-based Data\n  Generation","summary":"  The rapid advancement of large language models (LLMs) such as GPT-3, PaLM,\nand Llama has significantly transformed natural language processing, showcasing\nremarkable capabilities in understanding and generating language. However,\nthese models often struggle with tasks requiring complex reasoning,\nparticularly in mathematical problem-solving, due in part to the scarcity of\nlarge-scale, high-quality, domain-specific datasets necessary for training\nsophisticated reasoning abilities. To address this limitation, we introduce\nTemplate-based Data Generation (TDG), a novel approach that leverages LLMs\n(GPT-4) to automatically generate parameterized meta-templates, which are then\nused to synthesize a vast array of high-quality problems and solutions.\nLeveraging TDG, we create TemplateMath Part I: TemplateGSM, a dataset\ncomprising over 7 million synthetically generated grade school math\nproblems--each accompanied by code-based and natural language solutions--with\nthe potential to generate an effectively unlimited number more. This dataset\nalleviates the scarcity of large-scale mathematical datasets and serves as a\nvaluable resource for pre-training, fine-tuning, and evaluating LLMs in\nmathematical reasoning. Our method not only enables the generation of virtually\ninfinite data but also elevates data augmentation to a new level by using GPT-4\nfor meta-template generation, ensuring diverse and high-quality problem\nstructures. The TemplateMath Part I: TemplateGSM dataset is publicly available\nat https://huggingface.co/datasets/math-ai/TemplateGSM. The code is available\nat https://github.com/iiis-ai/TemplateMath.\n","authors":["Yifan Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.18104v2.pdf","comment":"9 pages, 2 figures"},{"id":"http://arxiv.org/abs/2409.07055v2","updated":"2025-03-06T05:48:54Z","published":"2024-09-11T07:01:08Z","title":"Legal Fact Prediction: The Missing Piece in Legal Judgment Prediction","summary":"  Legal judgment prediction (LJP), which enables litigants and their lawyers to\nforecast judgment outcomes and refine litigation strategies, has emerged as a\ncrucial legal NLP task. Existing studies typically utilize legal facts, i.e.,\nfacts that have been established by evidence and determined by the judge, to\npredict the judgment. However, legal facts are often difficult to obtain in the\nearly stages of litigation, significantly limiting the practical applicability\nof fact-based LJP. To address this limitation, we propose a novel legal NLP\ntask: \\textit{legal fact prediction} (LFP), which takes the evidence submitted\nby litigants for trial as input to predict legal facts, thereby empowering\nfact-based LJP technologies to perform prediction in the absence of\nground-truth legal facts. We also propose the first benchmark dataset,\nLFPBench, for evaluating the LFP task. Our extensive experiments on LFPBench\ndemonstrate the effectiveness of LFP-empowered LJP and highlight promising\nresearch directions for LFP. Our code and data are available at\nhttps://github.com/HPRCEST/LFPBench.\n","authors":["Junkai Liu","Yujie Tong","Hui Huang","Bowen Zheng","Yiran Hu","Peicheng Wu","Chuan Xiao","Makoto Onizuka","Muyun Yang","Shuyuan Zheng"],"pdf_url":"https://arxiv.org/pdf/2409.07055v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02398v2","updated":"2025-03-06T05:46:40Z","published":"2024-11-04T18:59:51Z","title":"Prompting with Phonemes: Enhancing LLMs' Multilinguality for Non-Latin\n  Script Languages","summary":"  Although multilingual LLMs have achieved remarkable performance across\nbenchmarks, we find they continue to underperform on non-Latin script languages\nacross contemporary LLM families. This discrepancy arises from the fact that\nLLMs are pretrained with orthographic scripts, which are dominated by Latin\ncharacters that obscure their shared phonology with non-Latin scripts. We\npropose leveraging phonemic transcriptions as complementary signals to induce\nscript-invariant representations. Our study demonstrates that integrating\nphonemic signals improves performance across both non-Latin and Latin script\nlanguages, with a particularly significant impact on closing the performance\ngap between the two. Through detailed experiments, we show that phonemic and\northographic scripts retrieve distinct examples for in-context learning (ICL).\nThis motivates our proposed Mixed-ICL retrieval strategy, where further\naggregation from both leads to our significant performance improvements for\nboth Latin script languages (up to 12.6%) and non-Latin script languages (up to\n15.1%) compared to randomized ICL retrieval.\n","authors":["Hoang H Nguyen","Khyati Mahajan","Vikas Yadav","Julian Salazar","Philip S. Yu","Masoud Hashemi","Rishabh Maheshwary"],"pdf_url":"https://arxiv.org/pdf/2411.02398v2.pdf","comment":"Accepted for NAACL 2025 (Main Conference)"},{"id":"http://arxiv.org/abs/2503.04113v1","updated":"2025-03-06T05:43:35Z","published":"2025-03-06T05:43:35Z","title":"Uncovering Gaps in How Humans and LLMs Interpret Subjective Language","summary":"  Humans often rely on subjective natural language to direct language models\n(LLMs); for example, users might instruct the LLM to write an enthusiastic\nblogpost, while developers might train models to be helpful and harmless using\nLLM-based edits. The LLM's operational semantics of such subjective phrases --\nhow it adjusts its behavior when each phrase is included in the prompt -- thus\ndictates how aligned it is with human intent. In this work, we uncover\ninstances of misalignment between LLMs' actual operational semantics and what\nhumans expect. Our method, TED (thesaurus error detector), first constructs a\nthesaurus that captures whether two phrases have similar operational semantics\naccording to the LLM. It then elicits failures by unearthing disagreements\nbetween this thesaurus and a human-constructed reference. TED routinely\nproduces surprising instances of misalignment; for example, Mistral 7B Instruct\nproduces more harassing outputs when it edits text to be witty, and Llama 3 8B\nInstruct produces dishonest articles when instructed to make the articles\nenthusiastic. Our results demonstrate that humans can uncover unexpected LLM\nbehavior by scrutinizing relationships between abstract concepts, without\nsupervising outputs directly.\n","authors":["Erik Jones","Arjun Patrawala","Jacob Steinhardt"],"pdf_url":"https://arxiv.org/pdf/2503.04113v1.pdf","comment":"Published at ICLR 2025"},{"id":"http://arxiv.org/abs/2502.07272v2","updated":"2025-03-06T05:41:32Z","published":"2025-02-11T05:39:49Z","title":"GENERator: A Long-Context Generative Genomic Foundation Model","summary":"  Advancements in DNA sequencing technologies have significantly improved our\nability to decode genomic sequences. However, the prediction and interpretation\nof these sequences remain challenging due to the intricate nature of genetic\nmaterial. Large language models (LLMs) have introduced new opportunities for\nbiological sequence analysis. Recent developments in genomic language models\nhave underscored the potential of LLMs in deciphering DNA sequences.\nNonetheless, existing models often face limitations in robustness and\napplication scope, primarily due to constraints in model structure and training\ndata scale. To address these limitations, we present GENERator, a generative\ngenomic foundation model featuring a context length of 98k base pairs (bp) and\n1.2B parameters. Trained on an expansive dataset comprising 386B bp of\neukaryotic DNA, the GENERator demonstrates state-of-the-art performance across\nboth established and newly proposed benchmarks. The model adheres to the\ncentral dogma of molecular biology, accurately generating protein-coding\nsequences that translate into proteins structurally analogous to known\nfamilies. It also shows significant promise in sequence optimization,\nparticularly through the prompt-responsive generation of enhancer sequences\nwith specific activity profiles. These capabilities position the GENERator as a\npivotal tool for genomic research and biotechnological advancement, enhancing\nour ability to interpret and predict complex biological systems and enabling\nprecise genomic interventions. Implementation details and supplementary\nresources are available at https://github.com/GenerTeam/GENERator.\n","authors":["Wei Wu","Qiuyi Li","Mingyang Li","Kun Fu","Fuli Feng","Jieping Ye","Hui Xiong","Zheng Wang"],"pdf_url":"https://arxiv.org/pdf/2502.07272v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.20680v5","updated":"2025-03-06T05:34:13Z","published":"2024-05-31T08:22:49Z","title":"Unraveling and Mitigating Retriever Inconsistencies in\n  Retrieval-Augmented Large Language Models","summary":"  Although Retrieval-Augmented Large Language Models (RALMs) demonstrate their\nsuperiority in terms of factuality, they do not consistently outperform the\noriginal retrieval-free Language Models (LMs). Our experiments reveal that this\nexample-level performance inconsistency exists not only between\nretrieval-augmented and retrieval-free LM but also among different retrievers.\nTo understand this phenomenon, we investigate the degeneration behavior of\nRALMs and theoretically decompose it into four categories. Further analysis\nbased on our decomposition reveals that the innate difference in knowledge\nsources and the unpredictable degeneration of the reader model contribute most\nto the inconsistency. Drawing from our analysis, we introduce Ensemble of\nRetrievers (EoR), a trainable framework that can adaptively retrieve from\ndifferent knowledge sources and effectively decrease unpredictable reader\nerrors. Our experiments on Open Domain Question Answering show that EoR\nsubstantially improves performance over the RALM with a single retriever by\nconsiderably reducing inconsistent behaviors.\n","authors":["Mingda Li","Xinyu Li","Yifan Chen","Wenfeng Xuan","Weinan Zhang"],"pdf_url":"https://arxiv.org/pdf/2405.20680v5.pdf","comment":"ACL 2024 (findings)"},{"id":"http://arxiv.org/abs/2503.04104v1","updated":"2025-03-06T05:25:43Z","published":"2025-03-06T05:25:43Z","title":"LLMs Can Generate a Better Answer by Aggregating Their Own Responses","summary":"  Large Language Models (LLMs) have shown remarkable capabilities across tasks,\nyet they often require additional prompting techniques when facing complex\nproblems. While approaches like self-correction and response selection have\nemerged as popular solutions, recent studies have shown these methods perform\npoorly when relying on the LLM itself to provide feedback or selection\ncriteria. We argue this limitation stems from the fact that common LLM\npost-training procedures lack explicit supervision for discriminative judgment\ntasks. In this paper, we propose Generative Self-Aggregation (GSA), a novel\nprompting method that improves answer quality without requiring the model's\ndiscriminative capabilities. GSA first samples multiple diverse responses from\nthe LLM, then aggregates them to obtain an improved solution. Unlike previous\napproaches, our method does not require the LLM to correct errors or compare\nresponse quality; instead, it leverages the model's generative abilities to\nsynthesize a new response based on the context of multiple samples. While GSA\nshares similarities with the self-consistency (SC) approach for response\naggregation, SC requires specific verifiable tokens to enable majority voting.\nIn contrast, our approach is more general and can be applied to open-ended\ntasks. Empirical evaluation demonstrates that GSA effectively improves response\nquality across various tasks, including mathematical reasoning, knowledge-based\nproblems, and open-ended generation tasks such as code synthesis and\nconversational responses.\n","authors":["Zichong Li","Xinyu Feng","Yuheng Cai","Zixuan Zhang","Tianyi Liu","Chen Liang","Weizhu Chen","Haoyu Wang","Tuo Zhao"],"pdf_url":"https://arxiv.org/pdf/2503.04104v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04099v1","updated":"2025-03-06T05:15:34Z","published":"2025-03-06T05:15:34Z","title":"Disparities in LLM Reasoning Accuracy and Explanations: A Case Study on\n  African American English","summary":"  Large Language Models (LLMs) have demonstrated remarkable capabilities in\nreasoning tasks, leading to their widespread deployment. However, recent\nstudies have highlighted concerning biases in these models, particularly in\ntheir handling of dialectal variations like African American English (AAE). In\nthis work, we systematically investigate dialectal disparities in LLM reasoning\ntasks. We develop an experimental framework comparing LLM performance given\nStandard American English (SAE) and AAE prompts, combining LLM-based dialect\nconversion with established linguistic analyses. We find that LLMs consistently\nproduce less accurate responses and simpler reasoning chains and explanations\nfor AAE inputs compared to equivalent SAE questions, with disparities most\npronounced in social science and humanities domains. These findings highlight\nsystematic differences in how LLMs process and reason about different language\nvarieties, raising important questions about the development and deployment of\nthese systems in our multilingual and multidialectal world. Our code repository\nis publicly available at https://github.com/Runtaozhou/dialect_bias_eval.\n","authors":["Runtao Zhou","Guangya Wan","Saadia Gabriel","Sheng Li","Alexander J Gates","Maarten Sap","Thomas Hartvigsen"],"pdf_url":"https://arxiv.org/pdf/2503.04099v1.pdf","comment":"ARR Under Review, First two authors contribute equally"},{"id":"http://arxiv.org/abs/2503.04095v1","updated":"2025-03-06T05:08:40Z","published":"2025-03-06T05:08:40Z","title":"Chart-HQA: A Benchmark for Hypothetical Question Answering in Charts","summary":"  Multimodal Large Language Models (MLLMs) have garnered significant attention\nfor their strong visual-semantic understanding. Most existing chart benchmarks\nevaluate MLLMs' ability to parse information from charts to answer\nquestions.However, they overlook the inherent output biases of MLLMs, where\nmodels rely on their parametric memory to answer questions rather than\ngenuinely understanding the chart content. To address this limitation, we\nintroduce a novel Chart Hypothetical Question Answering (HQA) task, which\nimposes assumptions on the same question to compel models to engage in\ncounterfactual reasoning based on the chart content. Furthermore, we introduce\nHAI, a human-AI interactive data synthesis approach that leverages the\nefficient text-editing capabilities of LLMs alongside human expert knowledge to\ngenerate diverse and high-quality HQA data at a low cost. Using HAI, we\nconstruct Chart-HQA, a challenging benchmark synthesized from publicly\navailable data sources. Evaluation results on 18 MLLMs of varying model sizes\nreveal that current models face significant generalization challenges and\nexhibit imbalanced reasoning performance on the HQA task.\n","authors":["Xiangnan Chen","Yuancheng Fang","Qian Xiao","Juncheng Li","Jun Lin","Siliang Tang","Yi Yang","Yueting Zhuang"],"pdf_url":"https://arxiv.org/pdf/2503.04095v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2501.17399v2","updated":"2025-03-06T04:41:56Z","published":"2025-01-29T03:29:24Z","title":"MultiChallenge: A Realistic Multi-Turn Conversation Evaluation Benchmark\n  Challenging to Frontier LLMs","summary":"  We present MultiChallenge, a pioneering benchmark evaluating large language\nmodels (LLMs) on conducting multi-turn conversations with human users, a\ncrucial yet underexamined capability for their applications. MultiChallenge\nidentifies four categories of challenges in multi-turn conversations that are\nnot only common and realistic among current human-LLM interactions, but are\nalso challenging to all current frontier LLMs. All 4 challenges require\naccurate instruction-following, context allocation, and in-context reasoning at\nthe same time. We also develop LLM as judge with instance-level rubrics to\nfacilitate an automatic evaluation method with fair agreement with experienced\nhuman raters. Despite achieving near-perfect scores on existing multi-turn\nevaluation benchmarks, all frontier models have less than 50% accuracy on\nMultiChallenge, with the top-performing Claude 3.5 Sonnet (June 2024) achieving\njust a 41.4% average accuracy.\n","authors":["Ved Sirdeshmukh","Kaustubh Deshpande","Johannes Mols","Lifeng Jin","Ed-Yeremai Cardona","Dean Lee","Jeremy Kritz","Willow Primack","Summer Yue","Chen Xing"],"pdf_url":"https://arxiv.org/pdf/2501.17399v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.15683v3","updated":"2025-03-06T03:59:59Z","published":"2024-05-24T16:21:59Z","title":"Visual Description Grounding Reduces Hallucinations and Boosts Reasoning\n  in LVLMs","summary":"  Large Vision-Language Models (LVLMs) often produce responses that misalign\nwith factual information, a phenomenon known as hallucinations. While\nhallucinations are well-studied, the exact causes behind them remain\nunderexplored. In this paper, we first investigate the root causes of\nhallucinations in LVLMs. Our findings reveal that existing mitigation\ntechniques primarily reduce hallucinations for visual recognition prompts-those\nthat require simple descriptions of visual elements-but fail for cognitive\nprompts that demand deliberate reasoning. We identify the core issue as a lack\nof true visual perception in LVLMs: although they can accurately recognize\nvisual elements, they struggle to fully interpret these elements in the context\nof the input prompt and effectively link this recognition to their internal\nknowledge, which is critical for reasoning. To address this gap, we introduce\nVisual Description Grounded Decoding (VDGD), a simple, robust, and\ntraining-free method designed to enhance visual perception and improve\nreasoning capabilities in LVLMs. VDGD works by first generating a detailed\ndescription of the image and appending it as a prefix to the instruction.\nDuring response generation, tokens are sampled based on their KL divergence to\nthe description, favoring candidates with lower divergence. Experimental\nresults on multiple visual reasoning benchmarks and LVLMs demonstrate that VDGD\nconsistently outperforms existing baselines 2% - 33%. Finally, we introduce\nVaLLu, a benchmark designed for comprehensive evaluation of the cognitive\ncapabilities of LVLMs.\n","authors":["Sreyan Ghosh","Chandra Kiran Reddy Evuru","Sonal Kumar","Utkarsh Tyagi","Oriol Nieto","Zeyu Jin","Dinesh Manocha"],"pdf_url":"https://arxiv.org/pdf/2405.15683v3.pdf","comment":"Accepted to ICLR 2025. Project: https://sreyan88.github.io/VDGD/"},{"id":"http://arxiv.org/abs/2503.04065v1","updated":"2025-03-06T03:43:21Z","published":"2025-03-06T03:43:21Z","title":"PP-DocBee: Improving Multimodal Document Understanding Through a Bag of\n  Tricks","summary":"  With the rapid advancement of digitalization, various document images are\nbeing applied more extensively in production and daily life, and there is an\nincreasingly urgent need for fast and accurate parsing of the content in\ndocument images. Therefore, this report presents PP-DocBee, a novel multimodal\nlarge language model designed for end-to-end document image understanding.\nFirst, we develop a data synthesis strategy tailored to document scenarios in\nwhich we build a diverse dataset to improve the model generalization. Then, we\napply a few training techniques, including dynamic proportional sampling, data\npreprocessing, and OCR postprocessing strategies. Extensive evaluations\ndemonstrate the superior performance of PP-DocBee, achieving state-of-the-art\nresults on English document understanding benchmarks and even outperforming\nexisting open source and commercial models in Chinese document understanding.\nThe source code and pre-trained models are publicly available at\n\\href{https://github.com/PaddlePaddle/PaddleMIX}{https://github.com/PaddlePaddle/PaddleMIX}.\n","authors":["Feng Ni","Kui Huang","Yao Lu","Wenyu Lv","Guanzhong Wang","Zeyu Chen","Yi Liu"],"pdf_url":"https://arxiv.org/pdf/2503.04065v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04064v1","updated":"2025-03-06T03:41:47Z","published":"2025-03-06T03:41:47Z","title":"Uncovering inequalities in new knowledge learning by large language\n  models across different languages","summary":"  As large language models (LLMs) gradually become integral tools for problem\nsolving in daily life worldwide, understanding linguistic inequality is\nbecoming increasingly important. Existing research has primarily focused on\nstatic analyses that assess the disparities in the existing knowledge and\ncapabilities of LLMs across languages. However, LLMs are continuously evolving,\nacquiring new knowledge to generate up-to-date, domain-specific responses.\nInvestigating linguistic inequalities within this dynamic process is,\ntherefore, also essential. In this paper, we explore inequalities in new\nknowledge learning by LLMs across different languages and four key dimensions:\neffectiveness, transferability, prioritization, and robustness. Through\nextensive experiments under two settings (in-context learning and fine-tuning)\nusing both proprietary and open-source models, we demonstrate that low-resource\nlanguages consistently face disadvantages across all four dimensions. By\nshedding light on these disparities, we aim to raise awareness of linguistic\ninequalities in LLMs' new knowledge learning, fostering the development of more\ninclusive and equitable future LLMs.\n","authors":["Chenglong Wang","Haoyu Tang","Xiyuan Yang","Yueqi Xie","Jina Suh","Sunayana Sitaram","Junming Huang","Yu Xie","Zhaoya Gong","Xing Xie","Fangzhao Wu"],"pdf_url":"https://arxiv.org/pdf/2503.04064v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03459v2","updated":"2025-03-06T03:32:45Z","published":"2025-03-05T12:49:44Z","title":"Unified Mind Model: Reimagining Autonomous Agents in the LLM Era","summary":"  Large language models (LLMs) have recently demonstrated remarkable\ncapabilities across domains, tasks, and languages (e.g., ChatGPT and GPT-4),\nreviving the research of general autonomous agents with human-like cognitive\nabilities. Such human-level agents require semantic comprehension and\ninstruction-following capabilities, which exactly fall into the strengths of\nLLMs. Although there have been several initial attempts to build human-level\nagents based on LLMs, the theoretical foundation remains a challenging open\nproblem. In this paper, we propose a novel theoretical cognitive architecture,\nthe Unified Mind Model (UMM), which offers guidance to facilitate the rapid\ncreation of autonomous agents with human-level cognitive abilities.\nSpecifically, our UMM starts with the global workspace theory and further\nleverage LLMs to enable the agent with various cognitive abilities, such as\nmulti-modal perception, planning, reasoning, tool use, learning, memory,\nreflection and motivation. Building upon UMM, we then develop an agent-building\nengine, MindOS, which allows users to quickly create domain-/task-specific\nautonomous agents without any programming effort.\n","authors":["Pengbo Hu","Xiang Ying"],"pdf_url":"https://arxiv.org/pdf/2503.03459v2.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2503.02365v2","updated":"2025-03-06T03:29:31Z","published":"2025-03-04T07:45:45Z","title":"EchoQA: A Large Collection of Instruction Tuning Data for Echocardiogram\n  Reports","summary":"  We introduce a novel question-answering (QA) dataset using echocardiogram\nreports sourced from the Medical Information Mart for Intensive Care database.\nThis dataset is specifically designed to enhance QA systems in cardiology,\nconsisting of 771,244 QA pairs addressing a wide array of cardiac abnormalities\nand their severity. We compare large language models (LLMs), including\nopen-source and biomedical-specific models for zero-shot evaluation, and\nclosed-source models for zero-shot and three-shot evaluation. Our results show\nthat fine-tuning LLMs improves performance across various QA metrics,\nvalidating the value of our dataset. Clinicians also qualitatively evaluate the\nbest-performing model to assess the LLM responses for correctness. Further, we\nconduct fine-grained fairness audits to assess the bias-performance trade-off\nof LLMs across various social determinants of health. Our objective is to\npropel the field forward by establishing a benchmark for LLM AI agents aimed at\nsupporting clinicians with cardiac differential diagnoses, thereby reducing the\ndocumentation burden that contributes to clinician burnout and enabling\nhealthcare professionals to focus more on patient care.\n","authors":["Lama Moukheiber","Mira Moukheiber","Dana Moukheiiber","Jae-Woo Ju","Hyung-Chul Lee"],"pdf_url":"https://arxiv.org/pdf/2503.02365v2.pdf","comment":"NeurIPS SafeGenAI 2024"},{"id":"http://arxiv.org/abs/2401.08392v4","updated":"2025-03-06T03:27:02Z","published":"2024-01-16T14:33:09Z","title":"DoraemonGPT: Toward Understanding Dynamic Scenes with Large Language\n  Models (Exemplified as A Video Agent)","summary":"  Recent LLM-driven visual agents mainly focus on solving image-based tasks,\nwhich limits their ability to understand dynamic scenes, making it far from\nreal-life applications like guiding students in laboratory experiments and\nidentifying their mistakes. Hence, this paper explores DoraemonGPT, a\ncomprehensive and conceptually elegant system driven by LLMs to understand\ndynamic scenes. Considering the video modality better reflects the\never-changing nature of real-world scenarios, we exemplify DoraemonGPT as a\nvideo agent. Given a video with a question/task, DoraemonGPT begins by\nconverting the input video into a symbolic memory that stores task-related\nattributes. This structured representation allows for spatial-temporal querying\nand reasoning by well-designed sub-task tools, resulting in concise\nintermediate results. Recognizing that LLMs have limited internal knowledge\nwhen it comes to specialized domains (e.g., analyzing the scientific principles\nunderlying experiments), we incorporate plug-and-play tools to assess external\nknowledge and address tasks across different domains. Moreover, a novel\nLLM-driven planner based on Monte Carlo Tree Search is introduced to explore\nthe large planning space for scheduling various tools. The planner iteratively\nfinds feasible solutions by backpropagating the result's reward, and multiple\nsolutions can be summarized into an improved final answer. We extensively\nevaluate DoraemonGPT's effectiveness on three benchmarks and several\nin-the-wild scenarios. The code will be released at\nhttps://github.com/z-x-yang/DoraemonGPT.\n","authors":["Zongxin Yang","Guikun Chen","Xiaodi Li","Wenguan Wang","Yi Yang"],"pdf_url":"https://arxiv.org/pdf/2401.08392v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.06916v2","updated":"2025-03-06T03:04:44Z","published":"2024-10-09T14:15:30Z","title":"SWIFT: On-the-Fly Self-Speculative Decoding for LLM Inference\n  Acceleration","summary":"  Speculative decoding (SD) has emerged as a widely used paradigm to accelerate\nLLM inference without compromising quality. It works by first employing a\ncompact model to draft multiple tokens efficiently and then using the target\nLLM to verify them in parallel. While this technique has achieved notable\nspeedups, most existing approaches necessitate either additional parameters or\nextensive training to construct effective draft models, thereby restricting\ntheir applicability across different LLMs and tasks. To address this\nlimitation, we explore a novel plug-and-play SD solution with layer-skipping,\nwhich skips intermediate layers of the target LLM as the compact draft model.\nOur analysis reveals that LLMs exhibit great potential for self-acceleration\nthrough layer sparsity and the task-specific nature of this sparsity. Building\non these insights, we introduce SWIFT, an on-the-fly self-speculative decoding\nalgorithm that adaptively selects intermediate layers of LLMs to skip during\ninference. SWIFT does not require auxiliary models or additional training,\nmaking it a plug-and-play solution for accelerating LLM inference across\ndiverse input data streams. Our extensive experiments across a wide range of\nmodels and downstream tasks demonstrate that SWIFT can achieve over a 1.3x-1.6x\nspeedup while preserving the original distribution of the generated text. We\nrelease our code in https://github.com/hemingkx/SWIFT.\n","authors":["Heming Xia","Yongqi Li","Jun Zhang","Cunxiao Du","Wenjie Li"],"pdf_url":"https://arxiv.org/pdf/2410.06916v2.pdf","comment":"ICLR 2025, camera-ready version"},{"id":"http://arxiv.org/abs/2408.15176v2","updated":"2025-03-06T02:45:08Z","published":"2024-08-27T16:18:51Z","title":"Unifying Multitrack Music Arrangement via Reconstruction Fine-Tuning and\n  Efficient Tokenization","summary":"  Automatic music arrangement streamlines the creation of musical variants for\ncomposers and arrangers, reducing reliance on extensive music expertise.\nHowever, existing methods suffer from inefficient tokenization,\nunderutilization of pre-trained music language models (LMs), and suboptimal\nfidelity and coherence in generated arrangements. This paper introduces an\nefficient multitrack music tokenizer for unconditional and conditional symbolic\nmusic generation, along with a unified sequence-to-sequence reconstruction\nfine-tuning objective for pre-trained music LMs that balances task-specific\nneeds with coherence constraints. Our approach achieves state-of-the-art\nresults on band arrangement, piano reduction, and drum arrangement, surpassing\ntask-specific models in both objective metrics and perceptual quality.\nAdditionally, we demonstrate that generative pretraining significantly\ncontributes to the performance across these arrangement tasks, especially when\nhandling long segments with complex alignment.\n","authors":["Longshen Ou","Jingwei Zhao","Ziyu Wang","Gus Xia","Ye Wang"],"pdf_url":"https://arxiv.org/pdf/2408.15176v2.pdf","comment":"Submitted to IJCAI 2025"},{"id":"http://arxiv.org/abs/2406.10292v3","updated":"2025-03-06T02:41:55Z","published":"2024-06-13T04:23:35Z","title":"Automatically Labeling Clinical Trial Outcomes: A Large-Scale Benchmark\n  for Drug Development","summary":"  Background The cost of drug discovery and development is substantial, with\nclinical trial outcomes playing a critical role in regulatory approval and\npatient care. However, access to large-scale, high-quality clinical trial\noutcome data remains limited, hindering advancements in predictive modeling and\nevidence-based decision-making.\n  Methods We present the Clinical Trial Outcome (CTO) benchmark, a fully\nreproducible, large-scale repository encompassing approximately 125,000 drug\nand biologics trials. CTO integrates large language model (LLM) interpretations\nof publications, trial phase progression tracking, sentiment analysis from news\nsources, stock price movements of trial sponsors, and additional trial-related\nmetrics. Furthermore, we manually annotated a dataset of clinical trials\nconducted between 2020 and 2024 to enhance the quality and reliability of\noutcome labels.\n  Results The trial outcome labels in the CTO benchmark agree strongly with\nexpert annotations, achieving an F1 score of 94 for Phase 3 trials and 91\nacross all phases. Additionally, benchmarking standard machine learning models\non our manually annotated dataset revealed distribution shifts in recent\ntrials, underscoring the necessity of continuously updated labeling approaches.\n  Conclusions By analyzing CTO's performance on recent clinical trials, we\ndemonstrate the ongoing need for high-quality, up-to-date trial outcome labels.\nWe publicly release the CTO knowledge base and annotated labels at\nhttps://chufangao.github.io/CTOD, with regular updates to support research on\nclinical trial outcomes and inform data-driven improvements in drug\ndevelopment.\n","authors":["Chufan Gao","Jathurshan Pradeepkumar","Trisha Das","Shivashankar Thati","Jimeng Sun"],"pdf_url":"https://arxiv.org/pdf/2406.10292v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04036v1","updated":"2025-03-06T02:40:51Z","published":"2025-03-06T02:40:51Z","title":"Robust Data Watermarking in Language Models by Injecting Fictitious\n  Knowledge","summary":"  Data watermarking in language models injects traceable signals, such as\nspecific token sequences or stylistic patterns, into copyrighted text, allowing\ncopyright holders to track and verify training data ownership. Previous data\nwatermarking techniques primarily focus on effective memorization after\npretraining, while overlooking challenges that arise in other stages of the LLM\npipeline, such as the risk of watermark filtering during data preprocessing, or\npotential forgetting through post-training, or verification difficulties due to\nAPI-only access. We propose a novel data watermarking approach that injects\ncoherent and plausible yet fictitious knowledge into training data using\ngenerated passages describing a fictitious entity and its associated\nattributes. Our watermarks are designed to be memorized by the LLM through\nseamlessly integrating in its training data, making them harder to detect\nlexically during preprocessing.We demonstrate that our watermarks can be\neffectively memorized by LLMs, and that increasing our watermarks' density,\nlength, and diversity of attributes strengthens their memorization. We further\nshow that our watermarks remain robust throughout LLM development, maintaining\ntheir effectiveness after continual pretraining and supervised finetuning.\nFinally, we show that our data watermarks can be evaluated even under API-only\naccess via question answering.\n","authors":["Xinyue Cui","Johnny Tian-Zheng Wei","Swabha Swayamdipta","Robin Jia"],"pdf_url":"https://arxiv.org/pdf/2503.04036v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04013v1","updated":"2025-03-06T02:01:59Z","published":"2025-03-06T02:01:59Z","title":"Benchmarking Large Language Models on Multiple Tasks in Bioinformatics\n  NLP with Prompting","summary":"  Large language models (LLMs) have become important tools in solving\nbiological problems, offering improvements in accuracy and adaptability over\nconventional methods. Several benchmarks have been proposed to evaluate the\nperformance of these LLMs. However, current benchmarks can hardly evaluate the\nperformance of these models across diverse tasks effectively. In this paper, we\nintroduce a comprehensive prompting-based benchmarking framework, termed\nBio-benchmark, which includes 30 key bioinformatics tasks covering areas such\nas proteins, RNA, drugs, electronic health records, and traditional Chinese\nmedicine. Using this benchmark, we evaluate six mainstream LLMs, including\nGPT-4o and Llama-3.1-70b, etc., using 0-shot and few-shot Chain-of-Thought\n(CoT) settings without fine-tuning to reveal their intrinsic capabilities. To\nimprove the efficiency of our evaluations, we demonstrate BioFinder, a new tool\nfor extracting answers from LLM responses, which increases extraction accuracy\nby round 30% compared to existing methods. Our benchmark results show the\nbiological tasks suitable for current LLMs and identify specific areas\nrequiring enhancement. Furthermore, we propose targeted prompt engineering\nstrategies for optimizing LLM performance in these contexts. Based on these\nfindings, we provide recommendations for the development of more robust LLMs\ntailored for various biological applications. This work offers a comprehensive\nevaluation framework and robust tools to support the application of LLMs in\nbioinformatics.\n","authors":["Jiyue Jiang","Pengan Chen","Jiuming Wang","Dongchen He","Ziqin Wei","Liang Hong","Licheng Zong","Sheng Wang","Qinze Yu","Zixian Ma","Yanyu Chen","Yimin Fan","Xiangyu Shi","Jiawei Sun","Chuan Wu","Yu Li"],"pdf_url":"https://arxiv.org/pdf/2503.04013v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20490v2","updated":"2025-03-06T00:59:40Z","published":"2025-02-27T19:54:16Z","title":"EgoNormia: Benchmarking Physical Social Norm Understanding","summary":"  Human activity is moderated by norms. However, machines are often trained\nwithout explicit supervision on norm understanding and reasoning, especially\nwhen the norms are grounded in a physical and social context. To improve and\nevaluate the normative reasoning capability of vision-language models (VLMs),\nwe present EgoNormia $\\|\\epsilon\\|$, consisting of 1,853 ego-centric videos of\nhuman interactions, each of which has two related questions evaluating both the\nprediction and justification of normative actions. The normative actions\nencompass seven categories: safety, privacy, proxemics, politeness,\ncooperation, coordination/proactivity, and communication/legibility. To compile\nthis dataset at scale, we propose a novel pipeline leveraging video sampling,\nautomatic answer generation, filtering, and human validation. Our work\ndemonstrates that current state-of-the-art vision-language models lack robust\nnorm understanding, scoring a maximum of 45% on EgoNormia (versus a human bench\nof 92%). Our analysis of performance in each dimension highlights the\nsignificant risks of safety, privacy, and the lack of collaboration and\ncommunication capability when applied to real-world agents. We additionally\nshow that through a retrieval-based generation method, it is possible to use\nEgoNormia to enhance normative reasoning in VLMs.\n","authors":["MohammadHossein Rezaei","Yicheng Fu","Phil Cuvin","Caleb Ziems","Yanzhe Zhang","Hao Zhu","Diyi Yang"],"pdf_url":"https://arxiv.org/pdf/2502.20490v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02163v2","updated":"2025-03-06T00:58:55Z","published":"2024-10-03T03:06:42Z","title":"Adversarial Decoding: Generating Readable Documents for Adversarial\n  Objectives","summary":"  We design, implement, and evaluate adversarial decoding, a new, generic text\ngeneration technique that produces readable documents for different adversarial\nobjectives. Prior methods either produce easily detectable gibberish, or cannot\nhandle objectives that include embedding similarity. In particular, they only\nwork for direct attacks (such as jailbreaking) and cannot produce adversarial\ntext for realistic indirect injection, e.g., documents that (1) are retrieved\nin RAG systems in response to broad classes of queries, and also (2)\nadversarially influence subsequent generation. We also show that fluency (low\nperplexity) is not sufficient to evade filtering. We measure the effectiveness\nof adversarial decoding for different objectives, including RAG poisoning,\njailbreaking, and evasion of defensive filters, and demonstrate that it\noutperforms existing methods while producing readable adversarial documents.\n","authors":["Collin Zhang","Tingwei Zhang","Vitaly Shmatikov"],"pdf_url":"https://arxiv.org/pdf/2410.02163v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.17651v3","updated":"2025-03-06T00:45:00Z","published":"2025-02-24T21:01:39Z","title":"METAL: A Multi-Agent Framework for Chart Generation with Test-Time\n  Scaling","summary":"  Chart generation aims to generate code to produce charts satisfying the\ndesired visual properties, e.g., texts, layout, color, and type. It has great\npotential to empower the automatic professional report generation in financial\nanalysis, research presentation, education, and healthcare. In this work, we\nbuild a vision-language model (VLM) based multi-agent framework for effective\nautomatic chart generation. Generating high-quality charts requires both strong\nvisual design skills and precise coding capabilities that embed the desired\nvisual properties into code. Such a complex multi-modal reasoning process is\ndifficult for direct prompting of VLMs. To resolve these challenges, we propose\nMETAL, a multi-agent framework that decomposes the task of chart generation\ninto the iterative collaboration among specialized agents. METAL achieves 5.2%\nimprovement over the current best result in the chart generation task. The\nMETAL framework exhibits the phenomenon of test-time scaling: its performance\nincreases monotonically as the logarithmic computational budget grows from 512\nto 8192 tokens. In addition, we find that separating different modalities\nduring the critique process of METAL boosts the self-correction capability of\nVLMs in the multimodal context.\n","authors":["Bingxuan Li","Yiwei Wang","Jiuxiang Gu","Kai-Wei Chang","Nanyun Peng"],"pdf_url":"https://arxiv.org/pdf/2502.17651v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.16457v2","updated":"2025-03-06T00:40:18Z","published":"2025-02-23T06:16:23Z","title":"Towards Fully-Automated Materials Discovery via Large-Scale Synthesis\n  Dataset and Expert-Level LLM-as-a-Judge","summary":"  Materials synthesis is vital for innovations such as energy storage,\ncatalysis, electronics, and biomedical devices. Yet, the process relies heavily\non empirical, trial-and-error methods guided by expert intuition. Our work aims\nto support the materials science community by providing a practical,\ndata-driven resource. We have curated a comprehensive dataset of 17K\nexpert-verified synthesis recipes from open-access literature, which forms the\nbasis of our newly developed benchmark, AlchemyBench. AlchemyBench offers an\nend-to-end framework that supports research in large language models applied to\nsynthesis prediction. It encompasses key tasks, including raw materials and\nequipment prediction, synthesis procedure generation, and characterization\noutcome forecasting. We propose an LLM-as-a-Judge framework that leverages\nlarge language models for automated evaluation, demonstrating strong\nstatistical agreement with expert assessments. Overall, our contributions offer\na supportive foundation for exploring the capabilities of LLMs in predicting\nand guiding materials synthesis, ultimately paving the way for more efficient\nexperimental design and accelerated innovation in materials science.\n","authors":["Heegyu Kim","Taeyang Jeon","Seungtaek Choi","Ji Hoon Hong","Dong Won Jeon","Sung Beom Cho","Ga-Yeon Baek","Kyung-Won Kwak","Dong-Hee Lee","Sun-Jin Choi","Jisu Bae","Chihoon Lee","Yunseo Kim","Jinsung Park","Hyunsouk Cho"],"pdf_url":"https://arxiv.org/pdf/2502.16457v2.pdf","comment":"under review"},{"id":"http://arxiv.org/abs/2503.03987v1","updated":"2025-03-06T00:19:54Z","published":"2025-03-06T00:19:54Z","title":"RetinalGPT: A Retinal Clinical Preference Conversational Assistant\n  Powered by Large Vision-Language Models","summary":"  Recently, Multimodal Large Language Models (MLLMs) have gained significant\nattention for their remarkable ability to process and analyze non-textual data,\nsuch as images, videos, and audio. Notably, several adaptations of\ngeneral-domain MLLMs to the medical field have been explored, including\nLLaVA-Med. However, these medical adaptations remain insufficiently advanced in\nunderstanding and interpreting retinal images. In contrast, medical experts\nemphasize the importance of quantitative analyses for disease detection and\ninterpretation. This underscores a gap between general-domain and\nmedical-domain MLLMs: while general-domain MLLMs excel in broad applications,\nthey lack the specialized knowledge necessary for precise diagnostic and\ninterpretative tasks in the medical field. To address these challenges, we\nintroduce \\textit{RetinalGPT}, a multimodal conversational assistant for\nclinically preferred quantitative analysis of retinal images. Specifically, we\nachieve this by compiling a large retinal image dataset, developing a novel\ndata pipeline, and employing customized visual instruction tuning to enhance\nboth retinal analysis and enrich medical knowledge. In particular, RetinalGPT\noutperforms MLLM in the generic domain by a large margin in the diagnosis of\nretinal diseases in 8 benchmark retinal datasets. Beyond disease diagnosis,\nRetinalGPT features quantitative analyses and lesion localization, representing\na pioneering step in leveraging LLMs for an interpretable and end-to-end\nclinical research framework. The code is available at\nhttps://github.com/Retinal-Research/RetinalGPT\n","authors":["Wenhui Zhu","Xin Li","Xiwen Chen","Peijie Qiu","Vamsi Krishna Vasa","Xuanzhao Dong","Yanxi Chen","Natasha Lepore","Oana Dumitrascu","Yi Su","Yalin Wang"],"pdf_url":"https://arxiv.org/pdf/2503.03987v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03983v1","updated":"2025-03-06T00:10:26Z","published":"2025-03-06T00:10:26Z","title":"Audio Flamingo 2: An Audio-Language Model with Long-Audio Understanding\n  and Expert Reasoning Abilities","summary":"  Understanding and reasoning over non-speech sounds and music are crucial for\nboth humans and AI agents to interact effectively with their environments. In\nthis paper, we introduce Audio Flamingo 2 (AF2), an Audio-Language Model (ALM)\nwith advanced audio understanding and reasoning capabilities. AF2 leverages (i)\na custom CLAP model, (ii) synthetic Audio QA data for fine-grained audio\nreasoning, and (iii) a multi-stage curriculum learning strategy. AF2 achieves\nstate-of-the-art performance with only a 3B parameter small language model,\nsurpassing large open-source and proprietary models across over 20 benchmarks.\nNext, for the first time, we extend audio understanding to long audio segments\n(30 secs to 5 mins) and propose LongAudio, a large and novel dataset for\ntraining ALMs on long audio captioning and question-answering tasks.\nFine-tuning AF2 on LongAudio leads to exceptional performance on our proposed\nLongAudioBench, an expert annotated benchmark for evaluating ALMs on long audio\nunderstanding capabilities. We conduct extensive ablation studies to confirm\nthe efficacy of our approach. Project Website:\nhttps://research.nvidia.com/labs/adlr/AF2/.\n","authors":["Sreyan Ghosh","Zhifeng Kong","Sonal Kumar","S Sakshi","Jaehyeon Kim","Wei Ping","Rafael Valle","Dinesh Manocha","Bryan Catanzaro"],"pdf_url":"https://arxiv.org/pdf/2503.03983v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03979v1","updated":"2025-03-06T00:03:55Z","published":"2025-03-06T00:03:55Z","title":"ReasonGraph: Visualisation of Reasoning Paths","summary":"  Large Language Models (LLMs) reasoning processes are challenging to analyze\ndue to their complexity and the lack of organized visualization tools. We\npresent ReasonGraph, a web-based platform for visualizing and analyzing LLM\nreasoning processes. It supports both sequential and tree-based reasoning\nmethods while integrating with major LLM providers and over fifty\nstate-of-the-art models. ReasonGraph incorporates an intuitive UI with meta\nreasoning method selection, configurable visualization parameters, and a\nmodular framework that facilitates efficient extension. Our evaluation shows\nhigh parsing reliability, efficient processing, and strong usability across\nvarious downstream applications. By providing a unified visualization\nframework, ReasonGraph reduces cognitive load in analyzing complex reasoning\npaths, improves error detection in logical processes, and enables more\neffective development of LLM-based applications. The platform is open-source,\npromoting accessibility and reproducibility in LLM reasoning analysis.\n","authors":["Zongqian Li","Ehsan Shareghi","Nigel Collier"],"pdf_url":"https://arxiv.org/pdf/2503.03979v1.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2503.04720v1","updated":"2025-03-06T18:59:06Z","published":"2025-03-06T18:59:06Z","title":"FluidNexus: 3D Fluid Reconstruction and Prediction from a Single Video","summary":"  We study reconstructing and predicting 3D fluid appearance and velocity from\na single video. Current methods require multi-view videos for fluid\nreconstruction. We present FluidNexus, a novel framework that bridges video\ngeneration and physics simulation to tackle this task. Our key insight is to\nsynthesize multiple novel-view videos as references for reconstruction.\nFluidNexus consists of two key components: (1) a novel-view video synthesizer\nthat combines frame-wise view synthesis with video diffusion refinement for\ngenerating realistic videos, and (2) a physics-integrated particle\nrepresentation coupling differentiable simulation and rendering to\nsimultaneously facilitate 3D fluid reconstruction and prediction. To evaluate\nour approach, we collect two new real-world fluid datasets featuring textured\nbackgrounds and object interactions. Our method enables dynamic novel view\nsynthesis, future prediction, and interaction simulation from a single fluid\nvideo. Project website: https://yuegao.me/FluidNexus.\n","authors":["Yue Gao","Hong-Xing Yu","Bo Zhu","Jiajun Wu"],"pdf_url":"https://arxiv.org/pdf/2503.04720v1.pdf","comment":"CVPR 2025. Project website: https://yuegao.me/FluidNexus"},{"id":"http://arxiv.org/abs/2503.04718v1","updated":"2025-03-06T18:58:45Z","published":"2025-03-06T18:58:45Z","title":"Floxels: Fast Unsupervised Voxel Based Scene Flow Estimation","summary":"  Scene flow estimation is a foundational task for many robotic applications,\nincluding robust dynamic object detection, automatic labeling, and sensor\nsynchronization. Two types of approaches to the problem have evolved: 1)\nSupervised and 2) optimization-based methods. Supervised methods are fast\nduring inference and achieve high-quality results, however, they are limited by\nthe need for large amounts of labeled training data and are susceptible to\ndomain gaps. In contrast, unsupervised test-time optimization methods do not\nface the problem of domain gaps but usually suffer from substantial runtime,\nexhibit artifacts, or fail to converge to the right solution. In this work, we\nmitigate several limitations of existing optimization-based methods. To this\nend, we 1) introduce a simple voxel grid-based model that improves over the\nstandard MLP-based formulation in multiple dimensions and 2) introduce a new\nmultiframe loss formulation. 3) We combine both contributions in our new\nmethod, termed Floxels. On the Argoverse 2 benchmark, Floxels is surpassed only\nby EulerFlow among unsupervised methods while achieving comparable performance\nat a fraction of the computational cost. Floxels achieves a massive speedup of\nmore than ~60 - 140x over EulerFlow, reducing the runtime from a day to 10\nminutes per sequence. Over the faster but low-quality baseline, NSFP, Floxels\nachieves a speedup of ~14x.\n","authors":["David T. Hoffmann","Syed Haseeb Raza","Hanqiu Jiang","Denis Tananaev","Steffen Klingenhoefer","Martin Meinke"],"pdf_url":"https://arxiv.org/pdf/2503.04718v1.pdf","comment":"Accepted at CVPR 2025"},{"id":"http://arxiv.org/abs/2503.04707v1","updated":"2025-03-06T18:55:21Z","published":"2025-03-06T18:55:21Z","title":"Iris Style Transfer: Enhancing Iris Recognition with Style Features and\n  Privacy Preservation through Neural Style Transfer","summary":"  Iris texture is widely regarded as a gold standard biometric modality for\nauthentication and identification. The demand for robust iris recognition\nmethods, coupled with growing security and privacy concerns regarding iris\nattacks, has escalated recently. Inspired by neural style transfer, an advanced\ntechnique that leverages neural networks to separate content and style\nfeatures, we hypothesize that iris texture's style features provide a reliable\nfoundation for recognition and are more resilient to variations like rotation\nand perspective shifts than traditional approaches. Our experimental results\nsupport this hypothesis, showing a significantly higher classification accuracy\ncompared to conventional features. Further, we propose using neural style\ntransfer to mask identifiable iris style features, ensuring the protection of\nsensitive biometric information while maintaining the utility of eye images for\ntasks like eye segmentation and gaze estimation. This work opens new avenues\nfor iris-oriented, secure, and privacy-aware biometric systems.\n","authors":["Mengdi Wang","Efe Bozkir","Enkelejda Kasneci"],"pdf_url":"https://arxiv.org/pdf/2503.04707v1.pdf","comment":"14 pages main paper, 4 pages appendix"},{"id":"http://arxiv.org/abs/2503.04698v1","updated":"2025-03-06T18:46:10Z","published":"2025-03-06T18:46:10Z","title":"DEAL-YOLO: Drone-based Efficient Animal Localization using YOLO","summary":"  Although advances in deep learning and aerial surveillance technology are\nimproving wildlife conservation efforts, complex and erratic environmental\nconditions still pose a problem, requiring innovative solutions for\ncost-effective small animal detection. This work introduces DEAL-YOLO, a novel\napproach that improves small object detection in Unmanned Aerial Vehicle (UAV)\nimages by using multi-objective loss functions like Wise IoU (WIoU) and\nNormalized Wasserstein Distance (NWD), which prioritize pixels near the centre\nof the bounding box, ensuring smoother localization and reducing abrupt\ndeviations. Additionally, the model is optimized through efficient feature\nextraction with Linear Deformable (LD) convolutions, enhancing accuracy while\nmaintaining computational efficiency. The Scaled Sequence Feature Fusion (SSFF)\nmodule enhances object detection by effectively capturing inter-scale\nrelationships, improving feature representation, and boosting metrics through\noptimized multiscale fusion. Comparison with baseline models reveals high\nefficacy with up to 69.5\\% fewer parameters compared to vanilla Yolov8-N,\nhighlighting the robustness of the proposed modifications. Through this\napproach, our paper aims to facilitate the detection of endangered species,\nanimal population analysis, habitat monitoring, biodiversity research, and\nvarious other applications that enrich wildlife conservation efforts. DEAL-YOLO\nemploys a two-stage inference paradigm for object detection, refining selected\nregions to improve localization and confidence. This approach enhances\nperformance, especially for small instances with low objectness scores.\n","authors":["Aditya Prashant Naidu","Hem Gosalia","Ishaan Gakhar","Shaurya Singh Rathore","Krish Didwania","Ujjwal Verma"],"pdf_url":"https://arxiv.org/pdf/2503.04698v1.pdf","comment":"Accepted as a Poster at the ML4RS Workshop at ICLR 2025"},{"id":"http://arxiv.org/abs/2503.04688v1","updated":"2025-03-06T18:31:41Z","published":"2025-03-06T18:31:41Z","title":"Teach YOLO to Remember: A Self-Distillation Approach for Continual\n  Object Detection","summary":"  Real-time object detectors like YOLO achieve exceptional performance when\ntrained on large datasets for multiple epochs. However, in real-world scenarios\nwhere data arrives incrementally, neural networks suffer from catastrophic\nforgetting, leading to a loss of previously learned knowledge. To address this,\nprior research has explored strategies for Class Incremental Learning (CIL) in\nContinual Learning for Object Detection (CLOD), with most approaches focusing\non two-stage object detectors. However, existing work suggests that Learning\nwithout Forgetting (LwF) may be ineffective for one-stage anchor-free detectors\nlike YOLO due to noisy regression outputs, which risk transferring corrupted\nknowledge. In this work, we introduce YOLO LwF, a self-distillation approach\ntailored for YOLO-based continual object detection. We demonstrate that when\ncoupled with a replay memory, YOLO LwF significantly mitigates forgetting.\nCompared to previous approaches, it achieves state-of-the-art performance,\nimproving mAP by +2.1% and +2.9% on the VOC and COCO benchmarks, respectively.\n","authors":["Riccardo De Monte","Davide Dalle Pezze","Gian Antonio Susto"],"pdf_url":"https://arxiv.org/pdf/2503.04688v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.12360v2","updated":"2025-03-06T18:07:00Z","published":"2025-02-17T22:50:45Z","title":"Detecting Systematic Weaknesses in Vision Models along Predefined\n  Human-Understandable Dimensions","summary":"  Slice discovery methods (SDMs) are prominent algorithms for finding\nsystematic weaknesses in DNNs. They identify top-k semantically coherent\nslices/subsets of data where a DNN-under-test has low performance. For being\ndirectly useful, slices should be aligned with human-understandable and\nrelevant dimensions, which, for example, are defined by safety and domain\nexperts as part of the operational design domain (ODD). While SDMs can be\napplied effectively on structured data, their application on image data is\ncomplicated by the lack of semantic metadata. To address these issues, we\npresent an algorithm that combines foundation models for zero-shot image\nclassification to generate semantic metadata with methods for combinatorial\nsearch to find systematic weaknesses in images. In contrast to existing\napproaches, ours identifies weak slices that are in line with pre-defined\nhuman-understandable dimensions. As the algorithm includes foundation models,\nits intermediate and final results may not always be exact. Therefore, we\ninclude an approach to address the impact of noisy metadata. We validate our\nalgorithm on both synthetic and real-world datasets, demonstrating its ability\nto recover human-understandable systematic weaknesses. Furthermore, using our\napproach, we identify systematic weaknesses of multiple pre-trained and\npublicly available state-of-the-art computer vision DNNs.\n","authors":["Sujan Sai Gannamaneni","Rohil Prakash Rao","Michael Mock","Maram Akila","Stefan Wrobel"],"pdf_url":"https://arxiv.org/pdf/2502.12360v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04666v1","updated":"2025-03-06T17:59:29Z","published":"2025-03-06T17:59:29Z","title":"What Are You Doing? A Closer Look at Controllable Human Video Generation","summary":"  High-quality benchmarks are crucial for driving progress in machine learning\nresearch. However, despite the growing interest in video generation, there is\nno comprehensive dataset to evaluate human generation. Humans can perform a\nwide variety of actions and interactions, but existing datasets, like TikTok\nand TED-Talks, lack the diversity and complexity to fully capture the\ncapabilities of video generation models. We close this gap by introducing `What\nAre You Doing?' (WYD): a new benchmark for fine-grained evaluation of\ncontrollable image-to-video generation of humans. WYD consists of 1{,}544\ncaptioned videos that have been meticulously collected and annotated with 56\nfine-grained categories. These allow us to systematically measure performance\nacross 9 aspects of human generation, including actions, interactions and\nmotion. We also propose and validate automatic metrics that leverage our\nannotations and better capture human evaluations. Equipped with our dataset and\nmetrics, we perform in-depth analyses of seven state-of-the-art models in\ncontrollable image-to-video generation, showing how WYD provides novel insights\nabout the capabilities of these models. We release our data and code to drive\nforward progress in human video generation modeling at\nhttps://github.com/google-deepmind/wyd-benchmark.\n","authors":["Emanuele Bugliarello","Anurag Arnab","Roni Paiss","Pieter-Jan Kindermans","Cordelia Schmid"],"pdf_url":"https://arxiv.org/pdf/2503.04666v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04665v1","updated":"2025-03-06T17:58:55Z","published":"2025-03-06T17:58:55Z","title":"Implicit Neural Representation for Video and Image Super-Resolution","summary":"  We present a novel approach for super-resolution that utilizes implicit\nneural representation (INR) to effectively reconstruct and enhance\nlow-resolution videos and images. By leveraging the capacity of neural networks\nto implicitly encode spatial and temporal features, our method facilitates\nhigh-resolution reconstruction using only low-resolution inputs and a 3D\nhigh-resolution grid. This results in an efficient solution for both image and\nvideo super-resolution. Our proposed method, SR-INR, maintains consistent\ndetails across frames and images, achieving impressive temporal stability\nwithout relying on the computationally intensive optical flow or motion\nestimation typically used in other video super-resolution techniques. The\nsimplicity of our approach contrasts with the complexity of many existing\nmethods, making it both effective and efficient. Experimental evaluations show\nthat SR-INR delivers results on par with or superior to state-of-the-art\nsuper-resolution methods, while maintaining a more straightforward structure\nand reduced computational demands. These findings highlight the potential of\nimplicit neural representations as a powerful tool for reconstructing\nhigh-quality, temporally consistent video and image signals from low-resolution\ndata.\n","authors":["Mary Aiyetigbo","Wanqi Yuan","Feng Luo","Nianyi Li"],"pdf_url":"https://arxiv.org/pdf/2503.04665v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.09696v2","updated":"2025-03-06T17:45:33Z","published":"2025-02-13T18:59:11Z","title":"ZeroBench: An Impossible Visual Benchmark for Contemporary Large\n  Multimodal Models","summary":"  Large Multimodal Models (LMMs) exhibit major shortfalls when interpreting\nimages and, by some measures, have poorer spatial cognition than small children\nor animals. Despite this, they attain high scores on many popular visual\nbenchmarks, with headroom rapidly eroded by an ongoing surge of model progress.\nTo address this, there is a pressing need for difficult benchmarks that remain\nrelevant for longer. We take this idea to its limit by introducing ZeroBench-a\nlightweight visual reasoning benchmark that is entirely impossible for\ncontemporary frontier LMMs. Our benchmark consists of 100 manually curated\nquestions and 334 less difficult subquestions. We evaluate 20 LMMs on\nZeroBench, all of which score 0.0%, and rigorously analyse the errors. To\nencourage progress in visual understanding, we publicly release ZeroBench.\n","authors":["Jonathan Roberts","Mohammad Reza Taesiri","Ansh Sharma","Akash Gupta","Samuel Roberts","Ioana Croitoru","Simion-Vlad Bogolin","Jialu Tang","Florian Langer","Vyas Raina","Vatsal Raina","Hanyi Xiong","Vishaal Udandarao","Jingyi Lu","Shiyang Chen","Sam Purkis","Tianshuo Yan","Wenye Lin","Gyungin Shin","Qiaochu Yang","Anh Totti Nguyen","David I. Atkinson","Aaditya Baranwal","Alexandru Coca","Mikah Dang","Sebastian Dziadzio","Jakob D. Kunz","Kaiqu Liang","Alexander Lo","Brian Pulfer","Steven Walton","Charig Yang","Kai Han","Samuel Albanie"],"pdf_url":"https://arxiv.org/pdf/2502.09696v2.pdf","comment":"20 pages, 13 figures"},{"id":"http://arxiv.org/abs/2503.04653v1","updated":"2025-03-06T17:43:03Z","published":"2025-03-06T17:43:03Z","title":"RadIR: A Scalable Framework for Multi-Grained Medical Image Retrieval\n  via Radiology Report Mining","summary":"  Developing advanced medical imaging retrieval systems is challenging due to\nthe varying definitions of `similar images' across different medical contexts.\nThis challenge is compounded by the lack of large-scale, high-quality medical\nimaging retrieval datasets and benchmarks. In this paper, we propose a novel\nmethodology that leverages dense radiology reports to define image-wise\nsimilarity ordering at multiple granularities in a scalable and fully automatic\nmanner. Using this approach, we construct two comprehensive medical imaging\nretrieval datasets: MIMIC-IR for Chest X-rays and CTRATE-IR for CT scans,\nproviding detailed image-image ranking annotations conditioned on diverse\nanatomical structures. Furthermore, we develop two retrieval systems, RadIR-CXR\nand model-ChestCT, which demonstrate superior performance in traditional\nimage-image and image-report retrieval tasks. These systems also enable\nflexible, effective image retrieval conditioned on specific anatomical\nstructures described in text, achieving state-of-the-art results on 77 out of\n78 metrics.\n","authors":["Tengfei Zhang","Ziheng Zhao","Chaoyi Wu","Xiao Zhou","Ya Zhang","Yangfeng Wang","Weidi Xie"],"pdf_url":"https://arxiv.org/pdf/2503.04653v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04649v1","updated":"2025-03-06T17:35:37Z","published":"2025-03-06T17:35:37Z","title":"Transferable Foundation Models for Geometric Tasks on Point Cloud\n  Representations: Geometric Neural Operators","summary":"  We introduce methods for obtaining pretrained Geometric Neural Operators\n(GNPs) that can serve as basal foundation models for use in obtaining geometric\nfeatures. These can be used within data processing pipelines for machine\nlearning tasks and numerical methods. We show how our GNPs can be trained to\nlearn robust latent representations for the differential geometry of\npoint-clouds to provide estimates of metric, curvature, and other shape-related\nfeatures. We demonstrate how our pre-trained GNPs can be used (i) to estimate\nthe geometric properties of surfaces of arbitrary shape and topologies with\nrobustness in the presence of noise, (ii) to approximate solutions of geometric\npartial differential equations (PDEs) on manifolds, and (iii) to solve\nequations for shape deformations such as curvature driven flows. We also\nrelease a package of the codes and weights for using our pre-trained GNPs for\nprocessing point cloud representations. This allows for incorporating our\npre-trained GNPs as components for reuse within existing and new data\nprocessing pipelines. The GNPs also can be used as part of numerical solvers\ninvolving geometry or as part of methods for performing inference and other\ngeometric tasks.\n","authors":["Blaine Quackenbush","Paul J. Atzberger"],"pdf_url":"https://arxiv.org/pdf/2503.04649v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.04873v2","updated":"2025-03-06T17:35:19Z","published":"2025-01-08T23:07:10Z","title":"Back Home: A Machine Learning Approach to Seashell Classification and\n  Ecosystem Restoration","summary":"  In Costa Rica, an average of 5 tons of seashells are extracted from\necosystems annually. Confiscated seashells, cannot be returned to their\necosystems due to the lack of origin recognition. To address this issue, we\ndeveloped a convolutional neural network (CNN) specifically for seashell\nidentification. We built a dataset from scratch, consisting of approximately\n19000 images from the Pacific and Caribbean coasts. Using this dataset, the\nmodel achieved a classification accuracy exceeding 85%. The model has been\nintegrated into a user-friendly application, which has classified over 36,000\nseashells to date, delivering real-time results within 3 seconds per image. To\nfurther enhance the system's accuracy, an anomaly detection mechanism was\nincorporated to filter out irrelevant or anomalous inputs, ensuring only valid\nseashell images are processed.\n","authors":["Alexander Valverde","Luis Solano"],"pdf_url":"https://arxiv.org/pdf/2501.04873v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04643v1","updated":"2025-03-06T17:32:15Z","published":"2025-03-06T17:32:15Z","title":"Adaptive Prototype Learning for Multimodal Cancer Survival Analysis","summary":"  Leveraging multimodal data, particularly the integration of whole-slide\nhistology images (WSIs) and transcriptomic profiles, holds great promise for\nimproving cancer survival prediction. However, excessive redundancy in\nmultimodal data can degrade model performance. In this paper, we propose\nAdaptive Prototype Learning (APL), a novel and effective approach for\nmultimodal cancer survival analysis. APL adaptively learns representative\nprototypes in a data-driven manner, reducing redundancy while preserving\ncritical information. Our method employs two sets of learnable query vectors\nthat serve as a bridge between high-dimensional representations and survival\nprediction, capturing task-relevant features. Additionally, we introduce a\nmultimodal mixed self-attention mechanism to enable cross-modal interactions,\nfurther enhancing information fusion. Extensive experiments on five benchmark\ncancer datasets demonstrate the superiority of our approach over existing\nmethods. The code is available at https://github.com/HongLiuuuuu/APL.\n","authors":["Hong Liu","Haosen Yang","Federica Eduati","Josien P. W. Pluim","Mitko Veta"],"pdf_url":"https://arxiv.org/pdf/2503.04643v1.pdf","comment":"10 pages, 3 figures"},{"id":"http://arxiv.org/abs/2503.04641v1","updated":"2025-03-06T17:31:43Z","published":"2025-03-06T17:31:43Z","title":"Simulating the Real World: A Unified Survey of Multimodal Generative\n  Models","summary":"  Understanding and replicating the real world is a critical challenge in\nArtificial General Intelligence (AGI) research. To achieve this, many existing\napproaches, such as world models, aim to capture the fundamental principles\ngoverning the physical world, enabling more accurate simulations and meaningful\ninteractions. However, current methods often treat different modalities,\nincluding 2D (images), videos, 3D, and 4D representations, as independent\ndomains, overlooking their interdependencies. Additionally, these methods\ntypically focus on isolated dimensions of reality without systematically\nintegrating their connections. In this survey, we present a unified survey for\nmultimodal generative models that investigate the progression of data\ndimensionality in real-world simulation. Specifically, this survey starts from\n2D generation (appearance), then moves to video (appearance+dynamics) and 3D\ngeneration (appearance+geometry), and finally culminates in 4D generation that\nintegrate all dimensions. To the best of our knowledge, this is the first\nattempt to systematically unify the study of 2D, video, 3D and 4D generation\nwithin a single framework. To guide future research, we provide a comprehensive\nreview of datasets, evaluation metrics and future directions, and fostering\ninsights for newcomers. This survey serves as a bridge to advance the study of\nmultimodal generative models and real-world simulation within a unified\nframework.\n","authors":["Yuqi Hu","Longguang Wang","Xian Liu","Ling-Hao Chen","Yuwei Guo","Yukai Shi","Ce Liu","Anyi Rao","Zeyu Wang","Hui Xiong"],"pdf_url":"https://arxiv.org/pdf/2503.04641v1.pdf","comment":"Repository for the related papers at\n  https://github.com/ALEEEHU/World-Simulator"},{"id":"http://arxiv.org/abs/2503.04639v1","updated":"2025-03-06T17:28:48Z","published":"2025-03-06T17:28:48Z","title":"Enhancing SAM with Efficient Prompting and Preference Optimization for\n  Semi-supervised Medical Image Segmentation","summary":"  Foundational models such as the Segment Anything Model (SAM) are gaining\ntraction in medical imaging segmentation, supporting multiple downstream tasks.\nHowever, such models are supervised in nature, still relying on large annotated\ndatasets or prompts supplied by experts. Conventional techniques such as active\nlearning to alleviate such limitations are limited in scope and still\nnecessitate continuous human involvement and complex domain knowledge for label\nrefinement or establishing reward ground truth. To address these challenges, we\npropose an enhanced Segment Anything Model (SAM) framework that utilizes\nannotation-efficient prompts generated in a fully unsupervised fashion, while\nstill capturing essential semantic, location, and shape information through\ncontrastive language-image pretraining and visual question answering. We adopt\nthe direct preference optimization technique to design an optimal policy that\nenables the model to generate high-fidelity segmentations with simple ratings\nor rankings provided by a virtual annotator simulating the human annotation\nprocess. State-of-the-art performance of our framework in tasks such as lung\nsegmentation, breast tumor segmentation, and organ segmentation across various\nmodalities, including X-ray, ultrasound, and abdominal CT, justifies its\neffectiveness in low-annotation data scenarios.\n","authors":["Aishik Konwer","Zhijian Yang","Erhan Bas","Cao Xiao","Prateek Prasanna","Parminder Bhatia","Taha Kass-Hout"],"pdf_url":"https://arxiv.org/pdf/2503.04639v1.pdf","comment":"Accepted to CVPR 2025"},{"id":"http://arxiv.org/abs/2503.04635v1","updated":"2025-03-06T17:23:55Z","published":"2025-03-06T17:23:55Z","title":"3HANDS Dataset: Learning from Humans for Generating Naturalistic\n  Handovers with Supernumerary Robotic Limbs","summary":"  Supernumerary robotic limbs (SRLs) are robotic structures integrated closely\nwith the user's body, which augment human physical capabilities and necessitate\nseamless, naturalistic human-machine interaction. For effective assistance in\nphysical tasks, enabling SRLs to hand over objects to humans is crucial. Yet,\ndesigning heuristic-based policies for robots is time-consuming, difficult to\ngeneralize across tasks, and results in less human-like motion. When trained\nwith proper datasets, generative models are powerful alternatives for creating\nnaturalistic handover motions. We introduce 3HANDS, a novel dataset of object\nhandover interactions between a participant performing a daily activity and\nanother participant enacting a hip-mounted SRL in a naturalistic manner. 3HANDS\ncaptures the unique characteristics of SRL interactions: operating in intimate\npersonal space with asymmetric object origins, implicit motion synchronization,\nand the user's engagement in a primary task during the handover. To demonstrate\nthe effectiveness of our dataset, we present three models: one that generates\nnaturalistic handover trajectories, another that determines the appropriate\nhandover endpoints, and a third that predicts the moment to initiate a\nhandover. In a user study (N=10), we compare the handover interaction performed\nwith our method compared to a baseline. The findings show that our method was\nperceived as significantly more natural, less physically demanding, and more\ncomfortable.\n","authors":["Artin Saberpour Abadian","Yi-Chi Liao","Ata Otaran","Rishabh Dabral","Marie Muehlhaus","Christian Theobalt","Martin Schmitz","Jürgen Steimle"],"pdf_url":"https://arxiv.org/pdf/2503.04635v1.pdf","comment":"CHI '25"},{"id":"http://arxiv.org/abs/2503.04634v1","updated":"2025-03-06T17:21:12Z","published":"2025-03-06T17:21:12Z","title":"PathoPainter: Augmenting Histopathology Segmentation via Tumor-aware\n  Inpainting","summary":"  Tumor segmentation plays a critical role in histopathology, but it requires\ncostly, fine-grained image-mask pairs annotated by pathologists. Thus,\nsynthesizing histopathology data to expand the dataset is highly desirable.\nPrevious works suffer from inaccuracies and limited diversity in image-mask\npairs, both of which affect training segmentation, particularly in small-scale\ndatasets and the inherently complex nature of histopathology images. To address\nthis challenge, we propose PathoPainter, which reformulates image-mask pair\ngeneration as a tumor inpainting task. Specifically, our approach preserves the\nbackground while inpainting the tumor region, ensuring precise alignment\nbetween the generated image and its corresponding mask. To enhance dataset\ndiversity while maintaining biological plausibility, we incorporate a sampling\nmechanism that conditions tumor inpainting on regional embeddings from a\ndifferent image. Additionally, we introduce a filtering strategy to exclude\nuncertain synthetic regions, further improving the quality of the generated\ndata. Our comprehensive evaluation spans multiple datasets featuring diverse\ntumor types and various training data scales. As a result, segmentation\nimproved significantly with our synthetic data, surpassing existing\nsegmentation data synthesis approaches, e.g., 75.69% -> 77.69% on CAMELYON16.\nThe code is available at https://github.com/HongLiuuuuu/PathoPainter.\n","authors":["Hong Liu","Haosen Yang","Evi M. C. Huijben","Mark Schuiveling","Ruisheng Su","Josien P. W. Pluim","Mitko Veta"],"pdf_url":"https://arxiv.org/pdf/2503.04634v1.pdf","comment":"10 pages, 3 figures"},{"id":"http://arxiv.org/abs/2503.00897v3","updated":"2025-03-06T17:19:22Z","published":"2025-03-02T13:43:53Z","title":"A Simple and Effective Reinforcement Learning Method for Text-to-Image\n  Diffusion Fine-tuning","summary":"  Reinforcement learning (RL)-based fine-tuning has emerged as a powerful\napproach for aligning diffusion models with black-box objectives. Proximal\npolicy optimization (PPO) is the most popular choice of method for policy\noptimization. While effective in terms of performance, PPO is highly sensitive\nto hyper-parameters and involves substantial computational overhead. REINFORCE,\non the other hand, mitigates some computational complexities such as high\nmemory overhead and sensitive hyper-parameter tuning, but has suboptimal\nperformance due to high-variance and sample inefficiency. While the variance of\nthe REINFORCE can be reduced by sampling multiple actions per input prompt and\nusing a baseline correction term, it still suffers from sample inefficiency. To\naddress these challenges, we systematically analyze the\nefficiency-effectiveness trade-off between REINFORCE and PPO, and propose\nleave-one-out PPO (LOOP), a novel RL for diffusion fine-tuning method. LOOP\ncombines variance reduction techniques from REINFORCE, such as sampling\nmultiple actions per input prompt and a baseline correction term, with the\nrobustness and sample efficiency of PPO via clipping and importance sampling.\nOur results demonstrate that LOOP effectively improves diffusion models on\nvarious black-box objectives, and achieves a better balance between\ncomputational efficiency and performance.\n","authors":["Shashank Gupta","Chaitanya Ahuja","Tsung-Yu Lin","Sreya Dutta Roy","Harrie Oosterhuis","Maarten de Rijke","Satya Narayan Shukla"],"pdf_url":"https://arxiv.org/pdf/2503.00897v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.12833v2","updated":"2025-03-06T17:18:49Z","published":"2024-05-21T14:37:35Z","title":"A Survey of Deep Learning-based Radiology Report Generation Using\n  Multimodal Data","summary":"  Automatic radiology report generation can alleviate the workload for\nphysicians and minimize regional disparities in medical resources, therefore\nbecoming an important topic in the medical image analysis field. It is a\nchallenging task, as the computational model needs to mimic physicians to\nobtain information from multi-modal input data (i.e., medical images, clinical\ninformation, medical knowledge, etc.), and produce comprehensive and accurate\nreports. Recently, numerous works have emerged to address this issue using\ndeep-learning-based methods, such as transformers, contrastive learning, and\nknowledge-base construction. This survey summarizes the key techniques\ndeveloped in the most recent works and proposes a general workflow for\ndeep-learning-based report generation with five main components, including\nmulti-modality data acquisition, data preparation, feature learning, feature\nfusion and interaction, and report generation. The state-of-the-art methods for\neach of these components are highlighted. Additionally, we summarize the latest\ndevelopments in large model-based methods and model explainability, along with\npublic datasets, evaluation methods, current challenges, and future directions\nin this field. We have also conducted a quantitative comparison between\ndifferent methods in the same experimental setting. This is the most up-to-date\nsurvey that focuses on multi-modality inputs and data fusion for radiology\nreport generation. The aim is to provide comprehensive and rich information for\nresearchers interested in automatic clinical report generation and medical\nimage analysis, especially when using multimodal inputs, and to assist them in\ndeveloping new algorithms to advance the field.\n","authors":["Xinyi Wang","Grazziela Figueredo","Ruizhe Li","Wei Emma Zhang","Weitong Chen","Xin Chen"],"pdf_url":"https://arxiv.org/pdf/2405.12833v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.11919v3","updated":"2025-03-06T17:12:48Z","published":"2024-09-18T12:32:25Z","title":"LLM-wrapper: Black-Box Semantic-Aware Adaptation of Vision-Language\n  Models for Referring Expression Comprehension","summary":"  Vision Language Models (VLMs) have demonstrated remarkable capabilities in\nvarious open-vocabulary tasks, yet their zero-shot performance lags behind\ntask-specific fine-tuned models, particularly in complex tasks like Referring\nExpression Comprehension (REC). Fine-tuning usually requires 'white-box' access\nto the model's architecture and weights, which is not always feasible due to\nproprietary or privacy concerns. In this work, we propose LLM-wrapper, a method\nfor 'black-box' adaptation of VLMs for the REC task using Large Language Models\n(LLMs). LLM-wrapper capitalizes on the reasoning abilities of LLMs, improved\nwith a light fine-tuning, to select the most relevant bounding box matching the\nreferring expression, from candidates generated by a zero-shot black-box VLM.\nOur approach offers several advantages: it enables the adaptation of\nclosed-source models without needing access to their internal workings, it is\nversatile as it works with any VLM, it transfers to new VLMs and datasets, and\nit allows for the adaptation of an ensemble of VLMs. We evaluate LLM-wrapper on\nmultiple datasets using different VLMs and LLMs, demonstrating significant\nperformance improvements and highlighting the versatility of our method. While\nLLM-wrapper is not meant to directly compete with standard white-box\nfine-tuning, it offers a practical and effective alternative for black-box VLM\nadaptation. Code and checkpoints are available at\nhttps://github.com/valeoai/LLM_wrapper .\n","authors":["Amaia Cardiel","Eloi Zablocki","Elias Ramzi","Oriane Siméoni","Matthieu Cord"],"pdf_url":"https://arxiv.org/pdf/2409.11919v3.pdf","comment":"LLM-wrapper (v3) is published as a conference paper at ICLR 2025. (v1\n  was presented at EVAL-FoMo workshop, ECCV 2024.)"},{"id":"http://arxiv.org/abs/2410.05116v2","updated":"2025-03-06T17:11:55Z","published":"2024-10-07T15:12:01Z","title":"Human-Feedback Efficient Reinforcement Learning for Online Diffusion\n  Model Finetuning","summary":"  Controllable generation through Stable Diffusion (SD) fine-tuning aims to\nimprove fidelity, safety, and alignment with human guidance. Existing\nreinforcement learning from human feedback methods usually rely on predefined\nheuristic reward functions or pretrained reward models built on large-scale\ndatasets, limiting their applicability to scenarios where collecting such data\nis costly or difficult. To effectively and efficiently utilize human feedback,\nwe develop a framework, HERO, which leverages online human feedback collected\non the fly during model learning. Specifically, HERO features two key\nmechanisms: (1) Feedback-Aligned Representation Learning, an online training\nmethod that captures human feedback and provides informative learning signals\nfor fine-tuning, and (2) Feedback-Guided Image Generation, which involves\ngenerating images from SD's refined initialization samples, enabling faster\nconvergence towards the evaluator's intent. We demonstrate that HERO is 4x more\nefficient in online feedback for body part anomaly correction compared to the\nbest existing method. Additionally, experiments show that HERO can effectively\nhandle tasks like reasoning, counting, personalization, and reducing NSFW\ncontent with only 0.5K online feedback.\n","authors":["Ayano Hiranaka","Shang-Fu Chen","Chieh-Hsin Lai","Dongjun Kim","Naoki Murata","Takashi Shibuya","Wei-Hsiang Liao","Shao-Hua Sun","Yuki Mitsufuji"],"pdf_url":"https://arxiv.org/pdf/2410.05116v2.pdf","comment":"Published in International Conference on Learning Representations\n  (ICLR) 2025"},{"id":"http://arxiv.org/abs/2503.02394v3","updated":"2025-03-06T17:10:24Z","published":"2025-03-04T08:35:01Z","title":"BHViT: Binarized Hybrid Vision Transformer","summary":"  Model binarization has made significant progress in enabling real-time and\nenergy-efficient computation for convolutional neural networks (CNN), offering\na potential solution to the deployment challenges faced by Vision Transformers\n(ViTs) on edge devices. However, due to the structural differences between CNN\nand Transformer architectures, simply applying binary CNN strategies to the ViT\nmodels will lead to a significant performance drop. To tackle this challenge,\nwe propose BHViT, a binarization-friendly hybrid ViT architecture and its full\nbinarization model with the guidance of three important observations.\nInitially, BHViT utilizes the local information interaction and hierarchical\nfeature aggregation technique from coarse to fine levels to address redundant\ncomputations stemming from excessive tokens. Then, a novel module based on\nshift operations is proposed to enhance the performance of the binary\nMultilayer Perceptron (MLP) module without significantly increasing\ncomputational overhead. In addition, an innovative attention matrix\nbinarization method based on quantization decomposition is proposed to evaluate\nthe token's importance in the binarized attention matrix. Finally, we propose a\nregularization loss to address the inadequate optimization caused by the\nincompatibility between the weight oscillation in the binary layers and the\nAdam Optimizer. Extensive experimental results demonstrate that our proposed\nalgorithm achieves SOTA performance among binary ViT methods.\n","authors":["Tian Gao","Zhiyuan Zhang","Yu Zhang","Huajun Liu","Kaijie Yin","Chengzhong Xu","Hui Kong"],"pdf_url":"https://arxiv.org/pdf/2503.02394v3.pdf","comment":"Accepted by CVPR2025"},{"id":"http://arxiv.org/abs/2407.18125v3","updated":"2025-03-06T17:03:35Z","published":"2024-07-25T15:32:59Z","title":"Self-supervised pre-training with diffusion model for few-shot landmark\n  detection in x-ray images","summary":"  Deep neural networks have been extensively applied in the medical domain for\nvarious tasks, including image classification, segmentation, and landmark\ndetection. However, their application is often hindered by data scarcity, both\nin terms of available annotations and images. This study introduces a novel\napplication of denoising diffusion probabilistic models (DDPMs) to the landmark\ndetection task, specifically addressing the challenge of limited annotated data\nin x-ray imaging. Our key innovation lies in leveraging DDPMs for\nself-supervised pre-training in landmark detection, a previously unexplored\napproach in this domain. This method enables accurate landmark detection with\nminimal annotated training data (as few as 50 images), surpassing both ImageNet\nsupervised pre-training and traditional self-supervised techniques across three\npopular x-ray benchmark datasets. To our knowledge, this work represents the\nfirst application of diffusion models for self-supervised learning in landmark\ndetection, which may offer a valuable pre-training approach in few-shot\nregimes, for mitigating data scarcity.\n","authors":["Roberto Di Via","Francesca Odone","Vito Paolo Pastore"],"pdf_url":"https://arxiv.org/pdf/2407.18125v3.pdf","comment":"Accepted at WACV 2025"},{"id":"http://arxiv.org/abs/2503.04606v1","updated":"2025-03-06T16:53:14Z","published":"2025-03-06T16:53:14Z","title":"The Best of Both Worlds: Integrating Language Models and Diffusion\n  Models for Video Generation","summary":"  Recent advancements in text-to-video (T2V) generation have been driven by two\ncompeting paradigms: autoregressive language models and diffusion models.\nHowever, each paradigm has intrinsic limitations: language models struggle with\nvisual quality and error accumulation, while diffusion models lack semantic\nunderstanding and causal modeling. In this work, we propose LanDiff, a hybrid\nframework that synergizes the strengths of both paradigms through\ncoarse-to-fine generation. Our architecture introduces three key innovations:\n(1) a semantic tokenizer that compresses 3D visual features into compact 1D\ndiscrete representations through efficient semantic compression, achieving a\n$\\sim$14,000$\\times$ compression ratio; (2) a language model that generates\nsemantic tokens with high-level semantic relationships; (3) a streaming\ndiffusion model that refines coarse semantics into high-fidelity videos.\nExperiments show that LanDiff, a 5B model, achieves a score of 85.43 on the\nVBench T2V benchmark, surpassing the state-of-the-art open-source models\nHunyuan Video (13B) and other commercial models such as Sora, Keling, and\nHailuo. Furthermore, our model also achieves state-of-the-art performance in\nlong video generation, surpassing other open-source models in this field. Our\ndemo can be viewed at https://landiff.github.io/.\n","authors":["Aoxiong Yin","Kai Shen","Yichong Leng","Xu Tan","Xinyu Zhou","Juncheng Li","Siliang Tang"],"pdf_url":"https://arxiv.org/pdf/2503.04606v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.17494v4","updated":"2025-03-06T16:43:10Z","published":"2024-10-23T01:25:25Z","title":"Enhancing Multimodal Medical Image Classification using Cross-Graph\n  Modal Contrastive Learning","summary":"  The classification of medical images is a pivotal aspect of disease\ndiagnosis, often enhanced by deep learning techniques. However, traditional\napproaches typically focus on unimodal medical image data, neglecting the\nintegration of diverse non-image patient data. This paper proposes a novel\nCross-Graph Modal Contrastive Learning (CGMCL) framework for multimodal\nstructured data from different data domains to improve medical image\nclassification. The model effectively integrates both image and non-image data\nby constructing cross-modality graphs and leveraging contrastive learning to\nalign multimodal features in a shared latent space. An inter-modality feature\nscaling module further optimizes the representation learning process by\nreducing the gap between heterogeneous modalities. The proposed approach is\nevaluated on two datasets: a Parkinson's disease (PD) dataset and a public\nmelanoma dataset. Results demonstrate that CGMCL outperforms conventional\nunimodal methods in accuracy, interpretability, and early disease prediction.\nAdditionally, the method shows superior performance in multi-class melanoma\nclassification. The CGMCL framework provides valuable insights into medical\nimage classification while offering improved disease interpretability and\npredictive capabilities.\n","authors":["Jun-En Ding","Chien-Chin Hsu","Chi-Hsiang Chu","Shuqiang Wang","Feng Liu"],"pdf_url":"https://arxiv.org/pdf/2410.17494v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04592v1","updated":"2025-03-06T16:31:34Z","published":"2025-03-06T16:31:34Z","title":"A Benchmark for Multi-Lingual Vision-Language Learning in Remote Sensing\n  Image Captioning","summary":"  Remote Sensing Image Captioning (RSIC) is a cross-modal field bridging vision\nand language, aimed at automatically generating natural language descriptions\nof features and scenes in remote sensing imagery. Despite significant advances\nin developing sophisticated methods and large-scale datasets for training\nvision-language models (VLMs), two critical challenges persist: the scarcity of\nnon-English descriptive datasets and the lack of multilingual capability\nevaluation for models. These limitations fundamentally impede the progress and\npractical deployment of RSIC, particularly in the era of large VLMs. To address\nthese challenges, this paper presents several significant contributions to the\nfield. First, we introduce and analyze BRSIC (Bilingual Remote Sensing Image\nCaptioning), a comprehensive bilingual dataset that enriches three established\nEnglish RSIC datasets with Chinese descriptions, encompassing 13,634 images\npaired with 68,170 bilingual captions. Building upon this foundation, we\ndevelop a systematic evaluation framework that addresses the prevalent\ninconsistency in evaluation protocols, enabling rigorous assessment of model\nperformance through standardized retraining procedures on BRSIC. Furthermore,\nwe present an extensive empirical study of eight state-of-the-art large\nvision-language models (LVLMs), examining their capabilities across multiple\nparadigms including zero-shot inference, supervised fine-tuning, and\nmulti-lingual training. This comprehensive evaluation provides crucial insights\ninto the strengths and limitations of current LVLMs in handling multilingual\nremote sensing tasks. Additionally, our cross-dataset transfer experiments\nreveal interesting findings. The code and data will be available at\nhttps://github.com/mrazhou/BRSIC.\n","authors":["Qing Zhou","Tao Yang","Junyu Gao","Weiping Ni","Junzheng Wu","Qi Wang"],"pdf_url":"https://arxiv.org/pdf/2503.04592v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03663v2","updated":"2025-03-06T16:25:37Z","published":"2025-03-05T16:52:34Z","title":"LION-FS: Fast & Slow Video-Language Thinker as Online Video Assistant","summary":"  First-person video assistants are highly anticipated to enhance our daily\nlives through online video dialogue. However, existing online video assistants\noften sacrifice assistant efficacy for real-time efficiency by processing\nlow-frame-rate videos with coarse-grained visual features.To overcome the\ntrade-off between efficacy and efficiency, we propose \"Fast & Slow\nVideo-Language Thinker\" as an onLIne videO assistaNt, LION-FS, achieving\nreal-time, proactive, temporally accurate, and contextually precise responses.\nLION-FS adopts a two-stage optimization strategy: 1)Fast Path: Routing-Based\nResponse Determination evaluates frame-by-frame whether an immediate response\nis necessary. To enhance response determination accuracy and handle higher\nframe-rate inputs efficiently, we employ Token Aggregation Routing to\ndynamically fuse spatiotemporal features without increasing token numbers,\nwhile utilizing Token Dropping Routing to eliminate redundant features. 2)Slow\nPath: Multi-granularity Keyframe Augmentation optimizes keyframes during\nresponse generation. To provide comprehensive and detailed responses beyond\natomic actions constrained by training data, fine-grained spatial features and\nhuman-environment interaction features are extracted through multi-granular\npooling. These features are further integrated into a meticulously designed\nmultimodal Thinking Template to guide more precise response generation.\nComprehensive evaluations on online video tasks demonstrate that LION-FS\nachieves state-of-the-art efficacy and efficiency.\n","authors":["Wei Li","Bing Hu","Rui Shao","Leyang Shen","Liqiang Nie"],"pdf_url":"https://arxiv.org/pdf/2503.03663v2.pdf","comment":"Accept to CVPR 2025, Project page:\n  https://github.com/JiuTian-VL/LION-FS"},{"id":"http://arxiv.org/abs/2503.04565v1","updated":"2025-03-06T15:53:42Z","published":"2025-03-06T15:53:42Z","title":"Omnidirectional Multi-Object Tracking","summary":"  Panoramic imagery, with its 360{\\deg} field of view, offers comprehensive\ninformation to support Multi-Object Tracking (MOT) in capturing spatial and\ntemporal relationships of surrounding objects. However, most MOT algorithms are\ntailored for pinhole images with limited views, impairing their effectiveness\nin panoramic settings. Additionally, panoramic image distortions, such as\nresolution loss, geometric deformation, and uneven lighting, hinder direct\nadaptation of existing MOT methods, leading to significant performance\ndegradation. To address these challenges, we propose OmniTrack, an\nomnidirectional MOT framework that incorporates Tracklet Management to\nintroduce temporal cues, FlexiTrack Instances for object localization and\nassociation, and the CircularStatE Module to alleviate image and geometric\ndistortions. This integration enables tracking in large field-of-view\nscenarios, even under rapid sensor motion. To mitigate the lack of panoramic\nMOT datasets, we introduce the QuadTrack dataset--a comprehensive panoramic\ndataset collected by a quadruped robot, featuring diverse challenges such as\nwide fields of view, intense motion, and complex environments. Extensive\nexperiments on the public JRDB dataset and the newly introduced QuadTrack\nbenchmark demonstrate the state-of-the-art performance of the proposed\nframework. OmniTrack achieves a HOTA score of 26.92% on JRDB, representing an\nimprovement of 3.43%, and further achieves 23.45% on QuadTrack, surpassing the\nbaseline by 6.81%. The dataset and code will be made publicly available at\nhttps://github.com/xifen523/OmniTrack.\n","authors":["Kai Luo","Hao Shi","Sheng Wu","Fei Teng","Mengfei Duan","Chang Huang","Yuhang Wang","Kaiwei Wang","Kailun Yang"],"pdf_url":"https://arxiv.org/pdf/2503.04565v1.pdf","comment":"Accepted to CVPR 2025. The dataset and code will be made publicly\n  available at https://github.com/xifen523/OmniTrack"},{"id":"http://arxiv.org/abs/2502.09990v2","updated":"2025-03-06T15:38:31Z","published":"2025-02-14T08:22:51Z","title":"X-Boundary: Establishing Exact Safety Boundary to Shield LLMs from\n  Multi-Turn Jailbreaks without Compromising Usability","summary":"  Despite the rapid development of safety alignment techniques for LLMs,\ndefending against multi-turn jailbreaks is still a challenging task. In this\npaper, we conduct a comprehensive comparison, revealing that some existing\ndefense methods can improve the robustness of LLMs against multi-turn\njailbreaks but compromise usability, i.e., reducing general capabilities or\ncausing the over-refusal problem. From the perspective of mechanism\ninterpretability of LLMs, we discover that these methods fail to establish a\nboundary that exactly distinguishes safe and harmful feature representations.\nTherefore, boundary-safe representations close to harmful representations are\ninevitably disrupted, leading to a decline in usability. To address this issue,\nwe propose X-Boundary to push harmful representations away from boundary-safe\nrepresentations and obtain an exact distinction boundary. In this way, harmful\nrepresentations can be precisely erased without disrupting safe ones.\nExperimental results show that X-Boundary achieves state-of-the-art defense\nperformance against multi-turn jailbreaks, while reducing the over-refusal rate\nby about 20% and maintaining nearly complete general capability. Furthermore,\nwe theoretically prove and empirically verify that X-Boundary can accelerate\nthe convergence process during training. Please see our code at:\nhttps://github.com/AI45Lab/X-Boundary.\n","authors":["Xiaoya Lu","Dongrui Liu","Yi Yu","Luxin Xu","Jing Shao"],"pdf_url":"https://arxiv.org/pdf/2502.09990v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04545v1","updated":"2025-03-06T15:33:19Z","published":"2025-03-06T15:33:19Z","title":"ViT-VS: On the Applicability of Pretrained Vision Transformer Features\n  for Generalizable Visual Servoing","summary":"  Visual servoing enables robots to precisely position their end-effector\nrelative to a target object. While classical methods rely on hand-crafted\nfeatures and thus are universally applicable without task-specific training,\nthey often struggle with occlusions and environmental variations, whereas\nlearning-based approaches improve robustness but typically require extensive\ntraining. We present a visual servoing approach that leverages pretrained\nvision transformers for semantic feature extraction, combining the advantages\nof both paradigms while also being able to generalize beyond the provided\nsample. Our approach achieves full convergence in unperturbed scenarios and\nsurpasses classical image-based visual servoing by up to 31.2\\% relative\nimprovement in perturbed scenarios. Even the convergence rates of\nlearning-based methods are matched despite requiring no task- or\nobject-specific training. Real-world evaluations confirm robust performance in\nend-effector positioning, industrial box manipulation, and grasping of unseen\nobjects using only a reference from the same category. Our code and simulation\nenvironment are available at: https://alessandroscherl.github.io/ViT-VS/\n","authors":["Alessandro Scherl","Stefan Thalhammer","Bernhard Neuberger","Wilfried Wöber","José Gracía-Rodríguez"],"pdf_url":"https://arxiv.org/pdf/2503.04545v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.00299v2","updated":"2025-03-06T15:32:33Z","published":"2024-10-01T00:43:45Z","title":"GSPR: Multimodal Place Recognition Using 3D Gaussian Splatting for\n  Autonomous Driving","summary":"  Place recognition is a crucial component that enables autonomous vehicles to\nobtain localization results in GPS-denied environments. In recent years,\nmultimodal place recognition methods have gained increasing attention. They\novercome the weaknesses of unimodal sensor systems by leveraging complementary\ninformation from different modalities. However, most existing methods explore\ncross-modality correlations through feature-level or descriptor-level fusion,\nsuffering from a lack of interpretability. Conversely, the recently proposed 3D\nGaussian Splatting provides a new perspective on multimodal fusion by\nharmonizing different modalities into an explicit scene representation. In this\npaper, we propose a 3D Gaussian Splatting-based multimodal place recognition\nnetwork dubbed GSPR. It explicitly combines multi-view RGB images and LiDAR\npoint clouds into a spatio-temporally unified scene representation with the\nproposed Multimodal Gaussian Splatting. A network composed of 3D graph\nconvolution and transformer is designed to extract spatio-temporal features and\nglobal descriptors from the Gaussian scenes for place recognition. Extensive\nevaluations on three datasets demonstrate that our method can effectively\nleverage complementary strengths of both multi-view cameras and LiDAR,\nachieving SOTA place recognition performance while maintaining solid\ngeneralization ability. Our open-source code will be released at\nhttps://github.com/QiZS-BIT/GSPR.\n","authors":["Zhangshuo Qi","Junyi Ma","Jingyi Xu","Zijie Zhou","Luqi Cheng","Guangming Xiong"],"pdf_url":"https://arxiv.org/pdf/2410.00299v2.pdf","comment":"8 pages, 6 figures"},{"id":"http://arxiv.org/abs/2412.07775v2","updated":"2025-03-06T15:15:58Z","published":"2024-12-10T18:59:58Z","title":"Efficient Diversity-Preserving Diffusion Alignment via Gradient-Informed\n  GFlowNets","summary":"  While one commonly trains large diffusion models by collecting datasets on\ntarget downstream tasks, it is often desired to align and finetune pretrained\ndiffusion models with some reward functions that are either designed by experts\nor learned from small-scale datasets. Existing post-training methods for reward\nfinetuning of diffusion models typically suffer from lack of diversity in\ngenerated samples, lack of prior preservation, and/or slow convergence in\nfinetuning. Inspired by recent successes in generative flow networks\n(GFlowNets), a class of probabilistic models that sample with the unnormalized\ndensity of a reward function, we propose a novel GFlowNet method dubbed\nNabla-GFlowNet (abbreviated as \\methodname), the first GFlowNet method that\nleverages the rich signal in reward gradients, together with an objective\ncalled \\graddb plus its variant \\resgraddb designed for prior-preserving\ndiffusion finetuning. We show that our proposed method achieves fast yet\ndiversity- and prior-preserving finetuning of Stable Diffusion, a large-scale\ntext-conditioned image diffusion model, on different realistic reward\nfunctions.\n","authors":["Zhen Liu","Tim Z. Xiao","Weiyang Liu","Yoshua Bengio","Dinghuai Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.07775v2.pdf","comment":"Technical Report (35 pages, 31 figures), Accepted at ICLR 2025"},{"id":"http://arxiv.org/abs/2503.04522v1","updated":"2025-03-06T15:08:34Z","published":"2025-03-06T15:08:34Z","title":"In-Context Reverse Classification Accuracy: Efficient Estimation of\n  Segmentation Quality without Ground-Truth","summary":"  Assessing the quality of automatic image segmentation is crucial in clinical\npractice, but often very challenging due to the limited availability of ground\ntruth annotations. In this paper, we introduce In-Context Reverse\nClassification Accuracy (In-Context RCA), a novel framework for automatically\nestimating segmentation quality in the absence of ground-truth annotations. By\nleveraging recent in-context learning segmentation models and incorporating\nretrieval-augmentation techniques to select the most relevant reference images,\nour approach enables efficient quality estimation with minimal reference data.\nValidated across diverse medical imaging modalities, our method demonstrates\nrobust performance and computational efficiency, offering a promising solution\nfor automated quality control in clinical workflows, where fast and reliable\nsegmentation assessment is essential. The code is available at\nhttps://github.com/mcosarinsky/In-Context-RCA.\n","authors":["Matias Cosarinsky","Ramiro Billot","Lucas Mansilla","Gabriel Gimenez","Nicolas Gaggión","Guanghui Fu","Enzo Ferrante"],"pdf_url":"https://arxiv.org/pdf/2503.04522v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.05874v2","updated":"2025-03-06T15:02:33Z","published":"2025-02-09T12:23:40Z","title":"MMGDreamer: Mixed-Modality Graph for Geometry-Controllable 3D Indoor\n  Scene Generation","summary":"  Controllable 3D scene generation has extensive applications in virtual\nreality and interior design, where the generated scenes should exhibit high\nlevels of realism and controllability in terms of geometry. Scene graphs\nprovide a suitable data representation that facilitates these applications.\nHowever, current graph-based methods for scene generation are constrained to\ntext-based inputs and exhibit insufficient adaptability to flexible user\ninputs, hindering the ability to precisely control object geometry. To address\nthis issue, we propose MMGDreamer, a dual-branch diffusion model for scene\ngeneration that incorporates a novel Mixed-Modality Graph, visual enhancement\nmodule, and relation predictor. The mixed-modality graph allows object nodes to\nintegrate textual and visual modalities, with optional relationships between\nnodes. It enhances adaptability to flexible user inputs and enables meticulous\ncontrol over the geometry of objects in the generated scenes. The visual\nenhancement module enriches the visual fidelity of text-only nodes by\nconstructing visual representations using text embeddings. Furthermore, our\nrelation predictor leverages node representations to infer absent relationships\nbetween nodes, resulting in more coherent scene layouts. Extensive experimental\nresults demonstrate that MMGDreamer exhibits superior control of object\ngeometry, achieving state-of-the-art scene generation performance. Project\npage: https://yangzhifeio.github.io/project/MMGDreamer.\n","authors":["Zhifei Yang","Keyang Lu","Chao Zhang","Jiaxing Qi","Hanqi Jiang","Ruifei Ma","Shenglin Yin","Yifan Xu","Mingzhe Xing","Zhen Xiao","Jieyi Long","Xiangde Liu","Guangyao Zhai"],"pdf_url":"https://arxiv.org/pdf/2502.05874v2.pdf","comment":"Accepted by AAAI 2025 Main Track"},{"id":"http://arxiv.org/abs/2503.04513v1","updated":"2025-03-06T14:59:38Z","published":"2025-03-06T14:59:38Z","title":"A Novel Solution for Drone Photogrammetry with Low-overlap Aerial Images\n  using Monocular Depth Estimation","summary":"  Low-overlap aerial imagery poses significant challenges to traditional\nphotogrammetric methods, which rely heavily on high image overlap to produce\naccurate and complete mapping products. In this study, we propose a novel\nworkflow based on monocular depth estimation to address the limitations of\nconventional techniques. Our method leverages tie points obtained from aerial\ntriangulation to establish a relationship between monocular depth and metric\ndepth, thus transforming the original depth map into a metric depth map,\nenabling the generation of dense depth information and the comprehensive\nreconstruction of the scene. For the experiments, a high-overlap drone dataset\ncontaining 296 images is processed using Metashape to generate depth maps and\nDSMs as ground truth. Subsequently, we create a low-overlap dataset by\nselecting 20 images for experimental evaluation. Results demonstrate that while\nthe recovered depth maps and resulting DSMs achieve meter-level accuracy, they\nprovide significantly better completeness compared to traditional methods,\nparticularly in regions covered by single images. This study showcases the\npotential of monocular depth estimation in low-overlap aerial photogrammetry.\n","authors":["Jiageng Zhong","Qi Zhou","Ming Li","Armin Gruen","Xuan Liao"],"pdf_url":"https://arxiv.org/pdf/2503.04513v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04504v1","updated":"2025-03-06T14:52:34Z","published":"2025-03-06T14:52:34Z","title":"AnyAnomaly: Zero-Shot Customizable Video Anomaly Detection with LVLM","summary":"  Video anomaly detection (VAD) is crucial for video analysis and surveillance\nin computer vision. However, existing VAD models rely on learned normal\npatterns, which makes them difficult to apply to diverse environments.\nConsequently, users should retrain models or develop separate AI models for new\nenvironments, which requires expertise in machine learning, high-performance\nhardware, and extensive data collection, limiting the practical usability of\nVAD. To address these challenges, this study proposes customizable video\nanomaly detection (C-VAD) technique and the AnyAnomaly model. C-VAD considers\nuser-defined text as an abnormal event and detects frames containing a\nspecified event in a video. We effectively implemented AnyAnomaly using a\ncontext-aware visual question answering without fine-tuning the large vision\nlanguage model. To validate the effectiveness of the proposed model, we\nconstructed C-VAD datasets and demonstrated the superiority of AnyAnomaly.\nFurthermore, our approach showed competitive performance on VAD benchmark\ndatasets, achieving state-of-the-art results on the UBnormal dataset and\noutperforming other methods in generalization across all datasets. Our code is\navailable online at github.com/SkiddieAhn/Paper-AnyAnomaly.\n","authors":["Sunghyun Ahn","Youngwan Jo","Kijung Lee","Sein Kwon","Inpyo Hong","Sanghyun Park"],"pdf_url":"https://arxiv.org/pdf/2503.04504v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.01262v2","updated":"2025-03-06T14:50:58Z","published":"2025-02-03T11:36:01Z","title":"FSPGD: Rethinking Black-box Attacks on Semantic Segmentation","summary":"  Transferability, the ability of adversarial examples crafted for one model to\ndeceive other models, is crucial for black-box attacks. Despite advancements in\nattack methods for semantic segmentation, transferability remains limited,\nreducing their effectiveness in real-world applications. To address this, we\nintroduce the Feature Similarity Projected Gradient Descent (FSPGD) attack, a\nnovel black-box approach that enhances both attack performance and\ntransferability. Unlike conventional segmentation attacks that rely on output\npredictions for gradient calculation, FSPGD computes gradients from\nintermediate layer features. Specifically, our method introduces a loss\nfunction that targets local information by comparing features between clean\nimages and adversarial examples, while also disrupting contextual information\nby accounting for spatial relationships between objects. Experiments on Pascal\nVOC 2012 and Cityscapes datasets demonstrate that FSPGD achieves superior\ntransferability and attack performance, establishing a new state-of-the-art\nbenchmark. Code is available at https://github.com/KU-AIVS/FSPGD.\n","authors":["Eun-Sol Park","MiSo Park","Seung Park","Yong-Goo Shin"],"pdf_url":"https://arxiv.org/pdf/2502.01262v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04501v1","updated":"2025-03-06T14:50:17Z","published":"2025-03-06T14:50:17Z","title":"IMFine: 3D Inpainting via Geometry-guided Multi-view Refinement","summary":"  Current 3D inpainting and object removal methods are largely limited to\nfront-facing scenes, facing substantial challenges when applied to diverse,\n\"unconstrained\" scenes where the camera orientation and trajectory are\nunrestricted. To bridge this gap, we introduce a novel approach that produces\ninpainted 3D scenes with consistent visual quality and coherent underlying\ngeometry across both front-facing and unconstrained scenes. Specifically, we\npropose a robust 3D inpainting pipeline that incorporates geometric priors and\na multi-view refinement network trained via test-time adaptation, building on a\npre-trained image inpainting model. Additionally, we develop a novel inpainting\nmask detection technique to derive targeted inpainting masks from object masks,\nboosting the performance in handling unconstrained scenes. To validate the\nefficacy of our approach, we create a challenging and diverse benchmark that\nspans a wide range of scenes. Comprehensive experiments demonstrate that our\nproposed method substantially outperforms existing state-of-the-art approaches.\n","authors":["Zhihao Shi","Dong Huo","Yuhongze Zhou","Kejia Yin","Yan Min","Juwei Lu","Xinxin Zuo"],"pdf_url":"https://arxiv.org/pdf/2503.04501v1.pdf","comment":"Accepted at CVPR 2025,\n  \\href{https://xinxinzuo2353.github.io/imfine/}{Project Page}"},{"id":"http://arxiv.org/abs/2503.04500v1","updated":"2025-03-06T14:49:28Z","published":"2025-03-06T14:49:28Z","title":"ReynoldsFlow: Exquisite Flow Estimation via Reynolds Transport Theorem","summary":"  Optical flow is a fundamental technique for motion estimation, widely applied\nin video stabilization, interpolation, and object tracking. Recent advancements\nin artificial intelligence (AI) have enabled deep learning models to leverage\noptical flow as an important feature for motion analysis. However, traditional\noptical flow methods rely on restrictive assumptions, such as brightness\nconstancy and slow motion constraints, limiting their effectiveness in complex\nscenes. Deep learning-based approaches require extensive training on large\ndomain-specific datasets, making them computationally demanding. Furthermore,\noptical flow is typically visualized in the HSV color space, which introduces\nnonlinear distortions when converted to RGB and is highly sensitive to noise,\ndegrading motion representation accuracy. These limitations inherently\nconstrain the performance of downstream models, potentially hindering object\ntracking and motion analysis tasks. To address these challenges, we propose\nReynolds flow, a novel training-free flow estimation inspired by the Reynolds\ntransport theorem, offering a principled approach to modeling complex motion\ndynamics. Beyond the conventional HSV-based visualization, denoted\nReynoldsFlow, we introduce an alternative representation, ReynoldsFlow+,\ndesigned to improve flow visualization. We evaluate ReynoldsFlow and\nReynoldsFlow+ across three video-based benchmarks: tiny object detection on\nUAVDB, infrared object detection on Anti-UAV, and pose estimation on GolfDB.\nExperimental results demonstrate that networks trained with ReynoldsFlow+\nachieve state-of-the-art (SOTA) performance, exhibiting improved robustness and\nefficiency across all tasks.\n","authors":["Yu-Hsi Chen","Chin-Tien Wu"],"pdf_url":"https://arxiv.org/pdf/2503.04500v1.pdf","comment":"10 pages, 3 figures, 3 tables"},{"id":"http://arxiv.org/abs/2503.04499v1","updated":"2025-03-06T14:48:25Z","published":"2025-03-06T14:48:25Z","title":"Spatial regularisation for improved accuracy and interpretability in\n  keypoint-based registration","summary":"  Unsupervised registration strategies bypass requirements in ground truth\ntransforms or segmentations by optimising similarity metrics between fixed and\nmoved volumes. Among these methods, a recent subclass of approaches based on\nunsupervised keypoint detection stand out as very promising for\ninterpretability. Specifically, these methods train a network to predict\nfeature maps for fixed and moving images, from which explainable centres of\nmass are computed to obtain point clouds, that are then aligned in closed-form.\nHowever, the features returned by the network often yield spatially diffuse\npatterns that are hard to interpret, thus undermining the purpose of\nkeypoint-based registration. Here, we propose a three-fold loss to regularise\nthe spatial distribution of the features. First, we use the KL divergence to\nmodel features as point spread functions that we interpret as probabilistic\nkeypoints. Then, we sharpen the spatial distributions of these features to\nincrease the precision of the detected landmarks. Finally, we introduce a new\nrepulsive loss across keypoints to encourage spatial diversity. Overall, our\nloss considerably improves the interpretability of the features, which now\ncorrespond to precise and anatomically meaningful landmarks. We demonstrate our\nthree-fold loss in foetal rigid motion tracking and brain MRI affine\nregistration tasks, where it not only outperforms state-of-the-art unsupervised\nstrategies, but also bridges the gap with state-of-the-art supervised methods.\nOur code is available at https://github.com/BenBillot/spatial_regularisation.\n","authors":["Benjamin Billot","Ramya Muthukrishnan","Esra Abaci-Turk","Ellen P. Grant","Nicholas Ayache","Hervé Delingette","Polina Golland"],"pdf_url":"https://arxiv.org/pdf/2503.04499v1.pdf","comment":"under review"},{"id":"http://arxiv.org/abs/2503.04496v1","updated":"2025-03-06T14:44:25Z","published":"2025-03-06T14:44:25Z","title":"Learning Object Placement Programs for Indoor Scene Synthesis with\n  Iterative Self Training","summary":"  Data driven and autoregressive indoor scene synthesis systems generate indoor\nscenes automatically by suggesting and then placing objects one at a time.\nEmpirical observations show that current systems tend to produce incomplete\nnext object location distributions. We introduce a system which addresses this\nproblem. We design a Domain Specific Language (DSL) that specifies functional\nconstraints. Programs from our language take as input a partial scene and\nobject to place. Upon execution they predict possible object placements. We\ndesign a generative model which writes these programs automatically. Available\n3D scene datasets do not contain programs to train on, so we build upon\nprevious work in unsupervised program induction to introduce a new program\nbootstrapping algorithm. In order to quantify our empirical observations we\nintroduce a new evaluation procedure which captures how well a system models\nper-object location distributions. We ask human annotators to label all the\npossible places an object can go in a scene and show that our system produces\nper-object location distributions more consistent with human annotators. Our\nsystem also generates indoor scenes of comparable quality to previous systems\nand while previous systems degrade in performance when training data is sparse,\nour system does not degrade to the same degree.\n","authors":["Adrian Chang","Kai Wang","Yuanbo Li","Manolis Savva","Angel X. Chang","Daniel Ritchie"],"pdf_url":"https://arxiv.org/pdf/2503.04496v1.pdf","comment":"21 pages, 20 figures Subjects: Graphics (cs.GR), Computer Vision and\n  Pattern Recognition (cs.CV), Machine Learning (cs.LG)"},{"id":"http://arxiv.org/abs/2412.04842v3","updated":"2025-03-06T14:40:15Z","published":"2024-12-06T08:27:53Z","title":"UniMLVG: Unified Framework for Multi-view Long Video Generation with\n  Comprehensive Control Capabilities for Autonomous Driving","summary":"  The creation of diverse and realistic driving scenarios has become essential\nto enhance perception and planning capabilities of the autonomous driving\nsystem. However, generating long-duration, surround-view consistent driving\nvideos remains a significant challenge. To address this, we present UniMLVG, a\nunified framework designed to generate extended street multi-perspective videos\nunder precise control. By integrating single- and multi-view driving videos\ninto the training data, our approach updates a DiT-based diffusion model\nequipped with cross-frame and cross-view modules across three stages with multi\ntraining objectives, substantially boosting the diversity and quality of\ngenerated visual content. Importantly, we propose an innovative explicit\nviewpoint modeling approach for multi-view video generation to effectively\nimprove motion transition consistency. Capable of handling various input\nreference formats (e.g., text, images, or video), our UniMLVG generates\nhigh-quality multi-view videos according to the corresponding condition\nconstraints such as 3D bounding boxes or frame-level text descriptions.\nCompared to the best models with similar capabilities, our framework achieves\nimprovements of 48.2% in FID and 35.2% in FVD.\n","authors":["Rui Chen","Zehuan Wu","Yichen Liu","Yuxin Guo","Jingcheng Ni","Haifeng Xia","Siyu Xia"],"pdf_url":"https://arxiv.org/pdf/2412.04842v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03222v2","updated":"2025-03-06T14:32:49Z","published":"2025-03-05T06:32:49Z","title":"Mocap-2-to-3: Lifting 2D Diffusion-Based Pretrained Models for 3D Motion\n  Capture","summary":"  Recovering absolute poses in the world coordinate system from monocular views\npresents significant challenges. Two primary issues arise in this context.\nFirstly, existing methods rely on 3D motion data for training, which requires\ncollection in limited environments. Acquiring such 3D labels for new actions in\na timely manner is impractical, severely restricting the model's generalization\ncapabilities. In contrast, 2D poses are far more accessible and easier to\nobtain. Secondly, estimating a person's absolute position in metric space from\na single viewpoint is inherently more complex. To address these challenges, we\nintroduce Mocap-2-to-3, a novel framework that decomposes intricate 3D motions\ninto 2D poses, leveraging 2D data to enhance 3D motion reconstruction in\ndiverse scenarios and accurately predict absolute positions in the world\ncoordinate system. We initially pretrain a single-view diffusion model with\nextensive 2D data, followed by fine-tuning a multi-view diffusion model for\nview consistency using publicly available 3D data. This strategy facilitates\nthe effective use of large-scale 2D data. Additionally, we propose an\ninnovative human motion representation that decouples local actions from global\nmovements and encodes geometric priors of the ground, ensuring the generative\nmodel learns accurate motion priors from 2D data. During inference, this allows\nfor the gradual recovery of global movements, resulting in more plausible\npositioning. We evaluate our model's performance on real-world datasets,\ndemonstrating superior accuracy in motion and absolute human positioning\ncompared to state-of-the-art methods, along with enhanced generalization and\nscalability. Our code will be made publicly available.\n","authors":["Zhumei Wang","Zechen Hu","Ruoxi Guo","Huaijin Pi","Ziyong Feng","Sida Peng","Xiaowei Zhou"],"pdf_url":"https://arxiv.org/pdf/2503.03222v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04478v1","updated":"2025-03-06T14:28:17Z","published":"2025-03-06T14:28:17Z","title":"Semantic Alignment of Unimodal Medical Text and Vision Representations","summary":"  General-purpose AI models, particularly those designed for text and vision,\ndemonstrate impressive versatility across a wide range of deep-learning tasks.\nHowever, they often underperform in specialised domains like medical imaging,\nwhere domain-specific solutions or alternative knowledge transfer approaches\nare typically required. Recent studies have noted that general-purpose models\ncan exhibit similar latent spaces when processing semantically related data,\nalthough this alignment does not occur naturally. Building on this insight, it\nhas been shown that applying a simple transformation - at most affine -\nestimated from a subset of semantically corresponding samples, known as\nanchors, enables model stitching across diverse training paradigms,\narchitectures, and modalities. In this paper, we explore how semantic alignment\n- estimating transformations between anchors - can bridge general-purpose AI\nwith specialised medical knowledge. Using multiple public chest X-ray datasets,\nwe demonstrate that model stitching across model architectures allows general\nmodels to integrate domain-specific knowledge without additional training,\nleading to improved performance on medical tasks. Furthermore, we introduce a\nnovel zero-shot classification approach for unimodal vision encoders that\nleverages semantic alignment across modalities. Our results show that our\nmethod not only outperforms general multimodal models but also approaches the\nperformance levels of fully trained, medical-specific multimodal solutions\n","authors":["Maxime Di Folco","Emily Chan","Marta Hasny","Cosmin I. Bercea","Julia A. Schnabel"],"pdf_url":"https://arxiv.org/pdf/2503.04478v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.13524v4","updated":"2025-03-06T14:27:12Z","published":"2025-02-19T08:21:59Z","title":"MobileViM: A Light-weight and Dimension-independent Vision Mamba for 3D\n  Medical Image Analysis","summary":"  Efficient evaluation of three-dimensional (3D) medical images is crucial for\ndiagnostic and therapeutic practices in healthcare. Recent years have seen a\nsubstantial uptake in applying deep learning and computer vision to analyse and\ninterpret medical images. Traditional approaches, such as convolutional neural\nnetworks (CNNs) and vision transformers (ViTs), face significant computational\nchallenges, prompting the need for architectural advancements. Recent efforts\nhave led to the introduction of novel architectures like the ``Mamba'' model as\nalternative solutions to traditional CNNs or ViTs. The Mamba model excels in\nthe linear processing of one-dimensional data with low computational demands.\nHowever, Mamba's potential for 3D medical image analysis remains underexplored\nand could face significant computational challenges as the dimension increases.\nThis manuscript presents MobileViM, a streamlined architecture for efficient\nsegmentation of 3D medical images. In the MobileViM network, we invent a new\ndimension-independent mechanism and a dual-direction traversing approach to\nincorporate with a vision-Mamba-based framework. MobileViM also features a\ncross-scale bridging technique to improve efficiency and accuracy across\nvarious medical imaging modalities. With these enhancements, MobileViM achieves\nsegmentation speeds exceeding 90 frames per second (FPS) on a single graphics\nprocessing unit (i.e., NVIDIA RTX 4090). This performance is over 24 FPS faster\nthan the state-of-the-art deep learning models for processing 3D images with\nthe same computational resources. In addition, experimental evaluations\ndemonstrate that MobileViM delivers superior performance, with Dice similarity\nscores reaching 92.72%, 86.69%, 80.46%, and 77.43% for PENGWIN, BraTS2024,\nATLAS, and Toothfairy2 datasets, respectively, which significantly surpasses\nexisting models.\n","authors":["Wei Dai","Jun Liu"],"pdf_url":"https://arxiv.org/pdf/2502.13524v4.pdf","comment":"The corresponding author disagrees with the manuscript submitted to\n  arXiv"},{"id":"http://arxiv.org/abs/2503.04475v1","updated":"2025-03-06T14:24:22Z","published":"2025-03-06T14:24:22Z","title":"ForestLPR: LiDAR Place Recognition in Forests Attentioning Multiple BEV\n  Density Images","summary":"  Place recognition is essential to maintain global consistency in large-scale\nlocalization systems. While research in urban environments has progressed\nsignificantly using LiDARs or cameras, applications in natural forest-like\nenvironments remain largely under-explored. Furthermore, forests present\nparticular challenges due to high self-similarity and substantial variations in\nvegetation growth over time. In this work, we propose a robust LiDAR-based\nplace recognition method for natural forests, ForestLPR. We hypothesize that a\nset of cross-sectional images of the forest's geometry at different heights\ncontains the information needed to recognize revisiting a place. The\ncross-sectional images are represented by \\ac{bev} density images of horizontal\nslices of the point cloud at different heights. Our approach utilizes a visual\ntransformer as the shared backbone to produce sets of local descriptors and\nintroduces a multi-BEV interaction module to attend to information at different\nheights adaptively. It is followed by an aggregation layer that produces a\nrotation-invariant place descriptor. We evaluated the efficacy of our method\nextensively on real-world data from public benchmarks as well as robotic\ndatasets and compared it against the state-of-the-art (SOTA) methods. The\nresults indicate that ForestLPR has consistently good performance on all\nevaluations and achieves an average increase of 7.38\\% and 9.11\\% on Recall@1\nover the closest competitor on intra-sequence loop closure detection and\ninter-sequence re-localization, respectively, validating our hypothesis\n","authors":["Yanqing Shen","Turcan Tuna","Marco Hutter","Cesar Cadena","Nanning Zheng"],"pdf_url":"https://arxiv.org/pdf/2503.04475v1.pdf","comment":"accepted by CVPR2025"},{"id":"http://arxiv.org/abs/2503.04470v1","updated":"2025-03-06T14:21:43Z","published":"2025-03-06T14:21:43Z","title":"Gate-Shift-Pose: Enhancing Action Recognition in Sports with Skeleton\n  Information","summary":"  This paper introduces Gate-Shift-Pose, an enhanced version of Gate-Shift-Fuse\nnetworks, designed for athlete fall classification in figure skating by\nintegrating skeleton pose data alongside RGB frames. We evaluate two fusion\nstrategies: early-fusion, which combines RGB frames with Gaussian heatmaps of\npose keypoints at the input stage, and late-fusion, which employs a\nmulti-stream architecture with attention mechanisms to combine RGB and pose\nfeatures. Experiments on the FR-FS dataset demonstrate that Gate-Shift-Pose\nsignificantly outperforms the RGB-only baseline, improving accuracy by up to\n40% with ResNet18 and 20% with ResNet50. Early-fusion achieves the highest\naccuracy (98.08%) with ResNet50, leveraging the model's capacity for effective\nmultimodal integration, while late-fusion is better suited for lighter\nbackbones like ResNet18. These results highlight the potential of multimodal\narchitectures for sports action recognition and the critical role of skeleton\npose information in capturing complex motion patterns.\n","authors":["Edoardo Bianchi","Oswald Lanz"],"pdf_url":"https://arxiv.org/pdf/2503.04470v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04459v1","updated":"2025-03-06T14:11:46Z","published":"2025-03-06T14:11:46Z","title":"Question-Aware Gaussian Experts for Audio-Visual Question Answering","summary":"  Audio-Visual Question Answering (AVQA) requires not only question-based\nmultimodal reasoning but also precise temporal grounding to capture subtle\ndynamics for accurate prediction. However, existing methods mainly use question\ninformation implicitly, limiting focus on question-specific details.\nFurthermore, most studies rely on uniform frame sampling, which can miss key\nquestion-relevant frames. Although recent Top-K frame selection methods aim to\naddress this, their discrete nature still overlooks fine-grained temporal\ndetails. This paper proposes \\textbf{QA-TIGER}, a novel framework that\nexplicitly incorporates question information and models continuous temporal\ndynamics. Our key idea is to use Gaussian-based modeling to adaptively focus on\nboth consecutive and non-consecutive frames based on the question, while\nexplicitly injecting question information and applying progressive refinement.\nWe leverage a Mixture of Experts (MoE) to flexibly implement multiple Gaussian\nmodels, activating temporal experts specifically tailored to the question.\nExtensive experiments on multiple AVQA benchmarks show that QA-TIGER\nconsistently achieves state-of-the-art performance. Code is available at\nhttps://github.com/AIM-SKKU/QA-TIGER\n","authors":["Hongyeob Kim","Inyoung Jung","Dayoon Suh","Youjia Zhang","Sangmin Lee","Sungeun Hong"],"pdf_url":"https://arxiv.org/pdf/2503.04459v1.pdf","comment":"CVPR 2025. Project page at https://aim-skku.github.io/QA-TIGER/"},{"id":"http://arxiv.org/abs/2503.04457v1","updated":"2025-03-06T14:11:00Z","published":"2025-03-06T14:11:00Z","title":"TPC: Cross-Temporal Prediction Connection for Vision-Language Model\n  Hallucination Reduction","summary":"  Vision-language models (VLMs) have achieved remarkable advancements,\ncapitalizing on the impressive capabilities of large language models (LLMs)\nacross diverse tasks. Despite this, a critical challenge known as hallucination\noccurs when models overconfidently describe objects or attributes absent from\nthe image, a problem exacerbated by the tendency of VLMs to rely on linguistic\npriors. This limitation reduces model reliability in high-stakes applications.\nIn this work, we have observed the characteristic of logits' continuity\nconsistency enhancement and introduced a straightforward and efficient method,\nCross-Temporal Prediction Connection (TPC), designed to enhance the semantic\nconsistency of logits by connecting them temporally across timesteps. TPC\namplifies information flow and improves coherence, effectively reducing\nhallucination. Extensive experiments show that TPC surpasses existing\nrepresentatives, delivering superior performance in both accuracy and\nefficiency while maintaining robustness in open-ended text generation tasks.\n","authors":["Chao Wang","Weiwei Fu","Yang Zhou"],"pdf_url":"https://arxiv.org/pdf/2503.04457v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04452v1","updated":"2025-03-06T14:06:35Z","published":"2025-03-06T14:06:35Z","title":"A lightweight model FDM-YOLO for small target improvement based on\n  YOLOv8","summary":"  Small targets are particularly difficult to detect due to their low pixel\ncount, complex backgrounds, and varying shooting angles, which make it hard for\nmodels to extract effective features. While some large-scale models offer high\naccuracy, their long inference times make them unsuitable for real-time\ndeployment on edge devices. On the other hand, models designed for low\ncomputational power often suffer from poor detection accuracy. This paper\nfocuses on small target detection and explores methods for object detection\nunder low computational constraints. Building on the YOLOv8 model, we propose a\nnew network architecture called FDM-YOLO. Our research includes the following\nkey contributions: We introduce FDM-YOLO by analyzing the output of the YOLOv8\ndetection head. We add a highresolution layer and remove the large target\ndetection layer to better handle small targets. Based on PConv, we propose a\nlightweight network structure called Fast-C2f, which is integrated into the PAN\nmodule of the model. To mitigate the accuracy loss caused by model\nlightweighting, we employ dynamic upsampling (Dysample) and a lightweight EMA\nattention mechanism.The FDM-YOLO model was validated on the Visdrone dataset,\nachieving a 38% reduction in parameter count and improving the Map0.5 score\nfrom 38.4% to 42.5%, all while maintaining nearly the same inference speed.\nThis demonstrates the effectiveness of our approach in balancing accuracy and\nefficiency for edge device deployment.\n","authors":["Xuerui Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.04452v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.04484v3","updated":"2025-03-06T14:06:24Z","published":"2023-12-07T17:59:53Z","title":"FRNet: Frustum-Range Networks for Scalable LiDAR Segmentation","summary":"  LiDAR segmentation has become a crucial component of advanced autonomous\ndriving systems. Recent range-view LiDAR segmentation approaches show promise\nfor real-time processing. However, they inevitably suffer from corrupted\ncontextual information and rely heavily on post-processing techniques for\nprediction refinement. In this work, we propose FRNet, a simple yet powerful\nmethod aimed at restoring the contextual information of range image pixels\nusing corresponding frustum LiDAR points. First, a frustum feature encoder\nmodule is used to extract per-point features within the frustum region, which\npreserves scene consistency and is critical for point-level predictions. Next,\na frustum-point fusion module is introduced to update per-point features\nhierarchically, enabling each point to extract more surrounding information\nthrough the frustum features. Finally, a head fusion module is used to fuse\nfeatures at different levels for final semantic predictions. Extensive\nexperiments conducted on four popular LiDAR segmentation benchmarks under\nvarious task setups demonstrate the superiority of FRNet. Notably, FRNet\nachieves 73.3% and 82.5% mIoU scores on the testing sets of SemanticKITTI and\nnuScenes. While achieving competitive performance, FRNet operates 5 times\nfaster than state-of-the-art approaches. Such high efficiency opens up new\npossibilities for more scalable LiDAR segmentation. The code has been made\npublicly available at https://github.com/Xiangxu-0103/FRNet.\n","authors":["Xiang Xu","Lingdong Kong","Hui Shuai","Qingshan Liu"],"pdf_url":"https://arxiv.org/pdf/2312.04484v3.pdf","comment":"TIP 2025; 18 pages, 11 figures, 14 tables; Code at\n  https://github.com/Xiangxu-0103/FRNet"},{"id":"http://arxiv.org/abs/2407.13304v3","updated":"2025-03-06T14:06:01Z","published":"2024-07-18T09:07:23Z","title":"A Dataset and Benchmark for Shape Completion of Fruits for Agricultural\n  Robotics","summary":"  As the world population is expected to reach 10 billion by 2050, our\nagricultural production system needs to double its productivity despite a\ndecline of human workforce in the agricultural sector. Autonomous robotic\nsystems are one promising pathway to increase productivity by taking over\nlabor-intensive manual tasks like fruit picking. To be effective, such systems\nneed to monitor and interact with plants and fruits precisely, which is\nchallenging due to the cluttered nature of agricultural environments causing,\nfor example, strong occlusions. Thus, being able to estimate the complete 3D\nshapes of objects in presence of occlusions is crucial for automating\noperations such as fruit harvesting. In this paper, we propose the first\npublicly available 3D shape completion dataset for agricultural vision systems.\nWe provide an RGB-D dataset for estimating the 3D shape of fruits.\nSpecifically, our dataset contains RGB-D frames of single sweet peppers in lab\nconditions but also in a commercial greenhouse. For each fruit, we additionally\ncollected high-precision point clouds that we use as ground truth. For\nacquiring the ground truth shape, we developed a measuring process that allows\nus to record data of real sweet pepper plants, both in the lab and in the\ngreenhouse with high precision, and determine the shape of the sensed fruits.\nWe release our dataset, consisting of almost 7,000 RGB-D frames belonging to\nmore than 100 different fruits. We provide segmented RGB-D frames, with camera\nintrinsics to easily obtain colored point clouds, together with the\ncorresponding high-precision, occlusion-free point clouds obtained with a\nhigh-precision laser scanner. We additionally enable evaluation of shape\ncompletion approaches on a hidden test set through a public challenge on a\nbenchmark server.\n","authors":["Federico Magistri","Thomas Läbe","Elias Marks","Sumanth Nagulavancha","Yue Pan","Claus Smitt","Lasse Klingbeil","Michael Halstead","Heiner Kuhlmann","Chris McCool","Jens Behley","Cyrill Stachniss"],"pdf_url":"https://arxiv.org/pdf/2407.13304v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04444v1","updated":"2025-03-06T14:00:59Z","published":"2025-03-06T14:00:59Z","title":"ToFu: Visual Tokens Reduction via Fusion for Multi-modal, Multi-patch,\n  Multi-image Task","summary":"  Large Multimodal Models (LMMs) are powerful tools that are capable of\nreasoning and understanding multimodal information beyond text and language.\nDespite their entrenched impact, the development of LMMs is hindered by the\nhigher computational requirements compared to their unimodal counterparts. One\nof the main causes of this is the large amount of tokens needed to encode the\nvisual input, which is especially evident for multi-image multimodal tasks.\nRecent approaches to reduce visual tokens depend on the visual encoder\narchitecture, require fine-tuning the LLM to maintain the performance, and only\nconsider single-image scenarios. To address these limitations, we propose ToFu,\na visual encoder-agnostic, training-free Token Fusion strategy that combines\nredundant visual tokens of LMMs for high-resolution, multi-image, tasks. The\ncore intuition behind our method is straightforward yet effective: preserve\ndistinctive tokens while combining similar ones. We achieve this by\nsequentially examining visual tokens and deciding whether to merge them with\nothers or keep them as separate entities. We validate our approach on the\nwell-established LLaVA-Interleave Bench, which covers challenging multi-image\ntasks. In addition, we push to the extreme our method by testing it on a\nnewly-created benchmark, ComPairs, focused on multi-image comparisons where a\nlarger amount of images and visual tokens are inputted to the LMMs. Our\nextensive analysis, considering several LMM architectures, demonstrates the\nbenefits of our approach both in terms of efficiency and performance gain.\n","authors":["Vittorio Pippi","Matthieu Guillaumin","Silvia Cascianelli","Rita Cucchiara","Maximilian Jaritz","Loris Bazzani"],"pdf_url":"https://arxiv.org/pdf/2503.04444v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04441v1","updated":"2025-03-06T13:56:48Z","published":"2025-03-06T13:56:48Z","title":"EvidMTL: Evidential Multi-Task Learning for Uncertainty-Aware Semantic\n  Surface Mapping from Monocular RGB Images","summary":"  For scene understanding in unstructured environments, an accurate and\nuncertainty-aware metric-semantic mapping is required to enable informed action\nselection by autonomous systems.Existing mapping methods often suffer from\noverconfident semantic predictions, and sparse and noisy depth sensing, leading\nto inconsistent map representations. In this paper, we therefore introduce\nEvidMTL, a multi-task learning framework that uses evidential heads for depth\nestimation and semantic segmentation, enabling uncertainty-aware inference from\nmonocular RGB images. To enable uncertainty-calibrated evidential multi-task\nlearning, we propose a novel evidential depth loss function that jointly\noptimizes the belief strength of the depth prediction in conjunction with\nevidential segmentation loss. Building on this, we present EvidKimera, an\nuncertainty-aware semantic surface mapping framework, which uses evidential\ndepth and semantics prediction for improved 3D metric-semantic consistency. We\ntrain and evaluate EvidMTL on the NYUDepthV2 and assess its zero-shot\nperformance on ScanNetV2, demonstrating superior uncertainty estimation\ncompared to conventional approaches while maintaining comparable depth\nestimation and semantic segmentation. In zero-shot mapping tests on ScanNetV2,\nEvidKimera outperforms Kimera in semantic surface mapping accuracy and\nconsistency, highlighting the benefits of uncertainty-aware mapping and\nunderscoring its potential for real-world robotic applications.\n","authors":["Rohit Menon","Nils Dengler","Sicong Pan","Gokul Krishna Chenchani","Maren Bennewitz"],"pdf_url":"https://arxiv.org/pdf/2503.04441v1.pdf","comment":"Submitted to IROS 2025 Conference"},{"id":"http://arxiv.org/abs/2503.03272v2","updated":"2025-03-06T13:49:46Z","published":"2025-03-05T08:52:55Z","title":"Towards Effective and Sparse Adversarial Attack on Spiking Neural\n  Networks via Breaking Invisible Surrogate Gradients","summary":"  Spiking neural networks (SNNs) have shown their competence in handling\nspatial-temporal event-based data with low energy consumption. Similar to\nconventional artificial neural networks (ANNs), SNNs are also vulnerable to\ngradient-based adversarial attacks, wherein gradients are calculated by\nspatial-temporal back-propagation (STBP) and surrogate gradients (SGs).\nHowever, the SGs may be invisible for an inference-only model as they do not\ninfluence the inference results, and current gradient-based attacks are\nineffective for binary dynamic images captured by the dynamic vision sensor\n(DVS). While some approaches addressed the issue of invisible SGs through\nuniversal SGs, their SGs lack a correlation with the victim model, resulting in\nsub-optimal performance. Moreover, the imperceptibility of existing SNN-based\nbinary attacks is still insufficient. In this paper, we introduce an innovative\npotential-dependent surrogate gradient (PDSG) method to establish a robust\nconnection between the SG and the model, thereby enhancing the adaptability of\nadversarial attacks across various models with invisible SGs. Additionally, we\npropose the sparse dynamic attack (SDA) to effectively attack binary dynamic\nimages. Utilizing a generation-reduction paradigm, SDA can fully optimize the\nsparsity of adversarial perturbations. Experimental results demonstrate that\nour PDSG and SDA outperform state-of-the-art SNN-based attacks across various\nmodels and datasets. Specifically, our PDSG achieves 100% attack success rate\non ImageNet, and our SDA obtains 82% attack success rate by modifying only\n0.24% of the pixels on CIFAR10DVS. The code is available at\nhttps://github.com/ryime/PDSG-SDA .\n","authors":["Li Lun","Kunyu Feng","Qinglong Ni","Ling Liang","Yuan Wang","Ying Li","Dunshan Yu","Xiaoxin Cui"],"pdf_url":"https://arxiv.org/pdf/2503.03272v2.pdf","comment":"Accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2503.04420v1","updated":"2025-03-06T13:23:03Z","published":"2025-03-06T13:23:03Z","title":"PointsToWood: A deep learning framework for complete canopy leaf-wood\n  segmentation of TLS data across diverse European forests","summary":"  Point clouds from Terrestrial Laser Scanning (TLS) are an increasingly\npopular source of data for studying plant structure and function but typically\nrequire extensive manual processing to extract ecologically important\ninformation. One key task is the accurate semantic segmentation of different\nplant material within point clouds, particularly wood and leaves, which is\nrequired to understand plant productivity, architecture and physiology.\nExisting automated semantic segmentation methods are primarily developed for\nsingle ecosystem types, and whilst they show good accuracy for biomass\nassessment from the trunk and large branches, often perform less well within\nthe crown. In this study, we demonstrate a new framework that uses a deep\nlearning architecture newly developed from PointNet and pointNEXT for\nprocessing 3D point clouds to provide a reliable semantic segmentation of wood\nand leaf in TLS point clouds from the tree base to branch tips, trained on data\nfrom diverse mature European forests. Our model uses meticulously labelled data\ncombined with voxel-based sampling, neighbourhood rescaling, and a novel gated\nreflectance integration module embedded throughout the feature extraction\nlayers. We evaluate its performance across open datasets from boreal,\ntemperate, Mediterranean and tropical regions, encompassing diverse ecosystem\ntypes and sensor characteristics. Our results show consistent outperformance\nagainst the most widely used PointNet based approach for leaf/wood segmentation\non our high-density TLS dataset collected across diverse mixed forest plots\nacross all major biomes in Europe. We also find consistently strong performance\ntested on others open data from China, Eastern Cameroon, Germany and Finland,\ncollected using both time-of-flight and phase-shift sensors, showcasing the\ntransferability of our model to a wide range of ecosystems and sensors.\n","authors":["Harry J. F. Owen","Matthew J. A. Allen","Stuart W. D. Grieve","Phill Wilkes","Emily R. Lines"],"pdf_url":"https://arxiv.org/pdf/2503.04420v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.08388v2","updated":"2025-03-06T13:19:58Z","published":"2024-09-12T20:34:34Z","title":"Continual Learning in 3D Point Clouds: Employing Spectral Techniques for\n  Exemplar Selection","summary":"  We introduce a novel framework for Continual Learning in 3D object\nclassification. Our approach, CL3D, is based on the selection of prototypes\nfrom each class using spectral clustering. For non-Euclidean data such as point\nclouds, spectral clustering can be employed as long as one can define a\ndistance measure between pairs of samples. Choosing the appropriate distance\nmeasure enables us to leverage 3D geometric characteristics to identify\nrepresentative prototypes for each class. We explore the effectiveness of\nclustering in the input space (3D points), local feature space\n(1024-dimensional points), and global feature space. We conduct experiments on\nthe ModelNet40, ShapeNet, and ScanNet datasets, achieving state-of-the-art\naccuracy exclusively through the use of input space features. By leveraging the\ncombined input, local, and global features, we have improved the\nstate-of-the-art on ModelNet and ShapeNet, utilizing nearly half the memory\nused by competing approaches. For the challenging ScanNet dataset, our method\nenhances accuracy by 4.1% while consuming just 28% of the memory used by our\ncompetitors, demonstrating the scalability of our approach.\n","authors":["Hossein Resani","Behrooz Nasihatkon","Mohammadreza Alimoradi Jazi"],"pdf_url":"https://arxiv.org/pdf/2409.08388v2.pdf","comment":"Accepted to WACV 2025, Tucson, Arizona, USA"},{"id":"http://arxiv.org/abs/2503.04416v1","updated":"2025-03-06T13:18:37Z","published":"2025-03-06T13:18:37Z","title":"Learning Transformer-based World Models with Contrastive Predictive\n  Coding","summary":"  The DreamerV3 algorithm recently obtained remarkable performance across\ndiverse environment domains by learning an accurate world model based on\nRecurrent Neural Networks (RNNs). Following the success of model-based\nreinforcement learning algorithms and the rapid adoption of the Transformer\narchitecture for its superior training efficiency and favorable scaling\nproperties, recent works such as STORM have proposed replacing RNN-based world\nmodels with Transformer-based world models using masked self-attention.\nHowever, despite the improved training efficiency of these methods, their\nimpact on performance remains limited compared to the Dreamer algorithm,\nstruggling to learn competitive Transformer-based world models. In this work,\nwe show that the next state prediction objective adopted in previous approaches\nis insufficient to fully exploit the representation capabilities of\nTransformers. We propose to extend world model predictions to longer time\nhorizons by introducing TWISTER (Transformer-based World model wIth contraSTivE\nRepresentations), a world model using action-conditioned Contrastive Predictive\nCoding to learn high-level temporal feature representations and improve the\nagent performance. TWISTER achieves a human-normalized mean score of 162% on\nthe Atari 100k benchmark, setting a new record among state-of-the-art methods\nthat do not employ look-ahead search.\n","authors":["Maxime Burchi","Radu Timofte"],"pdf_url":"https://arxiv.org/pdf/2503.04416v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.03420v2","updated":"2025-03-06T12:52:29Z","published":"2024-05-06T12:40:15Z","title":"Implantable Adaptive Cells: A Novel Enhancement for Pre-Trained U-Nets\n  in Medical Image Segmentation","summary":"  This paper introduces a novel approach to enhance the performance of\npre-trained neural networks in medical image segmentation using gradient-based\nNeural Architecture Search (NAS) methods. We present the concept of Implantable\nAdaptive Cell (IAC), small modules identified through Partially-Connected DARTS\nbased approach, designed to be injected into the skip connections of an\nexisting and already trained U-shaped model. Unlike traditional NAS methods,\nour approach refines existing architectures without full retraining.\nExperiments on four medical datasets with MRI and CT images show consistent\naccuracy improvements on various U-Net configurations, with segmentation\naccuracy gain by approximately 5 percentage points across all validation\ndatasets, with improvements reaching up to 11\\%pt in the best-performing cases.\nThe findings of this study not only offer a cost-effective alternative to the\ncomplete overhaul of complex models for performance upgrades but also indicate\nthe potential applicability of our method to other architectures and problem\ndomains.\n","authors":["Emil Benedykciuk","Marcin Denkowski","Grzegorz Wójcik"],"pdf_url":"https://arxiv.org/pdf/2405.03420v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20742v2","updated":"2025-03-06T12:50:44Z","published":"2025-02-28T05:47:34Z","title":"Structured Preference Optimization for Vision-Language Long-Horizon Task\n  Planning","summary":"  Existing methods for vision-language task planning excel in short-horizon\ntasks but often fall short in complex, long-horizon planning within dynamic\nenvironments. These challenges primarily arise from the difficulty of\neffectively training models to produce high-quality reasoning processes for\nlong-horizon tasks. To address this, we propose Structured Preference\nOptimization (SPO), which aims to enhance reasoning and action selection in\nlong-horizon task planning through structured preference evaluation and\noptimized training strategies. Specifically, SPO introduces: 1)\nPreference-Based Scoring and Optimization, which systematically evaluates\nreasoning chains based on task relevance, visual grounding, and historical\nconsistency; and 2) Curriculum-Guided Training, where the model progressively\nadapts from simple to complex tasks, improving its generalization ability in\nlong-horizon scenarios and enhancing reasoning robustness. To advance research\nin vision-language long-horizon task planning, we introduce ExtendaBench, a\ncomprehensive benchmark covering 1,509 tasks across VirtualHome and Habitat\n2.0, categorized into ultra-short, short, medium, and long tasks. Experimental\nresults demonstrate that SPO significantly improves reasoning quality and final\ndecision accuracy, outperforming prior methods on long-horizon tasks and\nunderscoring the effectiveness of preference-driven optimization in\nvision-language task planning. Specifically, SPO achieves a +5.98% GCR and\n+4.68% SR improvement in VirtualHome and a +3.30% GCR and +2.11% SR improvement\nin Habitat over the best-performing baselines.\n","authors":["Xiwen Liang","Min Lin","Weiqi Ruan","Rongtao Xu","Yuecheng Liu","Jiaqi Chen","Bingqian Lin","Yuzheng Zhuang","Xiaodan Liang"],"pdf_url":"https://arxiv.org/pdf/2502.20742v2.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2503.03285v2","updated":"2025-03-06T12:42:37Z","published":"2025-03-05T09:12:16Z","title":"Enhancing Vietnamese VQA through Curriculum Learning on Raw and\n  Augmented Text Representations","summary":"  Visual Question Answering (VQA) is a multimodal task requiring reasoning\nacross textual and visual inputs, which becomes particularly challenging in\nlow-resource languages like Vietnamese due to linguistic variability and the\nlack of high-quality datasets. Traditional methods often rely heavily on\nextensive annotated datasets, computationally expensive pipelines, and large\npre-trained models, specifically in the domain of Vietnamese VQA, limiting\ntheir applicability in such scenarios. To address these limitations, we propose\na training framework that combines a paraphrase-based feature augmentation\nmodule with a dynamic curriculum learning strategy. Explicitly, augmented\nsamples are considered \"easy\" while raw samples are regarded as \"hard\". The\nframework then utilizes a mechanism that dynamically adjusts the ratio of easy\nto hard samples during training, progressively modifying the same dataset to\nincrease its difficulty level. By enabling gradual adaptation to task\ncomplexity, this approach helps the Vietnamese VQA model generalize well, thus\nimproving overall performance. Experimental results show consistent\nimprovements on the OpenViVQA dataset and mixed outcomes on the ViVQA dataset,\nhighlighting both the potential and challenges of our approach in advancing VQA\nfor Vietnamese language.\n","authors":["Khoi Anh Nguyen","Linh Yen Vu","Thang Dinh Duong","Thuan Nguyen Duong","Huy Thanh Nguyen","Vinh Quang Dinh"],"pdf_url":"https://arxiv.org/pdf/2503.03285v2.pdf","comment":"10 pages, 3 figures, AAAI-25 Workshop on Document Understanding and\n  Intelligence"},{"id":"http://arxiv.org/abs/2503.04385v1","updated":"2025-03-06T12:36:35Z","published":"2025-03-06T12:36:35Z","title":"Scale-Invariant Adversarial Attack against Arbitrary-scale\n  Super-resolution","summary":"  The advent of local continuous image function (LIIF) has garnered significant\nattention for arbitrary-scale super-resolution (SR) techniques. However, while\nthe vulnerabilities of fixed-scale SR have been assessed, the robustness of\ncontinuous representation-based arbitrary-scale SR against adversarial attacks\nremains an area warranting further exploration. The elaborately designed\nadversarial attacks for fixed-scale SR are scale-dependent, which will cause\ntime-consuming and memory-consuming problems when applied to arbitrary-scale\nSR. To address this concern, we propose a simple yet effective\n``scale-invariant'' SR adversarial attack method with good transferability,\ntermed SIAGT. Specifically, we propose to construct resource-saving attacks by\nexploiting finite discrete points of continuous representation. In addition, we\nformulate a coordinate-dependent loss to enhance the cross-model\ntransferability of the attack. The attack can significantly deteriorate the SR\nimages while introducing imperceptible distortion to the targeted\nlow-resolution (LR) images. Experiments carried out on three popular LIIF-based\nSR approaches and four classical SR datasets show remarkable attack performance\nand transferability of SIAGT.\n","authors":["Yihao Huang","Xin Luo","Qing Guo","Felix Juefei-Xu","Xiaojun Jia","Weikai Miao","Geguang Pu","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2503.04385v1.pdf","comment":"15 pages, accepted by TIFS 2025"},{"id":"http://arxiv.org/abs/2503.04376v1","updated":"2025-03-06T12:27:58Z","published":"2025-03-06T12:27:58Z","title":"MIDAS: Modeling Ground-Truth Distributions with Dark Knowledge for\n  Domain Generalized Stereo Matching","summary":"  Despite the significant advances in domain generalized stereo matching,\nexisting methods still exhibit domain-specific preferences when transferring\nfrom synthetic to real domains, hindering their practical applications in\ncomplex and diverse scenarios. The probability distributions predicted by the\nstereo network naturally encode rich similarity and uncertainty information.\nInspired by this observation, we propose to extract these two types of dark\nknowledge from the pre-trained network to model intuitive multi-modal\nground-truth distributions for both edge and non-edge regions. To mitigate the\ninherent domain preferences of a single network, we adopt network ensemble and\nfurther distinguish between objective and biased knowledge in the Laplace\nparameter space. Finally, the objective knowledge and the original disparity\nlabels are jointly modeled as a mixture of Laplacians to provide fine-grained\nsupervision for the stereo network training. Extensive experiments demonstrate\nthat: 1) Our method is generic and effectively improves the generalization of\nexisting networks. 2) PCWNet with our method achieves the state-of-the-art\ngeneralization performance on both KITTI 2015 and 2012 datasets. 3) Our method\noutperforms existing methods in comprehensive ranking across four popular\nreal-world datasets.\n","authors":["Peng Xu","Zhiyu Xiang","Jingyun Fu","Tianyu Pu","Hanzhi Zhong","Eryun Liu"],"pdf_url":"https://arxiv.org/pdf/2503.04376v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.08824v3","updated":"2025-03-06T12:26:08Z","published":"2024-09-13T13:37:33Z","title":"Pathfinder for Low-altitude Aircraft with Binary Neural Network","summary":"  A prior global topological map (e.g., the OpenStreetMap, OSM) can boost the\nperformance of autonomous mapping by a ground mobile robot. However, the prior\nmap is usually incomplete due to lacking labeling in partial paths. To solve\nthis problem, this paper proposes an OSM maker using airborne sensors carried\nby low-altitude aircraft, where the core of the OSM maker is a novel efficient\npathfinder approach based on LiDAR and camera data, i.e., a binary dual-stream\nroad segmentation model. Specifically, a multi-scale feature extraction based\non the UNet architecture is implemented for images and point clouds. To reduce\nthe effect caused by the sparsity of point cloud, an attention-guided gated\nblock is designed to integrate image and point-cloud features. To optimize the\nmodel for edge deployment that significantly reduces storage footprint and\ncomputational demands, we propose a binarization streamline to each model\ncomponent, including a variant of vision transformer (ViT) architecture as the\nencoder of the image branch, and new focal and perception losses to optimize\nthe model training. The experimental results on two datasets demonstrate that\nour pathfinder method achieves SOTA accuracy with high efficiency in finding\npaths from the low-level airborne sensors, and we can create complete OSM prior\nmaps based on the segmented road skeletons. Code and data are available at:\n\\href{https://github.com/IMRL/Pathfinder}{https://github.com/IMRL/Pathfinder}.\n","authors":["Kaijie Yin","Tian Gao","Hui Kong"],"pdf_url":"https://arxiv.org/pdf/2409.08824v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.16532v2","updated":"2025-03-06T12:19:59Z","published":"2025-02-23T10:48:11Z","title":"Deep unrolling for learning optimal spatially varying regularisation\n  parameters for Total Generalised Variation","summary":"  We extend a recently introduced deep unrolling framework for learning\nspatially varying regularisation parameters in inverse imaging problems to the\ncase of Total Generalised Variation (TGV). The framework combines a deep\nconvolutional neural network (CNN) inferring the two spatially varying TGV\nparameters with an unrolled algorithmic scheme that solves the corresponding\nvariational problem. The two subnetworks are jointly trained end-to-end in a\nsupervised fashion and as such the CNN learns to compute those parameters that\ndrive the reconstructed images as close to the ground truth as possible.\nNumerical results in image denoising and MRI reconstruction show a significant\nqualitative and quantitative improvement compared to the best TGV scalar\nparameter case as well as to other approaches employing spatially varying\nparameters computed by unsupervised methods. We also observe that the inferred\nspatially varying parameter maps have a consistent structure near the image\nedges, asking for further theoretical investigations. In particular, the\nparameter that weighs the first-order TGV term has a triple-edge structure with\nalternating high-low-high values whereas the one that weighs the second-order\nterm attains small values in a large neighbourhood around the edges.\n","authors":["Thanh Trung Vu","Andreas Kofler","Kostas Papafitsoros"],"pdf_url":"https://arxiv.org/pdf/2502.16532v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.10329v2","updated":"2025-03-06T12:16:09Z","published":"2024-09-16T14:39:15Z","title":"InfoDisent: Explainability of Image Classification Models by Information\n  Disentanglement","summary":"  In this work, we introduce InfoDisent, a hybrid approach to explainability\nbased on the information bottleneck principle. InfoDisent enables the\ndisentanglement of information in the final layer of any pretrained model into\natomic concepts, which can be interpreted as prototypical parts. This approach\nmerges the flexibility of post-hoc methods with the concept-level modeling\ncapabilities of self-explainable neural networks, such as ProtoPNets. We\ndemonstrate the effectiveness of InfoDisent through computational experiments\nand user studies across various datasets using modern backbones such as ViTs\nand convolutional networks. Notably, InfoDisent generalizes the prototypical\nparts approach to novel domains (ImageNet).\n","authors":["Łukasz Struski","Dawid Rymarczyk","Jacek Tabor"],"pdf_url":"https://arxiv.org/pdf/2409.10329v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.01334v3","updated":"2025-03-06T11:59:11Z","published":"2024-08-02T15:32:42Z","title":"A Backbone for Long-Horizon Robot Task Understanding","summary":"  End-to-end robot learning, particularly for long-horizon tasks, often results\nin unpredictable outcomes and poor generalization. To address these challenges,\nwe propose a novel Therblig-Based Backbone Framework (TBBF) as a fundamental\nstructure to enhance interpretability, data efficiency, and generalization in\nrobotic systems. TBBF utilizes expert demonstrations to enable therblig-level\ntask decomposition, facilitate efficient action-object mapping, and generate\nadaptive trajectories for new scenarios. The approach consists of two stages:\noffline training and online testing. During the offline training stage, we\ndeveloped the Meta-RGate SynerFusion (MGSF) network for accurate therblig\nsegmentation across various tasks. In the online testing stage, after a\none-shot demonstration of a new task is collected, our MGSF network extracts\nhigh-level knowledge, which is then encoded into the image using Action\nRegistration (ActionREG). Additionally, Large Language Model (LLM)-Alignment\nPolicy for Visual Correction (LAP-VC) is employed to ensure precise action\nregistration, facilitating trajectory transfer in novel robot scenarios.\nExperimental results validate these methods, achieving 94.37% recall in\ntherblig segmentation and success rates of 94.4% and 80% in real-world online\nrobot testing for simple and complex scenarios, respectively. Supplementary\nmaterial is available at:\nhttps://sites.google.com/view/therbligsbasedbackbone/home\n","authors":["Xiaoshuai Chen","Wei Chen","Dongmyoung Lee","Yukun Ge","Nicolas Rojas","Petar Kormushev"],"pdf_url":"https://arxiv.org/pdf/2408.01334v3.pdf","comment":"8 pages, 8 figures. This work has been published by IEEE Robotics and\n  Automation Letters (RA-L)"},{"id":"http://arxiv.org/abs/2503.04353v1","updated":"2025-03-06T11:55:44Z","published":"2025-03-06T11:55:44Z","title":"ObjMST: An Object-Focused Multimodal Style Transfer Framework","summary":"  We propose ObjMST, an object-focused multimodal style transfer framework that\nprovides separate style supervision for salient objects and surrounding\nelements while addressing alignment issues in multimodal representation\nlearning. Existing image-text multimodal style transfer methods face the\nfollowing challenges: (1) generating non-aligned and inconsistent multimodal\nstyle representations; and (2) content mismatch, where identical style patterns\nare applied to both salient objects and their surrounding elements. Our\napproach mitigates these issues by: (1) introducing a Style-Specific Masked\nDirectional CLIP Loss, which ensures consistent and aligned style\nrepresentations for both salient objects and their surroundings; and (2)\nincorporating a salient-to-key mapping mechanism for stylizing salient objects,\nfollowed by image harmonization to seamlessly blend the stylized objects with\ntheir environment. We validate the effectiveness of ObjMST through experiments,\nusing both quantitative metrics and qualitative visual evaluations of the\nstylized outputs. Our code is available at:\nhttps://github.com/chandagrover/ObjMST.\n","authors":["Chanda Grover Kamra","Indra Deep Mastan","Debayan Gupta"],"pdf_url":"https://arxiv.org/pdf/2503.04353v1.pdf","comment":"8 pages, 8 Figures, 3 Tables"},{"id":"http://arxiv.org/abs/2503.04351v1","updated":"2025-03-06T11:49:43Z","published":"2025-03-06T11:49:43Z","title":"PLMP -- Point-Line Minimal Problems for Projective SfM","summary":"  We completely classify all minimal problems for Structure-from-Motion (SfM)\nwhere arrangements of points and lines are fully observed by multiple\nuncalibrated pinhole cameras. We find 291 minimal problems, 73 of which have\nunique solutions and can thus be solved linearly. Two of the linear problems\nallow an arbitrary number of views, while all other minimal problems have at\nmost 9 cameras. All minimal problems have at most 7 points and at most 12\nlines. We compute the number of solutions of each minimal problem, as this\ngives a measurement of the problem's intrinsic difficulty, and find that these\nnumber are relatively low (e.g., when comparing with minimal problems for\ncalibrated cameras). Finally, by exploring stabilizer subgroups of\nsubarrangements, we develop a geometric and systematic way to 1) factorize\nminimal problems into smaller problems, 2) identify minimal problems in\nunderconstrained problems, and 3) formally prove non-minimality.\n","authors":["Kim Kiehn","Albin Ahlbäck","Kathlén Kohn"],"pdf_url":"https://arxiv.org/pdf/2503.04351v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04344v1","updated":"2025-03-06T11:41:36Z","published":"2025-03-06T11:41:36Z","title":"LEDiT: Your Length-Extrapolatable Diffusion Transformer without\n  Positional Encoding","summary":"  Diffusion transformers(DiTs) struggle to generate images at resolutions\nhigher than their training resolutions. The primary obstacle is that the\nexplicit positional encodings(PE), such as RoPE, need extrapolation which\ndegrades performance when the inference resolution differs from training. In\nthis paper, we propose a Length-Extrapolatable Diffusion Transformer(LEDiT), a\nsimple yet powerful architecture to overcome this limitation. LEDiT needs no\nexplicit PEs, thereby avoiding extrapolation. The key innovations of LEDiT are\nintroducing causal attention to implicitly impart global positional information\nto tokens, while enhancing locality to precisely distinguish adjacent tokens.\nExperiments on 256x256 and 512x512 ImageNet show that LEDiT can scale the\ninference resolution to 512x512 and 1024x1024, respectively, while achieving\nbetter image quality compared to current state-of-the-art length extrapolation\nmethods(NTK-aware, YaRN). Moreover, LEDiT achieves strong extrapolation\nperformance with just 100K steps of fine-tuning on a pretrained DiT,\ndemonstrating its potential for integration into existing text-to-image DiTs.\n","authors":["Shen Zhang","Yaning Tan","Siyuan Liang","Linze Li","Ge Wu","Yuhao Chen","Shuheng Li","Zhenyu Zhao","Caihua Chen","Jiajun Liang","Yao Tang"],"pdf_url":"https://arxiv.org/pdf/2503.04344v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03644v2","updated":"2025-03-06T11:36:33Z","published":"2025-03-05T16:20:53Z","title":"DongbaMIE: A Multimodal Information Extraction Dataset for Evaluating\n  Semantic Understanding of Dongba Pictograms","summary":"  Dongba pictographs are the only pictographs still in use in the world. They\nhave pictorial ideographic features, and their symbols carry rich cultural and\ncontextual information. Due to the lack of relevant datasets, existing research\nhas difficulty in advancing the study of semantic understanding of Dongba\npictographs. To this end, we propose DongbaMIE, the first multimodal dataset\nfor semantic understanding and extraction of Dongba pictographs. The dataset\nconsists of Dongba pictograph images and their corresponding Chinese semantic\nannotations. It contains 23,530 sentence-level and 2,539 paragraph-level\nimages, covering four semantic dimensions: objects, actions, relations, and\nattributes. We systematically evaluate the GPT-4o, Gemini-2.0, and Qwen2-VL\nmodels. Experimental results show that the F1 scores of GPT-4o and Gemini in\nthe best object extraction are only 3.16 and 3.11 respectively. The F1 score of\nQwen2-VL after supervised fine-tuning is only 11.49. These results suggest that\ncurrent large multimodal models still face significant challenges in accurately\nrecognizing the diverse semantic information in Dongba pictographs. The dataset\ncan be obtained from this URL.\n","authors":["Xiaojun Bi","Shuo Li","Ziyue Wang","Fuwen Luo","Weizheng Qiao","Lu Han","Ziwei Sun","Peng Li","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2503.03644v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04333v1","updated":"2025-03-06T11:31:08Z","published":"2025-03-06T11:31:08Z","title":"GaussianVideo: Efficient Video Representation and Compression by\n  Gaussian Splatting","summary":"  Implicit Neural Representation for Videos (NeRV) has introduced a novel\nparadigm for video representation and compression, outperforming traditional\ncodecs. As model size grows, however, slow encoding and decoding speed and high\nmemory consumption hinder its application in practice. To address these\nlimitations, we propose a new video representation and compression method based\non 2D Gaussian Splatting to efficiently handle video data. Our proposed\ndeformable 2D Gaussian Splatting dynamically adapts the transformation of 2D\nGaussians at each frame, significantly reducing memory cost. Equipped with a\nmulti-plane-based spatiotemporal encoder and a lightweight decoder, it predicts\nchanges in color, coordinates, and shape of initialized Gaussians, given the\ntime step. By leveraging temporal gradients, our model effectively captures\ntemporal redundancy at negligible cost, significantly enhancing video\nrepresentation efficiency. Our method reduces GPU memory usage by up to 78.4%,\nand significantly expedites video processing, achieving 5.5x faster training\nand 12.5x faster decoding compared to the state-of-the-art NeRV methods.\n","authors":["Inseo Lee","Youngyoon Choi","Joonseok Lee"],"pdf_url":"https://arxiv.org/pdf/2503.04333v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04325v1","updated":"2025-03-06T11:18:22Z","published":"2025-03-06T11:18:22Z","title":"GBT-SAM: A Parameter-Efficient Depth-Aware Model for Generalizable Brain\n  tumour Segmentation on mp-MRI","summary":"  Gliomas are brain tumours that stand out for their highly lethal and\naggressive nature, which demands a precise approach in their diagnosis. Medical\nimage segmentation plays a crucial role in the evaluation and follow-up of\nthese tumours, allowing specialists to analyse their morphology. However,\nexisting methods for automatic glioma segmentation often lack generalization\ncapability across other brain tumour domains, require extensive computational\nresources, or fail to fully utilize the multi-parametric MRI (mp-MRI) data used\nto delineate them. In this work, we introduce GBT-SAM, a novel Generalizable\nBrain Tumour (GBT) framework that extends the Segment Anything Model (SAM) to\nbrain tumour segmentation tasks. Our method employs a two-step training\nprotocol: first, fine-tuning the patch embedding layer to process the entire\nmp-MRI modalities, and second, incorporating parameter-efficient LoRA blocks\nand a Depth-Condition block into the Vision Transformer (ViT) to capture\ninter-slice correlations. GBT-SAM achieves state-of-the-art performance on the\nAdult Glioma dataset (Dice Score of $93.54$) while demonstrating robust\ngeneralization across Meningioma, Pediatric Glioma, and Sub-Saharan Glioma\ndatasets. Furthermore, GBT-SAM uses less than 6.5M trainable parameters, thus\noffering an efficient solution for brain tumour segmentation. \\\\ Our code and\nmodels are available at https://github.com/vpulab/med-sam-brain .\n","authors":["Cecilia Diana-Albelda","Roberto Alcover-Couso","Álvaro García-Martín","Jesus Bescos","Marcos Escudero-Viñolo"],"pdf_url":"https://arxiv.org/pdf/2503.04325v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17634v2","updated":"2025-03-06T11:17:31Z","published":"2025-01-29T13:11:21Z","title":"Federated Learning With Individualized Privacy Through Client Sampling","summary":"  With growing concerns about user data collection, individualized privacy has\nemerged as a promising solution to balance protection and utility by accounting\nfor diverse user privacy preferences. Instead of enforcing a uniform level of\nanonymization for all users, this approach allows individuals to choose privacy\nsettings that align with their comfort levels. Building on this idea, we\npropose an adapted method for enabling Individualized Differential Privacy\n(IDP) in Federated Learning (FL) by handling clients according to their\npersonal privacy preferences. By extending the SAMPLE algorithm from\ncentralized settings to FL, we calculate client-specific sampling rates based\non their heterogeneous privacy budgets and integrate them into a modified\nIDP-FedAvg algorithm. We test this method under realistic privacy distributions\nand multiple datasets. The experimental results demonstrate that our approach\nachieves clear improvements over uniform DP baselines, reducing the trade-off\nbetween privacy and utility. Compared to the alternative SCALE method in\nrelated work, which assigns differing noise scales to clients, our method\nperforms notably better. However, challenges remain for complex tasks with\nnon-i.i.d. data, primarily stemming from the constraints of the decentralized\nsetting.\n","authors":["Lucas Lange","Ole Borchardt","Erhard Rahm"],"pdf_url":"https://arxiv.org/pdf/2501.17634v2.pdf","comment":"Accepted at 10th International Conference on Machine Learning\n  Technologies (ICMLT 2025)"},{"id":"http://arxiv.org/abs/2503.04322v1","updated":"2025-03-06T11:14:59Z","published":"2025-03-06T11:14:59Z","title":"A Modular Pipeline for 3D Object Tracking Using RGB Cameras","summary":"  Object tracking is a key challenge of computer vision with various\napplications that all require different architectures. Most tracking systems\nhave limitations such as constraining all movement to a 2D plane and they often\ntrack only one object. In this paper, we present a new modular pipeline that\ncalculates 3D trajectories of multiple objects. It is adaptable to various\nsettings where multiple time-synced and stationary cameras record moving\nobjects, using off the shelf webcams. Our pipeline was tested on the Table\nSetting Dataset, where participants are recorded with various sensors as they\nset a table with tableware objects. We need to track these manipulated objects,\nusing 6 rgb webcams. Challenges include: Detecting small objects in 9.874.699\ncamera frames, determining camera poses, discriminating between nearby and\noverlapping objects, temporary occlusions, and finally calculating a 3D\ntrajectory using the right subset of an average of 11.12.456 pixel coordinates\nper 3-minute trial. We implement a robust pipeline that results in accurate\ntrajectories with covariance of x,y,z-position as a confidence metric. It deals\ndynamically with appearing and disappearing objects, instantiating new Extended\nKalman Filters. It scales to hundreds of table-setting trials with very little\nhuman annotation input, even with the camera poses of each trial unknown. The\ncode is available at https://github.com/LarsBredereke/object_tracking\n","authors":["Lars Bredereke","Yale Hartmann","Tanja Schultz"],"pdf_url":"https://arxiv.org/pdf/2503.04322v1.pdf","comment":"9 pages, 11 figures, original paper not to be published anywhere else"},{"id":"http://arxiv.org/abs/2501.16981v3","updated":"2025-03-06T11:08:38Z","published":"2025-01-28T14:28:55Z","title":"Modulating CNN Features with Pre-Trained ViT Representations for\n  Open-Vocabulary Object Detection","summary":"  Owing to large-scale image-text contrastive training, pre-trained vision\nlanguage model (VLM) like CLIP shows superior open-vocabulary recognition\nability. Most existing open-vocabulary object detectors attempt to utilize the\npre-trained VLMs to attain generalized representation. F-ViT uses the\npre-trained visual encoder as the backbone network and freezes it during\ntraining. However, its frozen backbone doesn't benefit from the labeled data to\nstrengthen the representation for detection. Therefore, we propose a novel\ntwo-branch backbone network, named as \\textbf{V}iT-Feature-\\textbf{M}odulated\nMulti-Scale \\textbf{C}onvolutional Network (VMCNet), which consists of a\ntrainable convolutional branch, a frozen pre-trained ViT branch and a VMC\nmodule. The trainable CNN branch could be optimized with labeled data while the\nfrozen pre-trained ViT branch could keep the representation ability derived\nfrom large-scale pre-training. Then, the proposed VMC module could modulate the\nmulti-scale CNN features with the representations from ViT branch. With this\nproposed mixed structure, the detector is more likely to discover objects of\nnovel categories. Evaluated on two popular benchmarks, our method boosts the\ndetection performance on novel category and outperforms state-of-the-art\nmethods. On OV-COCO, the proposed method achieves 44.3\nAP$_{50}^{\\mathrm{novel}}$ with ViT-B/16 and 48.5 AP$_{50}^{\\mathrm{novel}}$\nwith ViT-L/14. On OV-LVIS, VMCNet with ViT-B/16 and ViT-L/14 reaches 27.8 and\n38.4 mAP$_{r}$.\n","authors":["Xiangyu Gao","Yu Dai","Benliu Qiu","Lanxiao Wang","Heqian Qiu","Hongliang Li"],"pdf_url":"https://arxiv.org/pdf/2501.16981v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.01879v3","updated":"2025-03-06T11:05:33Z","published":"2024-02-02T20:08:11Z","title":"$σ$-zero: Gradient-based Optimization of $\\ell_0$-norm Adversarial\n  Examples","summary":"  Evaluating the adversarial robustness of deep networks to gradient-based\nattacks is challenging. While most attacks consider $\\ell_2$- and\n$\\ell_\\infty$-norm constraints to craft input perturbations, only a few\ninvestigate sparse $\\ell_1$- and $\\ell_0$-norm attacks. In particular,\n$\\ell_0$-norm attacks remain the least studied due to the inherent complexity\nof optimizing over a non-convex and non-differentiable constraint. However,\nevaluating adversarial robustness under these attacks could reveal weaknesses\notherwise left untested with more conventional $\\ell_2$- and $\\ell_\\infty$-norm\nattacks. In this work, we propose a novel $\\ell_0$-norm attack, called\n$\\sigma$-zero, which leverages a differentiable approximation of the $\\ell_0$\nnorm to facilitate gradient-based optimization, and an adaptive projection\noperator to dynamically adjust the trade-off between loss minimization and\nperturbation sparsity. Extensive evaluations using MNIST, CIFAR10, and ImageNet\ndatasets, involving robust and non-robust models, show that\n$\\sigma$\\texttt{-zero} finds minimum $\\ell_0$-norm adversarial examples without\nrequiring any time-consuming hyperparameter tuning, and that it outperforms all\ncompeting sparse attacks in terms of success rate, perturbation size, and\nefficiency.\n","authors":["Antonio Emanuele Cinà","Francesco Villani","Maura Pintor","Lea Schönherr","Battista Biggio","Marcello Pelillo"],"pdf_url":"https://arxiv.org/pdf/2402.01879v3.pdf","comment":"Paper accepted at International Conference on Learning\n  Representations (ICLR 2025). Code available at\n  https://github.com/sigma0-advx/sigma-zero"},{"id":"http://arxiv.org/abs/2412.00156v3","updated":"2025-03-06T11:05:32Z","published":"2024-11-29T08:10:49Z","title":"VISION-XL: High Definition Video Inverse Problem Solver using Latent\n  Image Diffusion Models","summary":"  In this paper, we propose a novel framework for solving high-definition video\ninverse problems using latent image diffusion models. Building on recent\nadvancements in spatio-temporal optimization for video inverse problems using\nimage diffusion models, our approach leverages latent-space diffusion models to\nachieve enhanced video quality and resolution. To address the high\ncomputational demands of processing high-resolution frames, we introduce a\npseudo-batch consistent sampling strategy, allowing efficient operation on a\nsingle GPU. Additionally, to improve temporal consistency, we present\npseudo-batch inversion, an initialization technique that incorporates\ninformative latents from the measurement. By integrating with SDXL, our\nframework achieves state-of-the-art video reconstruction across a wide range of\nspatio-temporal inverse problems, including complex combinations of frame\naveraging and various spatial degradations, such as deblurring,\nsuper-resolution, and inpainting. Unlike previous methods, our approach\nsupports multiple aspect ratios (landscape, vertical, and square) and delivers\nHD-resolution reconstructions (exceeding 1280x720) in under 6 seconds per frame\non a single NVIDIA 4090 GPU.\n","authors":["Taesung Kwon","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2412.00156v3.pdf","comment":"Project page: https://vision-xl.github.io/"},{"id":"http://arxiv.org/abs/2501.10814v2","updated":"2025-03-06T11:05:23Z","published":"2025-01-18T16:23:09Z","title":"No More Sliding Window: Efficient 3D Medical Image Segmentation with\n  Differentiable Top-k Patch Sampling","summary":"  3D models surpass 2D models in CT/MRI segmentation by effectively capturing\ninter-slice relationships. However, the added depth dimension substantially\nincreases memory consumption. While patch-based training alleviates memory\nconstraints, it significantly slows down the inference speed due to the sliding\nwindow (SW) approach. We propose No-More-Sliding-Window (NMSW), a novel\nend-to-end trainable framework that enhances the efficiency of generic 3D\nsegmentation backbone during an inference step by eliminating the need for SW.\nNMSW employs a differentiable Top-k module to selectively sample only the most\nrelevant patches, thereby minimizing redundant computations. When patch-level\npredictions are insufficient, the framework intelligently leverages coarse\nglobal predictions to refine results. Evaluated across 3 tasks using 3\nsegmentation backbones, NMSW achieves competitive accuracy compared to SW\ninference while significantly reducing computational complexity by 91% (88.0 to\n8.00 TMACs). Moreover, it delivers a 9.1x faster inference on the H100 GPU\n(99.0 to 8.3 sec) and a 11.1x faster inference on the Xeon Gold CPU (2110 to\n189 sec). NMSW is model-agnostic, further boosting efficiency when integrated\nwith any existing efficient segmentation backbones.\n","authors":["Young Seok Jeon","Hongfei Yang","Huazhu Fu","Mengling Feng"],"pdf_url":"https://arxiv.org/pdf/2501.10814v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04314v1","updated":"2025-03-06T10:58:26Z","published":"2025-03-06T10:58:26Z","title":"S2Gaussian: Sparse-View Super-Resolution 3D Gaussian Splatting","summary":"  In this paper, we aim ambitiously for a realistic yet challenging problem,\nnamely, how to reconstruct high-quality 3D scenes from sparse low-resolution\nviews that simultaneously suffer from deficient perspectives and clarity.\nWhereas existing methods only deal with either sparse views or low-resolution\nobservations, they fail to handle such hybrid and complicated scenarios. To\nthis end, we propose a novel Sparse-view Super-resolution 3D Gaussian Splatting\nframework, dubbed S2Gaussian, that can reconstruct structure-accurate and\ndetail-faithful 3D scenes with only sparse and low-resolution views. The\nS2Gaussian operates in a two-stage fashion. In the first stage, we initially\noptimize a low-resolution Gaussian representation with depth regularization and\ndensify it to initialize the high-resolution Gaussians through a tailored\nGaussian Shuffle Split operation. In the second stage, we refine the\nhigh-resolution Gaussians with the super-resolved images generated from both\noriginal sparse views and pseudo-views rendered by the low-resolution\nGaussians. In which a customized blur-free inconsistency modeling scheme and a\n3D robust optimization strategy are elaborately designed to mitigate multi-view\ninconsistency and eliminate erroneous updates caused by imperfect supervision.\nExtensive experiments demonstrate superior results and in particular\nestablishing new state-of-the-art performances with more consistent geometry\nand finer details.\n","authors":["Yecong Wan","Mingwen Shao","Yuanshuo Cheng","Wangmeng Zuo"],"pdf_url":"https://arxiv.org/pdf/2503.04314v1.pdf","comment":"CVPR 2025"},{"id":"http://arxiv.org/abs/2503.04308v1","updated":"2025-03-06T10:51:04Z","published":"2025-03-06T10:51:04Z","title":"Shaken, Not Stirred: A Novel Dataset for Visual Understanding of Glasses\n  in Human-Robot Bartending Tasks","summary":"  Datasets for object detection often do not account for enough variety of\nglasses, due to their transparent and reflective properties. Specifically,\nopen-vocabulary object detectors, widely used in embodied robotic agents, fail\nto distinguish subclasses of glasses. This scientific gap poses an issue to\nrobotic applications that suffer from accumulating errors between detection,\nplanning, and action execution. The paper introduces a novel method for the\nacquisition of real-world data from RGB-D sensors that minimizes human effort.\nWe propose an auto-labeling pipeline that generates labels for all the acquired\nframes based on the depth measurements. We provide a novel real-world glass\nobject dataset that was collected on the Neuro-Inspired COLlaborator (NICOL), a\nhumanoid robot platform. The data set consists of 7850 images recorded from\nfive different cameras. We show that our trained baseline model outperforms\nstate-of-the-art open-vocabulary approaches. In addition, we deploy our\nbaseline model in an embodied agent approach to the NICOL platform, on which it\nachieves a success rate of 81% in a human-robot bartending scenario.\n","authors":["Lukáš Gajdošech","Hassan Ali","Jan-Gerrit Habekost","Martin Madaras","Matthias Kerzel","Stefan Wermter"],"pdf_url":"https://arxiv.org/pdf/2503.04308v1.pdf","comment":"Submitted to IEEE/RSJ International Conference on Intelligent Robots\n  and Systems (IROS) 2025"},{"id":"http://arxiv.org/abs/2412.01615v3","updated":"2025-03-06T10:49:58Z","published":"2024-12-02T15:38:44Z","title":"OmniGuard: Hybrid Manipulation Localization via Augmented Versatile Deep\n  Image Watermarking","summary":"  With the rapid growth of generative AI and its widespread application in\nimage editing, new risks have emerged regarding the authenticity and integrity\nof digital content. Existing versatile watermarking approaches suffer from\ntrade-offs between tamper localization precision and visual quality.\nConstrained by the limited flexibility of previous framework, their localized\nwatermark must remain fixed across all images. Under AIGC-editing, their\ncopyright extraction accuracy is also unsatisfactory. To address these\nchallenges, we propose OmniGuard, a novel augmented versatile watermarking\napproach that integrates proactive embedding with passive, blind extraction for\nrobust copyright protection and tamper localization. OmniGuard employs a hybrid\nforensic framework that enables flexible localization watermark selection and\nintroduces a degradation-aware tamper extraction network for precise\nlocalization under challenging conditions. Additionally, a lightweight\nAIGC-editing simulation layer is designed to enhance robustness across global\nand local editing. Extensive experiments show that OmniGuard achieves superior\nfidelity, robustness, and flexibility. Compared to the recent state-of-the-art\napproach EditGuard, our method outperforms it by 4.25dB in PSNR of the\ncontainer image, 20.7% in F1-Score under noisy conditions, and 14.8% in average\nbit accuracy.\n","authors":["Xuanyu Zhang","Zecheng Tang","Zhipei Xu","Runyi Li","Youmin Xu","Bin Chen","Feng Gao","Jian Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.01615v3.pdf","comment":"Accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2503.03370v2","updated":"2025-03-06T10:41:28Z","published":"2025-03-05T10:46:03Z","title":"MIAdapt: Source-free Few-shot Domain Adaptive Object Detection for\n  Microscopic Images","summary":"  Existing generic unsupervised domain adaptation approaches require access to\nboth a large labeled source dataset and a sufficient unlabeled target dataset\nduring adaptation. However, collecting a large dataset, even if unlabeled, is a\nchallenging and expensive endeavor, especially in medical imaging. In addition,\nconstraints such as privacy issues can result in cases where source data is\nunavailable. Taking in consideration these challenges, we propose MIAdapt, an\nadaptive approach for Microscopic Imagery Adaptation as a solution for\nSource-free Few-shot Domain Adaptive Object detection (SF-FSDA). We also define\ntwo competitive baselines (1) Faster-FreeShot and (2) MT-FreeShot. Extensive\nexperiments on the challenging M5-Malaria and Raabin-WBC datasets validate the\neffectiveness of MIAdapt. Without using any image from the source domain\nMIAdapt surpasses state-of-the-art source-free UDA (SF-UDA) methods by +21.3%\nmAP and few-shot domain adaptation (FSDA) approaches by +4.7% mAP on\nRaabin-WBC. Our code and models will be publicly available.\n","authors":["Nimra Dilawar","Sara Nadeem","Javed Iqbal","Waqas Sultani","Mohsen Ali"],"pdf_url":"https://arxiv.org/pdf/2503.03370v2.pdf","comment":"6 pages, 5 figures"},{"id":"http://arxiv.org/abs/2312.03286v2","updated":"2025-03-06T10:12:31Z","published":"2023-12-06T04:32:38Z","title":"Indirect Gradient Matching for Adversarial Robust Distillation","summary":"  Adversarial training significantly improves adversarial robustness, but\nsuperior performance is primarily attained with large models. This substantial\nperformance gap for smaller models has spurred active research into adversarial\ndistillation (AD) to mitigate the difference. Existing AD methods leverage the\nteacher's logits as a guide. In contrast to these approaches, we aim to\ntransfer another piece of knowledge from the teacher, the input gradient. In\nthis paper, we propose a distillation module termed Indirect Gradient\nDistillation Module (IGDM) that indirectly matches the student's input gradient\nwith that of the teacher. Experimental results show that IGDM seamlessly\nintegrates with existing AD methods, significantly enhancing their performance.\nParticularly, utilizing IGDM on the CIFAR-100 dataset improves the AutoAttack\naccuracy from 28.06% to 30.32% with the ResNet-18 architecture and from 26.18%\nto 29.32% with the MobileNetV2 architecture when integrated into the SOTA\nmethod without additional data augmentation.\n","authors":["Hongsin Lee","Seungju Cho","Changick Kim"],"pdf_url":"https://arxiv.org/pdf/2312.03286v2.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2503.04268v1","updated":"2025-03-06T09:57:26Z","published":"2025-03-06T09:57:26Z","title":"ControlFill: Spatially Adjustable Image Inpainting from Prompt Learning","summary":"  In this report, I present an inpainting framework named \\textit{ControlFill},\nwhich involves training two distinct prompts: one for generating plausible\nobjects within a designated mask (\\textit{creation}) and another for filling\nthe region by extending the background (\\textit{removal}). During the inference\nstage, these learned embeddings guide a diffusion network that operates without\nrequiring heavy text encoders. By adjusting the relative significance of the\ntwo prompts and employing classifier-free guidance, users can control the\nintensity of removal or creation. Furthermore, I introduce a method to\nspatially vary the intensity of guidance by assigning different scales to\nindividual pixels.\n","authors":["Boseong Jeon"],"pdf_url":"https://arxiv.org/pdf/2503.04268v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.18672v4","updated":"2025-03-06T09:55:41Z","published":"2025-01-30T18:51:54Z","title":"Drag Your Gaussian: Effective Drag-Based Editing with Score Distillation\n  for 3D Gaussian Splatting","summary":"  Recent advancements in 3D scene editing have been propelled by the rapid\ndevelopment of generative models. Existing methods typically utilize generative\nmodels to perform text-guided editing on 3D representations, such as 3D\nGaussian Splatting (3DGS). However, these methods are often limited to texture\nmodifications and fail when addressing geometric changes, such as editing a\ncharacter's head to turn around. Moreover, such methods lack accurate control\nover the spatial position of editing results, as language struggles to\nprecisely describe the extent of edits. To overcome these limitations, we\nintroduce DYG, an effective 3D drag-based editing method for 3D Gaussian\nSplatting. It enables users to conveniently specify the desired editing region\nand the desired dragging direction through the input of 3D masks and pairs of\ncontrol points, thereby enabling precise control over the extent of editing.\nDYG integrates the strengths of the implicit triplane representation to\nestablish the geometric scaffold of the editing results, effectively overcoming\nsuboptimal editing outcomes caused by the sparsity of 3DGS in the desired\nediting regions. Additionally, we incorporate a drag-based Latent Diffusion\nModel into our method through the proposed Drag-SDS loss function, enabling\nflexible, multi-view consistent, and fine-grained editing. Extensive\nexperiments demonstrate that DYG conducts effective drag-based editing guided\nby control point prompts, surpassing other baselines in terms of editing effect\nand quality, both qualitatively and quantitatively. Visit our project page at\nhttps://quyans.github.io/Drag-Your-Gaussian.\n","authors":["Yansong Qu","Dian Chen","Xinyang Li","Xiaofan Li","Shengchuan Zhang","Liujuan Cao","Rongrong Ji"],"pdf_url":"https://arxiv.org/pdf/2501.18672v4.pdf","comment":"Visit our project page at https://quyans.github.io/Drag-Your-Gaussian"},{"id":"http://arxiv.org/abs/2405.14736v2","updated":"2025-03-06T09:52:43Z","published":"2024-05-23T16:02:30Z","title":"GIFT: Unlocking Full Potential of Labels in Distilled Dataset at\n  Near-zero Cost","summary":"  Recent advancements in dataset distillation have demonstrated the significant\nbenefits of employing soft labels generated by pre-trained teacher models. In\nthis paper, we introduce a novel perspective by emphasizing the full\nutilization of labels. We first conduct a comprehensive comparison of various\nloss functions for soft label utilization in dataset distillation, revealing\nthat the model trained on the synthetic dataset exhibits high sensitivity to\nthe choice of loss function for soft label utilization. This finding highlights\nthe necessity of a universal loss function for training models on synthetic\ndatasets. Building on these insights, we introduce an extremely simple yet\nsurprisingly effective plug-and-play approach, GIFT, which encompasses soft\nlabel refinement and a cosine similarity-based loss function to efficiently\nleverage full label information. Extensive experiments indicate that GIFT\nconsistently enhances state-of-the-art dataset distillation methods across\nvarious dataset scales, without incurring additional computational costs.\nImportantly, GIFT significantly enhances cross-optimizer generalization, an\narea previously overlooked. For instance, on ImageNet-1K with IPC = 10, GIFT\nenhances the state-of-the-art method RDED by 30.8% in cross-optimizer\ngeneralization. Our code is available at https://github.com/LINs-lab/GIFT.\n","authors":["Xinyi Shang","Peng Sun","Tao Lin"],"pdf_url":"https://arxiv.org/pdf/2405.14736v2.pdf","comment":"https://github.com/LINs-lab/GIFT"},{"id":"http://arxiv.org/abs/2503.04258v1","updated":"2025-03-06T09:39:36Z","published":"2025-03-06T09:39:36Z","title":"TAIL: Text-Audio Incremental Learning","summary":"  Many studies combine text and audio to capture multi-modal information but\nthey overlook the model's generalization ability on new datasets. Introducing\nnew datasets may affect the feature space of the original dataset, leading to\ncatastrophic forgetting. Meanwhile, large model parameters can significantly\nimpact training performance. To address these limitations, we introduce a novel\ntask called Text-Audio Incremental Learning (TAIL) task for text-audio\nretrieval, and propose a new method, PTAT, Prompt Tuning for Audio-Text\nincremental learning. This method utilizes prompt tuning to optimize the model\nparameters while incorporating an audio-text similarity and feature\ndistillation module to effectively mitigate catastrophic forgetting. We\nbenchmark our method and previous incremental learning methods on AudioCaps,\nClotho, BBC Sound Effects and Audioset datasets, and our method outperforms\nprevious methods significantly, particularly demonstrating stronger resistance\nto forgetting on older datasets. Compared to the full-parameters Finetune\n(Sequential) method, our model only requires 2.42\\% of its parameters,\nachieving 4.46\\% higher performance.\n","authors":["Yingfei Sun","Xu Gu","Wei Ji","Hanbin Zhao","Hao Fei","Yifang Yin","Roger Zimmermann"],"pdf_url":"https://arxiv.org/pdf/2503.04258v1.pdf","comment":"4 figures, 5 tables"},{"id":"http://arxiv.org/abs/2503.04257v1","updated":"2025-03-06T09:39:09Z","published":"2025-03-06T09:39:09Z","title":"How to Move Your Dragon: Text-to-Motion Synthesis for Large-Vocabulary\n  Objects","summary":"  Motion synthesis for diverse object categories holds great potential for 3D\ncontent creation but remains underexplored due to two key challenges: (1) the\nlack of comprehensive motion datasets that include a wide range of high-quality\nmotions and annotations, and (2) the absence of methods capable of handling\nheterogeneous skeletal templates from diverse objects. To address these\nchallenges, we contribute the following: First, we augment the Truebones Zoo\ndataset, a high-quality animal motion dataset covering over 70 species, by\nannotating it with detailed text descriptions, making it suitable for\ntext-based motion synthesis. Second, we introduce rig augmentation techniques\nthat generate diverse motion data while preserving consistent dynamics,\nenabling models to adapt to various skeletal configurations. Finally, we\nredesign existing motion diffusion models to dynamically adapt to arbitrary\nskeletal templates, enabling motion synthesis for a diverse range of objects\nwith varying structures. Experiments show that our method learns to generate\nhigh-fidelity motions from textual descriptions for diverse and even unseen\nobjects, setting a strong foundation for motion synthesis across diverse object\ncategories and skeletal templates. Qualitative results are available on this\nlink: t2m4lvo.github.io\n","authors":["Wonkwang Lee","Jongwon Jeong","Taehong Moon","Hyeon-Jong Kim","Jaehyeon Kim","Gunhee Kim","Byeong-Uk Lee"],"pdf_url":"https://arxiv.org/pdf/2503.04257v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04250v1","updated":"2025-03-06T09:33:46Z","published":"2025-03-06T09:33:46Z","title":"An Egocentric Vision-Language Model based Portable Real-time Smart\n  Assistant","summary":"  We present Vinci, a vision-language system designed to provide real-time,\ncomprehensive AI assistance on portable devices. At its core, Vinci leverages\nEgoVideo-VL, a novel model that integrates an egocentric vision foundation\nmodel with a large language model (LLM), enabling advanced functionalities such\nas scene understanding, temporal grounding, video summarization, and future\nplanning. To enhance its utility, Vinci incorporates a memory module for\nprocessing long video streams in real time while retaining contextual history,\na generation module for producing visual action demonstrations, and a retrieval\nmodule that bridges egocentric and third-person perspectives to provide\nrelevant how-to videos for skill acquisition. Unlike existing systems that\noften depend on specialized hardware, Vinci is hardware-agnostic, supporting\ndeployment across a wide range of devices, including smartphones and wearable\ncameras. In our experiments, we first demonstrate the superior performance of\nEgoVideo-VL on multiple public benchmarks, showcasing its vision-language\nreasoning and contextual understanding capabilities. We then conduct a series\nof user studies to evaluate the real-world effectiveness of Vinci, highlighting\nits adaptability and usability in diverse scenarios. We hope Vinci can\nestablish a new framework for portable, real-time egocentric AI systems,\nempowering users with contextual and actionable insights. Including the\nfrontend, backend, and models, all codes of Vinci are available at\nhttps://github.com/OpenGVLab/vinci.\n","authors":["Yifei Huang","Jilan Xu","Baoqi Pei","Yuping He","Guo Chen","Mingfang Zhang","Lijin Yang","Zheng Nie","Jinyao Liu","Guoshun Fan","Dechen Lin","Fang Fang","Kunpeng Li","Chang Yuan","Xinyuan Chen","Yaohui Wang","Yali Wang","Yu Qiao","Limin Wang"],"pdf_url":"https://arxiv.org/pdf/2503.04250v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07481v5","updated":"2025-03-06T09:26:33Z","published":"2024-12-10T13:03:42Z","title":"Manta: Enhancing Mamba for Few-Shot Action Recognition of Long\n  Sub-Sequence","summary":"  In few-shot action recognition (FSAR), long sub-sequences of video naturally\nexpress entire actions more effectively. However, the high computational\ncomplexity of mainstream Transformer-based methods limits their application.\nRecent Mamba demonstrates efficiency in modeling long sequences, but directly\napplying Mamba to FSAR overlooks the importance of local feature modeling and\nalignment. Moreover, long sub-sequences within the same class accumulate\nintra-class variance, which adversely impacts FSAR performance. To solve these\nchallenges, we propose a Matryoshka MAmba and CoNtrasTive LeArning framework\n(Manta). Firstly, the Matryoshka Mamba introduces multiple Inner Modules to\nenhance local feature representation, rather than directly modeling global\nfeatures. An Outer Module captures dependencies of timeline between these local\nfeatures for implicit temporal alignment. Secondly, a hybrid contrastive\nlearning paradigm, combining both supervised and unsupervised methods, is\ndesigned to mitigate the negative effects of intra-class variance accumulation.\nThe Matryoshka Mamba and the hybrid contrastive learning paradigm operate in\ntwo parallel branches within Manta, enhancing Mamba for FSAR of long\nsub-sequence. Manta achieves new state-of-the-art performance on prominent\nbenchmarks, including SSv2, Kinetics, UCF101, and HMDB51. Extensive empirical\nstudies prove that Manta significantly improves FSAR of long sub-sequence from\nmultiple perspectives.\n","authors":["Wenbo Huang","Jinghui Zhang","Guang Li","Lei Zhang","Shuoyuan Wang","Fang Dong","Jiahui Jin","Takahiro Ogawa","Miki Haseyama"],"pdf_url":"https://arxiv.org/pdf/2412.07481v5.pdf","comment":"Accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2408.09110v3","updated":"2025-03-06T09:26:00Z","published":"2024-08-17T06:24:43Z","title":"Locate Anything on Earth: Advancing Open-Vocabulary Object Detection for\n  Remote Sensing Community","summary":"  Object detection, particularly open-vocabulary object detection, plays a\ncrucial role in Earth sciences, such as environmental monitoring, natural\ndisaster assessment, and land-use planning. However, existing open-vocabulary\ndetectors, primarily trained on natural-world images, struggle to generalize to\nremote sensing images due to a significant data domain gap. Thus, this paper\naims to advance the development of open-vocabulary object detection in remote\nsensing community. To achieve this, we first reformulate the task as Locate\nAnything on Earth (LAE) with the goal of detecting any novel concepts on Earth.\nWe then developed the LAE-Label Engine which collects, auto-annotates, and\nunifies up to 10 remote sensing datasets creating the LAE-1M - the first\nlarge-scale remote sensing object detection dataset with broad category\ncoverage. Using the LAE-1M, we further propose and train the novel LAE-DINO\nModel, the first open-vocabulary foundation object detector for the LAE task,\nfeaturing Dynamic Vocabulary Construction (DVC) and Visual-Guided Text Prompt\nLearning (VisGT) modules. DVC dynamically constructs vocabulary for each\ntraining batch, while VisGT maps visual features to semantic space, enhancing\ntext features. We comprehensively conduct experiments on established remote\nsensing benchmark DIOR, DOTAv2.0, as well as our newly introduced 80-class\nLAE-80C benchmark. Results demonstrate the advantages of the LAE-1M dataset and\nthe effectiveness of the LAE-DINO method.\n","authors":["Jiancheng Pan","Yanxing Liu","Yuqian Fu","Muyuan Ma","Jiahao Li","Danda Pani Paudel","Luc Van Gool","Xiaomeng Huang"],"pdf_url":"https://arxiv.org/pdf/2408.09110v3.pdf","comment":"15 pages, 11 figures"},{"id":"http://arxiv.org/abs/2503.00168v2","updated":"2025-03-06T09:23:35Z","published":"2025-02-28T20:30:56Z","title":"SSL4EO-S12 v1.1: A Multimodal, Multiseasonal Dataset for Pretraining,\n  Updated","summary":"  This technical report presents SSL4EO-S12 v1.1, a multimodal, multitemporal\nEarth Observation dataset designed for pretraining large-scale foundation\nmodels. Building on the success of SSL4EO-S12 v1.0, the new version addresses\nthe previous challenges of data misalignment and a limited data structure for\nlow-barrier, analysis-ready EO processing. SSL4EO-S12 v1.1 covers the world's\n10,000 largest cities and its surroundings within a 50 km radius across four\nseasons, resulting in a diverse collection of nearly one million patches.\nSSL4EO-S12 v1.1 packages the data in Zarr file format for cloud-efficient\nloading and representation of meta-information such as including cloud masks\nand geolocation. Released under the CC-BY-4.0 license, SSL4EO-S12 v1.1\nfacilitates open research and provides a robust foundation for future\nadvancements in self-supervised learning and geospatial analysis. The dataset\nis available online through https://datapub.fz-juelich.de/ssl4eo-s12, and we\nprovided additional resources at https://github.com/DLR-MF-DAS/SSL4EO-S12-v1.1.\n","authors":["Benedikt Blumenstiel","Nassim Ait Ali Braham","Conrad M Albrecht","Stefano Maurogiovanni","Paolo Fraccaro"],"pdf_url":"https://arxiv.org/pdf/2503.00168v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04235v1","updated":"2025-03-06T09:15:13Z","published":"2025-03-06T09:15:13Z","title":"Geometry-Constrained Monocular Scale Estimation Using Semantic\n  Segmentation for Dynamic Scenes","summary":"  Monocular visual localization plays a pivotal role in advanced driver\nassistance systems and autonomous driving by estimating a vehicle's ego-motion\nfrom a single pinhole camera. Nevertheless, conventional monocular visual\nodometry encoun-ters challenges in scale estimation due to the absence of depth\ninformation during projection. Previous methodologies, whether rooted in\nphysical constraints or deep learning paradigms, con-tend with issues related\nto computational complexity and the management of dynamic objects. This study\nextends our prior research, presenting innovative strategies for ego-motion\nestima-tion and the selection of ground points. Striving for a nuanced\nequilibrium between computational efficiency and precision, we propose a hybrid\nmethod that leverages the SegNeXt model for real-time applications,\nencompassing both ego-motion estimation and ground point selection. Our\nmethodology incorporates dy-namic object masks to eliminate unstable features\nand employs ground plane masks for meticulous triangulation. Furthermore, we\nexploit Geometry-constraint to delineate road regions for scale recovery. The\nintegration of this approach with the mo-nocular version of ORB-SLAM3\nculminates in the accurate esti-mation of a road model, a pivotal component in\nour scale recov-ery process. Rigorous experiments, conducted on the KITTI\nda-taset, systematically compare our method with existing monocu-lar visual\nodometry algorithms and contemporary scale recovery methodologies. The results\nundeniably confirm the superior ef-fectiveness of our approach, surpassing\nstate-of-the-art visual odometry algorithms. Our source code is available at\nhttps://git hub.com/bFr0zNq/MVOSegScale.\n","authors":["Hui Zhang","Zhiyang Wu","Qianqian Shangguan","Kang An"],"pdf_url":"https://arxiv.org/pdf/2503.04235v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07076v2","updated":"2025-03-06T09:13:28Z","published":"2024-11-11T15:51:48Z","title":"StoryTeller: Improving Long Video Description through Global\n  Audio-Visual Character Identification","summary":"  Existing large vision-language models (LVLMs) are largely limited to\nprocessing short, seconds-long videos and struggle with generating coherent\ndescriptions for extended video spanning minutes or more. Long video\ndescription introduces new challenges, such as consistent character\nidentification and plot-level descriptions incorporating both visual and audio\ninformation. To address these, we figure out audio-visual character\nidentification, matching character names to each dialogue, as a key factor. We\npropose StoryTeller, a system for generating dense descriptions of long videos,\nincorporating both low-level visual concepts and high-level plot information.\nStoryTeller uses a multimodal large language model that integrates visual,\naudio, and text modalities to perform audio-visual character identification on\nminute-long video clips. The results are then fed into a LVLM to enhance\nconsistency of video description. We validate our approach on movie description\ntasks and introduce MovieStory101, a dataset with dense descriptions for\nthree-minute movie clips. To evaluate long video descriptions, we create\nStoryQA, a large set of multiple-choice questions for MovieStory101 test set.\nWe assess descriptions by inputting them into GPT-4 to answer these questions,\nusing accuracy as an automatic evaluation metric. Experiments show that\nStoryTeller outperforms all open and closed-source baselines on StoryQA,\nachieving 9.5% higher accuracy than the strongest baseline, Gemini-1.5-pro, and\ndemonstrating a +15.56% advantage in human side-by-side evaluations.\nAdditionally, incorporating audio-visual character identification from\nStoryTeller improves the performance of all video description models, with\nGemini-1.5-pro and GPT-4o showing relative improvement of 5.5% and 13.0%,\nrespectively, in accuracy on StoryQA.\n","authors":["Yichen He","Yuan Lin","Jianchao Wu","Hanchong Zhang","Yuchen Zhang","Ruicheng Le"],"pdf_url":"https://arxiv.org/pdf/2411.07076v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09263v3","updated":"2025-03-06T09:10:07Z","published":"2024-11-14T08:02:14Z","title":"Rethinking Weight-Averaged Model-merging","summary":"  Model-merging has emerged as a powerful approach in deep learning, capable of\nenhancing model performance without any training. However, the underlying\nmechanisms that explain its effectiveness remain largely unexplored. In this\npaper, we investigate this technique from three novel perspectives to\nempirically provide deeper insights into why and how weight-averaged\nmodel-merging works: (1) we examine the intrinsic patterns captured by the\nlearning of the model weights, through the visualizations of their patterns on\nseveral datasets, showing that these weights often encode structured and\ninterpretable patterns and that is the essential why model-merging can work;\n(2) we mathematically and empirically investigate model ensemble merging\nstrategies based on averaging on weights versus averaging on features,\nproviding detailed analyses across diverse architectures and datasets; and (3)\nwe explore the impact on model-merging prediction stability in terms of\nchanging the parameter magnitude, revealing insights into the way of weight\naveraging works as regularization by showing the robustness across different\nparameter scales. Our findings shed light on the \"black box\" of weight-averaged\nmodel-merging, offering valuable insights and practical recommendations that\nadvance the model-merging process. The code is available at\nhttps://github.com/billhhh/Rethink-Merge.\n","authors":["Hu Wang","Congbo Ma","Ibrahim Almakky","Ian Reid","Gustavo Carneiro","Mohammad Yaqub"],"pdf_url":"https://arxiv.org/pdf/2411.09263v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04229v1","updated":"2025-03-06T09:09:18Z","published":"2025-03-06T09:09:18Z","title":"Synthetic Data is an Elegant GIFT for Continual Vision-Language Models","summary":"  Pre-trained Vision-Language Models (VLMs) require Continual Learning (CL) to\nefficiently update their knowledge and adapt to various downstream tasks\nwithout retraining from scratch. However, for VLMs, in addition to the loss of\nknowledge previously learned from downstream tasks, pre-training knowledge is\nalso corrupted during continual fine-tuning. This issue is exacerbated by the\nunavailability of original pre-training data, leaving VLM's generalization\nability degrading. In this paper, we propose GIFT, a novel continual\nfine-tuning approach that utilizes synthetic data to overcome catastrophic\nforgetting in VLMs. Taking advantage of recent advances in text-to-image\nsynthesis, we employ a pre-trained diffusion model to recreate both\npre-training and learned downstream task data. In this way, the VLM can revisit\nprevious knowledge through distillation on matching diffusion-generated images\nand corresponding text prompts. Leveraging the broad distribution and high\nalignment between synthetic image-text pairs in VLM's feature space, we propose\na contrastive distillation loss along with an image-text alignment constraint.\nTo further combat in-distribution overfitting and enhance distillation\nperformance with limited amount of generated data, we incorporate adaptive\nweight consolidation, utilizing Fisher information from these synthetic\nimage-text pairs and achieving a better stability-plasticity balance. Extensive\nexperiments demonstrate that our method consistently outperforms previous\nstate-of-the-art approaches across various settings.\n","authors":["Bin Wu","Wuxuan Shi","Jinqiao Wang","Mang Ye"],"pdf_url":"https://arxiv.org/pdf/2503.04229v1.pdf","comment":"This work is accepted by CVPR 2025. Modifications may be performed"},{"id":"http://arxiv.org/abs/2503.04223v1","updated":"2025-03-06T09:06:06Z","published":"2025-03-06T09:06:06Z","title":"Spiking Meets Attention: Efficient Remote Sensing Image Super-Resolution\n  with Attention Spiking Neural Networks","summary":"  Spiking neural networks (SNNs) are emerging as a promising alternative to\ntraditional artificial neural networks (ANNs), offering biological plausibility\nand energy efficiency. Despite these merits, SNNs are frequently hampered by\nlimited capacity and insufficient representation power, yet remain\nunderexplored in remote sensing super-resolution (SR) tasks. In this paper, we\nfirst observe that spiking signals exhibit drastic intensity variations across\ndiverse textures, highlighting an active learning state of the neurons. This\nobservation motivates us to apply SNNs for efficient SR of RSIs. Inspired by\nthe success of attention mechanisms in representing salient information, we\ndevise the spiking attention block (SAB), a concise yet effective component\nthat optimizes membrane potentials through inferred attention weights, which,\nin turn, regulates spiking activity for superior feature representation. Our\nkey contributions include: 1) we bridge the independent modulation between\ntemporal and channel dimensions, facilitating joint feature correlation\nlearning, and 2) we access the global self-similar patterns in large-scale\nremote sensing imagery to infer spatial attention weights, incorporating\neffective priors for realistic and faithful reconstruction. Building upon SAB,\nwe proposed SpikeSR, which achieves state-of-the-art performance across various\nremote sensing benchmarks such as AID, DOTA, and DIOR, while maintaining high\ncomputational efficiency. The code of SpikeSR will be available upon paper\nacceptance.\n","authors":["Yi Xiao","Qiangqiang Yuan","Kui Jiang","Qiang Zhang","Tingting Zheng","Chia-Wen Lin","Liangpei Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.04223v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.14153v3","updated":"2025-03-06T09:00:18Z","published":"2024-08-26T09:55:34Z","title":"Explaining Caption-Image Interactions in CLIP models with Second-Order\n  Attributions","summary":"  Dual encoder architectures like CLIP models map two types of inputs into a\nshared embedding space and predict similarities between them. Despite their\nsuccess, it is, however, not understood how these models compare their two\ninputs. Common first-order feature-attribution methods can only provide limited\ninsights into dual-encoders since their predictions depend on\nfeature-interactions rather than on individual features. In this paper, we\nfirst derive a second-order method enabling the attribution of predictions by\nany differentiable dual encoder onto feature-interactions between its inputs.\nSecond, we apply our method to CLIP models and show that they learn\nfine-grained correspondences between parts of captions and regions in images.\nThey match objects across input modes also account for mismatches. This\nvisual-linguistic grounding ability, however, varies heavily between object\nclasses and exhibits pronounced out-of-domain effects. We can identify\nindividual errors as well as systematic failure categories including object\ncoverage, unusual scenes and correlated contexts.\n","authors":["Lucas Möller","Pascal Tilli","Ngoc Thang Vu","Sebastian Padó"],"pdf_url":"https://arxiv.org/pdf/2408.14153v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04215v1","updated":"2025-03-06T08:52:29Z","published":"2025-03-06T08:52:29Z","title":"Energy-Guided Optimization for Personalized Image Editing with\n  Pretrained Text-to-Image Diffusion Models","summary":"  The rapid advancement of pretrained text-driven diffusion models has\nsignificantly enriched applications in image generation and editing. However,\nas the demand for personalized content editing increases, new challenges emerge\nespecially when dealing with arbitrary objects and complex scenes. Existing\nmethods usually mistakes mask as the object shape prior, which struggle to\nachieve a seamless integration result. The mostly used inversion noise\ninitialization also hinders the identity consistency towards the target object.\nTo address these challenges, we propose a novel training-free framework that\nformulates personalized content editing as the optimization of edited images in\nthe latent space, using diffusion models as the energy function guidance\nconditioned by reference text-image pairs. A coarse-to-fine strategy is\nproposed that employs text energy guidance at the early stage to achieve a\nnatural transition toward the target class and uses point-to-point\nfeature-level image energy guidance to perform fine-grained appearance\nalignment with the target object. Additionally, we introduce the latent space\ncontent composition to enhance overall identity consistency with the target.\nExtensive experiments demonstrate that our method excels in object replacement\neven with a large domain gap, highlighting its potential for high-quality,\npersonalized image editing.\n","authors":["Rui Jiang","Xinghe Fu","Guangcong Zheng","Teng Li","Taiping Yao","Xi Li"],"pdf_url":"https://arxiv.org/pdf/2503.04215v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.07155v3","updated":"2025-03-06T08:51:28Z","published":"2024-05-12T04:18:10Z","title":"Meta-Learned Modality-Weighted Knowledge Distillation for Robust\n  Multi-Modal Learning with Missing Data","summary":"  In multi-modal learning, some modalities are more influential than others,\nand their absence can have a significant impact on classification/segmentation\naccuracy. Addressing this challenge, we propose a novel approach called\nMeta-learned Modality-weighted Knowledge Distillation (MetaKD), which enables\nmulti-modal models to maintain high accuracy even when key modalities are\nmissing. MetaKD adaptively estimates the importance weight of each modality\nthrough a meta-learning process. These learned importance weights guide a\npairwise modality-weighted knowledge distillation process, allowing\nhigh-importance modalities to transfer knowledge to lower-importance ones,\nresulting in robust performance despite missing inputs. Unlike previous methods\nin the field, which are often task-specific and require significant\nmodifications, our approach is designed to work in multiple tasks (e.g.,\nsegmentation and classification) with minimal adaptation. Experimental results\non five prevalent datasets, including three Brain Tumor Segmentation datasets\n(BraTS2018, BraTS2019 and BraTS2020), the Alzheimer's Disease Neuroimaging\nInitiative (ADNI) classification dataset and the Audiovision-MNIST\nclassification dataset, demonstrate the proposed model is able to outperform\nthe compared models by a large margin. The code is available at\nhttps://github.com/billhhh/MetaKD.\n","authors":["Hu Wang","Salma Hassan","Yuyuan Liu","Congbo Ma","Yuanhong Chen","Yutong Xie","Mostafa Salem","Yu Tian","Jodie Avery","Louise Hull","Ian Reid","Mohammad Yaqub","Gustavo Carneiro"],"pdf_url":"https://arxiv.org/pdf/2405.07155v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04207v1","updated":"2025-03-06T08:31:40Z","published":"2025-03-06T08:31:40Z","title":"Bridging the Vision-Brain Gap with an Uncertainty-Aware Blur Prior","summary":"  Can our brain signals faithfully reflect the original visual stimuli, even\nincluding high-frequency details? Although human perceptual and cognitive\ncapacities enable us to process and remember visual information, these\nabilities are constrained by several factors, such as limited attentional\nresources and the finite capacity of visual memory. When visual stimuli are\nprocessed by human visual system into brain signals, some information is\ninevitably lost, leading to a discrepancy known as the \\textbf{System GAP}.\nAdditionally, perceptual and cognitive dynamics, along with technical noise in\nsignal acquisition, degrade the fidelity of brain signals relative to the\nvisual stimuli, known as the \\textbf{Random GAP}. When encoded brain\nrepresentations are directly aligned with the corresponding pretrained image\nfeatures, the System GAP and Random GAP between paired data challenge the\nmodel, requiring it to bridge these gaps. However, in the context of limited\npaired data, these gaps are difficult for the model to learn, leading to\noverfitting and poor generalization to new data. To address these GAPs, we\npropose a simple yet effective approach called the \\textbf{Uncertainty-aware\nBlur Prior (UBP)}. It estimates the uncertainty within the paired data,\nreflecting the mismatch between brain signals and visual stimuli. Based on this\nuncertainty, UBP dynamically blurs the high-frequency details of the original\nimages, reducing the impact of the mismatch and improving alignment. Our method\nachieves a top-1 accuracy of \\textbf{50.9\\%} and a top-5 accuracy of\n\\textbf{79.7\\%} on the zero-shot brain-to-image retrieval task, surpassing\nprevious state-of-the-art methods by margins of \\textbf{13.7\\%} and\n\\textbf{9.8\\%}, respectively. Code is available at\n\\href{https://github.com/HaitaoWuTJU/Uncertainty-aware-Blur-Prior}{GitHub}.\n","authors":["Haitao Wu","Qing Li","Changqing Zhang","Zhen He","Xiaomin Ying"],"pdf_url":"https://arxiv.org/pdf/2503.04207v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04205v1","updated":"2025-03-06T08:30:33Z","published":"2025-03-06T08:30:33Z","title":"Learning 3D Medical Image Models From Brain Functional Connectivity\n  Network Supervision For Mental Disorder Diagnosis","summary":"  In MRI-based mental disorder diagnosis, most previous studies focus on\nfunctional connectivity network (FCN) derived from functional MRI (fMRI).\nHowever, the small size of annotated fMRI datasets restricts its wide\napplication. Meanwhile, structural MRIs (sMRIs), such as 3D T1-weighted (T1w)\nMRI, which are commonly used and readily accessible in clinical settings, are\noften overlooked. To integrate the complementary information from both function\nand structure for improved diagnostic accuracy, we propose CINP (Contrastive\nImage-Network Pre-training), a framework that employs contrastive learning\nbetween sMRI and FCN. During pre-training, we incorporate masked image modeling\nand network-image matching to enhance visual representation learning and\nmodality alignment. Since the CINP facilitates knowledge transfer from FCN to\nsMRI, we introduce network prompting. It utilizes only sMRI from suspected\npatients and a small amount of FCNs from different patient classes for\ndiagnosing mental disorders, which is practical in real-world clinical\nscenario. The competitive performance on three mental disorder diagnosis tasks\ndemonstrate the effectiveness of the CINP in integrating multimodal MRI\ninformation, as well as the potential of incorporating sMRI into clinical\ndiagnosis using network prompting.\n","authors":["Xingcan Hu","Wei Wang","Li Xiao"],"pdf_url":"https://arxiv.org/pdf/2503.04205v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04204v1","updated":"2025-03-06T08:30:18Z","published":"2025-03-06T08:30:18Z","title":"FUSE: First-Order and Second-Order Unified SynthEsis in Stochastic\n  Optimization","summary":"  Stochastic optimization methods have actively been playing a critical role in\nmodern machine learning algorithms to deliver decent performance. While\nnumerous works have proposed and developed diverse approaches, first-order and\nsecond-order methods are in entirely different situations. The former is\nsignificantly pivotal and dominating in emerging deep learning but only leads\nconvergence to a stationary point. However, second-order methods are less\npopular due to their computational intensity in large-dimensional problems.\nThis paper presents a novel method that leverages both the first-order and\nsecond-order methods in a unified algorithmic framework, termed FUSE, from\nwhich a practical version (PV) is derived accordingly. FUSE-PV stands as a\nsimple yet efficient optimization method involving a switch-over between first\nand second orders. Additionally, we develop different criteria that determine\nwhen to switch. FUSE-PV has provably shown a smaller computational complexity\nthan SGD and Adam. To validate our proposed scheme, we present an ablation\nstudy on several simple test functions and show a comparison with baselines for\nbenchmark datasets.\n","authors":["Zhanhong Jiang","Md Zahid Hasan","Aditya Balu","Joshua R. Waite","Genyi Huang","Soumik Sarkar"],"pdf_url":"https://arxiv.org/pdf/2503.04204v1.pdf","comment":"6 pages, 7 figures"},{"id":"http://arxiv.org/abs/2411.13056v2","updated":"2025-03-06T08:28:09Z","published":"2024-11-20T06:08:21Z","title":"Efficient Masked AutoEncoder for Video Object Counting and A Large-Scale\n  Benchmark","summary":"  The dynamic imbalance of the fore-background is a major challenge in video\nobject counting, which is usually caused by the sparsity of target objects.\nThis remains understudied in existing works and often leads to severe\nunder-/over-prediction errors. To tackle this issue in video object counting,\nwe propose a density-embedded Efficient Masked Autoencoder Counting (E-MAC)\nframework in this paper. To empower the model's representation ability on\ndensity regression, we develop a new $\\mathtt{D}$ensity-$\\mathtt{E}$mbedded\n$\\mathtt{M}$asked m$\\mathtt{O}$deling ($\\mathtt{DEMO}$) method, which first\ntakes the density map as an auxiliary modality to perform multimodal\nself-representation learning for image and density map. Although\n$\\mathtt{DEMO}$ contributes to effective cross-modal regression guidance, it\nalso brings in redundant background information, making it difficult to focus\non the foreground regions. To handle this dilemma, we propose an efficient\nspatial adaptive masking derived from density maps to boost efficiency.\nMeanwhile, we employ an optical flow-based temporal collaborative fusion\nstrategy to effectively capture the dynamic variations across frames, aligning\nfeatures to derive multi-frame density residuals. The counting accuracy of the\ncurrent frame is boosted by harnessing the information from adjacent frames. In\naddition, considering that most existing datasets are limited to human-centric\nscenarios, we first propose a large video bird counting dataset, DroneBird, in\nnatural scenarios for migratory bird protection. Extensive experiments on three\ncrowd datasets and our \\textit{DroneBird} validate our superiority against the\ncounterparts. The code and dataset are available.\n","authors":["Bing Cao","Quanhao Lu","Jiekang Feng","Qilong Wang","Qinghua Hu","Pengfei Zhu"],"pdf_url":"https://arxiv.org/pdf/2411.13056v2.pdf","comment":"ICLR25"},{"id":"http://arxiv.org/abs/2503.04199v1","updated":"2025-03-06T08:27:51Z","published":"2025-03-06T08:27:51Z","title":"MASTER: Multimodal Segmentation with Text Prompts","summary":"  RGB-Thermal fusion is a potential solution for various weather and light\nconditions in challenging scenarios. However, plenty of studies focus on\ndesigning complex modules to fuse different modalities. With the widespread\napplication of large language models (LLMs), valuable information can be more\neffectively extracted from natural language. Therefore, we aim to leverage the\nadvantages of large language models to design a structurally simple and highly\nadaptable multimodal fusion model architecture. We proposed MultimodAl\nSegmentation with TExt PRompts (MASTER) architecture, which integrates LLM into\nthe fusion of RGB-Thermal multimodal data and allows complex query text to\nparticipate in the fusion process. Our model utilizes a dual-path structure to\nextract information from different modalities of images. Additionally, we\nemploy LLM as the core module for multimodal fusion, enabling the model to\ngenerate learnable codebook tokens from RGB, thermal images, and textual\ninformation. A lightweight image decoder is used to obtain semantic\nsegmentation results. The proposed MASTER performs exceptionally well in\nbenchmark tests across various automated driving scenarios, yielding promising\nresults.\n","authors":["Fuyang Liu","Shun Lu","Jilin Mei","Yu Hu"],"pdf_url":"https://arxiv.org/pdf/2503.04199v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04191v1","updated":"2025-03-06T08:06:03Z","published":"2025-03-06T08:06:03Z","title":"Conformal forecasting for surgical instrument trajectory","summary":"  Forecasting surgical instrument trajectories and predicting the next surgical\naction recently started to attract attention from the research community. Both\nthese tasks are crucial for automation and assistance in endoscopy surgery.\nGiven the safety-critical nature of these tasks, reliable uncertainty\nquantification is essential. Conformal prediction is a fast-growing and widely\nrecognized framework for uncertainty estimation in machine learning and\ncomputer vision, offering distribution-free, theoretically valid prediction\nintervals. In this work, we explore the application of standard conformal\nprediction and conformalized quantile regression to estimate uncertainty in\nforecasting surgical instrument motion, i.e., predicting direction and\nmagnitude of surgical instruments' future motion. We analyze and compare their\ncoverage and interval sizes, assessing the impact of multiple hypothesis\ntesting and correction methods. Additionally, we show how these techniques can\nbe employed to produce useful uncertainty heatmaps. To the best of our\nknowledge, this is the first study applying conformal prediction to surgical\nguidance, marking an initial step toward constructing principled prediction\nintervals with formal coverage guarantees in this domain.\n","authors":["Sara Sangalli","Gary Sarwin","Ertunc Erdil","Carlo Serra","Ender Konukoglu"],"pdf_url":"https://arxiv.org/pdf/2503.04191v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04171v1","updated":"2025-03-06T07:36:45Z","published":"2025-03-06T07:36:45Z","title":"DuCos: Duality Constrained Depth Super-Resolution via Foundation Model","summary":"  We introduce DuCos, a novel depth super-resolution framework grounded in\nLagrangian duality theory, offering a flexible integration of multiple\nconstraints and reconstruction objectives to enhance accuracy and robustness.\nOur DuCos is the first to significantly improve generalization across diverse\nscenarios with foundation models as prompts. The prompt design consists of two\nkey components: Correlative Fusion (CF) and Gradient Regulation (GR). CF\nfacilitates precise geometric alignment and effective fusion between prompt and\ndepth features, while GR refines depth predictions by enforcing consistency\nwith sharp-edged depth maps derived from foundation models. Crucially, these\nprompts are seamlessly embedded into the Lagrangian constraint term, forming a\nsynergistic and principled framework. Extensive experiments demonstrate that\nDuCos outperforms existing state-of-the-art methods, achieving superior\naccuracy, robustness, and generalization. The source codes and pre-trained\nmodels will be publicly available.\n","authors":["Zhiqiang Yan","Zhengxue Wang","Haoye Dong","Jun Li","Jian Yang","Gim Hee Lee"],"pdf_url":"https://arxiv.org/pdf/2503.04171v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04167v1","updated":"2025-03-06T07:29:33Z","published":"2025-03-06T07:29:33Z","title":"The Role of Visual Modality in Multimodal Mathematical Reasoning:\n  Challenges and Insights","summary":"  Recent research has increasingly focused on multimodal mathematical\nreasoning, particularly emphasizing the creation of relevant datasets and\nbenchmarks. Despite this, the role of visual information in reasoning has been\nunderexplored. Our findings show that existing multimodal mathematical models\nminimally leverage visual information, and model performance remains largely\nunaffected by changes to or removal of images in the dataset. We attribute this\nto the dominance of textual information and answer options that inadvertently\nguide the model to correct answers. To improve evaluation methods, we introduce\nthe HC-M3D dataset, specifically designed to require image reliance for\nproblem-solving and to challenge models with similar, yet distinct, images that\nchange the correct answer. In testing leading models, their failure to detect\nthese subtle visual differences suggests limitations in current visual\nperception capabilities. Additionally, we observe that the common approach of\nimproving general VQA capabilities by combining various types of image encoders\ndoes not contribute to math reasoning performance. This finding also presents a\nchallenge to enhancing visual reliance during math reasoning. Our benchmark and\ncode would be available at\n\\href{https://github.com/Yufang-Liu/visual_modality_role}{https://github.com/Yufang-Liu/visual\\_modality\\_role}.\n","authors":["Yufang Liu","Yao Du","Tao Ji","Jianing Wang","Yang Liu","Yuanbin Wu","Aimin Zhou","Mengdi Zhang","Xunliang Cai"],"pdf_url":"https://arxiv.org/pdf/2503.04167v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.11505v4","updated":"2025-03-06T07:26:35Z","published":"2024-11-18T12:05:27Z","title":"LaVin-DiT: Large Vision Diffusion Transformer","summary":"  This paper presents the Large Vision Diffusion Transformer (LaVin-DiT), a\nscalable and unified foundation model designed to tackle over 20 computer\nvision tasks in a generative framework. Unlike existing large vision models\ndirectly adapted from natural language processing architectures, which rely on\nless efficient autoregressive techniques and disrupt spatial relationships\nessential for vision data, LaVin-DiT introduces key innovations to optimize\ngenerative performance for vision tasks. First, to address the high\ndimensionality of visual data, we incorporate a spatial-temporal variational\nautoencoder that encodes data into a continuous latent space. Second, for\ngenerative modeling, we develop a joint diffusion transformer that\nprogressively produces vision outputs. Third, for unified multi-task training,\nin-context learning is implemented. Input-target pairs serve as task context,\nwhich guides the diffusion transformer to align outputs with specific tasks\nwithin the latent space. During inference, a task-specific context set and test\ndata as queries allow LaVin-DiT to generalize across tasks without fine-tuning.\nTrained on extensive vision datasets, the model is scaled from 0.1B to 3.4B\nparameters, demonstrating substantial scalability and state-of-the-art\nperformance across diverse vision tasks. This work introduces a novel pathway\nfor large vision foundation models, underscoring the promising potential of\ndiffusion transformers. The code and models are available.\n","authors":["Zhaoqing Wang","Xiaobo Xia","Runnan Chen","Dongdong Yu","Changhu Wang","Mingming Gong","Tongliang Liu"],"pdf_url":"https://arxiv.org/pdf/2411.11505v4.pdf","comment":"37 pages, 30 figures, 4 tables. Accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2503.04165v1","updated":"2025-03-06T07:25:43Z","published":"2025-03-06T07:25:43Z","title":"WeakSupCon: Weakly Supervised Contrastive Learning for Encoder\n  Pre-training","summary":"  Weakly supervised multiple instance learning (MIL) is a challenging task\ngiven that only bag-level labels are provided, while each bag typically\ncontains multiple instances. This topic has been extensively studied in\nhistopathological image analysis, where labels are usually available only at\nthe whole slide image (WSI) level, while each whole slide image can be divided\ninto thousands of small image patches for training. The dominant MIL approaches\ntake fixed patch features as inputs to address computational constraints and\nensure model stability. These features are commonly generated by encoders\npre-trained on ImageNet, foundation encoders pre-trained on large datasets, or\nthrough self-supervised learning on local datasets. While the self-supervised\nencoder pre-training on the same dataset as downstream MIL tasks helps mitigate\ndomain shift and generate better features, the bag-level labels are not\nutilized during the process, and the features of patches from different\ncategories may cluster together, reducing classification performance on MIL\ntasks. Recently, pre-training with supervised contrastive learning (SupCon) has\ndemonstrated superior performance compared to self-supervised contrastive\nlearning and even end-to-end training on traditional image classification\ntasks. In this paper, we propose a novel encoder pre-training method for\ndownstream MIL tasks called Weakly Supervised Contrastive Learning (WeakSupCon)\nthat utilizes bag-level labels. In our method, we employ multi-task learning\nand define distinct contrastive learning losses for samples with different bag\nlabels. Our experiments demonstrate that the features generated using\nWeakSupCon significantly enhance MIL classification performance compared to\nself-supervised approaches across three datasets.\n","authors":["Bodong Zhang","Hamid Manoochehri","Beatrice S. Knudsen","Tolga Tasdizen"],"pdf_url":"https://arxiv.org/pdf/2503.04165v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01234v2","updated":"2025-03-06T07:11:32Z","published":"2025-03-03T06:57:54Z","title":"Self-Adaptive Gamma Context-Aware SSM-based Model for Metal Defect\n  Detection","summary":"  Metal defect detection is critical in industrial quality assurance, yet\nexisting methods struggle with grayscale variations and complex defect states,\nlimiting its robustness. To address these challenges, this paper proposes a\nSelf-Adaptive Gamma Context-Aware SSM-based model(GCM-DET). This advanced\ndetection framework integrating a Dynamic Gamma Correction (GC) module to\nenhance grayscale representation and optimize feature extraction for precise\ndefect reconstruction. A State-Space Search Management (SSM) architecture\ncaptures robust multi-scale features, effectively handling defects of varying\nshapes and scales. Focal Loss is employed to mitigate class imbalance and\nrefine detection accuracy. Additionally, the CD5-DET dataset is introduced,\nspecifically designed for port container maintenance, featuring significant\ngrayscale variations and intricate defect patterns. Experimental results\ndemonstrate that the proposed model achieves substantial improvements, with\nmAP@0.5 gains of 27.6\\%, 6.6\\%, and 2.6\\% on the CD5-DET, NEU-DET, and GC10-DET\ndatasets.\n","authors":["Sijin Sun","Ming Deng","Xingrui Yu","Xinyu Xi","Liangbin Zhao"],"pdf_url":"https://arxiv.org/pdf/2503.01234v2.pdf","comment":"19 pages, 9 figures, under review"},{"id":"http://arxiv.org/abs/2410.14595v2","updated":"2025-03-06T07:06:50Z","published":"2024-10-18T16:48:31Z","title":"DRACO-DehazeNet: An Efficient Image Dehazing Network Combining Detail\n  Recovery and a Novel Contrastive Learning Paradigm","summary":"  Image dehazing is crucial for clarifying images obscured by haze or fog, but\ncurrent learning-based approaches is dependent on large volumes of training\ndata and hence consumed significant computational power. Additionally, their\nperformance is often inadequate under non-uniform or heavy haze. To address\nthese challenges, we developed the Detail Recovery And Contrastive DehazeNet,\nwhich facilitates efficient and effective dehazing via a dense dilated inverted\nresidual block and an attention-based detail recovery network that tailors\nenhancements to specific dehazed scene contexts. A major innovation is its\nability to train effectively with limited data, achieved through a novel\nquadruplet loss-based contrastive dehazing paradigm. This approach distinctly\nseparates hazy and clear image features while also distinguish lower-quality\nand higher-quality dehazed images obtained from each sub-modules of our\nnetwork, thereby refining the dehazing process to a larger extent. Extensive\ntests on a variety of benchmarked haze datasets demonstrated the superiority of\nour approach. The code repository for this work is available at\nhttps://github.com/GreedYLearner1146/DRACO-DehazeNet.\n","authors":["Gao Yu Lee","Tanmoy Dam","Md Meftahul Ferdaus","Daniel Puiu Poenar","Vu Duong"],"pdf_url":"https://arxiv.org/pdf/2410.14595v2.pdf","comment":"Once the paper is accepted and published, the copyright will be\n  transferred to the corresponding journal"},{"id":"http://arxiv.org/abs/2503.04154v1","updated":"2025-03-06T07:02:13Z","published":"2025-03-06T07:02:13Z","title":"CA-W3D: Leveraging Context-Aware Knowledge for Weakly Supervised\n  Monocular 3D Detection","summary":"  Weakly supervised monocular 3D detection, while less annotation-intensive,\noften struggles to capture the global context required for reliable 3D\nreasoning. Conventional label-efficient methods focus on object-centric\nfeatures, neglecting contextual semantic relationships that are critical in\ncomplex scenes. In this work, we propose a Context-Aware Weak Supervision for\nMonocular 3D object detection, namely CA-W3D, to address this limitation in a\ntwo-stage training paradigm. Specifically, we first introduce a pre-training\nstage employing Region-wise Object Contrastive Matching (ROCM), which aligns\nregional object embeddings derived from a trainable monocular 3D encoder and a\nfrozen open-vocabulary 2D visual grounding model. This alignment encourages the\nmonocular encoder to discriminate scene-specific attributes and acquire richer\ncontextual knowledge. In the second stage, we incorporate a pseudo-label\ntraining process with a Dual-to-One Distillation (D2OD) mechanism, which\neffectively transfers contextual priors into the monocular encoder while\npreserving spatial fidelity and maintaining computational efficiency during\ninference. Extensive experiments conducted on the public KITTI benchmark\ndemonstrate the effectiveness of our approach, surpassing the SoTA method over\nall metrics, highlighting the importance of contextual-aware knowledge in\nweakly-supervised monocular 3D detection.\n","authors":["Chupeng Liu","Runkai Zhao","Weidong Cai"],"pdf_url":"https://arxiv.org/pdf/2503.04154v1.pdf","comment":"The paper includes 8 pages, 6 figures and 4 tables"},{"id":"http://arxiv.org/abs/2503.04151v1","updated":"2025-03-06T07:01:08Z","published":"2025-03-06T07:01:08Z","title":"Robust Multi-View Learning via Representation Fusion of Sample-Level\n  Attention and Alignment of Simulated Perturbation","summary":"  Recently, multi-view learning (MVL) has garnered significant attention due to\nits ability to fuse discriminative information from multiple views. However,\nreal-world multi-view datasets are often heterogeneous and imperfect, which\nusually makes MVL methods designed for specific combinations of views lack\napplication potential and limits their effectiveness. To address this issue, we\npropose a novel robust MVL method (namely RML) with simultaneous representation\nfusion and alignment. Specifically, we introduce a simple yet effective\nmulti-view transformer fusion network where we transform heterogeneous\nmulti-view data into homogeneous word embeddings, and then integrate multiple\nviews by the sample-level attention mechanism to obtain a fused representation.\nFurthermore, we propose a simulated perturbation based multi-view contrastive\nlearning framework that dynamically generates the noise and unusable\nperturbations for simulating imperfect data conditions. The simulated noisy and\nunusable data obtain two distinct fused representations, and we utilize\ncontrastive learning to align them for learning discriminative and robust\nrepresentations. Our RML is self-supervised and can also be applied for\ndownstream tasks as a regularization. In experiments, we employ it in\nunsupervised multi-view clustering, noise-label classification, and as a\nplug-and-play module for cross-modal hashing retrieval. Extensive comparison\nexperiments and ablation studies validate the effectiveness of RML.\n","authors":["Jie Xu","Na Zhao","Gang Niu","Masashi Sugiyama","Xiaofeng Zhu"],"pdf_url":"https://arxiv.org/pdf/2503.04151v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.04014v3","updated":"2025-03-06T06:55:15Z","published":"2023-07-08T16:46:16Z","title":"Novel Pipeline for Diagnosing Acute Lymphoblastic Leukemia Sensitive to\n  Related Biomarkers","summary":"  Acute Lymphoblastic Leukemia (ALL) is one of the most common types of\nchildhood blood cancer. The quick start of the treatment process is critical to\nsaving the patient's life, and for this reason, early diagnosis of this disease\nis essential. Examining the blood smear images of these patients is one of the\nmethods used by expert doctors to diagnose this disease. Deep learning-based\nmethods have numerous applications in medical fields, as they have\nsignificantly advanced in recent years. ALL diagnosis is not an exception in\nthis field, and several machine learning-based methods for this problem have\nbeen proposed. In previous methods, high diagnostic accuracy was reported, but\nour work showed that this alone is not sufficient, as it can lead to models\ntaking shortcuts and not making meaningful decisions. This issue arises due to\nthe small size of medical training datasets. To address this, we constrained\nour model to follow a pipeline inspired by experts' work. We also demonstrated\nthat, since a judgement based on only one image is insufficient, redefining the\nproblem as a multiple-instance learning problem is necessary for achieving a\npractical result. Our model is the first to provide a solution to this problem\nin a multiple-instance learning setup. We introduced a novel pipeline for\ndiagnosing ALL that approximates the process used by hematologists, is\nsensitive to disease biomarkers, and achieves an accuracy of 96.15%, an\nF1-score of 94.24%, a sensitivity of 97.56%, and a specificity of 90.91% on ALL\nIDB 1. Our method was further evaluated on an out-of-distribution dataset,\nwhich posed a challenging test and had acceptable performance. Notably, our\nmodel was trained on a relatively small dataset, highlighting the potential for\nour approach to be applied to other medical datasets with limited data\navailability.\n","authors":["Amirhossein Askari Farsangi","Ali Sharifi-Zarchi","Mohammad Hossein Rohban"],"pdf_url":"https://arxiv.org/pdf/2307.04014v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04144v1","updated":"2025-03-06T06:41:38Z","published":"2025-03-06T06:41:38Z","title":"DM-Adapter: Domain-Aware Mixture-of-Adapters for Text-Based Person\n  Retrieval","summary":"  Text-based person retrieval (TPR) has gained significant attention as a\nfine-grained and challenging task that closely aligns with practical\napplications. Tailoring CLIP to person domain is now a emerging research topic\ndue to the abundant knowledge of vision-language pretraining, but challenges\nstill remain during fine-tuning: (i) Previous full-model fine-tuning in TPR is\ncomputationally expensive and prone to overfitting.(ii) Existing\nparameter-efficient transfer learning (PETL) for TPR lacks of fine-grained\nfeature extraction. To address these issues, we propose Domain-Aware\nMixture-of-Adapters (DM-Adapter), which unifies Mixture-of-Experts (MOE) and\nPETL to enhance fine-grained feature representations while maintaining\nefficiency. Specifically, Sparse Mixture-of-Adapters is designed in parallel to\nMLP layers in both vision and language branches, where different experts\nspecialize in distinct aspects of person knowledge to handle features more\nfinely. To promote the router to exploit domain information effectively and\nalleviate the routing imbalance, Domain-Aware Router is then developed by\nbuilding a novel gating function and injecting learnable domain-aware prompts.\nExtensive experiments show that our DM-Adapter achieves state-of-the-art\nperformance, outperforming previous methods by a significant margin.\n","authors":["Yating Liu","Zimo Liu","Xiangyuan Lan","Wenming Yang","Yaowei Li","Qingmin Liao"],"pdf_url":"https://arxiv.org/pdf/2503.04144v1.pdf","comment":"9 pages, 5 figures, accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2503.04139v1","updated":"2025-03-06T06:35:19Z","published":"2025-03-06T06:35:19Z","title":"Robust Computer-Vision based Construction Site Detection for\n  Assistive-Technology Applications","summary":"  Navigating urban environments poses significant challenges for people with\ndisabilities, particularly those with blindness and low vision. Environments\nwith dynamic and unpredictable elements like construction sites are especially\nchallenging. Construction sites introduce hazards like uneven surfaces,\nobstructive barriers, hazardous materials, and excessive noise, and they can\nalter routing, complicating safe mobility. Existing assistive technologies are\nlimited, as navigation apps do not account for construction sites during trip\nplanning, and detection tools that attempt hazard recognition struggle to\naddress the extreme variability of construction paraphernalia. This study\nintroduces a novel computer vision-based system that integrates open-vocabulary\nobject detection, a YOLO-based scaffolding-pole detection model, and an optical\ncharacter recognition (OCR) module to comprehensively identify and interpret\nconstruction site elements for assistive navigation. In static testing across\nseven construction sites, the system achieved an overall accuracy of 88.56\\%,\nreliably detecting objects from 2m to 10m within a 0$^\\circ$ -- 75$^\\circ$\nangular offset. At closer distances (2--4m), the detection rate was 100\\% at\nall tested angles. At\n","authors":["Junchi Feng","Giles Hamilton-Fletcher","Nikhil Ballem","Michael Batavia","Yifei Wang","Jiuling Zhong","Maurizio Porfiri","John-Ross Rizzo"],"pdf_url":"https://arxiv.org/pdf/2503.04139v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04134v1","updated":"2025-03-06T06:26:57Z","published":"2025-03-06T06:26:57Z","title":"Real-time Spatial-temporal Traversability Assessment via Feature-based\n  Sparse Gaussian Process","summary":"  Terrain analysis is critical for the practical application of ground mobile\nrobots in real-world tasks, especially in outdoor unstructured environments. In\nthis paper, we propose a novel spatial-temporal traversability assessment\nmethod, which aims to enable autonomous robots to effectively navigate through\ncomplex terrains. Our approach utilizes sparse Gaussian processes (SGP) to\nextract geometric features (curvature, gradient, elevation, etc.) directly from\npoint cloud scans. These features are then used to construct a high-resolution\nlocal traversability map. Then, we design a spatial-temporal Bayesian Gaussian\nkernel (BGK) inference method to dynamically evaluate traversability scores,\nintegrating historical and real-time data while considering factors such as\nslope, flatness, gradient, and uncertainty metrics. GPU acceleration is applied\nin the feature extraction step, and the system achieves real-time performance.\nExtensive simulation experiments across diverse terrain scenarios demonstrate\nthat our method outperforms SOTA approaches in both accuracy and computational\nefficiency. Additionally, we develop an autonomous navigation framework\nintegrated with the traversability map and validate it with a differential\ndriven vehicle in complex outdoor environments. Our code will be open-source\nfor further research and development by the community,\nhttps://github.com/ZJU-FAST-Lab/FSGP_BGK.\n","authors":["Senming Tan","Zhenyu Hou","Zhihao Zhang","Long Xu","Mengke Zhang","Zhaoqi He","Chao Xu","Fei Gao","Yanjun Cao"],"pdf_url":"https://arxiv.org/pdf/2503.04134v1.pdf","comment":"8 pages, 10 figures"},{"id":"http://arxiv.org/abs/2503.04131v1","updated":"2025-03-06T06:24:51Z","published":"2025-03-06T06:24:51Z","title":"Q-PART: Quasi-Periodic Adaptive Regression with Test-time Training for\n  Pediatric Left Ventricular Ejection Fraction Regression","summary":"  In this work, we address the challenge of adaptive pediatric Left Ventricular\nEjection Fraction (LVEF) assessment. While Test-time Training (TTT) approaches\nshow promise for this task, they suffer from two significant limitations.\nExisting TTT works are primarily designed for classification tasks rather than\ncontinuous value regression, and they lack mechanisms to handle the\nquasi-periodic nature of cardiac signals. To tackle these issues, we propose a\nnovel \\textbf{Q}uasi-\\textbf{P}eriodic \\textbf{A}daptive \\textbf{R}egression\nwith \\textbf{T}est-time Training (Q-PART) framework. In the training stage, the\nproposed Quasi-Period Network decomposes the echocardiogram into periodic and\naperiodic components within latent space by combining parameterized helix\ntrajectories with Neural Controlled Differential Equations. During inference,\nour framework further employs a variance minimization strategy across image\naugmentations that simulate common quality issues in echocardiogram\nacquisition, along with differential adaptation rates for periodic and\naperiodic components. Theoretical analysis is provided to demonstrate that our\nvariance minimization objective effectively bounds the regression error under\nmild conditions. Furthermore, extensive experiments across three pediatric age\ngroups demonstrate that Q-PART not only significantly outperforms existing\napproaches in pediatric LVEF prediction, but also exhibits strong clinical\nscreening capability with high mAUROC scores (up to 0.9747) and maintains\ngender-fair performance across all metrics, validating its robustness and\npractical utility in pediatric echocardiography analysis.\n","authors":["Jie Liu","Tiexin Qin","Hui Liu","Yilei Shi","Lichao Mou","Xiao Xiang Zhu","Shiqi Wang","Haoliang Li"],"pdf_url":"https://arxiv.org/pdf/2503.04131v1.pdf","comment":"Accepted to CVPR 2025"},{"id":"http://arxiv.org/abs/2503.04130v1","updated":"2025-03-06T06:17:38Z","published":"2025-03-06T06:17:38Z","title":"Token-Efficient Long Video Understanding for Multimodal LLMs","summary":"  Recent advances in video-based multimodal large language models (Video-LLMs)\nhave significantly improved video understanding by processing videos as\nsequences of image frames. However, many existing methods treat frames\nindependently in the vision backbone, lacking explicit temporal modeling, which\nlimits their ability to capture dynamic patterns and efficiently handle long\nvideos. To address these limitations, we introduce STORM\n(\\textbf{S}patiotemporal \\textbf{TO}ken \\textbf{R}eduction for\n\\textbf{M}ultimodal LLMs), a novel architecture incorporating a dedicated\ntemporal encoder between the image encoder and the LLM. Our temporal encoder\nleverages the Mamba State Space Model to integrate temporal information into\nimage tokens, generating enriched representations that preserve inter-frame\ndynamics across the entire video sequence. This enriched encoding not only\nenhances video reasoning capabilities but also enables effective token\nreduction strategies, including test-time sampling and training-based temporal\nand spatial pooling, substantially reducing computational demands on the LLM\nwithout sacrificing key temporal information. By integrating these techniques,\nour approach simultaneously reduces training and inference latency while\nimproving performance, enabling efficient and robust video understanding over\nextended temporal contexts. Extensive evaluations show that STORM achieves\nstate-of-the-art results across various long video understanding benchmarks\n(more than 5\\% improvement on MLVU and LongVideoBench) while reducing the\ncomputation costs by up to $8\\times$ and the decoding latency by\n2.4-2.9$\\times$ for the fixed numbers of input frames. Project page is\navailable at https://research.nvidia.com/labs/lpr/storm\n","authors":["Jindong Jiang","Xiuyu Li","Zhijian Liu","Muyang Li","Guo Chen","Zhiqi Li","De-An Huang","Guilin Liu","Zhiding Yu","Kurt Keutzer","Sungjin Ahn","Jan Kautz","Hongxu Yin","Yao Lu","Song Han","Wonmin Byeon"],"pdf_url":"https://arxiv.org/pdf/2503.04130v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04127v1","updated":"2025-03-06T06:13:27Z","published":"2025-03-06T06:13:27Z","title":"Diff-Reg v2: Diffusion-Based Matching Matrix Estimation for Image\n  Matching and 3D Registration","summary":"  Establishing reliable correspondences is crucial for all registration tasks,\nincluding 2D image registration, 3D point cloud registration, and 2D-3D\nimage-to-point cloud registration. However, these tasks are often complicated\nby challenges such as scale inconsistencies, symmetry, and large deformations,\nwhich can lead to ambiguous matches. Previous feature-based and\ncorrespondence-based methods typically rely on geometric or semantic features\nto generate or polish initial potential correspondences. Some methods typically\nleverage specific geometric priors, such as topological preservation, to devise\ndiverse and innovative strategies tailored to a given enhancement goal, which\ncannot be exhaustively enumerated. Additionally, many previous approaches rely\non a single-step prediction head, which can struggle with local minima in\ncomplex matching scenarios. To address these challenges, we introduce an\ninnovative paradigm that leverages a diffusion model in matrix space for robust\nmatching matrix estimation. Our model treats correspondence estimation as a\ndenoising diffusion process in the matching matrix space, gradually refining\nthe intermediate matching matrix to the optimal one. Specifically, we apply the\ndiffusion model in the doubly stochastic matrix space for 3D-3D and 2D-3D\nregistration tasks. In the 2D image registration task, we deploy the diffusion\nmodel in a matrix subspace where dual-softmax projection regularization is\napplied. For all three registration tasks, we provide adaptive matching matrix\nembedding implementations tailored to the specific characteristics of each task\nwhile maintaining a consistent \"match-to-warp\" encoding pattern. Furthermore,\nwe adopt a lightweight design for the denoising module. In inference, once\npoints or image features are extracted and fixed, this module performs\nmulti-step denoising predictions through reverse sampling.\n","authors":["Qianliang Wu","Haobo Jiang","Yaqing Ding","Lei Luo","Jin Xie","Jian Yang"],"pdf_url":"https://arxiv.org/pdf/2503.04127v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2403.19919"},{"id":"http://arxiv.org/abs/2503.04126v1","updated":"2025-03-06T06:10:21Z","published":"2025-03-06T06:10:21Z","title":"DVM-SLAM: Decentralized Visual Monocular Simultaneous Localization and\n  Mapping for Multi-Agent Systems","summary":"  Cooperative Simultaneous Localization and Mapping (C-SLAM) enables multiple\nagents to work together in mapping unknown environments while simultaneously\nestimating their own positions. This approach enhances robustness, scalability,\nand accuracy by sharing information between agents, reducing drift, and\nenabling collective exploration of larger areas. In this paper, we present\nDecentralized Visual Monocular SLAM (DVM-SLAM), the first open-source\ndecentralized monocular C-SLAM system. By only utilizing low-cost and\nlight-weight monocular vision sensors, our system is well suited for small\nrobots and micro aerial vehicles (MAVs). DVM-SLAM's real-world applicability is\nvalidated on physical robots with a custom collision avoidance framework,\nshowcasing its potential in real-time multi-agent autonomous navigation\nscenarios. We also demonstrate comparable accuracy to state-of-the-art\ncentralized monocular C-SLAM systems. We open-source our code and provide\nsupplementary material online.\n","authors":["Joshua Bird","Jan Blumenkamp","Amanda Prorok"],"pdf_url":"https://arxiv.org/pdf/2503.04126v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04123v1","updated":"2025-03-06T06:00:55Z","published":"2025-03-06T06:00:55Z","title":"GAGrasp: Geometric Algebra Diffusion for Dexterous Grasping","summary":"  We propose GAGrasp, a novel framework for dexterous grasp generation that\nleverages geometric algebra representations to enforce equivariance to SE(3)\ntransformations. By encoding the SE(3) symmetry constraint directly into the\narchitecture, our method improves data and parameter efficiency while enabling\nrobust grasp generation across diverse object poses. Additionally, we\nincorporate a differentiable physics-informed refinement layer, which ensures\nthat generated grasps are physically plausible and stable. Extensive\nexperiments demonstrate the model's superior performance in generalization,\nstability, and adaptability compared to existing methods. Additional details at\nhttps://gagrasp.github.io/\n","authors":["Tao Zhong","Christine Allen-Blanchette"],"pdf_url":"https://arxiv.org/pdf/2503.04123v1.pdf","comment":"Accepted at ICRA 2025"},{"id":"http://arxiv.org/abs/2503.00675v2","updated":"2025-03-06T05:59:08Z","published":"2025-03-02T00:40:50Z","title":"Dur360BEV: A Real-world 360-degree Single Camera Dataset and Benchmark\n  for Bird-Eye View Mapping in Autonomous Driving","summary":"  We present Dur360BEV, a novel spherical camera autonomous driving dataset\nequipped with a high-resolution 128-channel 3D LiDAR and a RTK-refined GNSS/INS\nsystem, along with a benchmark architecture designed to generate Bird-Eye-View\n(BEV) maps using only a single spherical camera. This dataset and benchmark\naddress the challenges of BEV generation in autonomous driving, particularly by\nreducing hardware complexity through the use of a single 360-degree camera\ninstead of multiple perspective cameras. Within our benchmark architecture, we\npropose a novel spherical-image-to-BEV module that leverages spherical imagery\nand a refined sampling strategy to project features from 2D to 3D. Our approach\nalso includes an innovative application of focal loss, specifically adapted to\naddress the extreme class imbalance often encountered in BEV segmentation\ntasks, that demonstrates improved segmentation performance on the Dur360BEV\ndataset. The results show that our benchmark not only simplifies the sensor\nsetup but also achieves competitive performance.\n","authors":["Wenke E","Chao Yuan","Li Li","Yixin Sun","Yona Falinie A. Gaus","Amir Atapour-Abarghouei","Toby P. Breckon"],"pdf_url":"https://arxiv.org/pdf/2503.00675v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04121v1","updated":"2025-03-06T05:58:41Z","published":"2025-03-06T05:58:41Z","title":"Simple Self Organizing Map with Visual Transformer","summary":"  Vision Transformers (ViTs) have demonstrated exceptional performance in\nvarious vision tasks. However, they tend to underperform on smaller datasets\ndue to their inherent lack of inductive biases. Current approaches address this\nlimitation implicitly-often by pairing ViTs with pretext tasks or by distilling\nknowledge from convolutional neural networks (CNNs) to strengthen the prior. In\ncontrast, Self-Organizing Maps (SOMs), a widely adopted self-supervised\nframework, are inherently structured to preserve topology and spatial\norganization, making them a promising candidate to directly address the\nlimitations of ViTs in limited or small training datasets. Despite this\npotential, equipping SOMs with modern deep learning architectures remains\nlargely unexplored. In this study, we conduct a novel exploration on how Vision\nTransformers (ViTs) and Self-Organizing Maps (SOMs) can empower each other,\naiming to bridge this critical research gap. Our findings demonstrate that\nthese architectures can synergistically enhance each other, leading to\nsignificantly improved performance in both unsupervised and supervised tasks.\nCode will be publicly available.\n","authors":["Alan Luo","Kaiwen Yuan"],"pdf_url":"https://arxiv.org/pdf/2503.04121v1.pdf","comment":"5 pages, 4 figures. Submitted to IEEE. All experiments and code work\n  were performed by the first author, with the second author serving in a\n  PI/mentor role, guiding the progression of the work"},{"id":"http://arxiv.org/abs/2503.04119v1","updated":"2025-03-06T05:56:25Z","published":"2025-03-06T05:56:25Z","title":"SCSA: A Plug-and-Play Semantic Continuous-Sparse Attention for Arbitrary\n  Semantic Style Transfer","summary":"  Attention-based arbitrary style transfer methods, including CNN-based,\nTransformer-based, and Diffusion-based, have flourished and produced\nhigh-quality stylized images. However, they perform poorly on the content and\nstyle images with the same semantics, i.e., the style of the corresponding\nsemantic region of the generated stylized image is inconsistent with that of\nthe style image. We argue that the root cause lies in their failure to consider\nthe relationship between local regions and semantic regions. To address this\nissue, we propose a plug-and-play semantic continuous-sparse attention, dubbed\nSCSA, for arbitrary semantic style transfer -- each query point considers\ncertain key points in the corresponding semantic region. Specifically, semantic\ncontinuous attention ensures each query point fully attends to all the\ncontinuous key points in the same semantic region that reflect the overall\nstyle characteristics of that region; Semantic sparse attention allows each\nquery point to focus on the most similar sparse key point in the same semantic\nregion that exhibits the specific stylistic texture of that region. By\ncombining the two modules, the resulting SCSA aligns the overall style of the\ncorresponding semantic regions while transferring the vivid textures of these\nregions. Qualitative and quantitative results prove that SCSA enables\nattention-based arbitrary style transfer methods to produce high-quality\nsemantic stylized images.\n","authors":["Chunnan Shang","Zhizhong Wang","Hongwei Wang","Xiangming Meng"],"pdf_url":"https://arxiv.org/pdf/2503.04119v1.pdf","comment":"Accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2410.24185v2","updated":"2025-03-06T05:34:17Z","published":"2024-10-31T17:48:45Z","title":"DexMimicGen: Automated Data Generation for Bimanual Dexterous\n  Manipulation via Imitation Learning","summary":"  Imitation learning from human demonstrations is an effective means to teach\nrobots manipulation skills. But data acquisition is a major bottleneck in\napplying this paradigm more broadly, due to the amount of cost and human effort\ninvolved. There has been significant interest in imitation learning for\nbimanual dexterous robots, like humanoids. Unfortunately, data collection is\neven more challenging here due to the challenges of simultaneously controlling\nmultiple arms and multi-fingered hands. Automated data generation in simulation\nis a compelling, scalable alternative to fuel this need for data. To this end,\nwe introduce DexMimicGen, a large-scale automated data generation system that\nsynthesizes trajectories from a handful of human demonstrations for humanoid\nrobots with dexterous hands. We present a collection of simulation environments\nin the setting of bimanual dexterous manipulation, spanning a range of\nmanipulation behaviors and different requirements for coordination among the\ntwo arms. We generate 21K demos across these tasks from just 60 source human\ndemos and study the effect of several data generation and policy learning\ndecisions on agent performance. Finally, we present a real-to-sim-to-real\npipeline and deploy it on a real-world humanoid can sorting task. Generated\ndatasets, simulation environments and additional results are at\nhttps://dexmimicgen.github.io/\n","authors":["Zhenyu Jiang","Yuqi Xie","Kevin Lin","Zhenjia Xu","Weikang Wan","Ajay Mandlekar","Linxi Fan","Yuke Zhu"],"pdf_url":"https://arxiv.org/pdf/2410.24185v2.pdf","comment":"ICRA 2025. Project website: https://dexmimicgen.github.io/"},{"id":"http://arxiv.org/abs/2503.04107v1","updated":"2025-03-06T05:29:20Z","published":"2025-03-06T05:29:20Z","title":"Fractional Correspondence Framework in Detection Transformer","summary":"  The Detection Transformer (DETR), by incorporating the Hungarian algorithm,\nhas significantly simplified the matching process in object detection tasks.\nThis algorithm facilitates optimal one-to-one matching of predicted bounding\nboxes to ground-truth annotations during training. While effective, this strict\nmatching process does not inherently account for the varying densities and\ndistributions of objects, leading to suboptimal correspondences such as failing\nto handle multiple detections of the same object or missing small objects. To\naddress this, we propose the Regularized Transport Plan (RTP). RTP introduces a\nflexible matching strategy that captures the cost of aligning predictions with\nground truths to find the most accurate correspondences between these sets. By\nutilizing the differentiable Sinkhorn algorithm, RTP allows for soft,\nfractional matching rather than strict one-to-one assignments. This approach\nenhances the model's capability to manage varying object densities and\ndistributions effectively. Our extensive evaluations on the MS-COCO and VOC\nbenchmarks demonstrate the effectiveness of our approach. RTP-DETR, surpassing\nthe performance of the Deform-DETR and the recently introduced DINO-DETR,\nachieving absolute gains in mAP of +3.8% and +1.7%, respectively.\n","authors":["Masoumeh Zareapoor","Pourya Shamsolmoali","Huiyu Zhou","Yue Lu","Salvador García"],"pdf_url":"https://arxiv.org/pdf/2503.04107v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04106v1","updated":"2025-03-06T05:28:44Z","published":"2025-03-06T05:28:44Z","title":"WeakMedSAM: Weakly-Supervised Medical Image Segmentation via SAM with\n  Sub-Class Exploration and Prompt Affinity Mining","summary":"  We have witnessed remarkable progress in foundation models in vision tasks.\nCurrently, several recent works have utilized the segmenting anything model\n(SAM) to boost the segmentation performance in medical images, where most of\nthem focus on training an adaptor for fine-tuning a large amount of pixel-wise\nannotated medical images following a fully supervised manner. In this paper, to\nreduce the labeling cost, we investigate a novel weakly-supervised SAM-based\nsegmentation model, namely WeakMedSAM. Specifically, our proposed WeakMedSAM\ncontains two modules: 1) to mitigate severe co-occurrence in medical images, a\nsub-class exploration module is introduced to learn accurate feature\nrepresentations. 2) to improve the quality of the class activation maps, our\nprompt affinity mining module utilizes the prompt capability of SAM to obtain\nan affinity map for random-walk refinement. Our method can be applied to any\nSAM-like backbone, and we conduct experiments with SAMUS and EfficientSAM. The\nexperimental results on three popularly-used benchmark datasets, i.e., BraTS\n2019, AbdomenCT-1K, and MSD Cardiac dataset, show the promising results of our\nproposed WeakMedSAM. Our code is available at\nhttps://github.com/wanghr64/WeakMedSAM.\n","authors":["Haoran Wang","Lian Huai","Wenbin Li","Lei Qi","Xingqun Jiang","Yinghuan Shi"],"pdf_url":"https://arxiv.org/pdf/2503.04106v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02910v2","updated":"2025-03-06T05:19:44Z","published":"2025-03-04T06:17:17Z","title":"LangGas: Introducing Language in Selective Zero-Shot Background\n  Subtraction for Semi-Transparent Gas Leak Detection with a New Dataset","summary":"  Gas leakage poses a significant hazard that requires prevention.\nTraditionally, human inspection has been used for detection, a slow and\nlabour-intensive process. Recent research has applied machine learning\ntechniques to this problem, yet there remains a shortage of high-quality,\npublicly available datasets. This paper introduces a synthetic dataset\nfeaturing diverse backgrounds, interfering foreground objects, diverse leak\nlocations, and precise segmentation ground truth. We propose a zero-shot method\nthat combines background subtraction, zero-shot object detection, filtering,\nand segmentation to leverage this dataset. Experimental results indicate that\nour approach significantly outperforms baseline methods based solely on\nbackground subtraction and zero-shot object detection with segmentation,\nreaching an IoU of 69\\% overall. We also present an analysis of various prompt\nconfigurations and threshold settings to provide deeper insights into the\nperformance of our method. The code and dataset will be released after\npublication.\n","authors":["Wenqi Guo","Yiyang Du","Shan Du"],"pdf_url":"https://arxiv.org/pdf/2503.02910v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.14909v2","updated":"2025-03-06T05:18:12Z","published":"2025-02-19T02:56:27Z","title":"Comparing Deep Neural Network for Multi-Label ECG Diagnosis From Scanned\n  ECG","summary":"  Automated ECG diagnosis has seen significant advancements with deep learning\ntechniques, but real-world applications still face challenges when dealing with\nscanned paper ECGs. In this study, we explore multi-label classification of\nECGs extracted from scanned images, moving beyond traditional binary\nclassification (normal/abnormal). We evaluate the performance of multiple deep\nneural network architectures, including AlexNet, VGG, ResNet, and Vision\nTransformer, on scanned ECG datasets. Our comparative analysis examines model\naccuracy, robustness to image artifacts, and generalizability across different\nECG conditions. Additionally, we investigate whether ECG signals extracted from\nscanned images retain sufficient diagnostic information for reliable automated\nclassification. The findings highlight the strengths and limitations of each\narchitecture, providing insights into the feasibility of image-based ECG\ndiagnosis and its potential integration into clinical workflows.\n","authors":["Cuong V. Nguyen","Hieu X. Nguyen","Dung D. Pham Minh","Cuong D. Do"],"pdf_url":"https://arxiv.org/pdf/2502.14909v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04096v1","updated":"2025-03-06T05:13:19Z","published":"2025-03-06T05:13:19Z","title":"Image-Based Relocalization and Alignment for Long-Term Monitoring of\n  Dynamic Underwater Environments","summary":"  Effective monitoring of underwater ecosystems is crucial for tracking\nenvironmental changes, guiding conservation efforts, and ensuring long-term\necosystem health. However, automating underwater ecosystem management with\nrobotic platforms remains challenging due to the complexities of underwater\nimagery, which pose significant difficulties for traditional visual\nlocalization methods. We propose an integrated pipeline that combines Visual\nPlace Recognition (VPR), feature matching, and image segmentation on\nvideo-derived images. This method enables robust identification of revisited\nareas, estimation of rigid transformations, and downstream analysis of\necosystem changes. Furthermore, we introduce the SQUIDLE+ VPR Benchmark-the\nfirst large-scale underwater VPR benchmark designed to leverage an extensive\ncollection of unstructured data from multiple robotic platforms, spanning time\nintervals from days to years. The dataset encompasses diverse trajectories,\narbitrary overlap and diverse seafloor types captured under varying\nenvironmental conditions, including differences in depth, lighting, and\nturbidity. Our code is available at: https://github.com/bev-gorry/underloc\n","authors":["Beverley Gorry","Tobias Fischer","Michael Milford","Alejandro Fontan"],"pdf_url":"https://arxiv.org/pdf/2503.04096v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.16805v3","updated":"2025-03-06T05:06:49Z","published":"2024-11-25T14:38:43Z","title":"Human Motion Instruction Tuning","summary":"  This paper presents LLaMo (Large Language and Human Motion Assistant), a\nmultimodal framework for human motion instruction tuning. In contrast to\nconventional instruction-tuning approaches that convert non-linguistic inputs,\nsuch as video or motion sequences, into language tokens, LLaMo retains motion\nin its native form for instruction tuning. This method preserves\nmotion-specific details that are often diminished in tokenization, thereby\nimproving the model's ability to interpret complex human behaviors. By\nprocessing both video and motion data alongside textual inputs, LLaMo enables a\nflexible, human-centric analysis. Experimental evaluations across\nhigh-complexity domains, including human behaviors and professional activities,\nindicate that LLaMo effectively captures domain-specific knowledge, enhancing\ncomprehension and prediction in motion-intensive scenarios. We hope LLaMo\noffers a foundation for future multimodal AI systems with broad applications,\nfrom sports analytics to behavioral prediction. Our code and models are\navailable on the project website: https://github.com/ILGLJ/LLaMo.\n","authors":["Lei Li","Sen Jia","Wang Jianhao","Zhongyu Jiang","Feng Zhou","Ju Dai","Tianfang Zhang","Wu Zongkai","Jenq-Neng Hwang"],"pdf_url":"https://arxiv.org/pdf/2411.16805v3.pdf","comment":"Accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2503.04087v1","updated":"2025-03-06T04:50:07Z","published":"2025-03-06T04:50:07Z","title":"Brain Tumor Detection in MRI Based on Federated Learning with YOLOv11","summary":"  One of the primary challenges in medical diagnostics is the accurate and\nefficient use of magnetic resonance imaging (MRI) for the detection of brain\ntumors. But the current machine learning (ML) approaches have two major\nlimitations, data privacy and high latency. To solve the problem, in this work\nwe propose a federated learning architecture for a better accurate brain tumor\ndetection incorporating the YOLOv11 algorithm. In contrast to earlier methods\nof centralized learning, our federated learning approach protects the\nunderlying medical data while supporting cooperative deep learning model\ntraining across multiple institutions. To allow the YOLOv11 model to locate and\nidentify tumor areas, we adjust it to handle MRI data. To ensure robustness and\ngeneralizability, the model is trained and tested on a wide range of MRI data\ncollected from several anonymous medical facilities. The results indicate that\nour method significantly maintains higher accuracy than conventional\napproaches.\n","authors":["Sheikh Moonwara Anjum Monisha","Ratun Rahman"],"pdf_url":"https://arxiv.org/pdf/2503.04087v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.14701v4","updated":"2025-03-06T04:38:23Z","published":"2024-05-23T15:35:48Z","title":"DreamText: High Fidelity Scene Text Synthesis","summary":"  Scene text synthesis involves rendering specified texts onto arbitrary\nimages. Current methods typically formulate this task in an end-to-end manner\nbut lack effective character-level guidance during training. Besides, their\ntext encoders, pre-trained on a single font type, struggle to adapt to the\ndiverse font styles encountered in practical applications. Consequently, these\nmethods suffer from character distortion, repetition, and absence, particularly\nin polystylistic scenarios. To this end, this paper proposes DreamText for\nhigh-fidelity scene text synthesis. Our key idea is to reconstruct the\ndiffusion training process, introducing more refined guidance tailored to this\ntask, to expose and rectify the model's attention at the character level and\nstrengthen its learning of text regions. This transformation poses a hybrid\noptimization challenge, involving both discrete and continuous variables. To\neffectively tackle this challenge, we employ a heuristic alternate optimization\nstrategy. Meanwhile, we jointly train the text encoder and generator to\ncomprehensively learn and utilize the diverse font present in the training\ndataset. This joint training is seamlessly integrated into the alternate\noptimization process, fostering a synergistic relationship between learning\ncharacter embedding and re-estimating character attention. Specifically, in\neach step, we first encode potential character-generated position information\nfrom cross-attention maps into latent character masks. These masks are then\nutilized to update the representation of specific characters in the current\nstep, which, in turn, enables the generator to correct the character's\nattention in the subsequent steps. Both qualitative and quantitative results\ndemonstrate the superiority of our method to the state of the art.\n","authors":["Yibin Wang","Weizhong Zhang","Honghui Xu","Cheng Jin"],"pdf_url":"https://arxiv.org/pdf/2405.14701v4.pdf","comment":"Code: https://github.com/CodeGoat24/DreamText, Project page:\n  https://codegoat24.github.io/DreamText/"},{"id":"http://arxiv.org/abs/2503.04082v1","updated":"2025-03-06T04:37:09Z","published":"2025-03-06T04:37:09Z","title":"Instrument-Splatting: Controllable Photorealistic Reconstruction of\n  Surgical Instruments Using Gaussian Splatting","summary":"  Real2Sim is becoming increasingly important with the rapid development of\nsurgical artificial intelligence (AI) and autonomy. In this work, we propose a\nnovel Real2Sim methodology, \\textit{Instrument-Splatting}, that leverages 3D\nGaussian Splatting to provide fully controllable 3D reconstruction of surgical\ninstruments from monocular surgical videos. To maintain both high visual\nfidelity and manipulability, we introduce a geometry pre-training to bind\nGaussian point clouds on part mesh with accurate geometric priors and define a\nforward kinematics to control the Gaussians as flexible as real instruments.\nAfterward, to handle unposed videos, we design a novel instrument pose tracking\nmethod leveraging semantics-embedded Gaussians to robustly refine per-frame\ninstrument poses and joint states in a render-and-compare manner, which allows\nour instrument Gaussian to accurately learn textures and reach photorealistic\nrendering. We validated our method on 2 publicly released surgical videos and 4\nvideos collected on ex vivo tissues and green screens. Quantitative and\nqualitative evaluations demonstrate the effectiveness and superiority of the\nproposed method.\n","authors":["Shuojue Yang","Zijian Wu","Mingxuan Hong","Qian Li","Daiyun Shen","Septimiu E. Salcudean","Yueming Jin"],"pdf_url":"https://arxiv.org/pdf/2503.04082v1.pdf","comment":"11 pages, 5 figures"},{"id":"http://arxiv.org/abs/2503.04079v1","updated":"2025-03-06T04:33:19Z","published":"2025-03-06T04:33:19Z","title":"Surgical Gaussian Surfels: Highly Accurate Real-time Surgical Scene\n  Rendering","summary":"  Accurate geometric reconstruction of deformable tissues in monocular\nendoscopic video remains a fundamental challenge in robot-assisted minimally\ninvasive surgery. Although recent volumetric and point primitive methods based\non neural radiance fields (NeRF) and 3D Gaussian primitives have efficiently\nrendered surgical scenes, they still struggle with handling artifact-free tool\nocclusions and preserving fine anatomical details. These limitations stem from\nunrestricted Gaussian scaling and insufficient surface alignment constraints\nduring reconstruction. To address these issues, we introduce Surgical Gaussian\nSurfels (SGS), which transforms anisotropic point primitives into\nsurface-aligned elliptical splats by constraining the scale component of the\nGaussian covariance matrix along the view-aligned axis. We predict accurate\nsurfel motion fields using a lightweight Multi-Layer Perceptron (MLP) coupled\nwith locality constraints to handle complex tissue deformations. We use\nhomodirectional view-space positional gradients to capture fine image details\nby splitting Gaussian Surfels in over-reconstructed regions. In addition, we\ndefine surface normals as the direction of the steepest density change within\neach Gaussian surfel primitive, enabling accurate normal estimation without\nrequiring monocular normal priors. We evaluate our method on two in-vivo\nsurgical datasets, where it outperforms current state-of-the-art methods in\nsurface geometry, normal map quality, and rendering efficiency, while remaining\ncompetitive in real-time rendering performance. We make our code available at\nhttps://github.com/aloma85/SurgicalGaussianSurfels\n","authors":["Idris O. Sunmola","Zhenjun Zhao","Samuel Schmidgall","Yumeng Wang","Paul Maria Scheikl","Axel Krieger"],"pdf_url":"https://arxiv.org/pdf/2503.04079v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20637v2","updated":"2025-03-06T04:31:21Z","published":"2025-02-28T01:36:38Z","title":"TractCloud-FOV: Deep Learning-based Robust Tractography Parcellation in\n  Diffusion MRI with Incomplete Field of View","summary":"  Tractography parcellation classifies streamlines reconstructed from diffusion\nMRI into anatomically defined fiber tracts for clinical and research\napplications. However, clinical scans often have incomplete fields of view\n(FOV) where brain regions are partially imaged, leading to partial or truncated\nfiber tracts. To address this challenge, we introduce TractCloud-FOV, a deep\nlearning framework that robustly parcellates tractography under conditions of\nincomplete FOV. We propose a novel training strategy, FOV-Cut Augmentation\n(FOV-CA), in which we synthetically cut tractograms to simulate a spectrum of\nreal-world inferior FOV cutoff scenarios. This data augmentation approach\nenriches the training set with realistic truncated streamlines, enabling the\nmodel to achieve superior generalization. We evaluate the proposed\nTractCloud-FOV on both synthetically cut tractography and two real-life\ndatasets with incomplete FOV. TractCloud-FOV significantly outperforms several\nstate-of-the-art methods on all testing datasets in terms of streamline\nclassification accuracy, generalization ability, tract anatomical depiction,\nand computational efficiency. Overall, TractCloud-FOV achieves efficient and\nconsistent tractography parcellation in diffusion MRI with incomplete FOV.\n","authors":["Yuqian Chen","Leo Zekelman","Yui Lo","Suheyla Cetin-Karayumak","Tengfei Xue","Yogesh Rathi","Nikos Makris","Fan Zhang","Weidong Cai","Lauren J. O'Donnell"],"pdf_url":"https://arxiv.org/pdf/2502.20637v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04078v1","updated":"2025-03-06T04:28:11Z","published":"2025-03-06T04:28:11Z","title":"Spatial-Temporal Perception with Causal Inference for Naturalistic\n  Driving Action Recognition","summary":"  Naturalistic driving action recognition is essential for vehicle cabin\nmonitoring systems. However, the complexity of real-world backgrounds presents\nsignificant challenges for this task, and previous approaches have struggled\nwith practical implementation due to their limited ability to observe subtle\nbehavioral differences and effectively learn inter-frame features from video.\nIn this paper, we propose a novel Spatial-Temporal Perception (STP)\narchitecture that emphasizes both temporal information and spatial\nrelationships between key objects, incorporating a causal decoder to perform\nbehavior recognition and temporal action localization. Without requiring\nmultimodal input, STP directly extracts temporal and spatial distance features\nfrom RGB video clips. Subsequently, these dual features are jointly encoded by\nmaximizing the expected likelihood across all possible permutations of the\nfactorization order. By integrating temporal and spatial features at different\nscales, STP can perceive subtle behavioral changes in challenging scenarios.\nAdditionally, we introduce a causal-aware module to explore relationships\nbetween video frame features, significantly enhancing detection efficiency and\nperformance. We validate the effectiveness of our approach using two publicly\navailable driver distraction detection benchmarks. The results demonstrate that\nour framework achieves state-of-the-art performance.\n","authors":["Qing Chang","Wei Dai","Zhihao Shuai","Limin Yu","Yutao Yue"],"pdf_url":"https://arxiv.org/pdf/2503.04078v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.17741v5","updated":"2025-03-06T04:11:30Z","published":"2024-12-23T17:44:05Z","title":"Reasoning to Attend: Try to Understand How <SEG> Token Works","summary":"  Current Large Multimodal Models (LMMs) empowered visual grounding typically\nrely on $\\texttt{<SEG>}$ tokens as a text prompt to jointly optimize the\nvision-language model (e.g., LLaVA) and the downstream task-specific model\n(e.g., SAM). However, we observe that little research has looked into how it\nworks.In this work, we first visualize the similarity maps, which are obtained\nby computing the semantic similarity between the $\\texttt{<SEG>}$ token and the\nimage token embeddings derived from the last hidden layer in both the LLaVA\nencoder and SAM decoder. Intriguingly, we have found that a striking\nconsistency holds in terms of activation responses in the similarity map, which\nreveals that what the $\\texttt{<SEG>}$ token contributes to is semantic\nsimilarity within image-text pairs. Specifically, the $\\texttt{<SEG>}$ token, a\nplaceholder expanded in text vocabulary, extensively queries among individual\ntokenized image patches to match the semantics of an object from text to the\npaired image, while the Large Language Models (LLMs) are being fine-tuned. Upon\nthe above findings, we present READ, which facilitates LMMs' resilient\n$\\textbf{REA}$soning capability of where to atten$\\textbf{D}$ under the\nguidance of highly activated points borrowed from similarity maps. Remarkably,\nREAD features an intuitive design, Similarity as Points module (SasP), which\ncan be seamlessly applied to $\\texttt{<SEG>}$-like paradigms in a plug-and-play\nfashion. Also, extensive experiments have been conducted on ReasonSeg and\nRefCOCO(+/g) datasets. To validate whether READ suffers from catastrophic\nforgetting of previous skills after fine-tuning, we further assess its\ngeneration ability on an augmented FP-RefCOCO(+/g) dataset. All codes and\nmodels are publicly available at https://github.com/rui-qian/READ.\n","authors":["Rui Qian","Xin Yin","Dejing Dou"],"pdf_url":"https://arxiv.org/pdf/2412.17741v5.pdf","comment":"This work has been accepted to CVPR 2025, please refer to\n  https://github.com/rui-qian/READ"},{"id":"http://arxiv.org/abs/2405.15683v3","updated":"2025-03-06T03:59:59Z","published":"2024-05-24T16:21:59Z","title":"Visual Description Grounding Reduces Hallucinations and Boosts Reasoning\n  in LVLMs","summary":"  Large Vision-Language Models (LVLMs) often produce responses that misalign\nwith factual information, a phenomenon known as hallucinations. While\nhallucinations are well-studied, the exact causes behind them remain\nunderexplored. In this paper, we first investigate the root causes of\nhallucinations in LVLMs. Our findings reveal that existing mitigation\ntechniques primarily reduce hallucinations for visual recognition prompts-those\nthat require simple descriptions of visual elements-but fail for cognitive\nprompts that demand deliberate reasoning. We identify the core issue as a lack\nof true visual perception in LVLMs: although they can accurately recognize\nvisual elements, they struggle to fully interpret these elements in the context\nof the input prompt and effectively link this recognition to their internal\nknowledge, which is critical for reasoning. To address this gap, we introduce\nVisual Description Grounded Decoding (VDGD), a simple, robust, and\ntraining-free method designed to enhance visual perception and improve\nreasoning capabilities in LVLMs. VDGD works by first generating a detailed\ndescription of the image and appending it as a prefix to the instruction.\nDuring response generation, tokens are sampled based on their KL divergence to\nthe description, favoring candidates with lower divergence. Experimental\nresults on multiple visual reasoning benchmarks and LVLMs demonstrate that VDGD\nconsistently outperforms existing baselines 2% - 33%. Finally, we introduce\nVaLLu, a benchmark designed for comprehensive evaluation of the cognitive\ncapabilities of LVLMs.\n","authors":["Sreyan Ghosh","Chandra Kiran Reddy Evuru","Sonal Kumar","Utkarsh Tyagi","Oriol Nieto","Zeyu Jin","Dinesh Manocha"],"pdf_url":"https://arxiv.org/pdf/2405.15683v3.pdf","comment":"Accepted to ICLR 2025. Project: https://sreyan88.github.io/VDGD/"},{"id":"http://arxiv.org/abs/2502.16445v3","updated":"2025-03-06T03:55:58Z","published":"2025-02-23T05:08:06Z","title":"Iterative Flow Matching -- Path Correction and Gradual Refinement for\n  Enhanced Generative Modeling","summary":"  Generative models for image generation are now commonly used for a wide\nvariety of applications, ranging from guided image generation for entertainment\nto solving inverse problems. Nonetheless, training a generator is a non-trivial\nfeat that requires fine-tuning and can lead to so-called hallucinations, that\nis, the generation of images that are unrealistic. In this work, we explore\nimage generation using flow matching. We explain and demonstrate why flow\nmatching can generate hallucinations, and propose an iterative process to\nimprove the generation process. Our iterative process can be integrated into\nvirtually $\\textit{any}$ generative modeling technique, thereby enhancing the\nperformance and robustness of image synthesis systems.\n","authors":["Eldad Haber","Shadab Ahamed","Md. Shahriar Rahim Siddiqui","Niloufar Zakariaei","Moshe Eliasof"],"pdf_url":"https://arxiv.org/pdf/2502.16445v3.pdf","comment":"17 pages, 8 figures"},{"id":"http://arxiv.org/abs/2503.04067v1","updated":"2025-03-06T03:52:46Z","published":"2025-03-06T03:52:46Z","title":"FREAK: Frequency-modulated High-fidelity and Real-time Audio-driven\n  Talking Portrait Synthesis","summary":"  Achieving high-fidelity lip-speech synchronization in audio-driven talking\nportrait synthesis remains challenging. While multi-stage pipelines or\ndiffusion models yield high-quality results, they suffer from high\ncomputational costs. Some approaches perform well on specific individuals with\nlow resources, yet still exhibit mismatched lip movements. The aforementioned\nmethods are modeled in the pixel domain. We observed that there are noticeable\ndiscrepancies in the frequency domain between the synthesized talking videos\nand natural videos. Currently, no research on talking portrait synthesis has\nconsidered this aspect. To address this, we propose a FREquency-modulated,\nhigh-fidelity, and real-time Audio-driven talKing portrait synthesis framework,\nnamed FREAK, which models talking portraits from the frequency domain\nperspective, enhancing the fidelity and naturalness of the synthesized\nportraits. FREAK introduces two novel frequency-based modules: 1) the Visual\nEncoding Frequency Modulator (VEFM) to couple multi-scale visual features in\nthe frequency domain, better preserving visual frequency information and\nreducing the gap in the frequency spectrum between synthesized and natural\nframes. and 2) the Audio Visual Frequency Modulator (AVFM) to help the model\nlearn the talking pattern in the frequency domain and improve audio-visual\nsynchronization. Additionally, we optimize the model in both pixel domain and\nfrequency domain jointly. Furthermore, FREAK supports seamless switching\nbetween one-shot and video dubbing settings, offering enhanced flexibility. Due\nto its superior performance, it can simultaneously support high-resolution\nvideo results and real-time inference. Extensive experiments demonstrate that\nour method synthesizes high-fidelity talking portraits with detailed facial\ntextures and precise lip synchronization in real-time, outperforming\nstate-of-the-art methods.\n","authors":["Ziqi Ni","Ao Fu","Yi Zhou"],"pdf_url":"https://arxiv.org/pdf/2503.04067v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.00741v2","updated":"2025-03-06T03:44:10Z","published":"2025-03-02T05:36:04Z","title":"LesionDiffusion: Towards Text-controlled General Lesion Synthesis","summary":"  Fully-supervised lesion recognition methods in medical imaging face\nchallenges due to the reliance on large annotated datasets, which are expensive\nand difficult to collect. To address this, synthetic lesion generation has\nbecome a promising approach. However, existing models struggle with\nscalability, fine-grained control over lesion attributes, and the generation of\ncomplex structures. We propose LesionDiffusion, a text-controllable lesion\nsynthesis framework for 3D CT imaging that generates both lesions and\ncorresponding masks. By utilizing a structured lesion report template, our\nmodel provides greater control over lesion attributes and supports a wider\nvariety of lesion types. We introduce a dataset of 1,505 annotated CT scans\nwith paired lesion masks and structured reports, covering 14 lesion types\nacross 8 organs. LesionDiffusion consists of two components: a lesion mask\nsynthesis network (LMNet) and a lesion inpainting network (LINet), both guided\nby lesion attributes and image features. Extensive experiments demonstrate that\nLesionDiffusion significantly improves segmentation performance, with strong\ngeneralization to unseen lesion types and organs, outperforming current\nstate-of-the-art models. Code will be available at\nhttps://github.com/HengruiTianSJTU/LesionDiffusion.\n","authors":["Henrui Tian","Wenhui Lei","Linrui Dai","Hanyu Chen","Xiaofan Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.00741v2.pdf","comment":"10 pages, 4 figures"},{"id":"http://arxiv.org/abs/2503.04065v1","updated":"2025-03-06T03:43:21Z","published":"2025-03-06T03:43:21Z","title":"PP-DocBee: Improving Multimodal Document Understanding Through a Bag of\n  Tricks","summary":"  With the rapid advancement of digitalization, various document images are\nbeing applied more extensively in production and daily life, and there is an\nincreasingly urgent need for fast and accurate parsing of the content in\ndocument images. Therefore, this report presents PP-DocBee, a novel multimodal\nlarge language model designed for end-to-end document image understanding.\nFirst, we develop a data synthesis strategy tailored to document scenarios in\nwhich we build a diverse dataset to improve the model generalization. Then, we\napply a few training techniques, including dynamic proportional sampling, data\npreprocessing, and OCR postprocessing strategies. Extensive evaluations\ndemonstrate the superior performance of PP-DocBee, achieving state-of-the-art\nresults on English document understanding benchmarks and even outperforming\nexisting open source and commercial models in Chinese document understanding.\nThe source code and pre-trained models are publicly available at\n\\href{https://github.com/PaddlePaddle/PaddleMIX}{https://github.com/PaddlePaddle/PaddleMIX}.\n","authors":["Feng Ni","Kui Huang","Yao Lu","Wenyu Lv","Guanzhong Wang","Zeyu Chen","Yi Liu"],"pdf_url":"https://arxiv.org/pdf/2503.04065v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.00736v2","updated":"2025-03-06T03:35:09Z","published":"2025-03-02T05:20:41Z","title":"Shazam: Unifying Multiple Foundation Models for Advanced Computational\n  Pathology","summary":"  Foundation Models (FMs) in computational pathology (CPath) have significantly\nadvanced the extraction of meaningful features from histopathology image\ndatasets, achieving strong performance across various clinical tasks. Despite\ntheir impressive performance, these models often exhibit variability when\napplied to different tasks, prompting the need for a unified framework capable\nof consistently excelling across various applications. In this work, we propose\nShazam, a novel framework designed to efficiently combine multiple CPath\nmodels. Unlike previous approaches that train a fixed-parameter FM, Shazam\ndynamically extracts and refines information from diverse FMs for each specific\ntask. To ensure that each FM contributes effectively without dominance, a novel\ndistillation strategy is applied, guiding the student model with features from\nall teacher models, which enhances its generalization ability. Experimental\nresults on two pathology patch classification datasets demonstrate that Shazam\noutperforms existing CPath models and other fusion methods. Its lightweight,\nflexible design makes it a promising solution for improving CPath analysis in\nreal-world settings. Code will be available at\nhttps://github.com/Tuner12/Shazam.\n","authors":["Wenhui Lei","Anqi Li","Yusheng Tan","Hanyu Chen","Xiaofan Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.00736v2.pdf","comment":"9 pages, 2 figures"},{"id":"http://arxiv.org/abs/2503.03190v2","updated":"2025-03-06T03:32:56Z","published":"2025-03-05T05:13:53Z","title":"DSPNet: Dual-vision Scene Perception for Robust 3D Question Answering","summary":"  3D Question Answering (3D QA) requires the model to comprehensively\nunderstand its situated 3D scene described by the text, then reason about its\nsurrounding environment and answer a question under that situation. However,\nexisting methods usually rely on global scene perception from pure 3D point\nclouds and overlook the importance of rich local texture details from\nmulti-view images. Moreover, due to the inherent noise in camera poses and\ncomplex occlusions, there exists significant feature degradation and reduced\nfeature robustness problems when aligning 3D point cloud with multi-view\nimages. In this paper, we propose a Dual-vision Scene Perception Network\n(DSPNet), to comprehensively integrate multi-view and point cloud features to\nimprove robustness in 3D QA. Our Text-guided Multi-view Fusion (TGMF) module\nprioritizes image views that closely match the semantic content of the text. To\nadaptively fuse back-projected multi-view images with point cloud features, we\ndesign the Adaptive Dual-vision Perception (ADVP) module, enhancing 3D scene\ncomprehension. Additionally, our Multimodal Context-guided Reasoning (MCGR)\nmodule facilitates robust reasoning by integrating contextual information\nacross visual and linguistic modalities. Experimental results on SQA3D and\nScanQA datasets demonstrate the superiority of our DSPNet. Codes will be\navailable at https://github.com/LZ-CH/DSPNet.\n","authors":["Jingzhou Luo","Yang Liu","Weixing Chen","Zhen Li","Yaowei Wang","Guanbin Li","Liang Lin"],"pdf_url":"https://arxiv.org/pdf/2503.03190v2.pdf","comment":"Accepted by CVPR 2025"},{"id":"http://arxiv.org/abs/2410.21259v4","updated":"2025-03-06T03:31:32Z","published":"2024-10-28T17:55:08Z","title":"AutoBench-V: Can Large Vision-Language Models Benchmark Themselves?","summary":"  Large Vision-Language Models (LVLMs) have become essential for advancing the\nintegration of visual and linguistic information. However, the evaluation of\nLVLMs presents significant challenges as the evaluation benchmark always\ndemands lots of human cost for its construction, and remains static, lacking\nflexibility once constructed. Even though automatic evaluation has been\nexplored in textual modality, the visual modality remains under-explored. As a\nresult, in this work, we address a question: \"Can LVLMs themselves be used to\nbenchmark each other in the visual automatically domain?\". We introduce\nAutoBench-V, an automated framework for serving evaluation on demand, i.e.,\nbenchmarking LVLMs based on specific aspects of model capability. AutoBench-V\nleverages text-to-image models to generate relevant image samples and then\nutilizes LVLMs to orchestrate visual question-answering (VQA) tasks, completing\nthe evaluation process efficiently and flexibly. Through an extensive\nevaluation of nine popular LVLMs across five demanded user inputs (i.e.,\nevaluation capabilities), the framework shows effectiveness and reliability.\n","authors":["Han Bao","Yue Huang","Yanbo Wang","Jiayi Ye","Xiangqi Wang","Xiuying Chen","Yue Zhao","Tianyi Zhou","Mohamed Elhoseiny","Xiangliang Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.21259v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04059v1","updated":"2025-03-06T03:27:14Z","published":"2025-03-06T03:27:14Z","title":"H3O: Hyper-Efficient 3D Occupancy Prediction with Heterogeneous\n  Supervision","summary":"  3D occupancy prediction has recently emerged as a new paradigm for holistic\n3D scene understanding and provides valuable information for downstream\nplanning in autonomous driving. Most existing methods, however, are\ncomputationally expensive, requiring costly attention-based 2D-3D\ntransformation and 3D feature processing. In this paper, we present a novel 3D\noccupancy prediction approach, H3O, which features highly efficient\narchitecture designs that incur a significantly lower computational cost as\ncompared to the current state-of-the-art methods. In addition, to compensate\nfor the ambiguity in ground-truth 3D occupancy labels, we advocate leveraging\nauxiliary tasks to complement the direct 3D supervision. In particular, we\nintegrate multi-camera depth estimation, semantic segmentation, and surface\nnormal estimation via differentiable volume rendering, supervised by\ncorresponding 2D labels that introduces rich and heterogeneous supervision\nsignals. We conduct extensive experiments on the Occ3D-nuScenes and\nSemanticKITTI benchmarks that demonstrate the superiority of our proposed H3O.\n","authors":["Yunxiao Shi","Hong Cai","Amin Ansari","Fatih Porikli"],"pdf_url":"https://arxiv.org/pdf/2503.04059v1.pdf","comment":"ICRA 2025"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2503.04653v1","updated":"2025-03-06T17:43:03Z","published":"2025-03-06T17:43:03Z","title":"RadIR: A Scalable Framework for Multi-Grained Medical Image Retrieval\n  via Radiology Report Mining","summary":"  Developing advanced medical imaging retrieval systems is challenging due to\nthe varying definitions of `similar images' across different medical contexts.\nThis challenge is compounded by the lack of large-scale, high-quality medical\nimaging retrieval datasets and benchmarks. In this paper, we propose a novel\nmethodology that leverages dense radiology reports to define image-wise\nsimilarity ordering at multiple granularities in a scalable and fully automatic\nmanner. Using this approach, we construct two comprehensive medical imaging\nretrieval datasets: MIMIC-IR for Chest X-rays and CTRATE-IR for CT scans,\nproviding detailed image-image ranking annotations conditioned on diverse\nanatomical structures. Furthermore, we develop two retrieval systems, RadIR-CXR\nand model-ChestCT, which demonstrate superior performance in traditional\nimage-image and image-report retrieval tasks. These systems also enable\nflexible, effective image retrieval conditioned on specific anatomical\nstructures described in text, achieving state-of-the-art results on 77 out of\n78 metrics.\n","authors":["Tengfei Zhang","Ziheng Zhao","Chaoyi Wu","Xiao Zhou","Ya Zhang","Yangfeng Wang","Weidi Xie"],"pdf_url":"https://arxiv.org/pdf/2503.04653v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04644v1","updated":"2025-03-06T17:32:22Z","published":"2025-03-06T17:32:22Z","title":"IFIR: A Comprehensive Benchmark for Evaluating Instruction-Following in\n  Expert-Domain Information Retrieval","summary":"  We introduce IFIR, the first comprehensive benchmark designed to evaluate\ninstruction-following information retrieval (IR) in expert domains. IFIR\nincludes 2,426 high-quality examples and covers eight subsets across four\nspecialized domains: finance, law, healthcare, and science literature. Each\nsubset addresses one or more domain-specific retrieval tasks, replicating\nreal-world scenarios where customized instructions are critical. IFIR enables a\ndetailed analysis of instruction-following retrieval capabilities by\nincorporating instructions at different levels of complexity. We also propose a\nnovel LLM-based evaluation method to provide a more precise and reliable\nassessment of model performance in following instructions. Through extensive\nexperiments on 15 frontier retrieval models, including those based on LLMs, our\nresults reveal that current models face significant challenges in effectively\nfollowing complex, domain-specific instructions. We further provide in-depth\nanalyses to highlight these limitations, offering valuable insights to guide\nfuture advancements in retriever development.\n","authors":["Tingyu Song","Guo Gan","Mingsheng Shang","Yilun Zhao"],"pdf_url":"https://arxiv.org/pdf/2503.04644v1.pdf","comment":"NAACL 2025 Main"},{"id":"http://arxiv.org/abs/2503.03606v2","updated":"2025-03-06T14:28:36Z","published":"2025-03-05T15:42:37Z","title":"Decoupled Recommender Systems: Exploring Alternative Recommender\n  Ecosystem Designs","summary":"  Recommender ecosystems are an emerging subject of research. Such research\nexamines how the characteristics of algorithms, recommendation consumers, and\nitem providers influence system dynamics and long-term outcomes. One\narchitectural possibility that has not yet been widely explored in this line of\nresearch is the consequences of a configuration in which recommendation\nalgorithms are decoupled from the platforms they serve. This is sometimes\ncalled \"the friendly neighborhood algorithm store\" or \"middleware\" model. We\nare particularly interested in how such architectures might offer a range of\ndifferent distributions of utility across consumers, providers, and\nrecommendation platforms. In this paper, we create a model of a recommendation\necosystem that incorporates algorithm choice and examine the outcomes of such a\ndesign.\n","authors":["Anas Buhayh","Elizabeth McKinnie","Robin Burke"],"pdf_url":"https://arxiv.org/pdf/2503.03606v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.13959v2","updated":"2025-03-06T13:51:24Z","published":"2025-01-21T06:32:25Z","title":"Assisting Mathematical Formalization with A Learning-based Premise\n  Retriever","summary":"  Premise selection is a crucial yet challenging step in mathematical\nformalization, especially for users with limited experience. Due to the lack of\navailable formalization projects, existing approaches that leverage language\nmodels often suffer from data scarcity. In this work, we introduce an\ninnovative method for training a premise retriever to support the formalization\nof mathematics. Our approach employs a BERT model to embed proof states and\npremises into a shared latent space. The retrieval model is trained within a\ncontrastive learning framework and incorporates a domain-specific tokenizer\nalong with a fine-grained similarity computation method. Experimental results\nshow that our model is highly competitive compared to existing baselines,\nachieving strong performance while requiring fewer computational resources.\nPerformance is further enhanced through the integration of a re-ranking module.\nTo streamline the formalization process, we will release a search engine that\nenables users to query Mathlib theorems directly using proof states,\nsignificantly improving accessibility and efficiency. Codes are available at\nhttps://github.com/ruc-ai4math/Premise-Retrieval.\n","authors":["Yicheng Tao","Haotian Liu","Shanwen Wang","Hongteng Xu"],"pdf_url":"https://arxiv.org/pdf/2501.13959v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04406v1","updated":"2025-03-06T13:00:53Z","published":"2025-03-06T13:00:53Z","title":"Training-Free Graph Filtering via Multimodal Feature Refinement for\n  Extremely Fast Multimodal Recommendation","summary":"  Multimodal recommender systems improve the performance of canonical\nrecommender systems with no item features by utilizing diverse content types\nsuch as text, images, and videos, while alleviating inherent sparsity of\nuser-item interactions and accelerating user engagement. However, current\nneural network-based models often incur significant computational overhead due\nto the complex training process required to learn and integrate information\nfrom multiple modalities. To overcome this limitation, we propose\nMultiModal-Graph Filtering (MM-GF), a training-free method based on the notion\nof graph filtering (GF) for efficient and accurate multimodal recommendations.\nSpecifically, MM-GF first constructs multiple similarity graphs through\nnontrivial multimodal feature refinement such as robust scaling and vector\nshifting by addressing the heterogeneous characteristics across modalities.\nThen, MM-GF optimally fuses multimodal information using linear low-pass\nfilters across different modalities. Extensive experiments on real-world\nbenchmark datasets demonstrate that MM-GF not only improves recommendation\naccuracy by up to 13.35% compared to the best competitor but also dramatically\nreduces computational costs by achieving the runtime of less than 10 seconds.\n","authors":["Yu-Seung Roh","Joo-Young Kim","Jin-Duk Park","Won-Yong Shin"],"pdf_url":"https://arxiv.org/pdf/2503.04406v1.pdf","comment":"10 pages, 6 figures, 6 tables"},{"id":"http://arxiv.org/abs/2503.01346v2","updated":"2025-03-06T12:27:24Z","published":"2025-03-03T09:37:33Z","title":"SRAG: Structured Retrieval-Augmented Generation for Multi-Entity\n  Question Answering over Wikipedia Graph","summary":"  Multi-entity question answering (MEQA) poses significant challenges for large\nlanguage models (LLMs), which often struggle to consolidate scattered\ninformation across multiple documents. An example question might be \"What is\nthe distribution of IEEE Fellows among various fields of study?\", which\nrequires retrieving information from diverse sources e.g., Wikipedia pages. The\neffectiveness of current retrieval-augmented generation (RAG) methods is\nlimited by the LLMs' capacity to aggregate insights from numerous pages. To\naddress this gap, this paper introduces a structured RAG (SRAG) framework that\nsystematically organizes extracted entities into relational tables (e.g.,\ntabulating entities with schema columns like \"name\" and \"field of study\") and\nthen apply table-based reasoning techniques. Our approach decouples retrieval\nand reasoning, enabling LLMs to focus on structured data analysis rather than\nraw text aggregation. Extensive experiments on Wikipedia-based multi-entity QA\ntasks demonstrate that SRAG significantly outperforms state-of-the-art\nlong-context LLMs and RAG solutions, achieving a 29.6% improvement in accuracy.\nThe results underscore the efficacy of structuring unstructured data to enhance\nLLMs' reasoning capabilities.\n","authors":["Teng Lin","Yizhang Zhu","Yuyu Luo","Nan Tang"],"pdf_url":"https://arxiv.org/pdf/2503.01346v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.12468v3","updated":"2025-03-06T11:53:49Z","published":"2024-07-17T10:40:39Z","title":"Evaluating Search Engines and Large Language Models for Answering Health\n  Questions","summary":"  Search engines (SEs) have traditionally been primary tools for information\nseeking, but the new Large Language Models (LLMs) are emerging as powerful\nalternatives, particularly for question-answering tasks. This study compares\nthe performance of four popular SEs, seven LLMs, and retrieval-augmented (RAG)\nvariants in answering 150 health-related questions from the TREC Health\nMisinformation (HM) Track. Results reveal SEs correctly answer between 50 and\n70% of questions, often hindered by many retrieval results not responding to\nthe health question. LLMs deliver higher accuracy, correctly answering about\n80% of questions, though their performance is sensitive to input prompts. RAG\nmethods significantly enhance smaller LLMs' effectiveness, improving accuracy\nby up to 30% by integrating retrieval evidence.\n","authors":["Marcos Fernández-Pichel","Juan C. Pichel","David E. Losada"],"pdf_url":"https://arxiv.org/pdf/2407.12468v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04338v1","updated":"2025-03-06T11:34:49Z","published":"2025-03-06T11:34:49Z","title":"In-depth Analysis of Graph-based RAG in a Unified Framework","summary":"  Graph-based Retrieval-Augmented Generation (RAG) has proven effective in\nintegrating external knowledge into large language models (LLMs), improving\ntheir factual accuracy, adaptability, interpretability, and trustworthiness. A\nnumber of graph-based RAG methods have been proposed in the literature.\nHowever, these methods have not been systematically and comprehensively\ncompared under the same experimental settings. In this paper, we first\nsummarize a unified framework to incorporate all graph-based RAG methods from a\nhigh-level perspective. We then extensively compare representative graph-based\nRAG methods over a range of questing-answering (QA) datasets -- from specific\nquestions to abstract questions -- and examine the effectiveness of all\nmethods, providing a thorough analysis of graph-based RAG approaches. As a\nbyproduct of our experimental analysis, we are also able to identify new\nvariants of the graph-based RAG methods over specific QA and abstract QA tasks\nrespectively, by combining existing techniques, which outperform the\nstate-of-the-art methods. Finally, based on these findings, we offer promising\nresearch opportunities. We believe that a deeper understanding of the behavior\nof existing methods can provide new valuable insights for future research.\n","authors":["Yingli Zhou","Yaodong Su","Youran Sun","Shu Wang","Taotao Wang","Runyuan He","Yongwei Zhang","Sicong Liang","Xilin Liu","Yuchi Ma","Yixiang Fang"],"pdf_url":"https://arxiv.org/pdf/2503.04338v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.01924v2","updated":"2025-03-06T10:39:48Z","published":"2024-05-03T08:34:13Z","title":"Semi-Parametric Retrieval via Binary Bag-of-Tokens Index","summary":"  Information retrieval has transitioned from standalone systems into essential\ncomponents across broader applications, with indexing efficiency,\ncost-effectiveness, and freshness becoming increasingly critical yet often\noverlooked. In this paper, we introduce SemI-parametric Disentangled Retrieval\n(SiDR), a bi-encoder retrieval framework that decouples retrieval index from\nneural parameters to enable efficient, low-cost, and parameter-agnostic\nindexing for emerging use cases. Specifically, in addition to using embeddings\nas indexes like existing neural retrieval methods, SiDR supports a\nnon-parametric tokenization index for search, achieving BM25-like indexing\ncomplexity with significantly better effectiveness. Our comprehensive\nevaluation across 16 retrieval benchmarks demonstrates that SiDR outperforms\nboth neural and term-based retrieval baselines under the same indexing\nworkload: (i) When using an embedding-based index, SiDR exceeds the performance\nof conventional neural retrievers while maintaining similar training\ncomplexity; (ii) When using a tokenization-based index, SiDR drastically\nreduces indexing cost and time, matching the complexity of traditional\nterm-based retrieval, while consistently outperforming BM25 on all in-domain\ndatasets; (iii) Additionally, we introduce a late parametric mechanism that\nmatches BM25 index preparation time while outperforming other neural retrieval\nbaselines in effectiveness.\n","authors":["Jiawei Zhou","Li Dong","Furu Wei","Lei Chen"],"pdf_url":"https://arxiv.org/pdf/2405.01924v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04188v1","updated":"2025-03-06T08:03:51Z","published":"2025-03-06T08:03:51Z","title":"Measuring temporal effects of agent knowledge by date-controlled tool\n  use","summary":"  Temporal progression is an integral part of knowledge accumulation and\nupdate. Web search is frequently adopted as grounding for agent knowledge, yet\nits inappropriate configuration affects the quality of agent responses. Here,\nwe construct a tool-based out-of-sample testing framework to measure the\nknowledge variability of large language model (LLM) agents from distinct\ndate-controlled tools (DCTs). We demonstrate the temporal effects of an LLM\nagent as a writing assistant, which can use web search to help complete\nscientific publication abstracts. We show that temporal effects of the search\nengine translates into tool-dependent agent performance but can be alleviated\nwith base model choice and explicit reasoning instructions such as\nchain-of-thought prompting. Our results indicate that agent evaluation should\ntake a dynamical view and account for the temporal influence of tools and the\nupdates of external resources.\n","authors":["R. Patrick Xian","Qiming Cui","Stefan Bauer","Reza Abbasi-Asl"],"pdf_url":"https://arxiv.org/pdf/2503.04188v1.pdf","comment":"comments welcome"},{"id":"http://arxiv.org/abs/2503.04162v1","updated":"2025-03-06T07:25:19Z","published":"2025-03-06T07:25:19Z","title":"Semantic Retrieval Augmented Contrastive Learning for Sequential\n  Recommendation","summary":"  Sequential recommendation aims to model user preferences based on historical\nbehavior sequences, which is crucial for various online platforms. Data\nsparsity remains a significant challenge in this area as most users have\nlimited interactions and many items receive little attention. To mitigate this\nissue, contrastive learning has been widely adopted. By constructing positive\nsample pairs from the data itself and maximizing their agreement in the\nembedding space,it can leverage available data more effectively. Constructing\nreasonable positive sample pairs is crucial for the success of contrastive\nlearning. However, current approaches struggle to generate reliable positive\npairs as they either rely on representations learned from inherently sparse\ncollaborative signals or use random perturbations which introduce significant\nuncertainty. To address these limitations, we propose a novel approach named\nSemantic Retrieval Augmented Contrastive Learning (SRA-CL), which leverages\nsemantic information to improve the reliability of contrastive samples. SRA-CL\ncomprises two main components: (1) Cross-Sequence Contrastive Learning via User\nSemantic Retrieval, which utilizes large language models (LLMs) to understand\ndiverse user preferences and retrieve semantically similar users to form\nreliable positive samples through a learnable sample synthesis method; and (2)\nIntra-Sequence Contrastive Learning via Item Semantic Retrieval, which employs\nLLMs to comprehend items and retrieve similar items to perform semantic-based\nitem substitution, thereby creating semantically consistent augmented views for\ncontrastive learning. SRA-CL is plug-and-play and can be integrated into\nstandard sequential recommendation models. Extensive experiments on four public\ndatasets demonstrate the effectiveness and generalizability of the proposed\napproach.\n","authors":["Ziqiang Cui","Yunpeng Weng","Xing Tang","Xiaokun Zhang","Dugang Liu","Shiwei Li","Peiyang Liu","Bowei He","Weihong Luo","Xiuqiang He","Chen Ma"],"pdf_url":"https://arxiv.org/pdf/2503.04162v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04141v1","updated":"2025-03-06T06:39:25Z","published":"2025-03-06T06:39:25Z","title":"HEISIR: Hierarchical Expansion of Inverted Semantic Indexing for\n  Training-free Retrieval of Conversational Data using LLMs","summary":"  The growth of conversational AI services has increased demand for effective\ninformation retrieval from dialogue data. However, existing methods often face\nchallenges in capturing semantic intent or require extensive labeling and\nfine-tuning. This paper introduces HEISIR (Hierarchical Expansion of Inverted\nSemantic Indexing for Retrieval), a novel framework that enhances semantic\nunderstanding in conversational data retrieval through optimized data\ningestion, eliminating the need for resource-intensive labeling or model\nadaptation. HEISIR implements a two-step process: (1) Hierarchical Triplets\nFormulation and (2) Adjunct Augmentation, creating semantic indices consisting\nof Subject-Verb-Object-Adjunct (SVOA) quadruplets. This structured\nrepresentation effectively captures the underlying semantic information from\ndialogue content. HEISIR achieves high retrieval performance while maintaining\nlow latency during the actual retrieval process. Our experimental results\ndemonstrate that HEISIR outperforms fine-tuned models across various embedding\ntypes and language models. Beyond improving retrieval capabilities, HEISIR also\noffers opportunities for intent and topic analysis in conversational data,\nproviding a versatile solution for dialogue systems.\n","authors":["Sangyeop Kim","Hangyeul Lee","Yohan Lee"],"pdf_url":"https://arxiv.org/pdf/2503.04141v1.pdf","comment":"Accepted by NAACL 2025 (Findings)"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2503.04725v1","updated":"2025-03-06T18:59:48Z","published":"2025-03-06T18:59:48Z","title":"L$^2$M: Mutual Information Scaling Law for Long-Context Language\n  Modeling","summary":"  We rigorously establish a bipartite mutual information scaling law in natural\nlanguage that governs long-range dependencies. This scaling law, which we show\nis distinct from and scales independently of the conventional two-point mutual\ninformation, is the key to understanding long-context language modeling. Using\nthis scaling law, we formulate the Long-context Language Modeling (L$^2$M)\ncondition, which relates a model's capacity for effective long context length\nmodeling to the scaling of its latent state size for storing past information.\nOur results are validated through experiments on both transformers and state\nspace models. This work establishes a theoretical foundation that guides the\ndevelopment of large language models toward longer context lengths.\n","authors":["Zhuo Chen","Oriol Mayné i Comas","Zhuotao Jin","Di Luo","Marin Soljačić"],"pdf_url":"https://arxiv.org/pdf/2503.04725v1.pdf","comment":"29 pages, 12 figures, 1 table"},{"id":"http://arxiv.org/abs/2503.04722v1","updated":"2025-03-06T18:59:23Z","published":"2025-03-06T18:59:23Z","title":"Enough Coin Flips Can Make LLMs Act Bayesian","summary":"  Large language models (LLMs) exhibit the ability to generalize given few-shot\nexamples in their input prompt, an emergent capability known as in-context\nlearning (ICL). We investigate whether LLMs utilize ICL to perform structured\nreasoning in ways that are consistent with a Bayesian framework or rely on\npattern matching. Using a controlled setting of biased coin flips, we find\nthat: (1) LLMs often possess biased priors, causing initial divergence in\nzero-shot settings, (2) in-context evidence outweighs explicit bias\ninstructions, (3) LLMs broadly follow Bayesian posterior updates, with\ndeviations primarily due to miscalibrated priors rather than flawed updates,\nand (4) attention magnitude has negligible effect on Bayesian inference. With\nsufficient demonstrations of biased coin flips via ICL, LLMs update their\npriors in a Bayesian manner.\n","authors":["Ritwik Gupta","Rodolfo Corona","Jiaxin Ge","Eric Wang","Dan Klein","Trevor Darrell","David M. Chan"],"pdf_url":"https://arxiv.org/pdf/2503.04722v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04718v1","updated":"2025-03-06T18:58:45Z","published":"2025-03-06T18:58:45Z","title":"Floxels: Fast Unsupervised Voxel Based Scene Flow Estimation","summary":"  Scene flow estimation is a foundational task for many robotic applications,\nincluding robust dynamic object detection, automatic labeling, and sensor\nsynchronization. Two types of approaches to the problem have evolved: 1)\nSupervised and 2) optimization-based methods. Supervised methods are fast\nduring inference and achieve high-quality results, however, they are limited by\nthe need for large amounts of labeled training data and are susceptible to\ndomain gaps. In contrast, unsupervised test-time optimization methods do not\nface the problem of domain gaps but usually suffer from substantial runtime,\nexhibit artifacts, or fail to converge to the right solution. In this work, we\nmitigate several limitations of existing optimization-based methods. To this\nend, we 1) introduce a simple voxel grid-based model that improves over the\nstandard MLP-based formulation in multiple dimensions and 2) introduce a new\nmultiframe loss formulation. 3) We combine both contributions in our new\nmethod, termed Floxels. On the Argoverse 2 benchmark, Floxels is surpassed only\nby EulerFlow among unsupervised methods while achieving comparable performance\nat a fraction of the computational cost. Floxels achieves a massive speedup of\nmore than ~60 - 140x over EulerFlow, reducing the runtime from a day to 10\nminutes per sequence. Over the faster but low-quality baseline, NSFP, Floxels\nachieves a speedup of ~14x.\n","authors":["David T. Hoffmann","Syed Haseeb Raza","Hanqiu Jiang","Denis Tananaev","Steffen Klingenhoefer","Martin Meinke"],"pdf_url":"https://arxiv.org/pdf/2503.04718v1.pdf","comment":"Accepted at CVPR 2025"},{"id":"http://arxiv.org/abs/2503.04715v1","updated":"2025-03-06T18:58:29Z","published":"2025-03-06T18:58:29Z","title":"Predictable Scale: Part I -- Optimal Hyperparameter Scaling Law in Large\n  Language Model Pretraining","summary":"  The impressive capabilities of Large Language Models (LLMs) across diverse\ntasks are now well-established, yet their effective deployment necessitates\ncareful hyperparameter optimization. Through extensive empirical studies\ninvolving grid searches across diverse configurations, we discover universal\nscaling laws governing these hyperparameters: optimal learning rate follows a\npower-law relationship with both model parameters and data sizes, while optimal\nbatch size scales primarily with data sizes. Our analysis reveals a convex\noptimization landscape for hyperparameters under fixed models and data size\nconditions. This convexity implies an optimal hyperparameter plateau. We\ncontribute a universal, plug-and-play optimal hyperparameter tool for the\ncommunity. Its estimated values on the test set are merely 0.07\\% away from the\nglobally optimal LLM performance found via an exhaustive search. These laws\ndemonstrate remarkable robustness across variations in model sparsity, training\ndata distribution, and model shape. To our best known, this is the first work\nthat unifies different model shapes and structures, such as Mixture-of-Experts\nmodels and dense transformers, as well as establishes optimal hyperparameter\nscaling laws across diverse data distributions. This exhaustive optimization\nprocess demands substantial computational resources, utilizing nearly one\nmillion NVIDIA H800 GPU hours to train 3,700 LLMs of varying sizes and\nhyperparameters from scratch and consuming approximately 100 trillion tokens in\ntotal. To facilitate reproducibility and further research, we will\nprogressively release all loss measurements and model checkpoints through our\ndesignated repository https://step-law.github.io/\n","authors":["Houyi Li","Wenzheng Zheng","Jingcheng Hu","Qiufeng Wang","Hanshan Zhang","Zili Wang","Yangshijie Xu","Shuigeng Zhou","Xiangyu Zhang","Daxin Jiang"],"pdf_url":"https://arxiv.org/pdf/2503.04715v1.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2503.04713v1","updated":"2025-03-06T18:57:40Z","published":"2025-03-06T18:57:40Z","title":"Scaling Rich Style-Prompted Text-to-Speech Datasets","summary":"  We introduce Paralinguistic Speech Captions (ParaSpeechCaps), a large-scale\ndataset that annotates speech utterances with rich style captions. While rich\nabstract tags (e.g. guttural, nasal, pained) have been explored in small-scale\nhuman-annotated datasets, existing large-scale datasets only cover basic tags\n(e.g. low-pitched, slow, loud). We combine off-the-shelf text and speech\nembedders, classifiers and an audio language model to automatically scale rich\ntag annotations for the first time. ParaSpeechCaps covers a total of 59 style\ntags, including both speaker-level intrinsic tags and utterance-level\nsituational tags. It consists of 342 hours of human-labelled data (PSC-Base)\nand 2427 hours of automatically annotated data (PSC-Scaled). We finetune\nParler-TTS, an open-source style-prompted TTS model, on ParaSpeechCaps, and\nachieve improved style consistency (+7.9% Consistency MOS) and speech quality\n(+15.5% Naturalness MOS) over the best performing baseline that combines\nexisting rich style tag datasets. We ablate several of our dataset design\nchoices to lay the foundation for future work in this space. Our dataset,\nmodels and code are released at https://github.com/ajd12342/paraspeechcaps .\n","authors":["Anuj Diwan","Zhisheng Zheng","David Harwath","Eunsol Choi"],"pdf_url":"https://arxiv.org/pdf/2503.04713v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04712v1","updated":"2025-03-06T18:57:34Z","published":"2025-03-06T18:57:34Z","title":"Efficiently Escaping Saddle Points under Generalized Smoothness via\n  Self-Bounding Regularity","summary":"  In this paper, we study the problem of non-convex optimization on functions\nthat are not necessarily smooth using first order methods. Smoothness\n(functions whose gradient and/or Hessian are Lipschitz) is not satisfied by\nmany machine learning problems in both theory and practice, motivating a recent\nline of work studying the convergence of first order methods to first order\nstationary points under appropriate generalizations of smoothness.\n  We develop a novel framework to study convergence of first order methods to\nfirst and \\textit{second} order stationary points under generalized smoothness,\nunder more general smoothness assumptions than the literature. Using our\nframework, we show appropriate variants of GD and SGD (e.g. with appropriate\nperturbations) can converge not just to first order but also \\textit{second\norder stationary points} in runtime polylogarithmic in the dimension. To our\nknowledge, our work contains the first such result, as well as the first\n'non-textbook' rate for non-convex optimization under generalized smoothness.\nWe demonstrate that several canonical non-convex optimization problems fall\nunder our setting and framework.\n","authors":["Daniel Yiming Cao","August Y. Chen","Karthik Sridharan","Benjamin Tang"],"pdf_url":"https://arxiv.org/pdf/2503.04712v1.pdf","comment":"79 pages"},{"id":"http://arxiv.org/abs/2503.04706v1","updated":"2025-03-06T18:54:42Z","published":"2025-03-06T18:54:42Z","title":"Sample-Optimal Agnostic Boosting with Unlabeled Data","summary":"  Boosting provides a practical and provably effective framework for\nconstructing accurate learning algorithms from inaccurate rules of thumb. It\nextends the promise of sample-efficient learning to settings where direct\nEmpirical Risk Minimization (ERM) may not be implementable efficiently. In the\nrealizable setting, boosting is known to offer this computational reprieve\nwithout compromising on sample efficiency. However, in the agnostic case,\nexisting boosting algorithms fall short of achieving the optimal sample\ncomplexity.\n  This paper highlights an unexpected and previously unexplored avenue of\nimprovement: unlabeled samples. We design a computationally efficient agnostic\nboosting algorithm that matches the sample complexity of ERM, given\npolynomially many additional unlabeled samples. In fact, we show that the total\nnumber of samples needed, unlabeled and labeled inclusive, is never more than\nthat for the best known agnostic boosting algorithm -- so this result is never\nworse -- while only a vanishing fraction of these need to be labeled for the\nalgorithm to succeed. This is particularly fortuitous for learning-theoretic\napplications of agnostic boosting, which often take place in the\ndistribution-specific setting, where unlabeled samples can be availed for free.\nWe detail other applications of this result in reinforcement learning.\n","authors":["Udaya Ghai","Karan Singh"],"pdf_url":"https://arxiv.org/pdf/2503.04706v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04704v1","updated":"2025-03-06T18:54:32Z","published":"2025-03-06T18:54:32Z","title":"Universality of Layer-Level Entropy-Weighted Quantization Beyond Model\n  Architecture and Size","summary":"  We present a novel approach to selective model quantization that transcends\nthe limitations of architecture-specific and size-dependent compression methods\nfor Large Language Models (LLMs) using Entropy-Weighted Quantization (EWQ). By\nanalyzing the entropy distribution across transformer blocks, EWQ determines\nwhich blocks can be safely quantized without causing significant performance\ndegradation, independent of model architecture or size. Our method outperforms\nuniform quantization approaches, maintaining Massive Multitask Language\nUnderstanding (MMLU) accuracy scores within 0.5% of unquantized models while\nreducing memory usage by up to 18%. We demonstrate the effectiveness of EWQ\nacross multiple architectures-from 1.6B to 70B parameters-showcasing consistent\nimprovements in the quality-compression trade-off regardless of model scale or\narchitectural design. A surprising finding of EWQ is its ability to reduce\nperplexity compared to unquantized models, suggesting the presence of\nbeneficial regularization through selective precision reduction. This\nimprovement holds across different model families, indicating a fundamental\nrelationship between layer-level entropy and optimal precision requirements.\nAdditionally, we introduce FastEWQ, a rapid method for entropy distribution\nanalysis that eliminates the need for loading model weights. This technique\nleverages universal characteristics of entropy distribution that persist across\nvarious architectures and scales, enabling near-instantaneous quantization\ndecisions while maintaining 80% classification accuracy with full entropy\nanalysis. Our results demonstrate that effective quantization strategies can be\ndeveloped independently of specific architectural choices or model sizes,\nopening new possibilities for efficient LLM deployment.\n","authors":["Alireza Behtash","Marijan Fofonjka","Ethan Baird","Tyler Mauer","Hossein Moghimifam","David Stout","Joel Dennison"],"pdf_url":"https://arxiv.org/pdf/2503.04704v1.pdf","comment":"29 pages, 7 figures, 14 tables; Comments are welcome"},{"id":"http://arxiv.org/abs/2503.04697v1","updated":"2025-03-06T18:43:29Z","published":"2025-03-06T18:43:29Z","title":"L1: Controlling How Long A Reasoning Model Thinks With Reinforcement\n  Learning","summary":"  Reasoning language models have shown an uncanny ability to improve\nperformance at test-time by ``thinking longer''-that is, by generating longer\nchain-of-thought sequences and hence using more compute. However, the length of\ntheir chain-of-thought reasoning is not controllable, making it impossible to\nallocate test-time compute to achieve a desired level of performance. We\nintroduce Length Controlled Policy Optimization (LCPO), a simple reinforcement\nlearning method that optimizes for accuracy and adherence to user-specified\nlength constraints. We use LCPO to train L1, a reasoning language model that\nproduces outputs satisfying a length constraint given in its prompt. L1's\nlength control allows for smoothly trading off computational cost and accuracy\non a wide range of tasks, and outperforms the state-of-the-art S1 method for\nlength control. Furthermore, we uncover an unexpected short chain-of-thought\ncapability in models trained with LCPO. For instance, our 1.5B L1 model\nsurpasses GPT-4o at equal reasoning lengths. Overall, LCPO enables precise\ncontrol over reasoning length, allowing for fine-grained allocation of\ntest-time compute and accuracy. We release code and models at\nhttps://www.cmu-l3.github.io/l1\n","authors":["Pranjal Aggarwal","Sean Welleck"],"pdf_url":"https://arxiv.org/pdf/2503.04697v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01843v2","updated":"2025-03-06T18:38:33Z","published":"2025-03-03T18:59:40Z","title":"When Can You Get Away with Low Memory Adam?","summary":"  Adam is the go-to optimizer for training modern machine learning models, but\nit requires additional memory to maintain the moving averages of the gradients\nand their squares. While various low-memory optimizers have been proposed that\nsometimes match the performance of Adam, their lack of reliability has left\nAdam as the default choice. In this work, we apply a simple layer-wise\nSignal-to-Noise Ratio (SNR) analysis to quantify when second-moment tensors can\nbe effectively replaced by their means across different dimensions. Our SNR\nanalysis reveals how architecture, training hyperparameters, and dataset\nproperties impact compressibility along Adam's trajectory, naturally leading to\n$\\textit{SlimAdam}$, a memory-efficient Adam variant. $\\textit{SlimAdam}$\ncompresses the second moments along dimensions with high SNR when feasible, and\nleaves when compression would be detrimental. Through experiments across a\ndiverse set of architectures and training scenarios, we show that\n$\\textit{SlimAdam}$ matches Adam's performance and stability while saving up to\n$98\\%$ of total second moments. Code for $\\textit{SlimAdam}$ is available at\nhttps://github.com/dayal-kalra/low-memory-adam.\n","authors":["Dayal Singh Kalra","John Kirchenbauer","Maissam Barkeshli","Tom Goldstein"],"pdf_url":"https://arxiv.org/pdf/2503.01843v2.pdf","comment":"Acknowledgement updates and minor writing edits"},{"id":"http://arxiv.org/abs/2503.04690v1","updated":"2025-03-06T18:32:35Z","published":"2025-03-06T18:32:35Z","title":"Coarse graining and reduced order models for plume ejection dynamics","summary":"  Monitoring the atmospheric dispersion of pollutants is increasingly critical\nfor environmental impact assessments. High-fidelity computational models are\noften employed to simulate plume dynamics, guiding decision-making and\nprioritizing resource deployment. However, such models can be prohibitively\nexpensive to simulate, as they require resolving turbulent flows at fine\nspatial and temporal resolutions. Moreover, there are at least two distinct\ndynamical regimes of interest in the plume: (i) the initial ejection of the\nplume where turbulent mixing is generated by the shear-driven Kelvin-Helmholtz\ninstability, and (ii) the ensuing turbulent diffusion and advection which is\noften modeled by the Gaussian plume model. We address the challenge of modeling\nthe initial plume generation. Specifically, we propose a data-driven framework\nthat identifies a reduced-order analytical model for plume dynamics -- directly\nfrom video data. We extract a time series of plume center and edge points from\nvideo snapshots and evaluate different regressions based to their extrapolation\nperformance to generate a time series of coefficients that characterize the\nplume's overall direction and spread. We regress to a sinusoidal model inspired\nby the Kelvin-Helmholtz instability for the edge points in order to identify\nthe plume's dispersion and vorticity. Overall, this reduced-order modeling\nframework provides a data-driven and lightweight approach to capture the\ndominant features of the initial nonlinear point-source plume dynamics,\nagnostic to plume type and starting only from video. The resulting model is a\npre-cursor to standard models such as the Gaussian plume model and has the\npotential to enable rapid assessment and evaluation of critical environmental\nhazards, such as methane leaks, chemical spills, and pollutant dispersal from\nsmokestacks.\n","authors":["Ike Griss Salas","Megan R. Ebers","Jake Stevens-Haas","J. Nathan Kutz"],"pdf_url":"https://arxiv.org/pdf/2503.04690v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02800v2","updated":"2025-03-06T18:30:45Z","published":"2025-03-04T17:20:43Z","title":"RAAD-LLM: Adaptive Anomaly Detection Using LLMs and RAG Integration","summary":"  Anomaly detection in complex industrial environments poses unique challenges,\nparticularly in contexts characterized by data sparsity and evolving\noperational conditions. Predictive maintenance (PdM) in such settings demands\nmethodologies that are adaptive, transferable, and capable of integrating\ndomain-specific knowledge. In this paper, we present RAAD-LLM, a novel\nframework for adaptive anomaly detection, leveraging large language models\n(LLMs) integrated with Retrieval-Augmented Generation (RAG). This approach\naddresses the aforementioned PdM challenges. By effectively utilizing\ndomain-specific knowledge, RAAD-LLM enhances the detection of anomalies in time\nseries data without requiring fine-tuning on specific datasets. The framework's\nadaptability mechanism enables it to adjust its understanding of normal\noperating conditions dynamically, thus increasing detection accuracy. We\nvalidate this methodology through a real-world application for a plastics\nmanufacturing plant and the Skoltech Anomaly Benchmark (SKAB). Results show\nsignificant improvements over our previous model with an accuracy increase from\n70.7% to 89.1% on the real-world dataset. By allowing for the enriching of\ninput series data with semantics, RAAD-LLM incorporates multimodal capabilities\nthat facilitate more collaborative decision-making between the model and plant\noperators. Overall, our findings support RAAD-LLM's ability to revolutionize\nanomaly detection methodologies in PdM, potentially leading to a paradigm shift\nin how anomaly detection is implemented across various industries.\n","authors":["Alicia Russell-Gilbert","Sudip Mittal","Shahram Rahimi","Maria Seale","Joseph Jabour","Thomas Arnold","Joshua Church"],"pdf_url":"https://arxiv.org/pdf/2503.02800v2.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2411.00914"},{"id":"http://arxiv.org/abs/2503.04687v1","updated":"2025-03-06T18:29:45Z","published":"2025-03-06T18:29:45Z","title":"Compositional World Knowledge leads to High Utility Synthetic data","summary":"  Machine learning systems struggle with robustness, under subpopulation\nshifts. This problem becomes especially pronounced in scenarios where only a\nsubset of attribute combinations is observed during training -a severe form of\nsubpopulation shift, referred as compositional shift. To address this problem,\nwe ask the following question: Can we improve the robustness by training on\nsynthetic data, spanning all possible attribute combinations? We first show\nthat training of conditional diffusion models on limited data lead to incorrect\nunderlying distribution. Therefore, synthetic data sampled from such models\nwill result in unfaithful samples and does not lead to improve performance of\ndownstream machine learning systems. To address this problem, we propose CoInD\nto reflect the compositional nature of the world by enforcing conditional\nindependence through minimizing Fisher's divergence between joint and marginal\ndistributions. We demonstrate that synthetic data generated by CoInD is\nfaithful and this translates to state-of-the-art worst-group accuracy on\ncompositional shift tasks on CelebA.\n","authors":["Sachit Gaudi","Gautam Sreekumar","Vishnu Boddeti"],"pdf_url":"https://arxiv.org/pdf/2503.04687v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04684v1","updated":"2025-03-06T18:26:42Z","published":"2025-03-06T18:26:42Z","title":"Propagating Model Uncertainty through Filtering-based Probabilistic\n  Numerical ODE Solvers","summary":"  Filtering-based probabilistic numerical solvers for ordinary differential\nequations (ODEs), also known as ODE filters, have been established as efficient\nmethods for quantifying numerical uncertainty in the solution of ODEs. In\npractical applications, however, the underlying dynamical system often contains\nuncertain parameters, requiring the propagation of this model uncertainty to\nthe ODE solution. In this paper, we demonstrate that ODE filters, despite their\nprobabilistic nature, do not automatically solve this uncertainty propagation\nproblem. To address this limitation, we present a novel approach that combines\nODE filters with numerical quadrature to properly marginalize over uncertain\nparameters, while accounting for both parameter uncertainty and numerical\nsolver uncertainty. Experiments across multiple dynamical systems demonstrate\nthat the resulting uncertainty estimates closely match reference solutions.\nNotably, we show how the numerical uncertainty from the ODE solver can help\nprevent overconfidence in the propagated uncertainty estimates, especially when\nusing larger step sizes. Our results illustrate that probabilistic numerical\nmethods can effectively quantify both numerical and parametric uncertainty in\ndynamical systems.\n","authors":["Dingling Yao","Filip Tronarp","Nathanael Bosch"],"pdf_url":"https://arxiv.org/pdf/2503.04684v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04680v1","updated":"2025-03-06T18:22:46Z","published":"2025-03-06T18:22:46Z","title":"Matrix Factorization for Inferring Associations and Missing Links","summary":"  Missing link prediction is a method for network analysis, with applications\nin recommender systems, biology, social sciences, cybersecurity, information\nretrieval, and Artificial Intelligence (AI) reasoning in Knowledge Graphs.\nMissing link prediction identifies unseen but potentially existing connections\nin a network by analyzing the observed patterns and relationships. In\nproliferation detection, this supports efforts to identify and characterize\nattempts by state and non-state actors to acquire nuclear weapons or associated\ntechnology - a notoriously challenging but vital mission for global security.\nDimensionality reduction techniques like Non-Negative Matrix Factorization\n(NMF) and Logistic Matrix Factorization (LMF) are effective but require\nselection of the matrix rank parameter, that is, of the number of hidden\nfeatures, k, to avoid over/under-fitting. We introduce novel Weighted (WNMFk),\nBoolean (BNMFk), and Recommender (RNMFk) matrix factorization methods, along\nwith ensemble variants incorporating logistic factorization, for link\nprediction. Our methods integrate automatic model determination for rank\nestimation by evaluating stability and accuracy using a modified bootstrap\nmethodology and uncertainty quantification (UQ), assessing prediction\nreliability under random perturbations. We incorporate Otsu threshold selection\nand k-means clustering for Boolean matrix factorization, comparing them to\ncoordinate descent-based Boolean thresholding. Our experiments highlight the\nimpact of rank k selection, evaluate model performance under varying test-set\nsizes, and demonstrate the benefits of UQ for reliable predictions using\nabstention. We validate our methods on three synthetic datasets (Boolean and\nuniformly distributed) and benchmark them against LMF and symmetric LMF\n(symLMF) on five real-world protein-protein interaction networks, showcasing an\nimproved prediction performance.\n","authors":["Ryan Barron","Maksim E. Eren","Duc P. Truong","Cynthia Matuszek","James Wendelberger","Mary F. Dorn","Boian Alexandrov"],"pdf_url":"https://arxiv.org/pdf/2503.04680v1.pdf","comment":"35 pages, 14 figures, 3 tables, 1 algorithm"},{"id":"http://arxiv.org/abs/2503.04679v1","updated":"2025-03-06T18:22:29Z","published":"2025-03-06T18:22:29Z","title":"Multi-Agent Inverse Q-Learning from Demonstrations","summary":"  When reward functions are hand-designed, deep reinforcement learning\nalgorithms often suffer from reward misspecification, causing them to learn\nsuboptimal policies in terms of the intended task objectives. In the\nsingle-agent case, inverse reinforcement learning (IRL) techniques attempt to\naddress this issue by inferring the reward function from expert demonstrations.\nHowever, in multi-agent problems, misalignment between the learned and true\nobjectives is exacerbated due to increased environment non-stationarity and\nvariance that scales with multiple agents. As such, in multi-agent general-sum\ngames, multi-agent IRL algorithms have difficulty balancing cooperative and\ncompetitive objectives. To address these issues, we propose Multi-Agent\nMarginal Q-Learning from Demonstrations (MAMQL), a novel sample-efficient\nframework for multi-agent IRL. For each agent, MAMQL learns a critic\nmarginalized over the other agents' policies, allowing for a well-motivated use\nof Boltzmann policies in the multi-agent context. We identify a connection\nbetween optimal marginalized critics and single-agent soft-Q IRL, allowing us\nto apply a direct, simple optimization criterion from the single-agent domain.\nAcross our experiments on three different simulated domains, MAMQL\nsignificantly outperforms previous multi-agent methods in average reward,\nsample efficiency, and reward recovery by often more than 2-5x. We make our\ncode available at https://sites.google.com/view/mamql .\n","authors":["Nathaniel Haynam","Adam Khoja","Dhruv Kumar","Vivek Myers","Erdem Bıyık"],"pdf_url":"https://arxiv.org/pdf/2503.04679v1.pdf","comment":"8 pages, 4 figures, 2 tables. Published at the International\n  Conference on Robotics and Automation (ICRA) 2025"},{"id":"http://arxiv.org/abs/2410.06186v4","updated":"2025-03-06T18:20:00Z","published":"2024-10-08T16:51:10Z","title":"The Last Iterate Advantage: Empirical Auditing and Principled Heuristic\n  Analysis of Differentially Private SGD","summary":"  We propose a simple heuristic privacy analysis of noisy clipped stochastic\ngradient descent (DP-SGD) in the setting where only the last iterate is\nreleased and the intermediate iterates remain hidden. Namely, our heuristic\nassumes a linear structure for the model.\n  We show experimentally that our heuristic is predictive of the outcome of\nprivacy auditing applied to various training procedures. Thus it can be used\nprior to training as a rough estimate of the final privacy leakage. We also\nprobe the limitations of our heuristic by providing some artificial\ncounterexamples where it underestimates the privacy leakage.\n  The standard composition-based privacy analysis of DP-SGD effectively assumes\nthat the adversary has access to all intermediate iterates, which is often\nunrealistic. However, this analysis remains the state of the art in practice.\nWhile our heuristic does not replace a rigorous privacy analysis, it\nillustrates the large gap between the best theoretical upper bounds and the\nprivacy auditing lower bounds and sets a target for further work to improve the\ntheoretical privacy analyses. We also empirically support our heuristic and\nshow existing privacy auditing attacks are bounded by our heuristic analysis in\nboth vision and language tasks.\n","authors":["Thomas Steinke","Milad Nasr","Arun Ganesh","Borja Balle","Christopher A. Choquette-Choo","Matthew Jagielski","Jamie Hayes","Abhradeep Guha Thakurta","Adam Smith","Andreas Terzis"],"pdf_url":"https://arxiv.org/pdf/2410.06186v4.pdf","comment":"ICLR 2025 camera-ready version"},{"id":"http://arxiv.org/abs/2402.10065v2","updated":"2025-03-06T18:17:02Z","published":"2024-02-15T16:30:55Z","title":"Some Targets Are Harder to Identify than Others: Quantifying the\n  Target-dependent Membership Leakage","summary":"  In a Membership Inference (MI) game, an attacker tries to infer whether a\ntarget point was included or not in the input of an algorithm. Existing works\nshow that some target points are easier to identify, while others are harder.\nThis paper explains the target-dependent hardness of membership attacks by\nstudying the powers of the optimal attacks in a fixed-target MI game. We\ncharacterise the optimal advantage and trade-off functions of attacks against\nthe empirical mean in terms of the Mahalanobis distance between the target\npoint and the data-generating distribution. We further derive the impacts of\ntwo privacy defences, i.e. adding Gaussian noise and sub-sampling, and that of\ntarget misspecification on optimal attacks. As by-products of our novel\nanalysis of the Likelihood Ratio (LR) test, we provide a new covariance attack\nwhich generalises and improves the scalar product attack. Also, we propose a\nnew optimal canary-choosing strategy for auditing privacy in the white-box\nfederated learning setting. Our experiments validate that the Mahalanobis score\nexplains the hardness of fixed-target MI games.\n","authors":["Achraf Azize","Debabrota Basu"],"pdf_url":"https://arxiv.org/pdf/2402.10065v2.pdf","comment":"Appears in AISTATS 2025 (Oral)"},{"id":"http://arxiv.org/abs/2502.02067v2","updated":"2025-03-06T18:09:38Z","published":"2025-02-04T07:32:39Z","title":"AdaptBot: Combining LLM with Knowledge Graphs and Human Input for\n  Generic-to-Specific Task Decomposition and Knowledge Refinement","summary":"  An embodied agent assisting humans is often asked to complete new tasks, and\nthere may not be sufficient time or labeled examples to train the agent to\nperform these new tasks. Large Language Models (LLMs) trained on considerable\nknowledge across many domains can be used to predict a sequence of abstract\nactions for completing such tasks, although the agent may not be able to\nexecute this sequence due to task-, agent-, or domain-specific constraints. Our\nframework addresses these challenges by leveraging the generic predictions\nprovided by LLM and the prior domain knowledge encoded in a Knowledge Graph\n(KG), enabling an agent to quickly adapt to new tasks. The robot also solicits\nand uses human input as needed to refine its existing knowledge. Based on\nexperimental evaluation in the context of cooking and cleaning tasks in\nsimulation domains, we demonstrate that the interplay between LLM, KG, and\nhuman input leads to substantial performance gains compared with just using the\nLLM. Project website{\\S}: https://sssshivvvv.github.io/adaptbot/\n","authors":["Shivam Singh","Karthik Swaminathan","Nabanita Dash","Ramandeep Singh","Snehasis Banerjee","Mohan Sridharan","Madhava Krishna"],"pdf_url":"https://arxiv.org/pdf/2502.02067v2.pdf","comment":"Accepted to IEEE International Conference on Robotics and Automation\n  (ICRA) 2025"},{"id":"http://arxiv.org/abs/2502.12360v2","updated":"2025-03-06T18:07:00Z","published":"2025-02-17T22:50:45Z","title":"Detecting Systematic Weaknesses in Vision Models along Predefined\n  Human-Understandable Dimensions","summary":"  Slice discovery methods (SDMs) are prominent algorithms for finding\nsystematic weaknesses in DNNs. They identify top-k semantically coherent\nslices/subsets of data where a DNN-under-test has low performance. For being\ndirectly useful, slices should be aligned with human-understandable and\nrelevant dimensions, which, for example, are defined by safety and domain\nexperts as part of the operational design domain (ODD). While SDMs can be\napplied effectively on structured data, their application on image data is\ncomplicated by the lack of semantic metadata. To address these issues, we\npresent an algorithm that combines foundation models for zero-shot image\nclassification to generate semantic metadata with methods for combinatorial\nsearch to find systematic weaknesses in images. In contrast to existing\napproaches, ours identifies weak slices that are in line with pre-defined\nhuman-understandable dimensions. As the algorithm includes foundation models,\nits intermediate and final results may not always be exact. Therefore, we\ninclude an approach to address the impact of noisy metadata. We validate our\nalgorithm on both synthetic and real-world datasets, demonstrating its ability\nto recover human-understandable systematic weaknesses. Furthermore, using our\napproach, we identify systematic weaknesses of multiple pre-trained and\npublicly available state-of-the-art computer vision DNNs.\n","authors":["Sujan Sai Gannamaneni","Rohil Prakash Rao","Michael Mock","Maram Akila","Stefan Wrobel"],"pdf_url":"https://arxiv.org/pdf/2502.12360v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04667v1","updated":"2025-03-06T17:59:51Z","published":"2025-03-06T17:59:51Z","title":"An Information-theoretic Multi-task Representation Learning Framework\n  for Natural Language Understanding","summary":"  This paper proposes a new principled multi-task representation learning\nframework (InfoMTL) to extract noise-invariant sufficient representations for\nall tasks. It ensures sufficiency of shared representations for all tasks and\nmitigates the negative effect of redundant features, which can enhance language\nunderstanding of pre-trained language models (PLMs) under the multi-task\nparadigm. Firstly, a shared information maximization principle is proposed to\nlearn more sufficient shared representations for all target tasks. It can avoid\nthe insufficiency issue arising from representation compression in the\nmulti-task paradigm. Secondly, a task-specific information minimization\nprinciple is designed to mitigate the negative effect of potential redundant\nfeatures in the input for each task. It can compress task-irrelevant redundant\ninformation and preserve necessary information relevant to the target for\nmulti-task prediction. Experiments on six classification benchmarks show that\nour method outperforms 12 comparative multi-task methods under the same\nmulti-task settings, especially in data-constrained and noisy scenarios.\nExtensive experiments demonstrate that the learned representations are more\nsufficient, data-efficient, and robust.\n","authors":["Dou Hu","Lingwei Wei","Wei Zhou","Songlin Hu"],"pdf_url":"https://arxiv.org/pdf/2503.04667v1.pdf","comment":"11 pages, accepted to AAAI 2025 (main conference), the code is\n  available at https://github.com/zerohd4869/InfoMTL"},{"id":"http://arxiv.org/abs/2503.04655v1","updated":"2025-03-06T17:49:13Z","published":"2025-03-06T17:49:13Z","title":"CLDyB: Towards Dynamic Benchmarking for Continual Learning with\n  Pre-trained Models","summary":"  The advent of the foundation model era has sparked significant research\ninterest in leveraging pre-trained representations for continual learning (CL),\nyielding a series of top-performing CL methods on standard evaluation\nbenchmarks. Nonetheless, there are growing concerns regarding potential data\ncontamination during the pre-training stage. Furthermore, standard evaluation\nbenchmarks, which are typically static, fail to capture the complexities of\nreal-world CL scenarios, resulting in saturated performance. To address these\nissues, we describe CL on dynamic benchmarks (CLDyB), a general computational\nframework based on Markov decision processes for evaluating CL methods\nreliably. CLDyB dynamically identifies inherently difficult and\nalgorithm-dependent tasks for the given CL methods, and determines challenging\ntask orders using Monte Carlo tree search. Leveraging CLDyB, we first conduct a\njoint evaluation of multiple state-of-the-art CL methods, leading to a set of\ncommonly challenging and generalizable task sequences where existing CL methods\ntend to perform poorly. We then conduct separate evaluations of individual CL\nmethods using CLDyB, discovering their respective strengths and weaknesses. The\nsource code and generated task sequences are publicly accessible at\nhttps://github.com/szc12153/CLDyB.\n","authors":["Shengzhuang Chen","Yikai Liao","Xiaoxiao Sun","Kede Ma","Ying Wei"],"pdf_url":"https://arxiv.org/pdf/2503.04655v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04650v1","updated":"2025-03-06T17:39:12Z","published":"2025-03-06T17:39:12Z","title":"Joint Masked Reconstruction and Contrastive Learning for Mining\n  Interactions Between Proteins","summary":"  Protein-protein interaction (PPI) prediction is an instrumental means in\nelucidating the mechanisms underlying cellular operations, holding significant\npractical implications for the realms of pharmaceutical development and\nclinical treatment. Presently, the majority of research methods primarily\nconcentrate on the analysis of amino acid sequences, while investigations\npredicated on protein structures remain in the nascent stages of exploration.\nDespite the emergence of several structure-based algorithms in recent years,\nthese are still confronted with inherent challenges: (1) the extraction of\nintrinsic structural information of proteins typically necessitates the\nexpenditure of substantial computational resources; (2) these models are overly\nreliant on seen protein data, struggling to effectively unearth interaction\ncues between unknown proteins. To further propel advancements in this domain,\nthis paper introduces a novel PPI prediction method jointing masked\nreconstruction and contrastive learning, termed JmcPPI. This methodology\ndissects the PPI prediction task into two distinct phases: during the residue\nstructure encoding phase, JmcPPI devises two feature reconstruction tasks and\nemploys graph attention mechanism to capture structural information between\nresidues; during the protein interaction inference phase, JmcPPI perturbs the\noriginal PPI graph and employs a multi-graph contrastive learning strategy to\nthoroughly mine extrinsic interaction information of novel proteins. Extensive\nexperiments conducted on three widely utilized PPI datasets demonstrate that\nJmcPPI surpasses existing optimal baseline models across various data partition\nschemes. The associated code can be accessed via\nhttps://github.com/lijfrank-open/JmcPPI.\n","authors":["Jiang Li","Xiaoping Wang"],"pdf_url":"https://arxiv.org/pdf/2503.04650v1.pdf","comment":"Submitted"},{"id":"http://arxiv.org/abs/2503.04649v1","updated":"2025-03-06T17:35:37Z","published":"2025-03-06T17:35:37Z","title":"Transferable Foundation Models for Geometric Tasks on Point Cloud\n  Representations: Geometric Neural Operators","summary":"  We introduce methods for obtaining pretrained Geometric Neural Operators\n(GNPs) that can serve as basal foundation models for use in obtaining geometric\nfeatures. These can be used within data processing pipelines for machine\nlearning tasks and numerical methods. We show how our GNPs can be trained to\nlearn robust latent representations for the differential geometry of\npoint-clouds to provide estimates of metric, curvature, and other shape-related\nfeatures. We demonstrate how our pre-trained GNPs can be used (i) to estimate\nthe geometric properties of surfaces of arbitrary shape and topologies with\nrobustness in the presence of noise, (ii) to approximate solutions of geometric\npartial differential equations (PDEs) on manifolds, and (iii) to solve\nequations for shape deformations such as curvature driven flows. We also\nrelease a package of the codes and weights for using our pre-trained GNPs for\nprocessing point cloud representations. This allows for incorporating our\npre-trained GNPs as components for reuse within existing and new data\nprocessing pipelines. The GNPs also can be used as part of numerical solvers\ninvolving geometry or as part of methods for performing inference and other\ngeometric tasks.\n","authors":["Blaine Quackenbush","Paul J. Atzberger"],"pdf_url":"https://arxiv.org/pdf/2503.04649v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.04873v2","updated":"2025-03-06T17:35:19Z","published":"2025-01-08T23:07:10Z","title":"Back Home: A Machine Learning Approach to Seashell Classification and\n  Ecosystem Restoration","summary":"  In Costa Rica, an average of 5 tons of seashells are extracted from\necosystems annually. Confiscated seashells, cannot be returned to their\necosystems due to the lack of origin recognition. To address this issue, we\ndeveloped a convolutional neural network (CNN) specifically for seashell\nidentification. We built a dataset from scratch, consisting of approximately\n19000 images from the Pacific and Caribbean coasts. Using this dataset, the\nmodel achieved a classification accuracy exceeding 85%. The model has been\nintegrated into a user-friendly application, which has classified over 36,000\nseashells to date, delivering real-time results within 3 seconds per image. To\nfurther enhance the system's accuracy, an anomaly detection mechanism was\nincorporated to filter out irrelevant or anomalous inputs, ensuring only valid\nseashell images are processed.\n","authors":["Alexander Valverde","Luis Solano"],"pdf_url":"https://arxiv.org/pdf/2501.04873v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04641v1","updated":"2025-03-06T17:31:43Z","published":"2025-03-06T17:31:43Z","title":"Simulating the Real World: A Unified Survey of Multimodal Generative\n  Models","summary":"  Understanding and replicating the real world is a critical challenge in\nArtificial General Intelligence (AGI) research. To achieve this, many existing\napproaches, such as world models, aim to capture the fundamental principles\ngoverning the physical world, enabling more accurate simulations and meaningful\ninteractions. However, current methods often treat different modalities,\nincluding 2D (images), videos, 3D, and 4D representations, as independent\ndomains, overlooking their interdependencies. Additionally, these methods\ntypically focus on isolated dimensions of reality without systematically\nintegrating their connections. In this survey, we present a unified survey for\nmultimodal generative models that investigate the progression of data\ndimensionality in real-world simulation. Specifically, this survey starts from\n2D generation (appearance), then moves to video (appearance+dynamics) and 3D\ngeneration (appearance+geometry), and finally culminates in 4D generation that\nintegrate all dimensions. To the best of our knowledge, this is the first\nattempt to systematically unify the study of 2D, video, 3D and 4D generation\nwithin a single framework. To guide future research, we provide a comprehensive\nreview of datasets, evaluation metrics and future directions, and fostering\ninsights for newcomers. This survey serves as a bridge to advance the study of\nmultimodal generative models and real-world simulation within a unified\nframework.\n","authors":["Yuqi Hu","Longguang Wang","Xian Liu","Ling-Hao Chen","Yuwei Guo","Yukai Shi","Ce Liu","Anyi Rao","Zeyu Wang","Hui Xiong"],"pdf_url":"https://arxiv.org/pdf/2503.04641v1.pdf","comment":"Repository for the related papers at\n  https://github.com/ALEEEHU/World-Simulator"},{"id":"http://arxiv.org/abs/2503.04639v1","updated":"2025-03-06T17:28:48Z","published":"2025-03-06T17:28:48Z","title":"Enhancing SAM with Efficient Prompting and Preference Optimization for\n  Semi-supervised Medical Image Segmentation","summary":"  Foundational models such as the Segment Anything Model (SAM) are gaining\ntraction in medical imaging segmentation, supporting multiple downstream tasks.\nHowever, such models are supervised in nature, still relying on large annotated\ndatasets or prompts supplied by experts. Conventional techniques such as active\nlearning to alleviate such limitations are limited in scope and still\nnecessitate continuous human involvement and complex domain knowledge for label\nrefinement or establishing reward ground truth. To address these challenges, we\npropose an enhanced Segment Anything Model (SAM) framework that utilizes\nannotation-efficient prompts generated in a fully unsupervised fashion, while\nstill capturing essential semantic, location, and shape information through\ncontrastive language-image pretraining and visual question answering. We adopt\nthe direct preference optimization technique to design an optimal policy that\nenables the model to generate high-fidelity segmentations with simple ratings\nor rankings provided by a virtual annotator simulating the human annotation\nprocess. State-of-the-art performance of our framework in tasks such as lung\nsegmentation, breast tumor segmentation, and organ segmentation across various\nmodalities, including X-ray, ultrasound, and abdominal CT, justifies its\neffectiveness in low-annotation data scenarios.\n","authors":["Aishik Konwer","Zhijian Yang","Erhan Bas","Cao Xiao","Prateek Prasanna","Parminder Bhatia","Taha Kass-Hout"],"pdf_url":"https://arxiv.org/pdf/2503.04639v1.pdf","comment":"Accepted to CVPR 2025"},{"id":"http://arxiv.org/abs/2503.04638v1","updated":"2025-03-06T17:25:46Z","published":"2025-03-06T17:25:46Z","title":"No Forgetting Learning: Memory-free Continual Learning","summary":"  Continual Learning (CL) remains a central challenge in deep learning, where\nmodels must sequentially acquire new knowledge while mitigating Catastrophic\nForgetting (CF) of prior tasks. Existing approaches often struggle with\nefficiency and scalability, requiring extensive memory or model buffers. This\nwork introduces ``No Forgetting Learning\" (NFL), a memory-free CL framework\nthat leverages knowledge distillation to maintain stability while preserving\nplasticity. Memory-free means the NFL does not rely on any memory buffer.\nThrough extensive evaluations of three benchmark datasets, we demonstrate that\nNFL achieves competitive performance while utilizing approximately 14.75 times\nless memory than state-of-the-art methods. Furthermore, we introduce a new\nmetric to better assess CL's plasticity-stability trade-off.\n","authors":["Mohammad Ali Vahedifar","Qi Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.04638v1.pdf","comment":"This paper is submitted to ICCV 2025"},{"id":"http://arxiv.org/abs/2202.00665v4","updated":"2025-03-06T17:24:46Z","published":"2022-02-01T18:58:33Z","title":"Tutorial on amortized optimization","summary":"  Optimization is a ubiquitous modeling tool and is often deployed in settings\nwhich repeatedly solve similar instances of the same problem. Amortized\noptimization methods use learning to predict the solutions to problems in these\nsettings, exploiting the shared structure between similar problem instances.\nThese methods have been crucial in variational inference and reinforcement\nlearning and are capable of solving optimization problems many orders of\nmagnitudes times faster than traditional optimization methods that do not use\namortization. This tutorial presents an introduction to the amortized\noptimization foundations behind these advancements and overviews their\napplications in variational inference, sparse coding, gradient-based\nmeta-learning, control, reinforcement learning, convex optimization, optimal\ntransport, and deep equilibrium networks. The source code for this tutorial is\navailable at\nhttps://github.com/facebookresearch/amortized-optimization-tutorial.\n","authors":["Brandon Amos"],"pdf_url":"https://arxiv.org/pdf/2202.00665v4.pdf","comment":"Foundations and Trends in Machine Learning"},{"id":"http://arxiv.org/abs/2503.04636v1","updated":"2025-03-06T17:24:06Z","published":"2025-03-06T17:24:06Z","title":"Mark Your LLM: Detecting the Misuse of Open-Source Large Language Models\n  via Watermarking","summary":"  As open-source large language models (LLMs) like Llama3 become more capable,\nit is crucial to develop watermarking techniques to detect their potential\nmisuse. Existing watermarking methods either add watermarks during LLM\ninference, which is unsuitable for open-source LLMs, or primarily target\nclassification LLMs rather than recent generative LLMs. Adapting these\nwatermarks to open-source LLMs for misuse detection remains an open challenge.\nThis work defines two misuse scenarios for open-source LLMs: intellectual\nproperty (IP) violation and LLM Usage Violation. Then, we explore the\napplication of inference-time watermark distillation and backdoor watermarking\nin these contexts. We propose comprehensive evaluation methods to assess the\nimpact of various real-world further fine-tuning scenarios on watermarks and\nthe effect of these watermarks on LLM performance. Our experiments reveal that\nbackdoor watermarking could effectively detect IP Violation, while\ninference-time watermark distillation is applicable in both scenarios but less\nrobust to further fine-tuning and has a more significant impact on LLM\nperformance compared to backdoor watermarking. Exploring more advanced\nwatermarking methods for open-source LLMs to detect their misuse should be an\nimportant future direction.\n","authors":["Yijie Xu","Aiwei Liu","Xuming Hu","Lijie Wen","Hui Xiong"],"pdf_url":"https://arxiv.org/pdf/2503.04636v1.pdf","comment":"Accepted by the 1st Workshop on GenAI Watermarking, collocated with\n  ICLR 2025"},{"id":"http://arxiv.org/abs/2503.00897v3","updated":"2025-03-06T17:19:22Z","published":"2025-03-02T13:43:53Z","title":"A Simple and Effective Reinforcement Learning Method for Text-to-Image\n  Diffusion Fine-tuning","summary":"  Reinforcement learning (RL)-based fine-tuning has emerged as a powerful\napproach for aligning diffusion models with black-box objectives. Proximal\npolicy optimization (PPO) is the most popular choice of method for policy\noptimization. While effective in terms of performance, PPO is highly sensitive\nto hyper-parameters and involves substantial computational overhead. REINFORCE,\non the other hand, mitigates some computational complexities such as high\nmemory overhead and sensitive hyper-parameter tuning, but has suboptimal\nperformance due to high-variance and sample inefficiency. While the variance of\nthe REINFORCE can be reduced by sampling multiple actions per input prompt and\nusing a baseline correction term, it still suffers from sample inefficiency. To\naddress these challenges, we systematically analyze the\nefficiency-effectiveness trade-off between REINFORCE and PPO, and propose\nleave-one-out PPO (LOOP), a novel RL for diffusion fine-tuning method. LOOP\ncombines variance reduction techniques from REINFORCE, such as sampling\nmultiple actions per input prompt and a baseline correction term, with the\nrobustness and sample efficiency of PPO via clipping and importance sampling.\nOur results demonstrate that LOOP effectively improves diffusion models on\nvarious black-box objectives, and achieves a better balance between\ncomputational efficiency and performance.\n","authors":["Shashank Gupta","Chaitanya Ahuja","Tsung-Yu Lin","Sreya Dutta Roy","Harrie Oosterhuis","Maarten de Rijke","Satya Narayan Shukla"],"pdf_url":"https://arxiv.org/pdf/2503.00897v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04626v1","updated":"2025-03-06T17:12:46Z","published":"2025-03-06T17:12:46Z","title":"IDInit: A Universal and Stable Initialization Method for Neural Network\n  Training","summary":"  Deep neural networks have achieved remarkable accomplishments in practice.\nThe success of these networks hinges on effective initialization methods, which\nare vital for ensuring stable and rapid convergence during training. Recently,\ninitialization methods that maintain identity transition within layers have\nshown good efficiency in network training. These techniques (e.g., Fixup) set\nspecific weights to zero to achieve identity control. However, settings of\nremaining weight (e.g., Fixup uses random values to initialize non-zero\nweights) will affect the inductive bias that is achieved only by a zero weight,\nwhich may be harmful to training. Addressing this concern, we introduce fully\nidentical initialization (IDInit), a novel method that preserves identity in\nboth the main and sub-stem layers of residual networks. IDInit employs a padded\nidentity-like matrix to overcome rank constraints in non-square weight\nmatrices. Furthermore, we show the convergence problem of an identity matrix\ncan be solved by stochastic gradient descent. Additionally, we enhance the\nuniversality of IDInit by processing higher-order weights and addressing dead\nneuron problems. IDInit is a straightforward yet effective initialization\nmethod, with improved convergence, stability, and performance across various\nsettings, including large-scale datasets and deep models.\n","authors":["Yu Pan","Chaozheng Wang","Zekai Wu","Qifan Wang","Min Zhang","Zenglin Xu"],"pdf_url":"https://arxiv.org/pdf/2503.04626v1.pdf","comment":"Accepted in ICLR 2025"},{"id":"http://arxiv.org/abs/2410.05116v2","updated":"2025-03-06T17:11:55Z","published":"2024-10-07T15:12:01Z","title":"Human-Feedback Efficient Reinforcement Learning for Online Diffusion\n  Model Finetuning","summary":"  Controllable generation through Stable Diffusion (SD) fine-tuning aims to\nimprove fidelity, safety, and alignment with human guidance. Existing\nreinforcement learning from human feedback methods usually rely on predefined\nheuristic reward functions or pretrained reward models built on large-scale\ndatasets, limiting their applicability to scenarios where collecting such data\nis costly or difficult. To effectively and efficiently utilize human feedback,\nwe develop a framework, HERO, which leverages online human feedback collected\non the fly during model learning. Specifically, HERO features two key\nmechanisms: (1) Feedback-Aligned Representation Learning, an online training\nmethod that captures human feedback and provides informative learning signals\nfor fine-tuning, and (2) Feedback-Guided Image Generation, which involves\ngenerating images from SD's refined initialization samples, enabling faster\nconvergence towards the evaluator's intent. We demonstrate that HERO is 4x more\nefficient in online feedback for body part anomaly correction compared to the\nbest existing method. Additionally, experiments show that HERO can effectively\nhandle tasks like reasoning, counting, personalization, and reducing NSFW\ncontent with only 0.5K online feedback.\n","authors":["Ayano Hiranaka","Shang-Fu Chen","Chieh-Hsin Lai","Dongjun Kim","Naoki Murata","Takashi Shibuya","Wei-Hsiang Liao","Shao-Hua Sun","Yuki Mitsufuji"],"pdf_url":"https://arxiv.org/pdf/2410.05116v2.pdf","comment":"Published in International Conference on Learning Representations\n  (ICLR) 2025"},{"id":"http://arxiv.org/abs/2412.16561v2","updated":"2025-03-06T17:04:11Z","published":"2024-12-21T10:07:40Z","title":"A learning-based approach to stochastic optimal control under\n  reach-avoid constraint","summary":"  We develop a model-free approach to optimally control stochastic, Markovian\nsystems subject to a reach-avoid constraint. Specifically, the state trajectory\nmust remain within a safe set while reaching a target set within a finite time\nhorizon. Due to the time-dependent nature of these constraints, we show that,\nin general, the optimal policy for this constrained stochastic control problem\nis non-Markovian, which increases the computational complexity. To address this\nchallenge, we apply the state-augmentation technique from arXiv:2402.19360,\nreformulating the problem as a constrained Markov decision process (CMDP) on an\nextended state space. This transformation allows us to search for a Markovian\npolicy, avoiding the complexity of non-Markovian policies. To learn the optimal\npolicy without a system model, and using only trajectory data, we develop a\nlog-barrier policy gradient approach. We prove that under suitable assumptions,\nthe policy parameters converge to the optimal parameters, while ensuring that\nthe system trajectories satisfy the stochastic reach-avoid constraint with high\nprobability.\n","authors":["Tingting Ni","Maryam Kamgarpour"],"pdf_url":"https://arxiv.org/pdf/2412.16561v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04606v1","updated":"2025-03-06T16:53:14Z","published":"2025-03-06T16:53:14Z","title":"The Best of Both Worlds: Integrating Language Models and Diffusion\n  Models for Video Generation","summary":"  Recent advancements in text-to-video (T2V) generation have been driven by two\ncompeting paradigms: autoregressive language models and diffusion models.\nHowever, each paradigm has intrinsic limitations: language models struggle with\nvisual quality and error accumulation, while diffusion models lack semantic\nunderstanding and causal modeling. In this work, we propose LanDiff, a hybrid\nframework that synergizes the strengths of both paradigms through\ncoarse-to-fine generation. Our architecture introduces three key innovations:\n(1) a semantic tokenizer that compresses 3D visual features into compact 1D\ndiscrete representations through efficient semantic compression, achieving a\n$\\sim$14,000$\\times$ compression ratio; (2) a language model that generates\nsemantic tokens with high-level semantic relationships; (3) a streaming\ndiffusion model that refines coarse semantics into high-fidelity videos.\nExperiments show that LanDiff, a 5B model, achieves a score of 85.43 on the\nVBench T2V benchmark, surpassing the state-of-the-art open-source models\nHunyuan Video (13B) and other commercial models such as Sora, Keling, and\nHailuo. Furthermore, our model also achieves state-of-the-art performance in\nlong video generation, surpassing other open-source models in this field. Our\ndemo can be viewed at https://landiff.github.io/.\n","authors":["Aoxiong Yin","Kai Shen","Yichong Leng","Xu Tan","Xinyu Zhou","Juncheng Li","Siliang Tang"],"pdf_url":"https://arxiv.org/pdf/2503.04606v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03770v1","updated":"2025-03-06T16:42:53Z","published":"2025-03-06T16:42:53Z","title":"Fusion of Various Optimization Based Feature Smoothing Methods for\n  Wearable and Non-invasive Blood Glucose Estimation","summary":"  Recently, the wearable and non-invasive blood glucose estimation approach has\nbeen proposed. However, due to the unreliability of the acquisition device, the\npresence of the noise and the variations of the acquisition environments, the\nobtained features and the reference blood glucose values are highly unreliable.\nTo address this issue, this paper proposes a polynomial fitting approach to\nsmooth the obtained features or the reference blood glucose values. First, the\nblood glucose values are estimated based on the individual optimization\napproaches. Second, the absolute difference values between the estimated blood\nglucose values and the actual blood glucose values based on each optimization\napproach are computed. Third, these absolute difference values for each\noptimization approach are sorted in the ascending order. Fourth, for each\nsorted blood glucose value, the optimization method corresponding to the\nminimum absolute difference value is selected. Fifth, the accumulate\nprobability of each selected optimization method is computed. If the accumulate\nprobability of any selected optimization method at a point is greater than a\nthreshold value, then the accumulate probabilities of these three selected\noptimization methods at that point are reset to zero. A range of the sorted\nblood glucose values are defined as that with the corresponding boundaries\npoints being the previous reset point and this reset point. Hence, after\nperforming the above procedures for all the sorted reference blood glucose\nvalues in the validation set, the regions of the sorted reference blood glucose\nvalues and the corresponding optimization methods in these regions are\ndetermined. The computer numerical simulation results show that our proposed\nmethod yields the mean absolute relative deviation (MARD) at 0.0930 and the\npercentage of the test data falling in the zone A of the Clarke error grid at\n94.1176%.\n","authors":["Yiting Wei","Bingo Wing-Kuen Ling","Danni Chen","Yuheng Dai","Qing Liu"],"pdf_url":"https://arxiv.org/pdf/2503.03770v1.pdf","comment":"This version corrects several typos"},{"id":"http://arxiv.org/abs/2503.04598v1","updated":"2025-03-06T16:40:48Z","published":"2025-03-06T16:40:48Z","title":"HybridNorm: Towards Stable and Efficient Transformer Training via Hybrid\n  Normalization","summary":"  Transformers have become the de facto architecture for a wide range of\nmachine learning tasks, particularly in large language models (LLMs). Despite\ntheir remarkable performance, challenges remain in training deep transformer\nnetworks, especially regarding the location of layer normalization. While\nPre-Norm structures facilitate easier training due to their more prominent\nidentity path, they often yield suboptimal performance compared to Post-Norm.\nIn this paper, we propose $\\textbf{HybridNorm}$, a straightforward yet\neffective hybrid normalization strategy that integrates the advantages of both\nPre-Norm and Post-Norm approaches. Specifically, HybridNorm employs QKV\nnormalization within the attention mechanism and Post-Norm in the feed-forward\nnetwork (FFN) of each transformer block. This design not only stabilizes\ntraining but also enhances performance, particularly in the context of LLMs.\nComprehensive experiments in both dense and sparse architectures show that\nHybridNorm consistently outperforms both Pre-Norm and Post-Norm approaches,\nachieving state-of-the-art results across various benchmarks. These findings\nhighlight the potential of HybridNorm as a more stable and effective technique\nfor improving the training and performance of deep transformer models. %Code\nwill be made publicly available. Code is available at\nhttps://github.com/BryceZhuo/HybridNorm.\n","authors":["Zhijian Zhuo","Yutao Zeng","Ya Wang","Sijun Zhang","Jian Yang","Xiaoqing Li","Xun Zhou","Jinwen Ma"],"pdf_url":"https://arxiv.org/pdf/2503.04598v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.17412v3","updated":"2025-03-06T16:22:22Z","published":"2024-05-27T17:57:12Z","title":"Towards One Model for Classical Dimensionality Reduction: A\n  Probabilistic Perspective on UMAP and t-SNE","summary":"  This paper shows that dimensionality reduction methods such as UMAP and\nt-SNE, can be approximately recast as MAP inference methods corresponding to a\nmodel introduced in ProbDR, that describes the graph Laplacian (an estimate of\nthe data precision matrix) using a Wishart distribution, with a mean given by a\nnon-linear covariance function evaluated on the latents. This interpretation\noffers deeper theoretical and semantic insights into such algorithms, by\nshowing that variances corresponding to these covariances are low (potentially\nmisspecified), and forging a connection to Gaussian process latent variable\nmodels by showing that well-known kernels can be used to describe covariances\nimplied by graph Laplacians. We also introduce tools with which similar\ndimensionality reduction methods can be studied.\n","authors":["Aditya Ravuri","Neil D. Lawrence"],"pdf_url":"https://arxiv.org/pdf/2405.17412v3.pdf","comment":"Updated preprint"},{"id":"http://arxiv.org/abs/2503.04585v1","updated":"2025-03-06T16:22:19Z","published":"2025-03-06T16:22:19Z","title":"Advancing Solutions for the Three-Body Problem Through Physics-Informed\n  Neural Networks","summary":"  First formulated by Sir Isaac Newton in his work \"Philosophiae Naturalis\nPrincipia Mathematica\", the concept of the Three-Body Problem was put forth as\na study of the motion of the three celestial bodies within the Earth-Sun-Moon\nsystem. In a generalized definition, it seeks to predict the motion for an\nisolated system composed of three point masses freely interacting under\nNewton's law of universal attraction. This proves to be analogous to a\nmultitude of interactions between celestial bodies, and thus, the problem finds\napplicability within the studies of celestial mechanics. Despite numerous\nattempts by renowned physicists to solve it throughout the last three\ncenturies, no general closed-form solutions have been reached due to its\ninherently chaotic nature for most initial conditions. Current state-of-the-art\nsolutions are based on two approaches, either numerical high-precision\nintegration or machine learning-based. Notwithstanding the breakthroughs of\nneural networks, these present a significant limitation, which is their\nignorance of any prior knowledge of the chaotic systems presented. Thus, in\nthis work, we propose a novel method that utilizes Physics-Informed Neural\nNetworks (PINNs). These deep neural networks are able to incorporate any prior\nsystem knowledge expressible as an Ordinary Differential Equation (ODE) into\ntheir learning processes as a regularizing agent. Our findings showcase that\nPINNs surpass current state-of-the-art machine learning methods with comparable\nprediction quality. Despite a better prediction quality, the usability of\nnumerical integrators suffers due to their prohibitively high computational\ncost. These findings confirm that PINNs are both effective and time-efficient\nopen-form solvers of the Three-Body Problem that capitalize on the extensive\nknowledge we hold of classical mechanics.\n","authors":["Manuel Santos Pereira","Luís Tripa","Nélson Lima","Francisco Caldas","Cláudia Soares"],"pdf_url":"https://arxiv.org/pdf/2503.04585v1.pdf","comment":"14 pages, 25 figures, 3 tables. 75th International Astronautical\n  Congress (IAC), Milan, Italy, 14-18 October"},{"id":"http://arxiv.org/abs/2503.04582v1","updated":"2025-03-06T16:20:25Z","published":"2025-03-06T16:20:25Z","title":"PSDNorm: Test-Time Temporal Normalization for Deep Learning on EEG\n  Signals","summary":"  Distribution shift poses a significant challenge in machine learning,\nparticularly in biomedical applications such as EEG signals collected across\ndifferent subjects, institutions, and recording devices. While existing\nnormalization layers, Batch-Norm, LayerNorm and InstanceNorm, help address\ndistribution shifts, they fail to capture the temporal dependencies inherent in\ntemporal signals. In this paper, we propose PSDNorm, a layer that leverages\nMonge mapping and temporal context to normalize feature maps in deep learning\nmodels. Notably, the proposed method operates as a test-time domain adaptation\ntechnique, addressing distribution shifts without additional training.\nEvaluations on 10 sleep staging datasets using the U-Time model demonstrate\nthat PSDNorm achieves state-of-the-art performance at test time on datasets not\nseen during training while being 4x more data-efficient than the best baseline.\nAdditionally, PSDNorm provides a significant improvement in robustness,\nachieving markedly higher F1 scores for the 20% hardest subjects.\n","authors":["Théo Gnassounou","Antoine Collas","Rémi Flamary","Alexandre Gramfort"],"pdf_url":"https://arxiv.org/pdf/2503.04582v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.17504v2","updated":"2025-03-06T16:14:45Z","published":"2025-02-21T19:22:10Z","title":"Protein Large Language Models: A Comprehensive Survey","summary":"  Protein-specific large language models (Protein LLMs) are revolutionizing\nprotein science by enabling more efficient protein structure prediction,\nfunction annotation, and design. While existing surveys focus on specific\naspects or applications, this work provides the first comprehensive overview of\nProtein LLMs, covering their architectures, training datasets, evaluation\nmetrics, and diverse applications. Through a systematic analysis of over 100\narticles, we propose a structured taxonomy of state-of-the-art Protein LLMs,\nanalyze how they leverage large-scale protein sequence data for improved\naccuracy, and explore their potential in advancing protein engineering and\nbiomedical research. Additionally, we discuss key challenges and future\ndirections, positioning Protein LLMs as essential tools for scientific\ndiscovery in protein science. Resources are maintained at\nhttps://github.com/Yijia-Xiao/Protein-LLM-Survey.\n","authors":["Yijia Xiao","Wanjia Zhao","Junkai Zhang","Yiqiao Jin","Han Zhang","Zhicheng Ren","Renliang Sun","Haixin Wang","Guancheng Wan","Pan Lu","Xiao Luo","Yu Zhang","James Zou","Yizhou Sun","Wei Wang"],"pdf_url":"https://arxiv.org/pdf/2502.17504v2.pdf","comment":"24 pages, 4 figures, 5 tables"},{"id":"http://arxiv.org/abs/2412.07093v2","updated":"2025-03-06T16:14:01Z","published":"2024-12-10T01:21:56Z","title":"Streaming Private Continual Counting via Binning","summary":"  In differential privacy, $\\textit{continual observation}$ refers to problems\nin which we wish to continuously release a function of a dataset that is\nrevealed one element at a time. The challenge is to maintain a good\napproximation while keeping the combined output over all time steps\ndifferentially private. In the special case of $\\textit{continual counting}$ we\nseek to approximate a sum of binary input elements. This problem has received\nconsiderable attention lately, in part due to its relevance in implementations\nof differentially private stochastic gradient descent. $\\textit{Factorization\nmechanisms}$ are the leading approach to continual counting, but the best such\nmechanisms do not work well in $\\textit{streaming}$ settings since they require\nspace proportional to the size of the input. In this paper, we present a simple\napproach to approximating factorization mechanisms in low space via\n$\\textit{binning}$, where adjacent matrix entries with similar values are\nchanged to be identical in such a way that a matrix-vector product can be\nmaintained in sublinear space. Our approach has provable sublinear space\nguarantees for a class of lower triangular matrices whose entries are\nmonotonically decreasing away from the diagonal. We show empirically that even\nwith very low space usage we are able to closely match, and sometimes surpass,\nthe performance of asymptotically optimal factorization mechanisms. Recently,\nand independently of our work, Dvijotham et al. have also suggested an approach\nto implementing factorization mechanisms in a streaming setting. Their work\ndiffers from ours in several respects: It only addresses factorization into\n$\\textit{Toeplitz}$ matrices, only considers $\\textit{maximum}$ error, and uses\na different technique based on rational function approximation that seems less\nversatile than our binning approach.\n","authors":["Joel Daniel Andersson","Rasmus Pagh"],"pdf_url":"https://arxiv.org/pdf/2412.07093v2.pdf","comment":"Accepted to SaTML 2025. Final version to appear on IEEE eXplore"},{"id":"http://arxiv.org/abs/2503.04579v1","updated":"2025-03-06T16:13:32Z","published":"2025-03-06T16:13:32Z","title":"Data-augmented Learning of Geodesic Distances in Irregular Domains\n  through Soner Boundary Conditions","summary":"  Geodesic distances play a fundamental role in robotics, as they efficiently\nencode global geometric information of the domain. Recent methods use neural\nnetworks to approximate geodesic distances by solving the Eikonal equation\nthrough physics-informed approaches. While effective, these approaches often\nsuffer from unstable convergence during training in complex environments. We\npropose a framework to learn geodesic distances in irregular domains by using\nthe Soner boundary condition, and systematically evaluate the impact of data\nlosses on training stability and solution accuracy. Our experiments demonstrate\nthat incorporating data losses significantly improves convergence robustness,\nreducing training instabilities and sensitivity to initialization. These\nfindings suggest that hybrid data-physics approaches can effectively enhance\nthe reliability of learning-based geodesic distance solvers with sparse data.\n","authors":["Rafael I. Cabral Muchacho","Florian T. Pokorny"],"pdf_url":"https://arxiv.org/pdf/2503.04579v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01804v2","updated":"2025-03-06T16:07:43Z","published":"2025-03-03T18:33:46Z","title":"$\\texttt{SEM-CTRL}$: Semantically Controlled Decoding","summary":"  Ensuring both syntactic and semantic correctness in Large Language Model\n(LLM) outputs remains a significant challenge, despite being critical for\nreal-world deployment. In this paper, we introduce $\\texttt{SEM-CTRL}$, a\nunified approach that enforces rich context-sensitive constraints and task- and\ninstance-specific semantics directly on an LLM decoder. Our approach integrates\ntoken-level MCTS, which is guided by specific syntactic and semantic\nconstraints. The constraints over the desired outputs are expressed using\nAnswer Set Grammars -- a logic-based formalism that generalizes\ncontext-sensitive grammars while incorporating background knowledge to\nrepresent task-specific semantics. We show that our approach guarantees correct\ncompletions for any off-the-shelf LLM without the need for fine-tuning. We\nevaluate $\\texttt{SEM-CTRL}$ on a range of tasks, including synthetic grammar\nsynthesis, combinatorial reasoning, and planning. Our results demonstrate that\n$\\texttt{SEM-CTRL}$ allows small pre-trained LLMs to efficiently outperform\nlarger variants and state-of-the-art reasoning models (e.g., o1-preview) while\nsimultaneously guaranteeing solution correctness.\n","authors":["Mohammad Albinhassan","Pranava Madhyastha","Alessandra Russo"],"pdf_url":"https://arxiv.org/pdf/2503.01804v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04570v1","updated":"2025-03-06T16:05:29Z","published":"2025-03-06T16:05:29Z","title":"Meta Learning not to Learn: Robustly Informing Meta-Learning under\n  Nuisance-Varying Families","summary":"  In settings where both spurious and causal predictors are available, standard\nneural networks trained under the objective of empirical risk minimization\n(ERM) with no additional inductive biases tend to have a dependence on a\nspurious feature. As a result, it is necessary to integrate additional\ninductive biases in order to guide the network toward generalizable hypotheses.\nOften these spurious features are shared across related tasks, such as\nestimating disease prognoses from image scans coming from different hospitals,\nmaking the challenge of generalization more difficult. In these settings, it is\nimportant that methods are able to integrate the proper inductive biases to\ngeneralize across both nuisance-varying families as well as task families.\nMotivated by this setting, we present RIME (Robustly Informed Meta lEarning), a\nnew method for meta learning under the presence of both positive and negative\ninductive biases (what to learn and what not to learn). We first develop a\ntheoretical causal framework showing why existing approaches at knowledge\nintegration can lead to worse performance on distributionally robust\nobjectives. We then show that RIME is able to simultaneously integrate both\nbiases, reaching state of the art performance under distributionally robust\nobjectives in informed meta-learning settings under nuisance-varying families.\n","authors":["Louis McConnell"],"pdf_url":"https://arxiv.org/pdf/2503.04570v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.18049v2","updated":"2025-03-06T16:03:59Z","published":"2025-02-25T10:15:16Z","title":"Golden Ratio Weighting Prevents Model Collapse","summary":"  Recent studies identified an intriguing phenomenon in recursive generative\nmodel training known as model collapse, where models trained on data generated\nby previous models exhibit severe performance degradation. Addressing this\nissue and developing more effective training strategies have become central\nchallenges in generative model research. In this paper, we investigate this\nphenomenon theoretically within a novel framework, where generative models are\niteratively trained on a combination of newly collected real data and synthetic\ndata from the previous training step. To develop an optimal training strategy\nfor integrating real and synthetic data, we evaluate the performance of a\nweighted training scheme in various scenarios, including Gaussian distribution\nestimation and linear regression. We theoretically characterize the impact of\nthe mixing proportion and weighting scheme of synthetic data on the final\nmodel's performance. Our key finding is that, across different settings, the\noptimal weighting scheme under different proportions of synthetic data\nasymptotically follows a unified expression, revealing a fundamental trade-off\nbetween leveraging synthetic data and generative model performance. Notably, in\nsome cases, the optimal weight assigned to real data corresponds to the\nreciprocal of the golden ratio. Finally, we validate our theoretical results on\nextensive simulated datasets and a real tabular dataset.\n","authors":["Hengzhi He","Shirong Xu","Guang Cheng"],"pdf_url":"https://arxiv.org/pdf/2502.18049v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.00153v2","updated":"2025-03-06T15:50:28Z","published":"2024-09-30T18:52:53Z","title":"Beyond Single Concept Vector: Modeling Concept Subspace in LLMs with\n  Gaussian Distribution","summary":"  Probing learned concepts in large language models (LLMs) is crucial for\nunderstanding how semantic knowledge is encoded internally. Training linear\nclassifiers on probing tasks is a principle approach to denote the vector of a\ncertain concept in the representation space. However, the single vector\nidentified for a concept varies with both data and training, making it less\nrobust and weakening its effectiveness in real-world applications. To address\nthis challenge, we propose an approach to approximate the subspace representing\na specific concept. Built on linear probing classifiers, we extend the concept\nvectors into Gaussian Concept Subspace (GCS). We demonstrate GCS's\neffectiveness through measuring its faithfulness and plausibility across\nmultiple LLMs with different sizes and architectures. Additionally, we use\nrepresentation intervention tasks to showcase its efficacy in real-world\napplications such as emotion steering. Experimental results indicate that GCS\nconcept vectors have the potential to balance steering performance and\nmaintaining the fluency in natural language generation tasks.\n","authors":["Haiyan Zhao","Heng Zhao","Bo Shen","Ali Payani","Fan Yang","Mengnan Du"],"pdf_url":"https://arxiv.org/pdf/2410.00153v2.pdf","comment":"Accepted by ICLR 2025"},{"id":"http://arxiv.org/abs/2501.02436v2","updated":"2025-03-06T15:49:50Z","published":"2025-01-05T04:23:21Z","title":"An Analysis Framework for Understanding Deep Neural Networks Based on\n  Network Dynamics","summary":"  Advancing artificial intelligence demands a deeper understanding of the\nmechanisms underlying deep learning. Here, we propose a straightforward\nanalysis framework based on the dynamics of learning models. Neurons are\ncategorized into two modes based on whether their transformation functions\npreserve order. This categorization reveals how deep neural networks (DNNs)\nmaximize information extraction by rationally allocating the proportion of\nneurons in different modes across deep layers. We further introduce the\nattraction basins of the training samples in both the sample vector space and\nthe weight vector space to characterize the generalization ability of DNNs.\nThis framework allows us to identify optimal depth and width configurations,\nproviding a unified explanation for fundamental DNN behaviors such as the \"flat\nminima effect,\" \"grokking,\" and double descent phenomena. Our analysis extends\nto networks with depths up to 100 layers.\n","authors":["Yuchen Lin","Yong Zhang","Sihan Feng","Hong Zhao"],"pdf_url":"https://arxiv.org/pdf/2501.02436v2.pdf","comment":"12 pages, 10 figures"},{"id":"http://arxiv.org/abs/2503.04556v1","updated":"2025-03-06T15:47:19Z","published":"2025-03-06T15:47:19Z","title":"Compositional Causal Reasoning Evaluation in Language Models","summary":"  Causal reasoning and compositional reasoning are two core aspirations in\ngenerative AI. Measuring the extent of these behaviors requires principled\nevaluation methods. We explore a unified perspective that considers both\nbehaviors simultaneously, termed compositional causal reasoning (CCR): the\nability to infer how causal measures compose and, equivalently, how causal\nquantities propagate through graphs. We instantiate a framework for the\nsystematic evaluation of CCR for the average treatment effect and the\nprobability of necessity and sufficiency. As proof of concept, we demonstrate\nthe design of CCR tasks for language models in the LLama, Phi, and GPT\nfamilies. On a math word problem, our framework revealed a range of\ntaxonomically distinct error patterns. Additionally, CCR errors increased with\nthe complexity of causal paths for all models except o1.\n","authors":["Jacqueline R. M. A. Maasch","Alihan Hüyük","Xinnuo Xu","Aditya V. Nori","Javier Gonzalez"],"pdf_url":"https://arxiv.org/pdf/2503.04556v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.18691v2","updated":"2025-03-06T15:47:01Z","published":"2024-07-26T12:16:53Z","title":"Graph Neural Networks for Virtual Sensing in Complex Systems: Addressing\n  Heterogeneous Temporal Dynamics","summary":"  Real-time condition monitoring is crucial for the reliable and efficient\noperation of complex systems. However, relying solely on physical sensors can\nbe limited due to their cost, placement constraints, or inability to directly\nmeasure certain critical parameters. Virtual sensing addresses these\nlimitations by leveraging readily available sensor data and system knowledge to\nestimate inaccessible parameters or infer system states. The increasing\ncomplexity of industrial systems necessitates deployments of sensors with\ndiverse modalities to provide a comprehensive understanding of system states.\nThese sensors capture data at varying frequencies to monitor both rapid and\nslowly varying system dynamics, as well as local and global state evolutions of\nthe systems. This leads to heterogeneous temporal dynamics, which, particularly\nunder varying operational end environmental conditions, pose a significant\nchallenge for accurate virtual sensing. To address this, we propose a\nHeterogeneous Temporal Graph Neural Network (HTGNN) framework. HTGNN explicitly\nmodels signals from diverse sensors and integrates operating conditions into\nthe model architecture. We evaluate HTGNN using two newly released datasets: a\nbearing dataset with diverse load conditions for bearing load prediction and a\nyear-long simulated dataset for predicting bridge live loads. Our results\ndemonstrate that HTGNN significantly outperforms established baseline methods\nin both tasks, particularly under highly varying operating conditions. These\nresults highlight HTGNN's potential as a robust and accurate virtual sensing\napproach for complex systems, paving the way for improved monitoring,\npredictive maintenance, and enhanced system performance. Our code and data are\navailable under https://github.com/EPFL-IMOS/htgnn.\n","authors":["Mengjie Zhao","Cees Taal","Stephan Baggerohr","Olga Fink"],"pdf_url":"https://arxiv.org/pdf/2407.18691v2.pdf","comment":"This paper extends our previous conference paper (Best Paper at\n  European Conference of the PHM Society 2024,\n  https://doi.org/10.36001/phme.2024.v8i1.3998). Accepted by Mechanical Systems\n  and Signal Processing (MSSP)"},{"id":"http://arxiv.org/abs/2502.18394v4","updated":"2025-03-06T15:39:55Z","published":"2025-02-25T17:43:43Z","title":"The FFT Strikes Back: An Efficient Alternative to Self-Attention","summary":"  Conventional self-attention mechanisms incur quadratic complexity, limiting\ntheir scalability on long sequences. We introduce \\textbf{FFTNet}, an adaptive\nspectral filtering framework that leverages the Fast Fourier Transform (FFT) to\nachieve global token mixing in $\\mathcal{O}(n\\log n)$ time. By transforming\ninputs into the frequency domain, FFTNet exploits the orthogonality and energy\npreservation guaranteed by Parseval's theorem to capture long-range\ndependencies efficiently. Our main theoretical contributions are 1) an adaptive\nspectral filter, 2) combining local windowing with a global FFT branch, and 3)\nrich nonlinearity introduction in both the frequency and token domains.\nExperiments on the Long Range Arena and ImageNet benchmarks validate our\ntheoretical insights and demonstrate superior performance over fixed Fourier\nand standard attention models.\n","authors":["Jacob Fein-Ashley"],"pdf_url":"https://arxiv.org/pdf/2502.18394v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.09990v2","updated":"2025-03-06T15:38:31Z","published":"2025-02-14T08:22:51Z","title":"X-Boundary: Establishing Exact Safety Boundary to Shield LLMs from\n  Multi-Turn Jailbreaks without Compromising Usability","summary":"  Despite the rapid development of safety alignment techniques for LLMs,\ndefending against multi-turn jailbreaks is still a challenging task. In this\npaper, we conduct a comprehensive comparison, revealing that some existing\ndefense methods can improve the robustness of LLMs against multi-turn\njailbreaks but compromise usability, i.e., reducing general capabilities or\ncausing the over-refusal problem. From the perspective of mechanism\ninterpretability of LLMs, we discover that these methods fail to establish a\nboundary that exactly distinguishes safe and harmful feature representations.\nTherefore, boundary-safe representations close to harmful representations are\ninevitably disrupted, leading to a decline in usability. To address this issue,\nwe propose X-Boundary to push harmful representations away from boundary-safe\nrepresentations and obtain an exact distinction boundary. In this way, harmful\nrepresentations can be precisely erased without disrupting safe ones.\nExperimental results show that X-Boundary achieves state-of-the-art defense\nperformance against multi-turn jailbreaks, while reducing the over-refusal rate\nby about 20% and maintaining nearly complete general capability. Furthermore,\nwe theoretically prove and empirically verify that X-Boundary can accelerate\nthe convergence process during training. Please see our code at:\nhttps://github.com/AI45Lab/X-Boundary.\n","authors":["Xiaoya Lu","Dongrui Liu","Yi Yu","Luxin Xu","Jing Shao"],"pdf_url":"https://arxiv.org/pdf/2502.09990v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03660v2","updated":"2025-03-06T15:32:00Z","published":"2025-03-05T16:47:36Z","title":"Chunking the Critic: A Transformer-based Soft Actor-Critic with N-Step\n  Returns","summary":"  Soft Actor-Critic (SAC) critically depends on its critic network, which\ntypically evaluates a single state-action pair to guide policy updates. Using\nN-step returns is a common practice to reduce the bias in the target values of\nthe critic. However, using N-step returns can again introduce high variance and\nnecessitates importance sampling, often destabilizing training. Recent\nalgorithms have also explored action chunking-such as direct action repetition\nand movement primitives-to enhance exploration. In this paper, we propose a\nTransformer-based Critic Network for SAC that integrates the N-returns\nframework in a stable and efficient manner. Unlike approaches that perform\nchunking in the actor network, we feed chunked actions into the critic network\nto explore potential performance gains. Our architecture leverages the\nTransformer's ability to process sequential information, facilitating more\nrobust value estimation. Empirical results show that this method not only\nachieves efficient, stable training but also excels in sparse\nreward/multi-phase environments-traditionally a challenge for step-based\nmethods. These findings underscore the promise of combining Transformer-based\ncritics with N-returns to advance reinforcement learning performance\n","authors":["Dong Tian","Ge Li","Hongyi Zhou","Onur Celik","Gerhard Neumann"],"pdf_url":"https://arxiv.org/pdf/2503.03660v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.07516v3","updated":"2025-03-06T15:30:10Z","published":"2023-12-12T18:47:12Z","title":"Learning finitely correlated states: stability of the spectral\n  reconstruction","summary":"  Matrix product operators allow efficient descriptions (or realizations) of\nstates on a 1D lattice. We consider the task of learning a realization of\nminimal dimension from copies of an unknown state, such that the resulting\noperator is close to the density matrix in trace norm. For finitely correlated\ntranslation-invariant states on an infinite chain, a realization of minimal\ndimension can be exactly reconstructed via linear algebra operations from the\nmarginals of a size depending on the representation dimension. We establish a\nbound on the trace norm error for an algorithm that estimates a candidate\nrealization from estimates of these marginals and outputs a matrix product\noperator, estimating the state of a chain of arbitrary length $t$. This bound\nallows us to establish an $O(t^2)$ upper bound on the sample complexity of the\nlearning task, with an explicit dependence on the site dimension, realization\ndimension and spectral properties of a certain map constructed from the state.\nA refined error bound can be proven for $C^*$-finitely correlated states, which\nhave an operational interpretation in terms of sequential quantum channels\napplied to the memory system. We can also obtain an analogous error bound for a\nclass of matrix product density operators on a finite chain reconstructible by\nlocal marginals. In this case, a linear number of marginals must be estimated,\nobtaining a sample complexity of $\\tilde{O}(t^3)$. The learning algorithm also\nworks for states that are sufficiently close to a finitely correlated state,\nwith the potential of providing competitive algorithms for other interesting\nfamilies of states.\n","authors":["Marco Fanizza","Niklas Galke","Josep Lumbreras","Cambyse Rouzé","Andreas Winter"],"pdf_url":"https://arxiv.org/pdf/2312.07516v3.pdf","comment":"42 pages, 7 figures. Manuscript restructured, with minor corrections\n  and clarifications"},{"id":"http://arxiv.org/abs/2403.00025v2","updated":"2025-03-06T15:29:41Z","published":"2024-02-28T15:19:33Z","title":"On the Challenges and Opportunities in Generative AI","summary":"  The field of deep generative modeling has grown rapidly in the last few\nyears. With the availability of massive amounts of training data coupled with\nadvances in scalable unsupervised learning paradigms, recent large-scale\ngenerative models show tremendous promise in synthesizing high-resolution\nimages and text, as well as structured data such as videos and molecules.\nHowever, we argue that current large-scale generative AI models exhibit several\nfundamental shortcomings that hinder their widespread adoption across domains.\nIn this work, our objective is to identify these issues and highlight key\nunresolved challenges in modern generative AI paradigms that should be\naddressed to further enhance their capabilities, versatility, and reliability.\nBy identifying these challenges, we aim to provide researchers with insights\nfor exploring fruitful research directions, thus fostering the development of\nmore robust and accessible generative AI solutions.\n","authors":["Laura Manduchi","Kushagra Pandey","Clara Meister","Robert Bamler","Ryan Cotterell","Sina Däubener","Sophie Fellenz","Asja Fischer","Thomas Gärtner","Matthias Kirchler","Marius Kloft","Yingzhen Li","Christoph Lippert","Gerard de Melo","Eric Nalisnick","Björn Ommer","Rajesh Ranganath","Maja Rudolph","Karen Ullrich","Guy Van den Broeck","Julia E Vogt","Yixin Wang","Florian Wenzel","Frank Wood","Stephan Mandt","Vincent Fortuin"],"pdf_url":"https://arxiv.org/pdf/2403.00025v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07180v5","updated":"2025-03-06T15:26:56Z","published":"2024-11-11T17:57:30Z","title":"Gumbel Counterfactual Generation From Language Models","summary":"  Understanding and manipulating the causal generation mechanisms in language\nmodels is essential for controlling their behavior. Previous work has primarily\nrelied on techniques such as representation surgery -- e.g., model ablations or\nmanipulation of linear subspaces tied to specific concepts -- to\n\\emph{intervene} on these models. To understand the impact of interventions\nprecisely, it is useful to examine \\emph{counterfactuals} -- e.g., how a given\nsentence would have appeared had it been generated by the model following a\nspecific intervention. We highlight that counterfactual reasoning is\nconceptually distinct from interventions, as articulated in Pearl's causal\nhierarchy. Based on this observation, we propose a framework for generating\ntrue string counterfactuals by reformulating language models as a structural\nequation model using the Gumbel-max trick, which we called Gumbel\ncounterfactual generation. This reformulation allows us to model the joint\ndistribution over original strings and their counterfactuals resulting from the\nsame instantiation of the sampling noise. We develop an algorithm based on\nhindsight Gumbel sampling that allows us to infer the latent noise variables\nand generate counterfactuals of observed strings. Our experiments demonstrate\nthat the approach produces meaningful counterfactuals while at the same time\nshowing that commonly used intervention techniques have considerable undesired\nside effects.\n","authors":["Shauli Ravfogel","Anej Svete","Vésteinn Snæbjarnarson","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2411.07180v5.pdf","comment":"Accepted in ICLR 2025"},{"id":"http://arxiv.org/abs/2503.04528v1","updated":"2025-03-06T15:16:57Z","published":"2025-03-06T15:16:57Z","title":"Federated Dynamic Modeling and Learning for Spatiotemporal Data\n  Forecasting","summary":"  This paper presents an advanced Federated Learning (FL) framework for\nforecasting complex spatiotemporal data, improving upon recent state-of-the-art\nmodels. In the proposed approach, the original Gated Recurrent Unit (GRU)\nmodule within previous Dynamic Spatial--Temporal Graph Convolutional Recurrent\nNetwork (DSTGCRN) modeling is first replaced with a Long Short-Term Memory\n(LSTM) network, enabling the resulting model to more effectively capture\nlong-term dependencies inherent to time series data. The resulting architecture\nsignificantly improves the model's capacity to handle complex temporal patterns\nin diverse forecasting applications. Furthermore, the proposed FL framework\nintegrates a novel Client-Side Validation (CSV) mechanism, introducing a\ncritical validation step at the client level before incorporating aggregated\nparameters from the central server into local models. This ensures that only\nthe most effective updates are adopted, improving both the robustness and\naccuracy of the forecasting model across clients. The efficiency of our\napproach is demonstrated through extensive experiments on real-world\napplications, including public datasets for multimodal transport demand\nforecasting and private datasets for Origin-Destination (OD) matrix forecasting\nin urban areas. The results demonstrate substantial improvements over\nconventional methods, highlighting the framework's ability to capture complex\nspatiotemporal dependencies while preserving data privacy. This work not only\nprovides a scalable and privacy-preserving solution for real-time,\nregion-specific forecasting and management but also underscores the potential\nof leveraging distributed data sources in a FL context. We provide our\nalgorithms as open-source on GitHub.\n","authors":["Thien Pham","Angelo Furno","Faïcel Chamroukhi","Latifa Oukhellou"],"pdf_url":"https://arxiv.org/pdf/2503.04528v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07775v2","updated":"2025-03-06T15:15:58Z","published":"2024-12-10T18:59:58Z","title":"Efficient Diversity-Preserving Diffusion Alignment via Gradient-Informed\n  GFlowNets","summary":"  While one commonly trains large diffusion models by collecting datasets on\ntarget downstream tasks, it is often desired to align and finetune pretrained\ndiffusion models with some reward functions that are either designed by experts\nor learned from small-scale datasets. Existing post-training methods for reward\nfinetuning of diffusion models typically suffer from lack of diversity in\ngenerated samples, lack of prior preservation, and/or slow convergence in\nfinetuning. Inspired by recent successes in generative flow networks\n(GFlowNets), a class of probabilistic models that sample with the unnormalized\ndensity of a reward function, we propose a novel GFlowNet method dubbed\nNabla-GFlowNet (abbreviated as \\methodname), the first GFlowNet method that\nleverages the rich signal in reward gradients, together with an objective\ncalled \\graddb plus its variant \\resgraddb designed for prior-preserving\ndiffusion finetuning. We show that our proposed method achieves fast yet\ndiversity- and prior-preserving finetuning of Stable Diffusion, a large-scale\ntext-conditioned image diffusion model, on different realistic reward\nfunctions.\n","authors":["Zhen Liu","Tim Z. Xiao","Weiyang Liu","Yoshua Bengio","Dinghuai Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.07775v2.pdf","comment":"Technical Report (35 pages, 31 figures), Accepted at ICLR 2025"},{"id":"http://arxiv.org/abs/2411.12580v2","updated":"2025-03-06T15:14:17Z","published":"2024-11-19T15:47:12Z","title":"Procedural Knowledge in Pretraining Drives Reasoning in Large Language\n  Models","summary":"  The capabilities and limitations of Large Language Models have been sketched\nout in great detail in recent years, providing an intriguing yet conflicting\npicture. On the one hand, LLMs demonstrate a general ability to solve problems.\nOn the other hand, they show surprising reasoning gaps when compared to humans,\ncasting doubt on the robustness of their generalisation strategies. The sheer\nvolume of data used in the design of LLMs has precluded us from applying the\nmethod traditionally used to measure generalisation: train-test set separation.\nTo overcome this, we study what kind of generalisation strategies LLMs employ\nwhen performing reasoning tasks by investigating the pretraining data they rely\non. For two models of different sizes (7B and 35B) and 2.5B of their\npretraining tokens, we identify what documents influence the model outputs for\nthree simple mathematical reasoning tasks and contrast this to the data that\nare influential for answering factual questions. We find that, while the models\nrely on mostly distinct sets of data for each factual question, a document\noften has a similar influence across different reasoning questions within the\nsame task, indicating the presence of procedural knowledge. We further find\nthat the answers to factual questions often show up in the most influential\ndata. However, for reasoning questions the answers usually do not show up as\nhighly influential, nor do the answers to the intermediate reasoning steps.\nWhen we characterise the top ranked documents for the reasoning questions\nqualitatively, we confirm that the influential documents often contain\nprocedural knowledge, like demonstrating how to obtain a solution using\nformulae or code. Our findings indicate that the approach to reasoning the\nmodels use is unlike retrieval, and more like a generalisable strategy that\nsynthesises procedural knowledge from documents doing a similar form of\nreasoning.\n","authors":["Laura Ruis","Maximilian Mozes","Juhan Bae","Siddhartha Rao Kamalakara","Dwarak Talupuru","Acyr Locatelli","Robert Kirk","Tim Rocktäschel","Edward Grefenstette","Max Bartolo"],"pdf_url":"https://arxiv.org/pdf/2411.12580v2.pdf","comment":"Published at ICLR 2025"},{"id":"http://arxiv.org/abs/2410.04166v2","updated":"2025-03-06T15:11:57Z","published":"2024-10-05T14:04:03Z","title":"Learning from negative feedback, or positive feedback or both","summary":"  Existing preference optimization methods often assume scenarios where paired\npreference feedback (preferred/positive vs. dis-preferred/negative examples) is\navailable. This requirement limits their applicability in scenarios where only\nunpaired feedback--for example, either positive or negative--is available. To\naddress this, we introduce a novel approach that decouples learning from\npositive and negative feedback. This decoupling enables control over the\ninfluence of each feedback type and, importantly, allows learning even when\nonly one feedback type is present. A key contribution is demonstrating stable\nlearning from negative feedback alone, a capability not well-addressed by\ncurrent methods. Our approach builds upon the probabilistic framework\nintroduced in (Dayan and Hinton, 1997), which uses expectation-maximization\n(EM) to directly optimize the probability of positive outcomes (as opposed to\nclassic expected reward maximization). We address a key limitation in current\nEM-based methods: they solely maximize the likelihood of positive examples,\nwhile neglecting negative ones. We show how to extend EM algorithms to\nexplicitly incorporate negative examples, leading to a theoretically grounded\nalgorithm that offers an intuitive and versatile way to learn from both\npositive and negative feedback. We evaluate our approach for training language\nmodels based on human feedback as well as training policies for sequential\ndecision-making problems, where learned value functions are available.\n","authors":["Abbas Abdolmaleki","Bilal Piot","Bobak Shahriari","Jost Tobias Springenberg","Tim Hertweck","Rishabh Joshi","Junhyuk Oh","Michael Bloesch","Thomas Lampe","Nicolas Heess","Jonas Buchli","Martin Riedmiller"],"pdf_url":"https://arxiv.org/pdf/2410.04166v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04518v1","updated":"2025-03-06T15:06:01Z","published":"2025-03-06T15:06:01Z","title":"Leveraging priors on distribution functions for multi-arm bandits","summary":"  We introduce Dirichlet Process Posterior Sampling (DPPS), a Bayesian\nnon-parametric algorithm for multi-arm bandits based on Dirichlet Process (DP)\npriors. Like Thompson-sampling, DPPS is a probability-matching algorithm, i.e.,\nit plays an arm based on its posterior-probability of being optimal. Instead of\nassuming a parametric class for the reward generating distribution of each arm,\nand then putting a prior on the parameters, in DPPS the reward generating\ndistribution is directly modeled using DP priors. DPPS provides a principled\napproach to incorporate prior belief about the bandit environment, and in the\nnoninformative limit of the DP posteriors (i.e. Bayesian Bootstrap), we recover\nNon Parametric Thompson Sampling (NPTS), a popular non-parametric bandit\nalgorithm, as a special case of DPPS. We employ stick-breaking representation\nof the DP priors, and show excellent empirical performance of DPPS in\nchallenging synthetic and real world bandit environments. Finally, using an\ninformation-theoretic analysis, we show non-asymptotic optimality of DPPS in\nthe Bayesian regret setup.\n","authors":["Sumit Vashishtha","Odalric-Ambrym Maillard"],"pdf_url":"https://arxiv.org/pdf/2503.04518v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.05874v2","updated":"2025-03-06T15:02:33Z","published":"2025-02-09T12:23:40Z","title":"MMGDreamer: Mixed-Modality Graph for Geometry-Controllable 3D Indoor\n  Scene Generation","summary":"  Controllable 3D scene generation has extensive applications in virtual\nreality and interior design, where the generated scenes should exhibit high\nlevels of realism and controllability in terms of geometry. Scene graphs\nprovide a suitable data representation that facilitates these applications.\nHowever, current graph-based methods for scene generation are constrained to\ntext-based inputs and exhibit insufficient adaptability to flexible user\ninputs, hindering the ability to precisely control object geometry. To address\nthis issue, we propose MMGDreamer, a dual-branch diffusion model for scene\ngeneration that incorporates a novel Mixed-Modality Graph, visual enhancement\nmodule, and relation predictor. The mixed-modality graph allows object nodes to\nintegrate textual and visual modalities, with optional relationships between\nnodes. It enhances adaptability to flexible user inputs and enables meticulous\ncontrol over the geometry of objects in the generated scenes. The visual\nenhancement module enriches the visual fidelity of text-only nodes by\nconstructing visual representations using text embeddings. Furthermore, our\nrelation predictor leverages node representations to infer absent relationships\nbetween nodes, resulting in more coherent scene layouts. Extensive experimental\nresults demonstrate that MMGDreamer exhibits superior control of object\ngeometry, achieving state-of-the-art scene generation performance. Project\npage: https://yangzhifeio.github.io/project/MMGDreamer.\n","authors":["Zhifei Yang","Keyang Lu","Chao Zhang","Jiaxing Qi","Hanqi Jiang","Ruifei Ma","Shenglin Yin","Yifan Xu","Mingzhe Xing","Zhen Xiao","Jieyi Long","Xiangde Liu","Guangyao Zhai"],"pdf_url":"https://arxiv.org/pdf/2502.05874v2.pdf","comment":"Accepted by AAAI 2025 Main Track"},{"id":"http://arxiv.org/abs/2503.04509v1","updated":"2025-03-06T14:55:25Z","published":"2025-03-06T14:55:25Z","title":"STX-Search: Explanation Search for Continuous Dynamic Spatio-Temporal\n  Models","summary":"  Recent improvements in the expressive power of spatio-temporal models have\nled to performance gains in many real-world applications, such as traffic\nforecasting and social network modelling. However, understanding the\npredictions from a model is crucial to ensure reliability and trustworthiness,\nparticularly for high-risk applications, such as healthcare and transport. Few\nexisting methods are able to generate explanations for models trained on\ncontinuous-time dynamic graph data and, of these, the computational complexity\nand lack of suitable explanation objectives pose challenges. In this paper, we\npropose $\\textbf{S}$patio-$\\textbf{T}$emporal E$\\textbf{X}$planation\n$\\textbf{Search}$ (STX-Search), a novel method for generating instance-level\nexplanations that is applicable to static and dynamic temporal graph\nstructures. We introduce a novel search strategy and objective function, to\nfind explanations that are highly faithful and interpretable. When compared\nwith existing methods, STX-Search produces explanations of higher fidelity\nwhilst optimising explanation size to maintain interpretability.\n","authors":["Saif Anwar","Nathan Griffiths","Thomas Popham","Abhir Bhalerao"],"pdf_url":"https://arxiv.org/pdf/2503.04509v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04507v1","updated":"2025-03-06T14:54:28Z","published":"2025-03-06T14:54:28Z","title":"A Morse Transform for Drug Discovery","summary":"  We introduce a new ligand-based virtual screening (LBVS) framework that uses\npiecewise linear (PL) Morse theory to predict ligand binding potential. We\nmodel ligands as simplicial complexes via a pruned Delaunay triangulation, and\ncatalogue the critical points across multiple directional height functions.\nThis produces a rich feature vector, consisting of crucial topological features\n-- peaks, troughs, and saddles -- that characterise ligand surfaces relevant to\nbinding interactions. Unlike contemporary LBVS methods that rely on\ncomputationally-intensive deep neural networks, we require only a lightweight\nclassifier. The Morse theoretic approach achieves state-of-the-art performance\non standard datasets while offering an interpretable feature vector and\nscalable method for ligand prioritization in early-stage drug discovery.\n","authors":["Alexander M. Tanaka","Aras T. Asaad","Richard Cooper","Vidit Nanda"],"pdf_url":"https://arxiv.org/pdf/2503.04507v1.pdf","comment":"25 pages, 5 main figures, 2 main tables, 6 supplementary figures and\n  4 supplementary tables"},{"id":"http://arxiv.org/abs/2501.00020v2","updated":"2025-03-06T14:52:11Z","published":"2024-12-16T11:35:40Z","title":"Magnetic Field Data Calibration with Transformer Model Using Physical\n  Constraints: A Scalable Method for Satellite Missions, Illustrated by\n  Tianwen-1","summary":"  This study introduces a novel approach that integrates the magnetic field\ndata correction from the Tianwen-1 Mars mission with a neural network\narchitecture constrained by physical principles derived from Maxwell's equation\nequations. By employing a Transformer based model capable of efficiently\nhandling sequential data, the method corrects measurement anomalies caused by\nsatellite dynamics, instrument interference, and environmental noise. As a\nresult, it significantly improves both the accuracy and the physical\nconsistency of the calibrated data. Compared to traditional methods that\nrequire long data segments and manual intervention often taking weeks or even\nmonths to complete this new approach can finish calibration in just minutes to\nhours, and predictions are made within seconds. This innovation not only\naccelerates the process of space weather modeling and planetary magnetospheric\nstudies but also provides a robust framework for future planetary exploration\nand solar wind interaction research.\n","authors":["Beibei Li","Yutian Chi","Yuming Wang"],"pdf_url":"https://arxiv.org/pdf/2501.00020v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04496v1","updated":"2025-03-06T14:44:25Z","published":"2025-03-06T14:44:25Z","title":"Learning Object Placement Programs for Indoor Scene Synthesis with\n  Iterative Self Training","summary":"  Data driven and autoregressive indoor scene synthesis systems generate indoor\nscenes automatically by suggesting and then placing objects one at a time.\nEmpirical observations show that current systems tend to produce incomplete\nnext object location distributions. We introduce a system which addresses this\nproblem. We design a Domain Specific Language (DSL) that specifies functional\nconstraints. Programs from our language take as input a partial scene and\nobject to place. Upon execution they predict possible object placements. We\ndesign a generative model which writes these programs automatically. Available\n3D scene datasets do not contain programs to train on, so we build upon\nprevious work in unsupervised program induction to introduce a new program\nbootstrapping algorithm. In order to quantify our empirical observations we\nintroduce a new evaluation procedure which captures how well a system models\nper-object location distributions. We ask human annotators to label all the\npossible places an object can go in a scene and show that our system produces\nper-object location distributions more consistent with human annotators. Our\nsystem also generates indoor scenes of comparable quality to previous systems\nand while previous systems degrade in performance when training data is sparse,\nour system does not degrade to the same degree.\n","authors":["Adrian Chang","Kai Wang","Yuanbo Li","Manolis Savva","Angel X. Chang","Daniel Ritchie"],"pdf_url":"https://arxiv.org/pdf/2503.04496v1.pdf","comment":"21 pages, 20 figures Subjects: Graphics (cs.GR), Computer Vision and\n  Pattern Recognition (cs.CV), Machine Learning (cs.LG)"},{"id":"http://arxiv.org/abs/2503.04492v1","updated":"2025-03-06T14:40:21Z","published":"2025-03-06T14:40:21Z","title":"Accurate predictive model of band gap with selected important features\n  based on explainable machine learning","summary":"  In the rapidly advancing field of materials informatics, nonlinear machine\nlearning models have demonstrated exceptional predictive capabilities for\nmaterial properties. However, their black-box nature limits interpretability,\nand they may incorporate features that do not contribute to, or even\ndeteriorate, model performance. This study employs explainable ML (XML)\ntechniques, including permutation feature importance and the SHapley Additive\nexPlanation, applied to a pristine support vector regression model designed to\npredict band gaps at the GW level using 18 input features. Guided by\nXML-derived individual feature importance, a simple framework is proposed to\nconstruct reduced-feature predictive models. Model evaluations indicate that an\nXML-guided compact model, consisting of the top five features, achieves\ncomparable accuracy to the pristine model on in-domain datasets while\ndemonstrating superior generalization with lower prediction errors on\nout-of-domain data. Additionally, the study underscores the necessity for\neliminating strongly correlated features to prevent misinterpretation and\noverestimation of feature importance before applying XML. This study highlights\nXML's effectiveness in developing simplified yet highly accurate machine\nlearning models by clarifying feature roles.\n","authors":["Joohwi Lee","Kaito Miyamoto"],"pdf_url":"https://arxiv.org/pdf/2503.04492v1.pdf","comment":"9 pages, 4 figures, SI is included"},{"id":"http://arxiv.org/abs/2503.04483v1","updated":"2025-03-06T14:32:00Z","published":"2025-03-06T14:32:00Z","title":"InfoSEM: A Deep Generative Model with Informative Priors for Gene\n  Regulatory Network Inference","summary":"  Inferring Gene Regulatory Networks (GRNs) from gene expression data is\ncrucial for understanding biological processes. While supervised models are\nreported to achieve high performance for this task, they rely on costly ground\ntruth (GT) labels and risk learning gene-specific biases, such as class\nimbalances of GT interactions, rather than true regulatory mechanisms. To\naddress these issues, we introduce InfoSEM, an unsupervised generative model\nthat leverages textual gene embeddings as informative priors, improving GRN\ninference without GT labels. InfoSEM can also integrate GT labels as an\nadditional prior when available, avoiding biases and further enhancing\nperformance. Additionally, we propose a biologically motivated benchmarking\nframework that better reflects real-world applications such as biomarker\ndiscovery and reveals learned biases of existing supervised methods. InfoSEM\noutperforms existing models by 38.5% across four datasets using textual\nembeddings prior and further boosts performance by 11.1% when integrating\nlabeled data as priors.\n","authors":["Tianyu Cui","Song-Jun Xu","Artem Moskalev","Shuwei Li","Tommaso Mansi","Mangal Prakash","Rui Liao"],"pdf_url":"https://arxiv.org/pdf/2503.04483v1.pdf","comment":"ICLR 2025 AI4NA Oral, ICLR 2025 MLGenX Spotlight, ICLR 2025 LMRL"},{"id":"http://arxiv.org/abs/2503.04482v1","updated":"2025-03-06T14:30:55Z","published":"2025-03-06T14:30:55Z","title":"Generalized Interpolating Discrete Diffusion","summary":"  While state-of-the-art language models achieve impressive results through\nnext-token prediction, they have inherent limitations such as the inability to\nrevise already generated tokens. This has prompted exploration of alternative\napproaches such as discrete diffusion. However, masked diffusion, which has\nemerged as a popular choice due to its simplicity and effectiveness,\nreintroduces this inability to revise words. To overcome this, we generalize\nmasked diffusion and derive the theoretical backbone of a family of general\ninterpolating discrete diffusion (GIDD) processes offering greater flexibility\nin the design of the noising processes. Leveraging a novel diffusion ELBO, we\nachieve compute-matched state-of-the-art performance in diffusion language\nmodeling. Exploiting GIDD's flexibility, we explore a hybrid approach combining\nmasking and uniform noise, leading to improved sample quality and unlocking the\nability for the model to correct its own mistakes, an area where autoregressive\nmodels notoriously have struggled. Our code and models are open-source:\nhttps://github.com/dvruette/gidd/\n","authors":["Dimitri von Rütte","Janis Fluri","Yuhui Ding","Antonio Orvieto","Bernhard Schölkopf","Thomas Hofmann"],"pdf_url":"https://arxiv.org/pdf/2503.04482v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04480v1","updated":"2025-03-06T14:30:15Z","published":"2025-03-06T14:30:15Z","title":"Poisoning Bayesian Inference via Data Deletion and Replication","summary":"  Research in adversarial machine learning (AML) has shown that statistical\nmodels are vulnerable to maliciously altered data. However, despite advances in\nBayesian machine learning models, most AML research remains concentrated on\nclassical techniques. Therefore, we focus on extending the white-box model\npoisoning paradigm to attack generic Bayesian inference, highlighting its\nvulnerability in adversarial contexts. A suite of attacks are developed that\nallow an attacker to steer the Bayesian posterior toward a target distribution\nthrough the strategic deletion and replication of true observations, even when\nonly sampling access to the posterior is available. Analytic properties of\nthese algorithms are proven and their performance is empirically examined in\nboth synthetic and real-world scenarios. With relatively little effort, the\nattacker is able to substantively alter the Bayesian's beliefs and, by\naccepting more risk, they can mold these beliefs to their will. By carefully\nconstructing the adversarial posterior, surgical poisoning is achieved such\nthat only targeted inferences are corrupted and others are minimally disturbed.\n","authors":["Matthieu Carreau","Roi Naveiro","William N. Caballero"],"pdf_url":"https://arxiv.org/pdf/2503.04480v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.13524v4","updated":"2025-03-06T14:27:12Z","published":"2025-02-19T08:21:59Z","title":"MobileViM: A Light-weight and Dimension-independent Vision Mamba for 3D\n  Medical Image Analysis","summary":"  Efficient evaluation of three-dimensional (3D) medical images is crucial for\ndiagnostic and therapeutic practices in healthcare. Recent years have seen a\nsubstantial uptake in applying deep learning and computer vision to analyse and\ninterpret medical images. Traditional approaches, such as convolutional neural\nnetworks (CNNs) and vision transformers (ViTs), face significant computational\nchallenges, prompting the need for architectural advancements. Recent efforts\nhave led to the introduction of novel architectures like the ``Mamba'' model as\nalternative solutions to traditional CNNs or ViTs. The Mamba model excels in\nthe linear processing of one-dimensional data with low computational demands.\nHowever, Mamba's potential for 3D medical image analysis remains underexplored\nand could face significant computational challenges as the dimension increases.\nThis manuscript presents MobileViM, a streamlined architecture for efficient\nsegmentation of 3D medical images. In the MobileViM network, we invent a new\ndimension-independent mechanism and a dual-direction traversing approach to\nincorporate with a vision-Mamba-based framework. MobileViM also features a\ncross-scale bridging technique to improve efficiency and accuracy across\nvarious medical imaging modalities. With these enhancements, MobileViM achieves\nsegmentation speeds exceeding 90 frames per second (FPS) on a single graphics\nprocessing unit (i.e., NVIDIA RTX 4090). This performance is over 24 FPS faster\nthan the state-of-the-art deep learning models for processing 3D images with\nthe same computational resources. In addition, experimental evaluations\ndemonstrate that MobileViM delivers superior performance, with Dice similarity\nscores reaching 92.72%, 86.69%, 80.46%, and 77.43% for PENGWIN, BraTS2024,\nATLAS, and Toothfairy2 datasets, respectively, which significantly surpasses\nexisting models.\n","authors":["Wei Dai","Jun Liu"],"pdf_url":"https://arxiv.org/pdf/2502.13524v4.pdf","comment":"The corresponding author disagrees with the manuscript submitted to\n  arXiv"},{"id":"http://arxiv.org/abs/2503.03454v2","updated":"2025-03-06T14:25:03Z","published":"2025-03-05T12:40:34Z","title":"Data Poisoning Attacks to Locally Differentially Private Range Query\n  Protocols","summary":"  Local Differential Privacy (LDP) has been widely adopted to protect user\nprivacy in decentralized data collection. However, recent studies have revealed\nthat LDP protocols are vulnerable to data poisoning attacks, where malicious\nusers manipulate their reported data to distort aggregated results. In this\nwork, we present the first study on data poisoning attacks targeting LDP range\nquery protocols, focusing on both tree-based and grid-based approaches. We\nidentify three key challenges in executing such attacks, including crafting\nconsistent and effective fake data, maintaining data consistency across levels\nor grids, and preventing server detection. To address the first two challenges,\nwe propose novel attack methods that are provably optimal, including a\ntree-based attack and a grid-based attack, designed to manipulate range query\nresults with high effectiveness. \\textbf{Our key finding is that the common\npost-processing procedure, Norm-Sub, in LDP range query protocols can help the\nattacker massively amplify their attack effectiveness.} In addition, we study a\npotential countermeasure, but also propose an adaptive attack capable of\nevading this defense to address the third challenge. We evaluate our methods\nthrough theoretical analysis and extensive experiments on synthetic and\nreal-world datasets. Our results show that the proposed attacks can\nsignificantly amplify estimations for arbitrary range queries by manipulating a\nsmall fraction of users, providing 5-10x more influence than a normal user to\nthe estimation.\n","authors":["Ting-Wei Liao","Chih-Hsun Lin","Yu-Lin Tsai","Takao Murakami","Chia-Mu Yu","Jun Sakuma","Chun-Ying Huang","Hiroaki Kikuchi"],"pdf_url":"https://arxiv.org/pdf/2503.03454v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04474v1","updated":"2025-03-06T14:24:12Z","published":"2025-03-06T14:24:12Z","title":"Know Thy Judge: On the Robustness Meta-Evaluation of LLM Safety Judges","summary":"  Large Language Model (LLM) based judges form the underpinnings of key safety\nevaluation processes such as offline benchmarking, automated red-teaming, and\nonline guardrailing. This widespread requirement raises the crucial question:\ncan we trust the evaluations of these evaluators? In this paper, we highlight\ntwo critical challenges that are typically overlooked: (i) evaluations in the\nwild where factors like prompt sensitivity and distribution shifts can affect\nperformance and (ii) adversarial attacks that target the judge. We highlight\nthe importance of these through a study of commonly used safety judges, showing\nthat small changes such as the style of the model output can lead to jumps of\nup to 0.24 in the false negative rate on the same dataset, whereas adversarial\nattacks on the model generation can fool some judges into misclassifying 100%\nof harmful generations as safe ones. These findings reveal gaps in commonly\nused meta-evaluation benchmarks and weaknesses in the robustness of current LLM\njudges, indicating that low attack success under certain judges could create a\nfalse sense of security.\n","authors":["Francisco Eiras","Eliott Zemour","Eric Lin","Vaikkunth Mugunthan"],"pdf_url":"https://arxiv.org/pdf/2503.04474v1.pdf","comment":"Accepted to the ICBINB Workshop at ICLR'25"},{"id":"http://arxiv.org/abs/2503.04472v1","updated":"2025-03-06T14:23:06Z","published":"2025-03-06T14:23:06Z","title":"DAST: Difficulty-Adaptive Slow-Thinking for Large Reasoning Models","summary":"  Recent advancements in slow-thinking reasoning models have shown exceptional\nperformance in complex reasoning tasks. However, these models often exhibit\noverthinking-generating redundant reasoning steps for simple problems, leading\nto excessive computational resource usage. While current mitigation strategies\nuniformly reduce reasoning tokens, they risk degrading performance on\nchallenging tasks that require extended reasoning. This paper introduces\nDifficulty-Adaptive Slow-Thinking (DAST), a novel framework that enables models\nto autonomously adjust the length of Chain-of-Thought(CoT) based on problem\ndifficulty. We first propose a Token Length Budget (TLB) metric to quantify\ndifficulty, then leveraging length-aware reward shaping and length preference\noptimization to implement DAST. DAST penalizes overlong responses for simple\ntasks while incentivizing sufficient reasoning for complex problems.\nExperiments on diverse datasets and model scales demonstrate that DAST\neffectively mitigates overthinking (reducing token usage by over 30\\% on\naverage) while preserving reasoning accuracy on complex problems.\n","authors":["Yi Shen","Jian Zhang","Jieyun Huang","Shuming Shi","Wenjing Zhang","Jiangze Yan","Ning Wang","Kai Wang","Shiguo Lian"],"pdf_url":"https://arxiv.org/pdf/2503.04472v1.pdf","comment":"working in progress"},{"id":"http://arxiv.org/abs/2503.04469v1","updated":"2025-03-06T14:19:55Z","published":"2025-03-06T14:19:55Z","title":"An artificially intelligent magnetic resonance spectroscopy\n  quantification method: Comparison between QNet and LCModel on the cloud\n  computing platform CloudBrain-MRS","summary":"  Objctives: This work aimed to statistically compare the metabolite\nquantification of human brain magnetic resonance spectroscopy (MRS) between the\ndeep learning method QNet and the classical method LCModel through an\neasy-to-use intelligent cloud computing platform CloudBrain-MRS. Materials and\nMethods: In this retrospective study, two 3 T MRI scanners Philips Ingenia and\nAchieva collected 61 and 46 in vivo 1H magnetic resonance (MR) spectra of\nhealthy participants, respectively, from the brain region of pregenual anterior\ncingulate cortex from September to October 2021. The analyses of Bland-Altman,\nPearson correlation and reasonability were performed to assess the degree of\nagreement, linear correlation and reasonability between the two quantification\nmethods. Results: Fifteen healthy volunteers (12 females and 3 males, age\nrange: 21-35 years, mean age/standard deviation = 27.4/3.9 years) were\nrecruited. The analyses of Bland-Altman, Pearson correlation and reasonability\nshowed high to good consistency and very strong to moderate correlation between\nthe two methods for quantification of total N-acetylaspartate (tNAA), total\ncholine (tCho), and inositol (Ins) (relative half interval of limits of\nagreement = 3.04%, 9.3%, and 18.5%, respectively; Pearson correlation\ncoefficient r = 0.775, 0.927, and 0.469, respectively). In addition,\nquantification results of QNet are more likely to be closer to the previous\nreported average values than those of LCModel. Conclusion: There were high or\ngood degrees of consistency between the quantification results of QNet and\nLCModel for tNAA, tCho, and Ins, and QNet generally has more reasonable\nquantification than LCModel.\n","authors":["Meijin Lin","Lin Guo","Dicheng Chen","Jianshu Chen","Zhangren Tu","Xu Huang","Jianhua Wang","Ji Qi","Yuan Long","Zhiguo Huang","Di Guo","Xiaobo Qu","Haiwei Han"],"pdf_url":"https://arxiv.org/pdf/2503.04469v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04462v1","updated":"2025-03-06T14:13:59Z","published":"2025-03-06T14:13:59Z","title":"PALo: Learning Posture-Aware Locomotion for Quadruped Robots","summary":"  With the rapid development of embodied intelligence, locomotion control of\nquadruped robots on complex terrains has become a research hotspot. Unlike\ntraditional locomotion control approaches focusing solely on velocity tracking,\nwe pursue to balance the agility and robustness of quadruped robots on diverse\nand complex terrains. To this end, we propose an end-to-end deep reinforcement\nlearning framework for posture-aware locomotion named PALo, which manages to\nhandle simultaneous linear and angular velocity tracking and real-time\nadjustments of body height, pitch, and roll angles. In PALo, the locomotion\ncontrol problem is formulated as a partially observable Markov decision\nprocess, and an asymmetric actor-critic architecture is adopted to overcome the\nsim-to-real challenge. Further, by incorporating customized training curricula,\nPALo achieves agile posture-aware locomotion control in simulated environments\nand successfully transfers to real-world settings without fine-tuning, allowing\nreal-time control of the quadruped robot's locomotion and body posture across\nchallenging terrains. Through in-depth experimental analysis, we identify the\nkey components of PALo that contribute to its performance, further validating\nthe effectiveness of the proposed method. The results of this study provide new\npossibilities for the low-level locomotion control of quadruped robots in\nhigher dimensional command spaces and lay the foundation for future research on\nupper-level modules for embodied intelligence.\n","authors":["Xiangyu Miao","Jun Sun","Hang Lai","Xinpeng Di","Jiahang Cao","Yong Yu","Weinan Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.04462v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01684v2","updated":"2025-03-06T14:07:34Z","published":"2025-03-03T15:58:15Z","title":"An Efficient Learning Method to Connect Observables","summary":"  Constructing fast and accurate surrogate models is a key ingredient for\nmaking robust predictions in many topics. We introduce a new model, the\nMultiparameter Eigenvalue Problem (MEP) emulator. The new method connects\nemulators and can make predictions directly from observables to observables. We\npresent that the MEP emulator can be trained with data from Eigenvector\nContinuation (EC) and Parametric Matrix Model (PMM) emulators. A simple\nsimulation on a one-dimensional lattice confirms the performance of the MEP\nemulator. Using $^{28}$O as an example, we also demonstrate that the predictive\nprobability distribution of the target observables can be easily obtained\nthrough the new emulator.\n","authors":["Hang Yu","Takayuki Miyagi"],"pdf_url":"https://arxiv.org/pdf/2503.01684v2.pdf","comment":"5+2 pages, 4 figures, updated acknowledgment"},{"id":"http://arxiv.org/abs/2503.04453v1","updated":"2025-03-06T14:06:50Z","published":"2025-03-06T14:06:50Z","title":"Reproducibility Assessment of Magnetic Resonance Spectroscopy of\n  Pregenual Anterior Cingulate Cortex across Sessions and Vendors via the Cloud\n  Computing Platform CloudBrain-MRS","summary":"  Given the need to elucidate the mechanisms underlying illnesses and their\ntreatment, as well as the lack of harmonization of acquisition and\npost-processing protocols among different magnetic resonance system vendors,\nthis work is to determine if metabolite concentrations obtained from different\nsessions, machine models and even different vendors of 3 T scanners can be\nhighly reproducible and be pooled for diagnostic analysis, which is very\nvaluable for the research of rare diseases. Participants underwent magnetic\nresonance imaging (MRI) scanning once on two separate days within one week (one\nsession per day, each session including two proton magnetic resonance\nspectroscopy (1H-MRS) scans with no more than a 5-minute interval between scans\n(no off-bed activity)) on each machine. were analyzed for reliability of\nwithin- and between- sessions using the coefficient of variation (CV) and\nintraclass correlation coefficient (ICC), and for reproducibility of across the\nmachines using correlation coefficient. As for within- and between- session,\nall CV values for a group of all the first or second scans of a session, or for\na session were almost below 20%, and most of the ICCs for metabolites range\nfrom moderate (0.4-0.59) to excellent (0.75-1), indicating high data\nreliability. When it comes to the reproducibility across the three scanners,\nall Pearson correlation coefficients across the three machines approached 1\nwith most around 0.9, and majority demonstrated statistical significance\n(P<0.01). Additionally, the intra-vendor reproducibility was greater than the\ninter-vendor ones.\n","authors":["Runhan Chen","Meijin Lin","Jianshu Chen","Liangjie Lin","Jiazheng Wang","Xiaoqing Li","Jianhua Wang","Xu Huang","Ling Qian","Shaoxing Liu","Yuan Long","Di Guo","Xiaobo Qu","Haiwei Han"],"pdf_url":"https://arxiv.org/pdf/2503.04453v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04451v1","updated":"2025-03-06T14:06:20Z","published":"2025-03-06T14:06:20Z","title":"Privacy Preserving and Robust Aggregation for Cross-Silo Federated\n  Learning in Non-IID Settings","summary":"  Federated Averaging remains the most widely used aggregation strategy in\nfederated learning due to its simplicity and scalability. However, its\nperformance degrades significantly in non-IID data settings, where client\ndistributions are highly imbalanced or skewed. Additionally, it relies on\nclients transmitting metadata, specifically the number of training samples,\nwhich introduces privacy risks and may conflict with regulatory frameworks like\nthe European GDPR. In this paper, we propose a novel aggregation strategy that\naddresses these challenges by introducing class-aware gradient masking. Unlike\ntraditional approaches, our method relies solely on gradient updates,\neliminating the need for any additional client metadata, thereby enhancing\nprivacy protection. Furthermore, our approach validates and dynamically weights\nclient contributions based on class-specific importance, ensuring robustness\nagainst non-IID distributions, convergence prevention, and backdoor attacks.\nExtensive experiments on benchmark datasets demonstrate that our method not\nonly outperforms FedAvg and other widely accepted aggregation strategies in\nnon-IID settings but also preserves model integrity in adversarial scenarios.\nOur results establish the effectiveness of gradient masking as a practical and\nsecure solution for federated learning.\n","authors":["Marco Arazzi","Mert Cihangiroglu","Antonino Nocera"],"pdf_url":"https://arxiv.org/pdf/2503.04451v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04447v1","updated":"2025-03-06T14:02:28Z","published":"2025-03-06T14:02:28Z","title":"A Graph-Partitioning Based Continuous Optimization Approach to\n  Semi-supervised Clustering Problems","summary":"  Semi-supervised clustering is a basic problem in various applications. Most\nexisting methods require knowledge of the ideal cluster number, which is often\ndifficult to obtain in practice. Besides, satisfying the must-link constraints\nis another major challenge for these methods. In this work, we view the\nsemi-supervised clustering task as a partitioning problem on a graph associated\nwith the given dataset, where the similarity matrix includes a scaling\nparameter to reflect the must-link constraints. Utilizing a relaxation\ntechnique, we formulate the graph partitioning problem into a continuous\noptimization model that does not require the exact cluster number, but only an\noverestimate of it. We then propose a block coordinate descent algorithm to\nefficiently solve this model, and establish its convergence result. Based on\nthe obtained solution, we can construct the clusters that theoretically meet\nthe must-link constraints under mild assumptions. Furthermore, we verify the\neffectiveness and efficiency of our proposed method through comprehensive\nnumerical experiments.\n","authors":["Wei Liu","Xin Liu","Michael K. Ng","Zaikun Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.04447v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.08010v2","updated":"2025-03-06T14:01:48Z","published":"2024-02-12T19:18:50Z","title":"Which Frequencies do CNNs Need? Emergent Bottleneck Structure in Feature\n  Learning","summary":"  We describe the emergence of a Convolution Bottleneck (CBN) structure in\nCNNs, where the network uses its first few layers to transform the input\nrepresentation into a representation that is supported only along a few\nfrequencies and channels, before using the last few layers to map back to the\noutputs. We define the CBN rank, which describes the number and type of\nfrequencies that are kept inside the bottleneck, and partially prove that the\nparameter norm required to represent a function $f$ scales as depth times the\nCBN rank $f$. We also show that the parameter norm depends at next order on the\nregularity of $f$. We show that any network with almost optimal parameter norm\nwill exhibit a CBN structure in both the weights and - under the assumption\nthat the network is stable under large learning rate - the activations, which\nmotivates the common practice of down-sampling; and we verify that the CBN\nresults still hold with down-sampling. Finally we use the CBN structure to\ninterpret the functions learned by CNNs on a number of tasks.\n","authors":["Yuxiao Wen","Arthur Jacot"],"pdf_url":"https://arxiv.org/pdf/2402.08010v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.17573v2","updated":"2025-03-06T13:47:53Z","published":"2024-05-27T18:15:05Z","title":"Hamiltonian Mechanics of Feature Learning: Bottleneck Structure in Leaky\n  ResNets","summary":"  We study Leaky ResNets, which interpolate between ResNets and Fully-Connected\nnets depending on an 'effective depth' hyper-parameter $\\tilde{L}$. In the\ninfinite depth limit, we study 'representation geodesics' $A_{p}$: continuous\npaths in representation space (similar to NeuralODEs) from input $p=0$ to\noutput $p=1$ that minimize the parameter norm of the network. We give a\nLagrangian and Hamiltonian reformulation, which highlight the importance of two\nterms: a kinetic energy which favors small layer derivatives\n$\\partial_{p}A_{p}$ and a potential energy that favors low-dimensional\nrepresentations, as measured by the 'Cost of Identity'. The balance between\nthese two forces offers an intuitive understanding of feature learning in\nResNets. We leverage this intuition to explain the emergence of a bottleneck\nstructure, as observed in previous work: for large $\\tilde{L}$ the potential\nenergy dominates and leads to a separation of timescales, where the\nrepresentation jumps rapidly from the high dimensional inputs to a\nlow-dimensional representation, move slowly inside the space of low-dimensional\nrepresentations, before jumping back to the potentially high-dimensional\noutputs. Inspired by this phenomenon, we train with an adaptive layer step-size\nto adapt to the separation of timescales.\n","authors":["Arthur Jacot","Alexandre Kaiser"],"pdf_url":"https://arxiv.org/pdf/2405.17573v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.05664v2","updated":"2025-03-06T13:40:09Z","published":"2024-07-08T06:59:29Z","title":"How DNNs break the Curse of Dimensionality: Compositionality and\n  Symmetry Learning","summary":"  We show that deep neural networks (DNNs) can efficiently learn any\ncomposition of functions with bounded $F_{1}$-norm, which allows DNNs to break\nthe curse of dimensionality in ways that shallow networks cannot. More\nspecifically, we derive a generalization bound that combines a covering number\nargument for compositionality, and the $F_{1}$-norm (or the related Barron\nnorm) for large width adaptivity. We show that the global minimizer of the\nregularized loss of DNNs can fit for example the composition of two functions\n$f^{*}=h\\circ g$ from a small number of observations, assuming $g$ is\nsmooth/regular and reduces the dimensionality (e.g. $g$ could be the quotient\nmap of the symmetries of $f^{*}$), so that $h$ can be learned in spite of its\nlow regularity. The measures of regularity we consider is the Sobolev norm with\ndifferent levels of differentiability, which is well adapted to the $F_{1}$\nnorm. We compute scaling laws empirically and observe phase transitions\ndepending on whether $g$ or $h$ is harder to learn, as predicted by our theory.\n","authors":["Arthur Jacot","Seok Hoan Choi","Yuxiao Wen"],"pdf_url":"https://arxiv.org/pdf/2407.05664v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12261v3","updated":"2025-03-06T13:39:32Z","published":"2024-10-16T05:58:55Z","title":"CATCH: Channel-Aware multivariate Time Series Anomaly Detection via\n  Frequency Patching","summary":"  Anomaly detection in multivariate time series is challenging as heterogeneous\nsubsequence anomalies may occur. Reconstruction-based methods, which focus on\nlearning normal patterns in the frequency domain to detect diverse abnormal\nsubsequences, achieve promising results, while still falling short on capturing\nfine-grained frequency characteristics and channel correlations. To contend\nwith the limitations, we introduce CATCH, a framework based on frequency\npatching. We propose to patchify the frequency domain into frequency bands,\nwhich enhances its ability to capture fine-grained frequency characteristics.\nTo perceive appropriate channel correlations, we propose a Channel Fusion\nModule (CFM), which features a patch-wise mask generator and a masked-attention\nmechanism. Driven by a bi-level multi-objective optimization algorithm, the CFM\nis encouraged to iteratively discover appropriate patch-wise channel\ncorrelations, and to cluster relevant channels while isolating adverse effects\nfrom irrelevant channels. Extensive experiments on 10 real-world datasets and\n12 synthetic datasets demonstrate that CATCH achieves state-of-the-art\nperformance. We make our code and datasets available at\nhttps://github.com/decisionintelligence/CATCH.\n","authors":["Xingjian Wu","Xiangfei Qiu","Zhengyu Li","Yihang Wang","Jilin Hu","Chenjuan Guo","Hui Xiong","Bin Yang"],"pdf_url":"https://arxiv.org/pdf/2410.12261v3.pdf","comment":"Accepted by ICLR 2025"},{"id":"http://arxiv.org/abs/2503.04426v1","updated":"2025-03-06T13:35:59Z","published":"2025-03-06T13:35:59Z","title":"FORTALESA: Fault-Tolerant Reconfigurable Systolic Array for DNN\n  Inference","summary":"  The emergence of Deep Neural Networks (DNNs) in mission- and safety-critical\napplications brings their reliability to the front. High performance demands of\nDNNs require the use of specialized hardware accelerators. Systolic array\narchitecture is widely used in DNN accelerators due to its parallelism and\nregular structure. This work presents a run-time reconfigurable systolic array\narchitecture with three execution modes and four implementation options. All\nfour implementations are evaluated in terms of resource utilization,\nthroughput, and fault tolerance improvement. The proposed architecture is used\nfor reliability enhancement of DNN inference on systolic array through\nheterogeneous mapping of different network layers to different execution modes.\nThe approach is supported by a novel reliability assessment method based on\nfault propagation analysis. It is used for the exploration of the appropriate\nexecution mode-layer mapping for DNN inference. The proposed architecture\nefficiently protects registers and MAC units of systolic array PEs from\ntransient and permanent faults. The reconfigurability feature enables a speedup\nof up to $3\\times$, depending on layer vulnerability. Furthermore, it requires\n$6\\times$ less resources compared to static redundancy and $2.5\\times$ less\nresources compared to the previously proposed solution for transient faults.\n","authors":["Natalia Cherezova","Artur Jutman","Maksim Jenihhin"],"pdf_url":"https://arxiv.org/pdf/2503.04426v1.pdf","comment":"11 pages, 15 figures"},{"id":"http://arxiv.org/abs/2503.04424v1","updated":"2025-03-06T13:32:13Z","published":"2025-03-06T13:32:13Z","title":"Determinant Estimation under Memory Constraints and Neural Scaling Laws","summary":"  Calculating or accurately estimating log-determinants of large positive\nsemi-definite matrices is of fundamental importance in many machine learning\ntasks. While its cubic computational complexity can already be prohibitive, in\nmodern applications, even storing the matrices themselves can pose a memory\nbottleneck. To address this, we derive a novel hierarchical algorithm based on\nblock-wise computation of the LDL decomposition for large-scale log-determinant\ncalculation in memory-constrained settings. In extreme cases where matrices are\nhighly ill-conditioned, accurately computing the full matrix itself may be\ninfeasible. This is particularly relevant when considering kernel matrices at\nscale, including the empirical Neural Tangent Kernel (NTK) of neural networks\ntrained on large datasets. Under the assumption of neural scaling laws in the\ntest error, we show that the ratio of pseudo-determinants satisfies a power-law\nrelationship, allowing us to derive corresponding scaling laws. This enables\naccurate estimation of NTK log-determinants from a tiny fraction of the full\ndataset; in our experiments, this results in a $\\sim$100,000$\\times$ speedup\nwith improved accuracy over competing approximations. Using these techniques,\nwe successfully estimate log-determinants for dense matrices of extreme sizes,\nwhich were previously deemed intractable and inaccessible due to their enormous\nscale and computational demands.\n","authors":["Siavash Ameli","Chris van der Heide","Liam Hodgkinson","Fred Roosta","Michael W. Mahoney"],"pdf_url":"https://arxiv.org/pdf/2503.04424v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.07978v4","updated":"2025-03-06T13:29:24Z","published":"2023-11-14T08:10:14Z","title":"AfroBench: How Good are Large Language Models on African Languages?","summary":"  Large-scale multilingual evaluations, such as MEGA, often include only a\nhandful of African languages due to the scarcity of high-quality evaluation\ndata and the limited discoverability of existing African datasets. This lack of\nrepresentation hinders comprehensive LLM evaluation across a diverse range of\nlanguages and tasks. To address these challenges, we introduce AfroBench -- a\nmulti-task benchmark for evaluating the performance of LLMs across 64 African\nlanguages, 15 tasks and 22 datasets. AfroBench consists of nine natural\nlanguage understanding datasets, six text generation datasets, six knowledge\nand question answering tasks, and one mathematical reasoning task. We present\nresults comparing the performance of prompting LLMs to fine-tuned baselines\nbased on BERT and T5-style models. Our results suggest large gaps in\nperformance between high-resource languages, such as English, and African\nlanguages across most tasks; but performance also varies based on the\navailability of monolingual data resources. Our findings confirm that\nperformance on African languages continues to remain a hurdle for current LLMs,\nunderscoring the need for additional efforts to close this gap.\n  https://mcgill-nlp.github.io/AfroBench/\n","authors":["Jessica Ojo","Odunayo Ogundepo","Akintunde Oladipo","Kelechi Ogueji","Jimmy Lin","Pontus Stenetorp","David Ifeoluwa Adelani"],"pdf_url":"https://arxiv.org/pdf/2311.07978v4.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2503.04418v1","updated":"2025-03-06T13:21:38Z","published":"2025-03-06T13:21:38Z","title":"AOLO: Analysis and Optimization For Low-Carbon Oriented Wireless Large\n  Language Model Services","summary":"  Recent advancements in large language models (LLMs) have led to their\nwidespread adoption and large-scale deployment across various domains. However,\ntheir environmental impact, particularly during inference, has become a growing\nconcern due to their substantial energy consumption and carbon footprint.\nExisting research has focused on inference computation alone, overlooking the\nanalysis and optimization of carbon footprint in network-aided LLM service\nsystems. To address this gap, we propose AOLO, a framework for analysis and\noptimization for low-carbon oriented wireless LLM services. AOLO introduces a\ncomprehensive carbon footprint model that quantifies greenhouse gas emissions\nacross the entire LLM service chain, including computational inference and\nwireless communication. Furthermore, we formulate an optimization problem aimed\nat minimizing the overall carbon footprint, which is solved through joint\noptimization of inference outputs and transmit power under\nquality-of-experience and system performance constraints. To achieve this joint\noptimization, we leverage the energy efficiency of spiking neural networks\n(SNNs) by adopting SNN as the actor network and propose a low-carbon-oriented\noptimization algorithm, i.e., SNN-based deep reinforcement learning (SDRL).\nComprehensive simulations demonstrate that SDRL algorithm significantly reduces\noverall carbon footprint, achieving an 18.77% reduction compared to the\nbenchmark soft actor-critic, highlighting its potential for enabling more\nsustainable LLM inference services.\n","authors":["Xiaoqi Wang","Hongyang Du","Yuehong Gao","Dong In Kim"],"pdf_url":"https://arxiv.org/pdf/2503.04418v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04416v1","updated":"2025-03-06T13:18:37Z","published":"2025-03-06T13:18:37Z","title":"Learning Transformer-based World Models with Contrastive Predictive\n  Coding","summary":"  The DreamerV3 algorithm recently obtained remarkable performance across\ndiverse environment domains by learning an accurate world model based on\nRecurrent Neural Networks (RNNs). Following the success of model-based\nreinforcement learning algorithms and the rapid adoption of the Transformer\narchitecture for its superior training efficiency and favorable scaling\nproperties, recent works such as STORM have proposed replacing RNN-based world\nmodels with Transformer-based world models using masked self-attention.\nHowever, despite the improved training efficiency of these methods, their\nimpact on performance remains limited compared to the Dreamer algorithm,\nstruggling to learn competitive Transformer-based world models. In this work,\nwe show that the next state prediction objective adopted in previous approaches\nis insufficient to fully exploit the representation capabilities of\nTransformers. We propose to extend world model predictions to longer time\nhorizons by introducing TWISTER (Transformer-based World model wIth contraSTivE\nRepresentations), a world model using action-conditioned Contrastive Predictive\nCoding to learn high-level temporal feature representations and improve the\nagent performance. TWISTER achieves a human-normalized mean score of 162% on\nthe Atari 100k benchmark, setting a new record among state-of-the-art methods\nthat do not employ look-ahead search.\n","authors":["Maxime Burchi","Radu Timofte"],"pdf_url":"https://arxiv.org/pdf/2503.04416v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04406v1","updated":"2025-03-06T13:00:53Z","published":"2025-03-06T13:00:53Z","title":"Training-Free Graph Filtering via Multimodal Feature Refinement for\n  Extremely Fast Multimodal Recommendation","summary":"  Multimodal recommender systems improve the performance of canonical\nrecommender systems with no item features by utilizing diverse content types\nsuch as text, images, and videos, while alleviating inherent sparsity of\nuser-item interactions and accelerating user engagement. However, current\nneural network-based models often incur significant computational overhead due\nto the complex training process required to learn and integrate information\nfrom multiple modalities. To overcome this limitation, we propose\nMultiModal-Graph Filtering (MM-GF), a training-free method based on the notion\nof graph filtering (GF) for efficient and accurate multimodal recommendations.\nSpecifically, MM-GF first constructs multiple similarity graphs through\nnontrivial multimodal feature refinement such as robust scaling and vector\nshifting by addressing the heterogeneous characteristics across modalities.\nThen, MM-GF optimally fuses multimodal information using linear low-pass\nfilters across different modalities. Extensive experiments on real-world\nbenchmark datasets demonstrate that MM-GF not only improves recommendation\naccuracy by up to 13.35% compared to the best competitor but also dramatically\nreduces computational costs by achieving the runtime of less than 10 seconds.\n","authors":["Yu-Seung Roh","Joo-Young Kim","Jin-Duk Park","Won-Yong Shin"],"pdf_url":"https://arxiv.org/pdf/2503.04406v1.pdf","comment":"10 pages, 6 figures, 6 tables"},{"id":"http://arxiv.org/abs/2503.04404v1","updated":"2025-03-06T12:58:09Z","published":"2025-03-06T12:58:09Z","title":"Temporal Analysis of NetFlow Datasets for Network Intrusion Detection\n  Systems","summary":"  This paper investigates the temporal analysis of NetFlow datasets for machine\nlearning (ML)-based network intrusion detection systems (NIDS). Although many\nprevious studies have highlighted the critical role of temporal features, such\nas inter-packet arrival time and flow length/duration, in NIDS, the currently\navailable NetFlow datasets for NIDS lack these temporal features. This study\naddresses this gap by creating and making publicly available a set of NetFlow\ndatasets that incorporate these temporal features [1]. With these temporal\nfeatures, we provide a comprehensive temporal analysis of NetFlow datasets by\nexamining the distribution of various features over time and presenting\ntime-series representations of NetFlow features. This temporal analysis has not\nbeen previously provided in the existing literature. We also borrowed an idea\nfrom signal processing, time frequency analysis, and tested it to see how\ndifferent the time frequency signal presentations (TFSPs) are for various\nattacks. The results indicate that many attacks have unique patterns, which\ncould help ML models to identify them more easily.\n","authors":["Majed Luay","Siamak Layeghy","Seyedehfaezeh Hosseininoorbin","Mohanad Sarhan","Nour Moustafa","Marius Portmann"],"pdf_url":"https://arxiv.org/pdf/2503.04404v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04398v1","updated":"2025-03-06T12:52:22Z","published":"2025-03-06T12:52:22Z","title":"Speculative MoE: Communication Efficient Parallel MoE Inference with\n  Speculative Token and Expert Pre-scheduling","summary":"  MoE (Mixture of Experts) prevails as a neural architecture that can scale\nmodern transformer-based LLMs (Large Language Models) to unprecedented scales.\nNevertheless, large MoEs' great demands of computing power, memory capacity and\nmemory bandwidth make scalable serving a fundamental challenge and efficient\nparallel inference has become a requisite to attain adequate throughput under\nlatency constraints. DeepSpeed-MoE, one state-of-the-art MoE inference\nframework, adopts a 3D-parallel paradigm including EP (Expert Parallelism), TP\n(Tensor Parallel) and DP (Data Parallelism). However, our analysis shows\nDeepSpeed-MoE's inference efficiency is largely bottlenecked by EP, which is\nimplemented with costly all-to-all collectives to route token activation. Our\nwork aims to boost DeepSpeed-MoE by strategically reducing EP's communication\noverhead with a technique named Speculative MoE. Speculative MoE has two\nspeculative parallelization schemes, speculative token shuffling and\nspeculative expert grouping, which predict outstanding tokens' expert routing\npaths and pre-schedule tokens and experts across devices to losslessly trim\nEP's communication volume. Besides DeepSpeed-MoE, we also build Speculative MoE\ninto a prevailing MoE inference engine SGLang. Experiments show Speculative MoE\ncan significantly boost state-of-the-art MoE inference frameworks on fast\nhomogeneous and slow heterogeneous interconnects.\n","authors":["Yan Li","Pengfei Zheng","Shuang Chen","Zewei Xu","Yunfei Du","Zhengang Wang"],"pdf_url":"https://arxiv.org/pdf/2503.04398v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.13483v3","updated":"2025-03-06T12:51:49Z","published":"2025-01-23T08:57:02Z","title":"Robust Amortized Bayesian Inference with Self-Consistency Losses on\n  Unlabeled Data","summary":"  Neural amortized Bayesian inference (ABI) can solve probabilistic inverse\nproblems orders of magnitude faster than classical methods. However, neural ABI\nis not yet sufficiently robust for widespread and safe applicability. In\nparticular, when performing inference on observations outside of the scope of\nthe simulated data seen during training, for example, because of model\nmisspecification, the posterior approximations are likely to become highly\nbiased. Due to the bad pre-asymptotic behavior of current neural posterior\nestimators in the out-of-simulation regime, the resulting estimation biases\ncannot be fixed in acceptable time by just simulating more training data. In\nthis proof-of-concept paper, we propose a semi-supervised approach that enables\ntraining not only on (labeled) simulated data generated from the model, but\nalso on unlabeled data originating from any source, including real-world data.\nTo achieve the latter, we exploit Bayesian self-consistency properties that can\nbe transformed into strictly proper losses without requiring knowledge of true\nparameter values, that is, without requiring data labels. The results of our\ninitial experiments show remarkable improvements in the robustness of ABI on\nout-of-simulation data. Even if the observed data is far away from both labeled\nand unlabeled training data, inference remains highly accurate. If our findings\nalso generalize to other scenarios and model classes, we believe that our new\nmethod represents a major breakthrough in neural ABI.\n","authors":["Aayush Mishra","Daniel Habermann","Marvin Schmitt","Stefan T. Radev","Paul-Christian Bürkner"],"pdf_url":"https://arxiv.org/pdf/2501.13483v3.pdf","comment":"added acknowledgements"},{"id":"http://arxiv.org/abs/2503.03285v2","updated":"2025-03-06T12:42:37Z","published":"2025-03-05T09:12:16Z","title":"Enhancing Vietnamese VQA through Curriculum Learning on Raw and\n  Augmented Text Representations","summary":"  Visual Question Answering (VQA) is a multimodal task requiring reasoning\nacross textual and visual inputs, which becomes particularly challenging in\nlow-resource languages like Vietnamese due to linguistic variability and the\nlack of high-quality datasets. Traditional methods often rely heavily on\nextensive annotated datasets, computationally expensive pipelines, and large\npre-trained models, specifically in the domain of Vietnamese VQA, limiting\ntheir applicability in such scenarios. To address these limitations, we propose\na training framework that combines a paraphrase-based feature augmentation\nmodule with a dynamic curriculum learning strategy. Explicitly, augmented\nsamples are considered \"easy\" while raw samples are regarded as \"hard\". The\nframework then utilizes a mechanism that dynamically adjusts the ratio of easy\nto hard samples during training, progressively modifying the same dataset to\nincrease its difficulty level. By enabling gradual adaptation to task\ncomplexity, this approach helps the Vietnamese VQA model generalize well, thus\nimproving overall performance. Experimental results show consistent\nimprovements on the OpenViVQA dataset and mixed outcomes on the ViVQA dataset,\nhighlighting both the potential and challenges of our approach in advancing VQA\nfor Vietnamese language.\n","authors":["Khoi Anh Nguyen","Linh Yen Vu","Thang Dinh Duong","Thuan Nguyen Duong","Huy Thanh Nguyen","Vinh Quang Dinh"],"pdf_url":"https://arxiv.org/pdf/2503.03285v2.pdf","comment":"10 pages, 3 figures, AAAI-25 Workshop on Document Understanding and\n  Intelligence"},{"id":"http://arxiv.org/abs/2407.07918v2","updated":"2025-03-06T12:41:21Z","published":"2024-07-07T12:41:40Z","title":"Detecting new obfuscated malware variants: A lightweight and\n  interpretable machine learning approach","summary":"  Machine learning has been successfully applied in developing malware\ndetection systems, with a primary focus on accuracy, and increasing attention\nto reducing computational overhead and improving model interpretability.\nHowever, an important question remains underexplored: How well can machine\nlearning-based models detect entirely new forms of malware not present in the\ntraining data? In this study, we present a machine learning-based system for\ndetecting obfuscated malware that is not only highly accurate, lightweight and\ninterpretable, but also capable of successfully adapting to new types of\nmalware attacks. Our system is capable of detecting 15 malware subtypes despite\nbeing exclusively trained on one malware subtype, namely the Transponder from\nthe Spyware family. This system was built after training 15 distinct random\nforest-based models, each on a different malware subtype from the\nCIC-MalMem-2022 dataset. These models were evaluated against the entire range\nof malware subtypes, including all unseen malware subtypes. To maintain the\nsystem's streamlined nature, training was confined to the top five most\nimportant features, which also enhanced interpretability. The\nTransponder-focused model exhibited high accuracy, exceeding 99.8%, with an\naverage processing speed of 5.7 microseconds per file. We also illustrate how\nthe Shapley additive explanations technique can facilitate the interpretation\nof the model predictions. Our research contributes to advancing malware\ndetection methodologies, pioneering the feasibility of detecting obfuscated\nmalware by exclusively training a model on a single or a few carefully selected\nmalware subtypes and applying it to detect unseen subtypes.\n","authors":["Oladipo A. Madamidola","Felix Ngobigha","Adnane Ez-zizi"],"pdf_url":"https://arxiv.org/pdf/2407.07918v2.pdf","comment":"30 pages (excluding Appendix), 5 figures and 5 tables. Now published\n  in Intelligent Systems with Applications\n  (https://doi.org/10.1016/j.iswa.2024.200472)"},{"id":"http://arxiv.org/abs/2503.04386v1","updated":"2025-03-06T12:37:55Z","published":"2025-03-06T12:37:55Z","title":"Time-varying Factor Augmented Vector Autoregression with Grouped Sparse\n  Autoencoder","summary":"  Recent economic events, including the global financial crisis and COVID-19\npandemic, have exposed limitations in linear Factor Augmented Vector\nAutoregressive (FAVAR) models for forecasting and structural analysis.\nNonlinear dimension techniques, particularly autoencoders, have emerged as\npromising alternatives in a FAVAR framework, but challenges remain in\nidentifiability, interpretability, and integration with traditional nonlinear\ntime series methods. We address these challenges through two contributions.\nFirst, we introduce a Grouped Sparse autoencoder that employs the\nSpike-and-Slab Lasso prior, with parameters under this prior being shared\nacross variables of the same economic category, thereby achieving\nsemi-identifiability and enhancing model interpretability. Second, we\nincorporate time-varying parameters into the VAR component to better capture\nevolving economic dynamics. Our empirical application to the US economy\ndemonstrates that the Grouped Sparse autoencoder produces more interpretable\nfactors through its parsimonious structure; and its combination with\ntime-varying parameter VAR shows superior performance in both point and density\nforecasting. Impulse response analysis reveals that monetary policy shocks\nduring recessions generate more moderate responses with higher uncertainty\ncompared to expansionary periods.\n","authors":["Yiyong Luo","Brooks Paige","Jim Griffin"],"pdf_url":"https://arxiv.org/pdf/2503.04386v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.07527v2","updated":"2025-03-06T12:34:23Z","published":"2025-02-11T13:08:03Z","title":"Nature Language Model: Deciphering the Language of Nature for Scientific\n  Discovery","summary":"  Foundation models have revolutionized natural language processing and\nartificial intelligence, significantly enhancing how machines comprehend and\ngenerate human languages. Inspired by the success of these foundation models,\nresearchers have developed foundation models for individual scientific domains,\nincluding small molecules, materials, proteins, DNA, RNA and even cells.\nHowever, these models are typically trained in isolation, lacking the ability\nto integrate across different scientific domains. Recognizing that entities\nwithin these domains can all be represented as sequences, which together form\nthe \"language of nature\", we introduce Nature Language Model (NatureLM), a\nsequence-based science foundation model designed for scientific discovery.\nPre-trained with data from multiple scientific domains, NatureLM offers a\nunified, versatile model that enables various applications including: (i)\ngenerating and optimizing small molecules, proteins, RNA, and materials using\ntext instructions; (ii) cross-domain generation/design, such as\nprotein-to-molecule and protein-to-RNA generation; and (iii) top performance\nacross different domains, matching or surpassing state-of-the-art specialist\nmodels. NatureLM offers a promising generalist approach for various scientific\ntasks, including drug discovery (hit generation/optimization, ADMET\noptimization, synthesis), novel material design, and the development of\ntherapeutic proteins or nucleotides. We have developed NatureLM models in\ndifferent sizes (1 billion, 8 billion, and 46.7 billion parameters) and\nobserved a clear improvement in performance as the model size increases.\n","authors":["Yingce Xia","Peiran Jin","Shufang Xie","Liang He","Chuan Cao","Renqian Luo","Guoqing Liu","Yue Wang","Zequn Liu","Yuan-Jyue Chen","Zekun Guo","Yeqi Bai","Pan Deng","Yaosen Min","Ziheng Lu","Hongxia Hao","Han Yang","Jielan Li","Chang Liu","Jia Zhang","Jianwei Zhu","Ran Bi","Kehan Wu","Wei Zhang","Kaiyuan Gao","Qizhi Pei","Qian Wang","Xixian Liu","Yanting Li","Houtian Zhu","Yeqing Lu","Mingqian Ma","Zun Wang","Tian Xie","Krzysztof Maziarz","Marwin Segler","Zhao Yang","Zilong Chen","Yu Shi","Shuxin Zheng","Lijun Wu","Chen Hu","Peggy Dai","Tie-Yan Liu","Haiguang Liu","Tao Qin"],"pdf_url":"https://arxiv.org/pdf/2502.07527v2.pdf","comment":"93 pages"},{"id":"http://arxiv.org/abs/2503.04378v1","updated":"2025-03-06T12:30:24Z","published":"2025-03-06T12:30:24Z","title":"Dedicated Feedback and Edit Models Empower Inference-Time Scaling for\n  Open-Ended General-Domain Tasks","summary":"  Inference-Time Scaling has been critical to the success of recent models such\nas OpenAI o1 and DeepSeek R1. However, many techniques used to train models for\ninference-time scaling require tasks to have answers that can be verified,\nlimiting their application to domains such as math, coding and logical\nreasoning. We take inspiration from how humans make first attempts, ask for\ndetailed feedback from others and make improvements based on such feedback\nacross a wide spectrum of open-ended endeavors. To this end, we collect data\nfor and train dedicated Feedback and Edit Models that are capable of performing\ninference-time scaling for open-ended general-domain tasks. In our setup, one\nmodel generates an initial response, which are given feedback by a second\nmodel, that are then used by a third model to edit the response. We show that\nperformance on Arena Hard, a benchmark strongly predictive of Chatbot Arena Elo\ncan be boosted by scaling the number of initial response drafts, effective\nfeedback and edited responses. When scaled optimally, our setup based on 70B\nmodels from the Llama 3 family can reach SoTA performance on Arena Hard at 92.7\nas of 5 Mar 2025, surpassing OpenAI o1-preview-2024-09-12 with 90.4 and\nDeepSeek R1 with 92.3.\n","authors":["Zhilin Wang","Jiaqi Zeng","Olivier Delalleau","Daniel Egert","Ellie Evans","Hoo-Chang Shin","Felipe Soares","Yi Dong","Oleksii Kuchaiev"],"pdf_url":"https://arxiv.org/pdf/2503.04378v1.pdf","comment":"22 pages, 2 figures"},{"id":"http://arxiv.org/abs/2503.04377v1","updated":"2025-03-06T12:28:59Z","published":"2025-03-06T12:28:59Z","title":"How can representation dimension dominate structurally pruned LLMs?","summary":"  Pruning assumes a subnetwork exists in the original deep neural network,\nwhich can achieve comparative model performance with less computation than the\noriginal. However, it is unclear how the model performance varies with the\ndifferent subnetwork extractions. In this paper, we choose the representation\ndimension (or embedding dimension, model dimension, the dimension of the\nresidual stream in the relevant literature) as the entry point to this issue.\nWe investigate the linear transformations in the LLM transformer blocks and\nconsider a specific structured pruning approach, SliceGPT, to extract the\nsubnetworks of different representation dimensions. We mechanistically analyse\nthe activation flow during the model forward passes, and find the\nrepresentation dimension dominates the linear transformations, model\npredictions, and, finally, the model performance. Explicit analytical relations\nare given to calculate the pruned model performance (perplexity and accuracy)\nwithout actual evaluation, and are empirically validated with\nLlama-3-8B-Instruct and Phi-3-mini-4k-Instruct.\n","authors":["Mingxue Xu","Lisa Alazraki","Danilo P. Mandic"],"pdf_url":"https://arxiv.org/pdf/2503.04377v1.pdf","comment":"ICLR 2025 Workshop on Sparsity in LLMs (SLLM)"},{"id":"http://arxiv.org/abs/2502.16532v2","updated":"2025-03-06T12:19:59Z","published":"2025-02-23T10:48:11Z","title":"Deep unrolling for learning optimal spatially varying regularisation\n  parameters for Total Generalised Variation","summary":"  We extend a recently introduced deep unrolling framework for learning\nspatially varying regularisation parameters in inverse imaging problems to the\ncase of Total Generalised Variation (TGV). The framework combines a deep\nconvolutional neural network (CNN) inferring the two spatially varying TGV\nparameters with an unrolled algorithmic scheme that solves the corresponding\nvariational problem. The two subnetworks are jointly trained end-to-end in a\nsupervised fashion and as such the CNN learns to compute those parameters that\ndrive the reconstructed images as close to the ground truth as possible.\nNumerical results in image denoising and MRI reconstruction show a significant\nqualitative and quantitative improvement compared to the best TGV scalar\nparameter case as well as to other approaches employing spatially varying\nparameters computed by unsupervised methods. We also observe that the inferred\nspatially varying parameter maps have a consistent structure near the image\nedges, asking for further theoretical investigations. In particular, the\nparameter that weighs the first-order TGV term has a triple-edge structure with\nalternating high-low-high values whereas the one that weighs the second-order\nterm attains small values in a large neighbourhood around the edges.\n","authors":["Thanh Trung Vu","Andreas Kofler","Kostas Papafitsoros"],"pdf_url":"https://arxiv.org/pdf/2502.16532v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04370v1","updated":"2025-03-06T12:15:56Z","published":"2025-03-06T12:15:56Z","title":"FILM: Framework for Imbalanced Learning Machines based on a new unbiased\n  performance measure and a new ensemble-based technique","summary":"  This research addresses the challenges of handling unbalanced datasets for\nbinary classification tasks. In such scenarios, standard evaluation metrics are\noften biased by the disproportionate representation of the minority class.\nConducting experiments across seven datasets, we uncovered inconsistencies in\nevaluation metrics when determining the model that outperforms others for each\nbinary classification problem. This justifies the need for a metric that\nprovides a more consistent and unbiased evaluation across unbalanced datasets,\nthereby supporting robust model selection. To mitigate this problem, we propose\na novel metric, the Unbiased Integration Coefficients (UIC), which exhibits\nsignificantly reduced bias ($p < 10^{-4}$) towards the minority class compared\nto conventional metrics. The UIC is constructed by aggregating existing metrics\nwhile penalising those more prone to imbalance. In addition, we introduce the\nIdentical Partitions for Imbalance Problems (IPIP) algorithm for imbalanced ML\nproblems, an ensemble-based approach. Our experimental results show that IPIP\noutperforms other baseline imbalance-aware approaches using Random Forest and\nLogistic Regression models in three out of seven datasets as assessed by the\nUIC metric, demonstrating its effectiveness in addressing imbalanced data\nchallenges in binary classification tasks. This new framework for dealing with\nimbalanced datasets is materialized in the FILM (Framework for Imbalanced\nLearning Machines) R Package, accessible at https://github.com/antoniogt/FILM.\n","authors":["Antonio Guillén-Teruel","Marcos Caracena","Jose A. Pardo","Fernando de-la-Gándara","José Palma","Juan A. Botía"],"pdf_url":"https://arxiv.org/pdf/2503.04370v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01257v2","updated":"2025-03-06T12:13:14Z","published":"2024-10-02T06:05:52Z","title":"HelpSteer2-Preference: Complementing Ratings with Preferences","summary":"  Reward models are critical for aligning models to follow instructions, and\nare typically trained following one of two popular paradigms: Bradley-Terry\nstyle or Regression style. However, there is a lack of evidence that either\napproach is better than the other, when adequately matched for data. This is\nprimarily because these approaches require data collected in different (but\nincompatible) formats, meaning that adequately matched data is not available in\nexisting public datasets. To tackle this problem, we release preference\nannotations (designed for Bradley-Terry training) to complement existing\nratings (designed for Regression style training) in the HelpSteer2 dataset. To\nimprove data interpretability, preference annotations are accompanied with\nhuman-written justifications. Using this data, we conduct the first\nhead-to-head comparison of Bradley-Terry and Regression models when adequately\nmatched for data. Based on insights derived from such a comparison, we propose\na novel approach to combine Bradley-Terry and Regression reward modeling. A\nLlama-3.1-70B-Instruct model tuned with this approach scores 94.1 on\nRewardBench, emerging top of more than 140 reward models as of 1 Oct 2024. This\nreward model can then be used with REINFORCE algorithm (RLHF) to align an\nInstruct model to reach 85.0 on Arena Hard, which is No. 1 as of 1 Oct 2024. We\nopen-source this dataset (CC-BY-4.0 license) at\nhttps://huggingface.co/datasets/nvidia/HelpSteer2#preferences-new -- 1-oct-2024\nand openly release the trained Reward and Instruct models at\nhttps://huggingface.co/nvidia/Llama-3.1-Nemotron-70B-Reward and\nhttps://huggingface.co/nvidia/Llama-3.1-Nemotron-70B-Instruct\n","authors":["Zhilin Wang","Alexander Bukharin","Olivier Delalleau","Daniel Egert","Gerald Shen","Jiaqi Zeng","Oleksii Kuchaiev","Yi Dong"],"pdf_url":"https://arxiv.org/pdf/2410.01257v2.pdf","comment":"Accepted to ICLR 2025; 28 pages, 3 figures"},{"id":"http://arxiv.org/abs/2503.04363v1","updated":"2025-03-06T12:06:54Z","published":"2025-03-06T12:06:54Z","title":"Causally Reliable Concept Bottleneck Models","summary":"  Concept-based models are an emerging paradigm in deep learning that\nconstrains the inference process to operate through human-interpretable\nconcepts, facilitating explainability and human interaction. However, these\narchitectures, on par with popular opaque neural models, fail to account for\nthe true causal mechanisms underlying the target phenomena represented in the\ndata. This hampers their ability to support causal reasoning tasks, limits\nout-of-distribution generalization, and hinders the implementation of fairness\nconstraints. To overcome these issues, we propose \\emph{Causally reliable\nConcept Bottleneck Models} (C$^2$BMs), a class of concept-based architectures\nthat enforce reasoning through a bottleneck of concepts structured according to\na model of the real-world causal mechanisms. We also introduce a pipeline to\nautomatically learn this structure from observational data and\n\\emph{unstructured} background knowledge (e.g., scientific literature).\nExperimental evidence suggest that C$^2$BM are more interpretable, causally\nreliable, and improve responsiveness to interventions w.r.t. standard opaque\nand concept-based models, while maintaining their accuracy.\n","authors":["Giovanni De Felice","Arianna Casanova Flores","Francesco De Santis","Silvia Santini","Johannes Schneider","Pietro Barbiero","Alberto Termine"],"pdf_url":"https://arxiv.org/pdf/2503.04363v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04362v1","updated":"2025-03-06T12:04:56Z","published":"2025-03-06T12:04:56Z","title":"A Generalist Cross-Domain Molecular Learning Framework for\n  Structure-Based Drug Discovery","summary":"  Structure-based drug discovery (SBDD) is a systematic scientific process that\ndevelops new drugs by leveraging the detailed physical structure of the target\nprotein. Recent advancements in pre-trained models for biomolecules have\ndemonstrated remarkable success across various biochemical applications,\nincluding drug discovery and protein engineering. However, in most approaches,\nthe pre-trained models primarily focus on the characteristics of either small\nmolecules or proteins, without delving into their binding interactions which\nare essential cross-domain relationships pivotal to SBDD. To fill this gap, we\npropose a general-purpose foundation model named BIT (an abbreviation for\nBiomolecular Interaction Transformer), which is capable of encoding a range of\nbiochemical entities, including small molecules, proteins, and protein-ligand\ncomplexes, as well as various data formats, encompassing both 2D and 3D\nstructures. Specifically, we introduce Mixture-of-Domain-Experts (MoDE) to\nhandle the biomolecules from diverse biochemical domains and\nMixture-of-Structure-Experts (MoSE) to capture positional dependencies in the\nmolecular structures. The proposed mixture-of-experts approach enables BIT to\nachieve both deep fusion and domain-specific encoding, effectively capturing\nfine-grained molecular interactions within protein-ligand complexes. Then, we\nperform cross-domain pre-training on the shared Transformer backbone via\nseveral unified self-supervised denoising tasks. Experimental results on\nvarious benchmarks demonstrate that BIT achieves exceptional performance in\ndownstream tasks, including binding affinity prediction, structure-based\nvirtual screening, and molecular property prediction.\n","authors":["Yiheng Zhu","Mingyang Li","Junlong Liu","Kun Fu","Jiansheng Wu","Qiuyi Li","Mingze Yin","Jieping Ye","Jian Wu","Zheng Wang"],"pdf_url":"https://arxiv.org/pdf/2503.04362v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04358v1","updated":"2025-03-06T12:01:41Z","published":"2025-03-06T12:01:41Z","title":"Learning Causal Response Representations through Direct Effect Analysis","summary":"  We propose a novel approach for learning causal response representations. Our\nmethod aims to extract directions in which a multidimensional outcome is most\ndirectly caused by a treatment variable. By bridging conditional independence\ntesting with causal representation learning, we formulate an optimisation\nproblem that maximises the evidence against conditional independence between\nthe treatment and outcome, given a conditioning set. This formulation employs\nflexible regression models tailored to specific applications, creating a\nversatile framework. The problem is addressed through a generalised eigenvalue\ndecomposition. We show that, under mild assumptions, the distribution of the\nlargest eigenvalue can be bounded by a known $F$-distribution, enabling\ntestable conditional independence. We also provide theoretical guarantees for\nthe optimality of the learned representation in terms of signal-to-noise ratio\nand Fisher information maximisation. Finally, we demonstrate the empirical\neffectiveness of our approach in simulation and real-world experiments. Our\nresults underscore the utility of this framework in uncovering direct causal\neffects within complex, multivariate settings.\n","authors":["Homer Durand","Gherardo Varando","Gustau Camps-Valls"],"pdf_url":"https://arxiv.org/pdf/2503.04358v1.pdf","comment":"32 pages, 15 figures, stat.ML"},{"id":"http://arxiv.org/abs/2503.04357v1","updated":"2025-03-06T12:01:20Z","published":"2025-03-06T12:01:20Z","title":"scDD: Latent Codes Based scRNA-seq Dataset Distillation with Foundation\n  Model Knowledge","summary":"  Single-cell RNA sequencing (scRNA-seq) technology has profiled hundreds of\nmillions of human cells across organs, diseases, development and perturbations\nto date. However, the high-dimensional sparsity, batch effect noise, category\nimbalance, and ever-increasing data scale of the original sequencing data pose\nsignificant challenges for multi-center knowledge transfer, data fusion, and\ncross-validation between scRNA-seq datasets. To address these barriers, (1) we\nfirst propose a latent codes-based scRNA-seq dataset distillation framework\nnamed scDD, which transfers and distills foundation model knowledge and\noriginal dataset information into a compact latent space and generates\nsynthetic scRNA-seq dataset by a generator to replace the original dataset.\nThen, (2) we propose a single-step conditional diffusion generator named SCDG,\nwhich perform single-step gradient back-propagation to help scDD optimize\ndistillation quality and avoid gradient decay caused by multi-step\nback-propagation. Meanwhile, SCDG ensures the scRNA-seq data characteristics\nand inter-class discriminability of the synthetic dataset through flexible\nconditional control and generation quality assurance. Finally, we propose a\ncomprehensive benchmark to evaluate the performance of scRNA-seq dataset\ndistillation in different data analysis tasks. It is validated that our\nproposed method can achieve 7.61% absolute and 15.70% relative improvement over\nprevious state-of-the-art methods on average task.\n","authors":["Zhen Yu","Jianan Han","Yang Liu","Qingchao Chen"],"pdf_url":"https://arxiv.org/pdf/2503.04357v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04350v1","updated":"2025-03-06T11:46:07Z","published":"2025-03-06T11:46:07Z","title":"EDCA -- An Evolutionary Data-Centric AutoML Framework for Efficient\n  Pipelines","summary":"  Automated Machine Learning (AutoML) gained popularity due to the increased\ndemand for Machine Learning (ML) specialists, allowing them to apply ML\ntechniques effortlessly and quickly. AutoML implementations use optimisation\nmethods to identify the most effective ML solution for a given dataset, aiming\nto improve one or more predefined metrics. However, most implementations focus\non model selection and hyperparameter tuning. Despite being an important factor\nin obtaining high-performance ML systems, data quality is usually an overlooked\npart of AutoML and continues to be a manual and time-consuming task. This work\npresents EDCA, an Evolutionary Data Centric AutoML framework. In addition to\nthe traditional tasks such as selecting the best models and hyperparameters,\nEDCA enhances the given data by optimising data processing tasks such as data\nreduction and cleaning according to the problems' needs. All these steps create\nan ML pipeline that is optimised by an evolutionary algorithm. To assess its\neffectiveness, EDCA was compared to FLAML and TPOT, two frameworks at the top\nof the AutoML benchmarks. The frameworks were evaluated in the same conditions\nusing datasets from AMLB classification benchmarks. EDCA achieved statistically\nsimilar results in performance to FLAML and TPOT but used significantly less\ndata to train the final solutions. Moreover, EDCA experimental results reveal\nthat a good performance can be achieved using less data and efficient ML\nalgorithm aspects that align with Green AutoML guidelines\n","authors":["Joana Simões","João Correia"],"pdf_url":"https://arxiv.org/pdf/2503.04350v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04347v1","updated":"2025-03-06T11:43:30Z","published":"2025-03-06T11:43:30Z","title":"Large Language Models for Zero-shot Inference of Causal Structures in\n  Biology","summary":"  Genes, proteins and other biological entities influence one another via\ncausal molecular networks. Causal relationships in such networks are mediated\nby complex and diverse mechanisms, through latent variables, and are often\nspecific to cellular context. It remains challenging to characterise such\nnetworks in practice. Here, we present a novel framework to evaluate large\nlanguage models (LLMs) for zero-shot inference of causal relationships in\nbiology. In particular, we systematically evaluate causal claims obtained from\nan LLM using real-world interventional data. This is done over one hundred\nvariables and thousands of causal hypotheses. Furthermore, we consider several\nprompting and retrieval-augmentation strategies, including large, and\npotentially conflicting, collections of scientific articles. Our results show\nthat with tailored augmentation and prompting, even relatively small LLMs can\ncapture meaningful aspects of causal structure in biological systems. This\nsupports the notion that LLMs could act as orchestration tools in biological\ndiscovery, by helping to distil current knowledge in ways amenable to\ndownstream analysis. Our approach to assessing LLMs with respect to\nexperimental data is relevant for a broad range of problems at the intersection\nof causal learning, LLMs and scientific discovery.\n","authors":["Izzy Newsham","Luka Kovačević","Richard Moulange","Nan Rosemary Ke","Sach Mukherjee"],"pdf_url":"https://arxiv.org/pdf/2503.04347v1.pdf","comment":"ICLR 2025 Workshop on Machine Learning for Genomics Explorations"},{"id":"http://arxiv.org/abs/2503.04342v1","updated":"2025-03-06T11:39:07Z","published":"2025-03-06T11:39:07Z","title":"TRANSIT your events into a new mass: Fast background interpolation for\n  weakly-supervised anomaly searches","summary":"  We introduce a new model for conditional and continuous data morphing called\nTRansport Adversarial Network for Smooth InTerpolation (TRANSIT). We apply it\nto create a background data template for weakly-supervised searches at the LHC.\nThe method smoothly transforms sideband events to match signal region mass\ndistributions. We demonstrate the performance of TRANSIT using the LHC Olympics\nR\\&D dataset. The model captures non-linear mass correlations of features and\nproduces a template that offers a competitive anomaly sensitivity compared to\nstate-of-the-art transport-based template generators. Moreover, the\ncomputational training time required for TRANSIT is an order of magnitude lower\nthan that of competing deep learning methods. This makes it ideal for analyses\nthat iterate over many signal regions and signal models. Unlike generative\nmodels, which must learn a full probability density distribution, i.e., the\ncorrelations between all the variables, the proposed transport model only has\nto learn a smooth conditional shift of the distribution. This allows for a\nsimpler, more efficient residual architecture, enabling mass uncorrelated\nfeatures to pass the network unchanged while the mass correlated features are\nadjusted accordingly. Furthermore, we show that the latent space of the model\nprovides a set of mass decorrelated features useful for anomaly detection\nwithout background sculpting.\n","authors":["Ivan Oleksiyuk","Svyatoslav Voloshynovskiy","Tobias Golling"],"pdf_url":"https://arxiv.org/pdf/2503.04342v1.pdf","comment":"34 pages, 14 figures"},{"id":"http://arxiv.org/abs/2401.13898v2","updated":"2025-03-06T11:38:00Z","published":"2024-01-25T02:25:23Z","title":"Cross-Modal Prototype based Multimodal Federated Learning under Severely\n  Missing Modality","summary":"  Multimodal federated learning (MFL) has emerged as a decentralized machine\nlearning paradigm, allowing multiple clients with different modalities to\ncollaborate on training a global model across diverse data sources without\nsharing their private data. However, challenges, such as data heterogeneity and\nseverely missing modalities, pose crucial hindrances to the robustness of MFL,\nsignificantly impacting the performance of global model. The occurrence of\nmissing modalities in real-world applications, such as autonomous driving,\noften arises from factors like sensor failures, leading knowledge gaps during\nthe training process. Specifically, the absence of a modality introduces\nmisalignment during the local training phase, stemming from zero-filling in the\ncase of clients with missing modalities. Consequently, achieving robust\ngeneralization in global model becomes imperative, especially when dealing with\nclients that have incomplete data. In this paper, we propose\n$\\textbf{Multimodal Federated Cross Prototype Learning (MFCPL)}$, a novel\napproach for MFL under severely missing modalities. Our MFCPL leverages the\ncomplete prototypes to provide diverse modality knowledge in modality-shared\nlevel with the cross-modal regularization and modality-specific level with\ncross-modal contrastive mechanism. Additionally, our approach introduces the\ncross-modal alignment to provide regularization for modality-specific features,\nthereby enhancing the overall performance, particularly in scenarios involving\nseverely missing modalities. Through extensive experiments on three multimodal\ndatasets, we demonstrate the effectiveness of MFCPL in mitigating the\nchallenges of data heterogeneity and severely missing modalities while\nimproving the overall performance and robustness of MFL.\n","authors":["Huy Q. Le","Chu Myaet Thwal","Yu Qiao","Ye Lin Tun","Minh N. H. Nguyen","Eui-Nam Huh","Choong Seon Hong"],"pdf_url":"https://arxiv.org/pdf/2401.13898v2.pdf","comment":"14 pages, 8 figures, 11 tables"},{"id":"http://arxiv.org/abs/2401.12113v2","updated":"2025-03-06T11:33:28Z","published":"2024-01-22T16:51:01Z","title":"Extracting Formulae in Many-Valued Logic from Deep Neural Networks","summary":"  We propose a new perspective on deep ReLU networks, namely as circuit\ncounterparts of Lukasiewicz infinite-valued logic -- a many-valued (MV)\ngeneralization of Boolean logic. An algorithm for extracting formulae in MV\nlogic from deep ReLU networks is presented. As the algorithm applies to\nnetworks with general, in particular also real-valued, weights, it can be used\nto extract logical formulae from deep ReLU networks trained on data.\n","authors":["Yani Zhang","Helmut Bölcskei"],"pdf_url":"https://arxiv.org/pdf/2401.12113v2.pdf","comment":"Signicant extension of the previous version"},{"id":"http://arxiv.org/abs/2503.04332v1","updated":"2025-03-06T11:30:32Z","published":"2025-03-06T11:30:32Z","title":"The Challenge of Identifying the Origin of Black-Box Large Language\n  Models","summary":"  The tremendous commercial potential of large language models (LLMs) has\nheightened concerns about their unauthorized use. Third parties can customize\nLLMs through fine-tuning and offer only black-box API access, effectively\nconcealing unauthorized usage and complicating external auditing processes.\nThis practice not only exacerbates unfair competition, but also violates\nlicensing agreements. In response, identifying the origin of black-box LLMs is\nan intrinsic solution to this issue. In this paper, we first reveal the\nlimitations of state-of-the-art passive and proactive identification methods\nwith experiments on 30 LLMs and two real-world black-box APIs. Then, we propose\nthe proactive technique, PlugAE, which optimizes adversarial token embeddings\nin a continuous space and proactively plugs them into the LLM for tracing and\nidentification. The experiments show that PlugAE can achieve substantial\nimprovement in identifying fine-tuned derivatives. We further advocate for\nlegal frameworks and regulations to better address the challenges posed by the\nunauthorized use of LLMs.\n","authors":["Ziqing Yang","Yixin Wu","Yun Shen","Wei Dai","Michael Backes","Yang Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.04332v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.00390v2","updated":"2025-03-06T11:21:39Z","published":"2024-03-30T15:03:52Z","title":"Learning truly monotone operators with applications to nonlinear inverse\n  problems","summary":"  This article introduces a novel approach to learning monotone neural networks\nthrough a newly defined penalization loss. The proposed method is particularly\neffective in solving classes of variational problems, specifically monotone\ninclusion problems, commonly encountered in image processing tasks. The\nForward-Backward-Forward (FBF) algorithm is employed to address these problems,\noffering a solution even when the Lipschitz constant of the neural network is\nunknown. Notably, the FBF algorithm provides convergence guarantees under the\ncondition that the learned operator is monotone. Building on plug-and-play\nmethodologies, our objective is to apply these newly learned operators to\nsolving non-linear inverse problems. To achieve this, we initially formulate\nthe problem as a variational inclusion problem. Subsequently, we train a\nmonotone neural network to approximate an operator that may not inherently be\nmonotone. Leveraging the FBF algorithm, we then show simulation examples where\nthe non-linear inverse problem is successfully solved.\n","authors":["Younes Belkouchi","Jean-Christophe Pesquet","Audrey Repetti","Hugues Talbot"],"pdf_url":"https://arxiv.org/pdf/2404.00390v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.05714v4","updated":"2025-03-06T11:20:32Z","published":"2024-06-09T10:12:08Z","title":"A conversion theorem and minimax optimality for continuum contextual\n  bandits","summary":"  We study the contextual continuum bandits problem, where the learner\nsequentially receives a side information vector and has to choose an action in\na convex set, minimizing a function associated with the context. The goal is to\nminimize all the underlying functions for the received contexts, leading to the\ncontextual notion of regret, which is stronger than the standard static regret.\nAssuming that the objective functions are $\\gamma$-H\\\"older with respect to the\ncontexts, $0<\\gamma\\le 1,$ we demonstrate that any algorithm achieving a\nsub-linear static regret can be extended to achieve a sub-linear contextual\nregret. We prove a static-to-contextual regret conversion theorem that provides\nan upper bound for the contextual regret of the output algorithm as a function\nof the static regret of the input algorithm. We further study the implications\nof this general result for three fundamental cases of dependency of the\nobjective function on the action variable: (a) Lipschitz bandits, (b) convex\nbandits, (c) strongly convex and smooth bandits. For Lipschitz bandits and\n$\\gamma=1,$ combining our results with the lower bound of Slivkins (2014), we\nprove that the minimax optimal contextual regret for the noise-free adversarial\nsetting is achieved. Then, we prove that in the presence of noise, the\ncontextual regret rate as a function of the number of queries is the same for\nconvex bandits as it is for strongly convex and smooth bandits. Lastly, we\npresent a minimax lower bound, implying two key facts. First, obtaining a\nsub-linear contextual regret may be impossible over functions that are not\ncontinuous with respect to the context. Second, for convex bandits and strongly\nconvex and smooth bandits, the algorithms that we propose achieve, up to a\nlogarithmic factor, the minimax optimal rate of contextual regret as a function\nof the number of queries.\n","authors":["Arya Akhavan","Karim Lounici","Massimiliano Pontil","Alexandre B. Tsybakov"],"pdf_url":"https://arxiv.org/pdf/2406.05714v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.17634v2","updated":"2025-03-06T11:17:31Z","published":"2025-01-29T13:11:21Z","title":"Federated Learning With Individualized Privacy Through Client Sampling","summary":"  With growing concerns about user data collection, individualized privacy has\nemerged as a promising solution to balance protection and utility by accounting\nfor diverse user privacy preferences. Instead of enforcing a uniform level of\nanonymization for all users, this approach allows individuals to choose privacy\nsettings that align with their comfort levels. Building on this idea, we\npropose an adapted method for enabling Individualized Differential Privacy\n(IDP) in Federated Learning (FL) by handling clients according to their\npersonal privacy preferences. By extending the SAMPLE algorithm from\ncentralized settings to FL, we calculate client-specific sampling rates based\non their heterogeneous privacy budgets and integrate them into a modified\nIDP-FedAvg algorithm. We test this method under realistic privacy distributions\nand multiple datasets. The experimental results demonstrate that our approach\nachieves clear improvements over uniform DP baselines, reducing the trade-off\nbetween privacy and utility. Compared to the alternative SCALE method in\nrelated work, which assigns differing noise scales to clients, our method\nperforms notably better. However, challenges remain for complex tasks with\nnon-i.i.d. data, primarily stemming from the constraints of the decentralized\nsetting.\n","authors":["Lucas Lange","Ole Borchardt","Erhard Rahm"],"pdf_url":"https://arxiv.org/pdf/2501.17634v2.pdf","comment":"Accepted at 10th International Conference on Machine Learning\n  Technologies (ICMLT 2025)"},{"id":"http://arxiv.org/abs/2402.03448v4","updated":"2025-03-06T11:07:54Z","published":"2024-02-05T19:02:19Z","title":"Decentralized Sporadic Federated Learning: A Unified Algorithmic\n  Framework with Convergence Guarantees","summary":"  Decentralized federated learning (DFL) captures FL settings where both (i)\nmodel updates and (ii) model aggregations are exclusively carried out by the\nclients without a central server. Existing DFL works have mostly focused on\nsettings where clients conduct a fixed number of local updates between local\nmodel exchanges, overlooking heterogeneity and dynamics in communication and\ncomputation capabilities. In this work, we propose Decentralized Sporadic\nFederated Learning ($\\texttt{DSpodFL}$), a DFL methodology built on a\ngeneralized notion of $\\textit{sporadicity}$ in both local gradient and\naggregation processes. $\\texttt{DSpodFL}$ subsumes many existing decentralized\noptimization methods under a unified algorithmic framework by modeling the\nper-iteration (i) occurrence of gradient descent at each client and (ii)\nexchange of models between client pairs as arbitrary indicator random\nvariables, thus capturing $\\textit{heterogeneous and time-varying}$\ncomputation/communication scenarios. We analytically characterize the\nconvergence behavior of $\\texttt{DSpodFL}$ for both convex and non-convex\nmodels and for both constant and diminishing learning rates, under mild\nassumptions on the communication graph connectivity, data heterogeneity across\nclients, and gradient noises. We show how our bounds recover existing results\nfrom decentralized gradient descent as special cases. Experiments demonstrate\nthat $\\texttt{DSpodFL}$ consistently achieves improved training speeds compared\nwith baselines under various system settings.\n","authors":["Shahryar Zehtabi","Dong-Jun Han","Rohit Parasnis","Seyyedali Hosseinalipour","Christopher G. Brinton"],"pdf_url":"https://arxiv.org/pdf/2402.03448v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.15109v2","updated":"2025-03-06T11:07:48Z","published":"2025-02-21T00:05:40Z","title":"Social Genome: Grounded Social Reasoning Abilities of Multimodal Models","summary":"  Social reasoning abilities are crucial for AI systems to effectively\ninterpret and respond to multimodal human communication and interaction within\nsocial contexts. We introduce Social Genome, the first benchmark for\nfine-grained, grounded social reasoning abilities of multimodal models. Social\nGenome contains 272 videos of interactions and 1,486 human-annotated reasoning\ntraces related to inferences about these interactions. These traces contain\n5,777 reasoning steps that reference evidence from visual cues, verbal cues,\nvocal cues, and external knowledge (contextual knowledge external to videos).\nSocial Genome is also the first modeling challenge to study external knowledge\nin social reasoning. Social Genome computes metrics to holistically evaluate\nsemantic and structural qualities of model-generated social reasoning traces.\nWe demonstrate the utility of Social Genome through experiments with\nstate-of-the-art models, identifying performance gaps and opportunities for\nfuture research to improve the grounded social reasoning abilities of\nmultimodal models.\n","authors":["Leena Mathur","Marian Qian","Paul Pu Liang","Louis-Philippe Morency"],"pdf_url":"https://arxiv.org/pdf/2502.15109v2.pdf","comment":"Under Review, 22 pages"},{"id":"http://arxiv.org/abs/2402.01879v3","updated":"2025-03-06T11:05:33Z","published":"2024-02-02T20:08:11Z","title":"$σ$-zero: Gradient-based Optimization of $\\ell_0$-norm Adversarial\n  Examples","summary":"  Evaluating the adversarial robustness of deep networks to gradient-based\nattacks is challenging. While most attacks consider $\\ell_2$- and\n$\\ell_\\infty$-norm constraints to craft input perturbations, only a few\ninvestigate sparse $\\ell_1$- and $\\ell_0$-norm attacks. In particular,\n$\\ell_0$-norm attacks remain the least studied due to the inherent complexity\nof optimizing over a non-convex and non-differentiable constraint. However,\nevaluating adversarial robustness under these attacks could reveal weaknesses\notherwise left untested with more conventional $\\ell_2$- and $\\ell_\\infty$-norm\nattacks. In this work, we propose a novel $\\ell_0$-norm attack, called\n$\\sigma$-zero, which leverages a differentiable approximation of the $\\ell_0$\nnorm to facilitate gradient-based optimization, and an adaptive projection\noperator to dynamically adjust the trade-off between loss minimization and\nperturbation sparsity. Extensive evaluations using MNIST, CIFAR10, and ImageNet\ndatasets, involving robust and non-robust models, show that\n$\\sigma$\\texttt{-zero} finds minimum $\\ell_0$-norm adversarial examples without\nrequiring any time-consuming hyperparameter tuning, and that it outperforms all\ncompeting sparse attacks in terms of success rate, perturbation size, and\nefficiency.\n","authors":["Antonio Emanuele Cinà","Francesco Villani","Maura Pintor","Lea Schönherr","Battista Biggio","Marcello Pelillo"],"pdf_url":"https://arxiv.org/pdf/2402.01879v3.pdf","comment":"Paper accepted at International Conference on Learning\n  Representations (ICLR 2025). Code available at\n  https://github.com/sigma0-advx/sigma-zero"},{"id":"http://arxiv.org/abs/2412.00156v3","updated":"2025-03-06T11:05:32Z","published":"2024-11-29T08:10:49Z","title":"VISION-XL: High Definition Video Inverse Problem Solver using Latent\n  Image Diffusion Models","summary":"  In this paper, we propose a novel framework for solving high-definition video\ninverse problems using latent image diffusion models. Building on recent\nadvancements in spatio-temporal optimization for video inverse problems using\nimage diffusion models, our approach leverages latent-space diffusion models to\nachieve enhanced video quality and resolution. To address the high\ncomputational demands of processing high-resolution frames, we introduce a\npseudo-batch consistent sampling strategy, allowing efficient operation on a\nsingle GPU. Additionally, to improve temporal consistency, we present\npseudo-batch inversion, an initialization technique that incorporates\ninformative latents from the measurement. By integrating with SDXL, our\nframework achieves state-of-the-art video reconstruction across a wide range of\nspatio-temporal inverse problems, including complex combinations of frame\naveraging and various spatial degradations, such as deblurring,\nsuper-resolution, and inpainting. Unlike previous methods, our approach\nsupports multiple aspect ratios (landscape, vertical, and square) and delivers\nHD-resolution reconstructions (exceeding 1280x720) in under 6 seconds per frame\non a single NVIDIA 4090 GPU.\n","authors":["Taesung Kwon","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2412.00156v3.pdf","comment":"Project page: https://vision-xl.github.io/"},{"id":"http://arxiv.org/abs/2501.10814v2","updated":"2025-03-06T11:05:23Z","published":"2025-01-18T16:23:09Z","title":"No More Sliding Window: Efficient 3D Medical Image Segmentation with\n  Differentiable Top-k Patch Sampling","summary":"  3D models surpass 2D models in CT/MRI segmentation by effectively capturing\ninter-slice relationships. However, the added depth dimension substantially\nincreases memory consumption. While patch-based training alleviates memory\nconstraints, it significantly slows down the inference speed due to the sliding\nwindow (SW) approach. We propose No-More-Sliding-Window (NMSW), a novel\nend-to-end trainable framework that enhances the efficiency of generic 3D\nsegmentation backbone during an inference step by eliminating the need for SW.\nNMSW employs a differentiable Top-k module to selectively sample only the most\nrelevant patches, thereby minimizing redundant computations. When patch-level\npredictions are insufficient, the framework intelligently leverages coarse\nglobal predictions to refine results. Evaluated across 3 tasks using 3\nsegmentation backbones, NMSW achieves competitive accuracy compared to SW\ninference while significantly reducing computational complexity by 91% (88.0 to\n8.00 TMACs). Moreover, it delivers a 9.1x faster inference on the H100 GPU\n(99.0 to 8.3 sec) and a 11.1x faster inference on the Xeon Gold CPU (2110 to\n189 sec). NMSW is model-agnostic, further boosting efficiency when integrated\nwith any existing efficient segmentation backbones.\n","authors":["Young Seok Jeon","Hongfei Yang","Huazhu Fu","Mengling Feng"],"pdf_url":"https://arxiv.org/pdf/2501.10814v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04318v1","updated":"2025-03-06T11:00:18Z","published":"2025-03-06T11:00:18Z","title":"InFL-UX: A Toolkit for Web-Based Interactive Federated Learning","summary":"  This paper presents InFL-UX, an interactive, proof-of-concept browser-based\nFederated Learning (FL) toolkit designed to integrate user contributions\nseamlessly into the machine learning (ML) workflow. InFL-UX enables users\nacross multiple devices to upload datasets, define classes, and collaboratively\ntrain classification models directly in the browser using modern web\ntechnologies. Unlike traditional FL toolkits, which often focus on backend\nsimulations, InFL-UX provides a simple user interface for researchers to\nexplore how users interact with and contribute to FL systems in real-world,\ninteractive settings. By prioritising usability and decentralised model\ntraining, InFL-UX bridges the gap between FL and Interactive Machine Learning\n(IML), empowering non-technical users to actively participate in ML\nclassification tasks.\n","authors":["Tim Maurer","Abdulrahman Mohamed Selim","Hasan Md Tusfiqur Alam","Matthias Eiletz","Michael Barz","Daniel Sonntag"],"pdf_url":"https://arxiv.org/pdf/2503.04318v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04315v1","updated":"2025-03-06T10:58:35Z","published":"2025-03-06T10:58:35Z","title":"Provable Robust Overfitting Mitigation in Wasserstein Distributionally\n  Robust Optimization","summary":"  Wasserstein distributionally robust optimization (WDRO) optimizes against\nworst-case distributional shifts within a specified uncertainty set, leading to\nenhanced generalization on unseen adversarial examples, compared to standard\nadversarial training which focuses on pointwise adversarial perturbations.\nHowever, WDRO still suffers fundamentally from the robust overfitting problem,\nas it does not consider statistical error. We address this gap by proposing a\nnovel robust optimization framework under a new uncertainty set for adversarial\nnoise via Wasserstein distance and statistical error via Kullback-Leibler\ndivergence, called the Statistically Robust WDRO. We establish a robust\ngeneralization bound for the new optimization framework, implying that\nout-of-distribution adversarial performance is at least as good as the\nstatistically robust training loss with high probability. Furthermore, we\nderive conditions under which Stackelberg and Nash equilibria exist between the\nlearner and the adversary, giving an optimal robust model in certain sense.\nFinally, through extensive experiments, we demonstrate that our method\nsignificantly mitigates robust overfitting and enhances robustness within the\nframework of WDRO.\n","authors":["Shuang Liu","Yihan Wang","Yifan Zhu","Yibo Miao","Xiao-Shan Gao"],"pdf_url":"https://arxiv.org/pdf/2503.04315v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.13794v2","updated":"2025-03-06T10:49:24Z","published":"2025-01-23T16:13:08Z","title":"Unveiling the Power of Noise Priors: Enhancing Diffusion Models for\n  Mobile Traffic Prediction","summary":"  Accurate prediction of mobile traffic, \\textit{i.e.,} network traffic from\ncellular base stations, is crucial for optimizing network performance and\nsupporting urban development. However, the non-stationary nature of mobile\ntraffic, driven by human activity and environmental changes, leads to both\nregular patterns and abrupt variations. Diffusion models excel in capturing\nsuch complex temporal dynamics due to their ability to capture the inherent\nuncertainties. Most existing approaches prioritize designing novel denoising\nnetworks but often neglect the critical role of noise itself, potentially\nleading to sub-optimal performance. In this paper, we introduce a novel\nperspective by emphasizing the role of noise in the denoising process. Our\nanalysis reveals that noise fundamentally shapes mobile traffic predictions,\nexhibiting distinct and consistent patterns. We propose NPDiff, a framework\nthat decomposes noise into \\textit{prior} and \\textit{residual} components,\nwith the \\textit{prior} derived from data dynamics, enhancing the model's\nability to capture both regular and abrupt variations. NPDiff can seamlessly\nintegrate with various diffusion-based prediction models, delivering\npredictions that are effective, efficient, and robust. Extensive experiments\ndemonstrate that it achieves superior performance with an improvement over\n30\\%, offering a new perspective on leveraging diffusion models in this domain.\n","authors":["Zhi Sheng","Yuan Yuan","Jingtao Ding","Yong Li"],"pdf_url":"https://arxiv.org/pdf/2501.13794v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18380v4","updated":"2025-03-06T10:25:17Z","published":"2024-06-26T14:21:21Z","title":"KAGNNs: Kolmogorov-Arnold Networks meet Graph Learning","summary":"  In recent years, Graph Neural Networks (GNNs) have become the de facto tool\nfor learning node and graph representations. Most GNNs typically consist of a\nsequence of neighborhood aggregation (a.k.a., message-passing) layers, within\nwhich the representation of each node is updated based on those of its\nneighbors. The most expressive message-passing GNNs can be obtained through the\nuse of the sum aggregator and of MLPs for feature transformation, thanks to\ntheir universal approximation capabilities. However, the limitations of MLPs\nrecently motivated the introduction of another family of universal\napproximators, called Kolmogorov-Arnold Networks (KANs) which rely on a\ndifferent representation theorem. In this work, we compare the performance of\nKANs against that of MLPs on graph learning tasks. We implement three new\nKAN-based GNN layers, inspired respectively by the GCN, GAT and GIN layers. We\nevaluate two different implementations of KANs using two distinct base families\nof functions, namely B-splines and radial basis functions. We perform extensive\nexperiments on node classification, link prediction, graph classification and\ngraph regression datasets. Our results indicate that KANs are on-par with or\nbetter than MLPs on all tasks studied in this paper. We also show that the size\nand training speed of RBF-based KANs is only marginally higher than for MLPs,\nmaking them viable alternatives. Code available at\nhttps://github.com/RomanBresson/KAGNN.\n","authors":["Roman Bresson","Giannis Nikolentzos","George Panagopoulos","Michail Chatzianastasis","Jun Pang","Michalis Vazirgiannis"],"pdf_url":"https://arxiv.org/pdf/2406.18380v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16935v2","updated":"2025-03-06T10:10:06Z","published":"2024-10-22T12:12:43Z","title":"Graph Neural Networks for Edge Signals: Orientation Equivariance and\n  Invariance","summary":"  Many applications in traffic, civil engineering, or electrical engineering\nrevolve around edge-level signals. Such signals can be categorized as\ninherently directed, for example, the water flow in a pipe network, and\nundirected, like the diameter of a pipe. Topological methods model edge signals\nwith inherent direction by representing them relative to a so-called\norientation assigned to each edge. These approaches can neither model\nundirected edge signals nor distinguish if an edge itself is directed or\nundirected. We address these shortcomings by (i) revising the notion of\norientation equivariance to enable edge direction-aware topological models,\n(ii) proposing orientation invariance as an additional requirement to describe\nsignals without inherent direction, and (iii) developing EIGN, an architecture\ncomposed of novel direction-aware edge-level graph shift operators, that\nprovably fulfills the aforementioned desiderata. It is the first\ngeneral-purpose topological GNN for edge-level signals that can model directed\nand undirected signals while distinguishing between directed and undirected\nedges. A comprehensive evaluation shows that EIGN outperforms prior work in\nedge-level tasks, for example, improving in RMSE on flow simulation tasks by up\nto 23.5%.\n","authors":["Dominik Fuchsgruber","Tim Poštuvan","Stephan Günnemann","Simon Geisler"],"pdf_url":"https://arxiv.org/pdf/2410.16935v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04283v1","updated":"2025-03-06T10:09:20Z","published":"2025-03-06T10:09:20Z","title":"Explainable AI in Time-Sensitive Scenarios: Prefetched Offline\n  Explanation Model","summary":"  As predictive machine learning models become increasingly adopted and\nadvanced, their role has evolved from merely predicting outcomes to actively\nshaping them. This evolution has underscored the importance of Trustworthy AI,\nhighlighting the necessity to extend our focus beyond mere accuracy and toward\na comprehensive understanding of these models' behaviors within the specific\ncontexts of their applications. To further progress in explainability, we\nintroduce Poem, Prefetched Offline Explanation Model, a model-agnostic, local\nexplainability algorithm for image data. The algorithm generates exemplars,\ncounterexemplars and saliency maps to provide quick and effective explanations\nsuitable for time-sensitive scenarios. Leveraging an existing local algorithm,\n\\poem{} infers factual and counterfactual rules from data to create\nillustrative examples and opposite scenarios with an enhanced stability by\ndesign. A novel mechanism then matches incoming test points with an explanation\nbase and produces diverse exemplars, informative saliency maps and believable\ncounterexemplars. Experimental results indicate that Poem outperforms its\npredecessor Abele in speed and ability to generate more nuanced and varied\nexemplars alongside more insightful saliency maps and valuable\ncounterexemplars.\n","authors":["Fabio Michele Russo","Carlo Metta","Anna Monreale","Salvatore Rinzivillo","Fabio Pinelli"],"pdf_url":"https://arxiv.org/pdf/2503.04283v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04280v1","updated":"2025-03-06T10:08:44Z","published":"2025-03-06T10:08:44Z","title":"Towards Autonomous Reinforcement Learning for Real-World Robotic\n  Manipulation with Large Language Models","summary":"  Recent advancements in Large Language Models (LLMs) and Visual Language\nModels (VLMs) have significantly impacted robotics, enabling high-level\nsemantic motion planning applications. Reinforcement Learning (RL), a\ncomplementary paradigm, enables agents to autonomously optimize complex\nbehaviors through interaction and reward signals. However, designing effective\nreward functions for RL remains challenging, especially in real-world tasks\nwhere sparse rewards are insufficient and dense rewards require elaborate\ndesign. In this work, we propose Autonomous Reinforcement learning for Complex\nHumanInformed Environments (ARCHIE), an unsupervised pipeline leveraging GPT-4,\na pre-trained LLM, to generate reward functions directly from natural language\ntask descriptions. The rewards are used to train RL agents in simulated\nenvironments, where we formalize the reward generation process to enhance\nfeasibility. Additionally, GPT-4 automates the coding of task success criteria,\ncreating a fully automated, one-shot procedure for translating human-readable\ntext into deployable robot skills. Our approach is validated through extensive\nsimulated experiments on single-arm and bi-manual manipulation tasks using an\nABB YuMi collaborative robot, highlighting its practicality and effectiveness.\nTasks are demonstrated on the real robot setup.\n","authors":["Niccolò Turcato","Matteo Iovino","Aris Synodinos","Alberto Dalla Libera","Ruggero Carli","Pietro Falco"],"pdf_url":"https://arxiv.org/pdf/2503.04280v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04278v1","updated":"2025-03-06T10:07:17Z","published":"2025-03-06T10:07:17Z","title":"A General Framework for Scalable UE-AP Association in User-Centric\n  Cell-Free Massive MIMO based on Recurrent Neural Networks","summary":"  This study addresses the challenge of access point (AP) and user equipment\n(UE) association in cell-free massive MIMO networks. It introduces a deep\nlearning algorithm leveraging Bidirectional Long Short-Term Memory cells and a\nhybrid probabilistic methodology for weight updating. This approach enhances\nscalability by adapting to variations in the number of UEs without requiring\nretraining. Additionally, the study presents a training methodology that\nimproves scalability not only with respect to the number of UEs but also to the\nnumber of APs. Furthermore, a variant of the proposed AP-UE algorithm ensures\nrobustness against pilot contamination effects, a critical issue arising from\npilot reuse in channel estimation. Extensive numerical results validate the\neffectiveness and adaptability of the proposed methods, demonstrating their\nsuperiority over widely used heuristic alternatives.\n","authors":["Giovanni Di Gennaro","Amedeo Buonanno","Gianmarco Romano","Stefano Buzzi","Francesco A. N. Palmieri"],"pdf_url":"https://arxiv.org/pdf/2503.04278v1.pdf","comment":"submitted to IEEE journal"},{"id":"http://arxiv.org/abs/2405.14736v2","updated":"2025-03-06T09:52:43Z","published":"2024-05-23T16:02:30Z","title":"GIFT: Unlocking Full Potential of Labels in Distilled Dataset at\n  Near-zero Cost","summary":"  Recent advancements in dataset distillation have demonstrated the significant\nbenefits of employing soft labels generated by pre-trained teacher models. In\nthis paper, we introduce a novel perspective by emphasizing the full\nutilization of labels. We first conduct a comprehensive comparison of various\nloss functions for soft label utilization in dataset distillation, revealing\nthat the model trained on the synthetic dataset exhibits high sensitivity to\nthe choice of loss function for soft label utilization. This finding highlights\nthe necessity of a universal loss function for training models on synthetic\ndatasets. Building on these insights, we introduce an extremely simple yet\nsurprisingly effective plug-and-play approach, GIFT, which encompasses soft\nlabel refinement and a cosine similarity-based loss function to efficiently\nleverage full label information. Extensive experiments indicate that GIFT\nconsistently enhances state-of-the-art dataset distillation methods across\nvarious dataset scales, without incurring additional computational costs.\nImportantly, GIFT significantly enhances cross-optimizer generalization, an\narea previously overlooked. For instance, on ImageNet-1K with IPC = 10, GIFT\nenhances the state-of-the-art method RDED by 30.8% in cross-optimizer\ngeneralization. Our code is available at https://github.com/LINs-lab/GIFT.\n","authors":["Xinyi Shang","Peng Sun","Tao Lin"],"pdf_url":"https://arxiv.org/pdf/2405.14736v2.pdf","comment":"https://github.com/LINs-lab/GIFT"},{"id":"http://arxiv.org/abs/2503.04266v1","updated":"2025-03-06T09:50:43Z","published":"2025-03-06T09:50:43Z","title":"Frequency Hopping Synchronization by Reinforcement Learning for\n  Satellite Communication System","summary":"  Satellite communication systems (SCSs) used for tactical purposes require\nrobust security and anti-jamming capabilities, making frequency hopping (FH) a\npowerful option. However, the current FH systems face challenges due to\nsignificant interference from other devices and the considerable path loss\ninherent in satellite communication. This misalignment leads to inefficient\nsynchronization, crucial for maintaining reliable communication. Traditional\nmethods, such as those employing long short-term memory (LSTM) networks, have\nmade improvements, but they still struggle in dynamic conditions of satellite\nenvironments. This paper presents a novel method for synchronizing FH signals\nin tactical SCSs by combining serial search and reinforcement learning to\nachieve coarse and fine acquisition, respectively. The mathematical analysis\nand simulation results demonstrate that the proposed method reduces the average\nnumber of hops required for synchronization by 58.17% and mean squared error\n(MSE) of the uplink hop timing estimation by 76.95%, as compared to the\nconventional serial search method. Comparing with the early late gate\nsynchronization method based on serial search and use of LSTM network, the\naverage number of hops for synchronization is reduced by 12.24% and the MSE by\n18.5%.\n","authors":["Inkyu Kim","Sangkeum Lee","Haechan Jeong","Sarvar Hussain Nengroo","Dongsoo Har"],"pdf_url":"https://arxiv.org/pdf/2503.04266v1.pdf","comment":"18pages, 5figures"},{"id":"http://arxiv.org/abs/2503.04263v1","updated":"2025-03-06T09:47:41Z","published":"2025-03-06T09:47:41Z","title":"Bi-Lipschitz Ansatz for Anti-Symmetric Functions","summary":"  Motivated by applications for simulating quantum many body functions, we\npropose a new universal ansatz for approximating anti-symmetric functions. The\nmain advantage of this ansatz over previous alternatives is that it is\nbi-Lipschitz with respect to a naturally defined metric. As a result, we are\nable to obtain quantitative approximation results for approximation of\nLipschitz continuous antisymmetric functions. Moreover, we provide preliminary\nexperimental evidence to the improved performance of this ansatz for learning\nantisymmetric functions.\n","authors":["Nadav Dym","Jianfeng Lu","Matan Mizrachi"],"pdf_url":"https://arxiv.org/pdf/2503.04263v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04256v1","updated":"2025-03-06T09:38:14Z","published":"2025-03-06T09:38:14Z","title":"Knowledge Retention for Continual Model-Based Reinforcement Learning","summary":"  We propose DRAGO, a novel approach for continual model-based reinforcement\nlearning aimed at improving the incremental development of world models across\na sequence of tasks that differ in their reward functions but not the state\nspace or dynamics. DRAGO comprises two key components: Synthetic Experience\nRehearsal, which leverages generative models to create synthetic experiences\nfrom past tasks, allowing the agent to reinforce previously learned dynamics\nwithout storing data, and Regaining Memories Through Exploration, which\nintroduces an intrinsic reward mechanism to guide the agent toward revisiting\nrelevant states from prior tasks. Together, these components enable the agent\nto maintain a comprehensive and continually developing world model,\nfacilitating more effective learning and adaptation across diverse\nenvironments. Empirical evaluations demonstrate that DRAGO is able to preserve\nknowledge across tasks, achieving superior performance in various continual\nlearning scenarios.\n","authors":["Yixiang Sun","Haotian Fu","Michael Littman","George Konidaris"],"pdf_url":"https://arxiv.org/pdf/2503.04256v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04252v1","updated":"2025-03-06T09:35:20Z","published":"2025-03-06T09:35:20Z","title":"RCRank: Multimodal Ranking of Root Causes of Slow Queries in Cloud\n  Database Systems","summary":"  With the continued migration of storage to cloud database systems,the impact\nof slow queries in such systems on services and user experience is increasing.\nRoot-cause diagnosis plays an indispensable role in facilitating slow-query\ndetection and revision. This paper proposes a method capable of both\nidentifying possible root cause types for slow queries and ranking these\naccording to their potential for accelerating slow queries. This enables\nprioritizing root causes with the highest impact, in turn improving slow-query\nrevision effectiveness. To enable more accurate and detailed diagnoses, we\npropose the multimodal Ranking for the Root Causes of slow queries (RCRank)\nframework, which formulates root cause analysis as a multimodal machine\nlearning problem and leverages multimodal information from query statements,\nexecution plans, execution logs, and key performance indicators. To obtain\nexpressive embeddings from its heterogeneous multimodal input, RCRank\nintegrates self-supervised pre-training that enhances cross-modal alignment and\ntask relevance. Next, the framework integrates root-cause-adaptive cross\nTransformers that enable adaptive fusion of multimodal features with varying\ncharacteristics. Finally, the framework offers a unified model that features an\nimpact-aware training objective for identifying and ranking root causes. We\nreport on experiments on real and synthetic datasets, finding that RCRank is\ncapable of consistently outperforming the state-of-the-art methods at root\ncause identification and ranking according to a range of metrics.\n","authors":["Biao Ouyang","Yingying Zhang","Hanyin Cheng","Yang Shu","Chenjuan Guo","Bin Yang","Qingsong Wen","Lunting Fan","Christian S. Jensen"],"pdf_url":"https://arxiv.org/pdf/2503.04252v1.pdf","comment":"Accepted by VLDB 2025"},{"id":"http://arxiv.org/abs/2403.15038v2","updated":"2025-03-06T09:32:52Z","published":"2024-03-22T08:42:41Z","title":"Estimation of multiple mean vectors in high dimension","summary":"  We endeavour to estimate numerous multi-dimensional means of various\nprobability distributions on a common space based on independent samples. Our\napproach involves forming estimators through convex combinations of empirical\nmeans derived from these samples. We introduce two strategies to find\nappropriate data-dependent convex combination weights: a first one employing a\ntesting procedure to identify neighbouring means with low variance, which\nresults in a closed-form plug-in formula for the weights, and a second one\ndetermining weights via minimization of an upper confidence bound on the\nquadratic risk.Through theoretical analysis, we evaluate the improvement in\nquadratic risk offered by our methods compared to the empirical means. Our\nanalysis focuses on a dimensional asymptotics perspective, showing that our\nmethods asymptotically approach an oracle (minimax) improvement as the\neffective dimension of the data increases.We demonstrate the efficacy of our\nmethods in estimating multiple kernel mean embeddings through experiments on\nboth simulated and real-world datasets.\n","authors":["Gilles Blanchard","Jean-Baptiste Fermanian","Hannah Marienwald"],"pdf_url":"https://arxiv.org/pdf/2403.15038v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04249v1","updated":"2025-03-06T09:32:39Z","published":"2025-03-06T09:32:39Z","title":"How to Mitigate Overfitting in Weak-to-strong Generalization?","summary":"  Aligning powerful AI models on tasks that surpass human evaluation\ncapabilities is the central problem of \\textbf{superalignment}. To address this\nproblem, weak-to-strong generalization aims to elicit the capabilities of\nstrong models through weak supervisors and ensure that the behavior of strong\nmodels aligns with the intentions of weak supervisors without unsafe behaviors\nsuch as deception. Although weak-to-strong generalization exhibiting certain\ngeneralization capabilities, strong models exhibit significant overfitting in\nweak-to-strong generalization: Due to the strong fit ability of strong models,\nerroneous labels from weak supervisors may lead to overfitting in strong\nmodels. In addition, simply filtering out incorrect labels may lead to a\ndegeneration in question quality, resulting in a weak generalization ability of\nstrong models on hard questions. To mitigate overfitting in weak-to-strong\ngeneralization, we propose a two-stage framework that simultaneously improves\nthe quality of supervision signals and the quality of input questions.\nExperimental results in three series of large language models and two\nmathematical benchmarks demonstrate that our framework significantly improves\nPGR compared to naive weak-to-strong generalization, even achieving up to 100\\%\nPGR on some models.\n","authors":["Junhao Shi","Qinyuan Cheng","Zhaoye Fei","Yining Zheng","Qipeng Guo","Xipeng Qiu"],"pdf_url":"https://arxiv.org/pdf/2503.04249v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.19085v2","updated":"2025-03-06T09:32:37Z","published":"2024-12-26T06:54:22Z","title":"Assessing Pre-Trained Models for Transfer Learning Through Distribution\n  of Spectral Components","summary":"  Pre-trained model assessment for transfer learning aims to identify the\noptimal candidate for the downstream tasks from a model hub, without the need\nof time-consuming fine-tuning. Existing advanced works mainly focus on\nanalyzing the intrinsic characteristics of the entire features extracted by\neach pre-trained model or how well such features fit the target labels. This\npaper proposes a novel perspective for pre-trained model assessment through the\nDistribution of Spectral Components (DISCO). Through singular value\ndecomposition of features extracted from pre-trained models, we investigate\ndifferent spectral components and observe that they possess distinct\ntransferability, contributing diversely to the fine-tuning performance.\nInspired by this, we propose an assessment method based on the distribution of\nspectral components which measures the proportions of their corresponding\nsingular values. Pre-trained models with features concentrating on more\ntransferable components are regarded as better choices for transfer learning.\nWe further leverage the labels of downstream data to better estimate the\ntransferability of each spectral component and derive the final assessment\ncriterion. Our proposed method is flexible and can be applied to both\nclassification and regression tasks. We conducted comprehensive experiments\nacross three benchmarks and two tasks including image classification and object\ndetection, demonstrating that our method achieves state-of-the-art performance\nin choosing proper pre-trained models from the model hub for transfer learning.\n","authors":["Tengxue Zhang","Yang Shu","Xinyang Chen","Yifei Long","Chenjuan Guo","Bin Yang"],"pdf_url":"https://arxiv.org/pdf/2412.19085v2.pdf","comment":"Accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2503.04242v1","updated":"2025-03-06T09:24:23Z","published":"2025-03-06T09:24:23Z","title":"Incorporating Surrogate Gradient Norm to Improve Offline Optimization\n  Techniques","summary":"  Offline optimization has recently emerged as an increasingly popular approach\nto mitigate the prohibitively expensive cost of online experimentation. The key\nidea is to learn a surrogate of the black-box function that underlines the\ntarget experiment using a static (offline) dataset of its previous input-output\nqueries. Such an approach is, however, fraught with an out-of-distribution\nissue where the learned surrogate becomes inaccurate outside the offline data\nregimes. To mitigate this, existing offline optimizers have proposed numerous\nconditioning techniques to prevent the learned surrogate from being too\nerratic. Nonetheless, such conditioning strategies are often specific to\nparticular surrogate or search models, which might not generalize to a\ndifferent model choice. This motivates us to develop a model-agnostic approach\ninstead, which incorporates a notion of model sharpness into the training loss\nof the surrogate as a regularizer. Our approach is supported by a new\ntheoretical analysis demonstrating that reducing surrogate sharpness on the\noffline dataset provably reduces its generalized sharpness on unseen data. Our\nanalysis extends existing theories from bounding generalized prediction loss\n(on unseen data) with loss sharpness to bounding the worst-case generalized\nsurrogate sharpness with its empirical estimate on training data, providing a\nnew perspective on sharpness regularization. Our extensive experimentation on a\ndiverse range of optimization tasks also shows that reducing surrogate\nsharpness often leads to significant improvement, marking (up to) a noticeable\n9.6% performance boost. Our code is publicly available at\nhttps://github.com/cuong-dm/IGNITE\n","authors":["Manh Cuong Dao","Phi Le Nguyen","Thao Nguyen Truong","Trong Nghia Hoang"],"pdf_url":"https://arxiv.org/pdf/2503.04242v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.19102v2","updated":"2025-03-06T09:23:22Z","published":"2025-01-31T12:51:55Z","title":"Reinforcement Learning on Reconfigurable Hardware: Overcoming Material\n  Variability in Laser Material Processing","summary":"  Ensuring consistent processing quality is challenging in laser processes due\nto varying material properties and surface conditions. Although some approaches\nhave shown promise in solving this problem via automation, they often rely on\npredetermined targets or are limited to simulated environments. To address\nthese shortcomings, we propose a novel real-time reinforcement learning\napproach for laser process control, implemented on a Field Programmable Gate\nArray to achieve real-time execution. Our experimental results from laser\nwelding tests on stainless steel samples with a range of surface roughnesses\nvalidated the method's ability to adapt autonomously, without relying on reward\nengineering or prior setup information. Specifically, the algorithm learned the\ncorrect power profile for each unique surface characteristic, demonstrating\nsignificant improvements over hand-engineered optimal constant power strategies\n-- up to 23% better performance on rougher surfaces and 7% on mixed surfaces.\nThis approach represents a significant advancement in automating and optimizing\nlaser processes, with potential applications across multiple industries.\n","authors":["Giulio Masinelli","Chang Rajani","Patrik Hoffmann","Kilian Wasmer","David Atienza"],"pdf_url":"https://arxiv.org/pdf/2501.19102v2.pdf","comment":"Accepted for the 2025 IEEE International Conference on Robotics and\n  Automation (ICRA), May 19-23, 2025, Atlanta, USA; Camera ready version --\n  addressed reviewer comments in text, improved plot clarity"},{"id":"http://arxiv.org/abs/2501.13430v2","updated":"2025-03-06T09:22:38Z","published":"2025-01-23T07:29:44Z","title":"Wasserstein-regularized Conformal Prediction under General Distribution\n  Shift","summary":"  Conformal prediction yields a prediction set with guaranteed $1-\\alpha$\ncoverage of the true target under the i.i.d. assumption, which may not hold and\nlead to a gap between $1-\\alpha$ and the actual coverage. Prior studies bound\nthe gap using total variation distance, which cannot identify the gap changes\nunder distribution shift at a given $\\alpha$. Besides, existing methods are\nmostly limited to covariate shift,while general joint distribution shifts are\nmore common in practice but less researched.In response, we first propose a\nWasserstein distance-based upper bound of the coverage gap and analyze the\nbound using probability measure pushforwards between the shifted joint data and\nconformal score distributions, enabling a separation of the effect of covariate\nand concept shifts over the coverage gap. We exploit the separation to design\nan algorithm based on importance weighting and regularized representation\nlearning (WR-CP) to reduce the Wasserstein bound with a finite-sample error\nbound.WR-CP achieves a controllable balance between conformal prediction\naccuracy and efficiency. Experiments on six datasets prove that WR-CP can\nreduce coverage gaps to $3.2\\%$ across different confidence levels and outputs\nprediction sets 37$\\%$ smaller than the worst-case approach on average.\n","authors":["Rui Xu","Chao Chen","Yue Sun","Parvathinathan Venkitasubramaniam","Sihong Xie"],"pdf_url":"https://arxiv.org/pdf/2501.13430v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04241v1","updated":"2025-03-06T09:22:23Z","published":"2025-03-06T09:22:23Z","title":"ThrowBench: Benchmarking LLMs by Predicting Runtime Exceptions","summary":"  Modern Large Language Models (LLMs) have shown astounding capabilities of\ncode understanding and synthesis. In order to assess such capabilities, several\nbenchmarks have been devised (e.g., HumanEval). However, most benchmarks focus\non code synthesis from natural language instructions. Hence, such benchmarks do\nnot test for other forms of code understanding. Moreover, there have been\nconcerns about contamination and leakage. That is, benchmark problems (or\nclosely related problems) may appear in training set, strongly biasing\nbenchmark results. In this work we investigate whether large language models\ncan correctly predict runtime program behavior. To this end, we introduce\nThrowBench, a benchmark consisting of over 2,400 short user-written programs\nwritten in four different programming languages. The majority of these programs\nthrow an exception during runtime (due to a bug). LLMs are asked to predict\nwhether a presented program throws an exception and, if so, which one.\nEvaluating our benchmark on six state-of-the-art code LLMs we see modest\nperformance ranging from 19 to 38% (F1 score). Benchmarking a wider set of code\ncapabilities could improve the assessment of code LLMs and help identify weak\npoints in current models. Moreover, as ground-truth answers have been\ndetermined through program execution, leakage is not a concern. We release\nThrowBench as well as all of our results together with this work.\n","authors":["Julian Aron Prenner","Romain Robbes"],"pdf_url":"https://arxiv.org/pdf/2503.04241v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04231v1","updated":"2025-03-06T09:12:43Z","published":"2025-03-06T09:12:43Z","title":"One-Shot Clustering for Federated Learning","summary":"  Federated Learning (FL) is a widespread and well adopted paradigm of\ndecentralized learning that allows training one model from multiple sources\nwithout the need to directly transfer data between participating clients. Since\nits inception in 2015, it has been divided into numerous sub-fields that deal\nwith application-specific issues, be it data heterogeneity or resource\nallocation. One such sub-field, Clustered Federated Learning (CFL), is dealing\nwith the problem of clustering the population of clients into separate cohorts\nto deliver personalized models. Although few remarkable works have been\npublished in this domain, the problem is still largely unexplored, as its basic\nassumption and settings are slightly different from standard FL. In this work,\nwe present One-Shot Clustered Federated Learning (OCFL), a clustering-agnostic\nalgorithm that can automatically detect the earliest suitable moment for\nclustering. Our algorithm is based on the computation of cosine similarity\nbetween gradients of the clients and a temperature measure that detects when\nthe federated model starts to converge. We empirically evaluate our methodology\nby testing various one-shot clustering algorithms for over thirty different\ntasks on three benchmark datasets. Our experiments showcase the good\nperformance of our approach when used to perform CFL in an automated manner\nwithout the need to adjust hyperparameters.\n","authors":["Maciej Krzysztof Zuziak","Roberto Pellungrini","Salvatore Rinzivillo"],"pdf_url":"https://arxiv.org/pdf/2503.04231v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.02796v3","updated":"2025-03-06T09:10:18Z","published":"2022-06-06T14:26:34Z","title":"Mixed Graph Contrastive Network for Semi-Supervised Node Classification","summary":"  Graph Neural Networks (GNNs) have achieved promising performance in\nsemi-supervised node classification in recent years. However, the problem of\ninsufficient supervision, together with representation collapse, largely limits\nthe performance of the GNNs in this field. To alleviate the collapse of node\nrepresentations in semi-supervised scenario, we propose a novel graph\ncontrastive learning method, termed Mixed Graph Contrastive Network (MGCN). In\nour method, we improve the discriminative capability of the latent embeddings\nby an interpolation-based augmentation strategy and a correlation reduction\nmechanism. Specifically, we first conduct the interpolation-based augmentation\nin the latent space and then force the prediction model to change linearly\nbetween samples. Second, we enable the learned network to tell apart samples\nacross two interpolation-perturbed views through forcing the correlation matrix\nacross views to approximate an identity matrix. By combining the two settings,\nwe extract rich supervision information from both the abundant unlabeled nodes\nand the rare yet valuable labeled nodes for discriminative representation\nlearning. Extensive experimental results on six datasets demonstrate the\neffectiveness and the generality of MGCN compared to the existing\nstate-of-the-art methods. The code of MGCN is available at\nhttps://github.com/xihongyang1999/MGCN on Github.\n","authors":["Xihong Yang","Yiqi Wang","Yue Liu","Yi Wen","Lingyuan Meng","Sihang Zhou","Xinwang Liu","En Zhu"],"pdf_url":"https://arxiv.org/pdf/2206.02796v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.09263v3","updated":"2025-03-06T09:10:07Z","published":"2024-11-14T08:02:14Z","title":"Rethinking Weight-Averaged Model-merging","summary":"  Model-merging has emerged as a powerful approach in deep learning, capable of\nenhancing model performance without any training. However, the underlying\nmechanisms that explain its effectiveness remain largely unexplored. In this\npaper, we investigate this technique from three novel perspectives to\nempirically provide deeper insights into why and how weight-averaged\nmodel-merging works: (1) we examine the intrinsic patterns captured by the\nlearning of the model weights, through the visualizations of their patterns on\nseveral datasets, showing that these weights often encode structured and\ninterpretable patterns and that is the essential why model-merging can work;\n(2) we mathematically and empirically investigate model ensemble merging\nstrategies based on averaging on weights versus averaging on features,\nproviding detailed analyses across diverse architectures and datasets; and (3)\nwe explore the impact on model-merging prediction stability in terms of\nchanging the parameter magnitude, revealing insights into the way of weight\naveraging works as regularization by showing the robustness across different\nparameter scales. Our findings shed light on the \"black box\" of weight-averaged\nmodel-merging, offering valuable insights and practical recommendations that\nadvance the model-merging process. The code is available at\nhttps://github.com/billhhh/Rethink-Merge.\n","authors":["Hu Wang","Congbo Ma","Ibrahim Almakky","Ian Reid","Gustavo Carneiro","Mohammad Yaqub"],"pdf_url":"https://arxiv.org/pdf/2411.09263v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04229v1","updated":"2025-03-06T09:09:18Z","published":"2025-03-06T09:09:18Z","title":"Synthetic Data is an Elegant GIFT for Continual Vision-Language Models","summary":"  Pre-trained Vision-Language Models (VLMs) require Continual Learning (CL) to\nefficiently update their knowledge and adapt to various downstream tasks\nwithout retraining from scratch. However, for VLMs, in addition to the loss of\nknowledge previously learned from downstream tasks, pre-training knowledge is\nalso corrupted during continual fine-tuning. This issue is exacerbated by the\nunavailability of original pre-training data, leaving VLM's generalization\nability degrading. In this paper, we propose GIFT, a novel continual\nfine-tuning approach that utilizes synthetic data to overcome catastrophic\nforgetting in VLMs. Taking advantage of recent advances in text-to-image\nsynthesis, we employ a pre-trained diffusion model to recreate both\npre-training and learned downstream task data. In this way, the VLM can revisit\nprevious knowledge through distillation on matching diffusion-generated images\nand corresponding text prompts. Leveraging the broad distribution and high\nalignment between synthetic image-text pairs in VLM's feature space, we propose\na contrastive distillation loss along with an image-text alignment constraint.\nTo further combat in-distribution overfitting and enhance distillation\nperformance with limited amount of generated data, we incorporate adaptive\nweight consolidation, utilizing Fisher information from these synthetic\nimage-text pairs and achieving a better stability-plasticity balance. Extensive\nexperiments demonstrate that our method consistently outperforms previous\nstate-of-the-art approaches across various settings.\n","authors":["Bin Wu","Wuxuan Shi","Jinqiao Wang","Mang Ye"],"pdf_url":"https://arxiv.org/pdf/2503.04229v1.pdf","comment":"This work is accepted by CVPR 2025. Modifications may be performed"},{"id":"http://arxiv.org/abs/2402.02998v2","updated":"2025-03-06T08:57:29Z","published":"2024-02-05T13:37:00Z","title":"Careful with that Scalpel: Improving Gradient Surgery with an EMA","summary":"  Beyond minimizing a single training loss, many deep learning estimation\npipelines rely on an auxiliary objective to quantify and encourage desirable\nproperties of the model (e.g. performance on another dataset, robustness,\nagreement with a prior). Although the simplest approach to incorporating an\nauxiliary loss is to sum it with the training loss as a regularizer, recent\nworks have shown that one can improve performance by blending the gradients\nbeyond a simple sum; this is known as gradient surgery. We cast the problem as\na constrained minimization problem where the auxiliary objective is minimized\namong the set of minimizers of the training loss. To solve this bilevel\nproblem, we follow a parameter update direction that combines the training loss\ngradient and the orthogonal projection of the auxiliary gradient to the\ntraining gradient. In a setting where gradients come from mini-batches, we\nexplain how, using a moving average of the training loss gradients, we can\ncarefully maintain this critical orthogonality property. We demonstrate that\nour method, Bloop, can lead to much better performances on NLP and vision\nexperiments than other gradient surgery methods without EMA.\n","authors":["Yu-Guan Hsieh","James Thornton","Eugene Ndiaye","Michal Klein","Marco Cuturi","Pierre Ablin"],"pdf_url":"https://arxiv.org/pdf/2402.02998v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04219v1","updated":"2025-03-06T08:54:31Z","published":"2025-03-06T08:54:31Z","title":"Quantum-Inspired Reinforcement Learning in the Presence of Epistemic\n  Ambivalence","summary":"  The complexity of online decision-making under uncertainty stems from the\nrequirement of finding a balance between exploiting known strategies and\nexploring new possibilities. Naturally, the uncertainty type plays a crucial\nrole in developing decision-making strategies that manage complexity\neffectively. In this paper, we focus on a specific form of uncertainty known as\nepistemic ambivalence (EA), which emerges from conflicting pieces of evidence\nor contradictory experiences. It creates a delicate interplay between\nuncertainty and confidence, distinguishing it from epistemic uncertainty that\ntypically diminishes with new information. Indeed, ambivalence can persist even\nafter additional knowledge is acquired. To address this phenomenon, we propose\na novel framework, called the epistemically ambivalent Markov decision process\n(EA-MDP), aiming to understand and control EA in decision-making processes.\nThis framework incorporates the concept of a quantum state from the quantum\nmechanics formalism, and its core is to assess the probability and reward of\nevery possible outcome. We calculate the reward function using quantum\nmeasurement techniques and prove the existence of an optimal policy and an\noptimal value function in the EA-MDP framework. We also propose the\nEA-epsilon-greedy Q-learning algorithm. To evaluate the impact of EA on\ndecision-making and the expedience of our framework, we study two distinct\nexperimental setups, namely the two-state problem and the lattice problem. Our\nresults show that using our methods, the agent converges to the optimal policy\nin the presence of EA.\n","authors":["Alireza Habibi","Saeed Ghoorchian","Setareh Maghsudi"],"pdf_url":"https://arxiv.org/pdf/2503.04219v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.02495v2","updated":"2025-03-06T08:51:47Z","published":"2025-03-04T11:01:25Z","title":"Union of Experts: Adapting Hierarchical Routing to Equivalently\n  Decomposed Transformer","summary":"  We propose Union-of-Experts (UoE), which decomposes transformer into an\nequitant group of experts, and then implement selective routing on input data\nand experts. Our approach advances MoE design with four key innovations: (1) We\nconducted equitant expert decomposition on both MLP blocks and attention blocks\nbased on matrix partition in tensor parallelism. (2) We developed two routing\nparadigms: patch-wise data selection and expert selection, to apply routing\nacross different levels. (3) We design the architecture of UoE model, including\nSelective Multi-Head Attention (SMHA) and Union-of-MLP-Experts (UoME). (4) We\ndevelop parallel implementation of UoE's routing and computation operation, and\noptimize efficiency based on the hardware processing analysis. The experiments\ndemonstrate that the UoE model surpass Full Attention, state-of-art MoEs and\nefficient transformers (including the model architecture of recently proposed\nDeepSeek-V3) in several tasks across image and natural language domains. In\nlanguage modeling tasks, we achieve an average reduction of 2.38 in perplexity\ncompared to the best-performed MoE method with an average of 76% FLOPs. In Long\nRange Arena benchmark, we recorded an average score that is at least 0.68%\nhigher than all comparison models including Full Attention, MoEs, and\ntransformer variants, with only 50% FLOPs of the best MoE method. In image\nclassification, our model yielded an average accuracy improvement of 1.75% than\nthe best model while maintaining comparable FLOPs. The source codes are\navailable at https://github.com/YujiaoYang-work/UoE.\n","authors":["Yujiao Yang","Jing Lian","Linhui Li"],"pdf_url":"https://arxiv.org/pdf/2503.02495v2.pdf","comment":"17 pages"},{"id":"http://arxiv.org/abs/2503.01224v2","updated":"2025-03-06T08:51:38Z","published":"2025-03-03T06:43:45Z","title":"CE-U: Cross Entropy Unlearning","summary":"  Large language models (LLMs) inadvertently memorize sensitive data from their\nmassive pretraining corpora \\cite{jang2022knowledge}. In this work, we propose\nCE-U (Cross Entropy Unlearning), a novel loss function designed specifically\nfor unlearning tasks. CE-U addresses fundamental limitations of gradient ascent\napproaches which suffer from instability due to vanishing gradients when model\nconfidence is high and gradient exploding when confidence is low. We also unify\nstandard cross entropy supervision and cross entropy unlearning into a single\nframework. Notably, on the TOFU benchmark for unlearning \\cite{maini2024tofu},\nCE-U achieves state-of-the-art results on LLaMA2-7B with 1\\% and 5\\%\nforgetting, even without the use of any extra reference model or additional\npositive samples. Our theoretical analysis further reveals that the gradient\ninstability issues also exist in popular reinforcement learning algorithms like\nDPO \\cite{rafailov2023direct} and GRPO\\cite{Shao2024DeepSeekMath}, as they\ninclude a gradient ascent component. This suggests that applying CE-U\nprinciples to reinforcement learning could be a promising direction for\nimproving stability and convergence.\n","authors":["Bo Yang"],"pdf_url":"https://arxiv.org/pdf/2503.01224v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.04204v1","updated":"2025-03-06T08:30:18Z","published":"2025-03-06T08:30:18Z","title":"FUSE: First-Order and Second-Order Unified SynthEsis in Stochastic\n  Optimization","summary":"  Stochastic optimization methods have actively been playing a critical role in\nmodern machine learning algorithms to deliver decent performance. While\nnumerous works have proposed and developed diverse approaches, first-order and\nsecond-order methods are in entirely different situations. The former is\nsignificantly pivotal and dominating in emerging deep learning but only leads\nconvergence to a stationary point. However, second-order methods are less\npopular due to their computational intensity in large-dimensional problems.\nThis paper presents a novel method that leverages both the first-order and\nsecond-order methods in a unified algorithmic framework, termed FUSE, from\nwhich a practical version (PV) is derived accordingly. FUSE-PV stands as a\nsimple yet efficient optimization method involving a switch-over between first\nand second orders. Additionally, we develop different criteria that determine\nwhen to switch. FUSE-PV has provably shown a smaller computational complexity\nthan SGD and Adam. To validate our proposed scheme, we present an ablation\nstudy on several simple test functions and show a comparison with baselines for\nbenchmark datasets.\n","authors":["Zhanhong Jiang","Md Zahid Hasan","Aditya Balu","Joshua R. Waite","Genyi Huang","Soumik Sarkar"],"pdf_url":"https://arxiv.org/pdf/2503.04204v1.pdf","comment":"6 pages, 7 figures"},{"id":"http://arxiv.org/abs/2503.04203v1","updated":"2025-03-06T08:29:36Z","published":"2025-03-06T08:29:36Z","title":"Geometric Re-Analysis of Classical MDP Solving Algorithms","summary":"  We build on a recently introduced geometric interpretation of Markov Decision\nProcesses (MDPs) to analyze classical MDP-solving algorithms: Value Iteration\n(VI) and Policy Iteration (PI). First, we develop a geometry-based analytical\napparatus, including a transformation that modifies the discount factor\n$\\gamma$, to improve convergence guarantees for these algorithms in several\nsettings. In particular, one of our results identifies a rotation component in\nthe VI method, and as a consequence shows that when a Markov Reward Process\n(MRP) induced by the optimal policy is irreducible and aperiodic, the\nasymptotic convergence rate of value iteration is strictly smaller than\n$\\gamma$.\n","authors":["Arsenii Mustafin","Aleksei Pakharev","Alex Olshevsky","Ioannis Ch. Paschalidis"],"pdf_url":"https://arxiv.org/pdf/2503.04203v1.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2503.04446v1","updated":"2025-03-06T14:02:01Z","published":"2025-03-06T14:02:01Z","title":"SMTPD: A New Benchmark for Temporal Prediction of Social Media\n  Popularity","summary":"  Social media popularity prediction task aims to predict the popularity of\nposts on social media platforms, which has a positive driving effect on\napplication scenarios such as content optimization, digital marketing and\nonline advertising. Though many studies have made significant progress, few of\nthem pay much attention to the integration between popularity prediction with\ntemporal alignment. In this paper, with exploring YouTube's multilingual and\nmulti-modal content, we construct a new social media temporal popularity\nprediction benchmark, namely SMTPD, and suggest a baseline framework for\ntemporal popularity prediction. Through data analysis and experiments, we\nverify that temporal alignment and early popularity play crucial roles in\nsocial media popularity prediction for not only deepening the understanding of\ntemporal dynamics of popularity in social media but also offering a suggestion\nabout developing more effective prediction models in this field. Code is\navailable at https://github.com/zhuwei321/SMTPD.\n","authors":["Yijie Xu","Bolun Zheng","Wei Zhu","Hangjia Pan","Yuchen Yao","Ning Xu","Anan Liu","Quan Zhang","Chenggang Yan"],"pdf_url":"https://arxiv.org/pdf/2503.04446v1.pdf","comment":"accept by CVPR 2025"}]}}